- en: Machine Learning Deep Dive
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入学习机器学习
- en: The prior chapter on machine learning provided a preliminary overview of the
    subject, including the different classes and core concepts in the subject area.
    This chapter will delve deeper into the theoretical aspects of machine learning
    such as the limits of algorithms and how different algorithms work.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 之前关于机器学习的章节提供了该主题的初步概述，包括该主题领域的不同类别和核心概念。本章将更深入地探讨机器学习的理论方面，比如算法的限制以及不同算法的工作原理。
- en: '**Machine learning** is a vast and complex subject, and to that end, this chapter
    focuses on the breadth of different topics, rather than the depth. The concepts
    are introduced at a high level and the reader may refer to other sources to further
    their understanding of the topics.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**是一个广阔而复杂的主题，因此本章侧重于不同主题的广度，而不是深度。这些概念是以高层次介绍的，读者可以参考其他来源进一步了解这些主题。'
- en: We will start out by discussing a few fundamental theories in machine learning,
    such as Gradient Descent and VC Dimension. Next, we will look at Bias and Variance,
    two of the most important factors in any modelling process and the concept of
    bias-variance trade-off.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先讨论机器学习中的一些基本理论，比如梯度下降和VC维度。接下来，我们将研究偏差和方差，这两个在任何建模过程中最重要的因素，以及偏差-方差权衡的概念。
- en: We'll then discuss the various machine learning algorithms, their strengths
    and areas of applications.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将讨论各种机器学习算法，它们的优势和应用领域。
- en: We'll conclude with exercises that leverage real-world datasets to perform machine
    learning operations using R.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将通过使用真实世界的数据集来执行机器学习操作，来总结本章。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The bias, variance, and regularization properties
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偏差、方差和正则化属性
- en: Gradient descent and VC dimension theories
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度下降和VC维度理论
- en: Machine learning algorithms
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习算法
- en: 'Tutorial: Machine learning with R'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教程：使用R进行机器学习
- en: The bias, variance, and regularization properties
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差、方差和正则化属性
- en: Bias, variance, and the closely related topic of regularization hold very special
    and fundamental positions in the field of machine learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差、方差以及与之密切相关的正则化在机器学习领域中占据着非常特殊和基础的位置。
- en: Bias happens when a machine learning model is too 'simple', leading to results
    that are consistently off from the actual values.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当机器学习模型过于“简单”时，就会出现偏差，导致结果与实际值一直偏离。
- en: Variance happens when a model is too 'complex', leading to results that are
    very accurate on test datasets, but do not perform well on unseen/new datasets.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 方差发生在模型过于“复杂”时，导致在测试数据集上结果非常准确，但在未见过/新的数据集上表现不佳。
- en: Once users become familiar with the process of creating machine learning models,
    it would seem that the process is quite simplistic - get the data, create a training
    set and a test set, create a model, apply the model on the test dataset, and the
    exercise is complete. Creating models is easy; creating a *good* model is a much
    more challenging topic. But how can one test the quality of a model? And, perhaps
    more importantly, how does one go about building a 'good' model?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦用户熟悉了创建机器学习模型的过程，似乎这个过程相当简单-获取数据，创建训练集和测试集，创建模型，在测试数据集上应用模型，练习完成。创建模型很容易；创建一个*好*模型则是一个更具挑战性的话题。但是如何测试模型的质量呢？也许更重要的是，如何构建一个“好”的模型呢？
- en: The answer lies in a term called regularization. It's arguably a fancy word,
    but all it means is that during the process of creating a model, one benefits
    from penalizing an overly impressive performance on a training dataset and relaxing
    the same on a poorly performing model.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 答案在于一个叫做正则化的术语。这可能是一个花哨的词，但它的意思只是在创建模型的过程中，通过对训练数据集上过于出色的表现进行惩罚，对表现不佳的模型进行放松，从而受益。
- en: To understand regularization, it would help to know the concepts of overfitting
    and underfitting. For this, let us look at a simple but familiar example of drawing
    lines of best fit. For those who have used Microsoft Excel, you may have noticed
    the option to draw the *line of best fit* - in essence, given a set of points,
    you can draw a line that represents the data and approximates the function that
    the points represent.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解正则化，了解过拟合和欠拟合的概念会有所帮助。为此，让我们看一个简单但熟悉的例子，即绘制最佳拟合线。对于那些使用过Microsoft Excel的人，你可能已经注意到了绘制*最佳拟合线*的选项-实质上，给定一组点，你可以绘制一条代表数据并逼近点所代表的函数的线。
- en: 'The following table shows the prices vs square footage of a few properties.
    In order to determine the relationship between house prices and the size of the
    house, we can draw a line of best fit, or a trend line, as shown as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了几个属性的价格与面积的关系。为了确定房价与房屋大小之间的关系，我们可以绘制最佳拟合线或趋势线，如下所示：
- en: '| **Sq. ft.** | **Price ($)** |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| **Sq. ft.** | **Price ($)** |'
- en: '| 862 | 170,982 |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 862 | 170,982 |'
- en: '| 1235 | 227,932 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 1235 | 227,932 |'
- en: '| 932 | 183,280 |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 932 | 183,280 |'
- en: '| 1624 | 237,945 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 1624 | 237,945 |'
- en: '| 1757 | 275,921 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 1757 | 275,921 |'
- en: '| **1630** | 274,713 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| **1630** | 274,713 |'
- en: '| **1236** | 201,428 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| **1236** | 201,428 |'
- en: '| **1002** | 193,128 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| **1002** | 193,128 |'
- en: '| **1118** | 187,073 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| **1118** | 187,073 |'
- en: '| **1339** | 202,422 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| **1339** | 202,422 |'
- en: '| **1753** | 283,989 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| **1753** | 283,989 |'
- en: '| **1239** | 228,170 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| **1239** | 228,170 |'
- en: '| **1364** | 230,662 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **1364** | 230,662 |'
- en: '| **995** | 169,369 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| **995** | 169,369 |'
- en: '| **1000** | 157,305 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| **1000** | 157,305 |'
- en: 'If we were to draw a *line of best* *fit* using a linear trend line, the chart
    would look somewhat like this:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用线性趋势线绘制*最佳拟合线*，图表会看起来像这样：
- en: '![](img/c352bb42-90f4-43a0-ab7a-05d53e2916ae.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c352bb42-90f4-43a0-ab7a-05d53e2916ae.png)'
- en: Excel provides an useful additional feature that allows users to draw an extension
    of the trend line which can provide an estimate, or a *prediction*, of unknown
    variables. In this case, extending the trendline will show us, based on the function,
    what the prices for houses in the 1,800-2,000 sq. ft. range are likely to be.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Excel提供了一个有用的附加功能，允许用户绘制趋势线的延伸，这可以提供未知变量的估计或*预测*。在这种情况下，延伸趋势线将告诉我们，根据函数，1800-2000平方英尺范围内的房屋价格可能是多少。
- en: 'The linear function that describes the data is as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 描述数据的线性函数如下：
- en: '*y=126.13x + 54,466.81*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*y=126.13x + 54,466.81*'
- en: 'The following chart with an extended trend line shows that the price is most
    likely between `$275,000` and `$300,000`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 下图中的延伸趋势线显示价格很可能在275,000美元和300,000美元之间：
- en: '![](img/70b446ec-c433-4589-8aea-731806451a1c.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70b446ec-c433-4589-8aea-731806451a1c.png)'
- en: However, one may argue that the line is not the best approximation and that
    it may be possible to increase the value of R2, which in this case is 0.87\. In
    general, the higher the R^2, the better the model that describes the data. There
    are various different types of *R²* values, but for the purpose of this section,
    we'll assume that the higher the *R²*, the better the model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有人可能会认为这条线不是最好的近似，可能可以增加R2的值，这种情况下是0.87。一般来说，R^2越高，描述数据的模型就越好。有各种不同类型的*R²*值，但在本节中，我们假设*R²*越高，模型就越好。
- en: In the next section, we will draw a new trend line that has a much higher R^2,
    but using a polynomial function. This function has a higher R^2 (0.91 vs 0.87)
    and visually appears to be closer to the points on average.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将绘制一个具有更高R^2的新趋势线，但使用多项式函数。这个函数具有更高的R^2（0.91比0.87），在视觉上看起来更接近平均点。
- en: 'The function in this case is a 6^(th)-order polynomial:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，函数是一个6次多项式：
- en: '*y = -0.00x⁶ + 0.00x⁵ - 0.00x⁴ + 2.50x³ - 2,313.40x² + 1,125,401.77x - 224,923,813.17*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*y = -0.00x⁶ + 0.00x⁵ - 0.00x⁴ + 2.50x³ - 2,313.40x² + 1,125,401.77x - 224,923,813.17*'
- en: '![](img/98b77763-7482-4c42-9e49-62c7c75e2021.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/98b77763-7482-4c42-9e49-62c7c75e2021.png)'
- en: But, even though the line has a higher R^2, if we extend the trend line, intending
    to find what the prices of houses in the 1,800-2,000 sq. ft. range are likely
    to be, we get the following result.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，即使该线具有更高的R^2，如果我们延伸趋势线，试图找出1800-2000平方英尺范围内房屋的价格可能是什么，我们得到以下结果。
- en: Houses in the 1,800-2,000 sq. ft. range go from approx. $280,000 to negative
    $2 million at the 2,000^(th) sq. ft. In other words, people purchasing houses
    with 1800 sq. ft. are expected to spend $ 280,000 and those purchasing houses
    with 2,000 sq. ft. should, according to this function, with a 'higher R^2', receive
    $2 million! This, of course, is not accurate, but what we have just witnessed
    is what is known as **over-fitting**. The image below illustrates this phenomenon.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 1800-2000平方英尺范围内的房屋价格从大约280,000美元到负2百万美元。换句话说，购买1800平方英尺房屋的人预计要花费280,000美元，而购买2000平方英尺房屋的人根据这个函数应该获得200万美元！当然，这是不准确的，但我们刚刚见证的是所谓的**过拟合**。下图说明了这一现象。
- en: '![](img/8f39c591-a89e-499e-921c-900f60f31753.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f39c591-a89e-499e-921c-900f60f31753.png)'
- en: 'At the other end of the spectrum is **under-fitting**. This happens when the
    model built does not describe the data. In the following chart, the function y
    = 0.25x - 200 is one such example:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在光谱的另一端是**欠拟合**。当构建的模型不能描述数据时就会发生这种情况。在下图中，函数y = 0.25x - 200就是一个例子：
- en: '![](img/60b80a9d-cace-4bbb-ac95-ed3eac84763b.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/60b80a9d-cace-4bbb-ac95-ed3eac84763b.png)'
- en: 'In brief, this section can be abbreviated as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这一部分可以简化如下：
- en: A function that fits the data too well, such that the function can approximate
    nearly all of the points in the training dataset is considered overfitting.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个过于拟合数据的函数，可以近似训练数据集中的几乎所有点的函数被认为是过拟合。
- en: A function that does not fit the data at all, or in other words is far from
    the actual points in the training dataset, is considered underfitting.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个完全不适合数据的函数，或者换句话说远离训练数据集中实际点的函数被认为是欠拟合。
- en: Machine learning is the process of balancing between overfitting and underfitting
    the data. This is arguably not an easy exercise, which is why even though building
    a model may be trivial, building a model that is reasonably good is a much more
    difficult challenge.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '机器学习是在过拟合和欠拟合数据之间取得平衡的过程。这可能是一个不容易的练习，这就是为什么即使构建模型可能是微不足道的，构建一个相当不错的模型却是一个更加困难的挑战。 '
- en: Underfitting is when your function is *not thinking at all* - it has a high
    bias.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欠拟合是指你的函数“根本不思考”-它具有很高的偏差。
- en: Overfitting is when your function is *thinking too hard* - it has a high variance.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过拟合是指你的函数“想得太多”-它具有很高的方差。
- en: Another example for underfitting and overfitting is given in coming example.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欠拟合和过拟合的另一个例子将在接下来的例子中给出。
- en: 'Say we are tasked with determining if a bunch of fruit are oranges or apples,
    and have been given their location in a fruit basket (left-side or right-side),
    size and weight:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的任务是确定一堆水果是橙子还是苹果，并已经知道它们在水果篮（左侧或右侧）、大小和重量的位置：
- en: '| ![](img/be16688e-a356-4b63-923b-d9e25b01abb1.png) | ![](img/f6035a45-cd01-4de4-be71-f428126da2b1.png)
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| ![](img/be16688e-a356-4b63-923b-d9e25b01abb1.png) | ![](img/f6035a45-cd01-4de4-be71-f428126da2b1.png)
    |'
- en: '| **Basket 1 (Training Dataset)** | **Basket 2 (Test Dataset)** |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| **篮子1（训练数据集）** | **篮子2（测试数据集）** |'
- en: An example of overfitting could be that, based on the training dataset, with
    regard to Basket 1 we could conclude that the only fruits located on the right
    hand side of the basket are oranges and those on the left are all apples.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合的一个例子可能是，根据训练数据集，关于篮子1，我们可能得出结论说篮子右侧只有橙子，左侧全是苹果。
- en: An example of underfitting could be that I conclude that the basket has only
    oranges.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 欠拟合的一个例子可能是我得出结论说篮子里只有橙子。
- en: '**Model 1**: In the first case - for overfitting - I have, in essence, memorized
    the locations.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型1**：在第一种情况下-过拟合-我实际上是在记忆位置。'
- en: '**Model 2**: In the second case - for underfitting - I could not remember anything
    precisely at all.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型2**：在第二种情况下 - 对于欠拟合 - 我根本记不清任何东西。'
- en: Now, given a second basket - the test dataset where the positions of the apples
    and oranges are switched - if I were to use Model 1, I would incorrectly conclude
    that all the fruits on the right hand side are oranges and those on the left hand
    side are apples (since I memorized the training data).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，给定第二个篮子 - 位置为苹果和橙子互换的测试数据集 - 如果我使用模型1，我会错误地得出右手边的所有水果都是橙子，左手边的都是苹果的结论（因为我记住了训练数据）。
- en: If I were to use Model 2, I would, again, incorrectly conclude that all the
    fruits are oranges.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我使用模型2，我会再次错误地得出所有水果都是橙子的结论。
- en: There are, however, ways to manage the balance between underfitting and overfitting
    - or in other words, between high bias and high variance.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有办法管理欠拟合和过拟合之间的平衡 - 或者换句话说，高偏差和高方差之间的平衡。
- en: One of the methods commonly used for bias-variance trade-off is known as regularization.
    This refers to the process of penalizing the model (for example, the model's coefficients
    in a regression) in order to produce an output that generalizes well across a
    range of data points.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 用于偏差-方差权衡的常用方法之一称为正则化。这指的是对模型进行惩罚（例如，回归中的模型系数），以产生一个能够在一系列数据点上很好泛化的输出。
- en: 'The table on the next page illustrates some of the key concepts of bias and
    variance and illustrates options for remedial steps when a model has high bias
    or high variance:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 下一页的表格说明了偏差和方差的一些关键概念，并说明了当模型存在高偏差或高方差时的补救措施选项：
- en: '![](img/7fd11d61-930f-4e67-a737-7ba72e754400.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7fd11d61-930f-4e67-a737-7ba72e754400.png)'
- en: In terms of the modeling process, a high bias is generally indicated by the
    fact that both the training set error as well as the test set error remain consistently
    high. For high variance (overfitting), the training set error decreases rapidly,
    but the test set error remains unchanged.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在建模过程中，高偏差通常表现为训练集误差和测试集误差保持一致地高。对于高方差（过拟合），训练集误差迅速减少，但测试集误差保持不变。
- en: The gradient descent and VC Dimension theories
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度下降和VC维度理论
- en: Gradient descent and VC Dimension are two fundamental theories in machine learning.
    In general, **gradient descent** gives a structured approach to finding the optimal
    co-efficients of a function. The hypothesis space of a function can be large and
    with gradient descent, the algorithm tries to find a minimum (*a minima*) where
    the cost function (for example, the squared sum of errors) is the lowest.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降和VC维度是机器学习中的两个基本理论。一般来说，**梯度下降**提供了一种结构化方法来找到函数的最优系数。函数的假设空间可能很大，通过梯度下降，算法试图找到成本函数（例如，误差的平方和）最低的最小值。
- en: '**VC Dimension** provides an upper bound on the maximum number of points that
    can be classified in a system. It is in essence the measure of the richness of
    a function and provides an assessment of what the limits of a hypothesis are in
    a structured way. The number of points that can be exactly classified by a function
    or hypothesis is known as the VC Dimension of the hypothesis. For example, a linear
    boundary can accurately classify 2 or 3 points but not 4\. Hence, the VC Dimension
    of this 2-dimensional space would be 3.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**VC维度**提供了系统中可以分类的最大点数的上限。它本质上是函数丰富性的度量，并以结构化方式提供了对假设限制的评估。函数或假设可以准确分类的点数称为假设的VC维度。例如，线性边界可以准确分类2或3个点，但不能是4个。因此，这个二维空间的VC维度将是3。'
- en: VC Dimension, like many other topics in computational learning theory, is both
    complex and interesting. It is a lesser known (and discussed) topic, but one that
    has a profound implication as it attempts to answer questions about what the limits
    of learning can be.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: VC维度，就像计算学习理论中的许多其他主题一样，既复杂又有趣。这是一个较少人知晓（和讨论）的话题，但它试图回答关于学习限制的问题，因此具有深远的影响。
- en: Popular machine learning algorithms
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流行的机器学习算法
- en: There are various different classes of machine learning algorithms. As such,
    since algorithms can belong to multiple 'classes' or categories at the same time
    at a conceptual level, it is hard to specifically state that an algorithm belongs
    exclusively to a single class. In this section, we will briefly discuss a few
    of the most commonly used and well-known algorithms.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种不同类别的机器学习算法。因此，由于算法可以同时属于多个“类别”或类别，概念上很难明确说明算法专属于单一类别。在本节中，我们将简要讨论一些最常用和知名的算法。
- en: 'These include:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包括：
- en: Regression models
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归模型
- en: Association rules
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则
- en: Decision trees
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: Random forest
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Boosting algorithms
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boosting算法
- en: Support vector machines
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: K-means
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K均值
- en: Neural networks
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络
- en: Note that in the examples, we have shown the basic use of the R functions using
    the entire dataset. In practice, we'd split the data into a training and test
    set, and once we have built a satisfactory model apply the same on the test dataset
    to evaluate the model's performance.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这些示例中，我们展示了使用整个数据集的R函数的基本用法。在实践中，我们会将数据分成训练集和测试集，一旦建立了令人满意的模型，就会将其应用于测试数据集以评估模型的性能。
- en: Regression models
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归模型
- en: Regression models range from commonly used linear, logistic, and multiple regression
    algorithms used in statistics to Ridge and Lasso regression, which penalizes co-efficients
    to improve model performance.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型从统计学中常用的线性、逻辑和多元回归算法到Ridge和Lasso回归，后者对系数进行惩罚以提高模型性能。
- en: In our earlier examples, we saw the application of **linear regression** when
    we created trend-lines. **Multiple linear regression** refers to the fact that
    the process of creating the model requires multiple independent variables.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的例子中，我们看到了在创建趋势线时应用**线性回归**的情况。**多元线性回归**指的是创建模型的过程需要多个自变量。
- en: 'For instance:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '**Total Advertising Cost = x* Print Ads**, would be a simple linear regression;
    whereas'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**总广告成本 = x*印刷广告**，将是一个简单的线性回归；而'
- en: '**Total Advertising Cost = X + Print Ads + Radio Ads + TV Ads**, due to the
    presence of more than one independent variable (Print, Radio, and TV), would be
    a multiple linear regression.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**总广告成本 = X + 印刷广告 + 广播广告 + 电视广告**，由于存在多个独立变量（印刷、广播和电视），将是多元线性回归。'
- en: '**Logistic regression** is another commonly used statistical regression modelling
    technique that predicts the outcome of a discrete categorical value, mainly for
    cases where the outcome variable is dichotomous (for example, 0 or 1, Yes or No,
    and so on). There can, however, be more than 2 discrete outcomes (for example,
    State NY, NJ, CT) and this type of logistic regression is known as **multinomial
    logistic regression**.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑回归**是另一种常用的统计回归建模技术，用于预测离散分类值的结果，主要用于结果变量是二分的情况（例如，0或1，是或否等）。然而，也可以有超过2个离散的结果（例如，州NY、NJ、CT），这种类型的逻辑回归称为**多项式逻辑回归**。'
- en: '**Ridge and Lasso Regressions** include a regularization term (λ) in addition
    to the other aspects of Linear Regression. The regularization term, Ridge Regression,
    has the effect of reducing the β coefficients (thus ''penalizing'' the co-efficients).
    In Lasso, the regularization term tends to reduce some of the co-efficients to
    0, thus eliminating the effect of the variable on the final model:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**岭回归和Lasso回归**在线性回归的其他方面之外还包括一个正则化项（λ）。正则化项，岭回归，会减少β系数（因此“惩罚”系数）。在Lasso中，正则化项倾向于将一些系数减少到0，从而消除变量对最终模型的影响：'
- en: '![](img/c0734ce4-09ff-4e4f-9ae6-150d20324b53.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c0734ce4-09ff-4e4f-9ae6-150d20324b53.png)'
- en: '[PRE0]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Association rules
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关联规则
- en: Association rules mining, or **apriori**, attempts to find relationships between
    variables in a dataset. Association rules are frequently used for various practical
    real-world use cases. Given a set of variables, apriori can indicate the patterns
    inherent in a transactional dataset. One of our tutorials will be based on implementing
    an R Shiny Application for apriori and hence, more emphasis is being provided
    for the same in this section.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则挖掘，或**apriori**，试图找到数据集中变量之间的关系。关联规则经常用于各种实际的现实用例。给定一组变量，apriori可以指示交易数据集中固有的模式。我们的一个教程将基于实现用于apriori的R
    Shiny应用程序，因此在本节中将更加重视这一点。
- en: For instance, let's say a supermarket chain is deciding the order for placing
    items on the shelves. An apriori algorithm run against a database containing sales
    transactions would identify the items that, say, are most often bought together.
    This permits the supermarket to determine which items, when placed strategically
    in close proximity to one another, can yield the most sales. This is also often
    referred to as *market basket analysis*.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设一个超市连锁店正在决定货架上商品的摆放顺序。针对包含销售交易的数据库运行的apriori算法将识别出最常一起购买的商品。这使得超市能够确定哪些商品，当放置在彼此紧邻的战略位置时，可以产生最多的销售额。这通常也被称为*市场篮子分析*。
- en: 'A simple example that reflects this could be as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 反映这一点的一个简单例子可能是：
- en: '[PRE1]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In all these cases, the act of purchasing something on the left-hand side led
    to the purchase of the item mentioned on the right-hand side of the expression.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些情况下，左侧购买某物导致了表达式右侧提到的物品的购买。
- en: It is also possible to derive association rules from databases that do not necessarily
    contain *transactions*, but instead use a sliding window to go through events
    along a temporal attribute, such as with the WINEPI algorithm.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以从不一定包含*交易*的数据库中导出关联规则，而是使用滑动窗口沿着时间属性浏览事件，比如WINEPI算法。
- en: 'There are 3 primary measures in apriori. To illustrate them, let us use a sample
    dataset containing items purchased in 4 separate transactions:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori中有3个主要的度量。为了说明它们，让我们使用一个包含4个独立交易中购买的商品的样本数据集：
- en: '| **Transaction** | **Item 1** | **Item 2** | **Item 3** |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| **交易** | **商品1** | **商品2** | **商品3** |'
- en: '| 1 | Milk | Bread | Butter |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 牛奶 | 面包 | 黄油 |'
- en: '| 2 | Milk | Egg | Butter |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 牛奶 | 鸡蛋 | 黄油 |'
- en: '| 3 | Bread | Egg | Cheese |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 面包 | 鸡蛋 | 奶酪 |'
- en: '| 4 | Butter | Bread | Egg |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 黄油 | 面包 | 鸡蛋 |'
- en: Confidence
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 置信度
- en: 'Confidence refers to how often the right-hand side of the apriori expression
    is valid when the left-hand side is valid. For instance, given an expression:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 置信度指的是当左侧有效时，apriori表达式的右侧有多少次有效。例如，给定一个表达式：
- en: '[PRE2]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We would like to know how often Bread was purchased *when Milk was also purchased*.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想知道牛奶也购买时面包经常购买吗。
- en: 'In this case:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下：
- en: '**Transaction 1**: Milk and Bread are both present'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易1**：牛奶和面包都存在'
- en: '**Transaction 2**: Milk is present, but not Bread'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易2**：有牛奶，但没有面包'
- en: '**Transactions 3 and 4**: Milk is not present'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易3和4**：牛奶不存在'
- en: Hence, based on the what we saw, there were 2 transactions where Milk was present
    and of them, Bread was present in 1 transaction. Hence, the confidence for the
    rule {Milk} à {Bread} would be ½ = 50%
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，根据我们所看到的，有2个交易中有牛奶，其中有1个交易中有面包。因此，规则{牛奶} à {面包}的置信度为1/2 = 50%
- en: 'Taking another expression:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 再举个例子：
- en: '[PRE3]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We would like to know, when Bread was purchased, how often was Butter also
    purchased?:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想知道，购买面包时，黄油也经常购买吗？：
- en: '**Transaction 1**: Bread and Butter are both present'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易1**：面包和黄油都存在'
- en: '**Transaction 2**: There is no Bread (Butter is present, but our point of reference
    is Bread and hence this does not count)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易2**：没有面包（黄油是存在的，但我们的参考点是面包，因此这不算）'
- en: '**Transaction 3**: Bread is present but no Butter'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易3**：有面包但没有黄油'
- en: '**Transaction 4**: Bread and Butter are both present'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易4**：面包和黄油都存在'
- en: Hence, we have Bread in 3 of the transactions, and Bread & Butter in 2 of the
    3 transactions. Hence, in this case, the 'confidence' of the rule `{Bread} à {Butter}`
    is *2/3 = 66.7*.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种情况下，我们有3个交易中有面包，3个交易中有面包和黄油。因此，在这种情况下，规则{面包} à {黄油}的“置信度”是*2/3 = 66.7*。
- en: Support
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持
- en: Support refers to the number of times the rule is satisfied relative to the
    total number of transactions in the dataset.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 支持是指规则满足的次数与数据集中的总交易次数的比率。
- en: 'For instance:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '{Milk} --> {Bread}, occurs in 1 out of 4 Transactions (in Transaction 1). Hence,
    the support for this rule is ¼ = 0.25 (or 25%).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '{牛奶} --> {面包}，在4次交易中发生了1次（在交易1）。因此，这条规则的支持率为¼ = 0.25（或25%）。'
- en: '{Bread} --> {Butter}, occurs in 2 out of 4 Transactions (in Transaction 1 and
    4). Hence, the support for this rule is ½ = 0.50 (or 50%).'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包} --> {黄油}，在4次交易中发生了2次（在交易1和4）。因此，这条规则的支持率为½ = 0.50（或50%）。'
- en: Lift
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升
- en: 'Lift is arguably the most important of the 3 measures; it measures the support
    of the rule relative to the support of the individual sides of the expression;
    put differently, it measures how strong the rule is with respect to a random occurrence
    of the LHS and RHS of the expression. It is formally defined as:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 提升可以说是3个度量中最重要的一个；它衡量了规则相对于表达式的两侧的支持度；换句话说，它衡量了规则相对于LHS和RHS的随机发生的强度。它正式定义为：
- en: '*Lift = Support (Rule)/(Support(LHS) * Support (RHS))*'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '*提升=支持（规则）/（支持（LHS）*支持（RHS））*'
- en: A low value for lift (say, less than or equal to 1) indicates that the LHS and
    RHS occurrence are independent of one another, whereas a higher lift measure indicates
    that the co-occurrence is significant.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 低提升值（例如，小于或等于1）表示LHS和RHS的发生是相互独立的，而较高的提升度量表示共同发生是显著的。
- en: In our prior example,
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的例子中，
- en: '{Bread} --> {Butter} has a lift of:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包} --> {黄油}的提升为：'
- en: Support ({Bread} --> {Butter})
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 支持（{面包} --> {黄油}）
- en: Support {Bread} * Support {Butter}
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 支持{面包} * 支持{黄油}
- en: = 0.50/((3/4) * (3/4)) = 0.50/(0.75 * 0.75) = 0.89.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: = 0.50/（（3/4）*（3/4））= 0.50/（0.75 * 0.75）= 0.89。
- en: This indicates that although the Confidence of the rule was high, the rule in
    and of itself is not significant relative to other rules that may be higher than
    1.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明尽管规则的置信度很高，但规则本身相对于可能高于1的其他规则并不重要。
- en: 'An example of a rule with a Lift higher than 1 would be:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一个提升高于1的规则示例是：
- en: '{Item 1: Bread} --> {Item 3: Cheese}'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '{项目1：面包} --> {项目3：奶酪}'
- en: 'This has a Lift of:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这有一个提升：
- en: 'Support {Item 1: Bread --> Item 3: Cheese}/(Support {Item 1: Cheese} * Support
    {Item 3: Cheese})'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 支持{项目1：面包 --> 项目3：奶酪}/（支持{项目1：奶酪} * 支持{项目3：奶酪}）
- en: = (1/4)/((1/4)*(1/4) = 4.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: =（1/4）/（（1/4）*（1/4）= 4。
- en: Decision trees
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树
- en: Decision Trees are a predictive modeling technique that generates rules that
    derive the likelihood of a certain outcome based on the likelihood of the preceding
    outcomes. In general, decision trees are typically constructed similar to a **flowchart**,
    with a series of nodes and leaves that denote a parent-child relationship. Nodes
    that do not link to other nodes are known as leaves.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是一种预测建模技术，它生成推断出某种结果的可能性的规则，这些规则是基于先前结果的可能性推导出来的。一般来说，决策树通常类似于**流程图**，具有一系列节点和叶子，表示父子关系。不链接到其他节点的节点称为叶子。
- en: Decision Trees belong to a class of algorithms that are often known as **CART**
    (**Classification and Regression Trees**). If the outcome of interest is a categorical
    variable, it falls under a classification exercise, whereas if the outcome is
    a number, it is known as a regression tree.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树属于一类算法，通常被称为**CART**（**分类和回归树**）。如果感兴趣的结果是一个分类变量，它属于分类练习，而如果结果是一个数字，它被称为回归树。
- en: 'An example will help to make this concept clearer. Take a look at the chart:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子将有助于使这个概念更清晰。看一下图表：
- en: '![](img/7ac42b3c-4ec1-4a83-8c52-0e51853d030b.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7ac42b3c-4ec1-4a83-8c52-0e51853d030b.png)'
- en: 'The chart shows a hypothetical scenario: if school is closed/not closed. The
    rectangular boxes (in blue) represent the nodes. The first rectangle (School Closed)
    represent the *root* node, whereas the inner rectangles represent the *internal*
    nodes. The rectangular boxes with angled edges (in green and italic letters) represent
    the ''*leaves*'' (or *terminal* nodes).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示了一个假设的场景：如果学校关闭/不关闭。蓝色的矩形框代表节点。第一个矩形（学校关闭）代表*根*节点，而内部矩形代表*内部*节点。带有倾斜边缘的矩形框（绿色和斜体字母）代表“*叶子*”（或*终端*节点）。
- en: Decision Trees are simple to understand and one of the few algorithms that are
    not a 'black box'. Algorithms such as those used to create Neural Networks are
    often considered black boxes, as it is very hard - if not impossible - to intuitively
    determine the exact path by which a final outcome was reached due to the complexity
    of the model.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树易于理解，是少数不是“黑匣子”的算法之一。用于创建神经网络的算法通常被认为是黑匣子，因为由于模型的复杂性，很难（甚至不可能）直观地确定最终结果达成的确切路径。
- en: In R, there are various facilities for creating Decision Trees. A commonly used
    library for creating them in R is `rpart`. We'll revisit our `PimaIndiansDiabetes`
    dataset to see how a decision tree can be created using the package.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，有各种创建决策树的工具。在R中创建它们的常用库是`rpart`。我们将重新访问我们的`PimaIndiansDiabetes`数据集，看看如何使用该包创建决策树。
- en: We would like to create a model to determine how glucose, insulin, (body) mass,
    and age are related to diabetes. Note that in the dataset, diabetes is a categorical
    variable with a yes/no response.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想创建一个模型来确定葡萄糖、胰岛素、（体重）质量和年龄与糖尿病的关系。请注意，在数据集中，糖尿病是一个具有是/否响应的分类变量。
- en: 'For visualizing the decision tree, we will use the `rpart.plot` package. The
    code for the same is given as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化决策树，我们将使用`rpart.plot`包。相同的代码如下所示：
- en: '[PRE4]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](img/27b2b5d4-4128-4690-8f2c-328712a01cfe.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27b2b5d4-4128-4690-8f2c-328712a01cfe.png)'
- en: Reading from the top, the graph shows that that there are 500 cases of `diabetes=neg`
    in the dataset (out of a total of 768 records).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 从顶部开始阅读，图表显示数据集中有500个`糖尿病=neg`的情况（共768条记录）。
- en: '[PRE5]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Of the total number of records in the dataset (768) with value of glucose <
    128, there were 485 records marked as negative. Of these, the model correctly
    predicted 391 cases as negative (Node Number 2, the first one on the left from
    the bottom).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集中总共768条记录中，血糖<128的记录有485条被标记为负面。其中，模型正确预测了391个案例为负面（节点编号2，从底部向左的第一个节点）。
- en: For the records which had a glucose reading of > 128, there were 283 records
    marked as positive (Node Number 3, the node immediately below the topmost/root
    node). The model correctly classified 174 of these cases.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 对于血糖读数>128的记录，有283条记录标记为阳性（节点编号3，即最顶部/根节点的下方节点）。模型正确分类了这些案例中的174个。
- en: 'Another, more recent package for intuitive decision trees with comprehensive
    visual information is **FFTrees** (**Fast and Frugal Decision Trees**). The following
    example has been provided for informational purposes:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个更近期的提供直观决策树和全面视觉信息的包是**FFTrees**（**Fast and Frugal Decision Trees**）。以下示例仅供信息目的：
- en: '[PRE6]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](img/c984b3e7-7aa5-4ff3-a53e-d2b4d2eb1943.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c984b3e7-7aa5-4ff3-a53e-d2b4d2eb1943.png)'
- en: Decision Trees work by splitting the data recursively until a stopping criterion,
    such as when a certain depth has been reached, or the number of cases, is below
    a specified value. Each split is done based on the variable that will lead to
    a 'purer subset'.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树通过递归地分割数据，直到达到停止条件，比如达到一定深度或案例数量低于指定值。每次分割都是基于将导致“更纯净子集”的变量进行的。
- en: In principle, we can grow an endless number of trees from a given set of variables,
    which makes it a particularly hard and intractable problem. Numerous algorithms
    exist which provide an efficient method for splitting and creating decision trees.
    One such method is Hunt's Algorithm.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，我们可以从给定的变量集合中生成无数棵树，这使得它成为一个特别困难和棘手的问题。存在许多算法可以提供一种有效的方法来分裂和创建决策树。其中一种方法是Hunt's
    Algorithm。
- en: 'Further details about the algorithm can be found at: [https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf](https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf).'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 有关该算法的更多详细信息可以在以下链接找到：[https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf](https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf)。
- en: The Random forest extension
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林扩展
- en: Random forest is an extension of the decision tree model that we just discussed.
    In practice, Decision Trees are simple to understand, simple to interpret, fast
    to create using available algorithms, and overall, intuitive. However, Decision
    Trees are sensitive to small changes in the data, permit splits only along an
    axis (linear splits) and can lead to overfitting. To mitigate some of the drawbacks
    of decision trees, whilst still getting the benefit of their elegance, algorithms
    such as Random Forest create multiple decision trees and sample random features
    to leverage and build an aggregate model.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是我们刚讨论的决策树模型的扩展。在实践中，决策树易于理解、易于解释、使用现有算法快速创建，并且直观。然而，决策树对数据的细微变化敏感，只允许沿着一个轴进行分割（线性分割），并且可能导致过拟合。为了减轻决策树的一些缺点，同时仍然获得其优雅之处，诸如随机森林的算法会创建多个决策树，并对随机特征进行抽样以建立一个聚合模型。
- en: Random forest works on the principle of **bootstrap aggregating** or **bagging**.
    Bootstrap is a statistical term indicating random sampling with replacement. Bootstrapping
    a given set of records means taking a random number of records and possibly including
    the same record multiple times in a sample. Thereafter, the user would measure
    their metric of interest on the sample and then repeat the process. In this manner,
    the distribution of the values of the metric calculated from random samples multiple
    times is expected to represent the distribution of the population, and so the
    entire dataset.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林基于**自助聚合**或**bagging**的原则。Bootstrap是一个统计术语，表示带有替换的随机抽样。对给定的记录进行自助采样意味着随机抽取一定数量的记录，并可能在样本中多次包含相同的记录。然后，用户会在样本上测量他们感兴趣的指标，然后重复这个过程。通过这种方式，从随机样本中多次计算的指标值的分布预计将代表总体的分布，以及整个数据集。
- en: 'An example of Bagging a set of 3 numbers, such as (1,2,3,4), would be:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging的一个例子是一组3个数字，比如（1,2,3,4）：
- en: (1,2,3), (1,1,3), (1,3,3), (2,2,1), and others.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: （1,2,3），（1,1,3），（1,3,3），（2,2,1），等等。
- en: Bootstrap Aggregating, or *bagging*, implies leveraging a voting method using
    *multiple bootstrap samples* at a time, building a model on each individual sample
    (set of n records) and then finally aggregating the results.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Bootstrap Aggregating，或*bagging*，意味着利用*多个自助采样*进行投票，同时在每个个体样本（n条记录的集合）上构建模型，最后对结果进行聚合。
- en: Random forests also implement another level of operation beyond simple bagging.
    It also randomly selects the variables to be included in the model building process
    at each split. For instance, if we were to create a random forest model using
    the `PimaIndiansDiabetes` dataset with the variables pregnant, glucose, pressure,
    triceps, insulin, mass, pedigree, age, and diabetes, in each bootstrap sample
    (draw of n records), we would select a random subset of features with which to
    build the model--for instance, glucose, pressure, and insulin; insulin, age, and
    pedigree; triceps, mass, and insulin; and others.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林还实现了简单bagging之外的另一层操作。它还会在每次分裂时随机选择要包括在模型构建过程中的变量。例如，如果我们使用`PimaIndiansDiabetes`数据集创建一个随机森林模型，其中包括变量pregnant,
    glucose, pressure, triceps, insulin, mass, pedigree, age, 和diabetes，在每个自助采样（n条记录的抽样）中，我们会选择一个随机特征子集来构建模型--例如，glucose,
    pressure, 和insulin; insulin, age, 和pedigree; triceps, mass, 和insulin; 等等。
- en: 'In R, the package commonly used for RandomForest is called by its namesake,
    RandomForest. We can use it via the package as is or via caret. Both methods are
    shown as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，用于RandomForest的常用包被称为RandomForest。我们可以通过该包直接使用，也可以通过caret使用。两种方法如下所示：
- en: 'Using Random Forest using the RandomForest package:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Random Forest包：
- en: '[PRE7]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Using Random Forest via caret using the `method="rf"` function:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用caret的`method="rf"`函数进行随机森林：
- en: '[PRE8]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'It is also possible to see the splits and other related information in each
    tree of the original Random Forest model (which did not use caret). This can be
    done using the `getTree` function as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以在原始随机森林模型的每棵树中看到分裂和其他相关信息（未使用caret）。这可以使用`getTree`函数来完成：
- en: '[PRE9]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Boosting algorithms
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升算法
- en: Boosting is a technique that uses weights and a set of *weak learners*, such
    as decision trees, in order to improve model performance. Boosting assigns weights
    to data based on model misclassification and future learner's (created during
    the boosting machine learning process) focus on the misclassified examples. Examples
    that were correctly classified will be reassigned new weights which will generally
    be lower than those that were not correctly classified. The weight can be based
    on a cost function, such as a majority vote, using subsets of the data.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 提升是一种使用权重和一组*弱学习器*（如决策树）来提高模型性能的技术。提升根据模型误分类和未来学习器（在提升机器学习过程中创建）关注误分类示例来为数据分配权重。正确分类的示例将被重新分配新的权重，通常低于未正确分类的示例。权重可以基于成本函数，例如使用数据子集的多数投票。
- en: In simple and non-technical terms, boosting uses *a series of weak learners,
    and each learner 'learns' from the mistakes of the prior learners*.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 简单而非技术性地说，提升使用*一系列弱学习器，每个学习器都从先前学习器的错误中“学习”*。
- en: Boosting is generally more popular compared to bagging as it assigns weights
    relative to model performance rather than assigning equal weights to all data
    points as in bagging. This is conceptually similar to the difference between a
    weighted average versus an average function with no weighting criteria.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 与装袋相比，提升通常更受欢迎，因为它根据模型性能分配权重，而不是像装袋那样对所有数据点分配相等的权重。这在概念上类似于加权平均与没有加权标准的平均函数之间的区别。
- en: 'There are several packages in R for boosting algorithms and some of the commonly
    used ones are as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: R中有几个用于提升算法的软件包，其中一些常用的如下：
- en: Adaboost
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adaboost
- en: '**GBM** (**Stochastic Gradient Boosting**)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GBM（随机梯度提升）
- en: XGBoost
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost
- en: Of these, XGBoost is a widely popular machine learning package that has been
    used very successfully in competitive machine learning platforms such as Kaggle.
    XGBoost has a very elegant and computationally efficient way to creating ensemble
    models. Because it is both accurate and extremely fast, users have often used
    XGBoost for compute-intensive ML challenges. You can learn more about Kaggle at
    [http://www.kaggle.com](http://www.kaggle.com).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，XGBoost是一个广泛流行的机器学习软件包，在竞争激烈的机器学习平台（如Kaggle）上被非常成功地使用。XGBoost有一种非常优雅和计算效率高的方式来创建集成模型。由于它既准确又极快，用户经常用XGBoost来处理计算密集型的机器学习挑战。您可以在[http://www.kaggle.com](http://www.kaggle.com)了解更多关于Kaggle的信息。
- en: '[PRE10]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Support vector machines
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Support vector machines, commonly known as **SVMs**, are another class of machine
    learning algorithm that are used to classify data into one or another category
    using a concept called **hyperplane**, which is used to demarcate a linear boundary
    between points.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机，通常称为**SVMs**，是另一类用于使用称为**超平面**的概念将数据分类为一类或另一类的机器学习算法。超平面用于在点之间划定线性边界。
- en: 'For instance, given a set of black and white points on an x-y axis, we can
    find multiple lines that will separate them. The line, in this case, represents
    the function that delineates the category that each point belongs to. In the following
    image, lines H1 and H2 both separate the points accurately. In this case, how
    can we determine which one of H1 and H2 would be the optimal line?:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在x-y轴上给定一组黑白点，我们可以找到多条分隔它们的线。在这种情况下，线代表了划分每个点所属类别的函数。在下图中，线H1和H2都准确地分隔了点。在这种情况下，我们如何确定H1和H2中哪一个是最佳线呢？：
- en: '![](img/086d5f41-630d-4146-b5bc-34957e49f501.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/086d5f41-630d-4146-b5bc-34957e49f501.png)'
- en: Intuitively, we can say the line that is closest to the points - for instance,
    the vertical line H1 - might *not* be the optimal line to separate the points.
    Since the line is too close to the points, and so too specific to the points on
    the given dataset, a new point may be misclassified if it is even slightly off
    to the right or the left side of the line. In other words, the line is too sensitive
    to small changes in the data (which could be due to stochastic/deterministic noise,
    such as imperfections in the data).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，最靠近点的线 - 例如，垂直线H1 - 可能*不*是分隔点的最佳线。由于该线离点太近，因此对给定数据集上的点太具体，如果新点稍微偏离线的右侧或左侧，可能会被错误分类。换句话说，该线对数据的小变化过于敏感（这可能是由于随机/确定性噪声，如数据中的缺陷）。
- en: On the other hand, the line H2 manages to separate the data whilst maintaining
    the maximum possible distance from the points closest to the line. Slight imperfections
    in the data are unlikely to affect the classification of the points to the extent
    line H1 may have done. This, in essence, describes the principle of the maximum
    margin of separation as shown in the image below.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，线H2成功地分隔了数据，同时保持了离线最近的点的最大可能距离。数据中的轻微缺陷不太可能影响点的分类，就像线H1可能做的那样。这本质上描述了下图中所示的最大间隔分离原则。
- en: '**![](img/6f17c69e-6d57-4497-a95a-c8b36d1cdb19.png)**'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/6f17c69e-6d57-4497-a95a-c8b36d1cdb19.png)**'
- en: The points close to the line, also known as the hyperplane, are known as the
    'support vectors' (hence the name). In the image, the points that lie on the dashed
    line are therefore the support vectors.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 靠近线的点，也称为超平面，被称为“支持向量”（因此得名）。在图像中，位于虚线上的点因此是支持向量。
- en: 'In the real world, however, not all points may be ''linearly separable''. SVMs
    leverage a concept known as the ''kernel trick''. In essence, points that might
    not be linearly separable can be projected or mapped onto a higher dimensional
    surface. For example, given a set of points on a 2D x-y space that are not linearly
    separable, it may be possible to separate them if we were to project the points
    on a 3-dimensional space as shown in the following image. The points colored in
    red were not separable by a 2D line, but when mapped to a 3-dimensional surface,
    they can be separated by a hyperplane as shown in the following image:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在现实世界中，并非所有点都可能是“线性可分”的。支持向量机利用了一种称为“核技巧”的概念。实质上，可能不是线性可分的点可以被投影或映射到更高维度的表面上。例如，给定一个在2D
    x-y空间上的一组点，如果它们不是线性可分的，那么可能可以将它们投影到3维空间上，如下图所示。红色的点在2D线上是不可分的，但是当映射到3维表面时，它们可以被如下图所示的超平面分开：
- en: '![](img/10a74760-3d89-464f-b9c2-685247b84ba6.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10a74760-3d89-464f-b9c2-685247b84ba6.png)'
- en: 'There are several packages in R that let users leverage SVM, such as `kernlab`,
    `e1071`, `klaR`, and others. Here, we illustrate the use of SVM from the `e1071`
    package, as shown as follow:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: R中有几个包可以让用户利用SVM，比如`kernlab`、`e1071`、`klaR`等。在这里，我们展示了来自`e1071`包的SVM的使用，如下所示：
- en: '[PRE11]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](img/469a697c-7c5c-457e-a232-e330b01b3e66.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](img/469a697c-7c5c-457e-a232-e330b01b3e66.png)'
- en: '[PRE12]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The K-Means machine learning technique
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-Means机器学习技术
- en: K-Means is one of the most popular unsupervised machine learning techniques
    that is used to create clusters, and so categorizes data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: K-Means是最流行的无监督机器学习技术之一，用于创建聚类，从而对数据进行分类。
- en: 'An intuitive example could be posed as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 一个直观的例子可以如下提出：
- en: Say a university was offering a new course on American History and Asian History.
    The university maintains a 15:1 student-teacher ratio, so there is 1 teacher per
    15 students. It has conducted a survey which contains a 10-point numeric score
    that was assigned by each student to their preference of studying American History
    or Asian History.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一所大学开设了一门新的美国历史和亚洲历史课程。该大学保持15:1的学生-教师比例，因此每15名学生配备1名教师。它进行了一项调查，其中包含每位学生对学习美国历史或亚洲历史的偏好分配的10分数值分数。
- en: 'We can use the in-built K-Means algorithm in R to create 2 clusters and presumably,
    by the number of points in each cluster, it may be possible to get an estimate
    of the number of students who may sign up for each course. The code for the same
    is given as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用R中内置的K-Means算法创建2个簇，可能通过每个簇中的点的数量来估计可能报名每门课程的学生人数。相同的代码如下所示：
- en: '[PRE13]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following image could provide an intuitive estimate of the number of students
    who may sign up for each course (and thereby determine how many teachers may be
    required):'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像可以直观地估计每门课程可能报名的学生人数（从而确定可能需要多少老师）：
- en: '![](img/33e06eed-9895-473c-a410-34899e68a800.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/33e06eed-9895-473c-a410-34899e68a800.png)'
- en: 'There are several variations of the K-Means algorithm, but the standard and
    the most commonly used one is Lloyd''s Algorithm. The algorithm steps are as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: K-Means算法有几种变体，但标准和最常用的是Lloyd算法。算法步骤如下：
- en: 'Given a set of n points (say in an x-y axis), in order to find k clusters:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组n个点（比如在x-y轴上），为了找到k个簇：
- en: Select k points at random from the dataset to represent the mid-points for k
    clusters (say, the *initial centroids*).
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据集中随机选择k个点，代表k个簇的中点（比如*初始质心*）。
- en: The distance from each of the other points to the selected k points (representing
    k clusters) is measured and assigned to the cluster that has the lowest distance
    from the point.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从所选的k个点到其他点的距离（代表k个簇）被测量，并分配给距离最近的簇。
- en: The cluster centers are recalculated as the mean of the points in the cluster.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 簇中心被重新计算为簇中点的平均值。
- en: The distance between the centroids and all the other points are again calculated
    as in Step 2 and new centroids are calculated as in Step 3\. In this manner, Steps
    2 and 3 are repeated until no new data is re-assigned.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次计算质心与所有其他点之间的距离，如步骤2中所示，并计算新的质心，如步骤3中所示。以此类推，重复步骤2和3，直到没有新数据被重新分配。
- en: Various *distance and similarity measures* exist for clustering, such as **Euclidean
    Distance** (straight-line distance), **Cosine Similarity** (Cosine of angles between
    vectors), **Hamming Distance** (generally used for categorical variables), **Mahalanobis
    Distance** (named after P.C. Mahalanobis; this measures the distance between a
    point and the mean of a distribution), and others.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 存在各种用于聚类的*距离和相似度度量*，如**欧氏距离**（直线距离），**余弦相似度**（向量之间的夹角的余弦），**汉明距离**（通常用于分类变量），**马哈拉诺比斯距离**（以P.C.马哈拉诺比斯命名；这测量了一个点与分布的均值之间的距离），等等。
- en: 'Although the optimal number of clusters cannot always be unambiguously identified,
    there are various methods that attempt to find an estimate. In general, clusters
    can be measured by how close points within a cluster are to one another (within
    cluster variance, such as the sum of squares--WSS) and how far apart the clusters
    are (so higher distances between clusters would make the clusters more readily
    distinguishable). One such method that is used to determine the optimal number
    is known as the **elbow method**. The following chart illustrates the concept:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不能总是明确地确定最佳的簇数，但有各种方法试图找到一个估计。一般来说，可以通过簇内点之间的接近程度（簇内方差，如平方和-WSS）和簇之间的距离来衡量簇（因此簇之间的较大距离会使簇更容易区分）。用于确定最佳数量的一种方法称为**肘部法**。以下图表说明了这个概念：
- en: '![](img/c0a29271-8d0e-4b07-9d74-bd3c2dc982c5.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c0a29271-8d0e-4b07-9d74-bd3c2dc982c5.png)'
- en: The chart shows a plot of the WSS (within the cluster sum of squares that we're
    seeking to minimize) versus the number of clusters. As is evident, increasing
    the number of clusters from 1 to 2 decreases the WSS value substantially. The
    value for WSS decreases rapidly up until the 4^(th) or 5^(th) cluster, when adding
    more clusters does not lead to a significant improvement in WSS. By visual assessment,
    the machine learning practitioner can conclude that the ideal number of clusters
    that can be created is between 3-5, based on the image.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示了WSS（我们试图最小化的簇内平方和）与簇的数量之间的关系。显然，将簇的数量从1增加到2会大幅降低WSS值。当增加更多的簇时，WSS的值会迅速下降，直到第4或第5个簇，之后再增加簇不会显著改善WSS。通过视觉评估，机器学习从业者可以得出结论，可以创建的理想簇的数量在3-5之间，根据图像。
- en: Note that a low WSS score is not enough to determine the optimal number of clusters.
    It has to be done by inspecting the improvement in the metric. The WSS will eventually
    reduce to 0 when each point becomes an independent cluster.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，低WSS分数不足以确定最佳簇的数量。必须通过检查指标的改善来完成。当每个点成为独立簇时，WSS最终会减少到0。
- en: The neural networks related algorithms
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与神经网络相关的算法
- en: Neural Network related algorithms have existed for many decades. The first computational
    model was described by Warren McCulloch and Walter Pitts in 1943 in the Bulletin
    of Mathematical Biophysics.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 与神经网络相关的算法已经存在了很多十年。第一个计算模型是由沃伦·麦卡洛克和沃尔特·皮茨于1943年在《数学生物物理学公报》上描述的。
- en: You can learn more about these concepts at [https://pdfs.semanticscholar.org/5272/8a99829792c3272043842455f3a110e841b1.pdf](https://pdfs.semanticscholar.org/5272/8a99829792c3272043842455f3a110e841b1.pdf)
    and [https://en.wikipedia.org/wiki/Artificial_neural_network](https://en.wikipedia.org/wiki/Artificial_neural_network).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://pdfs.semanticscholar.org/5272/8a99829792c3272043842455f3a110e841b1.pdf](https://pdfs.semanticscholar.org/5272/8a99829792c3272043842455f3a110e841b1.pdf)和[https://en.wikipedia.org/wiki/Artificial_neural_network](https://en.wikipedia.org/wiki/Artificial_neural_network)了解更多相关概念。
- en: Various man-made objects in the physical world, such as aeroplanes, have drawn
    inspiration from nature. A neural network is in essence a representation of the
    phenomenon of data exchange between the axons and dendrons (also known as dendrites)
    of neurons in the *human nervous system*. Just as data passes between one neuron
    to multiple other neurons to make complex decisions, an artificial neural network
    in similar ways creates a network of neurons that receive input from other neurons.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 物理世界中的各种人造物体，如飞机，都从自然中汲取了灵感。神经网络本质上是对神经元之间数据交换现象的一种表征，这种现象发生在*人类神经系统*中的轴突和树突（也称为树突）之间。就像数据在一个神经元和多个其他神经元之间传递以做出复杂的决策一样，人工神经网络以类似的方式创建了一个接收其他神经元输入的神经元网络。
- en: 'At a high level, an artificial neural network consists of 4 main components:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，人工神经网络由4个主要组件组成：
- en: Input Layer
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入层
- en: Hidden Layer(s)
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏层
- en: Output Layer
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出层
- en: Nodes and Weights
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点和权重
- en: 'This is depicted in the following image:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这在下图中表示出来：
- en: '![](img/1664ecf7-b0e7-4a0b-bcca-457fa1f07629.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1664ecf7-b0e7-4a0b-bcca-457fa1f07629.png)'
- en: Each node in the diagram produces an output based on the input from the preceding
    layer. The output is produced using an **activation function**. There are various
    types of activation functions and the output produced depends on the type of function
    used. Examples include binary step (0 or 1), tanh (between -1 and +1), sigmoid,
    and others.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的每个节点根据前一层的输入产生输出。输出是使用**激活函数**产生的。有各种类型的激活函数，产生的输出取决于所使用的函数类型。例如二进制步进（0或1）、双曲正切（-1到+1之间）、Sigmoid等。
- en: 'The following diagram illustrates the concept:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了这个概念：
- en: '![](img/a84f0aef-960d-4e7a-b280-d68dd85b9e11.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a84f0aef-960d-4e7a-b280-d68dd85b9e11.png)'
- en: 'The values x1 and x2 are the inputs, w1 and w2 represent the weights, and the
    node represents the point at which the inputs and their weights are evaluated
    and a specific output is produced by the activation function. The output f can
    thus be represented by:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 值x1和x2是输入，w1和w2代表权重，节点代表对输入和它们的权重进行评估并由激活函数产生特定输出的点。因此，输出f可以表示为：
- en: '![](img/889c62d8-9180-48a5-bfe3-06c3cdcd33ed.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![](img/889c62d8-9180-48a5-bfe3-06c3cdcd33ed.png)'
- en: Here, f represents the activation function, and b represents the bias term.
    The bias term is independent of the weights and the input values and allows the
    user to shift the output to achieve a better model performance.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，f代表激活函数，b代表偏置项。偏置项独立于权重和输入值，并允许用户移动输出以实现更好的模型性能。
- en: Neural networks with multiple hidden layers (generally 2 or more) are computationally
    intensive, and in recent days, neural networks with multiple hidden layers, also
    known as deep neural networks or more generally deep learning, have become immensely
    popular.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 具有多个隐藏层（通常为2个或更多）的神经网络计算量很大，在最近的日子里，具有多个隐藏层的神经网络，也被称为深度神经网络或更一般地称为深度学习，已经变得非常流行。
- en: A lot of the developments in the industry, driven by machine learning and artificial
    intelligence, have been the direct result of the implementation of such multi-layer
    neural networks.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 行业中的许多发展都是由机器学习和人工智能推动的，这些发展直接是多层神经网络的实现结果。
- en: 'In R, the package `nnet` provides a readily usable interface to neural networks.
    Although in practice, neural networks generally require sophisticated hardware,
    GPU cards, and so on for illustration purposes, we have leveraged the `nnet` package
    to run the earlier classification exercise on the `PimaIndiansDiabetes` dataset.
    In the example, we will leverage caret in order to execute the `nnet` model:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，`nnet`包提供了一个可直接使用的神经网络接口。尽管在实践中，神经网络通常需要复杂的硬件、GPU卡等，但为了说明的目的，我们已经利用`nnet`包在`PimaIndiansDiabetes`数据集上运行了早期的分类练习。在这个例子中，我们将利用caret来执行`nnet`模型：
- en: '[PRE14]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](img/c6baa443-294b-4514-8dcb-38bb030d0fbf.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6baa443-294b-4514-8dcb-38bb030d0fbf.png)'
- en: '[PRE15]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Tutorial - associative rules mining with CMS data
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 教程 - 使用CMS数据进行关联规则挖掘
- en: This tutorial will implement an interface for accessing rules created using
    the Apriori Package in R.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将实现一个用于访问在R中使用Apriori包创建的规则的接口。
- en: 'We''ll be downloading data from the CMS OpenPayments website. The site hosts
    data on payments made to physicians and hospitals by companies:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从CMS OpenPayments网站下载数据。该网站提供有关公司向医生和医院支付的数据：
- en: '![](img/f21aafc2-9e34-4665-865d-54eda8ee3aad.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f21aafc2-9e34-4665-865d-54eda8ee3aad.png)'
- en: The site provides various ways of downloading data. Users can select the dataset
    of interest and download it manually. In our case, we will download the data using
    one of the Web-based APIs that is available to all users.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 该网站提供了多种下载数据的方式。用户可以选择感兴趣的数据集并手动下载。在我们的情况下，我们将使用其中一种面向所有用户的基于Web的API来下载数据。
- en: Downloading the data
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载数据
- en: 'The dataset can be downloaded either at the Unix terminal (in the virtual machine)
    or by accessing the site directly from the browser. If you are downloading the
    dataset in the Virtual Machine, run the following command in the terminal window:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以通过Unix终端（在虚拟机中）下载，也可以直接从浏览器访问该网站进行下载。如果您在虚拟机中下载数据集，请在终端窗口中运行以下命令：
- en: '[PRE16]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Alternatively, if you are downloading the data from a browser, enter the following
    URL in the browser window and hit *Enter*:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您从浏览器下载数据，请在浏览器窗口中输入以下URL并点击*Enter*：
- en: '[https://openpaymentsdata.cms.gov/resource/vq63-hu5i.csv?$query=select Physician_First_Name
    as firstName,Physician_Last_Name as lastName,Recipient_City as city,Recipient_State
    as state,Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name as company,Total_Amount_of_Payment_USDollars
    as payment,Nature_of_Payment_or_Transfer_of_Value as paymentNature,Product_Category_or_Therapeutic_Area_1
    as category,Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1 as product
    where covered_recipient_type like "Covered Recipient Physician" and Recipient_State
    like "NY"](https://openpaymentsdata.cms.gov/resource/vq63-hu5i.csv?%24query=select%20Physician_First_Name%20as%20firstName,Physician_Last_Name%20as%20lastName,Recipient_City%20as%20city,Recipient_State%20as%20state,Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name%20as%20company,Total_Amount_of_Payment_USDollars%20as%20payment,Nature_of_Payment_or_Transfer_of_Value%20as%20paymentNature,Product_Category_or_Therapeutic_Area_1%20as%20category,Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1%20as%20product%20where%20covered_recipient_type%20like%20%22Covered%20Recipient%20Physician%22%20and%20Recipient_State%20like%20%22NY%22)'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://openpaymentsdata.cms.gov/resource/vq63-hu5i.csv?$query=select Physician_First_Name
    as firstName,Physician_Last_Name as lastName,Recipient_City as city,Recipient_State
    as state,Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name as company,Total_Amount_of_Payment_USDollars
    as payment,Nature_of_Payment_or_Transfer_of_Value as paymentNature,Product_Category_or_Therapeutic_Area_1
    as category,Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1 as product
    where covered_recipient_type like "Covered Recipient Physician" and Recipient_State
    like "NY"](https://openpaymentsdata.cms.gov/resource/vq63-hu5i.csv?%24query=select%20Physician_First_Name%20as%20firstName,Physician_Last_Name%20as%20lastName,Recipient_City%20as%20city,Recipient_State%20as%20state,Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name%20as%20company,Total_Amount_of_Payment_USDollars%20as%20payment,Nature_of_Payment_or_Transfer_of_Value%20as%20paymentNature,Product_Category_or_Therapeutic_Area_1%20as%20category,Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1%20as%20product%20where%20covered_recipient_type%20like%20%22Covered%20Recipient%20Physician%22%20and%20Recipient_State%20like%20%22NY%22)'
- en: 'As shown in the following image:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示：
- en: '![](img/2f67c791-65e6-4e7c-aca8-8011b4e0eb33.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2f67c791-65e6-4e7c-aca8-8011b4e0eb33.png)'
- en: Writing the R code for Apriori
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写Apriori的R代码
- en: The Apriori algorithm, as explained earlier, allows users to find relationships
    or patterns inherent in a dataset. For this, we will use the arules package in
    R/RStudio. The code will read the dataset downloaded (called `cms2016_2.csv` in
    the example) and run the apriori algorithm in order to find associative rules.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Apriori算法允许用户查找数据集中固有的关系或模式。为此，我们将在R/RStudio中使用arules包。该代码将读取下载的数据集（在示例中称为`cms2016_2.csv`）并运行Apriori算法以查找关联规则。
- en: 'Create a new R file in RStudio and enter the following code. Make sure that
    you change the location of the csv file that you downloaded to the appropriate
    directory where the file has been stored:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在RStudio中创建一个新的R文件，并输入以下代码。确保您更改了下载的csv文件的位置，以便将其存储在适当的目录中：
- en: '[PRE17]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Shiny (R Code)
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Shiny（R代码）
- en: 'In RStudio, select File | New File | Shiny Web App:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在RStudio中，选择文件|新建文件|Shiny Web应用程序：
- en: '![](img/f0044242-690a-47a1-92bd-7c09da18d9bb.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f0044242-690a-47a1-92bd-7c09da18d9bb.png)'
- en: 'Enter the following code in `app.R`:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在`app.R`中输入以下代码：
- en: '[PRE18]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The following image shows the code being copied and saved in a file called `app.R`.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像显示了代码被复制并保存在名为`app.R`的文件中。
- en: '![](img/fd2894d0-c621-4d9e-b169-450f2408f273.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fd2894d0-c621-4d9e-b169-450f2408f273.png)'
- en: Using custom CSS and fonts for the application
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为应用程序使用自定义CSS和字体
- en: For our application, we will use a custom CSS File. We will also use custom
    fonts in order to give the application a nice look-and-feel.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的应用程序，我们将使用自定义的CSS文件。我们还将使用自定义字体，以使应用程序具有良好的外观和感觉。
- en: You can download the custom CSS File from the software repository for this book.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从本书的软件存储库中下载自定义的CSS文件。
- en: 'The CSS, Fonts, and other related files should be stored in a folder called
    `www` in the directory where you created the R Shiny Application:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: CSS、字体和其他相关文件应存储在名为`www`的文件夹中，该文件夹位于您创建R Shiny应用程序的目录中：
- en: '![](img/429dc22c-98bc-473a-89dc-7961b7811cc9.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![](img/429dc22c-98bc-473a-89dc-7961b7811cc9.png)'
- en: Running the application
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行应用程序
- en: 'If all goes well, you should be now able to run the application by clicking
    on the Run App option on the top of the page, as shown in the following images:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，您现在应该能够通过点击页面顶部的“运行应用程序”选项来运行应用程序，如下图所示：
- en: '![](img/ebc58a2c-7459-439d-9364-d22e13b55c10.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebc58a2c-7459-439d-9364-d22e13b55c10.png)'
- en: Upon clicking the "Run" button, the user will see a popup window similar to
    the one shown below. Note that popups should be enabled in the browser for this
    to function.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 单击“运行”按钮后，用户将看到一个类似下面所示的弹出窗口。请注意，浏览器中应启用弹出窗口才能正常运行。
- en: '![](img/fa672f9b-88b0-4b6b-8da1-970452c79e7a.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fa672f9b-88b0-4b6b-8da1-970452c79e7a.png)'
- en: 'The app has multiple controls, such as:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序具有多个控件，例如：
- en: '**Search LHS/RHS**: Enter any test that you want to filter for, in the Left-Hand
    Side or the Right-Hand Side of the rule.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**搜索LHS/RHS**：在规则的左侧或右侧输入您想要过滤的任何测试。'
- en: '**Support**: Indicates the prevalence of the rule in the dataset.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持**：指示数据集中规则的普遍性。'
- en: '**Confidence**: Of the rules, how many were exact matches.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**置信度**：规则中有多少是精确匹配的。'
- en: '**Lift**: Variable defining the importance of a rule. Numbers above 1 are considered
    significant.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提升**：定义规则重要性的变量。大于1的数字被认为是显著的。'
- en: You can use this app for any other rules file as long as they are processed
    in a way similar to the one outlined before in the R Script section.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 只要它们以与R脚本部分中概述的方式类似的方式进行处理，您就可以将此应用于任何其他规则文件。
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Machine learning practitioners are often of the opinion that creating models
    is easy, but creating a good one is much more difficult. Indeed, not only is creating
    a *good* model important, but perhaps more importantly, knowing how to identify
    a *good* model is what distinguishes successful versus less successful Machine
    Learning endeavors.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习从业者常常认为创建模型很容易，但创建一个好模型要困难得多。事实上，不仅创建一个“好”模型很重要，更重要的是知道如何识别“好”模型，这是成功与不那么成功的机器学习努力之间的区别。
- en: In this chapter, we read up on some of the deeper theoretical concepts in Machine
    Learning. Bias, Variance, Regularization, and other common concepts were explained
    with examples as and where needed. With accompanying R code, we also learnt about
    some of the common machine learning algorithms such as Random Forest, Support
    Vector Machines, and others. We concluded with a tutorial on how to create an
    exhaustive web-based application for Association Rules Mining against CMS OpenPayments
    data.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入了解了机器学习中一些更深层次的理论概念。偏差、方差、正则化和其他常见概念都在需要时用例子解释了。通过附带的R代码，我们还学习了一些常见的机器学习算法，如随机森林、支持向量机等。最后，我们通过教程学习了如何针对CMS
    OpenPayments数据创建一个详尽的基于Web的关联规则挖掘应用程序。
- en: In the next chapter, we will read about some of the technologies that are being
    used in enterprises for both big data as well as machine learning. We will also
    discuss the merits of cloud computing and how they are influencing the selection
    of enterprise software and hardware stacks.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将阅读一些在企业中用于大数据和机器学习的技术。我们还将讨论云计算的优点以及它们如何影响企业软件和硬件堆栈的选择。
