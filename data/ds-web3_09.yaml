- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Generative Art for NFTs
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NFT的生成艺术
- en: “I use data as a pigment and paint with a painting brush that is assisted by
    artificial intelligence.”
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: “我使用数据作为颜料，借助人工智能的画笔进行绘画。”
- en: – Refik Anadol
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ——Refik Anadol
- en: In this chapter, we’ll take an artistic break and indulge in some creativity.
    While our previous focus was on analyzing content generated by others on the blockchain,
    in this chapter, we will be creating our own content to be added to the blockchain.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将进行一次艺术休息，尽情发挥创造力。虽然我们之前的重点是分析区块链上由他人生成的内容，但在本章中，我们将创造自己的内容，并将其添加到区块链上。
- en: The inclusion of this chapter stems from the recognition that, as data scientists,
    we might encounter requests to produce or assist in crafting an NFT collection
    in collaboration with a group of artists. In [*Chapter 4*](B19446_04.xhtml#_idTextAnchor145),
    we studied the artistic applications of NFTs and explored notable collections,
    such as *Bored Ape*, which has a total traded volume of 978,382 ETH (approximately
    USD 1,800 million). We do not know whether they used AI to produce all the images,
    but they are a good use case of how art can be owned and traded on the blockchain.
    To be able to participate in that market, we will learn about the entire process,
    from crafting an image to listing it for sale on OpenSea.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的加入源于认识到，作为数据科学家，我们可能会遇到需要与艺术家团队合作，制作或协助制作NFT系列的请求。在[*第4章*](B19446_04.xhtml#_idTextAnchor145)中，我们研究了NFT的艺术应用，并探索了诸如*Bored
    Ape*等知名系列，该系列的总交易量为978,382 ETH（约合18亿美元）。我们不清楚他们是否使用了人工智能来制作所有图像，但它们是艺术可以在区块链上拥有和交易的一个很好的案例。为了能够参与这个市场，我们将学习从制作图像到在OpenSea上列出销售的整个过程。
- en: 'One particular collection named *Artsy Monke* used AI to create images by combining
    the Bored Ape collection with 20 curated painting styles. You can find their OpenSea
    collection website at [https://opensea.io/collection/artsy-monke](https://opensea.io/collection/artsy-monke).
    The image on the cover of the book is Artsy Monke #9937.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '一个名为*Artsy Monke*的系列使用人工智能通过将Bored Ape系列与20种精选的绘画风格相结合来创作图像。您可以在[https://opensea.io/collection/artsy-monke](https://opensea.io/collection/artsy-monke)找到他们的OpenSea系列网站。书本封面上的图像是Artsy
    Monke #9937。'
- en: Another example is Refik Anadol’s *Machine Hallucinations* collection, which
    is a collaboration with NASA that uses over two million raw images, recorded by
    space institutions such as the International Space Station, the Hubble and MRO
    telescopes across the world into six AI data-created paintings and one sculpture
    as input.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是Refik Anadol的*机器幻觉*系列，这是与NASA合作的项目，使用了超过两百万张由国际空间站、哈勃望远镜和MRO望远镜等空间机构记录的原始图像，经过人工智能数据处理，创作了六幅画作和一件雕塑作为输入。
- en: 'The complete spectrum of tools that AI has enabled is beyond the scope of this
    chapter. However, we will discuss three practical tools that may be useful if
    an artist group contacts us to help them build their NFT collection: colorizing,
    transfer style, and prompt generative art. We will go from edits that do not modify
    the content and progress to full creation of images. Finally, we will learn how
    to create a collection on the blockchain and list it for sale.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能所带来的工具范围超出了本章的讨论范围。然而，我们将讨论三种可能对艺术家团队联系以帮助他们建立NFT系列时有用的实际工具：上色、风格迁移和提示生成艺术。我们将从不修改内容的编辑开始，逐步过渡到完全创作图像。最后，我们将学习如何在区块链上创建一个系列并将其列出销售。
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Creating with colors – colorization tool
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创作色彩——上色工具
- en: Creating with style – style transfer workflow
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创作风格——风格迁移工作流程
- en: Creating with prompts – text-to-image solutions
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创作提示——文本转图像解决方案
- en: Monetization – minting and selling NFTs
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变现——铸造和销售NFT
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we’ll employ distinct tools for each section. For the *colorization*
    segment, we will work with a program named `.zip` file onto your computer that
    needs to be extracted.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将为每个部分使用不同的工具。对于*上色*部分，我们将使用一个名为`.zip`的程序，该程序需要下载到您的计算机并解压缩。
- en: Moving to the *style transfer* segment, we will use a VGG19 model, whose documentation
    can be found at [https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19/VGG19](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19/VGG19).
    It follows the Keras example available at [https://keras.io/examples/generative/neural_style_transfer/](https://keras.io/examples/generative/neural_style_transfer/).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 转到*风格迁移*部分，我们将使用一个VGG19模型，其文档可以在[https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19/VGG19](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19/VGG19)找到。它遵循的是Keras示例，详见[https://keras.io/examples/generative/neural_style_transfer/](https://keras.io/examples/generative/neural_style_transfer/)。
- en: For the *text-to-image* segment, we will interact with a Leonardo AI platform
    for which we only need to create an account. Furthermore, we will interact with
    the OpenSea platform, which will require us to have an active wallet for minting
    purposes.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*文本到图像*部分，我们将与 Leonardo AI 平台进行互动，只需要创建一个账户。此外，我们还将与 OpenSea 平台互动，这要求我们拥有一个有效的钱包，以便进行铸造。
- en: You can find all the data and code files for this chapter in this book’s GitHub
    repository at [https://github.com/PacktPublishing/Data-Science-for-Web3/tree/main/Chapter09](https://github.com/PacktPublishing/Data-Science-for-Web3/tree/main/Chapter09).
    We recommend that you read through the code files in the `Chapter09` folder to
    follow along. The NFT collection created in this chapter is accessible at [https://opensea.io/collection/mysterious-library](https://opensea.io/collection/mysterious-library).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本书的GitHub仓库中找到所有数据和代码文件，链接为[https://github.com/PacktPublishing/Data-Science-for-Web3/tree/main/Chapter09](https://github.com/PacktPublishing/Data-Science-for-Web3/tree/main/Chapter09)。我们建议你阅读`Chapter09`文件夹中的代码文件，以便跟随本书学习。本章节中创建的NFT系列可以在[https://opensea.io/collection/mysterious-library](https://opensea.io/collection/mysterious-library)访问。
- en: Creating with colors – colorizing
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创作与颜色 – 着色
- en: Colorizing an image involves a lot of work for the artistic team. As data scientists,
    we can assist them with a tool that allows us to paint easily while following
    their artistic direction. The tool we’re referring to is named **Style2Paints**,
    a semi-automatic method for colorization that can produce automatic results when
    there is no need for color correction. It also provides a functionality to provide
    hints to the tool for more customized results.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 给图像着色需要艺术团队付出大量工作。作为数据科学家，我们可以借助一种工具来辅助他们，这个工具可以在遵循艺术方向的同时，轻松地进行绘画。我们所提到的工具叫做**Style2Paints**，它是一种半自动着色方法，在不需要色彩修正时可以生成自动化的结果。它还提供了一个功能，允许为工具提供提示，以便获得更加定制化的结果。
- en: Hands-on Style2Paints
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Style2Paints 实操
- en: 'Once Style2Paints has been installed, the main page looks like what’s shown
    in *Figure 9**.1*. There’s a color style column on the left-hand side and a color
    palette on the right:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了 Style2Paints，主页面将像*图 9.1*所示。左侧有一个颜色样式栏，右侧则有一个色板：
- en: '![Figure 9.1 – Style2Paints main view](img/B19446_09_01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.1 – Style2Paints 主视图](img/B19446_09_01.jpg)'
- en: Figure 9.1 – Style2Paints main view
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – Style2Paints 主视图
- en: 'This tool can be used with color and black-and-white images. Follow these steps:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工具可以与彩色图像和黑白图像一起使用。请按以下步骤操作：
- en: To upload an image for colorization, click on the symbol.![](img/Icon_1.jpg)
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要上传图像进行着色，点击符号。![](img/Icon_1.jpg)
- en: Select the painting region of the image and click **OK**.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择图像的绘画区域并点击**确定**。
- en: On the left, we will be offered a list of images that have already been pre-colored
    that can be clicked and downloaded. For instance, if we upload a basic sketch
    or “line art,” the tool will suggest some color styles located at the left-hand
    side of the site.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧，我们将看到一个已预先着色的图像列表，可以点击并下载。例如，如果我们上传一个基础草图或“线条艺术”，工具将会在网站的左侧建议一些颜色样式。
- en: 'Consider the following line art example:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下线条艺术示例：
- en: '![Figure 9.2 – Book binding machine, Joseph William Zaehnsdorf, public domain,
    via Wikimedia Commons](img/B19446_09_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.2 – 书籍装订机，Joseph William Zaehnsdorf，公共领域，来自 Wikimedia Commons](img/B19446_09_02.jpg)'
- en: Figure 9.2 – Book binding machine, Joseph William Zaehnsdorf, public domain,
    via Wikimedia Commons
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – 书籍装订机，Joseph William Zaehnsdorf，公共领域，来自 Wikimedia Commons
- en: 'By using these color styles, we can create eight different colored images of
    the book binder from a single black-and-white image just by clicking on a color
    combination:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用这些颜色样式，我们可以仅通过点击一种颜色组合，从一张黑白图像创建出八种不同颜色的书籍装订机图像：
- en: '![Figure 9.3 – Colorized versions of book binding](img/B19446_09_03.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.3 – 书籍装订的着色版本](img/B19446_09_03.jpg)'
- en: Figure 9.3 – Colorized versions of book binding
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 – 书籍装帧的彩色版本
- en: 'It is also possible to edit images that already have some color. For example,
    let’s consider Artsy Monke #9937:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '也可以编辑已经有一些颜色的图像。例如，我们考虑艺术猴 #9937：'
- en: '![Figure 9.4 – Artsy Monke #9937](img/B19446_09_04.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图9.4 – 艺术猴 #9937](img/B19446_09_04.jpg)'
- en: 'Figure 9.4 – Artsy Monke #9937'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '图9.4 – 艺术猴 #9937'
- en: 'We can easily change the colors that are used by the image by using the color
    style offering located on the left-hand side of the tool. By clicking on each
    color combination, the images change. Some examples can be seen in *Figure 9**.5*:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用位于工具左侧的颜色样式选项轻松更改图像使用的颜色。点击每种颜色组合，图像会发生变化。可以在*图9.5*中看到一些示例：
- en: '![Figure 9.5 – Colorized Artsy Monke #9937](img/B19446_09_05.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图9.5 – 彩色艺术猴 #9937](img/B19446_09_05.jpg)'
- en: 'Figure 9.5 – Colorized Artsy Monke #9937'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '图9.5 – 彩色艺术猴 #9937'
- en: It is also possible to manually colorize without the color style suggestions
    and use a color palette with “hint points,” as the documentation names it. A use
    case for hints is keeping a certain aesthetic the same or correcting some of the
    color style suggestions Follow these steps:.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以在没有颜色样式建议的情况下手动上色，并使用文档所称的“提示点”颜色调色板。提示的使用场景是保持某种美学一致性或纠正一些颜色样式建议。按照以下步骤操作：
- en: Select one of the colors on the right-hand side of the tool by clicking on it.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击工具右侧的颜色之一来选择一个颜色。
- en: Add a dot to the part of the image we want to colorize with the selected color.
    This is a “hint.”
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们想要用选定颜色着色的图像部分添加一个点。这是一个“提示”。
- en: Click on the icon; the image will reload, painting the selected area with the
    color we chose.![](img/Icon_2.jpg)
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击图标；图像将重新加载，用我们选择的颜色涂绘所选区域。![](img/Icon_2.jpg)
- en: A step-by-step tutorial on how to use this intuitive tool can be found in the
    *Further* *reading* section.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何使用这个直观工具的逐步教程可以在*进一步* *阅读*部分找到。
- en: Theory
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论
- en: A **convolutional neural network** (**CNN**) is a specialized type of deep neural
    network that’s designed primarily for analyzing visual data. At a high level,
    CNNs are inspired by how the human visual system processes information. They consist
    of layers that automatically learn and detect various features, such as edges,
    corners, textures, and more complex patterns, from raw pixel data. These learned
    features are then used for tasks such as image classification, object detection,
    facial recognition, and more.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNN**）是一种专门用于分析视觉数据的深度神经网络类型。总体而言，CNN受到人类视觉系统如何处理信息的启发。它们由多个层次组成，这些层次能够自动学习和检测各种特征，如边缘、角落、纹理以及更复杂的模式，从原始像素数据中提取出来。这些学习到的特征随后可用于图像分类、物体检测、人脸识别等任务。'
- en: 'The following are the key components of a CNN:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是CNN的关键组件：
- en: '**Convolutional layer**: This is the core of a CNN. It applies a set of learnable
    filters (also called kernels) to the input image. The layer identifies the distinct
    features of an image in a process known as feature extraction.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层**：这是卷积神经网络（CNN）的核心。它将一组可学习的滤波器（也叫卷积核）应用到输入图像上。这个过程被称为特征提取，用于识别图像的不同特征。'
- en: '**Pooling layer**: This layer reduces the spatial dimensions of the feature
    maps while retaining important information. There are two types of pooling: max
    pooling and average pooling. It is usually applied after the convolutional layer
    to reduce the size of the feature map that was created in the previous layer.
    After several convolutional and pooling layers, the feature maps are flattened
    into a one-dimensional vector, which serves as the input to the fully connected
    layers.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**池化层**：此层减少特征图的空间维度，同时保留重要信息。池化有两种类型：最大池化和平均池化。通常在卷积层后应用，以减少在前一层创建的特征图的大小。经过几层卷积和池化层后，特征图被展平成一维向量，作为全连接层的输入。'
- en: '**Fully connected layers**: These layers are similar to those in traditional
    neural networks, connecting separate layers.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层**：这些层类似于传统神经网络中的层，连接不同的层。'
- en: 'The components we’ve just detailed can be visualized in order in *Figure 9**.6*:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚详细描述的组件可以按顺序在*图9.6*中可视化：
- en: '![Figure 9.6 – Structure of a CNN. Photo by Alison Wang in Unsplash](img/B19446_09_06.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图9.6 – CNN的结构。照片由Alison Wang提供，来自Unsplash](img/B19446_09_06.jpg)'
- en: Figure 9.6 – Structure of a CNN. Photo by Alison Wang in Unsplash
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6 – CNN的结构。照片由Alison Wang提供，来自Unsplash
- en: CNNs are trained using labeled datasets. During training, the network’s parameters
    (weights and biases) are updated using optimization algorithms such as gradient
    descent to minimize a loss function that quantifies the difference between predicted
    and actual labels.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: CNN使用标注数据集进行训练。在训练过程中，网络的参数（权重和偏置）通过优化算法（如梯度下降）进行更新，以最小化一个损失函数，该损失函数量化了预测标签和实际标签之间的差异。
- en: 'The Style2Paints model is based on a CNN framework trained with the Danbooru
    database, which has two parts: the draft and refinement processes. According to
    the *Two-stage Sketch Colorization* paper, “*The first drafting stage aggressively
    splashes colors over the canvas to create a color draft, with the goal of enriching
    the color variety (…) The second refinement stage corrects the color mistakes,
    refines details and polishes blurry textures to achieve the final output*.” This
    neural network has been trained to work with color sketches that, by definition,
    lack some important information, such as shades or textures.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Style2Paints模型基于一个CNN框架，并使用Danbooru数据库进行训练，模型包含两个部分：草图和细化过程。根据*两阶段草图着色*论文，“*第一个草图阶段会大胆地将颜色涂抹到画布上，创建一个颜色草图，目的是丰富颜色的多样性
    (…) 第二个细化阶段纠正颜色错误，细化细节并打磨模糊的纹理，以达到最终的输出效果*。”该神经网络已被训练来处理缺乏一些重要信息（如阴影或纹理）的彩色草图。
- en: 'It uses **generative adversarial networks** (**GANs**), a type of CNN for generative
    modeling. This type of neural network works with two sub-models: a generator and
    a discriminator. The generator performs an unsupervised task, summarizing the
    distribution of the training dataset (generally images) and generating synthetic
    replicas to be analyzed by the discriminator. The discriminator receives the replicas,
    combined with some samples of the training dataset, and performs a supervised
    task, classifying between real (the ground truth sample) and fake (the generated
    by the generator). The model is considered trained when the discriminator cannot
    identify a generated image from a ground truth one. The generator is then kept
    to generate new samples of the problem domain.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 它使用**生成对抗网络**（**GANs**），这是一种用于生成建模的CNN类型。这种神经网络由两个子模型组成：生成器和判别器。生成器执行无监督任务，总结训练数据集（通常是图像）的分布，并生成合成副本供判别器分析。判别器接收这些副本，并将其与一些训练数据集的样本结合起来，执行有监督任务，区分真实样本（地面真实样本）和假样本（由生成器生成的）。当判别器无法区分生成图像和地面真实图像时，模型被认为已经训练完成。生成器此时被保留用于生成该问题领域的新样本。
- en: 'The training process can be seen in the following figure:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程可以通过以下图示来查看：
- en: '![Figure 9.7 – Steps in the training process](img/B19446_09_07.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.7 – 训练过程的步骤](img/B19446_09_07.jpg)'
- en: Figure 9.7 – Steps in the training process
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.7 – 训练过程的步骤
- en: This can be seen as two sub-models competing against each other and getting
    better at generating and discriminating. That is why the word “adversarial” is
    in its name. An overview of this structure can be found in the *Further* *reading*
    section.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以看作是两个子模型相互竞争并不断提高生成和辨别能力。这就是为什么“对抗性”这个词出现在它的名称中的原因。该结构的概述可以在*进一步阅读*部分找到。
- en: Training GANs require large datasets and a lot of GPU. Videos from the Washington
    University of Saint Louis have been included in the *Further reading* section
    if you are interested in training your own GAN.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 训练GAN需要大量数据集和大量GPU。如果你有兴趣训练自己的GAN，圣路易斯华盛顿大学的视频已经包含在*进一步阅读*部分。
- en: A note on training datasets
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于训练数据集的说明
- en: Better results will be yielded if the model that’s being used has been trained
    with the same image style that we are trying to reproduce. For example, if we
    want to paint with a photographic style, we may try to avoid using anime-trained
    models.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用的模型已经使用我们尝试重现的图像风格进行训练，通常会得到更好的结果。例如，如果我们想要用摄影风格进行绘画，我们可能会尽量避免使用经过动漫风格训练的模型。
- en: As anticipated, Style2Paints was trained with the Danbooru dataset, which is
    a tagged anime dataset that has been evolving and expanding over time. Style2Paints
    was trained on the 2018 version, but at the time of writing, there is a 2021 version.
    This dataset contains images accompanied by a JSON file with metadata and tags.
    The anime art has some common characteristics, such as big expressive eyes with
    vibrant colors, heightened expressions, and a varied color palette to reflect
    the atmosphere present in the images.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，Style2Paints是使用Danbooru数据集训练的，Danbooru是一个经过标注的动漫数据集，随着时间的推移不断发展和扩展。Style2Paints是在2018年版本上进行训练的，但在撰写时，已有2021年版本。该数据集包含带有元数据和标签的图像。动漫艺术有一些共同特征，例如大而富有表现力的眼睛、鲜艳的色彩、夸张的表情，以及变化丰富的色彩调色板，用以反映图像中的氛围。
- en: 'The following are some commonly used image datasets:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些常用的图像数据集：
- en: '**ImageNet**: This is a compilation of images that follows the WordNet hierarchy.
    Each relevant concept in the WordNet collection is a “synonym set” that forms
    relations with other synsets, establishing a hierarchy of concepts: from general
    to abstract and specific. The ImageNet project is trying to provide 1,000 images
    per synset. This dataset is useful for object classification tasks. For more information,
    visit [https://www.image-net.org/](https://www.image-net.org/).'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ImageNet**：这是一个图像集合，遵循WordNet层级结构。WordNet集合中的每个相关概念都是一个“同义词集”，与其他同义词集形成关系，建立起从一般到抽象和具体的概念层级。ImageNet项目试图为每个同义词集提供1,000张图像。该数据集对于目标分类任务非常有用。欲了解更多信息，请访问[https://www.image-net.org/](https://www.image-net.org/)。'
- en: '**Common Objects in Context** (**COCO**): This is a large-scale dataset that’s
    been annotated for object detection tasks. It contains over 33,000 images, organized
    into directories, and the annotations are in JSON format and contain the objects
    and the bounding box coordinates. For more information, visit [https://cocodataset.org/#home.](https://cocodataset.org/#home.)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常见的上下文对象**（**COCO**）：这是一个大型数据集，已被注释用于目标检测任务。它包含超过33,000张图像，按目录组织，注释以JSON格式存储，包含对象和边界框坐标。欲了解更多信息，请访问[https://cocodataset.org/#home](https://cocodataset.org/#home)。'
- en: '**MPII Human Pose Database**: This dataset has been prepared for use in human
    pose estimation tasks. It contains approximately 25,000 images reflecting over
    410 everyday human activities. For more information, visit [http://human-pose.mpi-inf.mpg.de/](http://human-pose.mpi-inf.mpg.de/).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MPII人体姿势数据库**：该数据集已为人体姿势估计任务准备。它包含大约25,000张图像，反映了超过410种日常人类活动。欲了解更多信息，请访问[http://human-pose.mpi-inf.mpg.de/](http://human-pose.mpi-inf.mpg.de/)。'
- en: '**Frames Labeled in Cinema**: This dataset contains images that have been extracted
    from popular Hollywood movies. The images went through multiple processes (from
    selection to cleaning) before undergoing a final manual review and annotation
    of body joints. For more information, visit [https://bensapp.github.io/flic-dataset.xhtml](https://bensapp.github.io/flic-dataset.xhtml).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电影中标记的帧**：该数据集包含从流行好莱坞电影中提取的图像。这些图像经过多个处理过程（从选择到清理），然后进行了最终的人工审查和身体关节的标注。欲了解更多信息，请访问[https://bensapp.github.io/flic-dataset.xhtml](https://bensapp.github.io/flic-dataset.xhtml)。'
- en: '**Caltech-UCSD Birds-200-2011**: This dataset contains close to 12,000 images
    of 200 categories of birds with test and train subsets. Each image has detailed
    annotations, including one subcategory label, 15 part locations, 312 binary attributes,
    and one bounding box. The dataset is available on TensorFlow. For more information,
    visit [https://www.vision.caltech.edu/datasets/cub_200_2011/](https://www.vision.caltech.edu/datasets/cub_200_2011/).'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Caltech-UCSD Birds-200-2011**：该数据集包含约12,000张来自200个鸟类类别的图像，并分为测试集和训练集。每张图像都有详细的注释，包括一个子类别标签、15个部位位置、312个二进制属性和一个边界框。该数据集可在TensorFlow上获取。欲了解更多信息，请访问[https://www.vision.caltech.edu/datasets/cub_200_2011/](https://www.vision.caltech.edu/datasets/cub_200_2011/)。'
- en: '**Laion-5b**: This is the dataset over which Stable Diffusion (something we’ll
    review shortly) was trained. It contains 5.85 billion CLIP-filtered image-text
    pairs via a general crawl of the internet that was done by the German entity LAION.
    For more information, visit [https://laion.ai/blog/laion-5b/](https://laion.ai/blog/laion-5b/).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Laion-5b**：这是Stable Diffusion（我们稍后将回顾的内容）训练所使用的数据集。它包含58.5亿对通过CLIP筛选的图像-文本对，这些数据通过德国实体LAION进行的互联网大规模抓取收集而来。欲了解更多信息，请访问[https://laion.ai/blog/laion-5b/](https://laion.ai/blog/laion-5b/)。'
- en: In this section, we learned how to use a tool that helps in the coloring workflow,
    automatically or manually. In the following section, we will dig deeper into coloring
    with a broader impact on the image by transferring a style from one image to the
    other with AI.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们学习了如何使用一个工具，它可以帮助进行着色工作流程，无论是自动还是手动。接下来的部分，我们将深入探讨通过 AI 将一种图像的风格迁移到另一张图像，从而对图像进行广泛的着色影响。
- en: Creating with style – style transfer
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 风格创作——风格迁移
- en: 'Another way we can assist an artistic team is via style transfer, a process
    that involves combining two images:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过风格迁移来帮助艺术团队，这是一种将两张图像结合起来的过程：
- en: The style image or *root* image, from which we will learn the style
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 风格图像或*根*图像，我们将从中学习风格
- en: The target image, which we will transform with the new style
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标图像，我们将使用新的风格来转换它
- en: The resulting image will retain the core elements of the target image but appear
    to be painted or printed following the style image.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图像将保留目标图像的核心元素，但看起来像是按照风格图像的风格绘制或印刷的。
- en: There are several methods for performing style transfer, including leveraging
    GANs (described in the previous section), using **Visual Geometry Group** (**VGG**),
    and employing Stable Diffusion (which we will cover in the next section).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 风格迁移有多种方法，包括利用 GAN（上一部分中描述）、使用 **视觉几何组**（**VGG**），以及使用稳定扩散（我们将在下一部分讨论）。
- en: In `style_transfer.ipynb`, we will use VGG19, a special type of CNN with 19
    layers that has been trained with over a million images from the ImageNet database
    to extract the style of a Picasso painting and transfer it to a photograph. Picasso
    belonged to the **cubism** movement, where the artists applied multiple perspectives,
    used geometric shapes, and flattened the picture plane. An interesting article
    on the defining characteristics of this artistic movement can be found in the
    *Further* *reading* section.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `style_transfer.ipynb` 中，我们将使用 VGG19，这是一个具有 19 层的特殊 CNN 类型，已使用来自 ImageNet
    数据库的超过百万张图像进行训练，以提取毕加索画作的风格并将其迁移到一张照片上。毕加索属于**立体主义**运动，在这一运动中，艺术家们运用了多种视角，使用几何形状，并且将画面平面进行了简化。关于这一艺术运动的定义特征，可以在
    *进一步* *阅读* 部分找到一篇有趣的文章。
- en: Let’s go through the steps we must follow.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步了解我们必须遵循的步骤。
- en: Preparation
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'First, we must obtain the tensor representations of the root and target images.
    The `preprocess_image()` function does this by leveraging the Keras library with
    the following code snippet:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须获得根图像和目标图像的张量表示。`preprocess_image()` 函数通过使用 Keras 库和以下代码片段来完成这项工作：
- en: '[PRE0]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Model building
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型构建
- en: 'We build the VGG19 model by setting the ImageNet dataset weights, which means
    the model will be initialized with weights that have been pre-trained on the ImageNet
    dataset. The `include_top` parameter is set to `False`, which means the top layers
    that are responsible for classification are not included in the model. The reason
    is that we want to use the VGG19 model as a feature extractor rather than for
    classification purposes:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过设置 ImageNet 数据集的权重来构建 VGG19 模型，这意味着模型将使用已经在 ImageNet 数据集上预训练的权重进行初始化。`include_top`
    参数设置为 `False`，这意味着模型中不包括负责分类的顶部层。原因是我们希望将 VGG19 模型用作特征提取器，而非用于分类目的：
- en: '[PRE1]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The code also extracts the information that’s generated by each layer of the
    model so that it can be used in the loss functions that we’ll describe here.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 代码还提取了由模型每一层生成的信息，以便在后续的损失函数中使用，这些损失函数我们将在此处进行描述。
- en: 'We define three loss functions:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了三个损失函数：
- en: The **total variation loss**, which seeks to ensure the coherence of the final
    image by measuring the spatial continuity between pixels in the resulting image.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总变差损失**，它通过衡量结果图像中像素之间的空间连续性，来确保最终图像的一致性。'
- en: The `content_layer_name`.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`content_layer_name`。'
- en: The `style_layer_names`.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`style_layer_names`。'
- en: The style loss uses a gram matrix (which is essentially a tensor multiplied
    by its transpose) and is calculated in the `gram_matrix()` function. The rationale
    behind the gram matrix of a convolutional layer is to combine the style features
    that are learned among them. For instance, Pablo Picasso's cubism is a combination
    of colors, shapes, and textures. A synthesis (the gram) of those features measuring
    the correlation between them will represent Picasso’s style.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 风格损失使用的是一个 Gram 矩阵（本质上是一个张量与其转置相乘），并在 `gram_matrix()` 函数中计算。卷积层的 Gram 矩阵的理论基础是将它们之间学到的风格特征结合起来。例如，毕加索的立体主义是一种颜色、形状和纹理的结合。通过这些特征的合成（即
    Gram 矩阵）来衡量它们之间的相关性，将能代表毕加索的风格。
- en: The `compute_loss` function summarizes the combination of the various losses
    defined previously, while `compute_loss_and_grads` runs the calculations.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`compute_loss`函数总结了之前定义的各种损失的组合，而`compute_loss_and_grads`执行计算。'
- en: Training and inference
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练与推理
- en: The training process will reduce the style loss and the content loss, which
    make up the total variation loss. The training process uses **stochastic gradient
    descent** (**SGD**) as the optimizer to iteratively decrease the loss.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程将减少风格损失和内容损失，这两者构成了总变差损失。训练过程使用**随机梯度下降**（**SGD**）作为优化器，以迭代方式减少损失。
- en: The proposed script saves the image every 100 iterations, allowing us to monitor
    image variation. The documentation proposes displaying the final image at the
    end of the training process, which we set at 4,000 steps.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 提议的脚本在每100次迭代后保存图像，以便我们监控图像变化。文档建议在训练过程结束时展示最终图像，我们将训练步数设置为4000步。
- en: 'By using the `util` function in the notebook named `deprocess_image()`, which
    rebuilds the image from a tensor into a `.png` file so that it’s ready to be saved
    and displayed, we can see the style transfer of a Pablo Picasso painting to a
    photograph:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用笔记本中名为`deprocess_image()`的`util`函数，该函数将张量重建为`.png`文件，以便可以保存和显示，我们可以看到将毕加索画作风格转移到照片上的效果：
- en: '![Figure 9.8 – A waterfall in Picasso’s painting style](img/B19446_09_08.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.8 – 毕加索画风中的瀑布](img/B19446_09_08.jpg)'
- en: Figure 9.8 – A waterfall in Picasso’s painting style
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.8 – 毕加索画风中的瀑布
- en: In the first section, we learned how to modify images automatically by applying
    color; in this section, we reviewed how to create images by combining a base image
    with a specific style. In both cases, we provided the images we wanted to modify.
    In the next section, we will learn how to create images with a text input or prompt.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一部分，我们学习了如何通过应用颜色自动修改图像；在这一部分，我们回顾了如何通过将基础图像与特定风格相结合来创建图像。在这两种情况下，我们都提供了想要修改的图像。在接下来的部分，我们将学习如何通过文本输入或提示生成图像。
- en: Creating with prompts – text to image
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用提示生成 – 文本到图像
- en: In this section, we will introduce some services that enable images to be generated
    based on a **prompt**. A prompt is a set of natural language instructions that,
    when fed to the model, generates images. Whatever can be described in words can
    be transformed into an image. The more descriptive the prompt is, the more unique
    the output will be. The instructions can include some keywords that will enhance
    the originality of the created pieces of art, such as the style of the generated
    image, the aspect ratio, the resolution of the expected images, and more.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍一些能够基于**提示**生成图像的服务。提示是一组自然语言指令，输入模型后可以生成图像。任何可以用语言描述的内容都可以转化为图像。提示越详细，输出的作品就越独特。指令可以包括一些关键词，这些关键词将增强生成作品的原创性，例如生成图像的风格、长宽比、预期图像的分辨率等。
- en: All of the services we will present use some form of **diffusion models**, combined
    with other models to make the image generation process more efficient, clean it
    from disturbing results (for example, for minor 18), and more. Diffusion models
    are generative models that try to replicate the training data. During training,
    the model adds noise to the training dataset and learns how to reverse it to recover
    the original image. By recovering from the training noise, the model learns the
    fundamental aspects of an image, as well as how to generate new data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍的所有服务都使用某种形式的**扩散模型**，结合其他模型以提高图像生成过程的效率，去除干扰性结果（例如，针对次要18），等等。扩散模型是生成模型，旨在复制训练数据。在训练过程中，模型将噪声添加到训练数据集中，并学习如何反向操作以恢复原始图像。通过从训练噪声中恢复，模型学习图像的基本特征以及如何生成新数据。
- en: Let’s briefly analyze them one by one.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要分析它们逐一。
- en: DALL.E 2
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DALL.E 2
- en: OpenAI, the same research team that developed ChatGPT, developed DALL-E 2, an
    image generator from text descriptions. According to their documentation, “*DALL·E
    is a transformer language model. It receives both the text and the image as a
    single stream of data containing up to 1280 tokens, and is trained using maximum
    likelihood to generate all of the tokens, one after another*.” The model is a
    12-billion parameter autoregressive transformer that’s trained on 250 million
    image-text pairs collected from the internet.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI，开发了 ChatGPT 的同一个研究团队，开发了 DALL-E 2，它是一个从文本描述生成图像的工具。根据他们的文档，“*DALL·E 是一个变换器语言模型。它接收文本和图像作为一个包含最多
    1280 个令牌的数据流，并使用最大似然训练来生成所有令牌，依次生成*。”该模型是一个 120 亿参数的自回归变换器，经过 2.5 亿对图像-文本对的训练，这些对从互联网上收集而来。
- en: DALL-E 2 not only generates images according to a predefined prompt but also
    enables the user to modify parts of the image or add contextual background to
    smaller pieces of images.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: DALL-E 2 不仅根据预定义的提示生成图像，还允许用户修改图像的部分内容或为较小的图像区域添加背景信息。
- en: This same team also designed **contrastive language image pre-training** (**CLIP**),
    which allows us to map texts with images and returns the most appropriate caption
    for an input image. More information can be found at [https://openai.com/research/clip](https://openai.com/research/clip).
    This takes image tagging and categorization to another level of speed.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的团队还设计了**对比语言图像预训练**（**CLIP**），它使我们能够将文本与图像进行映射，并返回最适合输入图像的标题。更多信息可以在[https://openai.com/research/clip](https://openai.com/research/clip)找到。这使得图像标签和分类的速度提升到了一个新水平。
- en: Stable Diffusion
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Stable Diffusion
- en: Stable Diffusion models are open source and contain code and checkpoints. To
    enable Stable Diffusion models to be trained on low GPU, they do not train on
    images but rather on the latent space of the dataset. The models learn from the
    underlying structure of the dataset instead of processing each image. Training
    with latent space enables us to feed the model with text and images in the same
    space that the model will use to regenerate the image.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion 模型是开源的，包含代码和检查点。为了让 Stable Diffusion 模型能够在低 GPU 上训练，它们并不是直接在图像上训练，而是在数据集的潜在空间中进行训练。模型从数据集的潜在结构中学习，而不是处理每一张图像。使用潜在空间进行训练使得我们能够向模型提供文本和图像，这些内容将在模型用来重新生成图像的同一空间中进行处理。
- en: The CLIP model mentioned in the previous section helped train the latest version
    of Stable Diffusion V2\. The link to the repository is [https://github.com/Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节提到的 CLIP 模型帮助训练了最新版本的 Stable Diffusion V2。仓库链接是[https://github.com/Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion)。
- en: Midjourney
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Midjourney
- en: The base models that are used by Midjourney are not disclosed, but they are
    likely a combination of diffusion models, as explained for DALL-E and Stable Diffusion.
    Midjourney is currently only accessible through a Discord bot on their official
    Discord server or by inviting the bot to a third-party server. It has no API.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Midjourney 使用的基础模型没有公开，但它们可能是多种扩散模型的组合，正如 DALL-E 和 Stable Diffusion 的解释所示。Midjourney
    目前只能通过其官方 Discord 服务器上的 Discord 机器人访问，或者邀请机器人到第三方服务器。它没有 API。
- en: This service became popular very fast.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这项服务迅速变得非常流行。
- en: Leonardo.Ai
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Leonardo.Ai
- en: The link to their page is [https://app.leonardo.ai/](https://app.leonardo.ai/).
    This tool offers off-the-shelf models that generate images specifically trained
    in some of the most common themes, such as **role-playing games** (**RPGs**) or
    realistic photographs. It also offers tools to fine-tune models so that they can
    be adapted to our training datasets and a liberal free tier. Finally, it is developer-friendly
    with an easy-to-interact API. Each model has a “base model” description based
    on Stable Diffusion releases.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 他们页面的链接是[https://app.leonardo.ai/](https://app.leonardo.ai/)。这个工具提供现成的模型，能够生成专门针对一些最常见主题训练的图像，例如**角色扮演游戏**（**RPGs**）或现实照片。它还提供工具来微调模型，使其能够适应我们的训练数据集，并且提供一个慷慨的免费层。最后，它对开发者友好，提供易于互动的
    API。每个模型都有一个基于 Stable Diffusion 发布版的“基础模型”描述。
- en: 'To get started, sign up on their app and complete the **Get started** survey.
    There is no need to pay to interact with the basic service, but you must do so
    to get API keys:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用，请在他们的应用程序上注册并完成**入门**调查。与基本服务互动无需付费，但获取 API 密钥时必须付费：
- en: '![Figure 9.9 – Logging in to Leonardo.Ai for the first time](img/B19446_09_09.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.9 – 第一次登录 Leonardo.Ai](img/B19446_09_09.jpg)'
- en: Figure 9.9 – Logging in to Leonardo.Ai for the first time
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.9 – 第一次登录 Leonardo.Ai
- en: In the home page view, there is a list of models that we can interact with,
    depending on the type of image we want to generate. As mentioned earlier, each
    model is optimized for a specific purpose. For example, there is a model specially
    designed for vintage-style photography or RPG character portraits.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在主页视图中，列出了我们可以互动的模型，具体取决于我们想生成的图像类型。如前所述，每个模型都是针对特定目的进行优化的。例如，有一个模型专门用于复古风格摄影或角色扮演游戏角色肖像。
- en: We can also see two tabs called **Community Feed** and **Personal Feed**, which
    show images generated by the community and our images, respectively.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到两个标签，分别是**社区动态**和**个人动态**，它们显示由社区和我们自己生成的图像。
- en: 'If we move to the AI generation tool, we will see several options to choose
    from on the left-hand side of the view, including the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们转到AI生成工具，我们将看到视图左侧有多个选项可供选择，其中包括以下内容：
- en: '**Number of images**: This allows us to select the number of images we want
    to generate with each run.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像数量**：这使我们可以选择每次运行时生成的图像数量。'
- en: '**Prompt magic**: According to their description, “*Our experimental render
    pipeline may have better prompt adherence*.” The images are more artistic with
    this enabled.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示魔力**：根据他们的描述，“*我们的实验性渲染管道可能具有更好的提示遵循性*”。启用此功能后，生成的图像更加艺术化。'
- en: '**Prompt magic strength**: This option determines the weight of the render
    detailed previously.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示魔力强度**：此选项决定了之前渲染的详细程度的权重。'
- en: '**Public images**: This option allows us to choose whether we want to share
    these images with the public feed.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公开图像**：此选项允许我们选择是否将这些图像与公共动态分享。'
- en: '**Image dimensions**: This option lets us set the size of the images.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像尺寸**：此选项让我们可以设置图像的大小。'
- en: '**Guidance scale**: This option determines the weight of the prompt in the
    final image. It is suggested to keep it at 7 or 8.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指导尺度**：此选项决定了提示在最终图像中的权重。建议将其保持在7或8。'
- en: We can also upload an image to be used as a prompt.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以上传一张图片作为提示使用。
- en: A note on good prompts
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 关于好提示的说明
- en: '**Vocabulary**: Avoid the use of “very” or “super” for emphasis. Instead, opt
    for words that convey the same meaning. For instance, replace “very tired” with
    “exhausted.”'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**词汇**：避免使用“very”或“super”来表示强调。相反，可以选择表达相同意思的词汇。例如，将“very tired”替换为“exhausted”。'
- en: '**Typos**: Refrain from sending incorrectly spelled words, abbreviations, contractions,
    or slang as the model may struggle to align them with the dataset on which it
    was trained.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**拼写错误**：避免发送拼写错误的单词、缩写、收缩词或俚语，因为模型可能难以将它们与其训练时所使用的数据集对齐。'
- en: '**Specificity**: Minimize ambiguity in word choices and unnecessary text. For
    improved results, opt for expressions such as “cheeseless pizza” instead of “pizza
    with no cheese.” Utilize negative prompts to exclude specific objects or characteristics
    from the image.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**具体性**：尽量减少词汇选择中的模糊性和不必要的文本。为了提高效果，可以使用“cheeseless pizza”而不是“pizza with no
    cheese”。利用负面提示来排除图像中的特定物体或特征。'
- en: '**Keywords to consider**: Include hints about the image’s background, style
    words (such as anime, realistic, paper art, cubism, charcoal painting, folk art,
    graffiti), lighting (soft, ambient, neon, studio lights), or time of day (morning,
    golden hour, midnight).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**需要考虑的关键词**：包括图像背景、风格词（如动漫、写实、纸艺、立体主义、炭笔画、民间艺术、涂鸦）、光线（柔光、环境光、霓虹灯、工作室灯光）或一天中的时间（早晨、黄金时段、午夜）的提示。'
- en: Furthermore, the application helps us with the prompt generation. Within the
    AI tool that we just described, we can see the **Prompt Generation** tab, which
    assists us in generating the prompt to obtain the desired image using AI.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该应用还帮助我们生成提示。在我们刚刚描述的AI工具中，我们可以看到**提示生成**标签，它帮助我们生成提示，以便使用AI获取所需的图像。
- en: Hands-on with Leonardo.Ai
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亲自体验 Leonardo.Ai
- en: Let’s try an exercise with the API. The documentation is available at [https://docs.leonardo.ai/reference/getuserself](https://docs.leonardo.ai/reference/getuserself).
    It is an easy-to-use API that can be accessed with our well-known `request` library.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过API做一个练习。文档可以在[https://docs.leonardo.ai/reference/getuserself](https://docs.leonardo.ai/reference/getuserself)找到。它是一个易于使用的API，可以通过我们熟悉的`request`库进行访问。
- en: The API can help us build the entire pipeline from a prompt to a folder that
    we can submit to the artistic team for review. The `Leonardo_AI.ipynb` file contains
    the workflow we’ll explore.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: API可以帮助我们从提示到文件夹的整个管道建设，我们可以将其提交给艺术团队进行审核。`Leonardo_AI.ipynb`文件包含我们将要探索的工作流。
- en: Although the API is under development and not all functionalities and models
    can be invoked programmatically, most of the options described previously can
    be added as parameters to the payload.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 API 仍在开发中，并且并非所有功能和模型都可以通过程序调用，但前面描述的大部分选项都可以作为参数添加到负载中。
- en: 'Let’s review the following code snippet:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看以下代码片段：
- en: '[PRE2]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To interact with the API, we need to log in and obtain a set of API keys that
    will pass as authorization in the header.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 要与 API 互动，我们需要登录并获得一组 API 密钥，这些密钥将作为授权信息传递在请求头中。
- en: It is important to read the parameters from the website as the documentation
    for this is not complete. For example, some models are trained with specific image
    dimensions, so it is better to input those preferred dimensions in the parameter
    payload. Additionally, not all the models can be called from the API, and there
    is no access to the prompt generator.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要从网站上阅读参数，因为文档并不完整。例如，有些模型是以特定的图像尺寸进行训练的，因此最好将这些首选尺寸输入到参数负载中。此外，并非所有模型都可以通过
    API 调用，也无法访问提示生成器。
- en: Despite these limitations, this is a great tool that can help us generate high-quality
    images rapidly.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这些限制，这仍然是一个很棒的工具，可以帮助我们快速生成高质量的图像。
- en: Minting an NFT collection
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 铸造一个 NFT 收藏
- en: The purpose of analyzing all the tools in this section is to create or modify
    images that we can sell or the artistic team we support will sell. Once we have
    generated the images, we want to “own” them in the Web3 sense, as explained in
    [*Chapter 4*](B19446_04.xhtml#_idTextAnchor145). To achieve this, we will create
    a collection in a marketplace.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 本节分析所有工具的目的是为了创建或修改我们可以出售的图像，或者艺术团队可以出售的图像。一旦我们生成了图像，我们希望以 Web3 的方式“拥有”它们，正如在
    [*第 4 章*](B19446_04.xhtml#_idTextAnchor145) 中解释的那样。为了实现这一目标，我们将在市场平台上创建一个收藏。
- en: '**Minting** is the act of creating the digital trace of an item on the blockchain.
    As we saw when describing ERC 721, it means that the trace will point to a URL
    containing the stored image. Everything that is stored on the chain pays a gas
    fee.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**铸造**是指在区块链上创建一个物品的数字踪迹。正如我们在描述 ERC 721 时看到的，它意味着这个踪迹将指向一个包含存储图像的 URL。所有存储在区块链上的内容都需要支付油费。'
- en: The concept of lazy minting has emerged rather recently. **Lazy minting** involves
    authorizing the platform to mint the NFT at the moment of the NFT sale and not
    before. This is important because minting involves gas expenditure, and, in moments
    of high congestion, gas prices can be high. In addition, lazy minting helps reduce
    the risk of creating a collection that may not be sold high enough to cover the
    initial investment. At the time of writing, the main marketplaces, such as OpenSea
    and Rarible, offer the service.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 懒铸造的概念相对较新。**懒铸造**意味着授权平台在 NFT 售出时铸造 NFT，而不是提前铸造。这一点很重要，因为铸造需要消耗油费，在高峰期油费可能很高。此外，懒铸造有助于减少创建一个可能不会高价售出的收藏品的风险。截至目前，主要的市场平台，如
    OpenSea 和 Rarible，提供这一服务。
- en: 'The process consists of the following steps:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程包括以下步骤：
- en: Creators mint an NFT *lazily* using a specific smart contract. The smart contract
    will mint and sell the NFT on our behalf. We provide the authorization.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创作者通过特定的智能合约 *懒铸造* NFT。智能合约会代表我们铸造并出售 NFT。我们提供授权。
- en: The buyer pays a price that covers the minting costs and the NFT itself when
    purchasing our NFT.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 买家在购买我们的 NFT 时支付包括铸造费用和 NFT 本身的费用。
- en: This method defers the minting process until just before the NFT is sold, which
    is an incentive for creators to continue producing and showcasing their art without
    necessarily paying for gas.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法将铸造过程推迟到 NFT 售出之前，这是对创作者的激励，鼓励他们继续创作和展示艺术作品，而无需支付油费。
- en: 'Let’s create a collection on OpenSea:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 OpenSea 上创建一个收藏：
- en: Go to [https://opensea.io/](https://opensea.io/). To interact with the platform,
    you will need a wallet.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 [https://opensea.io/](https://opensea.io/)。要与平台互动，你需要一个钱包。
- en: 'Connect your wallet and go to the profile options:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接你的钱包并进入个人资料选项：
- en: '![Figure 9.10 – Connecting to your wallet](img/B19446_09_10.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.10 – 连接到你的钱包](img/B19446_09_10.jpg)'
- en: Figure 9.10 – Connecting to your wallet
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.10 – 连接到你的钱包
- en: 'Click on **My Collections**:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **我的收藏**：
- en: '![Figure 9.11 – The My Collections tab](img/B19446_09_11.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.11 – 我的收藏标签页](img/B19446_09_11.jpg)'
- en: Figure 9.11 – The My Collections tab
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11 – 我的收藏标签页
- en: 'Click on the blue **Create a** **collection** button:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击蓝色的 **创建一个** **收藏** 按钮：
- en: '![Figure 9.12 – The My Collections page](img/B19446_09_12.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.12 – 我的收藏页面](img/B19446_09_12.jpg)'
- en: Figure 9.12 – The My Collections page
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.12 – 我的集合页面
- en: 'You will be offered two options: the traditional option (**Deploy your own
    contract**) and the lazy minting option (**Use the OpenSea contract**). Click
    on the second option:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 系统会提供两个选项：传统选项（**部署您自己的合约**）和懒铸造选项（**使用 OpenSea 合约**）。点击第二个选项：
- en: '![Figure 9.13 – Choosing the lazy minting option](img/B19446_09_13.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.13 – 选择懒铸造选项](img/B19446_09_13.jpg)'
- en: Figure 9.13 – Choosing the lazy minting option
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.13 – 选择懒铸造选项
- en: 'A page will open where you can complete the collection’s details. Among them
    we will find the following details:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 会打开一个页面，您可以在其中填写集合的详细信息。我们将找到以下几个细节：
- en: The name of the collection.
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集合的名称。
- en: Description.
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述
- en: The accepted currency.
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可接受的货币。
- en: Images for the collection page.
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集合页面的图片。
- en: Author earnings. As we mentioned in [*Chapter 4*](B19446_04.xhtml#_idTextAnchor145),
    it is possible to establish a percentage that the creator will retain each time
    the NFT is sold.
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作者收益。如我们在[*第4章*](B19446_04.xhtml#_idTextAnchor145)中提到的，每次 NFT 被出售时，可以设定创作者将保留的百分比。
- en: 'Once all the required details have been filled in, click **Save**. Now that
    we have a collection, we have to add pieces of art to it:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 填写完所有必需的详细信息后，点击**保存**。现在我们有了一个集合，接下来需要将艺术品添加到其中：
- en: 'Go back to your profile and click **Create**:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回您的个人资料并点击**创建**：
- en: '![Figure 9.14 – Creating an NFT](img/B19446_09_14.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.14 – 创建 NFT](img/B19446_09_14.jpg)'
- en: Figure 9.14 – Creating an NFT
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.14 – 创建 NFT
- en: 'You may require additional authorization to access this panel. If so, you will
    be taken to the **Create New Item** page: [https://opensea.io/asset/create](https://opensea.io/asset/create).'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可能需要额外的授权才能访问此面板。如果是这样，您将被带到**创建新项目**页面：[https://opensea.io/asset/create](https://opensea.io/asset/create)。
- en: 'Upload the image, video, or audio that you want to mint. In this example, we
    will mint one of the images that was generated with the `Leonardo_AI.ipynb` notebook:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传您想要铸造的图片、视频或音频。在这个示例中，我们将铸造一张使用`Leonardo_AI.ipynb`笔记本生成的图片：
- en: '![Figure 9.15 – Details of the new item](img/B19446_09_15.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.15 – 新项目的详细信息](img/B19446_09_15.jpg)'
- en: Figure 9.15 – Details of the new item
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.15 – 新项目的详细信息
- en: 'Start filling in the required fields:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始填写必填字段：
- en: Name
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 名称
- en: Description
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述
- en: Connect it to the collection that was created in *step* *4 previously*
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其连接到之前在*步骤* *4*中创建的集合
- en: Identify the number of items of the same nature that can be minted
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定可以铸造的相同性质的物品数量
- en: The network where this item will live
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该物品将所在的网络
- en: 'Click **Create**; you will see the following output:'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 点击**创建**；您将看到以下输出：
- en: '![Figure 9.16 – Resulting message after signing the creation](img/B19446_09_16.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.16 – 签署创建后的结果信息](img/B19446_09_16.jpg)'
- en: Figure 9.16 – Resulting message after signing the creation
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.16 – 签署创建后的结果信息
- en: 'Enable the sale. To do this, navigate to the page of the item and click on
    the **Sell** button:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用销售。为此，请访问该物品的页面并点击**出售**按钮：
- en: '![Figure 9.17 – Sale details](img/B19446_09_17.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.17 – 销售详情](img/B19446_09_17.jpg)'
- en: Figure 9.17 – Sale details
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.17 – 销售详情
- en: New options will appear for you to choose from. It is possible to choose between
    a fixed price or an auction with a limited time. If we want to sell for a fixed
    price, we can follow the next steps.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 新选项将会出现供您选择。可以选择固定价格或限定时间的拍卖。如果我们想以固定价格出售，可以按照以下步骤操作。
- en: 'Click on **Fixed price**:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**固定价格**：
- en: '![Figure 9.18 – The Fixed price option](img/B19446_09_18.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.18 – 固定价格选项](img/B19446_09_18.jpg)'
- en: Figure 9.18 – The Fixed price option
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.18 – 固定价格选项
- en: Set a price in any of the coins or tokens that are acceptable according to what
    we decided when creating the collection.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置一个价格，使用我们在创建集合时决定的任何可接受的货币或代币。
- en: Below this, we will find a summary of earnings and the fee that OpenSea charges
    (at the time of writing, this is 2.5%).
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此下方，我们将看到收益的总结以及 OpenSea 收取的费用（在写作时，这个费用为 2.5%）。
- en: If we agree, we can click on **Complete listing**. To approve the listing, OpenSea
    requires our signature.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们同意，可以点击**完成列表**。为了批准这个列表，OpenSea 需要我们的签名。
- en: Once signed, we will receive a new notification, informing us that the item
    has been listed. Now, it is out there in the marketplace and can be purchased!
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦签署完成，我们将收到新的通知，告知我们该物品已列出。现在，它已经在市场上，可以购买了！
- en: '![Figure 9.19 – The listing for sale has been enabled](img/B19446_09_19.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.19 – 销售列表已启用](img/B19446_09_19.jpg)'
- en: Figure 9.19 – The listing for sale has been enabled
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.19 – 销售列表已启用
- en: 'All the illustrations that were generated in this section are available in
    The Mysterious Library Collection: [https://opensea.io/collection/mysterious-library](https://opensea.io/collection/mysterious-library).'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中生成的所有插图均可在《神秘图书馆收藏》查看：[https://opensea.io/collection/mysterious-library](https://opensea.io/collection/mysterious-library)。
- en: Summary
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Throughout this chapter, we explored three different approaches to using AI
    tools in artistic projects. We examined the use of GAN models for colorizing sketches,
    explored the VGG19 model for transferring style, and discovered state-of-the-art
    applications of Stable Diffusion models for generating art based on prompts.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了三种不同的使用AI工具进行艺术项目的方式。我们研究了使用GAN模型为草图上色，探索了VGG19模型进行风格转移，并发现了基于提示生成艺术的Stable
    Diffusion模型的最先进应用。
- en: Moreover, we learned about the entire workflow, from the finished piece of art
    to listing the final image on a marketplace. By combining the power of AI and
    blockchain technology, we now have a range of new opportunities to explore and
    monetize artistic work in exciting and innovative ways.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还了解了整个工作流程，从完成的艺术作品到将最终图像列出在市场上。通过结合AI和区块链技术的力量，我们现在有了探索和变现艺术作品的新机会，以激动人心和创新的方式。
- en: It is worth noting that questions have arisen concerning the ownership of images
    generated using AI. This arises from the possibility that these models may have
    been trained on copyrighted pieces of art without the artist’s consent. Respondents
    contend that the transformative nature of the model’s outputs, coupled with the
    fair use argument, could potentially dismiss such accusations. This ongoing issue
    is yet to be definitively resolved by legal authorities and is likely to exhibit
    variations across different countries.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，关于使用AI生成的图像的所有权问题已经引发了讨论。这源于这些模型可能在没有艺术家同意的情况下使用了受版权保护的艺术作品进行训练的可能性。回应者认为，模型输出的变革性特征，加上合理使用的论点，可能会驳回此类指控。这个持续的问题尚未被法律当局明确解决，并且可能在不同国家之间存在差异。
- en: Having explored the area of NFTs, we’ll now shift our focus to a critical aspect
    that underpins the integrity of this innovative landscape – fraud detection. In
    the following chapter, we will analyze another use case where machine learning
    can help us uncover anomalies and increase transaction security.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索了NFT领域之后，我们将把注意力转向一个关键方面，这一方面是确保这一创新领域完整性的基础——欺诈检测。在接下来的章节中，我们将分析另一个应用案例，在这个案例中，机器学习可以帮助我们发现异常并提高交易安全性。
- en: Further reading
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解更多本章所涵盖的主题，请参考以下资源：
- en: 'Crypto Grims: [https://twitter.com/cryptogrims](https://twitter.com/cryptogrims)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Crypto Grims: [https://twitter.com/cryptogrims](https://twitter.com/cryptogrims)'
- en: 'Artsy Monke collection: [https://opensea.io/assets/ethereum/0xa4bcd3b7f141ba1f08f36033fdfce691565561bc](https://opensea.io/assets/ethereum/0xa4bcd3b7f141ba1f08f36033fdfce691565561bc).'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Artsy Monke 收藏品: [https://opensea.io/assets/ethereum/0xa4bcd3b7f141ba1f08f36033fdfce691565561bc](https://opensea.io/assets/ethereum/0xa4bcd3b7f141ba1f08f36033fdfce691565561bc)。'
- en: Mishra, M. (2020, September 2). *Convolutional neural networks, explained*.
    Medium. Available at [https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939](https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939).
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mishra, M. (2020, September 2). *卷积神经网络解析*. Medium. 可在[https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939](https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939)查看。
- en: Fortis, S. (n.d.). *Google AI turns all 10,000 BAYC NFTs into machine-made art*.
    Cointelegraph. Available at [https://cointelegraph.com/news/google-ai-turns-all-10-000-bayc-nfts-into-machine-made-art](https://cointelegraph.com/news/google-ai-turns-all-10-000-bayc-nfts-into-machine-made-art).
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fortis, S. (n.d.). *Google AI将所有10,000个BAYC NFT转化为机器生成艺术*. Cointelegraph. 可在[https://cointelegraph.com/news/google-ai-turns-all-10-000-bayc-nfts-into-machine-made-art](https://cointelegraph.com/news/google-ai-turns-all-10-000-bayc-nfts-into-machine-made-art)查看。
- en: Lllyasviel (n.d.). *style2paints.github.io*. Available at [https://style2paints.github.io/](https://style2paints.github.io/).
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lllyasviel (n.d.). *style2paints.github.io*. 可在[https://style2paints.github.io/](https://style2paints.github.io/)查看。
- en: Lllyasviel/style2paints. (n.d.). GitHub. Available at [https://github.com/lllyasviel/style2paints](https://github.com/lllyasviel/style2paints).
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lllyasviel/style2paints. (n.d.). GitHub. 可在[https://github.com/lllyasviel/style2paints](https://github.com/lllyasviel/style2paints)查看。
- en: Tang, J. (2020, October 20). *Attempt to understand an all-star auto-color project—Style2Paints
    (Part 1)*. Medium. Available at [https://medium.com/ai-innovation/attempt-to-understand-an-all-star-auto-color-project-style2paints-part-1-84d2e3d96da](https://medium.com/ai-innovation/attempt-to-understand-an-all-star-auto-color-project-style2paints-part-1-84d2e3d96da).
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang, J.（2020年10月20日）。*尝试理解一个全明星自动上色项目——Style2Paints（第1部分）*。Medium。可在[https://medium.com/ai-innovation/attempt-to-understand-an-all-star-auto-color-project-style2paints-part-1-84d2e3d96da](https://medium.com/ai-innovation/attempt-to-understand-an-all-star-auto-color-project-style2paints-part-1-84d2e3d96da)查看。
- en: Lvmin Zhang, Chengze Li, Tien-Tsin Wong, Yi Ji, and Chunping Liu. (n.d.). *CUHK
    Computer Science and Engineering*. Available at [https://www.cse.cuhk.edu.hk/~ttwong/papers/colorize/colorize.pdf](https://www.cse.cuhk.edu.hk/~ttwong/papers/colorize/colorize.pdf).
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lvmin Zhang, Chengze Li, Tien-Tsin Wong, Yi Ji 和 Chunping Liu。（无日期）。*CUHK计算机科学与工程*。可在[https://www.cse.cuhk.edu.hk/~ttwong/papers/colorize/colorize.pdf](https://www.cse.cuhk.edu.hk/~ttwong/papers/colorize/colorize.pdf)查看。
- en: Nerdy Rodent. (2020, November 19). *Style2Paints – Easily colour any line art
    using AI* [Video]. YouTube. Available at [https://www.youtube.com/watch?v=cvN9oQfC3w0](https://www.youtube.com/watch?v=cvN9oQfC3w0).
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nerdy Rodent。（2020年11月19日）。*Style2Paints——使用AI轻松为任何线条艺术上色* [视频]。YouTube。可在[https://www.youtube.com/watch?v=cvN9oQfC3w0](https://www.youtube.com/watch?v=cvN9oQfC3w0)查看。
- en: Overview of GAN structure. (n.d.). *Google for Developers*. Available at [https://developers.google.com/machine-learning/gan/gan_structure](https://developers.google.com/machine-learning/gan/gan_structure).
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GAN结构概述。（无日期）。*Google开发者平台*。可在[https://developers.google.com/machine-learning/gan/gan_structure](https://developers.google.com/machine-learning/gan/gan_structure)查看。
- en: Prof. Jeff Heaton – Washington University of St. Louis. (2022, January 19).
    *Introduction to GANS for Image and Data Generation (7.1)* [Video]. YouTube. Available
    at [https://www.youtube.com/watch?v=hZw-AjbdN5k](https://www.youtube.com/watch?v=hZw-AjbdN5k).
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prof. Jeff Heaton – 圣路易斯华盛顿大学。（2022年1月19日）。*图像和数据生成的GAN入门（7.1）* [视频]。YouTube。可在[https://www.youtube.com/watch?v=hZw-AjbdN5k](https://www.youtube.com/watch?v=hZw-AjbdN5k)查看。
- en: 'Prof. Jeff Heaton – Washington University of St. Louis. (2021, February 17).
    *Training a GAN from your Own Images: StyleGAN2 ADA* [Video]. YouTube. Available
    at [https://www.youtube.com/watch?v=kbDd5lW6rkM](https://www.youtube.com/watch?v=kbDd5lW6rkM).'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prof. Jeff Heaton – 圣路易斯华盛顿大学。（2021年2月17日）。*从您自己的图像训练GAN：StyleGAN2 ADA* [视频]。YouTube。可在[https://www.youtube.com/watch?v=kbDd5lW6rkM](https://www.youtube.com/watch?v=kbDd5lW6rkM)查看。
- en: Prof. Jeff Heaton – Washington University of St. Louis. (2021, May 12). *Training
    NVIDIA StyleGAN2 ADA under Colab Free and Colab Pro Tricks* [Video]. YouTube.
    Available at [https://www.youtube.com/watch?v=L3JLzoe-dJU](https://www.youtube.com/watch?v=L3JLzoe-dJU).
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prof. Jeff Heaton – 圣路易斯华盛顿大学。（2021年5月12日）。*在Colab Free和Colab Pro技巧下训练NVIDIA
    StyleGAN2 ADA* [视频]。YouTube。可在[https://www.youtube.com/watch?v=L3JLzoe-dJU](https://www.youtube.com/watch?v=L3JLzoe-dJU)查看。
- en: '*T81_558_deep_learning/t81_558_class_07_1_gan_intro.ipynb at master · jeffheaton/t81_558_deep_learning*.
    (n.d.). GitHub. Available at [https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_1_gan_intro.ipynb](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_1_gan_intro.ipynb).'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*T81_558_deep_learning/t81_558_class_07_1_gan_intro.ipynb at master · jeffheaton/t81_558_deep_learning*。（无日期）。GitHub。可在[https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_1_gan_intro.ipynb](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_1_gan_intro.ipynb)查看。'
- en: '*T81_558_deep_learning/t81_558_class_07_2_train_gan.ipynb at master · jeffheaton/t81_558_deep_learning*.
    (n.d.). GitHub. Available at [https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_2_train_gan.ipynb](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_2_train_gan.ipynb).'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*T81_558_deep_learning/t81_558_class_07_2_train_gan.ipynb at master · jeffheaton/t81_558_deep_learning*。（无日期）。GitHub。可在[https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_2_train_gan.ipynb](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_2_train_gan.ipynb)查看。'
- en: Jason Brownlee PhD. (2019, July 19). *Machine Learning Mastery*. Machine Learning
    Mastery. Available at [https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/](https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/).
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jason Brownlee博士。（2019年7月19日）。*机器学习精通*。机器学习精通。可在[https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/](https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/)查看。
- en: '*4 characteristics of cubism and why they are important*. (n.d.). Artlex –
    Art Dictionary and Encyclopedia. Available at [https://www.artlex.com/art-movements/cubism/characteristics/](https://www.artlex.com/art-movements/cubism/characteristics/).'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*立体主义的4个特征及其重要性*。（无日期）。Artlex – 艺术词典和百科全书。可在 [https://www.artlex.com/art-movements/cubism/characteristics/](https://www.artlex.com/art-movements/cubism/characteristics/)
    获取。'
- en: '*Neural style* *transfer*: [https://keras.io/examples/generative/neural_style_transfer/](https://keras.io/examples/generative/neural_style_transfer/).'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*神经风格* *迁移*：[https://keras.io/examples/generative/neural_style_transfer/](https://keras.io/examples/generative/neural_style_transfer/)。'
- en: '*DALL·E: Creating images from text*. (n.d.). OpenAI. Available at [https://openai.com/research/dall-e](https://openai.com/research/dall-e).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DALL·E：从文本创建图像*。（无日期）。OpenAI。可在 [https://openai.com/research/dall-e](https://openai.com/research/dall-e)
    获取。'
- en: '*Zero-shot text-to-Image generation*. (n.d.). arXiv.org. Available at [https://arxiv.org/abs/2102.12092](https://arxiv.org/abs/2102.12092).'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*零-shot文本到图像生成*。（无日期）。arXiv.org。可在 [https://arxiv.org/abs/2102.12092](https://arxiv.org/abs/2102.12092)
    获取。'
- en: 'Aleksa Gordić - The AI Epiphany. (2022, September 1). *Stable Diffusion: High-Resolution
    Image Synthesis with Latent Diffusion Models | ML Coding Series* [Video]. YouTube.
    Available at [https://www.youtube.com/watch?v=f6PtJKdey8E](https://www.youtube.com/watch?v=f6PtJKdey8E).'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aleksa Gordić - The AI Epiphany. (2022年9月1日). *稳定扩散：使用潜在扩散模型进行高分辨率图像合成 | ML
    编程系列* [视频]。YouTube。可在 [https://www.youtube.com/watch?v=f6PtJKdey8E](https://www.youtube.com/watch?v=f6PtJKdey8E)
    获取。
- en: '*Stability-AI/stablediffusion*. (n.d.). GitHub. Available at [https://github.com/Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Stability-AI/stablediffusion*。（无日期）。GitHub。可在 [https://github.com/Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion)
    获取。'
- en: '*How Stable Diffusion works? Latent Diffusion Models Explained*. (2022, December
    3). Louis Bouchard. Available at [https://www.louisbouchard.ai/latent-diffusion-models/](https://www.louisbouchard.ai/latent-diffusion-models/).'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*稳定扩散是如何工作的？潜在扩散模型解析*。（2022年12月3日）。Louis Bouchard。可在 [https://www.louisbouchard.ai/latent-diffusion-models/](https://www.louisbouchard.ai/latent-diffusion-models/)
    获取。'
- en: 'Arya, G. (2023, January 14). *Power of latent diffusion models: Revolutionizing
    image creation*. Analytics Vidhya. Available at [https://www.analyticsvidhya.com/blog/2023/01/power-of-latent-diffusion-models-revolutionizing-image-creation/](https://www.analyticsvidhya.com/blog/2023/01/power-of-latent-diffusion-models-revolutionizing-image-creation/).'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arya, G. (2023年1月14日). *潜在扩散模型的力量：革命性的图像创作*。Analytics Vidhya。可在 [https://www.analyticsvidhya.com/blog/2023/01/power-of-latent-diffusion-models-revolutionizing-image-creation/](https://www.analyticsvidhya.com/blog/2023/01/power-of-latent-diffusion-models-revolutionizing-image-creation/)
    获取。
- en: '*API Documentation*. (n.d.). Leonardo.Ai. Available at [https://docs.leonardo.ai/reference/getuserself](https://docs.leonardo.ai/reference/getuserself).'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*API文档*。（无日期）。Leonardo.Ai。可在 [https://docs.leonardo.ai/reference/getuserself](https://docs.leonardo.ai/reference/getuserself)
    获取。'
- en: 'Ashley, K. (2021). *Make art with artificial intelligence: Make and sell your
    art with AI, blockchain,* *and NFT*.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ashley, K. (2021). *用人工智能创作艺术：用AI、区块链和NFT创作并销售你的艺术*。
