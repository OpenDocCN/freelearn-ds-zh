- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: The Five Steps of Data Science
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学的五个步骤
- en: This chapter will dive into the five core steps involved in the data science
    process, with examples every step of the way. These five steps include defining
    a real problem, collecting and preprocessing the data, exploring and analyzing
    the data, drawing conclusions, and communicating results effectively.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将深入探讨数据科学流程中的五个核心步骤，并且每一步都会有示例。这五个步骤包括定义实际问题、收集和预处理数据、探索和分析数据、得出结论以及有效地传达结果。
- en: We will also delve into the important topics of data exploration and data visualization.
    Data exploration involves examining the characteristics and patterns in your data
    to better understand it, while data visualization involves using graphs, charts,
    and other visual aids to represent and communicate your data and findings.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将深入探讨数据探索和数据可视化的重要话题。数据探索涉及检查数据中的特征和模式，以便更好地理解它，而数据可视化则涉及使用图形、图表和其他可视化工具来表示和传达数据及其发现。
- en: By the end of this chapter, you will have a solid understanding of the data
    science process and how to apply it to solve real-world problems. So, let’s get
    started!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你将对数据科学流程有一个扎实的理解，并且能够将其应用于解决实际问题。那么，开始吧！
- en: 'We will also cover the following topics in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还将涵盖以下主题：
- en: An introduction to what data science really is
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学的真正介绍
- en: Exploring data effectively
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高效探索数据
- en: Exploration tips for all levels of data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各级数据探索技巧
- en: Using **pandas** to manipulate and optimize data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**pandas**进行数据处理和优化
- en: Introduction to data science
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学简介
- en: 'A question I’ve gotten at least once a month for the past decade is *What’s
    the difference between data science and data analytics?* One could argue that
    there is no difference between the two; others will argue that there are hundreds
    of differences! I believe that, regardless of how many differences there are between
    the two terms, the following applies:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 过去十年里，我每个月至少被问一次的问题是*数据科学和数据分析有什么区别？* 有人可能会认为这两者之间没有区别；也有人会认为它们之间有成百上千的不同！我相信，无论这两个术语之间有多少区别，以下内容都是适用的：
- en: '*Data science follows a structured, step-by-step process that, when followed,
    preserves the integrity of the results and leads to a deeper understanding of
    the data and the environment the data* *comes from.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据科学遵循一个结构化的、逐步的过程，当遵循这个过程时，能够保持结果的完整性，并加深对数据及其来源环境的理解。*'
- en: As with any other scientific endeavor, this process must be adhered to, or else
    the analysis and the results are in danger of scrutiny. On a simpler level, following
    a strict process can make it much easier for any data scientist, hobbyist, or
    professional to obtain results faster than if they were exploring data with no
    clear vision.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 和其他科学探索一样，必须遵循这个过程，否则分析和结果可能会受到质疑。从更简单的角度看，遵循严格的流程可以让任何数据科学家、爱好者或专业人士比在没有明确目标的情况下探索数据更快地获得结果。
- en: While these steps are a guiding lesson for amateur analysts, they also provide
    the foundation for all data scientists, even those in the highest levels of business
    and academia. Every data scientist recognizes the value of these steps and follows
    them in some way or another.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些步骤是为业余分析师提供的指导性课程，它们也为所有数据科学家奠定了基础，即使是那些在商业和学术界处于最高层次的人。每个数据科学家都认识到这些步骤的价值，并以某种方式遵循它们。
- en: Overview of the five steps
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 五个步骤概述
- en: 'The process of data science involves a series of steps that are essential for
    effectively extracting insights and knowledge from data. These steps are presented
    as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学的过程包括一系列步骤，这些步骤对于有效地从数据中提取洞察和知识至关重要。这些步骤如下所示：
- en: '**Asking an interesting question**: The first step in any data science project
    is to identify a question or challenge that you want to address with your analysis.
    This involves finding a topic that is relevant, important, and that can be addressed
    with data.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提出一个有趣的问题**：任何数据科学项目的第一步是确定一个你想通过分析解决的问题或挑战。这涉及找到一个相关、重要且可以通过数据来解决的话题。'
- en: '**Obtaining the data**: Once you have identified your question, the next step
    is to collect the data that you will need to answer it. This can involve sourcing
    data from a variety of sources, such as databases, online platforms, or through
    data scraping or data collection methods.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**获取数据**：一旦你确定了问题，下一步就是收集回答该问题所需的数据。这可能涉及从各种来源获取数据，例如数据库、在线平台，或通过数据抓取或数据收集方法。'
- en: '**Exploring the data**: After you have collected your data, the next step is
    to explore it and get a better understanding of its characteristics and patterns.
    This might involve examining summary statistics, visualizing the data, or applying
    statistical or **machine learning** (**ML**) techniques to identify trends or
    relationships.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**探索数据**：在收集完数据后，下一步是探索数据，更好地了解其特征和模式。这可能包括检查总结统计数据、可视化数据，或应用统计学或**机器学习**（**ML**）技术来识别趋势或关系。'
- en: '**Modeling the data**: Once you have explored your data, the next step is to
    build models that can be used to make predictions or inform decision-making. This
    might involve applying ML algorithms, building statistical models, or using other
    techniques to find patterns in the data.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**建模数据**：一旦你探索完数据，下一步是建立可以用来进行预测或辅助决策的模型。这可能涉及应用机器学习算法、构建统计模型，或使用其他技术来发现数据中的模式。'
- en: '**Communicating and visualizing the results**: Finally, it’s important to communicate
    your findings to others in a clear and effective way. This might involve creating
    reports, presentations, or visualizations that help to explain your results and
    their implications.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**沟通和可视化结果**：最后，重要的是以清晰有效的方式将你的发现传达给他人。这可能包括创建报告、演示文稿或可视化，帮助解释你的结果及其影响。'
- en: By following these five essential steps, you can effectively use data science
    to solve real-world problems and extract valuable insights from data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这五个关键步骤，你可以有效地利用数据科学解决现实世界的问题，并从数据中提取有价值的见解。
- en: It’s important to note that different data scientists may have different approaches
    to the data science process, and the steps outlined previously are just one way
    of organizing the process. Some data scientists might group the steps differently
    or include additional steps such as feature engineering or model evaluation.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，不同的数据科学家可能有不同的数据科学过程方法，之前列出的步骤仅仅是组织过程的一种方式。一些数据科学家可能会将步骤分组不同，或加入额外的步骤，如特征工程或模型评估。
- en: Despite these differences, most data scientists agree that the steps listed
    previously are essential to the data science process. Whether they are organized
    in this specific way or not, these steps are all crucial for effectively using
    data to solve problems and extract valuable insights. Let’s dive into these steps
    one by one.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些差异，大多数数据科学家一致认为，之前列出的步骤对于数据科学过程至关重要。无论这些步骤是否以这种具体的方式组织，它们对于有效地利用数据解决问题和提取有价值的见解都非常关键。让我们逐一深入了解这些步骤。
- en: Asking an interesting question
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提出一个有趣的问题
- en: This is probably my favorite step. Asking an interesting and relevant question
    is the first and perhaps most important step in the data science process. It sets
    the direction and focus of your analysis and determines the data and resources
    that you will need to collect and analyze.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是我最喜欢的一步。提出一个有趣且相关的问题是数据科学过程中第一步，也是最重要的一步。它决定了你的分析方向和重点，并决定了你需要收集和分析的数据和资源。
- en: As an entrepreneur, you are likely accustomed to constantly asking questions
    and seeking answers. This step can be approached like a brainstorming session,
    where you write down questions and ideas regardless of whether or not you think
    data exists to answer them. This helps to avoid bias and allows you to consider
    a wide range of possibilities.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名企业家，你可能已经习惯了不断地提问和寻找答案。这个步骤可以像头脑风暴会议一样进行，在会议中你写下所有问题和想法，无论你是否认为有数据可以回答它们。这有助于避免偏见，并允许你考虑更多可能性。
- en: It’s important to be specific and narrow in your focus when asking your question.
    This will help you to effectively address the problem and extract valuable insights
    from your data. It’s also important to consider the scope and feasibility of your
    question, as well as the resources and data that you will need to answer it.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在提问时，务必具体且聚焦。这将帮助你有效地解决问题，并从数据中提取有价值的见解。还需要考虑问题的范围和可行性，以及你需要的资源和数据。
- en: By asking an interesting and relevant question, you can set the foundation for
    a successful data science project and begin the journey of extracting valuable
    insights from data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 通过提出一个有趣且相关的问题，你可以为成功的数据科学项目奠定基础，开始从数据中提取有价值的见解。
- en: Obtaining the data
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取数据
- en: Obtaining the data is a crucial step in the data science process. It involves
    sourcing and collecting the data that you will need to answer the question or
    solve the problem you have identified. The data can come from a variety of sources,
    including databases, online platforms, research studies, or data scraping or data
    collection methods.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 获取数据是数据科学过程中的一个关键步骤。它涉及从各种来源收集你需要的数据，以回答你已识别的问题或解决所面临的难题。数据可以来自多种来源，包括数据库、在线平台、研究研究，或是数据抓取或收集方法。
- en: This step can be very creative as you will need to think creatively about where
    to find the data that is most relevant to your question. You may need to explore
    different sources and platforms, and you may need to use a variety of data collection
    methods to gather the data you need.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程可能非常富有创意，因为你需要创造性地思考从哪里获取与问题最相关的数据。你可能需要探索不同的来源和平台，并且可能需要使用多种数据收集方法来收集所需的数据。
- en: It’s important to be mindful of the quality of the data you are collecting,
    as well as any potential biases or limitations that may be present in the data.
    It’s also important to consider ethical and legal considerations, such as obtaining
    proper consent and protecting sensitive or confidential data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集数据时，重要的是要注意数据的质量，以及数据中可能存在的任何偏差或局限性。同时，还需要考虑伦理和法律问题，例如获得适当的同意和保护敏感或机密数据。
- en: Once you have collected your data, it’s essential to clean and preprocess it
    so that it is in a usable format. This can involve removing missing or inaccurate
    data, formatting the data in a way that makes it easier to work with, and ensuring
    that the data is consistent and accurate.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦收集到数据，至关重要的是对数据进行清理和预处理，以确保它处于可用的格式。这可能包括去除缺失或不准确的数据，将数据格式化以便于使用，并确保数据的一致性和准确性。
- en: By effectively collecting and preprocessing your data, you can set the stage
    for a successful data science project and be well prepared to move on to the next
    steps of exploring and analyzing the data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过有效地收集和预处理数据，你可以为成功的数据科学项目奠定基础，并为下一步的数据探索和分析做好准备。
- en: Exploring the data
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索数据
- en: Exploring the data is an essential step in the data science process as it involves
    examining the characteristics and patterns in your data to gain a better understanding
    of it. This step is crucial for identifying trends, relationships, and insights
    that can inform your analysis and answer your research question.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 探索数据是数据科学过程中的一个关键步骤，它涉及检查数据中的特征和模式，以便更好地理解数据。此步骤对于识别趋势、关系和洞察非常重要，这些可以为你的分析提供信息，并回答你的研究问题。
- en: There are many different ways to explore data, including visualizing it using
    graphs, charts, and plots, as well as applying statistical and ML techniques to
    identify patterns and relationships. It’s important to be mindful of the types
    of data you are working with, as different types of data may require different
    approaches to exploration.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 探索数据有多种方法，包括使用图形、图表和绘图来可视化数据，以及应用统计和机器学习技术来识别模式和关系。重要的是要注意你所处理的数据类型，因为不同类型的数据可能需要不同的探索方法。
- en: This step can be time-consuming as it may involve spending several hours learning
    about the domain and using code or other tools to manipulate and explore the data.
    By the time this step is completed, the analyst should have a good understanding
    of the potential insights that the data might contain and be able to form hypotheses
    about what the data might be trying to tell them.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程可能会非常耗时，因为它可能涉及花费数小时了解相关领域，并使用代码或其他工具来操作和探索数据。完成这一步骤后，分析师应该对数据中可能包含的潜在洞察有较好的理解，并能够形成关于数据可能传递的信息的假设。
- en: Exploring the data is a crucial step in the data science process as it helps
    to inform the direction of your analysis and guide your choice of modeling and
    analysis techniques. It’s important to be thorough and meticulous in this step
    as the insights you gain can have significant implications for your results and
    conclusions.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 探索数据是数据科学过程中的一个关键步骤，因为它有助于指导分析的方向，并帮助你选择合适的建模和分析技术。在此步骤中，重要的是要细致入微，因为你获得的洞察可能会对结果和结论产生重要影响。
- en: Modeling the data
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据建模
- en: Modeling the data is an important step in the data science process as it involves
    using statistical and ML techniques to build models that can be used to make predictions
    or inform decision-making. This step can be complex as it involves fitting and
    choosing the appropriate models for your data and objectives, as well as implementing
    mathematical validation metrics to quantify the effectiveness of the models.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 建模数据是数据科学过程中的重要一步，因为它涉及使用统计学和机器学习技术建立可以用来进行预测或指导决策的模型。这一步可能很复杂，因为它涉及为你的数据和目标拟合并选择合适的模型，并且还需要实施数学验证指标来量化模型的有效性。
- en: Many different types of models can be used in data science, including linear
    regression models, logistic regression models, decision tree models, and **neural
    network** (**NN**) models, to name a few. It’s important to choose the model that
    is most appropriate for your data and the question you are trying to answer.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学中可以使用多种不同类型的模型，包括线性回归模型、逻辑回归模型、决策树模型以及**神经网络**（**NN**）模型等等。选择最适合你的数据和你要回答的问题的模型非常重要。
- en: Once you have chosen your model, you will need to fit it to your data. This
    involves using statistical or ML algorithms to find the parameters that best fit
    the patterns in your data. You will also need to evaluate the performance of your
    model using validation metrics such as accuracy, precision, and recall. These
    metrics can help you to understand the effectiveness of your model and identify
    any areas for improvement.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你选择了模型，你需要将其拟合到数据中。这涉及使用统计或机器学习算法来找到最佳拟合数据模式的参数。你还需要使用验证指标，如准确率、精确度和召回率，评估模型的性能。这些指标可以帮助你了解模型的有效性，并找出改进的空间。
- en: By effectively modeling your data, you can gain insights and make informed decisions
    based on your analysis. It’s important to carefully consider the choices you make
    at this step, as the quality of your model can greatly affect the accuracy and
    usefulness of your results.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通过有效地建模你的数据，你可以获得见解，并根据你的分析做出明智的决策。仔细考虑在这一步做出的选择非常重要，因为模型的质量可以极大地影响结果的准确性和实用性。
- en: Communicating and visualizing the results
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 沟通和可视化结果
- en: This is arguably the most important step. Communicating and visualizing results
    involves effectively sharing your findings and insights with others. This step
    can be challenging as it requires you to clearly and concisely convey your results
    in a way that is understandable and digestible to your audience.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以说是最重要的一步。沟通和可视化结果涉及到有效地与他人分享你的发现和见解。这一步可能具有挑战性，因为它要求你清晰简洁地传达你的结果，以一种让受众能够理解并消化的方式。
- en: There are many different ways to communicate and visualize your results, including
    creating reports, presentations, and visualizations such as graphs, charts, and
    plots. It’s important to choose the method that is most appropriate for your audience
    and the message you are trying to convey.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的方式可以沟通和可视化你的结果，包括创建报告、演示文稿以及图表、图形和绘图等可视化方式。选择最适合你的受众和你要传达的信息的方式非常重要。
- en: It’s also important to consider the impact of your results and the implications
    of your findings. This can involve discussing the limitations of your analysis,
    the implications of your results, and any recommendations or next steps that may
    be warranted.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，考虑你的结果的影响和发现的意义也很重要。这可能涉及讨论分析的局限性、结果的含义，以及可能需要的任何建议或下一步行动。
- en: In this book, we will focus mainly on *steps 3*, *4*, and *5* of the data science
    process, which involve exploring and analyzing the data, modeling the data, and
    communicating and visualizing the results. While the first two steps of asking
    an interesting question and obtaining the data are also essential to the process,
    we will only touch upon these steps briefly and focus mainly on the more scientific
    aspects of the process. By focusing on these steps, we aim to provide interesting
    questions and datasets that can be used to explore and analyze data.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将主要集中在数据科学过程的*第3步*、*第4步*和*第5步*，即探索和分析数据、建模数据以及沟通和可视化结果。虽然提出有趣的问题和获取数据的前两步对于整个过程也至关重要，但我们将在这里简要提及这些步骤，主要关注过程中的更科学的方面。通过专注于这些步骤，我们旨在提供有趣的问题和数据集，供探索和分析使用。
- en: Why are we skipping steps 1 and 2 in this book?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么在本书中我们跳过了步骤1和步骤2？
- en: While the first two steps are undoubtedly imperative to the process, they generally
    precede statistical and programmatic systems. Later in this book, we will touch
    upon the different ways to obtain data; however, to focus on the more scientific
    aspects of the process, we will begin with exploration right away.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前两步无疑是整个过程中的关键步骤，但它们通常在统计分析和编程系统之前进行。在本书后面的部分，我们将涉及获得数据的不同方式；然而，为了聚焦于过程中的更科学方面，我们将立即开始探索数据。
- en: Let’s focus on the third step a bit more – exploring our data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更专注于第三步——探索我们的数据。
- en: Exploring the data
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据
- en: The process of exploring data is not always straightforward and can involve
    a variety of approaches and techniques. Some common tasks that are involved in
    data exploration include recognizing different types of data, transforming data
    types, and using code to systematically improve the quality of the entire dataset.
    These tasks can be accomplished using tools such as the `pandas` Python package,
    which is commonly used for data manipulation and analysis.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 数据探索的过程并不总是直截了当的，可能涉及多种方法和技术。数据探索中一些常见的任务包括识别不同类型的数据、转换数据类型以及使用代码系统地提高整个数据集的质量。这些任务可以通过工具来完成，例如常用的`pandas`
    Python包，用于数据处理和分析。
- en: 'There are a few basic questions that you should consider when exploring a new
    dataset. These questions can help you to get a sense of the data and guide your
    analysis. The three basic questions are presented here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索新数据集时，您应该考虑一些基本问题。这些问题可以帮助您了解数据并指导分析。以下是三个基本问题：
- en: What are the types of data that are present in the dataset?
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集中存在哪些类型的数据？
- en: What are the characteristics and patterns of the data?
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的特征和模式是什么？
- en: How is the data organized, and what transformations might be necessary to make
    it more usable?
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是如何组织的？需要进行哪些转化才能使其更易用？
- en: By answering these questions and exploring your data thoroughly, you can gain
    a deeper understanding of the data and be well prepared to move on to the next
    steps of modeling and analyzing the data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 通过回答这些问题并彻底探索数据，您可以更深入地理解数据，并为下一步的建模和分析做好充分准备。
- en: Guiding questions for data exploration
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据探索的指导问题
- en: 'When given a new dataset, whether it is familiar to you or not, it is important
    to use the following questions as guidelines for your preliminary analysis:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当遇到一个新的数据集时，无论它是否熟悉，都应该使用以下问题作为初步分析的指南：
- en: '**Is the data structured or not?**: We are checking whether or not the data
    is presented in a row/column structure. For the most part, data will be presented
    in a structured fashion. In this book, over 90% of our examples will begin with
    structured data. Nevertheless, this is the most basic question that we can answer
    before diving any deeper into our analysis. A general rule of thumb is that if
    we have unstructured data, we want to transform it into a row/column structure.
    For example, earlier in this book, we looked at ways to transform text into a
    row/column structure by counting the number of words/phrases.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据是结构化的还是非结构化的？**：我们需要检查数据是否以行/列结构呈现。大多数情况下，数据将以结构化的方式呈现。在本书中，超过90%的示例将从结构化数据开始。然而，在深入分析之前，这是我们可以回答的最基本问题。一般来说，如果我们拥有非结构化数据，我们需要将其转换为行/列结构。例如，在本书的早些章节，我们探讨了如何通过统计单词/短语的数量来将文本转化为行/列结构。'
- en: '**What does each row represent?**: Once we have an answer to how the data is
    organized and are looking at a nice row/column-based dataset, we should identify
    what each row actually represents. This step is usually very quick and can help
    put things into perspective much more quickly.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每一行代表什么？**：一旦我们弄清楚数据是如何组织的，并且看到一个整齐的行/列结构数据集，我们就应该确定每一行实际代表什么。这个步骤通常非常迅速，并且能够帮助我们更快地将事情理清。'
- en: '**What does each column represent?**: We should identify each column by the
    level of data, whether or not it is quantitative/qualitative, and so on. This
    categorization might change as our analysis progresses, but it is important to
    begin this step as early as possible.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每一列代表什么？**：我们应该通过数据的级别来识别每一列，判断它是定量的还是定性的，等等。随着分析的进行，这种分类可能会发生变化，但尽早开始这一步是很重要的。'
- en: '**Are there any missing data points?**: Data isn’t perfect. Sometimes, we might
    be missing data because of human or mechanical error. When this happens, we, as
    data scientists, must make decisions about how to deal with these discrepancies.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**是否有缺失的数据点？**：数据并不完美。有时，由于人为或机械错误，我们可能会缺少数据。当这种情况发生时，作为数据科学家，我们必须决定如何处理这些差异。'
- en: '**Do we need to perform any transformations on the columns?**: Depending on
    the level/type of data in each column, we might need to perform certain types
    of transformation. For example, generally speaking, for the sake of statistical
    modeling and ML, we would like each column to be numerical, so would use Python
    to make any transformations.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**我们是否需要对列进行任何转换？**：根据每列数据的级别/类型，我们可能需要执行某些类型的转换。例如，通常为了统计建模和机器学习的目的，我们希望每一列都是数值型的，因此我们会使用
    Python 来进行转换。'
- en: All the while, we are asking ourselves the overall question *What can we infer
    from the preliminary inferential statistics?* We want to be able to understand
    our data better than when we first found it.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个过程中，我们不断问自己一个总体问题：*我们从初步推断统计中能推导出什么？* 我们希望比最初发现数据时更好地理解这些数据。
- en: Enough talk; let’s see a hands-on example.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 够了，言归正传；让我们看一个实际操作的例子。
- en: Dataset 1 – Yelp
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集 1 – Yelp
- en: The first dataset we will look at is a public dataset made available by the
    restaurant review site *Yelp*. All **personally identifiable information** (**PII**)
    has been removed. I am purposefully not giving much information because part of
    our goal is to ascertain elements about this data for ourselves. If I told you
    more, where would be the fun in that?
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要查看的第一个数据集是餐厅评论网站 *Yelp* 提供的公开数据集。所有的 **个人可识别信息**（**PII**）都已被移除。我故意没有提供太多信息，因为我们的一部分目标是自己通过这个数据来推测一些内容。如果我告诉你更多，那还有什么乐趣呢？
- en: 'Let’s say we were just given this data. The first thing we have to do is read
    it in, as shown here:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们刚刚得到了这些数据。我们需要做的第一件事是读取它，如下所示：
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here’s a quick recap of what the preceding code does:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对前面代码功能的简要回顾：
- en: It imports the **pandas** package and nicknames it **pd**.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它导入 **pandas** 包并将其别名为 **pd**。
- en: It reads in the **.csv** file from the web and calls it **yelp_raw_data/**.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它从网络中读取 **.csv** 文件，并将其命名为 **yelp_raw_data/**。
- en: It looks at the head of the data (just the first few rows).
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它查看数据的头部（仅前几行）。
- en: 'We get the following output:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![Figure 3.1 – The first five rows (the head) of the pandas DataFrame of our
    Yelp dataset reveals a mix of data levels, including nominal (for example, text,
    business_id) and ordinal (cool, useful, and funny)](img/B19488_03_01.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.1 – 我们的 Yelp 数据集的 pandas DataFrame 中的前五行（头部）展示了不同的数据级别，包括名义数据（例如，text，business_id）和序数数据（cool，useful，funny）](img/B19488_03_01.jpg)'
- en: Figure 3.1 – The first five rows (the head) of the pandas DataFrame of our Yelp
    dataset reveals a mix of data levels, including nominal (for example, text, business_id)
    and ordinal (cool, useful, and funny)
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – 我们的 Yelp 数据集的 pandas DataFrame 中的前五行（头部）展示了不同的数据级别，包括名义数据（例如，text，business_id）和序数数据（cool，useful，funny）
- en: 'From here, we can begin to ask some key questions. Let’s start with this one:
    *Is the data structured or not?* Because we have a nice row/column structure,
    we can conclude that this data seems to be structured.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，我们可以开始提出一些关键问题。我们先从这个问题开始：*数据是结构化的还是非结构化的？* 由于我们有一个清晰的行/列结构，我们可以得出结论，这个数据看起来是结构化的。
- en: 'So, then, the next logical question would be *What does each row represent?*
    It seems pretty obvious that each row represents a user giving a review of a business.
    The next thing we should do is examine each row and label it by the type of data
    it contains. At this point, we can also use Python to figure out just how big
    our dataset is. We can use the shape quality of a DataFrame to find this out,
    as shown:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，接下来，合乎逻辑的下一个问题是：*每一行代表什么？* 看起来很明显，每一行代表一个用户对某个商家的评论。接下来，我们应该做的就是检查每一行，并根据它所包含的数据类型进行标注。此时，我们也可以使用
    Python 来找出数据集的大小。我们可以使用 DataFrame 的 shape 属性来查找这个信息，如下所示：
- en: '[PRE1]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It tells us that this dataset has `10000` rows and `10` columns. Another way
    to say this is that this dataset has 10,000 observations and 10 characteristics.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 它告诉我们这个数据集有 `10000` 行和 `10` 列。换句话说，这个数据集有 10,000 个观察值和 10 个特征。
- en: 'OK—so, then, the next question: *What does* each column represent? (Note that
    we have 10 columns.) Let’s have a look at the answers:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 好的——那么，接下来的问题是：*每一列代表什么？*（注意，我们有 10 列。）让我们来看看答案：
- en: '**business_id**: This is likely to be a unique identifier for the business
    the review is for. This would be at the **nominal level** because there is no
    natural order to this identifier.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**business_id**: 这很可能是评论所针对的商家的唯一标识符。由于这个标识符没有自然顺序，它属于**名义水平**。'
- en: '**date**: This is probably the date on which the review was posted. Note that
    it seems to be only specific to the day, month, and year. Even though time is
    usually considered continuous, this column would likely be considered discrete
    and at the **ordinal level** because of the natural order that dates have.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**date**: 这很可能是评论发布的日期。注意，它似乎仅针对日期、月份和年份。尽管时间通常被认为是连续的，但由于日期具有自然顺序，这一列可能被认为是离散的，且处于**顺序水平**。'
- en: '**review_id**: This is likely to be a unique identifier for the review that
    each post represents. This would be at the nominal level because, again, there
    is no natural order to this identifier.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**review_id**: 这很可能是每条帖子代表的评论的唯一标识符。由于这个标识符没有自然的顺序，因此它属于名义水平。'
- en: '**stars**: From a quick look (don’t worry; we will perform some further analysis
    soon), we can see that this is an ordered column that represents what the reviewer
    gave the restaurant as a final score. This is ordered and qualitative, so is at
    the ordinal level.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**stars**: 从快速查看来看（别担心，我们很快会进行进一步的分析），我们可以看到这是一个有序的列，表示评论者给餐厅的最终评分。它是有序且定性的，因此处于顺序水平。'
- en: '**text**: This is probably the raw text that each reviewer wrote. As with most
    text, we place this at the nominal level.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**text**: 这很可能是每个评论者写的原始文本。像大多数文本一样，我们将其放在名义水平。'
- en: '**type**: In the first five rows, all we see is the word **review**. This might
    be a column that identifies that each row is a review, implying that there might
    be another type of row other than a review. We will take a look at this later.
    We place this at the nominal level.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**type**: 在前五行中，我们看到的都是**review**这个词。这可能是一个标识每行数据为评论的列，意味着可能还有除评论之外的其他类型的行。我们稍后会再看这个。我们将其放在名义水平。'
- en: '**user_id**: This is likely to be a unique identifier for the user who is writing
    the review. Just as with the other unique identifiers, we place this data at the
    nominal level.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**user_id**: 这很可能是写评论的用户的唯一标识符。就像其他唯一标识符一样，我们把这个数据放在名义水平。'
- en: Our next question is *Are there any missing data points?* Perform an `isnull`
    operation. For example, if your DataFrame is called `awesome_dataframe`, then
    try the `awesome_dataframe.isnull().sum()` Python command, which will show the
    number of missing values in each column.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下一个问题是*是否存在缺失的数据点？* 执行`isnull`操作。例如，如果你的数据框名称是`awesome_dataframe`，可以尝试运行`awesome_dataframe.isnull().sum()`这个Python命令，它会显示每列缺失值的数量。
- en: Our question after that would be *Do we need to perform any transformations
    on the columns?* At this point, we are looking for a few things. For example,
    will we need to change the scale of some of the quantitative data, or do we need
    to create dummy variables for the qualitative variables? As this dataset only
    has qualitative columns, we can only focus on transformations at the ordinal and
    nominal scales.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来的问题是*我们是否需要对列进行任何变换？* 此时，我们正在寻找几个问题。例如，我们是否需要更改某些定量数据的尺度，或者是否需要为定性变量创建虚拟变量？由于此数据集只有定性列，我们只能关注顺序和名义尺度上的变换。
- en: Before starting, let’s go over some quick terminology for `pandas`, the Python
    data exploration module.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，让我们先了解一些`pandas`，这个Python数据探索模块的基本术语。
- en: DataFrames
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DataFrames
- en: When we read in a dataset, `pandas` creates a custom object called `DataFrame`.
    Think of this as the Python version of a spreadsheet (but way better). In this
    case, the `yelp_raw_data` variable is a DataFrame.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们读取数据集时，`pandas`会创建一个名为`DataFrame`的自定义对象。可以把它当作Python版本的电子表格（但要强大得多）。在这个例子中，`yelp_raw_data`变量就是一个DataFrame。
- en: 'To check whether this is true in Python, type in the following code:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查这是否在Python中为真，可以输入以下代码：
- en: '[PRE2]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: DataFrames are two-dimensional in nature, meaning that they are organized in
    a row/column structure just as spreadsheets are. The main benefit of using DataFrames
    over, say, spreadsheet software is that a DataFrame can handle much larger data
    than most common spreadsheet software. If you are familiar with the R language,
    you might recognize the word DataFrame. This is because the name was actually
    borrowed from the language!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame是二维的，这意味着它们的结构像电子表格一样按行/列组织。使用DataFrame的主要好处是，DataFrame可以处理比大多数常见电子表格软件更大的数据。如果你熟悉R语言，你可能会认出DataFrame这个词。因为这个名字实际上是从R语言借来的！
- en: As most of the data that we will deal with is structured, DataFrames are likely
    to be the most used object in `pandas`, second only to the `Series` object.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们处理的大部分数据是结构化的，因此DataFrame很可能是`pandas`中使用最广泛的对象，仅次于`Series`对象。
- en: Series
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 序列
- en: 'The `Series` object is simply a DataFrame, but only with one dimension. Essentially,
    it is a list of data points. Each column of a DataFrame is considered to be a
    `Series` object. Let’s check this—the first thing we need to do is grab a single
    column from our DataFrame; we generally use what is known as **bracket notation**.
    The following is an example:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`Series`对象本质上是一个DataFrame，只不过它只有一个维度。实际上，它是一个数据点的列表。DataFrame的每一列都被视为一个`Series`对象。让我们来检查一下——我们需要做的第一件事是从DataFrame中提取单列；我们通常使用被称为**括号表示法**的方式。以下是一个示例：'
- en: '[PRE3]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We will list the first and last few rows, as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将列出前几行和后几行，如下所示：
- en: '[PRE4]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s use the `type` function to check that this column is a `Series` object:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`type`函数检查这一列是否是`Series`对象：
- en: '[PRE5]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `pandas` `Series` object will come up time and time again as it is a core
    component of `DataFrame`.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`的`Series`对象会反复出现，因为它是`DataFrame`的核心组件。'
- en: Exploration tips for qualitative data
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定性数据探索提示
- en: Using these two `pandas` objects, let’s start performing some preliminary data
    exploration. For qualitative data, we will specifically look at the nominal and
    ordinal levels.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两个`pandas`对象，我们开始进行一些初步的数据探索。对于定性数据，我们将特别关注名义级和顺序级数据。
- en: Nominal-level columns
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 名义级数据列
- en: 'As we are at the nominal level, let’s recall that at this level, data is qualitative
    and is described purely by name. In this dataset, this refers to `business_id`,
    `review_id`, `text`, `type`, and `user_id`. Let’s use `pandas` in order to dive
    a bit deeper, as shown here:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们处于名义级数据层次，让我们回忆一下，在这个层次，数据是定性的，仅通过名称进行描述。在这个数据集中，这指的是`business_id`、`review_id`、`text`、`type`和`user_id`。让我们使用`pandas`进行更深入的探索，正如下面所示：
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `describe` function will give us some quick stats about the column whose
    name we enter into the quotation marks. Note how `pandas` automatically recognized
    that `business_id` was a qualitative column and gave us stats that make sense.
    When `describe` is called on a qualitative column, we will always get the following
    four items:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`describe`函数会给我们输入列名后的一些快速统计数据。注意，`pandas`自动识别了`business_id`是一个定性列，并提供了合适的统计信息。当`describe`函数作用于定性列时，我们总会得到以下四项内容：'
- en: '**count**: How many values are filled in'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**count**：填入的值的数量'
- en: '**unique**: How many unique values are filled in'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**unique**：填入的唯一值的数量'
- en: '**top**: The name of the most common item in the dataset'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**top**：数据集中最常见项的名称'
- en: '**freq**: How often the most common item appears in the dataset'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**freq**：数据集中最常见项出现的频率'
- en: 'At the nominal level, we are usually looking for a few things that would signal
    a transformation:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在名义级数据中，我们通常会寻找一些信号，表明数据需要转换：
- en: Do we have a reasonable number (usually under 20) of unique items?
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否有合理数量（通常低于20个）的唯一项？
- en: Is this column text?
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个列是文本数据吗？
- en: Is this column unique across all rows?
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这一列在所有行中是唯一的吗？
- en: 'So, for the `business_id` column, we have a count of 10,000\. Don’t be fooled,
    though! This does not mean that we have 10,000 businesses being reviewed here.
    It just means that of the 10,000 rows of reviews, the `business_id` column is
    filled in all 10,000 times. The next qualifier, `unique`, tells us that we have
    4,174 unique businesses being reviewed in this dataset. The most reviewed business
    is the `JokKtdXU7zXHcr20Lrk29A` business, which was reviewed 37 times:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，对于`business_id`这一列，我们有10,000个计数。不过，不要被迷惑！这并不意味着我们这里有10,000家企业在被评审。这仅仅意味着在10,000条评审数据中，`business_id`这一列每一行都填入了数据。下一个标志`unique`告诉我们，在这个数据集中，涉及4,174个独特的企业被评审。最多评审的企业是`JokKtdXU7zXHcr20Lrk29A`，它共被评审了37次：
- en: '[PRE7]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We have a `count` of `10000` and `unique` of `10000`. Think for a second—does
    this make sense? Think about what each row represents and what this column represents.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个`count`为`10000`，`unique`也为`10000`。稍微想一下——这有道理吗？想想每一行代表的是什么，这一列又代表的是什么。
- en: '*(Insert Jeopardy theme* *song here.)*'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*(在这里插入《Jeopardy》主题曲)*'
- en: 'Of course it does! Each row of this dataset is supposed to represent a single,
    unique review of a business, and this column is meant to serve as a unique identifier
    for a review. So, it makes sense that the `review_id` column has `10000` unique
    items in it. So, why is `eTa5KD-LTgQv6UT1Zmijmw` the *most common* review? This
    is just a random choice from `10000` and means nothing:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 当然有道理！该数据集的每一行应该代表一条单独的、独特的商业评论，而这一列旨在作为评论的唯一标识符。因此，`review_id`这一列中有`10000`个唯一项是合理的。那么，为什么`eTa5KD-LTgQv6UT1Zmijmw`是*最常见*的评论呢？这只是从`10000`中随机选出的，并没有什么特别的含义：
- en: '[PRE9]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This column, which represents the actual text people wrote, is interesting.
    We would imagine that this should also be similar to `review_id` in that each
    one should contain unique text because it would be weird if two people wrote exactly
    the same thing, but we have two reviews with the exact same text! Let’s take a
    second to learn about DataFrame filtering to examine this further.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这一列代表了人们写的实际文本，非常有趣。我们会想象这一列也应该像`review_id`一样，每一项都应该包含独特的文本，因为如果两个人写的完全相同，那就很奇怪了，但我们确实有两个评论的文本完全相同！让我们花点时间学习如何过滤DataFrame，进一步研究这个问题。
- en: Filtering in pandas
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pandas中的过滤
- en: Let’s talk a bit about how filtering works. Filtering rows based on certain
    criteria is quite easy in `pandas`. In a DataFrame, if we wish to filter out rows
    based on some search criteria, we will need to go row by row and check whether
    or not a row satisfies that particular condition; `pandas` handles this by passing
    in a `Series` object of `True` and `False` (Booleans).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微谈谈过滤是如何工作的。基于特定标准过滤行在`pandas`中非常简单。在DataFrame中，如果我们希望基于某些搜索条件来过滤行，我们需要逐行检查每一行是否满足该条件；`pandas`通过传递一个包含`True`和`False`（布尔值）的`Series`对象来处理这个问题。
- en: 'We literally pass into the DataFrame a list of `True` and `False` data that
    mean the following:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实际上是将一个包含`True`和`False`数据的列表传递给DataFrame，这意味着以下：
- en: '**True**: This row satisfies the condition'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**True**：这一行满足条件'
- en: '**False**: This row does not satisfy the condition'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**False**：这一行不满足条件'
- en: 'So, first, let’s make the conditions. In the following lines of code, I will
    grab the text that occurs twice:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，首先，让我们设定条件。在以下的代码行中，我将抓取那些出现了两次的文本：
- en: '[PRE10]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here is a snippet of the text:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这是文本的一个片段：
- en: '[PRE11]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Right off the bat, we can guess that this might actually be one person who went
    to review two businesses that belong to the same chain and wrote the exact same
    review. However, this is just a guess right now.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 立刻，我们可以猜测这可能是一个人去评论了两家属于同一连锁的商店，并写了完全相同的评论。不过，目前这只是猜测。
- en: Important note
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The **duplicate_text** variable is of the **string** type.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**duplicate_text**变量是**字符串**类型的。'
- en: 'Now that we have this text, let’s use some magic to create that `Series` object
    of `True` and `False`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了这些文本，让我们用一些魔法来创建这个`Series`对象，里面包含`True`和`False`：
- en: '[PRE12]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Right away, you might be confused. What we have done here is take the `text`
    column of the DataFrame and compare it to the `duplicate_text string`. This is
    strange because we seem to be comparing a list of `10,000` elements to a single
    string. Of course, the answer should be a straight false, right?
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会马上感到困惑。我们这里做的事情是将DataFrame中的`text`列与`duplicate_text string`进行比较。这很奇怪，因为我们似乎是在将一个包含`10,000`个元素的列表与一个单一的字符串进行比较。显然，答案应该是直接返回`false`，对吧？
- en: '`Series` has a very interesting feature in that if you compare the series to
    an object, it will return another series of Booleans of the same length where
    each `True` and `False` instance is the answer to the question *Is this element
    the same as the element you are comparing it to?* Very handy!'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`Series`有一个非常有趣的特性，就是如果你将它与一个对象进行比较，它将返回一个布尔值的系列，长度与原系列相同，其中每个`True`和`False`实例都是对问题*“这个元素是否与正在比较的元素相同？”*的答案。非常方便！'
- en: This next code block shows us a preview of the contents of this new Series.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的代码块将展示这个新Series的内容预览。
- en: '[PRE13]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In Python, we can add and subtract `True` and `False` as if they were `1` and
    `0`, respectively—for example, `True + False – True + False + True == 1`. So,
    we can verify that this `Series` object is correct by adding up all of the values.
    As only two of these rows should contain the duplicate text, the sum of the `Series`
    object should only be `2`, which it is! This is shown as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，我们可以像对待`1`和`0`一样加减`True`和`False`，例如，`True + False – True + False +
    True == 1`。因此，我们可以通过对所有值求和来验证这个`Series`对象是否正确。由于只有两行包含重复文本，`Series`对象的总和应该是`2`，而实际结果也是如此！如下所示：
- en: '[PRE14]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now that we have our series of Booleans, we can pass them directly into our
    DataFrame, using bracket notation, and get our filtered rows, as illustrated:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一系列布尔值，我们可以直接将它们传入我们的DataFrame，使用括号表示法，获取过滤后的行，如下所示：
- en: '[PRE15]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Figure 3.2 – Representing two rows with duplicate text, stars, and survey
    scores](img/B19488_03_02.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2 – 表示两行重复的文本、星级和调查得分](img/B19488_03_02.jpg)'
- en: Figure 3.2 – Representing two rows with duplicate text, stars, and survey scores
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – 表示两行重复的文本、星级和调查得分
- en: Data is hardly ever perfect, and a common thing to check for when dealing with
    raw text is the amount of duplicate fields. In this figure, we can see that there
    are two rows with duplicate text, stars, and survey scores. This is likely written
    by the same person given to two locations of a chain.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 数据很少是完美的，在处理原始文本时，常常需要检查重复字段的数量。在这个图表中，我们可以看到有两行重复的文本、星级和调查得分。很可能是同一个人给同一个连锁店的两个位置写的评论。
- en: 'It seems that our suspicions were correct, and one person, on the same day,
    gave the exact same review to two different `business IDs` column, presumably
    a part of the same chain. Let’s keep moving along to the rest of our columns:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 看来我们的怀疑是正确的，有一个人在同一天为两个不同的`business IDs`列写了完全相同的评论，推测这两个列可能属于同一个链条。让我们继续看接下来的列：
- en: '[PRE16]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Remember this column? Turns out they are all the exact same type, namely `review`:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 记得这个列吗？结果发现它们都是完全相同的类型，即`review`：
- en: '[PRE17]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Similar to the `business_id` column, all 10,000 values are filled in with 6,403
    unique users and one user reviewing 38 times!
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于`business_id`列，所有10,000个值都由6,403个独特的用户填写，其中有一个用户评论了38次！
- en: In this example, we won’t have to perform any transformations.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们无需进行任何转换。
- en: Ordinal-level columns
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 顺序型列
- en: 'As far as ordinal columns go, we are looking at `date` and `stars`. For each
    of these columns, let’s look at what the `describe` method brings back:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 对于顺序列，我们要查看的是`date`和`stars`。对于这些列，让我们看看`describe`方法返回的结果：
- en: '[PRE18]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Woah! Even though this column is ordinal, the `describe` method returns stats
    that we might expect for a quantitative column. This is because the software saw
    a bunch of numbers and just assumed that we wanted stats such as the mean or the
    min and max. This is not a problem. Let’s use a method called `value_counts` to
    see the count distribution, as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！即使这个列是顺序型的，`describe`方法返回的统计数据就像是数量型列的统计数据一样。这是因为软件看到了一堆数字，假设我们想要像均值、最小值和最大值这样的统计数据。这并不成问题。我们可以使用一个叫做`value_counts`的方法来查看计数分布，如下所示：
- en: '[PRE19]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `value_counts` method will return the distribution of values for any column.
    In this case, we see that the star rating `4` is the most common, with `3526`
    values, followed closely by rating `5`. We can also plot this data to get a nice
    visual. First, let’s sort by star rating, and then use the prebuilt `plot` method
    to make a bar chart:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`value_counts`方法将返回任何列的值分布。在这种情况下，我们看到星级`4`是最常见的，拥有`3526`个值，其次是星级`5`。我们还可以将这些数据可视化。首先，我们按星级排序，然后使用预构建的`plot`方法绘制柱状图：'
- en: '[PRE20]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![Figure 3.3 – A distribution of the star ratings given reveals that most  people
    are giving 4 or 5 stars, with the most common star rating being 4](img/B19488_03_03.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3 – 星级评分分布显示大多数人给4或5星，最常见的星级是4](img/B19488_03_03.jpg)'
- en: Figure 3.3 – A distribution of the star ratings given reveals that most people
    are giving 4 or 5 stars, with the most common star rating being 4
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 – 星级评分分布显示大多数人给4或5星，最常见的星级是4
- en: From this graph, we can conclude that people are definitely more likely to give
    good star ratings over bad ones! We can follow this procedure for the `date` column.
    I will leave you to try it on your own. For now, let’s look at a new dataset.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图表中，我们可以得出结论：人们显然更倾向于给出好评星级而非差评星级！我们可以对`date`列进行相同的处理。我会留给你自己尝试。现在，让我们来看一个新的数据集。
- en: Dataset 2 – Titanic
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集2 – 泰坦尼克号
- en: The `Titanic` dataset is one of those “rites of passage” datasets in data science.
    Everyone, at some point, has seen this dataset in some tutorial or book. It contains
    a sample of people who were on the Titanic when it struck an iceberg in 1912\.
    I give you my word that, going forward, we will be using much more interesting
    datasets, but trust me, it’s easier to start off with a dataset such as this one
    and Yelp to warm up the data science muscles.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`Titanic` 数据集是数据科学中一种“入门”数据集。每个人都在某些教程或书籍中看到过这个数据集。它包含了1912年泰坦尼克号撞上冰山时的一部分乘客样本。我向你保证，往后我们会使用更有趣的数据集，但相信我，先从像这样的数据集和
    Yelp 开始能更好地热身数据科学技能。'
- en: 'Let’s go ahead and import our new dataset and output the first five rows using
    the `head` method:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续导入新的数据集，并使用 `head` 方法输出前五行：
- en: '[PRE21]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This table represents the DataFrame for the `short_titanic.csv` dataset. This
    data is definitely organized in a row/column structure, as is most spreadsheet
    data. Let’s take a quick peek at its size:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表格表示 `short_titanic.csv` 数据集的 DataFrame。此数据肯定是以行/列结构组织的，就像大多数电子表格数据一样。让我们快速查看它的大小：
- en: '[PRE22]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We have `891` rows and `5` columns. Each row seems to represent a single passenger
    on the ship, and as far as columns are concerned, the following list tells us
    what they indicate:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有 `891` 行和 `5` 列。每一行似乎代表船上的一名乘客，至于列，以下列表告诉我们它们表示的内容：
- en: '**Survived**: This is a binary variable that indicates whether or not the passenger
    survived the accident (**1** if they survived, **0** if they died). This is likely
    to be at the nominal level because there are only two options.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生还**：这是一个二元变量，表示乘客是否在事故中幸存（**1** 表示幸存，**0** 表示死亡）。这可能属于名义层次，因为只有两个选项。'
- en: '**Pclass**: This is the class that the passenger was traveling in (**3** for
    third class, and so on). This is at the ordinal level.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**舱位**：这是乘客所乘的舱位（**3** 表示三等舱，以此类推）。这属于序数层次。'
- en: '**Name**: This is the name of the passenger, and it is definitely at the nominal
    level.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**姓名**：这是乘客的姓名，绝对属于名义层次。'
- en: '**Sex**: This indicates the gender of the passenger. It is at the nominal level.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性别**：这表示乘客的性别。它处于名义层次。'
- en: '**Age**: This one is a bit tricky. Arguably, you may place age at either a
    qualitative or quantitative level; however, I think that age belongs to a quantitative
    state, and thus, to the ratio level.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**年龄**：这个有点棘手。可以说，年龄可以放在定性或定量层次；不过，我认为年龄属于定量状态，因此属于比率层次。'
- en: 'As far as transformations are concerned, usually, we want all columns to be
    numerical, regardless of their qualitative state. This means that `Name` and `Sex`
    will have to be converted into numerical columns somehow. For `Sex`, we can change
    the column to hold 1 if the passenger was female and 0 if they were male. Let’s
    use `pandas` to make the change. We will have to import another Python module,
    called `numpy` or numerical Python, as illustrated:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 至于转换，通常我们希望所有列都是数值型的，无论它们的定性状态如何。这意味着 `姓名` 和 `性别` 列必须以某种方式转换为数值列。对于 `性别`，我们可以将该列更改为如果乘客是女性，则为
    1；如果是男性，则为 0。让我们使用 `pandas` 来进行更改。我们将需要导入另一个 Python 模块，叫做 `numpy` 或数值 Python，如下所示：
- en: '[PRE23]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `np.where` method takes in three things, as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`np.where` 方法接收三项内容，如下所示：'
- en: A list of Booleans (**True** or **False**)
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个布尔值列表（**True** 或 **False**）
- en: A new value
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个新值
- en: A backup value
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个备份值
- en: 'The method will replace all `True` instances with the first value (in this
    case, 1) and the `False` instances with the second value (in this case, 0), leaving
    us with a new numerical column that represents the same thing as the original
    `Sex` column:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法会将所有 `True` 实例替换为第一个值（在本例中为 1），将 `False` 实例替换为第二个值（在本例中为 0），从而生成一个新的数值列，该列表示与原始
    `性别` 列相同的内容：
- en: '[PRE24]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s use a shortcut and describe all the columns at once so that we can get
    a bird’s-eye view of what our data looks like and how it is roughly shaped. The
    code to do this is shown in this code snippet:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用一个快捷方式，一次性描述所有列，以便我们能快速了解数据的整体情况以及它的大致形态。执行此操作的代码如下所示：
- en: '[PRE25]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![Figure 3.4 – Descriptive statistics of our Titanic dataset’s numerically
    formatted columns ](img/B19488_03_04.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.4 – 我们的泰坦尼克号数据集的数值格式列的描述性统计](img/B19488_03_04.jpg)'
- en: Figure 3.4 – Descriptive statistics of our Titanic dataset’s numerically formatted
    columns
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 – 我们的泰坦尼克号数据集的数值格式列的描述性统计
- en: Reveal that these features have pretty different ranges and means. Note that
    just because the column is “numerical” doesn’t mean it is quantitative. Pclass
    would generally be recommended as qualitative even though it is shown here as
    integers.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 显示这些特征的范围和均值差异很大。请注意，仅仅因为列是“数值型”的，并不意味着它是定量的。尽管`Pclass`这里显示为整数，但通常建议将其视为定性变量。
- en: 'This table lists descriptive statistics of the Titanic dataset. Note how our
    qualitative columns are being treated as quantitative; however, I’m looking for
    something irrelevant to the data type. Note the `count` row: `Survived`, `Pclass`,
    and `Sex` all have `891` values (the number of rows), but `Age` only has `714`
    values. Some are missing! To double-verify, let’s use the `pandas` `isnull` and
    `sum functions`, as shown:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这张表列出了泰坦尼克号数据集的描述性统计信息。请注意，我们的定性列被当作定量列处理；然而，我正在寻找一些与数据类型无关的内容。注意`count`行：`Survived`、`Pclass`和`Sex`都有`891`个值（行数），但`Age`只有`714`个值。有些值是缺失的！为了再次验证，我们可以使用`pandas`的`isnull`和`sum`函数，如下所示：
- en: '[PRE26]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This will show us the number of missing values in each column. So, `Age` is
    the only column with missing values to deal with.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示每列中缺失值的数量。所以，`Age`是唯一一个需要处理缺失值的列。
- en: 'When dealing with missing values, you usually have the following two options:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理缺失值时，通常有以下两个选择：
- en: Drop the row with the missing value
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除含有缺失值的行
- en: Try to fill it in
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试填充它
- en: Dropping the row is the easy choice; however, you run the risk of losing valuable
    data! For example, in this case, we have 177 missing age values (891-714), which
    is nearly 20% of the data. To fill in the data, we could either go back to the
    history books, find each person one by one, and fill in their age, or we could
    fill in the age with a placeholder value.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 删除这一行是一个简单的选择；然而，你有可能丢失宝贵的数据！例如，在这个案例中，我们有177个缺失的年龄值（891-714），这几乎占了数据的20%。为了填补这些数据，我们可以回去查找历史记录，逐个找出每个人并填写他们的年龄，或者我们可以用占位符值来填充这些年龄。
- en: 'Let’s fill in each missing value of the `Age` column with the overall average
    age of the people in the dataset. For this, we will use two new methods, called
    `mean` and `fillna`. We use `isnull` to tell us which values are `null` and the
    `mean` function to give us the average value of the `Age` column. The `fillna`
    method is a `pandas` method that replaces null values with a given value:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用数据集中的所有人的平均年龄来填补`Age`列中的每个缺失值。为此，我们将使用两个新方法，分别是`mean`和`fillna`。我们使用`isnull`来告诉我们哪些值是`null`，而`mean`函数则为我们提供`Age`列的平均值。`fillna`方法是`pandas`中的一个方法，它用给定的值替换空值：
- en: '[PRE27]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We’re done! We have replaced each value with `26.69`, the average age in the
    dataset. The following code now confirms that no null values exist:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 完成了！我们已将每个缺失值替换为`26.69`，即数据集中的平均年龄。以下代码现在确认没有任何空值：
- en: '[PRE28]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Great! Nothing is missing, and we did not have to remove any rows. Let’s check
    back in with our data by looking at `head` again:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！没有缺失值，并且我们没有删除任何行。让我们再检查一下数据，看看`head`的结果：
- en: '[PRE29]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![Figure 3.5 – The first five rows of our Titanic dataset](img/B19488_03_05.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.5 – 我们的泰坦尼克号数据集的前五行](img/B19488_03_05.jpg)'
- en: Figure 3.5 – The first five rows of our Titanic dataset
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5 – 我们的泰坦尼克号数据集的前五行
- en: 'At this point, we could start getting a bit more complicated with our questions—for
    example, *What is the average age for a female or a male?* To answer this, we
    can filter by each gender and take the mean age; `pandas` has a built-in function
    for this, called `groupby`, as illustrated here:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以开始提出更复杂的问题——例如，*女性或男性的平均年龄是多少？* 为了回答这个问题，我们可以按性别进行筛选并计算平均年龄；`pandas`有一个内置的函数，叫做`groupby`，如下所示：
- en: '[PRE30]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This means the following: group the data by the `Sex` column, and then give
    me the mean age for each group. This gives us the following output:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着：按`Sex`列对数据进行分组，然后给我每个组的平均年龄。这将给出如下输出：
- en: '[PRE31]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We will ask more of these difficult and complex questions and will be able to
    answer them with Python and statistics.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将提出更多这些困难且复杂的问题，并能够通过Python和统计学来回答它们。
- en: Summary
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Exploring the data is only one of the essential steps in the data science process,
    and it is something that we will continue to do throughout this book as we work
    with different datasets. By following the steps of data exploration, we can transform,
    break down, and standardize our data to prepare it for modeling and analysis.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 探索数据只是数据科学过程中必不可少的步骤之一，在本书中，当我们处理不同的数据集时，我们将持续进行数据探索。通过遵循数据探索的步骤，我们可以转化、分解并标准化我们的数据，以便为建模和分析做好准备。
- en: Our five steps serve as a standard practice for data scientists and can be applied
    to any dataset that requires analysis. While they are only guidelines, they provide
    a framework for exploring and understanding new data, and they can help us to
    identify trends, relationships, and insights that can inform our analysis.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的五个步骤作为数据科学家的标准实践，可以应用于任何需要分析的数据集。虽然它们只是指导方针，但它们提供了一个探索和理解新数据的框架，帮助我们识别趋势、关系和洞察，从而为我们的分析提供参考。
- en: As we progress in this book, we will delve into the use of statistical, probabilistic,
    and ML models to analyze and make predictions from data. Before we can fully delve
    into these more complex models, however, it is important to review some of the
    basic mathematics that underlie these techniques. In the next chapter, we will
    cover some of the math that is necessary to perform some of the more complicated
    operations in modeling. Don’t worry—the math required for this process is minimal,
    and we will go through it step by step to ensure that you have a solid foundation.
    By understanding the underlying math, we can better understand the models and
    techniques that we will be using, and we can more effectively apply them to our
    data analysis
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们在本书中的进展，我们将深入探讨使用统计、概率和机器学习模型来分析数据并做出预测。然而，在我们能够完全深入这些更复杂的模型之前，回顾一些支撑这些技术的基础数学知识是非常重要的。在下一章中，我们将介绍一些进行更复杂建模操作所必需的数学知识。别担心——这个过程所需的数学是最基础的，我们会一步步讲解，确保你打下坚实的基础。通过理解这些基础数学，我们可以更好地理解我们将使用的模型和技术，也能更有效地将它们应用于数据分析中。
