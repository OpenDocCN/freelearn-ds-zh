- en: Chapter 2. Building Batch and Streaming Apps with Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章. 使用Spark构建批处理和流式应用程序
- en: The objective of the book is to teach you about PySpark and the PyData libraries
    by building an app that analyzes the Spark community's interactions on social
    networks. We will gather information on Apache Spark from GitHub, check the relevant
    tweets on Twitter, and get a feel for the buzz around Spark in the broader open
    source software communities using **Meetup**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是通过构建一个分析社交网络上Spark社区互动的应用程序来向您介绍PySpark和PyData库。我们将从GitHub收集有关Apache Spark的信息，检查Twitter上的相关推文，并使用**Meetup**来感受更广泛的开源软件社区中Spark的热潮。
- en: In this chapter, we will outline the various sources of data and information.
    We will get an understanding of their structure. We will outline the data processing
    pipeline, from collection to batch and streaming processing.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将概述各种数据和信息来源。我们将了解它们的结构。我们将概述数据处理管道，从收集到批处理和流处理。
- en: 'In this section, we will cover the following points:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将涵盖以下内容：
- en: Outline data processing pipelines from collection to batch and stream processing,
    effectively depicting the architecture of the app we are planning to build.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从收集到批处理和流处理概述数据处理管道，有效地描绘我们计划构建的应用程序的架构。
- en: Check out the various data sources (GitHub, Twitter, and Meetup), their data
    structure (JSON, structured information, unstructured text, geo-location, time
    series data, and so on), and their complexities. We also discuss the tools to
    connect to three different APIs, so you can build your own data mashups. The book
    will focus on Twitter in the following chapters.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查各种数据源（GitHub、Twitter和Meetup），它们的数据结构（JSON、结构化信息、非结构化文本、地理位置、时间序列数据等），以及它们的复杂性。我们还讨论了连接到三个不同API的工具，以便您可以构建自己的数据混合。本书将在以下章节中专注于Twitter。
- en: Architecting data-intensive apps
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建数据密集型应用程序的架构
- en: 'We defined the data-intensive app framework architecture blueprint in the previous
    chapter. Let''s put back in context the various software components we are going
    to use throughout the book in our original framework. Here''s an illustration
    of the various components of software mapped in the data-intensive architecture
    framework:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章中定义了数据密集型应用框架架构蓝图。现在，让我们将本书中将要使用的各种软件组件放回到我们的原始框架中。以下是数据密集型架构框架中映射的软件各种组件的示意图：
- en: '![Architecting data-intensive apps](img/B03986_02_01.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![构建数据密集型应用程序的架构](img/B03986_02_01.jpg)'
- en: Spark is an extremely efficient, distributed computing framework. In order to
    exploit its full power, we need to architect our solution accordingly. For performance
    reasons, the overall solution needs to also be aware of its usage in terms of
    CPU, storage, and network.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Spark是一个极其高效的分布式计算框架。为了充分利用其全部功能，我们需要相应地构建我们的解决方案。出于性能原因，整体解决方案还需要了解其在CPU、存储和网络方面的使用情况。
- en: 'These imperatives drive the architecture of our solution:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些必要性驱动着我们解决方案的架构：
- en: '**Latency**: This architecture combines slow and fast processing. Slow processing
    is done on historical data in batch mode. This is also called data at rest. This
    phase builds precomputed models and data patterns that will be used by the fast
    processing arm once live continuous data is fed into the system. Fast processing
    of data or real-time analysis of streaming data refers to data in motion. Data
    at rest is essentially processing data in batch mode with a longer latency. Data
    in motion refers to the streaming computation of data ingested in real time.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟**：此架构结合了慢速和快速处理。慢速处理在批处理模式下对历史数据进行。这也被称为静态数据。此阶段构建的预计算模型和数据模式将在实时连续数据输入系统后由快速处理臂使用。数据处理或流数据的实时分析指的是运动中的数据。静态数据基本上是以较长的延迟在批处理模式下处理的数据。运动中的数据指的是实时摄入数据的流计算。'
- en: '**Scalability**: Spark is natively linearly scalable through its distributed
    in-memory computing framework. Databases and data stores interacting with Spark
    need to be also able to scale linearly as data volume grows.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：Spark通过其分布式内存计算框架原生动地线性可扩展。与Spark交互的数据库和数据存储也需要能够随着数据量的增长而线性扩展。'
- en: '**Fault tolerance**: When a failure occurs due to hardware, software, or network
    reasons, the architecture should be resilient enough and provide availability
    at all times.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容错性**：当由于硬件、软件或网络原因发生故障时，架构应该足够弹性，并始终提供可用性。'
- en: '**Flexibility**: The data pipelines put in place in this architecture can be
    adapted and retrofitted very quickly depending on the use case.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性**：在这个架构中实施的数据管道可以根据用例快速适应和改造。'
- en: Spark is unique as it allows batch processing and streaming analytics on the
    same unified platform.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 独特之处在于它允许在同一统一平台上进行批量处理和流式分析。
- en: 'We will consider two data processing pipelines:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将考虑两个数据处理管道：
- en: The first one handles data at rest and is focused on putting together the pipeline
    for batch analysis of the data
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个处理静态数据，专注于构建数据的批量分析管道
- en: The second one, data in motion, targets real-time data ingestion and delivering
    insights based on precomputed models and data patterns
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个是动态数据，它针对实时数据摄取，并基于预计算模型和数据模式提供洞察
- en: Processing data at rest
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 静态数据处理
- en: Let's get an understanding of the data at rest or batch processing pipeline.
    The objective in this pipeline is to ingest the various datasets from Twitter,
    GitHub, and Meetup; prepare the data for Spark MLlib, the machine learning engine;
    and derive the base models that will be applied for insight generation in batch
    mode or in real time.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解静态数据或批量处理管道。在这个管道中的目标是摄取来自 Twitter、GitHub 和 Meetup 的各种数据集；为 Spark MLlib
    机器学习引擎准备数据；并推导出将在批量模式或实时模式下应用的基本模型，以生成洞察。
- en: 'The following diagram illustrates the data pipeline in order to enable processing
    data at rest:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了数据管道，以实现静态数据的处理：
- en: '![Processing data at rest](img/B03986_02_02.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![静态数据处理](img/B03986_02_02.jpg)'
- en: Processing data in motion
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动态数据处理
- en: Processing data in motion introduces a new level of complexity, as we are introducing
    a new possibility of failure. If we want to scale, we need to consider bringing
    in distributed message queue systems such as Kafka. We will dedicate a subsequent
    chapter to understanding streaming analytics.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 动态数据处理引入了新的复杂性级别，因为我们引入了新的失败可能性。如果我们想要扩展，我们需要考虑引入分布式消息队列系统，如 Kafka。我们将在下一章中专门讨论理解流式分析。
- en: 'The following diagram depicts a data pipeline for processing data in motion:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了处理动态数据的管道：
- en: '![Processing data in motion](img/B03986_02_03.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![动态数据处理](img/B03986_02_03.jpg)'
- en: Exploring data interactively
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交互式探索数据
- en: Building a data-intensive app is not as straightforward as exposing a database
    to a web interface. During the setup of both the data at rest and data in motion
    processing, we will capitalize on Spark's ability to analyse data interactively
    and refine the data richness and quality required for the machine learning and
    streaming activities. Here, we will go through an iterative cycle of data collection,
    refinement, and investigation in order to get to the dataset of interest for our
    apps.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个数据密集型应用并不像将数据库暴露给网络界面那样简单。在设置静态数据和动态数据处理的过程中，我们将利用 Spark 分析数据交互式的能力，以及优化机器学习和流式活动所需的数据丰富性和质量。在这里，我们将通过数据收集、精炼和调查的迭代周期，以获取我们应用感兴趣的数据集。
- en: Connecting to social networks
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接到社交网络
- en: 'Let''s delve into the first steps of the data-intensive app architecture''s
    integration layer. We are going to focus on harvesting the data, ensuring its
    integrity and preparing for batch and streaming data processing by Spark at the
    next stage. This phase is described in the five process steps: *connect*, *correct*,
    *collect*, *compose*, and *consume*. These are iterative steps of data exploration
    that will get us acquainted with the data and help us refine the data structure
    for further processing.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解数据密集型应用架构集成层的第一步。我们将专注于收集数据，确保其完整性，并为 Spark 在下一阶段进行批量和流式数据处理做准备。这一阶段在以下五个处理步骤中描述：*连接*、*纠正*、*收集*、*组合*和*消费*。这些是数据探索的迭代步骤，将使我们熟悉数据，并帮助我们优化数据结构以进行进一步处理。
- en: 'The following diagram depicts the iterative process of data acquisition and
    refinement for consumption:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了数据获取和精炼的迭代过程，以便进行消费：
- en: '![Connecting to social networks](img/B03986_02_04.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![连接到社交网络](img/B03986_02_04.jpg)'
- en: 'We connect to the social networks of interest: Twitter, GitHub, and Meetup.
    We will discuss the mode of access to the **APIs** (short for **Application Programming
    Interface**) and how to create a RESTful connection with those services while
    respecting the rate limitation imposed by the social networks. **REST** (short
    for **Representation State Transfer**) is the most widely adopted architectural
    style on the Internet in order to enable scalable web services. It relies on exchanging
    messages predominantly in **JSON** (short for **JavaScript Object Notation**).
    RESTful APIs and web services implement the four most prevalent verbs `GET`, `PUT`,
    `POST`, and `DELETE`. `GET` is used to retrieve an element or a collection from
    a given `URI`. `PUT` updates a collection with a new one. `POST` allows the creation
    of a new entry, while `DELETE` eliminates a collection.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将连接到感兴趣的社交网络：Twitter、GitHub 和 Meetup。我们将讨论访问 **API**（即 **应用程序编程接口**）的方式，以及如何在遵守社交网络施加的速率限制的同时，与这些服务建立
    RESTful 连接。**REST**（即 **表示状态转移**）是互联网上最广泛采用的架构风格，旨在实现可扩展的 Web 服务。它依赖于主要在 **JSON**（即
    **JavaScript 对象表示法**）中交换消息。RESTful API 和 Web 服务实现了四个最常用的动词 `GET`、`PUT`、`POST`
    和 `DELETE`。`GET` 用于从给定的 `URI` 中检索元素或集合。`PUT` 更新集合为新集合。`POST` 允许创建新条目，而 `DELETE`
    则删除集合。
- en: Getting Twitter data
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取 Twitter 数据
- en: Twitter allows access to registered users to its search and streaming tweet
    services under an authorization protocol called OAuth that allows API applications
    to securely act on a user's behalf. In order to create the connection, the first
    step is to create an application with Twitter at [https://apps.twitter.com/app/new](https://apps.twitter.com/app/new).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter 允许在 OAuth 授权协议下访问其搜索和流推文服务，OAuth 允许 API 应用程序代表用户安全地执行操作。为了创建连接，第一步是在
    Twitter 上创建一个应用程序，网址为 [https://apps.twitter.com/app/new](https://apps.twitter.com/app/new)。
- en: '![Getting Twitter data](img/B03986_02_05.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![获取 Twitter 数据](img/B03986_02_05.jpg)'
- en: 'Once the application has been created, Twitter will issue the four codes that
    will allow it to tap into the Twitter hose:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦应用程序创建完成，Twitter 将会发放四个代码，允许它接入 Twitter 流。
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you wish to get a feel for the various RESTful queries offered, you can
    explore the Twitter API on the dev console at [https://dev.twitter.com/rest/tools/console](https://dev.twitter.com/rest/tools/console):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解提供的各种 RESTful 查询，您可以在 [https://dev.twitter.com/rest/tools/console](https://dev.twitter.com/rest/tools/console)
    的开发者控制台中探索 Twitter API。
- en: '![Getting Twitter data](img/B03986_02_06.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![获取 Twitter 数据](img/B03986_02_06.jpg)'
- en: We will make a programmatic connection on Twitter using the following code,
    which will activate our OAuth access and allows us to tap into the Twitter API
    under the rate limitation. In the streaming mode, the limitation is for a GET
    request.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下代码在 Twitter 上建立程序连接，这将激活我们的 OAuth 访问权限，并允许我们在速率限制下接入 Twitter API。在流模式中，限制是针对
    GET 请求的。
- en: Getting GitHub data
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取 GitHub 数据
- en: 'GitHub uses a similar authentication process to Twitter. Head to the developer
    site and retrieve your credentials after duly registering with GitHub at [https://developer.github.com/v3/](https://developer.github.com/v3/):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub 使用与 Twitter 类似的认证过程。前往开发者网站，在 GitHub 上注册后获取您的凭证，注册地址为 [https://developer.github.com/v3/](https://developer.github.com/v3/)：
- en: '![Getting GitHub data](img/B03986_02_07.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![获取 GitHub 数据](img/B03986_02_07.jpg)'
- en: Getting Meetup data
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取 Meetup 数据
- en: 'Meetup can be accessed using the token issued in the developer resources to
    members of Meetup.com. The necessary token or OAuth credential for Meetup API
    access can be obtained on their developer''s website at [https://secure.meetup.com/meetup_api](https://secure.meetup.com/meetup_api):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Meetup 可以通过 Meetup.com 开发者资源中发放的令牌访问。获取 Meetup API 访问所需的令牌或 OAuth 凭证，可以在他们的开发者网站上找到，网址为
    [https://secure.meetup.com/meetup_api](https://secure.meetup.com/meetup_api)：
- en: '![Getting Meetup data](img/B03986_02_08.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![获取 Meetup 数据](img/B03986_02_08.jpg)'
- en: Analyzing the data
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析数据
- en: Let's get a first feel for the data extracted from each of the social networks
    and get an understanding of the data structure from each these sources.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先感受一下从每个社交网络中提取的数据，并了解这些来源的数据结构。
- en: Discovering the anatomy of tweets
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索推文的解剖结构
- en: 'In this section, we are going to establish connection with the Twitter API.
    Twitter offers two connection modes: the REST API, which allows us to search historical
    tweets for a given search term or hashtag, and the streaming API, which delivers
    real-time tweets under the rate limit in place.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将与 Twitter API 建立连接。Twitter 提供两种连接模式：REST API，允许我们搜索给定搜索词或标签的历史推文，以及流式
    API，在现有速率限制下提供实时推文。
- en: 'In order to get a better understanding of how to operate with the Twitter API,
    we will go through the following steps:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解如何操作 Twitter API，我们将进行以下步骤：
- en: Install the Twitter Python library.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Twitter Python 库。
- en: Establish a connection programmatically via OAuth, the authentication required
    for Twitter.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 OAuth 以编程方式建立连接，这是 Twitter 所需的认证。
- en: Search for recent tweets for the query *Apache Spark* and explore the results
    obtained.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索查询词 *Apache Spark* 的最近推文并探索获得的结果。
- en: Decide on the key attributes of interest and retrieve the information from the
    JSON output.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定感兴趣的关键属性并从 JSON 输出中检索信息。
- en: 'Let''s go through it step-by-step:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步来：
- en: 'Install the Python Twitter library. In order to install it, you need to write
    `pip install twitter` from the command line:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Python Twitter 库。为了安装它，您需要从命令行写入 `pip install twitter`：
- en: '[PRE1]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create the Python Twitter API class and its base methods for authentication,
    searching, and parsing the results. `self.auth` gets the credentials from Twitter.
    It then creates a registered API as `self.api`. We have implemented two methods:
    the first one to search Twitter with a given query and the second one to parse
    the output to retrieve relevant information such as the tweet ID, the tweet text,
    and the tweet author. The code is as follows:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Python Twitter API 类及其用于认证、搜索和解析结果的基类方法。`self.auth` 从 Twitter 获取凭证。然后创建一个注册的
    API 作为 `self.api`。我们实现了两个方法：第一个是使用给定的查询搜索 Twitter，第二个是解析输出以检索相关信息，如推文 ID、推文文本和推文作者。代码如下：
- en: '[PRE2]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Instantiate the class with the required authentication:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用所需的认证实例化类：
- en: '[PRE3]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Run a search on the query term *Apache Spark*:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对查询词 *Apache Spark* 进行搜索：
- en: '[PRE4]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Analyze the JSON output:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析 JSON 输出：
- en: '[PRE5]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Parse the Twitter output to retrieve key information of interest:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解析 Twitter 输出以检索感兴趣的关键信息：
- en: '[PRE6]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Exploring the GitHub world
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 GitHub 世界
- en: 'In order to get a better understanding on how to operate with the GitHub API,
    we will go through the following steps:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解如何操作 GitHub API，我们将进行以下步骤：
- en: Install the GitHub Python library.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 GitHub Python 库。
- en: Access the API by using the token provided when we registered in the developer
    website.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过我们在开发者网站上注册时提供的令牌访问 API。
- en: Retrieve some key facts on the Apache foundation that is hosting the spark repository.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索托管 spark 仓库的 Apache 基金会的相关关键事实。
- en: 'Let''s go through the process step-by-step:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步来：
- en: 'Install the Python PyGithub library. In order to install it, you need to `pip
    install PyGithub` from the command line:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Python PyGithub 库。为了安装它，您需要从命令行运行 `pip install PyGithub`：
- en: '[PRE7]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Programmatically create a client to instantiate the GitHub API:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以编程方式创建客户端以实例化 GitHub API：
- en: '[PRE8]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Retrieve key facts from the Apache User. There are 640 active Apache repositories
    in GitHub:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Apache 用户中检索关键事实。GitHub 上有 640 个活跃的 Apache 仓库：
- en: '[PRE9]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Retrieve key facts from the Spark repository, The programing languages used
    in the Spark repo are given here under:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Spark 仓库中检索关键事实，Spark 仓库中使用的编程语言如下所示：
- en: '[PRE10]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Retrieve a few key participants of the wide Spark GitHub repository network.
    There are 3,738 stargazers in the Apache Spark repository at the time of writing.
    The network is immense. The first stargazer is *Matei Zaharia*, the cofounder
    of the Spark project when he was doing his PhD in Berkeley.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取 Spark GitHub 仓库网络的一些关键参与者。在撰写本文时，Apache Spark 仓库有 3,738 个 star。网络非常庞大。第一个
    star 是 *Matei Zaharia*，当时他在伯克利大学攻读博士学位时是 Spark 项目的共同创始人。
- en: '[PRE11]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Understanding the community through Meetup
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过 Meetup 了解社区
- en: 'In order to get a better understanding of how to operate with the Meetup API,
    we will go through the following steps:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解如何操作 Meetup API，我们将进行以下步骤：
- en: Create a Python program to call the Meetup API using an authentication token.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 Python 程序，使用认证令牌调用 Meetup API。
- en: Retrieve information of past events for meetup groups such as *London Data Science*.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索类似 *London Data Science* 的 Meetup 群组过去活动的信息。
- en: Retrieve the profile of the meetup members in order to analyze their participation
    in similar meetup groups.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索Meetup成员的资料，以便分析他们在类似Meetup群组中的参与情况。
- en: 'Let''s go through the process step-by-step:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步地通过这个过程：
- en: 'As there is no reliable Meetup API Python library, we will programmatically
    create a client to instantiate the Meetup API:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于没有可靠的Meetup API Python库，我们将程序化创建一个客户端来实例化Meetup API：
- en: '[PRE12]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, we will retrieve past events from a given Meetup group:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将从给定的Meetup群组中检索过去的事件：
- en: '[PRE13]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Get information about the Meetup members:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取Meetup成员的信息：
- en: '[PRE14]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Previewing our app
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预览我们的应用程序
- en: 'Our challenge is to make sense of the data retrieved from these social networks,
    finding the key relationships and deriving insights. Some of the elements of interest
    are as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的挑战是从这些社交网络中提取数据，找到关键关系并得出见解。以下是一些感兴趣的元素：
- en: 'Visualizing the top influencers: Discover the top influencers in the community:'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化顶级影响者：发现社区中的顶级影响者：
- en: Heavy Twitter users on *Apache Spark*
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高频Twitter用户在*Apache Spark*上
- en: Committers in GitHub
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub的提交者
- en: Leading Meetup presentations
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领先的Meetup演讲
- en: 'Understanding the Network: Network graph of GitHub committers, watchers, and
    stargazers'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解网络：GitHub提交者、观察者和星标者的网络图
- en: 'Identifying the Hot Locations: Locating the most active location for Spark'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定热点位置：定位Spark最活跃的位置
- en: 'The following screenshot provides a preview of our app:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图提供了我们应用程序的预览：
- en: '![Previewing our app](img/B03986_02_09.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![预览我们的应用程序](img/B03986_02_09.jpg)'
- en: Summary
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we laid out the overall architecture of our app. We explained
    the two main paradigms of processing data: batch processing, also called data
    at rest, and streaming analytics, referred to as data in motion. We proceeded
    to establish connections to three social networks of interest: Twitter, GitHub,
    and Meetup. We sampled the data and provided a preview of what we are aiming to
    build. The remainder of the book will focus on the Twitter dataset. We provided
    here the tools and API to access three social networks, so you can at a later
    stage create your own data mashups. We are now ready to investigate the data collected,
    which will be the topic of the next chapter.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们概述了我们的应用程序的整体架构。我们解释了处理数据的主要范式：批处理，也称为静态数据，以及流分析，称为动态数据。我们继续建立与三个感兴趣的社会网络的连接：Twitter、GitHub和Meetup。我们采样了数据，并提供了我们旨在构建的预览。本书的其余部分将专注于Twitter数据集。我们提供了访问三个社交网络的工具和API，以便您可以在以后阶段创建自己的数据混合。我们现在准备调查收集到的数据，这将是下一章的主题。
- en: In the next chapter, we will delve deeper into data analysis, extracting the
    key attributes of interest for our purposes and managing the storage of the information
    for batch and stream processing.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更深入地探讨数据分析，提取我们目的的关键属性，并管理批处理和流处理的信息存储。
