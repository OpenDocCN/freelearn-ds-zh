- en: Boosting your Database
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升你的数据库
- en: In this chapter, we will explain what statistical boosting is, how it works,
    and introduce the notion of using statistical boosting to better understand data
    in a database.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将解释什么是统计提升，它如何运作，并介绍如何利用统计提升更好地理解数据库中的数据。
- en: 'We have again broken the subjects in this chapter down into the following important
    areas for clarity:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将本章的主题分解为以下重要领域以便更清晰：
- en: Definition and purpose of statistical boosting
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计提升的定义与目的
- en: What you can learn from boosting (to help) your database
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以从提升（帮助）你的数据库中学到什么
- en: Using R to illustrate boosting methods
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用R来说明提升方法
- en: Definition and purpose
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义与目的
- en: 'First, we can consider a common definition you may find online:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以考虑一个你可能在网上找到的常见定义：
- en: Boosting is a machine learning ensemble meta-algorithm for primarily reducing
    bias, and also variance in supervised learning, and a family of machine learning
    algorithms which convert weak learners to strong ones.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 提升是一种机器学习集成元算法，主要用于减少偏差，同时也减少监督学习中的方差，是一类将弱学习器转化为强学习器的机器学习算法。
- en: -Wikipedia
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: -维基百科
- en: '[https://en.wikipedia.org/wiki/Boosting_(machine_learning)](https://en.wikipedia.org/wiki/Boosting_(machine_learning))'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://en.wikipedia.org/wiki/Boosting_(machine_learning)](https://en.wikipedia.org/wiki/Boosting_(machine_learning))'
- en: 'Reminder: In statistics, ensemble methods use multiple learning algorithms
    to obtain better predictive performance than could be obtained from any of the
    fundamental or basic learning algorithms (although results vary by data and data
    model).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒：在统计学中，集成方法使用多个学习算法，目的是获得比任何基础学习算法更好的预测性能（尽管结果因数据和数据模型而异）。
- en: Before we head into the details behind statistical boosting, it is imperative
    that we take some time here to first understand bias, variance, noise, and what
    is meant by a weak learner, and a strong learner.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解统计学提升的细节之前，首先必须花些时间理解偏差、方差、噪声，以及什么是弱学习器和强学习器。
- en: The following sections will cover these terms and related concepts.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的章节将涵盖这些术语和相关概念。
- en: Bias
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差
- en: Let's start out with a discussion on the statistical bias.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从讨论统计偏差开始。
- en: A statistic is biased if it is calculated in such a way that it is analytically
    dissimilar to the population parameter being estimated.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果统计量的计算方式使其在分析上与被估计的总体参数不相似，那么该统计量就存在偏差。
- en: One of the best explanations for bias that I've come across is the concept of
    a scale that is off zero by a small amount. In this scenario, the scale will give
    slightly over-estimated results. In other words, when someone steps on the scale,
    the total weight may be over or understated (which might make that person conclude
    that the diet they are on is working better than it really is).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我遇到过的关于偏差的最佳解释是一个偏离零的小刻度的概念。在这种情况下，刻度会给出略微高估的结果。换句话说，当某人站上秤时，总体体重可能被高估或低估（这可能让那个人觉得他们的饮食比实际效果更好）。
- en: In statistics, data scientists need to recognize that there are actually several
    categories that are routinely used to define statistical bias. The next section
    lists these categories of bias along with examples.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，数据科学家需要认识到，实际上有多个常用的类别来定义统计偏差。下一节将列出这些偏差类别并提供示例。
- en: Categorizing bias is somewhat subjective since some of the categories will seem
    to overlap.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差的分类有些主观，因为某些类别可能会有重叠的情况。
- en: Categorizing bias
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差的分类
- en: 'There are many categories of bias, including the following specific examples:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差有许多类别，包括以下具体示例：
- en: '**Selection bias**: This is when individual observations are more likely to
    be selected for study than others.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择偏差**：指的是某些个体观察值比其他观察值更可能被选中进行研究。'
- en: '**Spectrum bias**: This occurs when data scientists evaluate results on biased
    samples, leading to an overestimate of the sensitivity and specificity of the
    test(s).'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**谱偏差**：当数据科学家在偏倚的样本上评估结果时，导致对测试的敏感性和特异性估计过高。'
- en: '**Estimator bias**: This is the difference between an estimator''s expected
    value and the true value of the parameter being estimated.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**估计器偏差**：指的是估计器的期望值与被估计参数的真实值之间的差异。'
- en: '**Omitted-variable bias**: This bias will occur in estimating the parameters
    in a regression analysis when the assumed specification neglects an independent
    variable.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遗漏变量偏差**：在回归分析中估计参数时，如果假设的模型忽略了某个自变量，就会出现这种偏差。'
- en: '**Detection bias**: This occurs when a character or event is more likely to
    be observed for a particular set of study subjects.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检测偏差**：当某个特征或事件在特定研究对象组中更容易被观察到时，就会发生这种偏差。'
- en: '**Sampling bias**: This bias occurs when a statistical error is imposed due
    to an error in the sampling data.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**抽样偏差**：当由于抽样数据的错误而导致统计误差时，就会发生这种偏差。'
- en: '**Measurement bias**: This occurs then there is a systematic problem with test
    content, testing administration, and/or scoring procedures.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测量偏差**：当测试内容、测试管理和/或评分程序存在系统性问题时，就会发生这种偏差。'
- en: '**Funding bias**: This type of bias can lead to a selection of specific outcomes,
    observations, test samples, or test procedures that favor a study''s financial
    sponsor.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资金偏差**：这种类型的偏差可能导致选择特定的结果、观察、测试样本或测试程序，这些都偏向于研究的资金赞助者。'
- en: '**Reporting bias**: Bias of this type involves askew in the availability of
    data, which causes observations of a certain type or collection to be more likely
    to be reported as a result or to affect performance.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**报告偏差**：这种类型的偏差涉及数据可用性的偏差，这导致某种类型或集合的观察结果更有可能被报告为结果，或影响表现。'
- en: '**Analytical bias**: This occurs based on the method or process used to evaluate
    the results of certain observations or the performance of a statistical model
    as a whole.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分析偏差**：这种偏差发生在用于评估某些观察结果或统计模型整体表现的方法或过程上。'
- en: '**Exclusion bias**: This category of bias may arise based upon a process or
    procedure that has the potential to systematically exclude certain samples or
    observations from a statistical study.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**排除偏差**：这种偏差类别可能由于某个过程或程序而产生，该过程或程序有可能系统性地排除某些样本或观察结果，导致统计研究中的样本或观察缺失。'
- en: '**Attrition bias**: When participants in a study or statistical project leave
    the program or process. In other words, a group or category of a project may leave
    or be removed and will no longer be considered by data scientists.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**脱落偏差**：当研究或统计项目中的参与者离开程序或过程时。换句话说，一个项目的某个组或类别可能会离开或被移除，并且不再被数据科学家考虑。'
- en: '**Recall bias**: When the accuracy or completeness of a study''s participants
    does not align due to misrecollections of past events or characteristics of what
    is being studied. This results in an over-estimation or under-estimation of the
    results.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回忆偏差**：当研究参与者的准确性或完整性由于对过去事件或研究对象特征的错误记忆而不一致时。这会导致结果的高估或低估。'
- en: '**Observer bias**: This type of bias occurs when the researcher subconsciously
    influences the data due to cognitive bias, where judgment may alter how an observation
    or study is carried out/how results are recorded.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**观察者偏差**：这种偏差发生在研究人员由于认知偏差无意识地影响数据时，判断可能会改变观察或研究的进行方式/结果的记录方式。'
- en: '**Confounding bias**: This type of bias occurs when factors affecting the same
    information in a study are misleading or otherwise confusing to the researcher
    or data scientist.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混杂偏差**：当影响研究中相同信息的因素使研究者或数据科学家感到误导或困惑时，就会发生这种偏差。'
- en: '**Negativity bias**: This occurs when a data scientist is inclined to give
    more weight or value to negative characteristics, events, or outcomes, just because
    they are negative.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负面偏差**：当数据科学家倾向于对负面的特征、事件或结果赋予更多的权重或价值，仅仅因为它们是负面的时，就会发生这种情况。'
- en: '**Representative bias**: This occurs when data scientists take something for
    granted based upon certain observed characteristics identified within a group
    or certain observations.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代表性偏差**：当数据科学家根据群体中识别出的某些观察特征将某些事情视为理所当然时，就会发生这种偏差。'
- en: '**Recency bias**: This category of bias occurs when the recent experiences
    and observations of a data scientist are used (or are given more value) to predict
    future outcomes.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**近期偏差**：这种偏差类别发生在数据科学家使用最近的经验和观察（或赋予更多的价值）来预测未来结果时。'
- en: 'And one of my favorite types:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 而我最喜欢的其中一种类型是：
- en: '**Data-snooping bias**: This happens when the data scientist forms an incorrect
    opinion or makes a hypothesis, then proceeds to mine data that is especially in
    defense of that notion.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据窥探偏差**：当数据科学家形成错误的意见或提出假设，并随后挖掘数据以特别支持该观点时，就会发生这种情况。'
- en: Causes of bias
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差的原因
- en: '*Bias* is a term that you will find is commonly thrown around in the field
    of statistics and, almost always, bias is equivalent to (or with) a negative or
    bad incident. In fact, even beyond the realm of statistics, bias almost always
    results in trouble or some form of distress.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*偏差* 是一个你会在统计学领域常常听到的术语，几乎总是与负面或不良事件相关。事实上，甚至在统计学的领域之外，偏差几乎总是导致麻烦或某种形式的困扰。'
- en: Consider bias as favoritism. Favoritism that is present in the data collection
    process, for example, will typically result in misleading results or incorrect
    assumptions.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将偏差视为偏袒。举例来说，在数据收集过程中存在的偏袒通常会导致误导性结果或错误的假设。
- en: Bias can arise in various ways and, as a data scientist, one must be familiar
    with these occasions. Actually, bias can be introduced to a statistical project
    at any time or phase.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差可以以各种方式出现，作为数据科学家，必须熟悉这些情况。事实上，偏差可以在任何时间或阶段进入统计项目。
- en: One of the most common times that bias is introduced is at the very start or
    beginning of a project when data is collected or selected. This is the worst,
    as almost every effort and all work completed afterwards will be suspect or, most
    likely, incorrect.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 引入偏差最常见的时机之一就是项目一开始的数据收集或选择时。这个时候是最糟糕的，因为几乎所有后续的工作和努力都会受到怀疑，或者很可能是错误的。
- en: Bias data collection
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差数据收集
- en: A major source of bias is the way data is collected. Frankly, researchers who
    are inexperienced, or hoping for a certain result, may use inferior data collection
    methods or practices or actually collect data in ways that expose a particular
    emphasis or lead to an anticipated or expected result.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差的一个主要来源是数据的收集方式。坦率地说，经验不足的研究人员，或者有某种特定结果期望的研究人员，可能会使用低劣的数据收集方法或实践，甚至以一种强调某种特定倾向或导致预期结果的方式收集数据。
- en: 'Some things to look for in data collection methods:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集方法中需要注意的事项：
- en: Surveys that are constructed with a particular slant or emphasis
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有特定倾向或强调的调查
- en: Choosing a known group with a particular background to respond to a survey
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一个已知的、具有特定背景的群体来回答调查
- en: The reporting of data in misleading categorical groupings
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以误导性分类方式报告数据
- en: A non-randomness sample selection
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非随机的样本选择
- en: Systematic measurement errors
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统性测量误差
- en: Bias sample selection
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差样本选择
- en: The process of sample selection or sampling is also subject to the introduction
    of bias. Sample bias occurs when the sample does not accurately represent a population.
    The bias that results from an unrepresentative sample is called **selection bias**.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 样本选择或抽样过程同样容易引入偏差。当样本不能准确代表总体时，就会出现样本偏差。由不具代表性的样本引发的偏差被称为**选择偏差**。
- en: 'Issues that can result in introducing bias to a statistical sample include:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 可能导致在统计样本中引入偏差的问题包括：
- en: The timing of taking the sample
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采样的时机
- en: The length or size of the sample
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本的长度或大小
- en: The level of difficulty of the question
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题的难度级别
- en: Undercoverage (of the population)
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低覆盖率（对于总体）
- en: Nonresponses incorrectly used in a sample
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非回应错误地用于样本中
- en: Voluntary responses incorrectly used within a sample
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自愿回应错误地用于样本中
- en: The manner (in which the subjects in the sample were contacted (phone, mail,
    door-to-door, and so on), or how the observation data was split)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本中被联系的方式（电话、邮件、上门等），或观察数据的划分方式
- en: Enough about bias. Let's move on to the next section, where we will cover statistical
    variance.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差说得够多了。让我们进入下一部分，讨论统计方差。
- en: Variance
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方差
- en: 'In statistical theory ([https://en.wikipedia.org/wiki/Statistics](https://en.wikipedia.org/wiki/Statistics)),
    the concept of variance is defined as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学理论中（[https://en.wikipedia.org/wiki/Statistics](https://en.wikipedia.org/wiki/Statistics)），方差的概念定义如下：
- en: The expectation ([https://en.wikipedia.org/wiki/Expected_value](https://en.wikipedia.org/wiki/Expected_value))
    of the squared deviation of a random variable from its mean or, in other words,
    it is a measurement of just how far a set of random numbers are spread out from
    their average value.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量与其均值的平方偏差的期望值（[https://en.wikipedia.org/wiki/Expected_value](https://en.wikipedia.org/wiki/Expected_value)），换句话说，它是衡量一组随机数相对于其平均值的分散程度。
- en: The practice of the analysis of variance (or simply variance analysis) involves
    a data scientist evaluating the difference between two figures. Typically, this
    process applies financial or operational data in an attempt to identify and determine
    the cause of the variance. In applied statistics, there are different forms of
    variance analysis.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 方差分析的实践（或简称方差分析）涉及数据科学家评估两个数值之间的差异。通常，这一过程应用于财务或运营数据，试图识别并确定方差的原因。在应用统计学中，方差分析有不同的形式。
- en: 'Variance and the analysis of variance is a big topic within the field and study
    of statistics, where it plays a key role in the following statistical practices:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 方差和方差分析是统计学领域中的一个重要话题，它在以下统计实践中发挥着关键作用：
- en: Descriptive statistics ([https://en.wikipedia.org/wiki/Descriptive_statistics](https://en.wikipedia.org/wiki/Descriptive_statistics))
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述性统计 ([https://en.wikipedia.org/wiki/Descriptive_statistics](https://en.wikipedia.org/wiki/Descriptive_statistics))
- en: Goodness of fit ([https://en.wikipedia.org/wiki/Goodness_of_fit](https://en.wikipedia.org/wiki/Goodness_of_fit))
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拟合优度 ([https://en.wikipedia.org/wiki/Goodness_of_fit](https://en.wikipedia.org/wiki/Goodness_of_fit))
- en: Hypothesis testing ([https://en.wikipedia.org/wiki/Statistical_hypothesis_testing](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing))
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设检验 ([https://en.wikipedia.org/wiki/Statistical_hypothesis_testing](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing))
- en: Monte Carlo sampling ([https://en.wikipedia.org/wiki/Monte_Carlo_method](https://en.wikipedia.org/wiki/Monte_Carlo_method))
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蒙特卡罗采样 ([https://en.wikipedia.org/wiki/Monte_Carlo_method](https://en.wikipedia.org/wiki/Monte_Carlo_method))
- en: Statistical inference ([https://en.wikipedia.org/wiki/Statistical_inference](https://en.wikipedia.org/wiki/Statistical_inference))
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计推断 ([https://en.wikipedia.org/wiki/Statistical_inference](https://en.wikipedia.org/wiki/Statistical_inference))
- en: 'You''ll find the following to be true with variance:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现方差分析有以下规律：
- en: Whenever there is a need for the statistical analysis of data, a data scientist
    will more than likely start with the process of variance analysis
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每当需要进行数据的统计分析时，数据科学家很可能会首先进行方差分析。
- en: Statistical variance provides data scientists with a measuring stick to gauge
    how the data distributes itself (about the mean or an expected value)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计方差为数据科学家提供了一个衡量数据如何分布（围绕均值或预期值）的标准。
- en: Unlike range (which only looks at extreme values), variance looks at all the
    data points and concludes their distribution
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与范围（仅看极端值）不同，方差会考虑所有数据点，并得出它们的分布结论。
- en: ANOVA
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方差分析（ANOVA）
- en: As a data scientist, when you are speaking about the process or practice of
    **analysis of variance**, you are speaking of **ANOVA. **ANOVA can be understood
    as an assortment of methods that are used in the investigation of found or potential
    differences (variances) amongst group means and their accompanying procedures.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，当你谈论方差分析的过程或实践时，你实际上是在谈论**ANOVA**。ANOVA可以理解为一系列方法，用于研究群体均值之间发现或潜在的差异（方差）及其相关过程。
- en: 'ANOVA is studied and used in the field of statistics in three distinct styles.
    These styles are determined and defined by the number of independent variables
    a data scientist is working with or interested in:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 方差分析（ANOVA）在统计学领域有三种不同的研究和应用方式。这些方式由数据科学家处理或感兴趣的独立变量的数量来决定和定义：
- en: One-way ANOVA (deals with just one independent variable)
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单因素方差分析（只处理一个独立变量）
- en: Two-way ANOVA (uses or focuses on two independent variables)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 双因素方差分析（使用或关注两个独立变量）
- en: N-way ANOVA (when the data scientist is interested in more than two independent
    variables)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多因素方差分析（当数据科学家感兴趣的不止两个独立变量时）
- en: When a data scientist or researcher conducts an ANOVA, they are endeavoring
    to conclude whether there is a statistically significant difference between groups
    within their population. If they find that there is a difference, they will then
    go on to determine where the group differences are.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家或研究人员进行ANOVA时，他们的目的是判断其群体内部是否存在统计学上显著的差异。如果他们发现存在差异，他们将继续确定这些群体差异的具体位置。
- en: Noise
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 噪声
- en: Noise or, to the data scientist, statistical noise, is the popular expression
    for acknowledged amounts of unexplained variation or variability in a sample,
    population, or data source.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声，或者对数据科学家来说，统计噪声，是指在样本、群体或数据源中公认的无法解释的变化量或变异性。
- en: The actual use of the term *noise* can be traced to early signal processing,
    where it was coined as a way of referring to undesirable (electromagnetic) energy
    that was found to be degrading the quality of signals and data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*噪声*一词的实际应用可以追溯到早期的信号处理，当时它被用来指代那些被发现会降低信号和数据质量的、不希望出现的（电磁）能量。'
- en: To the data or database developer, consider the example of running a simple
    database query to determine the performance of a particular sales region of an
    organization. If your SQL query returns sales for every sales region, one might
    consider the additional sales regions—in the context of this exercise—noise that
    perhaps renders the sales information useless (again, in the context of trying
    to focus on a particular sales region). To resolve this condition, of course,
    one could restructure the query so that it filters out unwanted regions or manipulate
    the results of the query to remove the noise of unwanted regions. Keep in mind,
    in statistics, it may be unrealistic to recreate the data source.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据或数据库开发人员来说，考虑这样一个例子：运行一个简单的数据库查询，来确定某个特定销售区域的业绩。如果你的 SQL 查询返回所有销售区域的销售数据，那么在这个练习的背景下，你可能会把其他的销售区域看作噪声，这些噪声使得销售信息变得无用（再说一次，是在试图关注某个特定销售区域的背景下）。当然，为了解决这个问题，你可以重新构造查询，以过滤掉不需要的区域，或者修改查询结果，以去除不需要区域的噪声。请记住，在统计学中，重建数据源可能不现实。
- en: Noisy data
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 噪声数据
- en: Outside of statistics, people often use the term statistical noise to dismiss
    any data that they aren't interested in. An example of this is a professional
    football team's stadium, where fans cheering interferes with the ability of the
    visiting team to communicate. The noise is an inconvenience.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学之外，人们常常使用“统计噪声”这一术语来抛开他们不感兴趣的数据。一个例子是职业足球队的体育场，球迷的欢呼声干扰了客队的沟通能力。噪声成了不便。
- en: Within statistics though, when a data scientist acknowledges the presence of
    noise within a sample, it means that any results from statistical sampling might
    not be duplicated if the process were repeated. In this case, the sample may become
    noisy data and rendered meaningless because of the existence of too much variation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在统计学中，当数据科学家意识到样本中存在噪声时，意味着任何来自统计抽样的结果，如果重复这个过程，可能无法再现。在这种情况下，样本可能变成噪声数据，并因为过多的变异而变得毫无意义。
- en: The effort of unraveling the noise from the true signal has pretty much always
    been a major emphasis in statistics (so that the meaningful data could be used
    by researchers), however, the percentage of noisy data that is meaningful is often
    too insignificant to be of much use.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 揭示噪声与真实信号之间的关系，几乎一直是统计学中的一个重要议题（以便研究人员能够使用有意义的数据），然而，噪声数据中有意义的数据比例通常太小，以至于难以派上用场。
- en: Over time, the term *noisy data* has grown to also refer to *any data that is
    not machine-readable*, such as unstructured text and even any data altered in
    some way that is no longer compatible with the program used to create it. Happily,
    advances in analytical tools are steadily overcoming these types of statistical
    obstacles (think IBM Watson analytics, but there are many others).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，*噪声数据*这个术语也被用来指代*任何机器无法读取的数据*，例如非结构化文本，甚至是任何在某种程度上被修改，导致不再与创建它的程序兼容的数据。幸运的是，分析工具的进步正在稳步克服这些统计障碍（比如
    IBM Watson 分析工具，当然还有许多其他工具）。
- en: Some of the most commonly accepted examples of statistical noise include Gaussian
    noise, shot noise, and white noise. Enough of this noise about (statistical) noise!
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一些最常见的统计噪声示例包括高斯噪声、散射噪声和白噪声。好了，够了，我们不再谈论（统计）噪声了！
- en: Let's move on to learners.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论学习者。
- en: Weak and strong learners
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弱学习者和强学习者
- en: A nice segue (back) into the topic of boosting is a statistical algorithm or
    model's ability to improve its ability to predict overtime, that is, its performance.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的过渡（回到）提升方法的主题，是统计算法或模型在时间推移中的预测能力的提升，也就是其性能的提高。
- en: If you are reading this book and have reached this section of this chapter,
    the assumption is that you understand the concept of machine learning, as it is
    related to statistical prediction-making. Learning is a computer or model's ability
    to learn (how to make predictions based upon data) without being explicitly programmed.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在阅读这本书，并且已经到达了这一章节的这一部分，那么假设你已经理解了与统计预测相关的机器学习概念。学习是指计算机或模型能够学习（如何根据数据做出预测），而不需要明确的编程指令。
- en: We use the term *explicitly* to mean *hardcoded* selections based upon data
    values.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用术语*显式地*来表示基于数据值的*硬编码*选择。
- en: If you build upon this concept, you can come to understand that a computer or
    model whose intention or objective is to make good predictions (to guess an outcome
    correctly) based upon data will perform or produce results that are somewhere
    between incorrect (bad) and correct (or good).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你基于这一概念进一步思考，你可以理解，计算机或模型的目标是基于数据做出良好预测（正确猜测结果），其表现或结果会介于不正确（差）和正确（好）之间。
- en: One can also then say that the computer or model could perhaps improve its performance
    with more experience (more data) and could improve learning at some rate.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以说，计算机或模型或许能通过更多经验（更多数据）来提高其表现，并且能以某个速率改善学习。
- en: Thus, a data scientist will label a computer or model (the learner) as a weak
    or strong learner, based on its performance (or its ability to predict or guess
    outcomes).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据科学家会根据计算机或模型的表现（或其预测或猜测结果的能力）将其标记为弱学习器或强学习器。
- en: In the field of statistics and data science, one can also refer to a *learner*
    as a classifier or predictor.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学和数据科学领域，人们也可以将*学习器*称为分类器或预测器。
- en: So, what qualifies a learner as weak or strong?
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如何界定一个学习器是弱还是强呢？
- en: A weak learner is one that, no matter what the data looks like (meaning the
    distribution of values within the data the model is being trained on), will always
    perform better than chance when it tries to label the data.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 弱学习器是指无论数据呈现何种形式（意味着模型训练数据中的值分布），在尝试标记数据时，总能比随机猜测表现得更好。
- en: We qualify doing better than chance as always having an error rate which is
    less than half.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将做得比随机猜测好定义为始终具有小于一半的错误率。
- en: Weak to strong
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从弱到强
- en: '*Better than random* *guessing* is fundamentally the one and only prerequisite
    for a weak learner. So, as long as an algorithm or model can consistently beat
    random guessing, applying a boosting algorithm will be able to increase the accuracy
    of the model''s predictions (its performance) and consequently convert the model
    from being a weak learner to a strong learner.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '*比随机* *猜测* 好，基本上是弱学习器的唯一先决条件。因此，只要算法或模型能始终优于随机猜测，应用提升算法将能提高模型预测的准确性（其表现），从而将模型从弱学习器转变为强学习器。'
- en: Take note, data scientists agree that increasing a model's predictive ability
    or performance even to ever so slightly better than random guessing results means
    success.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，数据科学家一致认为，将模型的预测能力或表现提高，即使只是略微优于随机猜测，也意味着成功。
- en: When a data scientist considers the options for improving the performance of
    a model (or converting a weak learner to a strong learner), numerous factors need
    to be considered.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家考虑提升模型表现（或将弱学习器转变为强学习器）时，需要考虑许多因素。
- en: These factors include model bias, processing time, and complexity. Let's explain
    each a little.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这些因素包括模型偏差、处理时间和复杂性。让我们稍微解释一下每一个。
- en: Model bias
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型偏差
- en: We talked about *statistical bias* in an earlier section of this chapter. The
    level of bias identified within a statistical model needs to be considered. Typically,
    the lower the amount of bias, the better, since some methods for improving on
    a weak learner—such as boosting—can overfit, resulting in misleading results.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章的早期部分讨论了*统计偏差*。在统计模型中识别的偏差水平需要被考虑。通常，偏差越小越好，因为一些改善弱学习器的方法——例如提升（boosting）——可能会导致过拟合，从而产生误导性的结果。
- en: Training and prediction time
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和预测时间
- en: Whether or not, the approach for improving a weak learner's performance adds
    significantly to the amount of time a model takes to learn, train, or predict
    on a data subset. Usually, the more you train a model, the better the results,
    so if you are anticipating requiring hundreds of training iterations, you need
    to consider how much longer that effort or process will take if your improvements
    increase the training iteration by 100%.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，提升弱学习器表现的方法是否显著增加了模型学习、训练或在数据子集上预测的时间。通常，训练得越多，结果越好，因此如果你预期需要进行数百次训练迭代，你需要考虑如果改进使训练迭代增加100%，这一过程或努力将需要多长时间。
- en: Complexity
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复杂性
- en: Often, there is an assumption that a weak learner is computationally simple
    in design (it's a weak learner, right?), but that is not always the case. Understanding
    the level of complexity of an algorithm or model before choosing an approach for
    improving performance is critical in the decision-making process.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 通常会假设弱学习者在设计上计算上比较简单（它是一个弱学习者，对吧？），但情况并不总是如此。在选择提升性能的方法之前，理解算法或模型的复杂程度对决策过程至关重要。
- en: Which way?
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哪种方式？
- en: Which way (which approach) a data scientist will go or take to improve a model's
    performance and convert it from a weak learner into a strong learner will ultimately
    depend on many factors, but in the end, the approach taken depends on the individual
    problem.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家为了提升模型性能，将其从弱学习者转变为强学习者，最终选择哪种方式（方法）将取决于许多因素，但归根结底，所采取的方法依赖于具体问题。
- en: AdaBoost (also known as **Adaptive Boosting**) is an iterative algorithm using
    a designated number of iterations or rounds to improve on a weak learner. This
    algorithm starts by training/testing a weak learner on data, weighting each example
    equally. The examples which are misclassified get their weights increased for
    the next round(s), while those that are correctly classified get their weights
    decreased.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: AdaBoost（也称为**自适应提升**）是一个迭代算法，使用指定次数的迭代或回合来提升一个弱学习者。该算法从在数据上训练/测试一个弱学习者开始，为每个示例赋予相等的权重。那些被错误分类的示例，其权重将在下一轮（回合）中增加，而正确分类的示例则会减小其权重。
- en: We will know about AdaBoost later in this chapter.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章稍后了解AdaBoost。
- en: Back to boosting
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回到提升
- en: At this point, we have covered all of the topics most pertinent to boosting,
    so let's now get back to the main event, statistical boosting.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我们已经涵盖了与提升（boosting）最相关的所有话题，现在让我们回到重点，统计提升。
- en: We have already offered a description of what statistical boosting is and what
    it is used for (a learning algorithm intended to reduce bias and variance and
    convert weak learners into strong ones).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经描述了统计提升是什么以及它的用途（即旨在减少偏差和方差，并将弱学习者转变为强学习者的学习算法）。
- en: Key to this concept is the idea of how learners inherently behave, with a weak
    learner defined as one which is only slightly correlated with the true classification
    (it can label examples better than random guessing). In contrast, a strong learner
    is one that is well-correlated with the true classification.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念的关键在于学习者的行为方式，其中弱学习者被定义为与真实分类仅有轻微相关性的学习者（它比随机猜测更能正确标记示例）。相对地，强学习者则是与真实分类有良好相关性的学习者。
- en: How it started
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何开始的
- en: Boosting an algorithm in an attempt to improve performance is, in reality, hypothetical.
    That is, it is a question every data scientist should ask for their statistical
    algorithm or model.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试通过提升算法来提高性能，实际上是一个假设问题。也就是说，这是每个数据科学家都应该问自己在其统计算法或模型中的问题。
- en: This is known in statistics as the hypothesis-boosting question and is all about
    the data scientist finding a way to even slightly improve a learning process (turning
    a weak learner into a strong(er) learner).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这在统计学中被称为假设提升问题，核心是数据科学家寻找一种方法，即使是稍微改进学习过程（将弱学习者转变为更强的学习者）。
- en: The idea of a strong learner only implies a slightly improved learner--actually,
    only slightly better than random guessing.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 强学习者的概念仅仅意味着稍微改进的学习者——实际上，它仅比随机猜测略好。
- en: In the data science or statistics world, the hypothesis-boosting question also
    implies the actual existence of an efficient algorithm that outputs a hypothesis
    of arbitrary accuracy for the problem being solved. These algorithms (that improve
    learners) have quickly become known simply as **boosting**.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学或统计学领域，假设提升问题也暗示着存在一个高效的算法，它能输出一个针对所解决问题的任意准确度的假设。这些（能够改善学习者的）算法迅速被称为**提升**。
- en: As usual, data scientists interchangeably use terms to identify the same thing,
    and boosting is no different, as some data scientists will refer to boosting as
    *resampling* or *combining*.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，数据科学家交替使用不同术语来表示相同的概念，提升也不例外，一些数据科学家会将提升称为*重采样*或*组合*。
- en: AdaBoost
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AdaBoost
- en: Back to our previous mention of a package named **AdaBoost**, which is short
    for **adaptive boosting**. AdaBoost is a boosting approach referred to as an *ensemble
    learning algorithm*. Ensemble learning is when multiple learners are used in conjunction
    with each other to build a stronger learning algorithm.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们之前提到的一个名为**AdaBoost**的包，它是**自适应增强**（adaptive boosting）的缩写。AdaBoost是一种增强方法，通常被称为*集成学习算法*。集成学习是指通过结合多个学习器来构建一个更强大的学习算法。
- en: AdaBoost works by selecting a base algorithm and then iteratively improving
    it by accounting for the incorrectly classified examples in the training dataset.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: AdaBoost的工作原理是选择一个基础算法，然后通过考虑训练数据集中的错误分类样本，迭代地改进它。
- en: 'A wonderful explanation of boosting and AdaBoost can be found online: *Better
    living through AdaBoost* [http://bbacon.org/Better-Living-Through-AdaBoost](http://bbacon.org/Better-Living-Through-AdaBoost).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在线可以找到对增强和AdaBoost的精彩解释：*通过AdaBoost实现更好的生活* [http://bbacon.org/Better-Living-Through-AdaBoost](http://bbacon.org/Better-Living-Through-AdaBoost)。
- en: 'The aforementioned article describes how AdaBoost works:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 上述文章描述了AdaBoost的工作原理：
- en: AdaBoost trains a model on a data subset
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AdaBoost在数据子集上训练一个模型
- en: Weak learners (based upon performance) are weighted
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弱学习器（基于性能）被加权
- en: The process is repeated
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个过程会重复进行
- en: 'In narrative form, the AdaBoost boosting logic can be explained in the following
    way:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 从叙述的角度来看，AdaBoost增强逻辑可以通过以下方式来解释：
- en: 'The process works by building a model on training data and then measuring the
    results'' accuracy on that training data, then:'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该过程通过在训练数据上构建模型，然后衡量结果在训练数据上的准确性，接着：
- en: The individual results that were erroneous in the model are assigned a larger
    weight (or weighted more) than those that were correct, and then the model is
    *retrained* again using these new weights. This logic is then repeated multiple
    times, adjusting the weights of individual observations each time based on whether
    they were correctly classified or not in the last iteration!
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模型中那些错误的个体结果会被赋予更大的权重（或赋予更多的权重），而正确的结果则不会，然后模型会使用这些新的权重进行*再训练*。这个逻辑会重复多次，每次根据上一次迭代中是否正确分类来调整个体观察的权重！
- en: The AdaBoost algorithm was originally offered by *Freund* and *Schapire* in
    the Journal of *Computer and System Sciences* in a 1997 paper titled *A Decision-Theoretic
    Generalization of On-Line Learning and an Application to Boosting*.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: AdaBoost算法最初由*Freund*和*Schapire*在1997年发表于《计算机与系统科学杂志》上的一篇论文中提出，论文标题为*在线学习的决策理论推广及其在增强中的应用*。
- en: What you can learn from boosting (to help) your database
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你可以从增强（以帮助）你的数据库中学到什么
- en: 'Thinking from the perspective or point of view of a database developer, you
    may be trying to conceptualize the process of boosting. As we''ve done throughout
    this book, here, we''ll try to use a database-oriented example to help our understanding
    of boosting:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据库开发者的角度思考，你可能正在尝试构思增强的过程。正如我们在本书中所做的那样，在这里，我们将尝试使用一个*面向数据库的示例*来帮助我们理解增强：
- en: '![](img/afc226d4-457b-4aeb-a77b-10357eac5485.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/afc226d4-457b-4aeb-a77b-10357eac5485.png)'
- en: Our example starts with a relational database. There, effective indexes are
    one of the best ways to improve the performance of a database application. Without
    an effective (strong?) index, the database engine is like a reader trying to find
    a phrase within a reference book by having to take the time to examine each and
    every page. But if the reader uses the reference book's index, the reader can
    then complete the task in a much shorter time (better performance = better results).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例从一个关系数据库开始。在那里，有效的索引是提高数据库应用程序性能的最佳方式之一。如果没有有效的（强大的）索引，数据库引擎就像是一个读者，试图通过检查每一页来找到参考书中的某个短语。但如果读者使用参考书的索引，那么读者就能在更短的时间内完成任务（更好的性能
    = 更好的结果）。
- en: In database terms, a table scan occurs when there is no available index identified
    to boost the performance of a database query. In a table scan, the database engine
    examines each and every row in the table to satisfy the query results.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据库术语中，当没有可用的索引来提升数据库查询性能时，就会发生表扫描。在表扫描中，数据库引擎检查表中的每一行，以满足查询结果。
- en: One of the most important jobs for a database developer is finding the best
    index to use when generating an execution plan (for a query). Most major databases
    offer tools to show you execution plans for a query and help in optimizing and
    tuning query indexes.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库开发者最重要的工作之一是找到生成执行计划时使用的最佳索引（针对查询）。大多数主要数据库都提供工具来显示查询的执行计划，并帮助优化和调优查询索引。
- en: The preceding situation might be compared to repetitively testing queries in
    a database, scoring individual performances (in returning the query results) until
    an efficient (or strong) index is determined.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 前述情况可以与在数据库中反复测试查询、评分每个查询结果的表现（即返回查询结果）直到确定一个高效（或强大的）索引进行比较。
- en: This then has the effect of improving the performance of the database query
    so that it becomes a strong responder (or, if you will, a strong learner).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这会改善数据库查询的性能，使其成为强大的响应者（或者，如果你愿意，可以说是强大的学习者）。
- en: Using R to illustrate boosting methods
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用R语言展示提升方法
- en: In order to further illustrate the use of boosting, we should have an example.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步说明提升方法的使用，我们应该有一个示例。
- en: In this section, we'll take a high-level look at a thought-provoking prediction
    problem drawn from *Mastering Predictive Analytics with R, Second Edition,* James
    D. Miller and Rui Miguel Forte, August 2017 ([https://www.packtpub.com/big-data-and-business-intelligence/mastering-predictive-analytics-r-second-edition](https://www.packtpub.com/big-data-and-business-intelligence/mastering-predictive-analytics-r-second-edition)).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将从*Mastering Predictive Analytics with R, Second Edition,* James D. Miller
    和 Rui Miguel Forte，2017年8月（[https://www.packtpub.com/big-data-and-business-intelligence/mastering-predictive-analytics-r-second-edition](https://www.packtpub.com/big-data-and-business-intelligence/mastering-predictive-analytics-r-second-edition)）中引入一个发人深思的预测问题，做一个高层次的回顾。
- en: In this original example, patterns made by radiation on a telescope camera are
    analyzed in an attempt to predict whether a certain pattern came from gamma rays
    leaking into the atmosphere or from regular background radiation.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个原始示例中，分析了望远镜相机上辐射形成的图案，试图预测某一特定图案是来自大气中泄漏的γ射线还是来自常规的背景辐射。
- en: Gamma rays leave distinctive elliptical patterns and so we can create a set
    of features to describe these. The dataset used is the *MAGIC Gamma Telescope
    Data Set*, hosted by the *UCI Machine Learning* *Repository* at [http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope](http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: γ射线会留下具有独特椭圆形状的图案，因此我们可以创建一组特征来描述这些图案。使用的数据集是*MAGIC Gamma Telescope Data Set*，由*UCI
    Machine Learning* *Repository* 提供，网址为[http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope](http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope)。
- en: 'This data consists of 19,020 observations, holding the following list of attributes:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含19,020个观测值，具有以下属性列表：
- en: '| **Column name** | **Type** | **Definition** |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| **列名** | **类型** | **定义** |'
- en: '| `FLENGTH` | Numerical | The major axis of the ellipse (mm) |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| `FLENGTH` | 数值型 | 椭圆的主轴（毫米） |'
- en: '| `FWIDTH` | Numerical | The minor axis of the ellipse (mm) |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| `FWIDTH` | 数值型 | 椭圆的次轴（毫米） |'
- en: '| `FSIZE` | Numerical | Logarithm to the base ten of the sum of the content
    of all pixels in the camera photo |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| `FSIZE` | 数值型 | 所有像素内容总和的十进对数 |'
- en: '| `FCONC` | Numerical | Ratio of the sum of the two highest pixels over `FSIZE`
    |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| `FCONC` | 数值型 | 两个最高像素之和与`FSIZE`的比率 |'
- en: '| `FCONC1` | Numerical | Ratio of the highest pixel over `FSIZE` |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| `FCONC1` | 数值型 | 最高像素与`FSIZE`的比率 |'
- en: '| `FASYM` | Numerical | Distance from the highest pixel to the centre, projected
    onto the major axis (mm) |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| `FASYM` | 数值型 | 从最高像素到中心的距离，投影到主轴上（毫米） |'
- en: '| `FM3LONG` | Numerical | Third root of the third moment along the major axis
    (mm) |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| `FM3LONG` | 数值型 | 沿主轴的三次矩的三次根（毫米） |'
- en: '| `FM3TRANS` | Numerical | Third root of the third moment along the minor axis
    (mm) |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| `FM3TRANS` | 数值型 | 沿次轴的三次矩的三次根（毫米） |'
- en: '| `FALPHA` | Numerical | Angle of the major axis with the vector to the origin
    (degrees) |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| `FALPHA` | 数值型 | 主轴与指向原点的向量之间的角度（度） |'
- en: '| `FDIST` | Numerical | Distance from the origin to the centre of the ellipse
    (mm) |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| `FDIST` | 数值型 | 从原点到椭圆中心的距离（毫米） |'
- en: '| `CLASS` | Binary | Gamma rays (g) or Background Hadron Radiation (b) |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| `CLASS` | 二元 | γ射线（g）或背景哈德龙辐射（b） |'
- en: Prepping the data
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备
- en: First, various steps need to be performed on our example data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，需要对我们的示例数据执行多个步骤。
- en: 'The data is first loaded into an R data frame object named `magic`, recoding
    the `CLASS` output variable to use classes `1` and `-1` for gamma rays and background
    radiation respectively:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 数据首先加载到一个名为`magic`的R数据框对象中，并将`CLASS`输出变量重新编码，分别使用`1`和`-1`表示伽马射线和背景辐射：
- en: '[PRE0]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, the data is split into two files: a training data and a test data frame
    using an 80-20 split:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将数据分成两个文件：训练数据和测试数据框，采用80-20的拆分方式：
- en: '[PRE1]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The model used for boosting is a simple multilayer perceptron with a single
    hidden layer leveraging R's `nnet` package.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 用于提升的模型是一个简单的多层感知机，具有一个单隐藏层，利用R的`nnet`包。
- en: 'Neural networks, (covered in [Chapter 9](224b964c-c313-4435-b36a-96f77fbabd9b.xhtml),
    *Databases and Neural Networks*) often produce higher accuracy when inputs are
    normalized, so, in this example, before training any models, this preprocessing
    is performed:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络（在[第9章](224b964c-c313-4435-b36a-96f77fbabd9b.xhtml)，*数据库与神经网络*中讨论）通常在输入数据标准化时能产生更高的准确性，因此在本例中，在训练任何模型之前，首先执行此预处理：
- en: '[PRE2]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Training
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练
- en: Boosting is designed to work best with weak learners, so a very small number
    of hidden neurons in the model's hidden layer are used.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 提升（Boosting）旨在与弱学习者一起最佳工作，因此在模型的隐藏层中使用非常少量的隐藏神经元。
- en: Concretely, we will begin with the simplest possible multilayer perceptron that
    uses a single hidden neuron. To understand the effect of using boosting, a baseline
    performance is established by training a single neural network (and measuring
    its performance).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将从最简单的多层感知机开始，使用一个隐藏神经元。为了理解提升的效果，通过训练一个单一的神经网络并测量其性能来建立基准性能。
- en: 'This is to accomplish the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这将完成以下任务：
- en: '[PRE3]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This establishes that we have a baseline accuracy of around 79.5 percent. Not
    too bad, but can boost to improve upon this score?
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明我们有一个大约79.5%的基准准确率。还不错，但是否可以通过提升来改善这个得分呢？
- en: To that end, the function `AdaBoostNN()`, which is shown as follows, is used.
    This function will take input from a data frame, the name of the output variable,
    the number of single hidden layer neural network models to be built, and finally,
    the number of hidden units these neural networks will have.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，使用如下的`AdaBoostNN()`函数。该函数将接受数据框输入、输出变量的名称、要构建的单层隐藏神经网络模型数量，最后是这些神经网络将包含的隐藏单元数量。
- en: The function will then implement the AdaBoost algorithm and return a list of
    models with their corresponding weights.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，该函数将实现AdaBoost算法，并返回一个包含相应权重的模型列表。
- en: 'Here is the function:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该函数：
- en: '[PRE4]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding function uses the following logic:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 上述函数使用以下逻辑：
- en: First, initialize empty lists of models and model weights (`alphas`). Compute
    the number of observations in the training data, storing this in the variable
    `n`. The name of the output column provided is then used to create a formula that
    describes the neural network that will be built.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，初始化空的模型和模型权重（`alphas`）列表。计算训练数据中的观测值数量，并将其存储在变量`n`中。然后，使用提供的输出列名称创建一个公式，描述将构建的神经网络。
- en: In the dataset used, this formula will be `CLASS ~ .`, meaning that the neural
    network will compute `CLASS` as a function of all the other columns as input features.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在所使用的数据集中，该公式将是`CLASS ~ .`，意味着神经网络将计算`CLASS`作为所有其他列（输入特征）的函数。
- en: Next, initialize the weights vector and define a loop that will run for `M`
    iterations in order to build `M` models.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，初始化权重向量并定义一个循环，该循环将运行`M`次迭代，以构建`M`个模型。
- en: In every iteration, the first step is to use the current setting of the weights
    vector to train a neural network using as many hidden units as specified in the
    input, `hidden_units`.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每次迭代中，第一步是使用当前的权重向量设置来训练神经网络，使用输入中指定的隐藏单元数量`hidden_units`。
- en: Then, compute a vector of predictions that the model generates on the training
    data using the `predict()` function. By comparing these predictions to the output
    column of the training data, calculate the errors that the current model makes
    on the training data. This then allows the computation of the error rate.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用`predict()`函数计算模型在训练数据上生成的预测向量。通过将这些预测与训练数据的输出列进行比较，计算当前模型在训练数据上的误差。这将允许计算误差率。
- en: This error rate is set as the weight of the current model and, finally, the
    observation weights to be used in the next iteration of the loop are updated according
    to whether each observation was correctly classified.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该错误率被设置为当前模型的权重，最后，观察权重将根据每个观察是否被正确分类，更新以便在下一次迭代中使用。
- en: The weight vector is then normalized and we are ready to begin the next iteration!
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，权重向量将被归一化，接下来我们就可以开始下一次迭代了！
- en: After completing `M` iterations, output a list of models and their corresponding
    model weights.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成`M`次迭代后，输出模型列表及其对应的模型权重。
- en: Ready for boosting
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备进行提升
- en: There is now a function able to train our ensemble classifier using AdaBoost,
    but we also need a function to make the actual predictions. This function will
    take in the output list produced by our training function, `AdaBoostNN()`, along
    with a test dataset.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有一个函数可以使用AdaBoost训练我们的集成分类器，但我们还需要一个函数来进行实际的预测。该函数将接受由我们训练函数`AdaBoostNN()`产生的输出列表，以及一个测试数据集。
- en: 'This function is `AdaBoostNN.predict()` and it is shown as follows:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数是`AdaBoostNN.predict()`，其表现如下所示：
- en: '[PRE5]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This function first extracts the models and the model weights (from the list
    produced by the previous function). A matrix of predictions is created, where
    each column corresponds to the vector of predictions made by a particular model.
    Thus, there will be as many columns in this matrix as the models that we used
    for boosting.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数首先提取模型和模型权重（来自前一个函数产生的列表）。然后创建一个预测矩阵，其中每列对应于某个特定模型所做的预测向量。因此，这个矩阵的列数将等于我们用于提升的模型数量。
- en: We then multiply the predictions produced by each model with their corresponding
    model weight. For example, every prediction from the first model is in the first
    column of the prediction matrix and will have its value multiplied by the first
    model weight *α[1]*.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将每个模型产生的预测与其对应的模型权重相乘。例如，第一个模型的每个预测值都位于预测矩阵的第一列，并将其值乘以第一个模型的权重*α[1]*。
- en: Lastly, the matrix of weighted observations is reduced into a single vector
    of observations by summing the weighted predictions for each observation and taking
    the sign of the result. This vector of predictions is then returned by the function.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过对每个观察的加权预测求和，并取结果的符号，将加权观察矩阵减少为一个单一的观察向量。这个预测向量将由函数返回。
- en: 'As an experiment, we will train ten neural network models with a single hidden
    unit and see if boosting improves accuracy:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 作为实验，我们将训练十个带有单个隐藏单元的神经网络模型，并观察提升是否提高了准确率：
- en: '[PRE6]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this example, boosting ten models shows a marginal improvement in accuracy,
    but perhaps training more models might make more of a difference.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，提升十个模型仅显示了微小的准确率提高，但或许训练更多的模型可能会带来更大的变化。
- en: As we have stated several times in this chapter, even a marginal improvement
    in performance qualifies as converting a weak learner into a strong one!
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章中多次提到的，即使是性能上的微小提升，也足以将一个弱学习器转化为强学习器！
- en: Example results
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例结果
- en: From the preceding example, you may conclude that, for the neural networks with
    one hidden unit, as the number of boosting models increases, we see an improvement
    in accuracy, but after 100 models, this tapers off and is actually slightly less
    for 200 models. The improvement over the baseline of a single model is substantial
    for these networks. When we increase the complexity of our learner by having a
    hidden layer with three hidden neurons, we get a much smaller improvement in performance.
    At 200 models, both ensembles perform at a similar level, indicating that, at
    this point, our accuracy is being limited by the type of model trained.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的例子中，你可能得出结论，对于具有一个隐藏单元的神经网络，随着提升模型数量的增加，我们看到准确度有所提高，但在达到100个模型后，这种提升开始减缓，甚至在200个模型时稍微下降。与单一模型的基准相比，这些网络的提升是显著的。当我们通过添加一个包含三个隐藏神经元的隐藏层来增加学习器的复杂度时，性能的提升就变得非常小。在200个模型时，两个集成模型表现相似，这表明此时我们的准确度受限于训练的模型类型。
- en: Summary
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discovered *s*tatistical boosting, first providing an explanation
    of the key concepts used in statistics relevant to the topic of boosting, thus
    helping to define boosting itself.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们发现了*统计提升*，首先提供了与提升主题相关的统计学关键概念的解释，从而有助于定义提升算法本身。
- en: We also contemplated the notion of using statistical boosting to better understand
    data in just about every database.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还考虑了使用统计提升来更好地理解几乎每个数据库中的数据的概念。
- en: In the next chapter, will again strive to use developer terminologies, this
    time in an effort to define a support vector machine, identify various applications
    for its use, and walk through an example of using a simple SVM to classify the
    data in a database.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将再次努力使用开发者术语，这次旨在定义支持向量机，识别其各种应用，并通过一个简单的SVM示例，演示如何使用支持向量机对数据库中的数据进行分类。
