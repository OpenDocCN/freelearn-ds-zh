- en: Chapter 1. Getting Acquainted with Storm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章. 熟悉Storm
- en: 'In this chapter, you will get acquainted with the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将熟悉以下主题：
- en: An overview of Storm
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storm概述
- en: The "before Storm" era and key features of Storm
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “Storm之前”的时代和Storm的关键特性
- en: Storm cluster modes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storm集群模式
- en: Storm installation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storm安装
- en: Starting various daemons
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动各种守护进程
- en: Playing with Storm configurations
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 玩转Storm配置
- en: Over the complete course of the chapter, you will learn why Storm is creating
    a buzz in the industry and why it is relevant in present-day scenarios. What is
    this real-time computation? We will also explain the different types of Storm's
    cluster modes, the installation, and the approach to configuration.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的整个过程中，你将了解为什么Storm在业界引起了轰动，以及为什么它在当今场景中是相关的。什么是实时计算？我们还将解释Storm的不同集群模式、安装和配置方法。
- en: Overview of Storm
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Storm概述
- en: Storm is a distributed, fault-tolerant, and highly scalable platform for processing
    streaming data in a real-time manner. It became an Apache top-level project in
    September 2014, and was previously an Apache Incubator project since September
    2013.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Storm是一个分布式、容错且高度可扩展的平台，用于实时处理流数据。它在2014年9月成为Apache顶级项目，之前自2013年9月起一直是Apache孵化器项目。
- en: Real-time processing on a massive scale has become a requirement of businesses.
    Apache Storm provides the capability to process data (a.k.a tuples or stream)
    as and when it arrives in a real-time manner with distributed computing options.
    The ability to add more machines to the Storm cluster makes Storm scalable. Then,
    the third most important thing that comes with storm is fault tolerance. If the
    storm program (also known as topology) is equipped with reliable spout, it can
    reprocess the failed tuples lost due to machine failure and also give fault tolerance.
    It is based on XOR magic, which will be explained in [Chapter 2](ch02.html "Chapter 2. The
    Storm Anatomy"), *The Storm Anatomy*.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在大规模上实时处理已成为企业的需求。Apache Storm提供了实时处理数据（即元组或流）的能力，这些数据（元组或流）在到达时即可处理，具有分布式计算选项。能够向Storm集群添加更多机器使Storm可扩展。然后，随着Storm而来的第三件最重要的事情是容错性。如果Storm程序（也称为拓扑）配备了可靠的spout，它可以重新处理由于机器故障而丢失的失败元组，并提供容错性。它基于XOR魔法，将在[第2章](ch02.html
    "第2章. Storm解剖")*Storm解剖*中解释。
- en: Storm was originally created by Nathan Marz and his team at BackType. The project
    was made open source after it was acquired by Twitter. Interestingly, Storm received
    a tag as Real Time Hadoop.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Storm最初是由Nathan Marz及其团队在BackType创建的。该项目在被Twitter收购后开源。有趣的是，Storm被标记为实时Hadoop。
- en: 'Storm is best suited for many real-time use cases. A few of its interesting
    use cases are explained here:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Storm非常适合许多实时用例。以下是一些有趣的用例说明：
- en: '**ETL pipeline**: ETL stands for **Extraction**, **Transformation**, and **Load**.
    It is a very common use case of Storm. Data can be extracted or read from any
    source. Here, the data can be complex XML, a JDBC result set row, or simply a
    few key-value records. Data (also known as tuples in Storm) can be enriched on
    the fly with more information, transformed into the required storage format, and
    stored in a NoSQL/RDBMS data store. All of these things can be achieved at a very
    high throughput in a real-time manner with simple storm programs. Using the Storm
    ETL pipeline, you can ingest into a big data warehouse at high speed.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ETL管道**：ETL代表**提取**、**转换**和**加载**。这是Storm非常常见的用例。数据可以从任何来源提取或读取。在这里，数据可以是复杂的XML、JDBC结果集行，或者仅仅是几个键值记录。数据（在Storm中也称为元组）可以即时地添加更多信息，转换为所需的存储格式，并存储在NoSQL/RDBMS数据存储中。所有这些都可以通过简单的Storm程序以非常高的吞吐量实时完成。使用Storm
    ETL管道，你可以高速地将数据导入大数据仓库。'
- en: '**Trending topic analysis**: Twitter uses such use cases to know the trending
    topics within a given time frame or at present. There are numerous use cases,
    and finding the top trends in a real-time manner is required. Storm can fit well
    in such use cases. You can also perform running aggregation of values with the
    help of any database.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**趋势话题分析**：Twitter使用此类用例来了解在给定时间段或当前的趋势话题。有无数种用例，并且需要实时地找到最热门的趋势。Storm非常适合此类用例。你还可以借助任何数据库执行值的运行聚合。'
- en: '**Regulatory check engine**: Real-time event data can pass through a business-specific
    regulatory algorithm, which can perform a compliance check in a real-time manner.
    Banks use these for trade data checks in real time.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监管检查引擎**：实时事件数据可以通过业务特定的监管算法进行传递，该算法可以实时执行合规性检查。银行使用这些工具进行实时交易数据检查。'
- en: Storm can ideally fit into any use case where there is a need to process data
    in a fast and reliable manner, at a rate of more than 10,000 messages processing
    per second, as soon as data arrives. Actually, 10,000+ is a small number. Twitter
    is able to process millions of tweets per second on a large cluster. It depends
    on how well the Storm topology is written, how well it is tuned, and the cluster
    size.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Storm 理想地适用于任何需要快速且可靠地处理数据的用例，每秒处理超过 10,000 条消息，数据一到即可处理。实际上，10,000+ 是一个较小的数字。Twitter
    能够在大型集群上每秒处理数百万条推文。这取决于 Storm 拓扑编写的好坏、调优程度以及集群大小。
- en: Storm program (a.k.a topologies) are designed to run 24x7 and will not stop
    until someone stops them explicitly.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Storm 程序（即拓扑）设计为全天候运行，除非有人明确停止它们，否则不会停止。
- en: Storm is written using both Clojure as well as Java. Clojure is a Lisp, functional
    programming language that runs on JVM and is best for concurrency and parallel
    programming. Storm leverages the mature Java library, which was built over the
    last 10 years. All of these can be found inside the `storm`/`lib` folder.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Storm 使用 Clojure 和 Java 编写。Clojure 是一种运行在 JVM 上的 Lisp 函数式编程语言，非常适合并发和并行编程。Storm
    利用过去 10 年中构建的成熟 Java 库。所有这些都可以在 `storm`/`lib` 文件夹中找到。
- en: Before the Storm era
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Storm 时代之前
- en: Before Storm became popular, real-time or near-real-time processing problems
    were solved using intermediate brokers and with the help of message queues. Listener
    or worker processes run using the Python or Java languages. For parallel processing,
    code was dependent on the threading model supplied using the programming language
    itself. Many times, the old style of working did not utilize CPU and memory very
    well. In some cases, mainframes were used as well, but they also became outdated
    over time. Distributed computing was not so easy. There were either many intermediate
    outputs or hops in this old style of working. There was no way to perform a fail
    replay automatically. Storm addressed all of these pain areas very well. It is
    one of the best real-time computation frameworks available for use.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Storm 流行之前，实时或准实时处理问题是通过中间代理和消息队列的帮助解决的。监听器或工作进程使用 Python 或 Java 语言运行。对于并行处理，代码依赖于编程语言本身提供的线程模型。很多时候，旧的工作方式没有很好地利用
    CPU 和内存。在某些情况下，也使用了大型机，但随着时间的推移，它们也变得过时了。分布式计算并不容易。在旧的工作方式中，要么有大量的中间输出，要么有多个跳跃。无法自动执行故障重放。Storm
    非常好地解决了所有这些痛点。它是可用的最佳实时计算框架之一。
- en: Key features of Storm
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Storm 的关键特性
- en: 'Here are Storm''s key features; they address the aforementioned problems:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是 Storm 的关键特性；它们解决了上述问题：
- en: '**Simple to program**: It''s easy to learn the Storm framework. You can write
    code in the programming language of your choice and can also use the existing
    libraries of that programming language. There is no compromise.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于编程**：学习 Storm 框架很容易。你可以使用你选择的编程语言编写代码，也可以使用该编程语言的现有库。没有任何妥协。'
- en: '**Storm already supports most programming languages**: However, even if something
    is not supported, it can be done by supplying code and configuration using the
    JSON protocol defined in the Storm **Data Specification Language** (**DSL**).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Storm 已经支持大多数编程语言**：然而，即使某些语言不受支持，也可以通过提供代码和配置，使用在 Storm **数据规范语言**（**DSL**）中定义的
    JSON 协议来实现。'
- en: '**Horizontal scalability or distributed computing is possible**: Computation
    can be multiplied by adding more machines to the Storm cluster without stopping
    running programs, also known as topologies.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水平扩展或分布式计算是可能的**：通过向 Storm 集群添加更多机器来增加计算能力，而无需停止正在运行的程序，也称为拓扑。'
- en: '**Fault tolerant**: Storm manages worker and machine-level failure. Heartbeats
    of each process are tracked to manage different types of failure, such as task
    failure on one machine or an entire machine''s failure.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容错性**: Storm 管理工作节点和机器级别的故障。每个进程的心跳被跟踪以管理不同类型的故障，例如一台机器上的任务故障或整个机器的故障。'
- en: '**Guaranteed message processing**: There is a provision of performing auto
    and explicit ACK within storm processes on messages (tuples). If ACK is not received,
    storm can do a reply of a message.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保证消息处理**：在Storm进程中，对消息（元组）进行自动和显式ACK有相应的机制。如果没有收到ACK，Storm可以对消息进行回复。'
- en: '**Free, open source, and lots of open source community support**: Being an
    Apache project, Storm has free distribution and modifying rights without any worry
    about the legal aspect. Storm gets a lot of attention from the open source community
    and is attracting a large number of good developers to contribute to the code.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**免费、开源，并且拥有大量的开源社区支持**：作为Apache项目，Storm具有免费分发和修改的权利，无需担心法律方面的问题。Storm受到了开源社区的广泛关注，并吸引了许多优秀的开发者为其代码贡献力量。'
- en: Storm cluster modes
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Storm集群模式
- en: The Storm cluster can be set up in four flavors based on the requirement. If
    you want to set up a large cluster, go for distributed installation. If you want
    to learn Storm, then go for a single machine installation. If you want to connect
    to an existing Storm cluster, use client mode. Finally, if you want to perform
    development on an IDE, simply unzip the `storm` TAR and point to all dependencies
    of the `storm` library. At the initial learning phase, a single-machine storm
    installation is actually what you need.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 根据需求，Storm集群可以设置为四种模式。如果你想搭建一个大型集群，可以选择分布式安装。如果你想学习Storm，那么可以选择单机安装。如果你想连接到现有的Storm集群，请使用客户端模式。最后，如果你想在一个IDE上进行开发，只需解压`storm`
    TAR文件，并指向`storm`库的所有依赖项。在初始学习阶段，单机Storm安装实际上是你所需要的。
- en: Developer mode
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开发者模式
- en: A developer can download storm from the distribution site, unzip it somewhere
    in `$HOME`, and simply submit the Storm topology as local mode. Once the topology
    is successfully tested locally, it can be submitted to run over the cluster.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者可以从分发站点下载Storm，将其解压到`$HOME`目录下的某个位置，并以本地模式提交Storm拓扑。一旦拓扑在本地成功测试，就可以提交到集群上运行。
- en: Single-machine Storm cluster
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单机Storm集群
- en: 'This flavor is best for students and medium-scale computation. Here, everything
    runs on a single machine, including **Zookeeper**, **Nimbus**, and **Supervisor**.
    `Storm/bin` is used to run all commands. Also, no extra Storm client is required.
    You can do everything from the same machine. This case is well demonstrated in
    the following figure:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式最适合学生和中等规模的计算。在这里，包括**Zookeeper**、**Nimbus**和**Supervisor**在内的所有操作都在单台机器上运行。使用`Storm/bin`目录下的所有命令。此外，不需要额外的Storm客户端。你可以在同一台机器上完成所有操作。以下图示很好地展示了这种情况：
- en: '![Single-machine Storm cluster](img/B03471_01_01.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![单机Storm集群](img/B03471_01_01.jpg)'
- en: Multimachine Storm cluster
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多机Storm集群
- en: This option is required when you have a large-scale computation requirement.
    It is a horizontal scaling option. The following figure explains this case in
    detail. In this figure, we have five physical machines, and to increase fault
    tolerance in the systems, we are running Zookeeper on two machines. As shown in
    the diagram, **Machine 1** and **Machine 2** are a group of Zookeeper machines;
    one of them is the leader at any point of time, and when it dies, the other becomes
    the leader. **Nimbus** is a lightweight process, so it can run on either machine,
    1 or 2\. We also have **Machine 3**, **Machine 4**, and **Machine 5** dedicated
    for performing actual processing. Each one of these machines (3, 4, and 5) requires
    a supervisor daemon to run over there. Machines 3, 4, and 5 should know where
    the Nimbus/Zookeeper daemon is running and that entry should be present in their
    `storm.yaml`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有大规模计算需求时，这个选项是必需的。这是一个水平扩展选项。以下图详细解释了这种情况。在这个图中，我们有五台物理机器，为了提高系统的容错性，我们在两台机器上运行Zookeeper。如图所示，**机器1**和**机器2**是一组Zookeeper机器；在任何时候，其中一台是领导者，当它死亡时，另一台成为领导者。**Nimbus**是一个轻量级进程，因此它可以在机器1或机器2上运行。我们还有**机器3**、**机器4**和**机器5**专门用于执行实际处理。这些机器（3、4和5）都需要一个supervisor守护进程来运行。机器3、4和5应该知道Nimbus/Zookeeper守护进程在哪里运行，并且这个条目应该出现在它们的`storm.yaml`文件中。
- en: '![Multimachine Storm cluster](img/B03471_01_02.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![多机Storm集群](img/B03471_01_02.jpg)'
- en: So, each physical machine (3, 4, and 5) runs one supervisor daemon, and each
    machine's `storm.yaml` points to the IP address of the machine where Nimbus is
    running (this can be 1 or 2). All Supervisor machines must add the Zookeeper IP
    addresses (1 and 2) to `storm.yaml`. The Storm UI daemon should run on the Nimbus
    machine (this can be 1 or 2).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每台物理机器（3、4 和 5）运行一个监督守护进程，每台机器的 `storm.yaml` 文件指向运行 Nimbus 的机器的 IP 地址（这可以是
    1 或 2）。所有监督机器都必须将 Zookeeper IP 地址（1 和 2）添加到 `storm.yaml` 文件中。Storm UI 守护进程应该在
    Nimbus 机器上运行（这可以是 1 或 2）。
- en: The Storm client
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Storm 客户端
- en: The Storm client is required only when you have a Storm cluster of multiple
    machines. To start the client, unzip the Storm distribution and add the Nimbus
    IP address to the `storm.yaml` file. The Storm client can be used to submit Storm
    topologies and check the status of running topologies from command-line options.
    Storm versions older than 0.9 should put the `yaml` file inside `$STORM_HOME/.storm/storm.yaml`
    (not required for newer versions).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有一个多机 Storm 集群时，才需要 Storm 客户端。要启动客户端，解压 Storm 发行版并将 Nimbus IP 地址添加到 `storm.yaml`
    文件中。Storm 客户端可以用于从命令行选项提交 Storm 拓扑并检查运行拓扑的状态。Storm 版本低于 0.9 的应该将 `yaml` 文件放在 `$STORM_HOME/.storm/storm.yaml`
    内（对于新版本不是必需的）。
- en: Note
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `jps` command is a very useful Unix command for seeing the Java process
    ID of Zookeeper, Nimbus, and Supervisor. The `kill -9 <pid>` option can stop a
    running process. The `jps` command will work only when `JAVA_HOME` is set in the
    `PATH` environment variable.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`jps` 命令是一个非常有用的 Unix 命令，用于查看 Zookeeper、Nimbus 和 Supervisor 的 Java 进程 ID。`kill
    -9 <pid>` 选项可以停止正在运行的过程。`jps` 命令只有在 `JAVA_HOME` 设置在 `PATH` 环境变量中时才会工作。'
- en: Prerequisites for a Storm installation
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Storm 安装的先决条件
- en: 'Installing Java and Python is easy. Let''s assume our Linux machine is ready
    with Java and Python:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Java 和 Python 很简单。假设我们的 Linux 机器已经安装了 Java 和 Python：
- en: A Linux machine (Storm version 0.9 and later can also run on Windows machines)
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台 Linux 机器（Storm 版本 0.9 及以后的版本也可以在 Windows 机器上运行）
- en: Java 6 (`set export PATH=$PATH:$JAVA_HOME/bin`)
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java 6 (`set export PATH=$PATH:$JAVA_HOME/bin`)
- en: Python 2.6 (required to run Storm daemons and management commands)
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 2.6（运行 Storm 守护进程和管理命令所必需）
- en: We will be making lots of changes in the storm configuration file (that is,
    `storm.yaml`), which is actually present under `$STORM_HOME/config`. First, we
    start the Zookeeper process, which carries out coordination between Nimbus and
    the Supervisors. Then, we start the Nimbus master daemon, which distributes code
    in the Storm cluster. Next, the Supervisor daemon listens for work assigned (by
    Nimbus) to the node it runs on and starts and stops the worker processes as necessary.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对 storm 配置文件（即 `storm.yaml`）进行很多修改，该文件实际上位于 `$STORM_HOME/config` 下。首先，我们启动
    Zookeeper 进程，该进程执行 Nimbus 和监督者之间的协调。然后，我们启动 Nimbus 主守护进程，该守护进程在 Storm 集群中分发代码。接下来，监督守护进程监听分配给其运行的节点的工作（由
    Nimbus 分配），并根据需要启动和停止工作进程。
- en: ZeroMQ/JZMQ and Netty are inter-JVM communication libraries that permit two
    machines or two JVMs to send and receive process data (tuples) between each other.
    JZMQ is a Java binding of ZeroMQ. The latest versions of Storm (0.9+) have now
    been moved to Netty. If you download an old version of Storm, installing ZeroMQ
    and JZMQ is required. In this book, we will be considering only the latest versions
    of Storm, so you don't really require ZeroMQ/JZMQ.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ZeroMQ/JZMQ 和 Netty 是 JVM 间通信库，允许两台机器或两个 JVM 之间相互发送和接收进程数据（元组）。JZMQ 是 ZeroMQ
    的 Java 绑定。Storm（0.9+）的最新版本已经迁移到 Netty。如果你下载了 Storm 的旧版本，则需要安装 ZeroMQ 和 JZMQ。在这本书中，我们将只考虑
    Storm 的最新版本，因此你实际上不需要 ZeroMQ/JZMQ。
- en: Zookeeper installation
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Zookeeper 安装
- en: Zookeeper is a coordinator for the Storm cluster. The interaction between Nimbus
    and worker nodes is done through Zookeeper. The installation of Zookeeper is well
    explained on the official website at [http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html#sc_InstallingSingleMode](http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html#sc_InstallingSingleMode).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Zookeeper 是 Storm 集群的协调器。Nimbus 和工作节点之间的交互是通过 Zookeeper 完成的。Zookeeper 的安装过程在官方网站上解释得非常详细，请参阅[http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html#sc_InstallingSingleMode](http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html#sc_InstallingSingleMode)。
- en: 'The setup can be downloaded from:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 设置可以从以下链接下载：
- en: '[https://archive.apache.org/dist/zookeeper/zookeeper-3.3.5/zookeeper-3.3.5.tar.gz](https://archive.apache.org/dist/zookeeper/zookeeper-3.3.5/zookeeper-3.3.5.tar.gz).
    After downloading, edit the `zoo.cfg` file.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://archive.apache.org/dist/zookeeper/zookeeper-3.3.5/zookeeper-3.3.5.tar.gz](https://archive.apache.org/dist/zookeeper/zookeeper-3.3.5/zookeeper-3.3.5.tar.gz)。下载后，编辑
    `zoo.cfg` 文件。'
- en: 'The following are the Zookeeper commands that are used:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是用到的 Zookeeper 命令：
- en: 'Starting the `zookeeper` process:'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动 `zookeeper` 进程：
- en: '[PRE0]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Checking the running status of the `zookeeper` service:'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查 `zookeeper` 服务的运行状态：
- en: '[PRE1]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Stopping the `zookeeper` service:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止 `zookeeper` 服务：
- en: '[PRE2]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Alternatively, use `jps` to find `<pid>` and then use `kill -9 <pid>` to kill
    the processes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，使用 `jps` 查找 `<pid>`，然后使用 `kill -9 <pid>` 杀死进程。
- en: Storm installation
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Storm 安装
- en: 'Storm can be installed in either of these two ways:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Storm 可以通过以下两种方式之一进行安装：
- en: 'Fetch a Storm release from this location using Git:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Git 从此位置获取 Storm 发布版：
- en: '[https://github.com/nathanmarz/storm.git](https://github.com/nathanmarz/storm.git)'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/nathanmarz/storm.git](https://github.com/nathanmarz/storm.git)'
- en: 'Download directly from the following link: [https://storm.apache.org/downloads.html](https://storm.apache.org/downloads.html)'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接从以下链接下载：[https://storm.apache.org/downloads.html](https://storm.apache.org/downloads.html)
- en: Storm configurations can be done using `storm.yaml`, which is present in the
    `conf` folder.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Storm 配置可以通过 `storm.yaml` 完成，该文件位于 `conf` 文件夹中。
- en: The following are the configurations for a single-machine Storm cluster installation.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个单机 Storm 集群安装的配置。
- en: 'Port `# 2181` is the default port of Zookeeper. To add more than one `zookeeper`,
    keep entry – separated:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 端口 `# 2181` 是 Zookeeper 的默认端口。要添加多个 `zookeeper`，请保持条目之间用空格分隔：
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Notice `supervisor.childopts: "-Xmx256m"`. In this setting, we reserved four
    supervisor ports, which means that a maximum of four worker processes can run
    on this machine.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '注意 `supervisor.childopts: "-Xmx256m"`。在此设置中，我们预留了四个 supervisor 端口，这意味着最多有四个工作进程可以在此机器上运行。'
- en: '`storm.local.dir`: This directory location should be cleaned if there is a
    problem with starting Nimbus and Supervisor. In the case of running a topology
    on the local IDE on a Windows machine, `C:\Users\<User-Name>\AppData\Local\Temp`
    should be cleaned.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`storm.local.dir`：如果启动 Nimbus 和 Supervisor 时出现问题，应清理此目录位置。在 Windows 机器上在本地
    IDE 上运行拓扑时，应清理 `C:\Users\<用户名>\AppData\Local\Temp`。'
- en: Enabling native (Netty only) dependency
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启用本地（仅Netty）依赖项
- en: Netty enables inter JVM communication and it is very simple to use.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Netty 允许 JVM 之间的通信，并且使用起来非常简单。
- en: Netty configuration
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Netty 配置
- en: You don't really need to install anything extra for Netty. This is because it's
    a pure Java-based communication library. All new versions of Storm support Netty.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 您实际上不需要为 Netty 安装任何额外的软件。这是因为它是一个基于纯 Java 的通信库。所有新的 Storm 版本都支持 Netty。
- en: 'Add the following lines to your `storm.yaml` file. Configure and adjust the
    values to best suit your use case:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下行添加到您的 `storm.yaml` 文件中。根据您的使用情况配置和调整这些值：
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Starting daemons
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启动守护进程
- en: 'Storm daemons are the processes that are needed to pre-run before you submit
    your program to the cluster. When you run a topology program on a local IDE, these
    daemons auto-start on predefined ports, but over the cluster, they must run at
    all times:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Storm 守护进程是在您将程序提交到集群之前需要预先运行的进程。当您在本地 IDE 上运行拓扑程序时，这些守护进程会在预定义的端口上自动启动，但在集群中，它们必须始终运行：
- en: 'Start the master daemon, `nimbus`. Go to the `bin` directory of the Storm installation
    and execute the following command (assuming that `zookeeper` is running):'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动主守护进程 `nimbus`。转到 Storm 安装目录下的 `bin` 目录并执行以下命令（假设 `zookeeper` 正在运行）：
- en: '[PRE5]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now we have to start the `supervisor` daemon. Go to the `bin` directory of
    the Storm installation and execute this command:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们必须启动 `supervisor` 守护进程。转到 Storm 安装目录下的 `bin` 目录并执行以下命令：
- en: '[PRE6]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To run in the background, use the following command:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要在后台运行，请使用以下命令：
- en: '[PRE7]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If Nimbus or the Supervisors restart, the running topologies are unaffected
    as both are stateless.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果 Nimbus 或 Supervisors 重新启动，正在运行的拓扑不受影响，因为它们都是无状态的。
- en: 'Let''s start the `storm` UI. The Storm UI is an optional process. It helps
    us to see the Storm statistics of a running topology. You can see how many executors
    and workers are assigned to a particular topology. The command needed to run the
    storm UI is as follows:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们启动 `storm` UI。Storm UI 是一个可选进程。它帮助我们查看正在运行的拓扑的 Storm 统计信息。您可以看到分配给特定拓扑的执行器和工人数。运行
    storm UI 所需的命令如下：
- en: '[PRE8]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Alternatively, to run in the background, use this line with `nohup`:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者，要在后台运行，请使用带有 `nohup` 的以下行：
- en: '[PRE9]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To access the Storm UI, visit `http://localhost:8080`.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问 Storm UI，请访问 `http://localhost:8080`。
- en: 'We will now start `storm logviewer`. Storm UI is another optional process for
    seeing the log from the browser. You can also see the `storm` log using the command-line
    option in the `$STORM_HOME/logs` folder. To start logviewer, use this command:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将启动 `storm logviewer`。Storm UI 是另一个可选进程，用于通过浏览器查看日志。您还可以使用 `$STORM_HOME/logs`
    文件夹中的命令行选项查看 `storm` 日志。要启动日志查看器，请使用此命令：
- en: '[PRE10]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To run in the background, use the following line with `nohup`:'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要在后台运行，请使用以下带有 `nohup` 的行：
- en: '[PRE11]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'To access Storm''s log, visit `http://localhost:8000log viewer` daemon should
    run on each machine. Another way to access the log of `<machine name>` for worker
    port `6700` is given here:'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问 Storm 的日志，请访问 `http://localhost:8000log viewer` 守护进程应在每台机器上运行。另一种访问 `<machine
    name>` 的 `6700` 工作端口日志的方法如下：
- en: '[PRE12]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'DRPC daemon: DRPC is another optional service. **DRPC** stands for **Distributed
    Remote Procedure Call**. You will require the DRPC daemon if you want to supply
    to the storm topology an argument externally through the DRPC client. Note that
    an argument can be supplied only once, and the DRPC client can wait for long until
    storm topology does the processing and the return. DRPC is not a popular option
    to use in projects, as firstly, it is blocking to the client, and secondly, you
    can supply only one argument at a time. DRPC is not supported by Python and Petrel.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DRPC 守护进程：DRPC 是另一个可选服务。**DRPC** 代表 **分布式远程过程调用**。如果您想通过 DRPC 客户端将参数外部提供给 Storm
    拓扑，则需要 DRPC 守护进程。请注意，参数只能提供一次，并且 DRPC 客户端可以长时间等待 Storm 拓扑完成处理并返回。由于首先，它会对客户端造成阻塞，其次，您一次只能提供一个参数，因此
    DRPC 并不是在项目中使用的一个流行选项。Python 和 Petrel 不支持 DRPC。
- en: 'Summarizing, the steps for starting processes are as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 总结，启动进程的步骤如下：
- en: First, all the Zookeeper daemons.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，所有的 Zookeeper 守护进程。
- en: Nimbus daemons.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Nimbus 守护进程。
- en: Supervisor daemon on one or more machine.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一台或多台机器上的管理守护进程。
- en: The UI daemon where Nimbus is running (optional).
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行在 Nimbus 上的 UI 守护进程（可选）。
- en: The Logviewer daemon (optional).
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日志查看器守护进程（可选）。
- en: Submitting the topology.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交拓扑。
- en: You can restart the `nimbus` daemon anytime without any impact on existing processes
    or topologies. You can restart the supervisor daemon and can also add more supervisor
    machines to the Storm cluster anytime.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以随时重启 `nimbus` 守护进程，而不会对现有进程或拓扑造成任何影响。您也可以重启管理守护进程，并且可以随时向 Storm 集群添加更多管理节点。
- en: 'To submit `jar` to the Storm cluster, go to the `bin` directory of the Storm
    installation and execute the following command:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 `jar` 提交给 Storm 集群，请转到 Storm 安装目录的 `bin` 目录并执行以下命令：
- en: '[PRE13]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Playing with optional configurations
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 玩转可选配置
- en: All the previous settings are required to start the cluster, but there are many
    other settings that are optional and can be tuned based on the topology's requirement.
    A prefix can help find the nature of a configuration. The complete list of default
    `yaml` configuration is available at [https://github.com/apache/storm/blob/master/conf/defaults.yaml](https://github.com/apache/storm/blob/master/conf/defaults.yaml).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 所有之前的设置都是启动集群所必需的，但还有许多其他设置是可选的，可以根据拓扑的需求进行调整。前缀可以帮助找到配置的性质。完整的默认 `yaml` 配置列表可在
    [https://github.com/apache/storm/blob/master/conf/defaults.yaml](https://github.com/apache/storm/blob/master/conf/defaults.yaml)
    找到。
- en: Configurations can be identified by how the prefix starts. For example, all
    UI configurations start with `ui*`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 配置可以通过其前缀来识别。例如，所有 UI 配置都以 `ui*` 开头。
- en: '| Nature of the configuration | Prefix to look into |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 配置的性质 | 查找前缀 |'
- en: '| --- | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| General | `storm.*` |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 一般 | `storm.*` |'
- en: '| Nimbus | `nimbus.*` |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| Nimbus | `nimbus.*` |'
- en: '| UI | `ui.*` |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| UI | `ui.*` |'
- en: '| Log viewer | `logviewer.*` |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 日志查看器 | `logviewer.*` |'
- en: '| DRPC | `drpc.*` |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| DRPC | `drpc.*` |'
- en: '| Supervisor | `supervisor.*` |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 管理器 | `supervisor.*` |'
- en: '| Topology | `topology.*` |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 拓扑 | `topology.*` |'
- en: 'All of these optional configurations can be added to `STORM_HOME/conf/storm.yaml`
    for any change other than the default values. All settings that start with `topology.*`
    can either be set programmatically from the topology or from `storm.yaml`. All
    other settings can be set only from the `storm.yaml` file. For example, the following
    table shows three different ways to play with these parameters. However, all of
    these three do the same thing:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些可选配置都可以添加到 `STORM_HOME/conf/storm.yaml` 中，以更改除默认值之外的所有设置。所有以 `topology.*`
    开头的设置既可以从拓扑中程序化设置，也可以从 `storm.yaml` 中设置。所有其他设置只能从 `storm.yaml` 文件中设置。例如，以下表格显示了三种不同的参数设置方式。然而，这三种方式都做了同样的事情：
- en: '| /conf/storm.yaml | Topology builder | Custom yaml |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| /conf/storm.yaml | 拓扑构建器 | 自定义 yaml |'
- en: '| --- | --- | --- |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Changing `storm.yaml`(impacts all the topologies of the cluster) | Changing
    the topology builder while writing code(impacts only the current topology) | Supplying
    `topology.yaml` as a command-line option(impacts only the current topology) |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 更改 `storm.yaml`(影响集群中所有拓扑) | 在编写代码时更改拓扑构建器(仅影响当前拓扑) | 将 `topology.yaml` 作为命令行选项提供(仅影响当前拓扑)
    |'
- en: '| `topology.workers: 1` | `conf.setNumberOfWorker(1);`This is supplied through
    Python code | Create `topology.yaml` with the entry made into it similar to `storm.yaml`,
    and supply it when running the topologyPython:`petrel submit --config topology.yaml`
    |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| `topology.workers: 1` | `conf.setNumberOfWorker(1);` 这是通过Python代码提供的 | 创建包含类似
    `storm.yaml` 的条目的 `topology.yaml`，并在运行拓扑时提供它 Python:`petrel submit --config topology.yaml`
    |'
- en: Any configuration change in `storm.yaml` will affect all running topologies,
    but when using the `conf.setXXX` option in code, different topologies can overwrite
    that option, what is best suited for each of them.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `storm.yaml` 中的任何配置更改都将影响所有正在运行拓扑，但当你使用代码中的 `conf.setXXX` 选项时，不同的拓扑可以覆盖该选项，最适合它们的是哪个。
- en: Summary
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Here comes the conclusion of the first chapter. This chapter gave an overview
    of how applications were developed before Storm came into existence. A brief knowledge
    of what real-time computations are and how Storm, as a programming framework,
    is becoming so popular was also acquired as we went through the chapter and approached
    the conclusion. This chapter taught you to perform Storm configurations. It also
    gave you details about the daemons of Storm, Storm clusters, and their step up.
    In the next chapter, we will be exploring the details of Storm's anatomy.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是第一章的结论。本章概述了在Storm出现之前应用程序是如何开发的。随着我们阅读本章并接近结论，我们也获得了对实时计算是什么以及Storm作为一个编程框架为何如此受欢迎的简要了解。本章教会了你如何执行Storm配置。它还提供了关于Storm守护进程、Storm集群及其升级的详细信息。在下一章中，我们将探讨Storm结构的细节。
