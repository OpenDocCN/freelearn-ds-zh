- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: General Usage and Performance Tips
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一般使用和性能优化建议
- en: At this point in the book, we have covered a rather large part of the pandas
    library while walking through sample applications to reinforce good usage. Equipped
    with all of this knowledge, you are now well prepared to step into the real world
    and start applying everything you have learned to your data analysis problems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经覆盖了 pandas 库的相当大一部分，同时通过示例应用来强化良好的使用习惯。掌握了这些知识后，你现在已经做好准备，踏入实际工作，并将所学的内容应用到数据分析问题中。
- en: This chapter will offer some tips and tricks you should keep in mind as you
    go out on your own. The recipes presented in this chapter are common mistakes
    I see by pandas users of all experience levels. While well-intentioned, improper
    usage of pandas constructs can leave a lot of performance on the table. When your
    datasets are smaller in size that may not be a big issue, but data has the tendency
    to grow, not to retreat in size. Using proper idioms and avoiding the maintenance
    burden of inefficient code can yield significant time and money savings for your
    organization.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将提供一些你在独立工作时应牢记的小窍门和建议。本章介绍的食谱是我在多种经验水平的 pandas 用户中经常看到的常见错误。尽管这些做法出发点良好，但不当使用
    pandas 构造会浪费很多性能。当数据集较小时，这可能不是大问题，但数据通常是增长的，而不是缩小。使用正确的惯用法并避免低效代码带来的维护负担，可以为你的组织节省大量时间和金钱。
- en: 'We are going to cover the following recipes in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下食谱：
- en: Avoid `dtype=object`
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免 `dtype=object`
- en: Be cognizant of data sizes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意数据大小
- en: Use vectorized functions instead of loops
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用矢量化函数代替循环
- en: Avoid mutating data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免修改数据
- en: Dictionary-encode low cardinality data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用字典编码低基数数据
- en: Test-driven development features
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试驱动开发功能
- en: Avoid dtype=object
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免使用 dtype=object
- en: Using `dtype=object` to store strings is one of the most error-prone and inefficient
    things you can do in pandas. Unfortunately, for the longest time, `dtype=object`
    was the only way to work with string data; this wasn’t “solved” until the 1.0
    release.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 中使用 `dtype=object` 来存储字符串是最容易出错且效率低下的做法之一。不幸的是，在很长一段时间里，`dtype=object`
    是处理字符串数据的唯一方法；直到 1.0 版本发布之前，这个问题才“得到解决”。
- en: I intentionally put “solved” in quotes because, while pandas 1.0 did introduce
    the `pd.StringDtype()`, it was not used by default by many construction and I/O
    methods until the 3.0 release. In effect, unless you told pandas otherwise, you
    would end up with `dtype=object` for all your string data in the 2.x series. For
    what it’s worth, the `pd.StringDtype()` that was introduced in 1.0 helped to assert
    you *only* stored strings, but it was never optimized for performance until the
    pandas 3.0 release.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我故意将“解决”放在引号中，因为尽管 pandas 1.0 确实引入了 `pd.StringDtype()`，但直到 3.0 版本发布之前，许多构造和
    I/O 方法默认并未使用它。实际上，除非你明确告诉 pandas 否则，在 2.x 版本中，你所有的字符串数据都会使用 `dtype=object`。值得一提的是，1.0
    引入的 `pd.StringDtype()` 帮助确保你*仅*存储字符串，但直到 3.0 版本发布之前，它并未进行性能优化。
- en: If you are using the 3.0 release of pandas and beyond, chances are you will
    still come across legacy code that reads like `ser = ser.astype(object)`. More
    often than not, such calls should be replaced with `ser = ser.astype(pd.StringDtype())`,
    unless you truly do need to store Python objects in a `pd.Series`. Unfortunately,
    there is no true way to know the intent, so you as a developer should be aware
    of the pitfalls of using `dtype=object` and how to identify if it can suitably
    be replaced with the `pd.StringDtype()`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是 pandas 3.0 版本及更高版本，可能仍然会遇到一些旧代码，如 `ser = ser.astype(object)`。通常情况下，这类调用应该被替换为
    `ser = ser.astype(pd.StringDtype())`，除非你确实需要在 `pd.Series` 中存储 Python 对象。不幸的是，我们无法真正了解原始意图，所以作为开发者，你应该意识到使用
    `dtype=object` 的潜在问题，并学会判断是否可以用 `pd.StringDtype()` 适当地替代它。
- en: How to do it
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: We already covered some of the issues with using `dtype=object` back in *Chapter
    3*, *Data Types,* but it is worth restating and expanding upon some of those issues
    here.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第 3 章*《数据类型》中已经讨论过使用 `dtype=object` 的一些问题，但在此重申并扩展这些问题是值得的。
- en: 'For an easy comparison, let’s create two `pd.Series` objects with identical
    data, where one uses the `object` data type and the other uses the `pd.StringDtype`:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做一个简单的比较，我们来创建两个 `pd.Series` 对象，它们的数据相同，一个使用 `object` 数据类型，另一个使用 `pd.StringDtype`：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Attempting to assign a non-string value to `ser_str` will fail:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试为 `ser_str` 分配一个非字符串值将会失败：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'By contrast, the object-typed `pd.Series` will gladly accept our `Boolean`
    value:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，`pd.Series` 类型的对象会很乐意接受我们的 `Boolean` 值：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In turn, this just ends up obfuscating where issues with your data may occur.
    With `pd.StringDtype`, the point of failure was very obvious when we tried to
    assign non-string data. With the object data type, you may not discover there
    is a problem until later in your code, when you try some string operation like
    capitalization:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 反过来，这只会让你更难发现数据中的问题。当我们尝试分配非字符串数据时，使用`pd.StringDtype`时，失败的地方是非常明显的。而在使用对象数据类型时，直到你在代码的后面尝试做一些字符串操作（比如大小写转换）时，才可能发现问题：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Instead of raising an error, pandas just decided to set our `False` entry in
    the first row to a missing value. Odds are just silently setting things to missing
    values like that is not the behavior you wanted, but with the object data type,
    you lose a lot of control over your data quality.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: pandas并没有抛出错误，而是决定将我们在第一行的`False`条目设置为缺失值。这样的默认行为可能并不是你想要的，但使用对象数据类型时，你对数据质量的控制会大大减弱。
- en: 'If you are working with pandas 3.0 and beyond, you will also see that, when
    PyArrow is installed, `pd.StringDtype` becomes significantly faster. Let’s recreate
    our `pd.Series` objects to measure this:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是pandas 3.0及更高版本，当安装了PyArrow时，你还会发现`pd.StringDtype`变得显著更快。让我们重新创建我们的`pd.Series`对象来测量这一点：
- en: '[PRE6]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For a quick timing comparison, let’s use the `timeit` module, built into the
    standard library:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速比较执行时间，让我们使用标准库中的`timeit`模块：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Compare that runtime to the same values but with the proper `pd.StringDtype`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 将该运行时间与使用正确的`pd.StringDtype`的情况进行比较：
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Unfortunately, users prior to the 3.0 release will not see any performance difference,
    but the data validation alone is worth it to move away from `dtype=object`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，3.0版本之前的用户无法看到任何性能差异，但单单是数据验证的改进就足以让你远离`dtype=object`。
- en: 'So what is the easiest way to avoid `dtype=object`? If you are fortunate enough
    to be working with the 3.0 release and beyond of pandas, you will naturally not
    run into this data type as often, as a natural evolution in the library. Even
    still, and for users that may still be using the pandas 2.x series, I advise using
    the `dtype_backend="numpy_nullable"` argument with I/O methods:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，避免使用`dtype=object`的最简单方法是什么？如果你有幸使用pandas 3.0及以上版本，你会发现这个数据类型不再那么常见，因为这是该库的自然发展。即便如此，对于仍然使用pandas
    2.x系列的用户，我建议在I/O方法中使用`dtype_backend="numpy_nullable"`参数：
- en: '[PRE11]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'If you are constructing a `pd.DataFrame` by hand, you can use `pd.DataFrame.convert_dtypes`
    paired with the same `dtype_backend="numpy_nullable"` argument:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你手动构建一个`pd.DataFrame`，可以使用`pd.DataFrame.convert_dtypes`方法，并配合使用相同的`dtype_backend="numpy_nullable"`参数：
- en: '[PRE13]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Please note that the `numpy_nullable` term is a bit of a misnomer. The argument
    would have probably been better named `pandas_nullable` or even just `pandas`
    or `nullable`, but when it was first introduced, it was strongly tied to the NumPy
    system still. Over time, the term `numpy_nullable` stuck, but the types moved
    away from using NumPy. Beyond the publication of this book, there may be a more
    suitable value to use to get the same behavior, which essentially asks for optimal
    data types in pandas that can support missing values.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`numpy_nullable`这个术语有些误导。这个参数本来应该被命名为`pandas_nullable`，甚至直接命名为`pandas`或`nullable`也更合适，但当它首次引入时，它与NumPy系统密切相关。随着时间的推移，`numpy_nullable`这个术语保留下来了，但类型已经不再依赖于NumPy。在本书出版后，可能会有更合适的值来实现相同的行为，基本上是为了找到支持缺失值的pandas最佳数据类型。
- en: 'While using `dtype=object` is most commonly *misused* for strings, it also
    exposes some rough edges with datetimes. I commonly see code like this from new
    users trying to create what they think is a `pd.Series` of dates:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`dtype=object`最常被*误用*来处理字符串，但它在处理日期时间时也暴露了一些问题。我常常看到新用户写出这样的代码，试图创建一个他们认为是日期的`pd.Series`：
- en: '[PRE15]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'While this is a logical way to try and accomplish the task at hand, the problem
    is that pandas does not have a true *date* type. Instead, these get stored in
    an `object` data type array using the `datetime.date` type from the Python standard
    library. This rather unfortunate usage of Python objects obfuscates the fact that
    you are trying to work with dates, and subsequently trying to use the `pd.Series.dt`
    accessor will throw an error:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一种逻辑上可行的方法，但问题在于pandas并没有一个真正的*日期*类型。相反，这些数据会使用Python标准库中的`datetime.date`类型存储在一个`object`数据类型的数组中。Python对象的这种不幸用法掩盖了你正在处理日期的事实，因此，尝试使用`pd.Series.dt`访问器时会抛出错误：
- en: '[PRE17]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Back in *Chapter 3*, *Data Types*, we talked briefly about the PyArrow `date32`
    type, which would be a more native solution to this problem:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第3章*，*数据类型*中，我们简要讨论了PyArrow的`date32`类型，它会是解决这个问题的一个更原生的方案：
- en: '[PRE19]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This will then unlock the `pd.Series.dt` attributes for use:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就解锁了`pd.Series.dt`属性，可以使用了：
- en: '[PRE21]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: I find this nuance rather unfortunate and hope future versions of pandas will
    be able to abstract these issues away, but nonetheless, they are present at the
    time of publication and may be for some time.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我觉得这个细节有些遗憾，希望未来的pandas版本能够抽象化这些问题，但无论如何，它们在当前版本中存在，并且可能会存在一段时间。
- en: In spite of all of the downsides that I have highlighted with respect to `dtype=object`,
    it still does have its uses when dealing with messy data. Sometimes, you may not
    know anything about your data and just need to inspect it before making further
    decisions. The object data type gives you the flexibility to load essentially
    any data and apply the same pandas algorithms to it. While these algorithms may
    not be very efficient, they still give you a consistent way to interact with and
    explore your data, ultimately buying you time to figure out how to best cleanse
    it and store it in a more proper data form. For this reason, I consider `dtype=object`
    best as a staging area – I would not advise keeping your types in it, but the
    fact that it buys you time to make assertions about your data types can be an
    asset.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我已经指出了`dtype=object`的一些缺点，但在处理凌乱数据时，它仍然有其用处。有时，你可能对数据一无所知，需要先检查它，才能做出进一步的决策。对象数据类型为你提供了加载几乎任何数据的灵活性，并且可以应用相同的pandas算法。虽然这些算法可能效率不高，但它们仍然为你提供了一种一致的方式来与数据交互和探索数据，最终为你争取了时间，帮助你找出如何最好地清理数据并将其存储为更合适的格式。因此，我认为`dtype=object`最好作为一个暂存区——我不建议将类型保存在其中，但它为你争取时间，以便对数据类型做出断言，可能是一个资产。
- en: Be cognizant of data sizes
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 留意数据大小
- en: As your datasets grow larger, you may find that you have to pick more optimal
    data types to ensure your `pd.DataFrame` can still fit into memory.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据集的增长，你可能会发现必须选择更合适的数据类型，以确保`pd.DataFrame`仍然能适应内存。
- en: Back in *Chapter 3*, *Data Types*, we discussed the different integral types
    and how they are a trade-off between memory usage and capacity. When dealing with
    untyped data sources like CSV and Excel files, pandas will err on the side of
    using too much memory as opposed to picking the wrong capacity. This conservative
    approach can lead to inefficient usage of your system’s memory, so knowing how
    to optimize that can make the difference between loading a file and receiving
    an `OutOfMemory` error.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第3章*，*数据类型*中，我们讨论了不同的整数类型，以及它们在内存使用和容量之间的权衡。当处理像CSV和Excel文件这样的无类型数据源时，pandas会倾向于使用过多的内存，而不是选择错误的容量。这种保守的做法可能导致系统内存的低效使用，因此，了解如何优化内存使用可能是加载文件和收到`OutOfMemory`错误之间的关键差异。
- en: How to do it
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做
- en: 'To illustrate the impact of picking proper data types, let’s start with a relatively
    large `pd.DataFrame` composed of Python integers:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明选择合适的数据类型的影响，我们从一个相对较大的`pd.DataFrame`开始，这个DataFrame由Python整数组成：
- en: '[PRE23]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'With the integral types, determining how much memory each `pd.Series` requires
    is a rather simple exercise. With a `pd.Int64Dtype`, each record is a 64-bit integer
    that requires 8 bytes of memory. Alongside each record, the `pd.Series` associates
    a single byte that is either 0 or 1, telling us if the record is missing or not.
    Thus, in total, we need 9 bytes for each record, and with 100,000 records per
    `pd.Series`, our memory usage should come out to 900,000 bytes. `pd.DataFrame.memory_usage`
    confirms that this math is correct:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于整数类型，确定每个`pd.Series`需要多少内存是一个相对简单的过程。对于`pd.Int64Dtype`，每条记录是一个64位整数，需要8个字节的内存。每条记录旁边，`pd.Series`还会关联一个字节，值为0或1，用来表示记录是否缺失。因此，每条记录总共需要9个字节，对于每个`pd.Series`中的100,000条记录，我们的内存使用量应该为900,000字节。`pd.DataFrame.memory_usage`确认这个计算是正确的：
- en: '[PRE25]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'If you know what the types should be, you could explicitly pick better sizes
    for the `pd.DataFrame` columns using `.astype`:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你知道应该使用什么类型，可以通过`.astype`显式地为`pd.DataFrame`的列选择更合适的大小：
- en: '[PRE27]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'As a convenience, pandas can try and infer better sizes for you with a call
    `pd.to_numeric`. Passing the `downcast="signed"` argument will ensure that we
    continue to work with signed integers, and we will continue to pass `dtype_backend="numpy_nullable"`
    to ensure we get proper missing value support:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种便捷方式，pandas 可以通过调用 `pd.to_numeric` 来推断更合适的大小。传递 `downcast="signed"` 参数将确保我们继续使用带符号整数，并且我们将继续传递
    `dtype_backend="numpy_nullable"` 来确保我们获得适当的缺失值支持：
- en: '[PRE29]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Use vectorized functions instead of loops
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用向量化函数代替循环
- en: Python as a language is celebrated for its looping prowess. Whether you are
    working with a list or a dictionary, looping over an object in Python is a relatively
    easy task to perform, and can allow you to write really clean, concise code.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Python 作为一门语言，以其强大的循环能力而著称。无论你是在处理列表还是字典，循环遍历 Python 对象通常是一个相对容易完成的任务，并且能够编写出非常简洁、清晰的代码。
- en: Even though pandas is a Python library, those same looping constructs are ironically
    an impediment to writing idiomatic, performant code. In contrast to looping, pandas
    offers *vectorized computations*, i.e, computations that work with all of the
    elements contained within a `pd.Series` but which do not require you to explicitly
    loop.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 pandas 是一个 Python 库，但这些相同的循环结构反而成为编写符合 Python 编程习惯且高效代码的障碍。与循环相比，pandas 提供了*向量化计算*，即对
    `pd.Series` 中的所有元素进行计算，而无需显式地循环。
- en: How to do it
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: 'Let’s start with a simple `pd.Series` constructed from a range:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个简单的 `pd.Series` 开始，这个 `pd.Series` 是由一个范围构造的：
- en: '[PRE31]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We could use the built-in `pd.Series.sum` method to easily calculate the summation:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用内置的 `pd.Series.sum` 方法轻松计算求和：
- en: '[PRE32]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Looping over the `pd.Series` and accumulating your own result will yield the
    same number:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历 `pd.Series` 并积累自己的结果会得到相同的数字：
- en: '[PRE34]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Yet the two code samples are nothing alike. With `pd.Series.sum`, pandas performs
    the summation of elements in a lower-level language like C, avoiding any interaction
    with the Python runtime. In pandas speak, we would refer to this as a *vectorized*
    function.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，两个代码示例完全不同。使用 `pd.Series.sum` 时，pandas 在低级语言（如 C）中执行元素求和，避免了与 Python 运行时的任何交互。在
    pandas 中，我们称之为*向量化*函数。
- en: By contrast, the `for` loop is handled by the Python runtime, and as you may
    or may not be aware, Python is a much slower language than C.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，`for` 循环由 Python 运行时处理，正如你可能知道的那样，Python 比 C 慢得多。
- en: 'To put some tangible numbers forth, we can run a simple timing benchmark using
    Python’s `timeit` module. Let’s start with `pd.Series.sum`:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供一些具体的数字，我们可以使用 Python 的 `timeit` 模块进行简单的时间基准测试。我们先从 `pd.Series.sum` 开始：
- en: '[PRE36]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let’s compare that to the Python loop:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其与 Python 循环进行比较：
- en: '[PRE38]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: That’s a huge slowdown with the loop!
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用循环会导致巨大的性能下降！
- en: Generally, you should look to use the built-in vectorized functions of pandas
    for most of your analysis needs. For more complex applications, reach for the
    `.agg`, `.transform`, `.map`, and `.apply` methods, which were covered back in
    *Chapter 5**, Algorithms and How to Apply Them*. You should be able to avoid using
    `for`loops in 99.99% of your analyses; if you find yourself using them more often,
    you should rethink your design, more than likely after a thorough re-read of *Chapter
    5**, Algorithms and How to Apply Them*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，你应该使用 pandas 内置的向量化函数来满足大多数分析需求。对于更复杂的应用，使用 `.agg`、`.transform`、`.map`
    和 `.apply` 方法，这些方法已经在*第五章，算法及其应用*中讲解过。你应该能避免在99.99%的分析中使用 `for` 循环；如果你发现自己更频繁地使用它们，可能需要重新考虑你的设计，通常可以通过仔细重读*第五章，算法及其应用*来解决。
- en: 'The one exception to this rule where it may make sense to use a `for`loop is
    when dealing with a `pd.GroupBy` object, which can be efficiently iterated like
    a dictionary:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个规则的唯一例外情况是当处理 `pd.GroupBy` 对象时，使用 `for` 循环可能更合适，因为它可以像字典一样高效地进行迭代：
- en: '[PRE40]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Avoid mutating data
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免修改数据
- en: Although pandas allows you to mutate data, the cost impact of doing so varies
    by data type. In some cases, it can be prohibitively expensive, so you will be
    best served trying to minimize mutations you have to perform at all costs.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 pandas 允许你修改数据，但修改的成本会根据数据类型有所不同。在某些情况下，这可能代价高昂，因此你应该尽可能地减少任何必须执行的修改操作。
- en: How to do it
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: 'When thinking about data mutation, a best effort should be made to mutate before
    loading into a pandas structure. We can easily illustrate a performance difference
    by comparing the time to mutate a record after loading it into a `pd.Series`:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑数据变更时，应该尽量在加载数据到 pandas 结构之前进行变更。我们可以通过比较加载到 `pd.Series` 后修改记录所需的时间，轻松地说明性能差异：
- en: '[PRE42]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'To the time it takes if the mutation was performed beforehand:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果变异事先执行，所需的时间：
- en: '[PRE44]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: There’s more…
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: You can go down a technical rabbit hole trying to decipher the impact of mutating
    various data types in pandas, across all of the different versions. However, starting
    in pandas 3.0, the behavior started to become more consistent with the introduction
    of Copy-on-Write, which was proposed as part of PDEP-07\. In essence, any time
    you try to mutate a `pd.Series` or `pd.DataFrame`, you end up with a copy of the
    original data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会陷入一个技术性的深坑，试图解读在不同版本的pandas中变异不同数据类型的影响。然而，从pandas 3.0开始，行为变得更加一致，这是由于引入了按需写入（Copy-on-Write），这一点是PDEP-07提案的一部分。简单来说，每次你尝试变异`pd.Series`或`pd.DataFrame`时，都会得到原始数据的一个副本。
- en: While this behavior is now easier to anticipate, it also means that mutations
    are potentially very expensive, especially if you try to mutate a large `pd.Series`
    or `pd.DataFrame`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种行为现在更容易预测，但也意味着变异可能非常昂贵，特别是如果你尝试变异一个大的`pd.Series`或`pd.DataFrame`。
- en: Dictionary-encode low cardinality data
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字典编码低基数数据
- en: Back in *Chapter 3*, *Data Types*, we talked about the categorical data type,
    which can help to reduce memory usage by replacing occurrences of strings (or
    any data type really) with much smaller integral code. While *Chapter 3*, *Data
    Types*, provides a good technical deep dive, it is worth restating this as a best
    practice here, given how significant of a saving this can represent when working
    with *low cardinality* data, i.e, data where the ratio of unique values to the
    overall record count is relatively low.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第3章*，*数据类型*中，我们讨论了分类数据类型，它可以通过将字符串（或任何数据类型）替换为更小的整数代码来减少内存使用。虽然*第3章*，*数据类型*提供了一个很好的技术深度讲解，但考虑到在处理*低基数*数据时，这可以带来显著的节省，因此在这里再强调一次作为最佳实践是值得的。*低基数*数据是指唯一值与总记录数的比率相对较低的数据。
- en: How to do it
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做
- en: 'Just to drive home the point about memory savings, let’s create a *low cardinality*
    `pd.Series`. Our `pd.Series` is going to have 300,000 rows of data, but only three
    unique values of `"foo"`, `"bar"`, and `"baz"`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步强调内存节省的观点，假设我们创建一个*低基数*的`pd.Series`。我们的`pd.Series`将有300,000行数据，但只有三个唯一值`"foo"`，`"bar"`和`"baz"`：
- en: '[PRE46]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Simply changing this to a categorical data type will yield massive memory improvements:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅将其更改为分类数据类型，就能大幅提升内存性能：
- en: '[PRE48]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Test-driven development features
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试驱动开发特点
- en: '**Test-driven development** (or **TDD**, for short) is a popular software development
    practice that aims to improve code quality and maintenance. At a high level, TDD
    starts with a developer creating tests that describe the expected functionality
    of their change. The tests start in a failed state, and the developer can become
    confident that their implementation is correct when the tests finally pass.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**测试驱动开发**（简称**TDD**）是一种流行的软件开发实践，旨在提高代码质量和可维护性。总体上，TDD从开发者编写测试开始，测试描述了对变更的预期功能。测试从失败状态开始，开发者在测试最终通过时，可以确信他们的实现是正确的。'
- en: Tests are often the first thing code reviewers look at when considering code
    changes (when contributing to pandas, tests are a must!). After a change with
    an accompanying test has been accepted, that same test will be re-run for any
    subsequent code changes, ensuring that your code base continues to work as expected
    over time. Generally, properly constructed tests can help your code base scale
    out, while mitigating the risk of regressions as you develop new features.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 测试通常是代码评审者在考虑代码变更时首先查看的内容（在贡献pandas时，测试是必须的！）。在接受了一个有测试的变更后，后续的任何代码变更都会重新运行该测试，确保你的代码库随着时间的推移继续按预期工作。通常，正确构造的测试可以帮助你的代码库扩展，同时在开发新特性时减轻回归的风险。
- en: The pandas library exposes utilities that make writing tests for your `pd.Series`
    and `pd.DataFrame` objects possible through the `pd.testing` module, which we
    will review in this recipe.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: pandas库提供了工具，使得你可以通过`pd.testing`模块为你的`pd.Series`和`pd.DataFrame`对象编写测试，我们将在本教程中进行回顾。
- en: How it works
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: The Python standard library offers the `unittest` module to declare and automate
    the execution of your tests. To create tests, you typically create a class that
    inherits from `unittest.TestCase`, and create methods on that class that make
    assertions about your program behavior.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Python标准库提供了`unittest`模块，用于声明和自动执行测试。创建测试时，通常会创建一个继承自`unittest.TestCase`的类，并在该类中创建方法来对程序行为进行断言。
- en: 'In the following code sample, the `MyTests.test_42` method is going to call
    `unittest.TestCase.assertEqual` with two arguments, `21 * 2` and `42`. Since those
    arguments are logically equal, the test execution will pass:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码示例中，`MyTests.test_42` 方法将调用 `unittest.TestCase.assertEqual`，并传入两个参数，`21
    * 2` 和 `42`。由于这两个参数在逻辑上是相等的，测试执行将通过：
- en: '[PRE50]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Now let’s try to follow that same execution framework with pandas, but instead
    of comparing `21 * 2` to `42`, we are going to try and compare two `pd.Series`
    objects:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试使用 pandas 遵循相同的执行框架，不过这次我们不是比较 `21 * 2` 和 `42`，而是尝试比较两个 `pd.Series` 对象：
- en: '[PRE52]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Well…that was surprising!
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 哦……这真是让人吃惊！
- en: The underlying issue here is that the call to `self.assertEqual(result, expected)`
    executes the expression `result == expected`. If the result of that expression
    were `True`, the test would pass; an expression that returns `False` would fail
    the test.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的根本问题是调用 `self.assertEqual(result, expected)` 执行表达式 `result == expected`。如果该表达式的结果是
    `True`，测试将通过；返回 `False` 的表达式将使测试失败。
- en: 'However, pandas overloads the equality operator for a `pd.Series`, so that
    instead of returning `True` or `False`, you actually get back another `pd.Series`
    with an element-wise comparison:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，pandas 重载了 `pd.Series` 的等于运算符，因此它不会返回 `True` 或 `False`，而是返回另一个进行逐元素比较的 `pd.Series`：
- en: '[PRE54]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Since testing frameworks don’t know what to make of this, you will have to
    reach for custom functions in the `pd.testing` namespace. For `pd.Series` comparison,
    `pd.testing.assert_series_equal` is the right tool for the job:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 由于测试框架不知道如何处理这个问题，你需要使用 `pd.testing` 命名空间中的自定义函数。对于 `pd.Series` 的比较，`pd.testing.assert_series_equal`
    是最合适的工具：
- en: '[PRE56]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'For completeness, let’s trigger an intentional failure and review the output:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，让我们触发一个故意的失败并查看输出：
- en: '[PRE58]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Within the test failure traceback, pandas is telling us that the data types
    of the compared objects are not the same. The result of a call to `some_cool_numbers`
    returns a `pd.Series` with a `pd.Int64Dtype`, whereas our expectation was looking
    for a `pd.Int32Dtype`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试失败的追踪信息中，pandas 告诉我们，比较对象的数据类型不同。调用 `some_cool_numbers` 返回一个带有 `pd.Int64Dtype`
    的 `pd.Series`，而我们的期望是 `pd.Int32Dtype`。
- en: While these examples focused on using `pd.testing.assert_series_equal`, the
    equivalent method for a `pd.DataFrame` is `pd.testing.assert_frame_equal`. Both
    of these functions know how to handle potentially different row indexes, column
    indexes, values, and missing value semantics, and will report back informative
    errors to the test runner if expectations are not met.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些示例集中在使用 `pd.testing.assert_series_equal`，但对于 `pd.DataFrame`，等效的方法是 `pd.testing.assert_frame_equal`。这两个函数知道如何处理可能不同的行索引、列索引、值和缺失值语义，并且如果期望不符合，它们会向测试运行器报告有用的错误信息。
- en: There’s more…
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: This recipe used the `unittest` module because it is built into the Python language.
    However, many large Python projects, particularly in the scientific Python space,
    use the `pytest` library to write and execute unit tests.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例使用了 `unittest` 模块，因为它是 Python 语言自带的。然而，许多大型 Python 项目，特别是在科学 Python 领域，使用
    `pytest` 库来编写和执行单元测试。
- en: In contrast to `unittest`, `pytest` abandons a class-based testing structure
    with `setUp` and `tearDown` methods, opting instead for a test fixture-based approach.
    A comparison of these two different testing paradigms can be found within the
    *pytest* documentation.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `unittest` 不同，`pytest` 放弃了基于类的测试结构（包括 `setUp` 和 `tearDown` 方法），转而采用基于测试夹具的方法。关于这两种不同测试范式的比较，可以在
    *pytest* 文档中找到。
- en: The `pytest` library also offers a rich set of plugins. Some plugins may aim
    to improve integration with third-party libraries (as is the case for `pytest-django`
    and `pytest-sqlalchemy`), whereas others may be focused on scaling your test suite
    to use all of your system’s resources (as is the case for `pytest-xdist`). There
    are countless plugin use cases in between, so I strongly recommend giving `pytest`
    and its plugin ecosystem a look for testing your Python code bases.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest` 库还提供了一套丰富的插件。有些插件可能旨在改善与第三方库的集成（比如 `pytest-django` 和 `pytest-sqlalchemy`），而其他插件则可能专注于扩展测试套件，利用系统的所有资源（例如
    `pytest-xdist`）。介于两者之间，还有无数的插件使用场景，因此我强烈建议你了解 `pytest` 及其插件生态系统，以便测试你的 Python
    代码库。'
- en: Join our community on Discord
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者一起讨论：
- en: '[https://packt.link/pandas](https://packt.link/pandas)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/pandas](https://packt.link/pandas)'
- en: '![](img/QR_Code5040900042138312.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code5040900042138312.png)'
