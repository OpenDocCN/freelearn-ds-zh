- en: Practical Machine Learning with Spark Using Scala
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark和Scala进行实用机器学习
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Configuring IntelliJ to work with Spark and run Spark ML sample codes
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置IntelliJ以与Spark配合工作并运行Spark ML示例代码
- en: Running a sample ML code from Spark
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行Spark中的示例ML代码
- en: Identifying data sources for practical machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别实用机器学习的数据源
- en: Running your first program using Apache Spark 2.0 with the IntelliJ IDE
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用IntelliJ IDE运行您的第一个Apache Spark 2.0程序
- en: How to add graphics to your Spark program
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何向您的Spark程序添加图形
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: With the recent advancements in cluster computing coupled with the rise of big
    data, the field of machine learning has been pushed to the forefront of computing.
    The need for an interactive platform that enables data science at scale has long been
    a dream that is now a reality.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 随着集群计算的最新进展，以及大数据的兴起，机器学习领域已被推到了计算的前沿。长期以来，人们一直梦想有一个能够实现大规模数据科学的交互式平台，现在这个梦想已成为现实。
- en: 'The following three areas together have enabled and accelerated interactive
    data science at scale:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以下三个领域的结合使得大规模交互式数据科学得以实现并加速发展：
- en: '**Apache Spark**: A unified technology platform for data science that combines
    a fast compute engine and fault-tolerant data structures into a well-designed
    and integrated offering'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Spark**：一个统一的数据科学技术平台，它将快速计算引擎和容错数据结构结合成一个设计精良且集成的解决方案'
- en: '**Machine learning**: A field of artificial intelligence that enables machines
    to mimic some of the tasks originally reserved exclusively for the human brain'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习**：人工智能的一个领域，使机器能够模仿原本专属于人脑的一些任务'
- en: '**Scala**: A modern JVM-based language that builds on traditional languages,
    but unites functional and object-oriented concepts without the verboseness of
    other languages'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scala**：一种基于现代JVM的语言，它建立在传统语言之上，但将函数式和面向对象的概念结合在一起，而不会像其他语言那样冗长'
- en: 'First, we need to set up the development environment, which will consist of
    the following components:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要设置开发环境，它将包括以下组件：
- en: Spark
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark
- en: IntelliJ community edition IDE
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IntelliJ社区版IDE
- en: Scala
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scala
- en: The recipes in this chapter will give you detailed instructions for installing
    and configuring the IntelliJ IDE, Scala plugin, and Spark. After the development
    environment is set up, we'll proceed to run one of the Spark ML sample codes to
    test the setup.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的配方将为您提供详细的安装和配置IntelliJ IDE、Scala插件和Spark的说明。开发环境设置完成后，我们将继续运行一个Spark ML示例代码来测试设置。
- en: Apache Spark
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark
- en: Apache Spark is emerging as the de facto platform and trade language for big
    data analytics and as a complement to the **Hadoop** paradigm. Spark enables a
    data scientist to work in the manner that is most conducive to their workflow
    right out of the box. Spark's approach is to process the workload in a completely
    distributed manner without the need for **MapReduce** (**MR**) or repeated writing
    of the intermediate results to a disk.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark正成为大数据分析的事实标准平台和行业语言，并作为**Hadoop**范式的补充。Spark使数据科学家能够以最有利于其工作流程的方式直接开始工作。Spark的方法是在完全分布式的方式下处理工作负载，无需**MapReduce**（**MR**）或重复将中间结果写入磁盘。
- en: Spark provides an easy-to-use distributed framework in a unified technology
    stack, which has made it the platform of choice for data science projects, which
    more often than not require an iterative algorithm that eventually merges toward
    a solution. These algorithms, due to their inner workings, generate a large ...
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供了一个易于使用的统一技术栈中的分布式框架，这使其成为数据科学项目的首选平台，这些项目往往需要一个最终合并到解决方案的迭代算法。由于这些算法的内部工作原理，它们会产生大量的...
- en: Machine learning
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: The aim of machine learning is to produce machines and devices that can mimic
    human intelligence and automate some of the tasks that have been traditionally
    reserved for a human brain. Machine learning algorithms are designed to go through
    very large data sets in a relatively short time and approximate answers that would
    have taken a human much longer to process.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的目的是制造能够模仿人类智能并自动化一些传统上由人脑完成的任务的机器和设备。机器学习算法旨在在相对较短的时间内处理大量数据集，并近似出人类需要更长时间才能处理出的答案。
- en: The field of machine learning can be classified into many forms and at a high
    level, it can be classified as supervised and unsupervised learning. Supervised
    learning algorithms are a class of ML algorithms that use a training set (that
    is, labeled data) to compute a probabilistic distribution or graphical model that
    in turn allows them to classify the new data points without further human intervention.
    Unsupervised learning is a type of machine learning algorithm used to draw inferences
    from datasets consisting of input data without labeled responses.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: （机器学习领域可以分为多种形式，从高层次上可以分为监督学习和无监督学习。监督学习算法是一类使用训练集（即标记数据）来计算概率分布或图形模型的 ML 算法，进而使它们能够在没有进一步人工干预的情况下对新数据点进行分类。无监督学习是一种机器学习算法，用于从没有标签响应的输入数据集中提取推断。）
- en: 'Out of the box, Spark offers a rich set of ML algorithms that can be deployed
    on large datasets without any further coding. The following figure depicts Spark''s
    MLlib algorithms as a mind map. Spark''s MLlib is designed to take advantage of
    parallelism while having fault-tolerant distributed data structures. Spark refers
    to such data structures as **Resilient Distributed Datasets** or **RDDs**:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: （Spark 开箱即提供丰富的 ML 算法集合，无需进一步编码即可部署在大型数据集上。下图展示了 Spark 的 MLlib 算法作为思维导图。Spark
    的 MLlib 旨在利用并行性，同时拥有容错分布式数据结构。Spark 将此类数据结构称为 **弹性分布式数据集** 或 **RDD**。）
- en: '![](img/2651bc34-49cd-4574-a38e-de98c563668e.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2651bc34-49cd-4574-a38e-de98c563668e.png)'
- en: Scala
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala
- en: '**Scala** is a modern programming language that is emerging as an alternative
    to traditional programming languages such as **Java** and **C++**. Scala is a
    JVM-based language that not only offers a concise syntax without the traditional
    boilerplate code, but also incorporates both object-oriented and functional programming
    into an extremely crisp and extraordinarily powerful type-safe language.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**Scala** 是一种新兴的现代编程语言，作为传统编程语言如 **Java** 和 **C++** 的替代品而崭露头角。Scala 是一种基于 JVM
    的语言，不仅提供简洁的语法，避免了传统的样板代码，还将面向对象和函数式编程融合到一个极其精炼且功能强大的类型安全语言中。'
- en: Scala takes a flexible and expressive approach, which makes it perfect for interacting
    with Spark's MLlib. The fact that Spark itself is written in Scala provides a
    strong evidence that the Scala language is a full-service programming language
    that can be used to create sophisticated system code with heavy performance needs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 采用灵活且富有表现力的方法，使其非常适合与 Spark 的 MLlib 交互。Spark 本身是用 Scala 编写的，这一事实有力地证明了
    Scala 语言是一种全功能编程语言，可用于创建具有高性能需求的复杂系统代码。
- en: Scala builds on Java's tradition ...
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 基于 Java 的传统...
- en: Software versions and libraries used in this book
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Software versions and libraries used in this book
- en: 'The following table provides a detailed list of software versions and libraries
    used in this book. If you follow the installation instructions covered in this
    chapter, it will include most of the items listed here. Any other JAR or library
    files that may be required for specific recipes are covered via additional installation
    instructions in the respective recipes:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 'The following table provides a detailed list of software versions and libraries
    used in this book. If you follow the installation instructions covered in this
    chapter, it will include most of the items listed here. Any other JAR or library
    files that may be required for specific recipes are covered via additional installation
    instructions in the respective recipes:'
- en: '| **Core systems** | **Version** |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **Core systems** | **Version** |'
- en: '| Spark | 2.0.0 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| Spark | 2.0.0 |'
- en: '| Java | 1.8 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| Java | 1.8 |'
- en: '| IntelliJ IDEA | 2016.2.4 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| IntelliJ IDEA | 2016.2.4 |'
- en: '| Scala-sdk | 2.11.8 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Scala-sdk | 2.11.8 |'
- en: 'Miscellaneous JARs that will be required are as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 'Miscellaneous JARs that will be required are as follows:'
- en: '| **Miscellaneous JARs** | **Version** |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| **Miscellaneous JARs** | **Version** |'
- en: '| `bliki-core` | 3.0.19 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| `bliki-core` | 3.0.19 |'
- en: '| `breeze-viz` | 0.12 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| `breeze-viz` | 0.12 |'
- en: '| `Cloud9` | 1.5.0 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| `Cloud9` | 1.5.0 |'
- en: '| `Hadoop-streaming` | 2.2.0 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `Hadoop-streaming` | 2.2.0 |'
- en: '| `JCommon` | 1.0.23 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `JCommon` | 1.0.23 |'
- en: '| `JFreeChart` | 1.0.19 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `JFreeChart` | 1.0.19 |'
- en: '| `lucene-analyzers-common` | 6.0.0 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `lucene-analyzers-common` | 6.0.0 |'
- en: '| `Lucene-Core` | 6.0.0 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `Lucene-Core` | 6.0.0 |'
- en: '| `scopt` | 3.3.0 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| `scopt` | 3.3.0 |'
- en: '| `spark-streaming-flume-assembly` | 2.0.0 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| `spark-streaming-flume-assembly` | 2.0.0 |'
- en: '| `spark-streaming-kafka-0-8-assembly` | 2.0.0 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `spark-streaming-kafka-0-8-assembly` | 2.0.0 |'
- en: We have additionally tested all the recipes in this book on Spark 2.1.1 and
    found that the programs executed as expected. It is recommended for learning purposes
    you use the software versions and libraries listed in these tables.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: We have additionally tested all the recipes in this book on Spark 2.1.1 and
    found that the programs executed as expected. It is recommended for learning purposes
    you use the software versions and libraries listed in these tables.
- en: To stay current with the rapidly changing Spark landscape and documentation,
    the API links to the Spark documentation mentioned throughout this book point
    to the latest version of Spark 2.x.x, but the API references in the recipes are
    explicitly for Spark 2.0.0.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟上快速变化的Spark环境和文档，本书中提到的Spark文档的API链接指向最新的Spark 2.x.x版本，但食谱中的API参考明确针对Spark
    2.0.0。
- en: 'All the Spark documentation links provided in this book will point to the latest
    documentation on Spark''s website. If you prefer to look for documentation for
    a specific version of Spark (for example, Spark 2.0.0), look for relevant documentation
    on the Spark website using the following URL:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本书提供的所有Spark文档链接将指向Spark网站上的最新文档。如果您希望查找特定版本的Spark（例如，Spark 2.0.0）的文档，请使用以下URL在Spark网站上查找相关文档：
- en: '[https://spark.apache.org/documentation.html](https://spark.apache.org/documentation.html)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/documentation.html](https://spark.apache.org/documentation.html)'
- en: We've made the code as simple as possible for clarity purposes rather than demonstrating
    the advanced features of Scala.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，我们已尽可能简化代码，而不是展示Scala的高级特性。
- en: Configuring IntelliJ to work with Spark and run Spark ML sample codes
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置IntelliJ以配合Spark运行Spark ML示例代码
- en: We need to run some configurations to ensure that the project settings are correct
    before being able to run the samples that are provided by Spark or any of the
    programs listed this book.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行Spark或本书列出的任何程序提供的示例之前，我们需要进行一些配置以确保项目设置正确。
- en: Getting ready
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: We need to be particularly careful when configuring the project structure and
    global libraries. After we set everything up, we proceed to run the sample ML
    code provided by the Spark team to verify the setup. Sample code can be found
    under the Spark directory or can be obtained by downloading the Spark source code
    with samples.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置项目结构和全局库时，我们需要特别小心。设置完成后，我们运行Spark团队提供的示例ML代码以验证安装。示例代码可在Spark目录下找到，或通过下载包含示例的Spark源代码获取。
- en: How to do it...
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The following are the steps for configuring IntelliJ to work with Spark MLlib
    and for running the sample ML code provided by Spark in the examples directory.
    The examples directory can be found in your home directory for Spark. Use the
    Scala samples to proceed:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是配置IntelliJ以配合Spark MLlib工作以及在示例目录中运行Spark提供的示例ML代码的步骤。示例目录可在您的Spark主目录中找到。使用Scala示例继续：
- en: 'Click on the Project Structure... option, as shown in the following screenshot,
    to configure project settings:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“项目结构...”选项，如以下截图所示，以配置项目设置：
- en: '![](img/0d1ca754-2685-4f65-8e23-80edaf3a3992.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0d1ca754-2685-4f65-8e23-80edaf3a3992.png)'
- en: 'Verify the settings:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证设置：
- en: '![](img/c7b7d942-4e71-4afe-bc92-afee16c93ecb.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c7b7d942-4e71-4afe-bc92-afee16c93ecb.png)'
- en: 'Configure Global Libraries. Select Scala SDK as your global library:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置全局库。选择Scala SDK作为您的全局库：
- en: Select the JARs for the new Scala SDK and let the download ...
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择新的Scala SDK的JAR文件并允许下载...
- en: There's more...
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Prior to Spark 2.0, we needed another library from Google called **Guava**
    for facilitating I/O and for providing a set of rich methods of defining tables
    and then letting Spark broadcast them across the cluster. Due to dependency issues
    that were hard to work around, Spark 2.0 no longer uses the Guava library. Make
    sure you use the Guava library if you are using Spark versions prior to 2.0 (required
    in version 1.5.2). The Guava library can be accessed at the following URL:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark 2.0之前，我们需要Google的另一个库**Guava**来促进I/O并提供定义表的一组丰富方法，然后让Spark在集群中广播它们。由于难以解决的依赖问题，Spark
    2.0不再使用Guava库。如果您使用的是2.0之前的Spark版本（在1.5.2版本中需要），请确保使用Guava库。Guava库可从此URL访问：
- en: '[https://github.com/google/guava/wiki](https://github.com/google/guava/wiki)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/google/guava/wiki](https://github.com/google/guava/wiki)'
- en: 'You may want to use Guava version 15.0, which can be found here:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能希望使用Guava版本15.0，该版本可在此处找到：
- en: '[https://mvnrepository.com/artifact/com.google.guava/guava/15.0](https://mvnrepository.com/artifact/com.google.guava/guava/15.0)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://mvnrepository.com/artifact/com.google.guava/guava/15.0](https://mvnrepository.com/artifact/com.google.guava/guava/15.0)'
- en: If you are using installation instructions from previous blogs, make sure to
    exclude the Guava library from the installation set.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用的是之前博客中的安装说明，请确保从安装集中排除Guava库。
- en: See also
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'If there are other third-party libraries or JARs required for the completion
    of the Spark installation, you can find those in the following Maven repository:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果完成Spark安装还需要其他第三方库或JAR，您可以在以下Maven仓库中找到它们：
- en: '[https://repo1.maven.org/maven2/org/apache/spark/](https://repo1.maven.org/maven2/org/apache/spark/)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://repo1.maven.org/maven2/org/apache/spark/](https://repo1.maven.org/maven2/org/apache/spark/)'
- en: Running a sample ML code from Spark
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Spark运行样本ML代码
- en: We can verify the setup by simply downloading the sample code from the Spark
    source tree and importing it into IntelliJ to make sure it runs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过简单地下载Spark源树中的样本代码并将其导入IntelliJ以确保其运行来验证设置。
- en: Getting ready
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: We will first run the logistic regression code from the samples to verify installation.
    In the next section, we proceed to write our own version of the same program and
    examine the output in order to understand how it works.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先运行样本中的逻辑回归代码以验证安装。在下一节中，我们将编写自己的版本并检查输出，以便理解其工作原理。
- en: How to do it...
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Go to the source directory and pick one of the ML sample code files to run.
    We've selected the logistic regression example.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到源目录并选择一个ML样本代码文件运行。我们选择了逻辑回归示例。
- en: If you cannot find the source code in your directory, you can always download
    the Spark source, unzip, and then extract the examples directory accordingly.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在目录中找不到源代码，您可以随时下载Spark源码，解压缩，然后相应地提取示例目录。
- en: 'After selecting the example, select Edit Configurations..., as shown in the
    following screenshot:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择示例后，选择“编辑配置...”，如下面的截图所示：
- en: '![](img/b0826b04-9920-401b-a74e-23c650d70b49.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b0826b04-9920-401b-a74e-23c650d70b49.png)'
- en: 'In the Configurations tab, define the following options:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在配置选项卡中，定义以下选项：
- en: 'VM options: The choice shown allows you to run a standalone Spark cluster'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: VM选项：所示选项允许您运行独立Spark集群
- en: 'Program arguments: What we are supposed to pass into the program'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序参数：我们需要传递给程序的内容
- en: '![](img/a74269e6-9e2a-49d7-8971-26c941a19264.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a74269e6-9e2a-49d7-8971-26c941a19264.png)'
- en: 'Run the logistic regression by going to Run ''LogisticRegressionExample'',
    as shown in the following screenshot:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过转到运行'LogisticRegressionExample'来运行逻辑回归，如下面的截图所示：
- en: '![](img/fcb89557-0451-4306-b937-972e2c1864bf.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fcb89557-0451-4306-b937-972e2c1864bf.png)'
- en: 'Verify the exit code and make sure it is as shown in the following screenshot:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证退出代码，并确保它与下面的截图所示相同：
- en: '![](img/64a1a0db-aae3-4870-bbfd-96ba850d663f.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/64a1a0db-aae3-4870-bbfd-96ba850d663f.png)'
- en: Identifying data sources for practical machine learning
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别实用机器学习的数据源
- en: Getting data for machine learning projects was a challenge in the past. However,
    now there is a rich set of public data sources specifically suitable for machine
    learning.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 过去为机器学习项目获取数据是一个挑战。然而，现在有一系列特别适合机器学习的公共数据源。
- en: Getting ready
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: In addition to the university and government sources, there are many other open
    sources of data that can be used to learn and code your own examples and projects.
    We will list the data sources and show you how to best obtain and download data
    for each chapter.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 除了大学和政府来源外，还有许多其他开放数据源可用于学习和编写自己的示例和项目。我们将列出数据源，并向您展示如何最好地获取和下载每章的数据。
- en: How to do it...
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The following is a list of open source data worth exploring if you would like
    to develop applications in this field:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些值得探索的开源数据列表，如果您想在此领域开发应用程序：
- en: '*UCI machine learning repository*: This is an extensive library with search
    functionality. At the time of writing, there were more than 350 datasets. You
    can click on the [https://archive.ics.uci.edu/ml/index.html](https://archive.ics.uci.edu/ml/index.html)
    link to see all the datasets or look for a specific set using a simple search
    (*Ctrl* + *F*).'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*UCI机器学习库*：这是一个具有搜索功能的广泛库。在撰写本文时，已有超过350个数据集。您可以点击[https://archive.ics.uci.edu/ml/index.html](https://archive.ics.uci.edu/ml/index.html)链接查看所有数据集，或使用简单搜索（*Ctrl*
    + *F*）查找特定数据集。'
- en: '*Kaggle datasets*: You need to create an account, but you can download any
    sets for learning as well as for competing in machine learning competitions. The
    [https://www.kaggle.com/competitions](https://www.kaggle.com/competitions) link
    provides details for exploring and learning more about Kaggle, and the inner workings
    of machine learning competitions. ...'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kaggle数据集*：你需要创建一个账户，但你可以下载任何用于学习和参加机器学习竞赛的数据集。[https://www.kaggle.com/competitions](https://www.kaggle.com/competitions)链接提供了探索和了解更多关于Kaggle以及机器学习竞赛内部运作的详细信息。...'
- en: See also
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'Other sources for machine learning data:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习数据的其它来源：
- en: 'SMS spam data: [http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SMS垃圾邮件数据：[http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)
- en: Financial dataset from Lending Club [https://www.lendingclub.com/info/download-data.action](https://www.lendingclub.com/info/download-data.action)
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自Lending Club的金融数据集 [https://www.lendingclub.com/info/download-data.action](https://www.lendingclub.com/info/download-data.action)
- en: Research data from Yahoo [http://webscope.sandbox.yahoo.com/index.php](http://webscope.sandbox.yahoo.com/index.php)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雅虎的研究数据 [http://webscope.sandbox.yahoo.com/index.php](http://webscope.sandbox.yahoo.com/index.php)
- en: Amazon AWS public dataset [http://aws.amazon.com/public-data-sets/](http://aws.amazon.com/public-data-sets/)
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊AWS公共数据集 [http://aws.amazon.com/public-data-sets/](http://aws.amazon.com/public-data-sets/)
- en: Labeled visual data from Image Net [http://www.image-net.org](http://www.image-net.org)
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自ImageNet的标记视觉数据 [http://www.image-net.org](http://www.image-net.org)
- en: Census datasets [http://www.census.gov](http://www.census.gov)
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口普查数据集 [http://www.census.gov](http://www.census.gov)
- en: Compiled YouTube dataset [http://netsg.cs.sfu.ca/youtubedata/](http://netsg.cs.sfu.ca/youtubedata/)
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译的YouTube数据集 [http://netsg.cs.sfu.ca/youtubedata/](http://netsg.cs.sfu.ca/youtubedata/)
- en: Collected rating data from the MovieLens site [http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自MovieLens网站的收集评分数据 [http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)
- en: Enron dataset available to the public [http://www.cs.cmu.edu/~enron/](http://www.cs.cmu.edu/~enron/)
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公开的安然数据集 [http://www.cs.cmu.edu/~enron/](http://www.cs.cmu.edu/~enron/)
- en: Dataset for the classic book elements of statistical learning [http://statweb.stanford.edu/~tibs/ElemStatLearn/data.htmlIMDB](http://statweb.stanford.edu/~tibs/ElemStatLearn/data.htmlIMDB)
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经典书籍《统计学习要素》的数据集 [http://statweb.stanford.edu/~tibs/ElemStatLearn/data.htmlIMDB](http://statweb.stanford.edu/~tibs/ElemStatLearn/data.htmlIMDB)
- en: Movie dataset [http://www.imdb.com/interfaces](http://www.imdb.com/interfaces)
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影数据集 [http://www.imdb.com/interfaces](http://www.imdb.com/interfaces)
- en: Million Song dataset [http://labrosa.ee.columbia.edu/millionsong/](http://labrosa.ee.columbia.edu/millionsong/)
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 百万歌曲数据集 [http://labrosa.ee.columbia.edu/millionsong/](http://labrosa.ee.columbia.edu/millionsong/)
- en: Dataset for speech and audio [http://labrosa.ee.columbia.edu/projects/](http://labrosa.ee.columbia.edu/projects/)
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音和音频数据集 [http://labrosa.ee.columbia.edu/projects/](http://labrosa.ee.columbia.edu/projects/)
- en: Face recognition data [http://www.face-rec.org/databases/](http://www.face-rec.org/databases/)
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸识别数据 [http://www.face-rec.org/databases/](http://www.face-rec.org/databases/)
- en: Social science data [http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies](http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies)
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会科学数据 [http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies](http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies)
- en: Bulk datasets from Cornell University [http://arxiv.org/help/bulk_data_s3](http://arxiv.org/help/bulk_data_s3)
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 康奈尔大学的大量数据集 [http://arxiv.org/help/bulk_data_s3](http://arxiv.org/help/bulk_data_s3)
- en: Project Guttenberg datasets [http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs](http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs)
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 古腾堡项目数据集 [http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs](http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs)
- en: Datasets from World Bank [http://data.worldbank.org](http://data.worldbank.org)
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 世界银行数据集 [http://data.worldbank.org](http://data.worldbank.org)
- en: Lexical database from World Net [http://wordnet.princeton.edu](http://wordnet.princeton.edu)
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 世界词网词汇数据库 [http://wordnet.princeton.edu](http://wordnet.princeton.edu)
- en: Collision data from NYPD [http://nypd.openscrape.com/#/](http://nypd.openscrape.com/#/)
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纽约警察局的碰撞数据 [http://nypd.openscrape.com/#/](http://nypd.openscrape.com/#/)
- en: Dataset for congressional row calls and others [http://voteview.com/dwnl.htm](http://voteview.com/dwnl.htm)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 国会唱名表决等数据集 [http://voteview.com/dwnl.htm](http://voteview.com/dwnl.htm)
- en: Large graph datasets from Stanford [http://snap.stanford.edu/data/index.html](http://snap.stanford.edu/data/index.html)
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斯坦福大学的大型图数据集 [http://snap.stanford.edu/data/index.html](http://snap.stanford.edu/data/index.html)
- en: Rich set of data from datahub [https://datahub.io/dataset](https://datahub.io/dataset)
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自datahub的丰富数据集 [https://datahub.io/dataset](https://datahub.io/dataset)
- en: Yelp's academic dataset [https://www.yelp.com/academic_dataset](https://www.yelp.com/academic_dataset)
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yelp的学术数据集 [https://www.yelp.com/academic_dataset](https://www.yelp.com/academic_dataset)
- en: Source of data from GitHub [https://github.com/caesar0301/awesome-public-datasets](https://github.com/caesar0301/awesome-public-datasets)
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub上的数据源 [https://github.com/caesar0301/awesome-public-datasets](https://github.com/caesar0301/awesome-public-datasets)
- en: Dataset archives from Reddit [https://www.reddit.com/r/datasets/](https://www.reddit.com/r/datasets/)
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自Reddit的数据集存档 [https://www.reddit.com/r/datasets/](https://www.reddit.com/r/datasets/)
- en: 'There are some specialized datasets (for example, text analytics in Spanish,
    and gene and IMF data) that might be of some interest to you:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些专业数据集（例如，西班牙语文本分析数据集，以及基因和IMF数据）可能对您有所帮助：
- en: 'Datasets from Colombia (in Spanish): [http://www.datos.gov.co/frm/buscador/frmBuscador.aspx](http://www.datos.gov.co/frm/buscador/frmBuscador.aspx)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自哥伦比亚的数据集（西班牙语）：[http://www.datos.gov.co/frm/buscador/frmBuscador.aspx](http://www.datos.gov.co/frm/buscador/frmBuscador.aspx)
- en: Dataset from cancer studies [http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi](http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi)
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自癌症研究的数据集 [http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi](http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi)
- en: Research data from Pew [http://www.pewinternet.org/datasets/](http://www.pewinternet.org/datasets/)
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自皮尤研究中心的研究数据 [http://www.pewinternet.org/datasets/](http://www.pewinternet.org/datasets/)
- en: Data from the state of Illinois/USA [https://data.illinois.gov](https://data.illinois.gov)
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自美国伊利诺伊州的数据 [https://data.illinois.gov](https://data.illinois.gov)
- en: Data from freebase.com [http://www.freebase.com](http://www.freebase.com)
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自freebase.com的数据 [http://www.freebase.com](http://www.freebase.com)
- en: Datasets from the UN and its associated agencies [http://data.un.org](http://data.un.org)
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联合国及其附属机构的数据集 [http://data.un.org](http://data.un.org)
- en: International Monetary Fund datasets [http://www.imf.org/external/data.htm](http://www.imf.org/external/data.htm)
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 国际货币基金组织数据集 [http://www.imf.org/external/data.htm](http://www.imf.org/external/data.htm)
- en: UK government data [https://data.gov.uk](https://data.gov.uk)
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英国政府数据 [https://data.gov.uk](https://data.gov.uk)
- en: Open data from Estonia [http://pub.stat.ee/px-web.2001/Dialog/statfile1.asp](http://pub.stat.ee/px-web.2001/Dialog/statfile1.asp)
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自爱沙尼亚的开放数据 [http://pub.stat.ee/px-web.2001/Dialog/statfile1.asp](http://pub.stat.ee/px-web.2001/Dialog/statfile1.asp)
- en: Many ML libraries in R containing data that can be exported as CSV [https://www.r-project.org](https://www.r-project.org)
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R语言中许多包含数据并可导出为CSV的ML库 [https://www.r-project.org](https://www.r-project.org)
- en: Gene expression datasets [http://www.ncbi.nlm.nih.gov/geo/](http://www.ncbi.nlm.nih.gov/geo/)
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基因表达数据集 [http://www.ncbi.nlm.nih.gov/geo/](http://www.ncbi.nlm.nih.gov/geo/)
- en: Running your first program using Apache Spark 2.0 with the IntelliJ IDE
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用IntelliJ IDE运行您的第一个Apache Spark 2.0程序
- en: The purpose of this program is to get you comfortable with compiling and running
    a recipe using the Spark 2.0 development environment you just set up. We will
    explore the components and steps in later chapters.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 本程序的目的是让您熟悉使用刚设置的Spark 2.0开发环境编译和运行示例。我们将在后续章节中探讨组件和步骤。
- en: We are going to write our own version of the Spark 2.0.0 program and examine
    the output so we can understand how it works. To emphasize, this short recipe
    is only a simple RDD program with Scala sugar syntax to make sure you have set
    up your environment correctly before starting to work with more complicated recipes.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将编写自己的Spark 2.0.0程序版本，并检查输出，以便理解其工作原理。需要强调的是，这个简短的示例仅是一个简单的RDD程序，使用了Scala的糖语法，以确保在开始处理更复杂的示例之前，您已正确设置了环境。
- en: How to do it...
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含了必要的JAR文件。
- en: Download the sample code for the book, find the `myFirstSpark20.scala` file,
    and place the code in the following directory.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载本书的示例代码，找到`myFirstSpark20.scala`文件，并将代码放置在以下目录中。
- en: We installed Spark 2.0 in the `C:\spark-2.0.0-bin-hadoop2.7\` directory on a
    Windows machine.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在Windows机器上的`C:\spark-2.0.0-bin-hadoop2.7\`目录下安装了Spark 2.0。
- en: 'Place the `myFirstSpark20.scala` file in the `C:\spark-2.0.0-bin-hadoop2.7\examples\src\main\scala\spark\ml\cookbook\chapter1` directory:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`myFirstSpark20.scala`文件放置在`C:\spark-2.0.0-bin-hadoop2.7\examples\src\main\scala\spark\ml\cookbook\chapter1`目录下：
- en: '![](img/c91a16fa-6bd9-4971-b0db-e96b39641279.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c91a16fa-6bd9-4971-b0db-e96b39641279.png)'
- en: Mac users note that we installed Spark 2.0 in the `/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/`
    directory on a Mac machine.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Mac用户请注意，我们在Mac机器上的`/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/`目录下安装了Spark
    2.0。
- en: Place the `myFirstSpark20.scala` file in the `/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/examples/src/main/scala/spark/ml/cookbook/chapter1`
    directory.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 将`myFirstSpark20.scala`文件放置在`/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/examples/src/main/scala/spark/ml/cookbook/chapter1`目录下。
- en: 'Set up the package location where the program will reside:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置程序将驻留的包位置：
- en: '[PRE0]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Import the necessary packages for the Spark session to gain access to the cluster
    and `log4j.Logger` to reduce the amount of output produced by Spark:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使Spark会话能够访问集群并使用`log4j.Logger`减少Spark产生的输出量，导入必要的包：
- en: '[PRE1]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Set output level to `ERROR` to reduce Spark''s logging output:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输出级别设置为`ERROR`以减少Spark的日志输出：
- en: '[PRE2]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Initialize a Spark session by specifying configurations with the builder pattern,
    thus making an entry point available for the Spark cluster:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用构建器模式指定配置来初始化Spark会话，从而为Spark集群提供一个入口点：
- en: '[PRE3]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `myFirstSpark20` object will run in local mode. The previous code block
    is a typical way to start creating a `SparkSession` object.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`myFirstSpark20`对象将在本地模式下运行。前面的代码块是创建`SparkSession`对象的典型方式。'
- en: 'We then create two array variables:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们创建两个数组变量：
- en: '[PRE4]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We then let Spark create two RDDs based on the array created before:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后让Spark基于之前创建的数组创建两个RDD：
- en: '[PRE5]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, we let Spark operate on the `RDD`; the `zip()` function will create a
    new `RDD` from the two RDDs mentioned before:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们让Spark对`RDD`进行操作；`zip()`函数将从之前提到的两个RDD创建一个新的`RDD`：
- en: '[PRE6]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the console output at runtime (more details on how to run the program in
    the IntelliJ IDE in the following steps), you will see this:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行时控制台输出（关于如何在IntelliJ IDE中运行程序的更多详细信息将在后续步骤中介绍），您将看到这个：
- en: '![](img/9282b5ba-0927-4911-94c5-1cc2ee084d2f.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9282b5ba-0927-4911-94c5-1cc2ee084d2f.png)'
- en: 'Now, we sum up the value for `xRDD` and `yRDD` and calculate the new `zipedRDD`
    sum value. We also calculate the item count for `zipedRDD`:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们汇总`xRDD`和`yRDD`的值，并计算新的`zipedRDD`总和值。我们还计算了`zipedRDD`的项目计数：
- en: '[PRE7]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We print out the value calculated previously in the console:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在控制台上打印出之前计算的值：
- en: '[PRE8]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here''s the console output:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是控制台输出：
- en: '![](img/8584177e-8723-4303-af1d-472174b89309.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8584177e-8723-4303-af1d-472174b89309.png)'
- en: 'We close the program by stopping the Spark session:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过停止Spark会话来关闭程序：
- en: '[PRE9]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once the program is complete, the layout of `myFirstSpark20.scala` in the IntelliJ
    project explorer will look like the following:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序完成后，`myFirstSpark20.scala`在IntelliJ项目资源管理器中的布局将如下所示：
- en: '![](img/499b8f6b-90d1-4b13-a84b-5b2fed8873a7.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/499b8f6b-90d1-4b13-a84b-5b2fed8873a7.png)'
- en: 'Make sure there is no compiling error. You can test this by rebuilding the
    project:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保没有编译错误。您可以通过重建项目来测试这一点：
- en: '![](img/65f74350-8ff4-4239-a524-0c9575256308.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/65f74350-8ff4-4239-a524-0c9575256308.png)'
- en: 'Once the rebuild is complete, there should be a build completed message on
    the console:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦重建完成，控制台上应该会出现构建完成的消息：
- en: '[PRE10]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You can run the previous program by right-clicking on `the myFirstSpark20` object
    in the project explorer and selecting the context menu option (shown in the next
    screenshot) called `Run myFirstSpark20`.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过在项目资源管理器中右键点击`myFirstSpark20`对象并选择上下文菜单选项（如下一张截图所示）`运行myFirstSpark20`来运行前面的程序。
- en: You can also use the Run menu from the menu bar to perform the same action.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以从菜单栏的“运行”菜单执行相同的操作。
- en: '![](img/8b54aab8-e7da-496d-9c2e-73458fc9d172.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b54aab8-e7da-496d-9c2e-73458fc9d172.png)'
- en: 'Once the program is successfully executed, you will see the following message:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦程序成功执行，您将看到以下消息：
- en: '[PRE11]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This is also shown in the following screenshot:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这也显示在下面的截图中：
- en: '![](img/f541842c-fa04-4078-a14d-23fc23f0b625.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f541842c-fa04-4078-a14d-23fc23f0b625.png)'
- en: Mac users with IntelliJ will be able to perform this action using the same context
    menu.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: IntelliJ的Mac用户可以使用相同的上下文菜单执行此操作。
- en: Place the code in the correct path.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码放置在正确的路径上。
- en: How it works...
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this example, we wrote our first Scala program, `myFirstSpark20.scala`, and
    displayed the steps to execute the program in IntelliJ. We placed the code in
    the path described in the steps for both Windows and Mac.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们编写了第一个Scala程序`myFirstSpark20.scala`，并在IntelliJ中展示了执行该程序的步骤。我们按照步骤中描述的路径，在Windows和Mac上都放置了代码。
- en: In the `myFirstSpark20` code, we saw a typical way to create a `SparkSession`
    object and how to configure it to run in local mode using the `master()` function.
    We created two RDDs out of the array objects and used a simple `zip()` function
    to create a new RDD.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在`myFirstSpark20`代码中，我们看到了创建`SparkSession`对象的典型方式，以及如何使用`master()`函数配置它以在本地模式下运行。我们从数组对象创建了两个RDD，并使用简单的`zip()`函数创建了一个新的RDD。
- en: We also did a simple sum calculation on the RDDs that were created and then
    displayed the result in the console. Finally, we exited and released the resource
    by calling `spark.stop()`.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还对创建的RDD进行了简单的求和计算，并在控制台中显示了结果。最后，我们通过调用`spark.stop()`退出并释放资源。
- en: There's more...
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Spark can be downloaded from [http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Spark可以从[http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)下载。
- en: Documentation for Spark 2.0 related to RDD can be found at [http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations](http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 2.0关于RDD的文档可以在[http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations](http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations)找到。
- en: See also
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: More information about JetBrain IntelliJ can be found at [https://www.jetbrains.com/idea/](https://www.jetbrains.com/idea/).
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于JetBrain IntelliJ的更多信息，请访问[https://www.jetbrains.com/idea/](https://www.jetbrains.com/idea/)。
- en: How to add graphics to your Spark program
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何向你的Spark程序添加图形
- en: In this recipe, we discuss how to use JFreeChart to add a graphic chart to your
    Spark 2.0.0 program.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们讨论了如何使用JFreeChart向你的Spark 2.0.0程序添加图形图表。
- en: How to do it...
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Set up the JFreeChart library. JFreeChart JARs can be downloaded from the [https://sourceforge.net/projects/jfreechart/files/](https://sourceforge.net/projects/jfreechart/files/)
    site.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置JFreeChart库。JFreeChart的JAR文件可以从[https://sourceforge.net/projects/jfreechart/files/](https://sourceforge.net/projects/jfreechart/files/)网站下载。
- en: 'The JFreeChart version we have covered in this book is JFreeChart 1.0.19, as
    can be seen in the following screenshot. It can be downloaded from the [https://sourceforge.net/projects/jfreechart/files/1.%20JFreeChart/1.0.19/jfreechart-1.0.19.zip/download](https://sourceforge.net/projects/jfreechart/files/1.%20JFreeChart/1.0.19/jfreechart-1.0.19.zip/download) site:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本书中介绍的JFreeChart版本为JFreeChart 1.0.19，如以下截图所示。它可以从[https://sourceforge.net/projects/jfreechart/files/1.%20JFreeChart/1.0.19/jfreechart-1.0.19.zip/download](https://sourceforge.net/projects/jfreechart/files/1.%20JFreeChart/1.0.19/jfreechart-1.0.19.zip/download)网站下载：
- en: '![](img/39158216-47c5-4394-bf11-f9e4d0883505.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/39158216-47c5-4394-bf11-f9e4d0883505.png)'
- en: Once the ZIP file is downloaded, extract it. We extracted the ZIP file under
    `C:\` for a Windows machine, then proceed to find the `lib` directory under the
    extracted destination directory.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载ZIP文件后，将其解压。我们在Windows机器上的`C:\`下解压了ZIP文件，然后继续在解压的目标目录下找到`lib`目录。
- en: We then find the two libraries we need (JFreeChart ...
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们找到了所需的两个库（JFreeChart...
- en: How it works...
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this example, we wrote `MyChart.scala` and saw the steps for executing the
    program in IntelliJ. We placed code in the path described in the steps for both
    Windows and Mac.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们编写了`MyChart.scala`，并看到了在IntelliJ中执行程序的步骤。我们按照步骤中描述的路径在Windows和Mac上放置了代码。
- en: In the code, we saw a typical way to create the `SparkSession` object and how
    to use the `master()` function. We created an RDD out of an array of random integers
    in the range of 1 to 15 and zipped it with the Index.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，我们看到了创建`SparkSession`对象的典型方法以及如何使用`master()`函数。我们创建了一个RDD，其元素为1到15范围内的随机整数数组，并将其与索引进行了压缩。
- en: We then used JFreeChart to compose a basic chart that contains a simple *x*
    and *y* axis, and supplied the chart with the dataset we generated from the original
    RDD in the previous steps.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用JFreeChart制作了一个包含简单*x*和*y*轴的基本图表，并提供了我们从前几步中的原始RDD生成的数据集。
- en: We set up the schema for the chart and called the `show()` function in JFreeChart
    to show a Frame with the *x* and *y* axes displayed as a linear graphical chart.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为图表设置了架构，并在JFreeChart中调用`show()`函数，以显示一个带有*x*和*y*轴的线性图形图表的框架。
- en: Finally, we exited and released the resource by calling `spark.stop()`.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过调用`spark.stop()`退出并释放资源。
- en: There's more...
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'More about JFreeChart can be found here:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于JFreeChart的信息，请访问：
- en: '[http://www.jfree.org/jfreechart/](http://www.jfree.org/jfreechart/)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.jfree.org/jfreechart/](http://www.jfree.org/jfreechart/)'
- en: '[http://www.jfree.org/jfreechart/api/javadoc/index.html](http://www.jfree.org/jfreechart/api/javadoc/index.html)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.jfree.org/jfreechart/api/javadoc/index.html](http://www.jfree.org/jfreechart/api/javadoc/index.html)'
- en: See also
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'Additional examples about the features and capabilities of JFreeChart can be
    found at the following website:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 关于JFreeChart功能和能力的更多示例，请访问以下网站：
- en: '[http://www.jfree.org/jfreechart/samples.html](http://www.jfree.org/jfreechart/samples.html)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.jfree.org/jfreechart/samples.html](http://www.jfree.org/jfreechart/samples.html)'
