- en: Chapter 6. Beyond the Linear Trend Line (authored by Renata Nemeth and Gergely
    Toth)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 超越线性趋势线（由Renata Nemeth和Gergely Toth撰写）
- en: Linear regression models, which we covered in the previous chapter, can handle
    continuous responses that have a linear association with the predictors. In this
    chapter, we will extend these models to allow the response variable to differ
    in distribution. But, before getting our hands dirty with the generalized linear
    models, we need to stop for a while and discuss regression models in general.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章中讨论的线性回归模型可以处理与预测变量具有线性关联的连续响应变量。在本章中，我们将扩展这些模型，允许响应变量在分布上有所不同。但在我们深入探讨广义线性模型之前，我们需要停下来讨论一下回归模型的一般情况。
- en: The modeling workflow
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模工作流程
- en: First, some words about the terminology. Statisticians call the *Y* variable
    the response, the outcome, or the dependent variable. The *X* variables are often
    called the predictors, the explanatory variables, or the independent variables.
    Some of the predictors are of our main interest, other predictors are added just
    because they are potential confounders. Continuous predictors are sometimes called
    covariates.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们谈谈术语。统计学家将 *Y* 变量称为响应变量、结果变量或因变量。*X* 变量通常被称为预测变量、解释变量或自变量。其中一些预测变量是我们主要感兴趣的，而其他预测变量只是因为它们可能是潜在的混杂因素而被添加。连续预测变量有时被称为协变量。
- en: The GLM is a generalization of linear regression. GLM (also referred to as `glm`
    in R, from the `stats` package) allows the predictors to be related to the response
    variable via a link function, and by allowing the magnitude of the variance of
    each measurement to be a function of its predicted value.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 广义线性模型（GLM）是线性回归的推广。GLM（在R中称为`glm`，来自`stats`包）允许预测变量通过链接函数与响应变量相关联，并通过允许每个测量的方差的大小是预测值的函数。
- en: Whatever regression model you use, the main question is, "in what form can we
    add continuous predictors to the model?" If the relationship between the response
    and the predictor does not meet the model assumptions, you can transform the variable
    in some way. For example, a logarithmic or quadratic transformation in a linear
    regression model is a very common way to solve the problem of non-linear relationships
    between the independent and dependent variables via linear formulas.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用哪种回归模型，主要问题是：“我们可以在什么形式下将连续预测因子添加到模型中？”如果响应变量和预测变量之间的关系不符合模型假设，你可以通过某种方式变换变量。例如，在线性回归模型中，对数或二次变换是一种非常常见的通过线性公式解决独立变量和因变量之间非线性关系问题的方法。
- en: Or, you can transform the continuous predictor into a discrete one by subdividing
    its range in a proper way. When choosing the classes, one of the best options
    is to follow some convention, like choosing 18 as a cut-point in the case of age.
    Or you can follow a more technical way, for example, by categorizing the predictor
    into quantiles. An advanced way to go about this process would be to use some
    classification or regression trees, on which you will be able to read more in
    [Chapter 10](ch10.html "Chapter 10. Classification and Clustering"), *Classification
    and Clustering*.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以通过适当细分其范围将连续预测因子转换为离散的。在选择类别时，最好的选择之一是遵循某些惯例，例如在年龄的情况下选择18岁作为截断点。或者，你可以遵循更技术的方法，例如通过将预测变量分类到分位数。处理此过程的更高级方法之一是使用某些分类或回归树，你可以在第10章[分类和聚类](ch10.html
    "第10章. 分类和聚类")中了解更多信息。
- en: Discrete predictors can be added to the model as dummy variables using reference
    category coding, as we have seen in the previous chapter for linear regression
    models.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 离散预测因子可以通过参考类别编码添加到模型中，就像我们在上一章中为线性回归模型所做的那样。
- en: 'But how do we actually build a model? We have compiled a general workflow to
    answer this question:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们实际上如何构建模型呢？我们已经编制了一个通用工作流程来回答这个问题：
- en: First, fit the model with the main predictors and all the relevant confounders,
    and then reduce the number of confounders by dropping out the non-significant
    ones. There are some automatic procedures (such as backward elimination) for this.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，用主要预测因子和所有相关混杂因素拟合模型，然后通过删除非显著的混杂因素来减少混杂因素的数量。为此有一些自动程序（例如向后消除）。
- en: Note
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The given sample size limits the number of predictors. A rule of thumb for the
    required sample size is that you should have at least 20 observations per predictor.
  id: totrans-11
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 给定的样本大小限制了预测因子的数量。一个关于所需样本大小的经验法则是，你应该每个预测因子至少有20个观测值。
- en: Decide whether to use the continuous variables in their original or categorized
    form.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决定是否使用连续变量在其原始形式或分类形式中。
- en: Try to achieve a better fit by testing for non-linear relationships, if they
    are pragmatically relevant.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果它们在实用上相关，尝试通过测试非线性关系来提高拟合度。
- en: Finally, check the model assumptions.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，检查模型假设。
- en: And how do we find the best model? Is it as simple as the better the fit, the
    better the model? Unfortunately not. Our aim is to find the best fitting model,
    but with as few predictors as possible. A good model fit and a low number of independent
    variables are contradictory to each other.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那我们如何找到最佳模型呢？是不是拟合度越好，模型就越好？不幸的是并非如此。我们的目标是找到最佳拟合模型，但尽可能少地使用预测变量。良好的模型拟合和独立变量的低数量是相互矛盾的。
- en: As we have seen earlier, entering newer predictors into a linear regression
    model always increases the value of R-squared, and it may result in an over-fitted
    model. Overfitting means that the model describes the sample with its random noise,
    instead of the underlying data-generating process. Overfitting occurs, for example,
    when we have too many predictors in the model for its sample size to accommodate.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，将新的预测变量输入到线性回归模型中总是会增加R-squared的值，这可能会导致过度拟合的模型。过度拟合意味着模型描述的是样本的随机噪声，而不是潜在的数据生成过程。例如，当我们模型中的预测变量太多，以至于无法适应样本大小时，就会发生过度拟合。
- en: Consequently, the best model gives the desired level of fit with as few predictors
    as possible. AIC is one of those proper measures that takes into account both
    fit and parsimony. We highly recommend using it when comparing different models,
    which is very easy via the `AIC` function from the `stats` package.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最佳模型以尽可能少的预测变量给出所需的拟合水平。AIC是那些考虑拟合和简洁性的适当度量之一。我们强烈建议在比较不同模型时使用它，这可以通过`stats`包中的`AIC`函数非常容易地完成。
- en: Logistic regression
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: So far, we have discussed linear regression models, an appropriate method to
    model continuous response variables. However, non-continuous, binary responses
    (such as being ill or healthy, being faithful or deciding to switch to a new job,
    mobile supplier or partner) are also very common. The main difference compared
    to the continuous case is that now we should rather model probability instead
    of the expected value of the response variable.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论了线性回归模型，这是建模连续响应变量的适当方法。然而，非连续的二进制响应（如生病或健康，忠诚或决定换工作，移动供应商或合作伙伴）也非常常见。与连续情况相比，主要区别在于现在我们应该而不是建模响应变量的期望值，而是建模概率。
- en: The naive solution would be to use the probability as outcome in a linear model.
    But the problem with this solution is that the probability should be always between
    0 and 1, and this bounded range is not guaranteed at all when using a linear model.
    A better solution is to fit a logistic regression model, which models not only
    the probability but also the natural logarithm of the odds, called the **logit**.
    The logit can be any (positive or negative) number, so the problem of limited
    range is eliminated.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 天真的解决方案是在线性模型中将概率作为结果。但这个解决方案的问题在于概率应该始终在0和1之间，而使用线性模型时，这个有界范围根本无法保证。更好的解决方案是拟合逻辑回归模型，它不仅建模概率，还建模称为**logit**的赔率的自然对数。logit可以是任何（正或负）数字，因此消除了范围有限的问题。
- en: Let's have a simple example of predicting the probability of the death penalty,
    using some information on the race of the defendant. This model relates to the
    much more complicated issue of racism in the infliction of the death penalty,
    a question with a long history in the USA. We will use the `deathpenalty` dataset
    from the `catdata` package about the judgment of defendants in cases of multiple
    murders in Florida between 1976 and 1987\. The cases are classified with respect
    to the death penalty (where 0 refers to no, 1 to yes), the race of the defendant,
    and the race of the victim (black is referred as 0, white is 1).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个简单的例子来说明如何预测死刑的概率，使用一些关于被告种族的信息。这个模型与死刑执行中的种族主义问题密切相关，这是一个在美国有着悠久历史的问题。我们将使用来自`catdata`包的`deathpenalty`数据集，关于1976年至1987年佛罗里达州多起谋杀案中被告的判决。这些案件根据死刑（其中0表示没有，1表示有）进行分类，被告的种族和受害者的种族（黑人表示0，白人表示1）。
- en: 'First, we expand the frequency table into case form via the `expand.dtf` function
    from the `vcdExtra` package, then we fit our first generalized model in the dataset:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们通过`vcdExtra`包中的`expand.dtf`函数将频率表扩展成案例形式，然后在数据集中拟合我们的第一个广义模型：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The regression coefficient is statistically not significant, so at first sight,
    we can''t see a racial bias in the data. Anyway, for didactic purposes, let''s
    interpret the regression coefficient. It''s `0.37`, which means that the natural
    logarithm of the odds of getting a death penalty increases by 0.37 when moving
    from the black category to the white one. This difference is easily interpretable
    if you take its exponent, which is the ratio of the odds:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 回归系数在统计上不显著，所以乍一看，我们看不到数据中的种族偏见。无论如何，为了教学目的，让我们解释回归系数。它是`0.37`，这意味着从黑人类别移动到白人类别时，获得死刑机会的自然对数增加0.37。如果您取其指数，这个差异很容易解释，因为它是优势的比率：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The odds ratio pertaining to the race of the defendant is `1.45`, which means
    that white defendants have 45 percent larger odds of getting the death penalty
    than black defendants.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与被告种族相关的优势比是`1.45`，这意味着白人被告获得死刑的机会比黑人被告高出45%。
- en: Note
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Although R produces this, the odds ratio for the intercept is generally not
    interpreted.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然R生成了这个结果，但截距的优势比通常不被解释。
- en: We can say something more general. We have seen that in linear regression models,
    the regression coefficient, *b*, can be interpreted as a one unit increase in
    *X* increases *Y* by *b*. But, in logistic regression models, a one unit increase
    in *X* multiplies the odds of *Y* by `exp(b)`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以说得更加普遍。我们已经看到在线性回归模型中，回归系数*b*可以解释为X增加一个单位时，Y增加*b*。但是，在逻辑回归模型中，X增加一个单位会使Y的优势乘以`exp(b)`。
- en: Please note that the preceding predictor was a discrete one, with values of
    0 (black) and 1 (white), so it's basically a dummy variable for white, and black
    is the reference category. We have seen the same solution for entering discrete
    variables in the case of linear regression models. If you have more than two racial
    categories, you should define a second dummy for the third race and enter it into
    the model as well. The exponent of each dummy variables' coefficients equal to
    the odds ratio, which compares the given category to the reference. If you have
    a continuous predictor, the exponent of the coefficient equals to the odds ratio
    pertaining to a one unit increase in the predictor.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面的预测变量是一个离散变量，其值为0（黑人）和1（白人），所以它基本上是一个白人的虚拟变量，而黑人则是参照类别。我们已经看到了在线性回归模型中输入离散变量的相同解决方案。如果您有超过两个种族类别，您应该为第三个种族定义第二个虚拟变量，并将其也输入到模型中。每个虚拟变量系数的指数等于优势比，它比较给定类别与参照类别。如果您有一个连续预测变量，系数的指数等于预测变量增加一个单位时的优势比。
- en: 'Now, let''s enter the race of the victim into the examination, since it''s
    a plausible confounder. Let''s control for it, and fit the logistic regression
    model with both the `DefendantRace` and `VictimRace` as predictors:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将受害者种族纳入考虑，因为它是一个可能的混杂因素。让我们控制它，并使用`DefendantRace`和`VictimRace`作为预测变量拟合逻辑回归模型：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'When controlling for `VictimRace`, the effect of `DefendantRace` becomes significant!
    The odds ratio is `0.42`, which means that white defendants'' odds of getting
    the death penalty are only 42 percent of the odds of black defendants, holding
    the race of the victim fixed. Also, the odds ratio of `VictimRace` (11.07) shows
    an extremely strong effect: killers of white victims are 11 times more likely
    to get a death penalty than killers of black victims.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当控制`VictimRace`时，`DefendantRace`的影响变得显著！优势比是`0.42`，这意味着白人被告获得死刑的机会只是黑人被告机会的42%，在受害者种族固定的情况下。此外，`VictimRace`的优势比（11.07）显示出极其强烈的影响：杀害白人受害者的凶手获得死刑的可能性是杀害黑人受害者的11倍。
- en: 'So, the effect of `DefendantRace` is exactly the opposite of what we have got
    in the one-predictor model. The reversed association may seem to be paradoxical,
    but it can be explained. Let''s have a look at the following output:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`DefendantRace`的影响与我们在一预测变量模型中得到的影响正好相反。这种逆转的关联可能看起来是矛盾的，但它可以解释。让我们看一下以下输出：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The data seems to be homogeneous in some sense: black defendants are more likely
    to have black victims, and vice versa. If you put these pieces of information
    together, you start to see that black defendants yield a smaller proportion of
    death sentences just because they are more likely to have black victims, and those
    who have black victims are less likely to get a death penalty. The paradox disappears:
    the crude death penalty and `DefendantRace` association was confounded by `VictimRace`.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据似乎在某种程度上具有同质性：黑人被告更有可能遇到黑人受害者，反之亦然。如果你将这些信息放在一起，你就会开始看到，黑人被告产生更小的死刑判决比例，仅仅是因为他们更有可能遇到黑人受害者，而那些有黑人受害者的人不太可能被判死刑。这种悖论消失了：粗略的死刑和`DefendantRace`（被告种族）关联被`VictimRace`（受害者种族）所混淆。
- en: 'To sum it up, it seems that taking the available information into account,
    you can come to the following conclusions:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，似乎在考虑可用信息的情况下，你可以得出以下结论：
- en: Black defendants are more likely to get the death penalty
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黑人被告更有可能被判死刑
- en: Killing a white person is considered to be a more serious crime than killing
    a black person
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杀死一个白人被认为比杀死一个黑人更严重的罪行
- en: Of course, you should draw such conclusions extremely carefully, as the question
    of racial bias needs a very thorough analysis using all the relevant information
    regarding the circumstances of the crime, and much more.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你应该非常谨慎地得出这样的结论，因为种族偏见的问题需要使用所有与犯罪情况相关的相关信息进行非常彻底的分析，以及更多。
- en: Data considerations
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据考虑
- en: Logistic regression models work on the assumption that the observations are
    totally independent from each other. This assumption is violated, for example,
    if your observations are consecutive years. The deviance residuals and other diagnostic
    statistics can help validate the model and detect problems such as the misspecification
    of the link function. For further reference, see the `LogisticDx` package.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型基于观察值之间完全独立的假设。例如，如果你的观察值是连续的年份，这个假设就被违反了。偏差残差和其他诊断统计量可以帮助验证模型并检测诸如链接函数误指定等问题。有关进一步参考，请参阅`LogisticDx`包。
- en: As a general rule of thumb, logistic regression models require at least 10 events
    per predictors, where an event denotes the observations belonging to the less
    frequent category in the response. In our death penalty example, death is the
    less frequent category in the response, and we have 68 death sentences in the
    database. So, the rule suggests that a maximum of 6-7 predictors are allowed.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，逻辑回归模型需要每个预测因子至少有10个事件，其中事件表示属于响应中较少出现类别的观察值。在我们的死刑案例中，死刑是响应中较少出现的类别，我们在数据库中有68个死刑判决。因此，规则建议最多允许6-7个预测因子。
- en: The regression coefficients are estimated using the maximum likelihood method.
    Since there is no closed mathematical form to get these ML estimations, R uses
    an optimization algorithm instead. In some cases, you may get an error message
    that the algorithm doesn't reach convergence. In such cases, it is unable to find
    an appropriate solution. This may occur for a number of reasons, such as having
    too many predictors, too few events, and so on.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 回归系数是通过最大似然法估计的。由于没有封闭的数学形式来获取这些最大似然估计，R使用优化算法。在某些情况下，你可能会收到一个错误消息，表明算法没有达到收敛。在这种情况下，它无法找到合适的解决方案。这可能是由多种原因造成的，例如预测因子太多、事件太少等等。
- en: Goodness of model fit
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型拟合优度
- en: One measure of model fit, to evaluate the performance of the model, is the significance
    of the overall model. The corresponding likelihood ratio tests whether the given
    model fits significantly better than a model with just an intercept, which we
    call the null model.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型性能的一个指标是整体模型的显著性。相应的似然比检验表明，给定的模型与仅包含截距项的模型相比，拟合得更好，我们称之为零模型。
- en: To obtain the test results, you have to look at the residual deviance in the
    output. It measures the disagreement between the maxima of the observed and the
    fitted log likelihood functions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得测试结果，你必须查看输出中的残差偏差。它衡量了观察到的最大值和拟合的对数似然函数之间的不一致性。
- en: Note
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Since logistic regression follows the maximal likelihood principle, the goal
    is to minimize the sum of the deviance residuals. Therefore, this residual is
    parallel to the raw residual in linear regression, where the goal is to minimize
    the sum of squared residuals.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于逻辑回归遵循最大似然原理，目标是使偏差残差的总和最小化。因此，这个残差与线性回归中的原始残差平行，在线性回归中，目标是使残差平方和最小化。
- en: 'The null deviance represents how well the response is predicted by a model
    with nothing but an intercept. To judge the model, you have to compare the residual
    deviance to the null deviance; the difference follows a chi-square distribution.
    The corresponding test is available in the `lmtest` package:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 空偏差表示仅由截距预测的模型对响应的预测效果如何。为了评估模型，你必须将残差偏差与空偏差进行比较；差异遵循卡方分布。相应的检验在`lmtest`包中可用：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The *p* value indicates a highly significant decrease in deviance. This means
    that the model is significant, and the predictors have a significant effect on
    the response probability.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*p*值表示偏差的显著降低。这意味着模型是显著的，预测因子对响应概率有显著影响。'
- en: You can think of the likelihood ratio as the F-test in the linear regression
    models. It reveals if the model is significant, but it doesn't tell anything about
    the goodness-of-fit, which was described by the adjusted R-squared measure in
    the linear case.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将似然比视为线性回归模型中的F检验。它揭示了模型是否显著，但它没有提供关于拟合优度方面的任何信息，这在线性情况下是由调整R平方测量的。
- en: 'An equivalent statistic for logistic regression models does not exist, but
    several pseudo R-squared have been developed. These usually range from 0 to 1
    with higher values indicating a better fit. We will use the `PseudoR2` function
    from the `BaylorEdPsych` package to compute this value:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于逻辑回归模型，不存在等效的统计量，但已经开发出几种伪R平方。这些值通常在0到1之间，值越高表示拟合度越好。我们将使用来自`BaylorEdPsych`包的`PseudoR2`函数来计算这个值：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: But be careful, the pseudo R-squared cannot be interpreted as an OLS R-squared,
    and there are some documented problems with them as well, but they give us a rough
    picture. In our case, they say that the explanative power of the model is rather
    low, which is not surprising if we consider the fact that only two predictors
    were used in the modeling of such a complex process as judging a crime.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 但请注意，伪R平方不能解释为OLS R平方，而且它们也存在一些已记录的问题，但它们为我们提供了一个大致的图景。在我们的案例中，它们表示模型的解释力相当低，如果我们考虑到在如此复杂的过程（如判断犯罪）中只使用了两个预测因子，这一点并不令人惊讶。
- en: Model comparison
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型比较
- en: As we have seen in the previous chapter, the adjusted R-squared provides a good
    base for model comparison when dealing with nested linear regression models. For
    nested logistic regression models, you can use the likelihood ratio test (such
    as the `lrtest` function from the `lmtest` library), which compares the difference
    between the residual deviances.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一章中看到的，当处理嵌套线性回归模型时，调整R平方为模型比较提供了一个良好的基础。对于嵌套逻辑回归模型，你可以使用似然比检验（例如来自`lmtest`库的`lrtest`函数），它比较残差偏差的差异。
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '`LogLiK`, in the preceding output denotes the log-likelihood of the model;
    you got the residual deviance by multiplying it by 2.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，`LogLiK`表示模型的对数似然；你通过将其乘以2得到残差偏差。
- en: For un-nested models, you can use AIC, just like we did in the case of linear
    regression models, but in logistic regression models, AIC is part of the standard
    output, so there is no need to call the AIC function separately. Here, the `binom.model.1`
    has a lower AIC than `binom.model.0`, and the difference is not negligible since
    it is greater than 2.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非嵌套模型，你可以使用AIC，就像我们在线性回归模型的情况中所做的那样，但在逻辑回归模型中，AIC是标准输出的一部分，因此不需要单独调用AIC函数。在这里，`binom.model.1`的AIC比`binom.model.0`低，差异不可忽视，因为它大于2。
- en: Models for count data
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计数数据的模型
- en: Logistic regression can handle only binary responses. If you have count data,
    such as the number of deaths or failures in a given period of time, or in a given
    geographical area, you can use Poisson or negative binomial regression. These
    data types are particularly common when working with aggregated data, which is
    provided as a number of events classified in different categories.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归只能处理二元响应。如果你有计数数据，例如在特定时间段或特定地理区域内死亡或失败的数量，你可以使用泊松或负二项式回归。这些数据类型在处理作为不同类别事件数量提供的汇总数据时尤其常见。
- en: Poisson regression
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 泊松回归
- en: Poisson regression models are generalized linear models with the logarithm as
    the link function, and they assume that the response has a **Poisson distribution**.
    The Poisson distribution takes only integer values. It is appropriate for count
    data, such as events occurring over a fixed period of time, that is, if the events
    are rather rare, such as a number of hard drive failures per day.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 泊松回归模型是具有对数作为链接函数的广义线性模型，并且假设响应具有**泊松分布**。泊松分布只取整数值。它适用于计数数据，例如在固定时间段内发生的事件，即如果事件相对罕见，例如每天硬盘故障的数量。
- en: In the following example, we will use the Hard Drive Data Sets for the year
    of 2013\. The dataset was downloaded from [https://docs.backblaze.com/public/hard-drive-data/2013_data.zip](https://docs.backblaze.com/public/hard-drive-data/2013_data.zip),
    but we polished and simplified it a bit. Each record in the original database
    corresponds to a daily snapshot of one drive. The failure variable, our main point
    of interest, can be either zero (if the drive is OK), or one (on the last day
    of the hard drive before failing).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将使用2013年的硬盘数据集。数据集是从[https://docs.backblaze.com/public/hard-drive-data/2013_data.zip](https://docs.backblaze.com/public/hard-drive-data/2013_data.zip)下载的，但我们对其进行了一些打磨和简化。原始数据库中的每条记录对应一个硬盘的每日快照。故障变量，我们主要感兴趣的部分，可以是零（如果驱动器正常），或者一（在硬盘发生故障前的最后一天）。
- en: 'Let''s try to determine which factors affect the appearance of a failure. The
    potential predictive factors are the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试确定哪些因素会影响故障的出现。潜在的预测因素如下：
- en: '`model`: The manufacturer-assigned model number of the drive'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`: 驱动器制造商指定的型号编号'
- en: '`capacity_bytes`: The drive capacity in bytes'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`capacity_bytes`: 驱动器容量（以字节为单位）'
- en: '`age_month`: The drive age in the average month'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`age_month`: 平均月份的驱动年龄'
- en: '`temperature`: The hard disk drive temperature'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature`: 硬盘驱动器的温度'
- en: '`PendingSector`: A logical value indicating the occurrence of unstable sectors
    (waiting for remapping on the given hard drive, on the given day)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PendingSector`: 一个逻辑值，表示不稳定扇区的发生（在给定的硬盘上，在给定的那天等待重映射）'
- en: 'We aggregated the original dataset by these variables, where the `freq` variable
    denotes the number of records in the given category. It''s time to load this final,
    cleansed, and aggregated dataset:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过这些变量对这些原始数据集进行了聚合，其中`freq`变量表示给定类别中的记录数。现在是时候加载这个最终、清洗和聚合的数据集了：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Take a quick look at the number of failures by model:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 快速查看按型号划分的故障数量：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, let''s get rid of those hard-drive models that didn''t have any failure,
    by removing all rows from the preceding table where there are only zeros beside
    the first column:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过删除前表中只有第一列旁边有零的所有行，来去除那些没有发生任何故障的硬盘驱动器型号：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To get a quick overview on the number of failures, let''s plot a histogram
    on a log scale by model numbers, with the help of the `ggplot2` package:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速了解故障数量，让我们通过型号编号在对数尺度上绘制一个直方图，借助`ggplot2`包：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Poisson regression](img/2028OS_05_01.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![泊松回归](img/2028OS_05_01.jpg)'
- en: Now, it's time to fit a Poisson regression model to the data, using the `model`
    number as the predictor. The model can be fitted using the `glm` function with
    the option, `family=poisson`. By default, the expected log count is modeled, so
    we use the `log` link.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候将泊松回归模型拟合到数据中，使用`model`编号作为预测因子。可以使用带有选项`family=poisson`的`glm`函数来拟合模型。默认情况下，期望的对数计数是模型化的，因此我们使用`log`链接。
- en: 'In the database, each observation corresponds to a group with a varying number
    of hard drives. As we need to handle the different group sizes, we will use the
    `offset` function:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据库中，每个观测值对应一个具有不同数量硬盘的组。由于我们需要处理不同的组大小，我们将使用`offset`函数：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'First, let''s interpret the coefficients. The model number is a discrete predictor,
    so we entered a number of dummy variables to represent it is as a predictor. The
    reference category is not present in the output by default, but we can query it
    at any time:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们解释系数。型号是一个离散预测因子，所以我们输入了一些虚拟变量来表示它作为预测因子。默认情况下，参考类别不在输出中，但我们可以随时查询它：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'So, it turns out that the reference category is `HGST`, and the dummy variables
    compare each model with the `HGST` hard drive. For example, the coefficient of
    `Hitachi` is `1.77`, so the expected log-count for `Hitachi` drives is about 1.77
    greater than those for `HGST` drives. Or, you can compute its exponent when speaking
    about ratios instead of differences:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，结果证明参考类别是 `HGST`，虚拟变量将每个模型与 `HGST` 硬盘驱动器进行比较。例如，`Hitachi` 的系数是 `1.77`，所以
    `Hitachi` 驱动器的预期对数计数比 `HGST` 驱动器大约高 1.77。或者，当讨论比率而不是差异时，可以计算其指数：
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'So, the expected number of failures for `Hitachi` drives is 5.85 times greater
    than for `HGST` drives. In general, the interpretation goes as: a one unit increase
    in *X* multiplies *Y* by `exp(b)`.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`Hitachi` 驱动的预期故障次数是 `HGST` 驱动的 5.85 倍。一般来说，解释如下：`X` 单位增加会使 `Y` 乘以 `exp(b)`。
- en: 'Similar to logistic regression, let''s determine the significance of the model.
    To do this, we compare the present model to the null model without any predictors,
    so the difference between the residual deviance and the null deviance can be identified.
    We expect the difference to be large enough, and the corresponding chi-squared
    test to be significant:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 与逻辑回归类似，让我们确定模型的显著性。为此，我们将当前模型与没有任何预测因子的空模型进行比较，因此可以识别残差偏差和空偏差之间的差异。我们期望差异足够大，相应的卡方检验是显著的：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: And it seems that the model is significant, but we should also try to determine
    whether any of the model assumptions might fail.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来模型是显著的，但我们也应该尝试确定是否有任何模型假设可能失败。
- en: Just like we did with the linear and logistic regression models, we have an
    independence assumption, where Poisson regression assumes the events to be independent.
    This means that the occurrence of one failure will not make another more or less
    likely. In the case of drive failures, this assumption holds. Another important
    assumption comes from the fact that the response has a Poisson distribution with
    an equal mean and variance. Our model assumes that the variance and the mean,
    conditioned on the predictor variables, will be approximately equal.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们对线性回归和逻辑回归模型所做的那样，我们有一个独立性假设，泊松回归假设事件是独立的。这意味着一个故障的发生不会使另一个故障更有可能或更不可能。在驱动器故障的情况下，这个假设成立。另一个重要的假设来自于响应具有具有相等均值和方差的泊松分布。我们的模型假设，在预测变量的条件下，方差和均值将大致相等。
- en: To decide whether the assumption holds, we can compare the residual deviance
    to its degree of freedom. For a well-fitting model, their ratio should be close
    to one. Unfortunately, the reported residual deviance is `17622` on `9844` degrees
    of freedom, so their ratio is much above one, which suggests that the variance
    is much greater than the mean. This phenomenon is called **overdispersion**.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了决定假设是否成立，我们可以将残差偏差与其自由度进行比较。对于一个拟合良好的模型，它们的比率应该接近于 1。不幸的是，报告的残差偏差是 `17622`，自由度是
    `9844`，所以它们的比率远高于 1，这表明方差远大于均值。这种现象称为 **过度分散**。
- en: Negative binomial regression
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负二项式回归
- en: In such a case, a negative binomial distribution can be used to model an over-dispersed
    count response, which is a generalization of the Poisson regression since it has
    an extra parameter to model the over-dispersion. In other words, Poisson and the
    negative binomial models are nested models; the former is a subset of the latter
    one.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，可以使用负二项式分布来模拟过度分散的计数响应，这是泊松回归的推广，因为它有一个额外的参数来模拟过度分散。换句话说，泊松和负二项式模型是嵌套模型；前者是后者的子集。
- en: 'In the following output, we use the `glm.nb` function from the `MASS` package
    to fit a negative binomial regression to our drive failure data:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下输出中，我们使用 `MASS` 包中的 `glm.nb` 函数来拟合我们的驱动器故障数据的负二项式回归：
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To compare this model''s performance to the Poisson model, we can use the likelihood
    ratio test, since the two models are nested. The negative binomial model shows
    a significantly better fit:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 要将此模型的性能与泊松模型进行比较，我们可以使用似然比检验，因为这两个模型是嵌套的。负二项式模型显示出显著更好的拟合度：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This result clearly suggests choosing the negative binomial model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果清楚地表明应选择负二项式模型。
- en: Multivariate non-linear models
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多元非线性模型
- en: So far, the only predictor in our model was the model name, but we have other
    potentially important information about the drives as well, such as capacity,
    age, and temperature. Now let's add these to the model, and determine whether
    the new model is better than the original one.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们模型中唯一的预测变量是模型名称，但我们还有关于驱动器的其他可能重要的信息，例如容量、年龄和温度。现在让我们将这些添加到模型中，并确定新模型是否比原始模型更好。
- en: 'Furthermore, let''s check the importance of `PendingSector` as well. In short,
    we define a two-step model building procedure with the nested models; hence we
    can use likelihood ratio statistics to test whether the model fit has significantly
    increased in both steps:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，让我们也检查`PendingSector`的重要性。简而言之，我们定义了一个包含嵌套模型的两个步骤模型构建过程；因此，我们可以使用似然比统计量来检验模型拟合在两个步骤中是否显著增加：
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Both of these steps are significant, so it was worth adding each predictor
    to the model. Now, let''s interpret the best model:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个步骤都很重要，因此将每个预测变量添加到模型中是值得的。现在，让我们解释最佳模型：
- en: '[PRE18]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Each predictor is significant—with a few exceptions of some contrast in model
    type. For example, `Toshiba` doesn't differ significantly from the reference category,
    `HGST`, when controlling for age, temperature, and so on.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 每个预测变量都是显著的——除了模型类型中的一些对比例外。例如，在控制年龄、温度等因素的情况下，`Toshiba`与参考类别`HGST`没有显著差异。
- en: 'The interpretation of the negative binomial regression parameters is similar
    to the Poisson model. For example, the coefficient of `age_month` is 0.048, which
    shows that a one month increase in age, increases the expected log-count of failures
    by 0.048\. Or, you can opt for using exponentials as well:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 负二项回归参数的解释与泊松模型类似。例如，`age_month`的系数为0.048，这表明年龄增加一个月，预期故障的对数计数会增加0.048。或者，你也可以选择使用指数：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'So, it seems that one month in a lifetime increases the expected number of
    failures by 4.9 percent, and a larger capacity also increases the number of failures.
    On the other hand, temperature shows a reversed effect: the exponent of the coefficient
    is 0.947, which says that one degree of increased warmth decreases the expected
    number of failures by 5.3 percent.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，似乎一生中的一年会增加预期故障次数的4.9%，而更大的容量也会增加故障次数。另一方面，温度显示出相反的效果：系数的指数为0.947，这意味着温度每增加一度，预期故障次数会减少5.3%。
- en: 'The effect of the model name can be judged on the basis of comparison to the
    reference category, which is `HGST` in our case. One may want to change this reference.
    For example, for the most common drive: `WDC`. This can be easily done by changing
    the order of the factor levels in hard drive models, or simply defining the reference
    category in the factor via the extremely useful `relevel` function:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 模型名称的影响可以通过与参考类别进行比较来判断，在我们的例子中是`HGST`。有人可能想改变这个参考。例如，对于最常见的驱动器：`WDC`。这可以通过改变硬盘驱动器模型中因子水平的顺序或简单地通过极其有用的`relevel`函数在因子中定义参考类别来实现：
- en: '[PRE20]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, let''s verify if `HGST` indeed replaced `WDC` in the coefficients list,
    but instead of the lengthy output of summary, we will use the `tidy` function
    from the `broom` package, which can extract the most important features (for the
    model summary, take a look at the `glance` function) of different statistical
    models:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们验证`HGST`是否确实替换了系数列表中的`WDC`，但为了不输出冗长的摘要，我们将使用来自`broom`包的`tidy`函数，该函数可以提取不同统计模型的最重要特征（对于模型摘要，请查看`glance`函数）：
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Use the `broom` package to extract model coefficients, compare model fit, and
    other metrics to be passed to, for example, `ggplot2`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`broom`包提取模型系数，比较模型拟合和其他指标，例如传递给`ggplot2`。
- en: The effect of temperature suggests that the higher the temperature, the lower
    the number of hard drive failures. However, everyday experiences show a very different
    picture, for example, as described at [https://www.backblaze.com/blog/hard-drive-temperature-does-it-matter](https://www.backblaze.com/blog/hard-drive-temperature-does-it-matter).
    Google engineers found that temperature was not a good predictor of failure, while
    Microsoft and the University of Virginia found that it had a significant effect.
    Disk drive manufacturers suggest keeping disks at cooler temperatures.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 温度的效应表明，温度越高，硬盘故障的数量越低。然而，日常经验显示了一个非常不同的画面，例如，在[https://www.backblaze.com/blog/hard-drive-temperature-does-it-matter](https://www.backblaze.com/blog/hard-drive-temperature-does-it-matter)中描述的那样。谷歌工程师发现温度并不是故障的良好预测因子，而微软和弗吉尼亚大学发现它有显著影响。磁盘驱动器制造商建议保持磁盘在较低的温度下。
- en: 'So, let''s take a closer look at this interesting question, and we will have
    the `temperature` as a predictor of drive failure. First, let''s classify temperature
    into six equal categories, and then we will draw a bar plot presenting the mean
    number of failures per categories. Note that we have to take into account the
    different groups'' sizes, so we will weight by `freq`, and as we are doing some
    data aggregation, it''s the right time to convert our dataset into a `data.table`
    object:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们更仔细地看看这个有趣的问题，我们将把`温度`作为驱动器故障的预测因子。首先，让我们将温度分为六个相等的类别，然后我们将绘制一个条形图来展示每个类别的平均故障数量。请注意，我们必须考虑到不同组的大小，因此我们将通过`freq`进行加权，并且由于我们正在进行一些数据聚合，现在是将我们的数据集转换为`data.table`对象的时候了：
- en: '[PRE22]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![Multivariate non-linear models](img/2028OS_05_02.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![多元非线性模型](img/2028OS_05_02.jpg)'
- en: 'The assumption of linear relation is clearly not supported. The bar plot suggests
    using the temperature in this classified form, instead of the original continuous
    variable when entering the model. To actually see which model is better, let''s
    compare those! Since they are not nested, we have to use the AIC, which strongly
    supports the categorized version:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 线性关系的假设显然没有得到支持。条形图建议在模型中输入时使用这种分类形式的温度，而不是原始的连续变量。为了真正看到哪个模型更好，让我们比较一下！由于它们不是嵌套的，我们必须使用AIC，它强烈支持分类版本：
- en: '[PRE23]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Well, it was really worth categorizing temperature! Now, let''s check the other
    two continuous predictors as well. Again, we will use `freq` as a weighting factor:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，对温度进行分类真的很有价值！现在，让我们检查其他两个连续预测因子。同样，我们将使用`freq`作为权重因子：
- en: '[PRE24]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As in the previous plots, we will use `ggplot2` to plot the distribution of
    these discrete variables, but instead of a bar plot, we will use a stair-line
    chart to overcome the issue of the fixed width of bar charts:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的图表一样，我们将使用`ggplot2`来绘制这些离散变量的分布，但我们将使用阶梯线图而不是条形图来克服条形图固定宽度的缺点：
- en: '[PRE25]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![Multivariate non-linear models](img/2028OS_05_03.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![多元非线性模型](img/2028OS_05_03.jpg)'
- en: 'The relations are again, clearly not linear. The case of `age` is particularly
    interesting; there seems to be highly risky periods in the hard drives'' lifetime.
    Now, let''s force R to use `capacity` as a nominal variable (it has only five
    values, so there is no real need to categorize it), and let''s classify `age`
    into 8 equally sized categories:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这些关系显然不是线性的。`年龄`的情况尤其有趣；硬盘寿命中似乎存在高度危险的时期。现在，让我们强制R使用`容量`作为名义变量（它只有五个值，所以实际上没有必要对其进行分类），并将`年龄`分为8个大小相等的类别：
- en: '[PRE26]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'According to the AIC, the last model with the categorized age and capacity
    is much better, and is the best fitting model so far:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 根据AIC，最后一个具有分类年龄和容量的模型要好得多，是目前为止的最佳拟合模型：
- en: '[PRE27]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'If you look at the parameter estimates, you can see that the first dummy variable
    on capacity significantly differ from the reference:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看参数估计，你可以看到容量上的第一个虚拟变量与参考值显著不同：
- en: '[PRE28]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The next three capacities are more likely to cause failures, but the trend is
    not linear. The effect of age also does not seem to be linear. In general, aging
    increases the number of failures, but there are some exceptions. For example,
    drives are significantly more likely to have a failure in the first (reference)
    age group than in the second one. This finding is plausible since drives have
    a higher failure rate at the beginning of their operation. The effect of temperature
    suggests that the middle temperature (22-30 degrees Celsius) is more likely to
    cause failures than low or high temperatures. Remember that each effect is controlled
    for every other predictor.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的三个容量更有可能引起故障，但趋势并非线性。年龄的影响似乎也不是线性的。总的来说，老化会增加故障数量，但也有一些例外。例如，驱动器在第一个（参考）年龄组比第二个年龄组更有可能发生故障。这一发现是合理的，因为驱动器在其操作初期有更高的故障率。温度的影响表明，中等温度（22-30摄氏度）比低温或高温更有可能引起故障。记住，每个效应都是控制其他每个预测变量的。
- en: It would also be important to judge the effect-size of different predictors,
    comparing them to each other. As a picture is worth a thousand words, let's summarize
    the coefficients with the confidence intervals in one plot.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 判断不同预测变量的效应大小也很重要，将它们相互比较。毕竟，一张图胜过千言万语，让我们用一个图表来总结系数及其置信区间。
- en: 'First, we have to extract the significant terms from the model:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须从模型中提取显著的术语：
- en: '[PRE29]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, let''s identify the confidence intervals of the coefficients using the
    `confint` function and the good old `plyr` package:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们使用 `confint` 函数和古老的 `plyr` 包来识别系数的置信区间：
- en: '[PRE30]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Unfortunately, this resulting data frame is not yet complete. We need to add
    the term names, and also, let''s extract the grouping variables via a simple,
    regular expression:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 很遗憾，这个生成的数据框还不完整。我们需要添加术语名称，并且，让我们通过一个简单的正则表达式提取分组变量：
- en: '[PRE31]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'And now we have the confidence intervals of the coefficients in a nicely formatted
    dataset, which can be easily plotted by `ggplot`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经得到了一个格式良好的数据集中系数的置信区间，这些区间可以用 `ggplot` 很容易地绘制出来：
- en: '[PRE32]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![Multivariate non-linear models](img/2028OS_05_04.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![多元非线性模型](img/2028OS_05_04.jpg)'
- en: It can be easily seen that although each predictor is significant, the size
    of their effects strongly differ. For example, `PendingSector` has just a slight
    effect on the number of failures, but `age`, `capacity`, and `temperature` have
    a much stronger effect, and the hard drive model is the predictor that best differentiates
    the number of failures.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易看出，尽管每个预测变量都很显著，但它们的影响大小差异很大。例如，`PendingSector` 对故障数量的影响微乎其微，但 `age`、`capacity`
    和 `temperature` 的影响则要大得多，硬盘型号是区分故障数量最好的预测变量。
- en: 'As we have mentioned in the *Logistic regression* section, different pseudo
    R-squared measures are available for nonlinear models as well. We again warn you
    to use these metrics with reservation. Anyway, in our case, they uniformly suggest
    the model''s explanative power to be pretty good:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 *逻辑回归* 部分中提到的，非线性模型也有不同的伪 R 平方度量。我们再次提醒您，对这些指标要持保留态度。无论如何，在我们的案例中，它们一致表明模型的解释力相当好：
- en: '[PRE33]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This chapter introduced three well known nonlinear regression models: the logistic,
    Poisson, and negative binomial models, and you became familiar with the general
    logic of modeling. It was also shown how the same concepts, such as effect of
    predictors, goodness of fit, explanative power, model comparison for nested and
    non-nested models, and model building are applied in different contexts. Now,
    having spent some time on mastering the data analysis skills, in the next chapter,
    we will get back to some hardcore data science problems, such as the cleansing
    and structuring of data.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了三种著名的非线性回归模型：逻辑回归、泊松回归和负二项回归模型，并且你对建模的一般逻辑已经熟悉。还展示了相同的概念，如预测变量的影响、拟合优度、解释力、嵌套和非嵌套模型的模型比较以及模型构建，在不同情境中的应用。现在，在掌握数据分析技能上花费了一些时间之后，在下一章中，我们将回到一些核心的数据科学问题，例如数据的清洗和结构化。
