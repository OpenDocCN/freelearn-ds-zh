- en: 3\. Details of Logistic Regression and Feature Exploration
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 逻辑回归及特征探索的详细内容
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter teaches you how to evaluate features quickly and efficiently, in
    order to know which ones will probably be most important for a machine learning
    model. Once we get a taste for this, we'll explore the inner workings of logistic
    regression so you can continue your journey to mastery of this fundamental technique.
    After reading this chapter, you will be able to make a correlation plot of many
    features and a response variable and interpret logistic regression as a linear
    model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将教你如何快速高效地评估特征，以便了解哪些特征可能对机器学习模型最为重要。一旦我们掌握了这一点，我们将深入探讨逻辑回归的内部工作原理，让你能够继续在这一基础技术上迈向精通之路。阅读完本章后，你将能够制作多特征与响应变量的相关性图，并将逻辑回归解读为线性模型。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In the previous chapter, we developed a few example machine learning models
    using scikit-learn, to get familiar with how it works. However, the features we
    used, `EDUCATION` and `LIMIT_BAL`, were not chosen in a systematic way.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们使用 scikit-learn 开发了几个示例机器学习模型，以便熟悉它的工作原理。然而，我们使用的特征`EDUCATION`和`LIMIT_BAL`并不是以系统化的方式选择的。
- en: In this chapter, we will start to develop techniques that can be used to assess
    features for their usefulness in modeling. This will enable you to make a quick
    pass over all candidate features, to have an idea of which will be the most important.
    For the most promising features, we will see how to create visual summaries that
    serve as useful communication tools.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将开始开发评估特征在建模中有效性的方法。这将使你能够快速浏览所有候选特征，从而大致了解哪些特征可能是最重要的。对于最有潜力的特征，我们将看到如何创建视觉总结，以便作为有用的沟通工具。
- en: Next, we will begin our detailed examination of logistic regression. We'll learn
    why logistic regression is considered to be a linear model, even if the formulation
    involves some non-linear functions. We'll learn what a decision boundary is and
    see that as a key consequence of its linearity, the decision boundary of logistic
    regression could make it difficult to accurately classify the response variable.
    Along the way, we'll get more familiar with Python, by using list comprehensions
    and writing functions.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将详细研究逻辑回归。我们将了解为什么逻辑回归被认为是一个线性模型，即使其公式中涉及了一些非线性函数。我们将学习什么是决策边界，并看到由于其线性特性，逻辑回归的决策边界可能会使得准确分类响应变量变得困难。在这个过程中，我们将通过使用列表推导和编写函数，更加熟悉
    Python。
- en: Examining the Relationships Between Features and the Response Variable
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查特征与响应变量之间的关系
- en: In order to make accurate predictions of the response variable, good features
    are necessary. We need features that are clearly linked to the response variable
    in some way. Thus far, we've examined the relationship between a couple of features
    and the response variable, either by calculating the `groupby`/`mean` of a feature
    and the response variable, or using individual features in a model and examining
    performance. However, we have not yet done a systematic exploration of how all
    the features relate to the response variable. We will do that now and begin to
    capitalize on all the hard work we put in when we were exploring the features
    and making sure the data quality was good.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准确预测响应变量，好的特征是必要的。我们需要那些与响应变量有明确联系的特征。到目前为止，我们已经通过计算特征和响应变量的`groupby`/`mean`值，或在模型中使用单独的特征并检查性能，来检查几个特征与响应变量之间的关系。然而，我们还没有系统地探讨所有特征与响应变量的关系。现在我们将进行这项工作，并开始利用我们在探索特征和确保数据质量时所付出的努力。
- en: A popular way of getting a quick look at how all the features relate to the
    response variable, as well as how the features are related to each other, is by
    using a **correlation plot**. We will first create a correlation plot for the
    case study data, then discuss how to interpret it, along with some mathematical
    details.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一种快速了解所有特征与响应变量之间关系，以及特征间相互关系的流行方法是使用**相关性图**。我们将首先为案例研究数据创建一个相关性图，然后讨论如何解读它，并提供一些数学细节。
- en: 'In order to create a correlation plot, the necessary inputs include all features
    that we plan to explore, as well as the response variable. Since we are going
    to use most of the column names from the DataFrame for this, a quick way to get
    the appropriate list in Python is to start with all the column names and remove
    those that we don''t want. As a preliminary step, we start a new notebook for
    this chapter and load packages and the cleaned data from *Chapter 1*, *Data Exploration
    and Cleaning*, with this code:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建相关性图，我们需要的输入包括我们计划探索的所有特征以及响应变量。由于我们将使用DataFrame中的大部分列名，获取适当列名列表的快速方法是在Python中从所有列名开始，然后移除那些我们不需要的列名。作为初步步骤，我们为本章启动一个新的笔记本，并加载*第1章*、*数据探索与清理*中的包和清理后的数据，代码如下：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: 'The path to your cleaned data file may be different, depending on where you
    saved it in *Chapter 1*, *Data Exploration and Cleaning*. The code and the outputs
    presented in this section are also present in the reference notebook: [https://packt.link/pMvWa](https://packt.link/pMvWa).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您的清理数据文件的路径可能不同，取决于您在*第1章*、*数据探索与清理*中保存的位置。本节中提供的代码和输出也可以在参考笔记本中找到：[https://packt.link/pMvWa](https://packt.link/pMvWa)。
- en: 'Notice that this notebook starts out in a very similar way to the previous
    chapter''s notebook, except we also import the **Seaborn** package, which has
    many convenient plotting features that build on **Matplotlib**. Now let''s make
    a list of all the columns of the DataFrame and look at the first and last five:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这个笔记本的开始与上一章的笔记本非常相似，唯一不同的是我们还导入了**Seaborn**包，它基于**Matplotlib**提供了许多方便的绘图功能。现在，让我们列出DataFrame中的所有列，并查看前五行和后五行：
- en: '![Figure 3.1: Get a list of column names'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1：获取列名列表'
- en: '](img/B16925_03_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_01.jpg)'
- en: 'Figure 3.1: Get a list of column names'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：获取列名列表
- en: 'Recall that we are not to use the `gender` variable due to ethical concerns,
    and we learned that `PAY_2`, `PAY_3`,…, `PAY_6` are incorrect and should be ignored.
    Also, we are not going to examine the one-hot encoding we created from the `EDUCATION`
    variable, since the information from those columns is already included in the
    original feature, at least in some form. We will just use the `EDUCATION` feature
    directly. Finally, it makes no sense to use `ID` as a feature, since this is simply
    a unique account identifier and has nothing to do with the response variable.
    Let''s make another list of column names that are neither features nor the response.
    We want to exclude these from our analysis:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，由于伦理问题，我们不能使用`gender`变量，并且我们了解到`PAY_2`、`PAY_3`、…、`PAY_6`是错误的，应当忽略。此外，我们不会检查从`EDUCATION`变量创建的独热编码，因为这些列中的信息已经包含在原始特征中，至少以某种形式存在。我们将直接使用`EDUCATION`特征。最后，使用`ID`作为特征没有意义，因为它仅仅是一个唯一的账户标识符，与响应变量无关。我们需要列出那些既不是特征也不是响应变量的列名，并将它们从我们的分析中排除：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To have a list of column names that consists only of the features and response
    we will use, we want to remove the names in `items_to_remove` from the current
    list contained in `features_response`. There are several ways to do this in Python.
    We will use this opportunity to learn about a particular way of building a list
    in Python, called a **list comprehension**. When people talk about certain constructions
    as being **Pythonic**, or idiomatic to the Python language, list comprehensions
    are often one of the things that are mentioned.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了拥有一个仅包含我们将使用的特征和响应的列名列表，我们需要从当前的`features_response`列表中删除`items_to_remove`中的列名。在Python中，有几种方法可以做到这一点。我们将利用这个机会学习一种特定的构建列表的方式，叫做**列表推导式**。当人们谈论某些构造是**Pythonic**或符合Python语言习惯时，列表推导式通常是其中之一。
- en: 'What is a list comprehension? Conceptually, it is basically the same as a `for`
    loop. However, list comprehensions enable the creation of lists, which may be
    spread across several lines in an actual `for` loop, to be written in one line.
    They are also slightly faster than `for` loops, due to optimizations within Python.
    While this likely won''t save us much time here, this is a good chance to become
    familiar with them. Here is an example list comprehension:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是列表推导式？从概念上讲，它与`for`循环基本相同。然而，列表推导式使得可以将原本可能需要多行代码的`for`循环，用一行代码来实现。由于Python内置的优化，列表推导式通常比`for`循环稍微更快。虽然在这里这可能不会节省我们太多时间，但这是一个很好机会来熟悉它们。以下是一个列表推导式的例子：
- en: '![Figure 3.2: Example of a list comprehension'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.2：列表推导式示例'
- en: '](img/B16925_03_02.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_02.jpg)'
- en: 'Figure 3.2: Example of a list comprehension'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：列表推导示例
- en: That's all there is to it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这么简单。
- en: 'We can also use additional clauses to make the list comprehensions flexible.
    For example, we can use them to reassign the `features_response` variable with
    a list containing everything that''s not in the list of strings we wish to remove:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用其他子句来使列表推导更加灵活。例如，我们可以用它们重新赋值 `features_response` 变量，创建一个包含所有不在我们希望删除的字符串列表中的内容的列表：
- en: '![Figure 3.3: Using a list comprehension to prune down the column names'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.3：使用列表推导修剪列名'
- en: '](img/B16925_03_03.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_03.jpg)'
- en: 'Figure 3.3: Using a list comprehension to prune down the column names'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3：使用列表推导修剪列名
- en: The use of `if` and `not in` within the list comprehension is fairly self-explanatory.
    Easy readability in structures such as list comprehensions is one of the reasons
    for the popularity of Python.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表推导中使用 `if` 和 `not in` 是相当直观的。结构如列表推导的易读性是 Python 流行的原因之一。
- en: Note
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Python documentation ([https://docs.python.org/3/tutorial/datastructures.html](https://docs.python.org/3/tutorial/datastructures.html))
    defines list comprehensions as the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Python 文档（[https://docs.python.org/3/tutorial/datastructures.html](https://docs.python.org/3/tutorial/datastructures.html)）将列表推导定义为如下内容：
- en: '*"A list comprehension consists of brackets containing an expression followed
    by a for clause, then zero or more for or if clauses."*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*“列表推导由包含一个表达式的括号组成，后面跟着一个 for 子句，然后是零个或多个 for 或 if 子句。”*'
- en: Thus, list comprehensions can enable you to do things with less code, in a way
    that is usually pretty readable and understandable.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，列表推导可以让你通过更少的代码来完成任务，而且通常非常易读和易理解。
- en: Pearson Correlation
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pearson 相关性
- en: 'Now we are ready to create our correlation plot. Underlying a correlation plot
    is a `.corr()` method on these columns. As we calculate this, note that the type
    of correlation available to us in pandas is **linear correlation**, also known
    as **Pearson correlation**. Pearson correlation is used to measure the strength
    and direction (that is, positive or negative) of the linear relationship between
    two variables:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备创建我们的相关性图。相关性图的基础是对这些列调用 `.corr()` 方法。在我们计算这个时，注意到在 pandas 中可用的相关性类型是**线性相关性**，也称为**Pearson
    相关性**。Pearson 相关性用于衡量两个变量之间线性关系的强度和方向（即，正向或负向）：
- en: '![Figure 3.4: First five rows and columns of the correlation matrix'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.4：相关性矩阵的前五行和列'
- en: '](img/B16925_03_04.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_04.jpg)'
- en: 'Figure 3.4: First five rows and columns of the correlation matrix'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4：相关性矩阵的前五行和列
- en: 'After creating the correlation matrix, notice that the row and column names
    are the same. Then, for each possible comparison between all pairs of features,
    as well as all features and the response, which we can''t yet see here in the
    first five rows and columns, there is a number. This number is called the **correlation**
    between these two columns. All the correlations are between -1 and 1; a column
    has a correlation of 1 with itself (the diagonal of the correlation matrix), and
    there is repetition: each comparison appears twice since each column name from
    the original DataFrame appears as both a row and column in the correlation matrix.
    Before saying more about correlation, we''ll use Seaborn to make a nice plot of
    it. Here is the plotting code, followed by the output (please see the notebook
    on GitHub for a color figure if you''re reading in black and white; it''s necessary
    here - [https://packt.link/pMvWa](https://packt.link/pMvWa)):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建相关性矩阵后，注意到行和列名是相同的。然后，对于所有特征对之间的每一个可能的比较，以及所有特征和响应之间的比较，虽然在这里的前五行和列中我们还看不到响应，但每个比较都有一个数值。这个数值被称为这两列之间的**相关性**。所有的相关性都在
    -1 和 1 之间；一列与自身的相关性为 1（即相关性矩阵的对角线），并且存在重复：每个比较都会出现两次，因为原始 DataFrame 中的每个列名都会同时作为行和列出现在相关性矩阵中。在进一步讨论相关性之前，我们将使用
    Seaborn 绘制一个漂亮的图表。以下是绘图代码，后面是输出（如果你是在黑白模式下阅读，请参阅 GitHub 上的笔记本中的彩色图形；在这里这是必要的 -
    [https://packt.link/pMvWa](https://packt.link/pMvWa)）：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You should see the following output:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下输出：
- en: '![Figure 3.5: Heatmap of the correlation plot in Seaborn'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.5：Seaborn 中相关性图的热力图'
- en: '](img/B16925_03_05.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_05.jpg)'
- en: 'Figure 3.5: Heatmap of the correlation plot in Seaborn'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5：Seaborn 中相关性图的热力图
- en: The Seaborn `heatmap` feature makes an obvious visualization of the correlation
    matrix, according to the color scale on the right of *Figure 3.5*, which is called
    a `sns.heatmap`, in addition to the matrix, we supplied the **tick labels** for
    the *x* and *y* axes, which are the features and response names, and indicated
    that the center of the colorbar should be 0, so that positive and negative correlation
    are distinguishable as red and blue, respectively.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Seaborn 的 `heatmap` 功能能够清晰地可视化相关矩阵，参照*图 3.5*右侧的颜色标尺，这个功能叫做 `sns.heatmap`。除了矩阵外，我们还为
    *x* 和 *y* 轴提供了**刻度标签**，这些刻度标签分别代表特征和响应名称，并且指出颜色条的中心应该是 0，这样正相关和负相关就能分别以红色和蓝色区分开来。
- en: Note
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you''re reading the print version of this book, you can download and browse
    the color versions of some of the images in this chapter by visiting the following
    link: [https://packt.link/veMmT](https://packt.link/veMmT).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在阅读这本书的印刷版，你可以通过访问以下链接下载并浏览本章部分图像的彩色版本：[https://packt.link/veMmT](https://packt.link/veMmT)。
- en: What does this plot tell us? At a high level, if two features, or a feature
    and the response, are **highly correlated** with each other, you can say there
    is a strong association between them. Features that are highly correlated to the
    response will be good features to use for prediction. This high correlation could
    be positive or negative; we'll explain the difference shortly.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表告诉我们什么？从整体来看，如果两个特征或一个特征与响应之间的相关性**非常强**，那么你可以说它们之间存在很强的关联。与响应变量高度相关的特征将是预测中很好的特征。这个强相关性可以是正相关也可以是负相关；我们稍后会解释两者的区别。
- en: To see the correlation with the response variable, we look along the bottom
    row, or equivalently, the last column. Here we see that the `PAY_1` feature is
    probably the most strongly correlated feature to the response variable. We can
    also see that a number of features are highly correlated to each other, in particular
    the `BILL_AMT` features. We will talk in the next chapter about the importance
    of features that are correlated with each other; this is important to know about
    for certain models, such as logistic regression, that make assumptions about the
    correlations between features. For now, we make the observation that `PAY_1` is
    likely going to be one of the best, most predictive features for our model. The
    other feature that looks like it may be important is `LIMIT_BAL`, which is negatively
    correlated. Depending on how astute your vision is, only these two really appear
    to be any color other than black (meaning 0 correlation) in the bottom row of
    *Figure 3.5*.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看与响应变量的相关性，我们可以查看底部行，或者等价地，最后一列。在这里我们看到，`PAY_1` 特征可能是与响应变量最强相关的特征。我们还可以看到许多特征彼此之间高度相关，特别是
    `BILL_AMT` 特征。我们将在下一章讨论彼此相关的特征的重要性；对于某些模型（例如逻辑回归）来说，这一点非常重要，因为这些模型假设特征之间存在相关性。目前，我们可以观察到，`PAY_1`
    很可能是我们模型中最好的、最具预测力的特征。另一个看起来可能重要的特征是 `LIMIT_BAL`，它与响应变量呈负相关。根据你的观察能力，只有这两个特征在*图
    3.5*的底部行中看起来有颜色（即不同于黑色，表示 0 相关性）。
- en: Mathematics of Linear Correlation
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性相关性数学
- en: 'What is linear correlation, mathematically speaking? If you''ve taken basic
    statistics, you are likely familiar with linear correlation already. Linear correlation
    works very similarly to linear regression. For two columns, *X* and *Y*, linear
    correlation *ρ* (the lowercase Greek letter "rho") is defined as the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度来说，什么是线性相关性？如果你学过基础统计学，你可能已经对线性相关性有所了解。线性相关性与线性回归非常相似。对于两列数据，*X* 和 *Y*，线性相关性
    *ρ*（希腊字母“rho”）定义如下：
- en: '![Figure 3.6: Linear correlation equation'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.6：线性相关性方程'
- en: '](img/B16925_03_06.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_06.jpg)'
- en: 'Figure 3.6: Linear correlation equation'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6：线性相关性方程
- en: This equation describes the `[-1, 1]`. Because Pearson correlation is adjusted
    for the mean and standard deviation of the data, the actual values of the data
    are not as important as the relationship between *X* and *Y*. *Stronger linear
    correlations are closer to 1 or -1\. If there is no linear relation between X
    and Y, the correlation will be close to 0.*
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程描述了 `[-1, 1]`。因为皮尔逊相关性已经调整了数据的均值和标准差，所以数据的实际值并不像 *X* 和 *Y* 之间的关系那么重要。*较强的线性相关性越接近
    1 或 -1。如果 X 和 Y 之间没有线性关系，相关性将接近 0。*
- en: It's worth noting that, while it is regularly used in this context by data science
    practitioners, Pearson correlation is not strictly appropriate for a binary response
    variable, as we have in the case study problem. Technically speaking, among other
    restrictions, Pearson correlation is only valid for **continuous data**, such
    as the data we used for our linear regression exercise in *Chapter 2*, *Introduction
    to Scikit-Learn and Model Evaluation*. However, Pearson correlation can still
    accomplish the purpose of giving a quick idea of the potential usefulness of features.
    It is also conveniently available in software libraries such as pandas.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，尽管数据科学从业者在此背景下经常使用皮尔逊相关性，但对于二元响应变量，它并不严格适用，就像我们在案例研究问题中所遇到的那样。从技术上讲，皮尔逊相关性在其他一些限制条件下，仅适用于**连续数据**，例如我们在*第
    2 章*中使用的数据——*Scikit-Learn 和模型评估入门*。然而，皮尔逊相关性仍然可以快速提供特征潜在有用性的初步了解。它也方便地可以在如 pandas
    等软件库中找到。
- en: In data science in general, you will find that certain widely used techniques
    may be applied to data that violate their formal statistical assumptions. It is
    important to be aware of the formal assumptions underlying analytical methods.
    In fact, knowledge of these assumptions may be tested during interviews for data
    science jobs. However, in practice, as long as a technique can help us on our
    way to understanding the problem and finding an effective solution, it can still
    be a valuable tool.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学领域，通常会发现某些广泛使用的技术可能被应用于违反其正式统计假设的数据。了解分析方法背后的正式假设是很重要的。事实上，这些假设的知识可能会在数据科学职位的面试中进行考察。然而，在实际操作中，只要某项技术能帮助我们理解问题并找到有效的解决方案，它仍然可以是一个有价值的工具。
- en: 'That being said, linear correlation will not be an effective measure of the
    predictive power of all features. In particular, it only picks up on linear relationships.
    Shifting our focus momentarily to a hypothetical regression problem, have a look
    at the following examples and discuss what you expect the linear correlations
    to be. Notice that the values of the data on the *x* and *y* axes are not labeled;
    this is because the location (mean) and standard deviation (scale) of data does
    not affect the Pearson correlation, only the relationship between the variables,
    which can be discerned by plotting them together:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，线性相关性并不是所有特征预测能力的有效衡量标准。特别是，它只关注线性关系。稍微转移我们的焦点，假设我们正在处理一个回归问题，看看以下例子，并讨论你预期的线性相关性是什么。注意，数据的
    *x* 轴和 *y* 轴上的值没有标签；这是因为数据的位置（均值）和标准差（尺度）并不影响皮尔逊相关性，只有变量之间的关系会影响相关性，这可以通过将它们一起绘制出来来辨别：
- en: '![Figure 3.7: Scatter plots of the relationship between example variables'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.7：示例变量之间关系的散点图'
- en: '](img/B16925_03_07.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_07.jpg)'
- en: 'Figure 3.7: Scatter plots of the relationship between example variables'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7：示例变量之间关系的散点图
- en: 'For *examples A* and *B*, the actual Pearson correlations of these datasets
    are 0.96 and -0.97, respectively, according to the formula given previously. From
    looking at the plots, it''s pretty clear that a correlation close to 1 or -1 has
    provided useful insight into the relationship between these variables. For *example
    C*, the correlation is 0.06\. A correlation closer to 0 looks like an effective
    indication of the lack of an association here: the value of *Y* doesn''t really
    seem to have much to do with the value of *X*. However, in *example D*, there
    is clearly some relationship between the variables. But the linear correlation
    is actually lower than the previous example, at 0.02\. Here, *X* and *Y* tend
    to "move together" over smaller scales, but this is averaged out over all samples
    when the linear correlation is calculated.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*示例 A*和*B*，根据前面给出的公式，这些数据集的实际皮尔逊相关性分别为 0.96 和 -0.97。从图表上看，很明显，接近 1 或 -1 的相关性为我们提供了关于这些变量之间关系的有用见解。对于*示例
    C*，相关性为 0.06。接近 0 的相关性看起来有效地表明这里没有关联：*Y* 的值似乎与 *X* 的值没有太大关系。然而，在*示例 D*中，变量之间显然存在某种关系。但线性相关性实际上比前一个例子低，为
    0.02。在这里，*X* 和 *Y* 在较小的尺度上“共同变化”，但在计算线性相关性时，这种关系会被所有样本的平均值所抵消。
- en: Note
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The code to generate the plots presented in this and the preceding section
    can be found here: [https://packt.link/XrUJU](https://packt.link/XrUJU).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 生成本节及前一节中所示图表的代码可以在此找到：[https://packt.link/XrUJU](https://packt.link/XrUJU)。
- en: 'Ultimately, any summary statistic such as correlation that you may choose is
    only that: a summary. It could hide important details. For this reason, it is
    usually a good idea to visually examine the relationship between the features
    and response. This potentially takes up a lot of space on the page, so we won''t
    demonstrate it here for all features in the case study. However, both pandas and
    Seaborn offer functions to create what''s called a **scatter plot matrix**. A
    scatter plot matrix is similar to a correlation plot, but it actually shows all
    the data as a grid of scatter plots of all features and the response variable.
    This allows you to examine the data directly in a concise format. Since this could
    potentially be a lot of data and plots, you may need to downsample your data and
    look at a reduced number of features for the function to run efficiently.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，任何你选择的汇总统计量（如相关系数）都只是汇总。它可能会隐藏重要的细节。因此，通常最好通过可视化来检查特征和响应之间的关系。这可能会占用页面上的大量空间，因此我们不会在案例研究中对所有特征进行演示。然而，pandas
    和 Seaborn 都提供了创建**散点图矩阵**的功能。散点图矩阵类似于相关图，但它实际上显示了所有数据，以所有特征和响应变量的散点图网格的形式。这使你能够以简洁的格式直接检查数据。由于这可能包含大量数据和图表，你可能需要对数据进行降采样，并查看较少的特征，以便函数能够高效运行。
- en: F-test
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: F 检验
- en: 'While Pearson correlation is theoretically valid for continuous response variables,
    the binary response variable for the case study data could be considered categorical
    data, with only two categories: 0 and 1\. Among the different kinds of tests we
    can run, to see whether features are associated with a categorical response, is
    the `f_classif`. `f_regression`.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然皮尔逊相关系数在理论上对于连续响应变量是有效的，但案例研究数据中的二元响应变量可以视为分类数据，只有两个类别：0 和 1。在我们可以进行的不同类型的检验中，用于查看特征是否与分类响应相关的是
    `f_classif` 和 `f_regression`。
- en: We will do an ANOVA F-test using the candidate features for the case study data
    in the following exercise. You will see that the output consists of F-statistics,
    as well as **p-values**. How can we interpret this output? We will focus on the
    p-value, for reasons that will become clear in the exercise. The p-value is a
    useful concept across a wide variety of statistical measures. For instance, although
    we didn't examine them, each of the Pearson correlations calculated for the preceding
    correlation matrix has a corresponding p-value. There is a similar concept of
    a p-value corresponding to linear regression coefficients, logistic regression
    coefficients, and other measures.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用候选特征对案例研究数据进行 ANOVA F 检验。你将看到输出包括 F 统计量以及**p 值**。我们该如何解释这些输出？我们将重点关注 p
    值，原因将在练习中解释清楚。p 值是一个在多种统计测量中都很有用的概念。例如，虽然我们没有检查它们，但之前为相关矩阵计算的每个皮尔逊相关系数都有一个相应的
    p 值。对于线性回归系数、逻辑回归系数及其他测量值，也有类似的 p 值概念。
- en: 'In the context of the F-test, the p-value answers the question: "For the samples
    in the positive class, how likely is it that the average value of this feature
    is the same as that of samples in the negative class?" If the data indicated that
    a feature has very different average values between the positive and negative
    classes, the following will be the case:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在 F 检验的背景下，p 值回答了这个问题：“对于正类样本，特征的平均值与负类样本的平均值相同的可能性有多大？”如果数据表明某个特征在正负类样本之间的平均值非常不同，那么以下情况将成立：
- en: It will be very unlikely that those average values are the same (low p-value).
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些平均值相同的可能性将非常低（低 p 值）。
- en: It will probably be a good feature in our model because it will help us discriminate
    between positive and negative classes.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个特征可能是我们模型中的一个好特征，因为它有助于我们区分正负类样本。
- en: Keep these points in mind during the following exercise.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的练习中，请牢记以下几点。
- en: 'Exercise 3.01: F-test and Univariate Feature Selection'
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.01：F 检验和单变量特征选择
- en: 'In this exercise, we''ll use the F-test to examine the relationship between
    the features and response variable. We will use this method to do what is called
    **univariate feature selection**: the practice of testing features one by one
    against the response variable, to see which ones have predictive power. Perform
    the following steps to complete the exercise:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将使用 F 检验来检查特征和响应变量之间的关系。我们将使用这种方法进行所谓的**单变量特征选择**：逐一检验特征与响应变量的关系，看看哪些特征具有预测能力。请按以下步骤完成练习：
- en: Note
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注：
- en: 'The Jupyter notebook for this exercise can be found here: [https://packt.link/ZDPYf](https://packt.link/ZDPYf).
    This notebook also contains the prerequisite steps of loading the cleaned data
    and importing the necessary libraries. These steps should be executed before step
    1 of this exercise.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习的Jupyter笔记本可以在这里找到：[https://packt.link/ZDPYf](https://packt.link/ZDPYf)。该笔记本还包含加载清洗过的数据和导入必要库的先决步骤。在执行本练习的第一步之前，应该先执行这些步骤。
- en: 'Our first step in doing the ANOVA F-test is to separate out the features and
    response as NumPy arrays, taking advantage of the list we created, as well as
    integer indexing in pandas:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行ANOVA F检验的第一步是将特征和响应分离为NumPy数组，利用我们创建的列表以及pandas中的整数索引：
- en: '[PRE3]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output should show the shapes of the features and response:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该显示特征和响应的形状：
- en: '[PRE4]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: There are 17 features, and both the features and response arrays have the same
    number of samples as expected.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有17个特征，并且特征和响应数组的样本数与预期相同。
- en: 'Import the `f_classif` function and feed in the features and response:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`f_classif`函数并传入特征和响应：
- en: '[PRE5]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'There are two outputs from `f_classif`: the **F-statistic** and the **p-value**,
    for the comparison of each feature to the response variable. Let''s create a new
    DataFrame containing the feature names and these outputs, to facilitate our inspection.
    One way to specify a new DataFrame is by using a **dictionary**, with **key:value**
    pairs of column names and the data to be contained in each column. We show the
    DataFrame sorted (ascending) on p-value.'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`f_classif`有两个输出：**F统计量**和**p值**，用于比较每个特征与响应变量之间的关系。我们可以创建一个新的DataFrame，包含特征名称以及这些输出，以便于检查。我们展示了按p值升序排序的DataFrame。'
- en: 'Use this code to create a DataFrame of feature names, F-statistics, and p-values,
    and show it sorted on p-value:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建一个包含特征名称、F统计量和p值的DataFrame，并按p值排序显示：
- en: '[PRE6]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output should look like this:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 3.8: Results of the ANOVA F-test'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.8：ANOVA F检验结果'
- en: '](img/B16925_03_08.jpg)'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_08.jpg)'
- en: 'Figure 3.8: Results of the ANOVA F-test'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.8：ANOVA F检验结果
- en: Note that for every decrease in p-value, there is an increase in the F-statistic,
    so the information in these columns is identical in terms of ranking features.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，每当p值降低时，F统计量会增加，因此这些列中的信息在特征排名方面是相同的。
- en: 'The conclusions we can draw from the DataFrame of F-statistics and p-values
    are similar to what we observed in the correlation plot: `PAY_1` and `LIMIT_BAL`
    appear to be the most useful features. They have the smallest p-values, indicating
    the average values of these features are `SelectPercentile` class. Also note there
    is a similar class for the selection of the top "*k*" features (where *k* is any
    number you specify), called `SelectKBest`. Here we demonstrate how to select the
    top 20%.'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从F统计量和p值的DataFrame中得出的结论与我们在相关性图中观察到的相似：`PAY_1`和`LIMIT_BAL`似乎是最有用的特征。它们的p值最小，表示这些特征的平均值是`SelectPercentile`类。还要注意，选择前`*k*`个特征（其中*k*是您指定的任何数字）有类似的类，称为`SelectKBest`。在这里，我们演示如何选择前20%的特征。
- en: 'To select the top 20% of features according to the F-test, first import the
    `SelectPercentile` class:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要根据F检验选择前20%的特征，首先导入`SelectPercentile`类：
- en: '[PRE7]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Instantiate an object of this class, indicating we''d like to use the same
    feature selection criteria, ANOVA F-test, that we''ve already been considering
    in this exercise, and that we''d like to select the top 20% of features:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化该类的一个对象，表示我们希望使用与本练习中已经考虑过的相同特征选择标准——ANOVA F检验，并且我们希望选择前20%的特征：
- en: '[PRE8]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Use the `.fit` method to fit the object on our features and response data,
    similar to how a model would be fit:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.fit`方法对我们的特征和响应数据进行拟合，类似于模型拟合的方式：
- en: '[PRE9]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output should appear like this:'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE10]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: There are several ways to access the selected features directly, which you may
    learn about in the scikit-learn documentation (that is, the `.transform` method,
    or in the same step as fitting with `.fit_transform`). However, these methods
    will return NumPy arrays, which don't tell you the names of the features that
    were selected, just the values. For that, you can use the `.get_support` method
    of the feature selector object, which will give you the column indices of the
    feature array that were selected.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有几种方法可以直接访问所选特征，你可以在scikit-learn文档中了解（即`.transform`方法，或与`.fit_transform`在同一步骤中使用）。然而，这些方法会返回NumPy数组，它们不会告诉你已选择的特征名称，只会给出特征的值。为此，你可以使用特征选择器对象的`.get_support`方法，它将返回所选特征数组的列索引。
- en: 'Capture the indices of the selected features in an array named `best_feature_ix`:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所选特征的索引捕获到一个名为`best_feature_ix`的数组中：
- en: '[PRE11]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output should appear as follows, indicating a logical index that can be
    used with an array of feature names, as well as values, assuming they''re in the
    same order as the features array supplied to `SelectPercentile`:'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应如下所示，表示一个逻辑索引，可与特征名称数组及其对应的值一起使用，前提是它们与传递给`SelectPercentile`的特征数组的顺序一致：
- en: '[PRE12]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The feature names can be obtained using all but the last element (the `name`
    response variable) of our `features_response` list by indexing with `:-1`:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以通过索引`features_response`列表中的`:-1`，获取除最后一个元素（`name`响应变量）外的所有特征名称：
- en: '[PRE13]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Use the index array we created in *Step 7* with a list comprehension and the
    `features` list, to find the selected feature names, as follows:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们在*第7步*中创建的索引数组，通过列表推导式和`features`列表，查找所选特征名称，如下所示：
- en: '[PRE14]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output should be as follows:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '[PRE15]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In this code, the list comprehension has looped through the number of elements
    in the `features` array (`len(features)`) with the `counter` loop increment, using
    the `best_feature_ix` Boolean array, representing selected features, in the `if`
    statement to test whether each feature was selected and capturing the name if
    so.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这段代码中，列表推导式通过`features`数组中的元素数量（`len(features)`）和`counter`循环递增，使用`best_feature_ix`布尔数组表示已选择的特征，在`if`语句中测试每个特征是否被选择，如果是，则捕获该特征的名称。
- en: The selected features agree with the top four rows of our DataFrame of F-test
    results, so the feature selection has worked as expected. While it's not strictly
    necessary to do things both ways, since they both lead to the same result, it's
    good to check your work, especially as you are learning new concepts. You should
    be aware that with convenient methods such as `SelectPercentile`, you don't get
    visibility of the F-statistics or p-values. However, in some situations, it may
    be more convenient to use these methods, as the p-values may not necessarily be
    important, outside of their utility in ranking features.
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所选特征与我们的F检验结果数据框的前四行一致，因此特征选择按预期工作。尽管从严格意义上讲不必两种方式都做，因为它们都会导致相同的结果，但检查你的工作是一个好习惯，尤其是在你学习新概念时。你应该意识到，使用像`SelectPercentile`这样的便捷方法时，你无法看到F统计量或p值。然而，在某些情况下，使用这些方法可能更方便，因为p值的排名作用可能不是特别重要。
- en: 'Finer Points of the F-test: Equivalence to the t-test for Two Classes and Cautions'
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: F检验的细节：与两类t检验的等价性及注意事项
- en: When we use an F-test to look at the difference in means between just two groups,
    as we've done here for the binary classification problem of the case study, the
    test we are performing actually reduces to what's called a **t-test**. An F-test
    is extensible to three or more groups and so is useful for multiclass classification.
    A t-test just compares the means between two groups of samples, to see whether
    the difference in those means is **statistically significant**.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用F检验来查看仅两个组之间的均值差异时，正如我们在案例研究的二分类问题中所做的那样，实际上我们执行的检验会简化为**t检验**。F检验可以扩展到三个或更多组，因此对于多分类问题非常有用。t检验仅比较两个样本组之间的均值，以查看这些均值之间的差异是否**具有统计显著性**。
- en: While the F-test served our purposes here of univariate feature selection, there
    are a few cautions to keep in mind. Going back to the concept of formal statistical
    assumptions, for the F-test these include that the data is `y`, to many potential
    features from the matrix, `X`, we have performed what is known in statistics as
    **multiple comparisons**. In short, this means that by examining multiple features
    in comparison to the same response over and over, the odds increase that we'll
    find what we think is a "good feature" just by random chance. However, such features
    may not generalize to new data. There are statistical **corrections for multiple
    comparisons** that amount to adjusting the p-values to account for this.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 F 检验在这里满足了我们的单变量特征选择目的，但仍有一些注意事项需要牢记。回到正式统计假设的概念，对于 F 检验，这些假设包括数据为 `y`，从矩阵
    `X` 中提取了多个潜在特征，我们进行了统计学中所称的**多重比较**。简而言之，这意味着通过反复比较多个特征与同一响应的关系，我们找到“好特征”的机会会因为纯粹的随机机会而增加。然而，这些特征可能无法推广到新的数据。有针对**多重比较的统计修正**，即调整
    p 值以考虑这一点。
- en: Even if we have not followed all the statistical rules that go along with these
    methods, we can still get useful results from them. The multiple comparisons correction
    is more of a concern when p-values are the ultimate quantity of interest, for
    example, when making statistical inferences. Here, p-values are just a means to
    an end of ranking the feature list. The order of this ranking would not change
    if the p-values were corrected for multiple comparisons.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们没有遵循与这些方法相关的所有统计规则，我们仍然可以从中获得有用的结果。当 p 值是最终关注的量时，多重比较的修正会更为重要，例如在进行统计推断时。在这里，p
    值只是对特征列表进行排序的一种手段。如果对 p 值进行了多重比较修正，排序的顺序不会发生变化。
- en: In addition to knowing which features are likely to be useful for modeling,
    it is good to have a deeper understanding of the important features. Consequently,
    we will do a detailed graphical exploration of these in the next exercise. We
    will also look at other methods for feature selection later that don't make the
    same assumptions as those we've introduced here and are more directly integrated
    with the predictive models that we will build.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 除了了解哪些特征可能对建模有用外，深入理解重要特征也是很有必要的。因此，我们将在下一个练习中对这些特征进行详细的图形化探索。稍后我们还会查看其他特征选择方法，这些方法不作我们在此介绍的假设，并且与我们将要构建的预测模型更加直接集成。
- en: Hypotheses and Next Steps
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 假设和下一步
- en: 'According to our univariate feature exploration, the feature with the strongest
    association with the response variable is `PAY_1`. Does this make sense? What
    is the interpretation of `PAY_1`? `PAY_1` is the payment status of the account,
    in the most recent month. As we learned in the initial data exploration, there
    are some values that indicate that the account was in good standing: -2 means
    no account usage, -1 means balance paid in full, and 0 means at least the minimum
    payment was made. On the other hand, positive integer values indicate a delay
    of payment by that many months. Accounts with delayed payments last month were
    accounts that could be considered in default. This means that, essentially, this
    feature captures historical values of the response variable. Features such as
    this are extremely important as *one of the best predictors for just about any
    machine learning problem is historical data on the same thing you are trying to
    predict (that is, the response variable)*. This should make sense: people who
    have defaulted before are probably at the highest risk of defaulting again.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的单变量特征探索，和响应变量关联最强的特征是 `PAY_1`。这是否有意义？`PAY_1`的解释是什么？`PAY_1`是账户在最近一个月的付款状态。正如我们在最初的数据探索中所学到的，有些值表示账户状态良好：-2
    表示未使用账户，-1 表示余额已全额支付，0 表示至少已支付最低金额。另一方面，正整数值表示延迟付款的月份数。上个月延迟付款的账户可以视为违约账户。实际上，这意味着该特征捕捉到了响应变量的历史值。像这样的特征非常重要，因为*几乎任何机器学习问题中最好的预测因子之一就是关于你要预测的同一事物的历史数据（即响应变量）*。这应该是合理的：曾经违约过的人可能是再次违约的最高风险群体。
- en: How about `LIMIT_BAL`, the credit limit of accounts? Thinking about how credit
    limits are assigned, it is likely that our client has assessed how risky a borrower
    is when deciding their credit limit. Riskier clients should be given lower limits,
    so the creditor is less exposed. Therefore, we may expect to see a higher probability
    of default for accounts with lower values for `LIMIT_BAL`.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`LIMIT_BAL`，账户的信用额度如何？考虑到信用额度的分配方式，我们的客户很可能在决定他们的信用额度时评估了借款人的风险。风险更高的客户应该被给予较低的限额，这样债权人的风险就较小了。因此，我们可能期望看到`LIMIT_BAL`较低值的账户的违约概率较高。'
- en: 'What have we learned from our univariate feature selection exercise? We have
    an idea of what the most important features in our model are likely to be. And,
    from the correlation matrix, we have some idea of how they are related to the
    response variable. However, knowing the limitations of the tests we used, it is
    a good idea to visualize these features for a closer look at the relationship
    between the features and response variable. We have also started to develop **hypotheses**
    about these features: why do we think they are important? Now, by visualizing
    the relationships between the features and the response variable, we can determine
    whether our ideas are compatible with what we can see in the data.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从我们的单变量特征选择练习中学到了什么？我们对我们模型中最重要的特征有了一个大致的了解。并且从相关矩阵中，我们对它们与响应变量的关系有了一些想法。然而，知道我们所使用的测试的限制是个好主意，最好将这些特征可视化，以更仔细地观察特征和响应变量之间的关系。我们还开始对这些特征发展了**假设**：我们为什么认为它们很重要？现在，通过可视化特征和响应变量之间的关系，我们可以确定我们的想法是否与数据中所见的相符。
- en: Such hypotheses and visualizations are often a key part of presenting your results
    to a client, who may be interested in how a model works, not just the fact that
    it does work.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这些假设和可视化通常是向客户展示结果的重要部分，客户可能对模型的工作方式感兴趣，而不仅仅是它能工作这个事实。
- en: 'Exercise 3.02: Visualizing the Relationship Between the Features and Response
    Variable'
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.02：可视化特征与响应变量之间的关系
- en: 'In this exercise, you will further your knowledge of plotting functions from
    Matplotlib that you used earlier in this book. You''ll learn how to customize
    graphics to better answer specific questions with the data. As you pursue these
    analyses, you will create insightful visualizations of how the `PAY_1` and `LIMIT_BAL`
    features relate to the response variable, which may possibly provide support for
    the hypotheses you formed about these features. This will be done by becoming
    more familiar with the Matplotlib **Application Programming Interface** (**API**),
    in other words, the syntax you use to interact with Matplotlib. Perform the following
    steps to complete the exercise:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您将进一步了解本书中早期使用的 Matplotlib 绘图函数。您将学习如何自定义图形以更好地回答数据中的特定问题。随着您进行这些分析，您将创建关于`PAY_1`和`LIMIT_BAL`特征如何与响应变量相关的深刻可视化，这可能会支持您对这些特征形成的假设。这将通过更加熟悉
    Matplotlib **应用程序编程接口**（**API**）来完成，换句话说，您用来与 Matplotlib 交互的语法。执行以下步骤完成本练习：
- en: Note
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Before beginning step 1 of this exercise, make sure that you have imported
    the necessary libraries and have loaded the correct dataframe. You can refer to
    the following notebook for the prerequisite steps along with the code for this
    exercise: [https://packt.link/DOrZ9](https://packt.link/DOrZ9).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始本练习的第一步之前，请确保已导入必要的库并加载了正确的数据框架。您可以参考以下笔记本获取先决步骤以及此练习的代码：[https://packt.link/DOrZ9](https://packt.link/DOrZ9)。
- en: 'Calculate a baseline for the response variable of the default rate across the
    whole dataset using pandas'' `.mean()`:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 的 `.mean()` 计算整个数据集中响应变量的违约率基线：
- en: '[PRE16]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output of this should be the following:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个练习的输出应该如下所示：
- en: '[PRE17]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: What would be a good way to visualize default rates for different values of
    the `PAY_1` feature?
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如何有效地可视化`PAY_1`特征不同值的违约率？
- en: Recall our observation that this feature is sort of like a hybrid categorical
    and numerical feature. We'll choose to plot it in a way that is typical for categorical
    features, due to the relatively small number of unique values. In *Chapter 1*,
    *Data Exploration and Cleaning*, we did `value_counts` of this feature as part
    of data exploration, then later we learned about `groupby`/`mean` when looking
    at the `EDUCATION` feature. `groupby`/`mean` would be a good way to visualize
    the default rate again here, for different payment statuses.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 回想一下我们之前的观察，这个特征有点像混合型的类别和数值型特征。由于独特值的数量相对较少，我们选择以典型的类别特征方式来绘制它。在 *第1章*，《数据探索与清洗》中，我们在数据探索中使用了
    `value_counts` 来查看这个特征的分布，之后我们学习了如何通过 `groupby` 和 `mean` 来查看 `EDUCATION` 特征的情况。`groupby`
    和 `mean` 也是一个很好的方式来可视化不同支付状态下的违约率。
- en: 'Use this code to create a `groupby`/`mean` aggregation:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这段代码来创建一个 `groupby`/`mean` 聚合：
- en: '[PRE18]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '{''default payment next month'':np.mean})'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{''下个月违约支付'': np.mean})'
- en: '[PRE19]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output should look as follows:'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '![Figure 3.9: Mean of the response variable by groups of the PAY_1 feature'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.9：按 PAY_1 特征分组的响应变量的均值'
- en: '](img/B16925_03_09.jpg)'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_09.jpg)'
- en: 'Figure 3.9: Mean of the response variable by groups of the PAY_1 feature'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.9：按 PAY_1 特征分组的响应变量的均值
- en: Looking at these values, you may already be able to discern the trend. Let's
    go straight to plotting them. We'll take it step by step and introduce some new
    concepts. You should put all the code from *Steps 3* through *6* in a single code
    cell.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看着这些值，你可能已经能够辨别出趋势了。我们直接开始绘制它们。我们将一步步进行，并介绍一些新的概念。你应该把从 *步骤 3* 到 *步骤 6* 的所有代码放在一个代码单元格中。
- en: In Matplotlib, every plot exists on an axes, and within a `figure` window. By
    creating objects for `axes` and `figure`, you can directly access and change their
    properties, including axis labels and other kinds of annotation on the axes.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 Matplotlib 中，每个图表都存在于一个坐标轴（axes）和一个 `figure` 窗口中。通过创建 `axes` 和 `figure` 对象，你可以直接访问并修改它们的属性，包括坐标轴标签和坐标轴上的其他注释。
- en: 'Create an `axes` object in a variable also called `axes`, using the following
    code:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码在一个名为 `axes` 的变量中创建一个 `axes` 对象：
- en: '[PRE20]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Plot the overall default rate as a red horizontal line.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将整体违约率绘制为一条红色的水平线。
- en: 'Matplotlib makes this easy; you just have to indicate the *y* intercept of
    this line with the `axhline` function. Notice that instead of calling this function
    from `plt`, now we are calling it as a method on our `axes` object:'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Matplotlib 使这变得简单；你只需要通过 `axhline` 函数来指示该直线的 *y* 截距。注意，现在我们不是从 `plt` 调用这个函数，而是作为
    `axes` 对象的方法来调用：
- en: '[PRE21]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now, over this line, we want to plot the default rate within each group of `PAY_1` values.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们希望在这条线的基础上，绘制每个 `PAY_1` 值组内的违约率。
- en: 'Use the `plot` method of the DataFrame of grouped data we created. Specify
    to include an `''x''` marker along the line plot, to not have a `legend` instance,
    which we''ll create later, and that the **parent axes** of this plot should be
    the axes we are already working with (otherwise, pandas would erase what was already
    there and create new axes):'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们创建的分组数据的 DataFrame 的 `plot` 方法。指定在线条图中包括一个 `'x'` 标记，不要有 `legend` 实例（我们稍后会创建它），并且该图的
    **父轴** 应该是我们当前使用的轴（否则，pandas 会擦除已经存在的内容并创建新的轴）：
- en: '[PRE22]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This is all the data we want to plot.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这就是我们要绘制的所有数据。
- en: 'Set the *y*-axis label and create a `legend` instance (there are many possible
    options for controlling the legend appearance, but a simple way is to provide
    a list of strings, indicating the labels for the graphical elements in the order
    they were added to the axes):'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 *y* 轴标签，并创建一个 `legend` 实例（有许多控制图例外观的选项，但一种简单的方法是提供一个字符串列表，表示按添加到轴上的顺序排列的图形元素的标签）：
- en: '[PRE23]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Executing all the code from *Steps 3* through *6* in a single code cell should
    result in the following plot:![Figure 3.10: Credit default rates across the dataset'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行从 *步骤 3* 到 *步骤 6* 的所有代码，结果应该是以下图表：![图 3.10：数据集中的信用违约率
- en: '](img/B16925_03_10.jpg)'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_10.jpg)'
- en: 'Figure 3.10: Credit default rates across the dataset'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.10：数据集中的信用违约率
- en: 'Our visualization of payment statuses has revealed a clear, and probably expected,
    story: those who defaulted before are in fact more likely to default again. The
    default rate of accounts in good standing is well below the overall default rate,
    which we know from before is about 22%. However, over 30% of the accounts that
    were in default last month will be in default again next month, according to this.
    This is a good visual to share with our business partner as it shows the effect
    of what may be one of the most important features in our model.'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对支付状态的可视化揭示了一个明确的，并且可能是预期的故事：那些曾经违约的人实际上更可能再次违约。保持良好状态的账户的违约率远低于整体违约率，后者我们之前知道大约是
    22%。然而，根据这一点，超过 30% 上个月处于违约状态的账户下个月仍然会处于违约状态。这是一个很好的可视化，值得与我们的业务合作伙伴分享，因为它展示了我们模型中可能是最重要的特征之一的影响。
- en: 'Now we turn our attention to the feature ranked as having the second strongest
    association with the target variable: `LIMIT_BAL`. This is a numerical feature
    with many unique values. A good way to visualize features such as this, for a
    classification problem, is to plot multiple histograms on the same axis, with
    different colors for the different classes. As a way to separate the classes,
    we can index them from the DataFrame using logical arrays.'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们将注意力转向排名第二与目标变量关联最强的特征：`LIMIT_BAL`。这是一个具有许多唯一值的数值特征。对于分类问题，查看此类特征的一个好方法是将多个直方图绘制在同一坐标轴上，为不同类别使用不同的颜色。作为区分类别的一种方式，我们可以使用逻辑数组从
    DataFrame 中索引它们。
- en: 'Use this code to create logical masks for positive and negative samples:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用此代码为正类和负类样本创建逻辑掩码：
- en: '[PRE24]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'To create our dual histogram plot, we''ll make another `axes` object, then
    call the `.hist` method on it twice for the positive and negative class histograms.
    We supply a few additional keyword arguments: the first histogram will have black
    edges and white bars, while the second will use `alpha` to create transparency,
    so we can see both histograms in the places they overlap. Once we have the histograms,
    we rotate the *x*-axis tick labels to make them more legible and create several
    other annotations that should be self-explanatory.'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了创建我们的双重直方图，我们将再创建一个 `axes` 对象，然后调用 `.hist` 方法分别为正类和负类直方图绘制两次。我们提供一些额外的关键字参数：第一个直方图将有黑色边缘和白色条形，而第二个将使用
    `alpha` 来创建透明度，这样我们就可以看到两个直方图在重叠的地方。得到直方图后，我们旋转 *x* 轴刻度标签，使它们更易读，并创建一些其他自解释的注释。
- en: 'Use the following code to create the dual histogram plot with the aforementioned
    properties:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码来创建具有上述属性的双重直方图：
- en: '[PRE25]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The plot should appear like this:'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图表应该如下所示：
- en: '![Figure 3.11: Dual histograms of credit limits'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.11：信用额度的双重直方图'
- en: '](img/B16925_03_11.jpg)'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_11.jpg)'
- en: '[PRE26]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Create and display the histogram bin edges with this code:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建并显示直方图的箱子边缘：
- en: '[PRE27]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output should be as follows:'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE28]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The plotting code for the normalized histograms is similar to before, with
    a few key changes: the use of the `bins` keyword to define bin edge locations,
    `density=True` to normalize the histograms, and changes to the plot annotations.
    The most complex part is that we need to adjust the `np.round` is needed due to
    slight errors of floating-point arithmetic.'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 归一化直方图的绘图代码与之前类似，但有几个关键的变化：使用 `bins` 关键字来定义箱子边缘的位置，`density=True` 用于归一化直方图，并对绘图注释进行了一些更改。最复杂的部分是我们需要调整
    `np.round`，因为浮点数运算可能会有轻微的误差。
- en: 'Run this code to produce normalized histograms:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码以生成归一化的直方图：
- en: '[PRE29]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The plot should look like this:'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图表应该如下所示：
- en: '![Figure 3.12: Normalized dual histograms'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.12：归一化的双重直方图'
- en: '](img/B16925_03_12.jpg)'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_12.jpg)'
- en: 'Figure 3.12: Normalized dual histograms'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.12：归一化的双重直方图
- en: 'You can see that plots in Matplotlib are highly customizable. In order to view
    all the different things you can get from and set on Matplotlib axes, have a look
    here: [https://matplotlib.org/stable/api/axes_api.html](https://matplotlib.org/stable/api/axes_api.html).'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，Matplotlib 中的图表是高度可定制的。为了查看你可以从 Matplotlib 坐标轴中获取和设置的所有不同内容，可以查看这里：[https://matplotlib.org/stable/api/axes_api.html](https://matplotlib.org/stable/api/axes_api.html)。
- en: What can we learn from this plot? It looks like the accounts that default tend
    to have a higher proportion of lower credit limits. Accounts with credit limits
    less than NT$150,000 are relatively more likely to default, while the opposite
    is true for accounts with limits higher than this. We should ask ourselves, does
    this make sense? Our hypothesis was that the client would give riskier accounts
    lower limits. This intuition is compatible with the higher proportions of defaulters
    with lower credit limits that we observed here.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从这个图表中能学到什么？看起来，违约的账户往往具有较高比例的低信用额度。信用额度低于新台币150,000元的账户更有可能违约，而对于信用额度高于这个数额的账户则相反。我们应该问自己，这是否有意义？我们的假设是，客户会给风险较高的账户设置较低的信用额度。这种直觉与我们在此观察到的低信用额度账户中违约者的较高比例相符。
- en: Depending on how the model building goes, if the features we examined in this
    exercise turn out to be important for predictive modeling as we expect, it would
    be good to show these graphs to our client, as part of a presentation of our work.
    This would give the client insight into how the model works, as well as insights
    into their data.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型构建的进展，如果我们在本次练习中检查的特征如我们预期的那样对预测建模非常重要，那么将这些图表展示给客户作为我们工作成果的一部分是很好的。这样可以让客户了解模型如何工作，以及对他们数据的洞察。
- en: A key learning from this section is that effective visual presentations take
    substantial time to produce. It is good to budget some time in your project workflow
    for this. Convincing visuals are worth the effort since they should be able to
    quickly and effectively communicate important findings to the client. They are
    usually a better choice than adding lots of text to the materials that you create.
    Visual communication of quantitative concepts is a core data science skill.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的一个重要学习点是，制作有效的视觉展示需要大量时间。最好在项目工作流程中预留一些时间用于此项工作。令人信服的视觉效果是值得付出努力的，因为它们应该能够迅速且有效地将重要的发现传达给客户。与其在制作材料时加入大量文字，视觉效果通常是更好的选择。定量概念的视觉传达是数据科学的核心技能。
- en: 'Univariate Feature Selection: What it Does and Doesn''t Do'
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单变量特征选择：它能做什么，不能做什么
- en: In this chapter, we have learned techniques for going through features one by
    one to see whether they have predictive power. This is a good first step, and
    if you already have features that are very predictive of the outcome variable,
    you may not need to spend much more time considering features before modeling.
    However, there are drawbacks to univariate feature selection. In particular, it
    does not consider the **interactions** between features. For example, what if
    the credit default rate is very high specifically for people with both a certain
    education level and a certain range of credit limit?
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们学习了逐一查看特征以判断它们是否具有预测能力的技巧。这是一个良好的第一步，如果你已经有了对结果变量具有较强预测能力的特征，你可能不需要花太多时间考虑其他特征，便可以进行建模。然而，单变量特征选择也有其缺点，特别是它没有考虑特征之间的**相互作用**。例如，如果信用违约率特别高的是那些既有某种教育水平又有一定范围的信用额度的人群怎么办？
- en: Also, with the methods we used here, only the linear effects of features are
    captured. If a feature is more predictive when it's undergone some type of **transformation**,
    such as a **polynomial** or **logarithmic** transformation, or **binning** (**discretization**),
    linear techniques of univariate feature selection may not be effective. Interactions
    and transformations are examples of **feature engineering**, or creating new features,
    in these cases from existing features. The shortcomings of linear feature selection
    methods can be remedied by non-linear modeling techniques including decision trees
    and methods based on them, which we will examine later. But there is still value
    in looking for simple relationships that can be found by linear methods for univariate
    feature selection, and it is quick to do.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们在这里使用的方法仅能捕捉特征的线性效应。如果某个特征在经历某种**变换**（如**多项式**或**对数**变换，或者**分箱**（**离散化**））后能更好地预测，单变量特征选择的线性方法可能就不太有效。相互作用和变换是**特征工程**的例子，或者说，在这些情况下通过现有特征创建新特征。线性特征选择方法的不足可以通过非线性建模技术来弥补，包括决策树及其相关方法，我们将在后续进行讨论。但从简单关系入手，寻找那些可以通过线性方法实现的单变量特征选择，依然具有价值，而且这种方法非常迅速。
- en: Understanding Logistic Regression and the Sigmoid Function Using Function Syntax
    in Python
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Python函数语法理解逻辑回归和Sigmoid函数
- en: 'In this section, we will open the "black box" of logistic regression all the
    way: we will gain a comprehensive understanding of how it works. We''ll start
    off by introducing a new programming concept: **functions**. At the same time,
    we''ll learn about a mathematical function, the sigmoid function, which plays
    a key role in logistic regression.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将全面揭开逻辑回归的“黑箱”：我们将全面理解它是如何工作的。我们将从介绍一个新的编程概念：**函数**开始。同时，我们将学习一个数学函数——sigmoid函数，它在逻辑回归中起着关键作用。
- en: 'In the most basic sense, a function in computer programming is a piece of code
    that takes inputs and produces outputs. You have been using functions throughout
    the book: functions that were written by someone else. Any time that you use syntax
    such as this: `output = do_something_to(input)`, you have used a function. For
    example, NumPy has a function you can use to calculate the mean of the input:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 从最基本的角度来看，计算机编程中的函数是一段接受输入并产生输出的代码。你在本书中已经使用了函数：这些函数是由别人编写的。每次你使用类似于这样的语法：`output
    = do_something_to(input)`时，你实际上就是在使用一个函数。例如，NumPy 有一个函数可以用来计算输入的均值：
- en: '[PRE30]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Functions **abstract** away the operations being performed so that, in our
    example, you don''t need to see all the lines of code that it takes to calculate
    a mean, every time you need to do this. For many common mathematical functions,
    there are already pre-defined versions available in packages such as NumPy. You
    do not need to "reinvent the wheel." The implementations in popular packages are
    likely popular for a reason: people have spent time thinking about how to create
    them in the most efficient way. So, it would be wise to use them. However, since
    all the packages we are using are **open source**, if you are interested in seeing
    how the functions in the libraries we use are implemented, you are able to look
    at the code within any of them.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 函数**抽象**了正在执行的操作，以便在我们的示例中，每次需要计算均值时，你不需要看到所有执行此操作的代码行。对于许多常见的数学函数，像NumPy这样的包中已经有了预定义的版本。你无需“发明轮子”。流行包中的实现之所以流行，可能是因为人们花了时间思考如何以最有效的方式创建它们。因此，使用它们是明智的。然而，由于我们使用的所有包都是**开源**的，如果你有兴趣查看我们使用的库中函数的实现，你可以查看它们的代码。
- en: 'Now, for the sake of illustration, let''s learn Python function syntax by writing
    our own function for the arithmetic mean. Function syntax in Python is similar
    to `for` or `if` blocks, in that the body of a function is indented and the declaration
    of the function is followed by a colon. Here is the code for a function to compute
    the mean:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了说明，我们通过编写自己的算术平均数函数来学习Python函数语法。Python中的函数语法类似于`for`或`if`块，其中函数体是缩进的，函数声明后面跟着一个冒号。下面是一个计算均值的函数代码：
- en: '[PRE31]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'After you execute the code cell with this definition, the function is available
    to you in other code cells in the notebook. Take the following example:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在你执行了包含此定义的代码单元后，函数在笔记本中的其他代码单元中可以使用。举个例子：
- en: '[PRE32]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The first part of defining a function, as shown here, is to start a line of
    code with `def`, followed by a space, followed by the name you''d like to call
    the function. After this come parentheses, inside which the names of the **parameters**
    of the function are specified. Parameters are names of the input variables, where
    these names are internal to the body of the function: the variable names defined
    as parameters are available within the function when it is **called** (used),
    but not outside the function. There can be more than one parameter; they would
    be comma-separated. After the parentheses comes a colon.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 定义函数的第一部分，如这里所示，是以`def`开始一行代码，后面跟一个空格，然后是你想为函数命名的名称。接下来是括号，括号内指定函数的**参数**名称。参数是输入变量的名称，这些名称是函数体内部的：作为参数定义的变量在函数被**调用**（使用）时可用，但在函数外部不可用。可以有多个参数；它们之间用逗号分隔。括号后跟冒号。
- en: The body of the function is indented and can contain any code that operates
    on the inputs. Once these operations are done, the last line should start with
    `return` and contain the output variable(s), comma-separated if there is more
    than one. We are leaving out many fine points in this very simple introduction
    to functions, but those are the essential parts you need to get started.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 函数体是缩进的，可以包含对输入进行操作的任何代码。操作完成后，最后一行应以`return`开头，并包含输出变量，如果有多个输出变量，它们之间用逗号分隔。在这段非常简单的函数介绍中，我们省略了许多细节，但这些是你开始使用函数时需要掌握的基本部分。
- en: The power of a function comes when you use it. Notice how after we define the
    function, in a separate code block we can **call** it by the name we've given
    it, and it operates on whatever inputs we **pass** it. It's as if we've copied
    and pasted all the code to this new location. But it looks much nicer than actually
    doing that. And if you are going to use the same code many times, a function can
    greatly reduce the overall length of your code.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的威力在于它的使用。注意，我们定义了函数后，在一个单独的代码块中，我们可以通过给定的名称 **调用** 它，它会对我们 **传递** 的输入进行操作。就像我们把所有代码复制粘贴到这个新位置一样，但看起来比实际复制粘贴要整洁得多。如果你需要多次使用相同的代码，函数可以大大减少代码的整体长度。
- en: 'As a brief additional note, you can optionally specify the inputs using the
    parameter names explicitly, which can be clearer when there are many inputs:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个简短的补充说明，你可以选择明确指定输入参数的名称，这样在有多个输入时会更清晰：
- en: '[PRE33]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now that we''re familiar with the basics of Python functions, we are going
    to consider a mathematical function that''s important to logistic regression,
    called **sigmoid**. This function may also be called the **logistic function**.
    The definition of sigmoid is as follows:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经熟悉了 Python 函数的基础知识，接下来我们将讨论一个对逻辑回归非常重要的数学函数，叫做 **Sigmoid** 函数。这个函数也可以称为
    **逻辑函数**。Sigmoid 的定义如下：
- en: '![Figure 3.13: The sigmoid function'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.13：Sigmoid 函数'
- en: '](img/B16925_03_13.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_13.jpg)'
- en: 'Figure 3.13: The sigmoid function'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.13：Sigmoid 函数
- en: 'We will break down the different parts of this function. As you can see, the
    sigmoid function involves the `exp`, that takes `e` to the input exponent automatically.
    If you look at the documentation, you will see this process is called taking the
    "exponential," which sounds vague. But it is assumed to be understood that the
    base of the exponent is *e* in this case. In general, if you want to take an exponent
    in Python, such as 23 ("two to the third power"), the syntax is two asterisks:
    `2**3`, which equals 8, for example.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分解这个函数的不同部分。正如你所看到的，sigmoid 函数涉及到 `exp`，它会自动将 `e` 提供给输入指数。如果你查看文档，你会看到这个过程叫做取“指数”，这听起来有点模糊。但通常理解的是，这里指数的底数是
    *e*。一般来说，如果你想在 Python 中计算指数，比如 23（“2 的三次方”），语法是两个星号：`2**3`，例如结果为 8。
- en: 'Consider how inputs may be passed to the `np.exp` function. Since NumPy''s
    implementation is **vectorized**, this function can take individual numbers as
    well as arrays or matrices as input. To illustrate individual arguments, we compute
    the exponential of 1, which shows the approximate value of *e*, as well as *e0*,
    which of course equals 1, as does the zeroth power of any base:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑如何将输入传递给 `np.exp` 函数。由于 NumPy 的实现是 **向量化** 的，这个函数可以接受单个数字，也可以接受数组或矩阵作为输入。为了说明单个参数，我们计算了
    1 的指数，这显示了 *e* 的近似值，以及 *e0*，它当然等于 1，就像任何底数的零次方一样：
- en: '[PRE34]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To illustrate the vectorized implementation of `np.exp`, we create an array
    of numbers using NumPy''s `linspace` function. This function takes as input the
    starting and stopping points of a range, both inclusive, and the number of values
    you''d like within that range, to create an array of that many linearly spaced
    values. This function performs a somewhat similar role to Python''s `range`, but
    can also produce decimal values:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明 `np.exp` 的向量化实现，我们使用 NumPy 的 `linspace` 函数创建一个数字数组。这个函数输入一个范围的起始和结束点（包括这两个点），以及该范围内你希望包含的值的数量，以创建一个等间距的数组。这个函数的作用与
    Python 的 `range` 类似，但还可以生成小数值：
- en: '![Figure 3.14: Using np.linspace to make an array'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.14：使用 np.linspace 创建数组'
- en: '](img/B16925_03_14.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_14.jpg)'
- en: 'Figure 3.14: Using np.linspace to make an array'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.14：使用 np.linspace 创建数组
- en: 'Since `np.exp` is vectorized, it will compute the exponential of the whole
    array at once, in an efficient manner. Here is the code with output, to calculate
    the exponential of our `X_exp` array and examine the first five values:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `np.exp` 是向量化的，它会一次性高效地计算整个数组的指数。这里是计算我们 `X_exp` 数组的指数并检查前五个值的代码和输出：
- en: '![Figure 3.15: NumPy''s exp function'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.15：NumPy 的 exp 函数'
- en: '](img/B16925_03_15.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_15.jpg)'
- en: 'Figure 3.15: NumPy''s exp function'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.15：NumPy 的 exp 函数
- en: 'Exercise 3.03: Plotting the Sigmoid Function'
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.03：绘制 Sigmoid 函数
- en: 'In this exercise, we will use `X_exp` and `Y_exp`, created previously, to make
    a plot of what the exponential function looks like over the interval `[-4, 4]`.
    You need to have run all the code in *Figures 3.14* and *3.15* to have these variables
    available for this exercise. Then we will define a function for the sigmoid, create
    a plot of that, and consider how it is related to the exponential function. Perform
    the following steps to complete the exercise:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用先前创建的 `X_exp` 和 `Y_exp`，绘制指数函数在区间 `[-4, 4]` 上的图形。你需要先运行 *图 3.14*
    和 *图 3.15* 中的所有代码，以便为本练习提供这些变量。接下来，我们将定义一个 sigmoid 函数，绘制它的图形，并考虑它与指数函数的关系。执行以下步骤以完成此练习：
- en: Note
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Before beginning step 1 of this exercise, make sure that you have imported the
    necessary libraries. The code for importing the libraries along with that for
    rest of the steps in the exercise can be found here: [https://packt.link/Uq012](https://packt.link/Uq012).'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始本练习的第一步之前，请确保你已导入必要的库。导入库的代码以及练习其余步骤的代码可以在这里找到：[https://packt.link/Uq012](https://packt.link/Uq012)。
- en: 'Use this code to plot the exponential function:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用此代码绘制指数函数：
- en: '[PRE35]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The plot should look like this:'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图形应该是这样的：
- en: '![Figure 3.14: Using np.linspace to make an array'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.14：使用 np.linspace 创建一个数组'
- en: '](img/B16925_03_16.jpg)'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_16.jpg)'
- en: 'Figure 3.16: Plotting the exponential function'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.16：绘制指数函数
- en: Notice that in titling the plot, we've taken advantage of a kind of syntax called
    `^`.
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，在图表标题中，我们利用了一种叫做 `^` 的语法。
- en: Also note in *Figure 3.16* that many points spaced close together create the
    appearance of a smooth curve, but in fact, it is a graph of discrete points connected
    by line segments.
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 还要注意在 *图 3.16* 中，许多紧密间隔的点创造出平滑曲线的效果，但实际上它是由离散点通过线段连接而成的图形。
- en: '**What can we observe about the exponential function?**'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**我们可以从指数函数中观察到什么？**'
- en: 'It is never negative: as *X* approaches negative infinity, *Y* approaches 0.'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它永远不会是负数：当 *X* 趋近于负无穷时，*Y* 趋近于 0。
- en: As *X* increases, *Y* increases slowly at first, but very quickly "blows up."
    This is what is meant when people say "exponential growth" to signify a rapid
    increase.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随着 *X* 的增加，*Y* 起初增长缓慢，但很快就“爆炸”了。这就是人们所说的“指数增长”来表示快速增长的含义。
- en: '**How can you think about the sigmoid in terms of the exponential?**'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**你如何从指数函数的角度理解 sigmoid？**'
- en: First, the sigmoid involves *e*-X, as opposed to *e*X. The graph of *e*-X is
    just the reflection of *e*X about the *y* axis. This can be plotted easily and
    annotated using curly braces for multiple-character superscript in the plot title.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，sigmoid 涉及 *e*-X，而不是 *e*X。*e*-X 的图形只是 *e*X 关于 *y* 轴的反射。这可以很容易地绘制出来，并在图表标题中使用大括号标注多字符的上标。
- en: 'Run this code to see the plot of *e*-X:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码以查看 *e*-X 的图形：
- en: '[PRE36]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output should appear like this:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该是这样的：
- en: '![Figure 3.17: Plot of exp(-X)'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.17：exp(-X) 的图'
- en: '](img/B16925_03_17.jpg)'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_17.jpg)'
- en: 'Figure 3.17: Plot of exp(-X)'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.17：exp(-X) 的图
- en: Now, in the sigmoid function, *e*-X is in the denominator, with 1 added to it.
    The numerator is 1\. So, what happens to the sigmoid as *X* approaches negative
    infinity? We know that *e*-X "blows up," becoming very large. Overall, the denominator
    becomes very large and the fraction approaches 0\. What about when *X* increases
    toward positive infinity? We can see that *e*-X becomes very close to 0\. So,
    in this case, the sigmoid function would be approximately *1/1 = 1*. This should
    give you an intuition that the sigmoid function stays between 0 and 1\. Let's
    now implement a sigmoid function in Python and use it to create a plot to see
    how reality matches this intuition.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，在 sigmoid 函数中，*e*-X 位于分母，且加上了 1。分子是 1。那么，当 *X* 趋近于负无穷时，sigmoid 会发生什么呢？我们知道
    *e*-X 会“爆炸”，变得非常大。总的来说，分母变得非常大，分数接近于 0。那么，当 *X* 增加到正无穷时，会怎样呢？我们可以看到 *e*-X 会变得非常接近于
    0。所以，在这种情况下，sigmoid 函数大约等于 *1/1 = 1*。这应该给你一个直觉，sigmoid 函数始终保持在 0 和 1 之间。现在让我们在
    Python 中实现一个 sigmoid 函数，并用它绘制一个图形，看看现实与这个直觉如何匹配。
- en: 'Define a sigmoid function like this:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个 sigmoid 函数，如下所示：
- en: '[PRE37]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Make a larger range of *x* values to plot over and plot the sigmoid. Use this
    code:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩大 *x* 值的范围以绘制 sigmoid 图。使用以下代码：
- en: '[PRE38]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The plot should look like this:'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图形应该是这样的：
- en: '![Figure 3.18: A sigmoid function plot'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.18：一个 sigmoid 函数图'
- en: '](img/B16925_03_18.jpg)'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_18.jpg)'
- en: 'Figure 3.18: A sigmoid function plot'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.18：一个 sigmoid 函数图
- en: This plot matches what we expected. Further, we can see that `sigmoid(0) = 0.5`.
    What is special about the sigmoid function? The output of this function is strictly
    bounded between 0 and 1\. This is a good property for a function that should predict
    probabilities, which are also required to be between 0 and 1\. Technically, probabilities
    can be exactly equal to 0 and 1, while the sigmoid never is. But the sigmoid can
    be close enough that this is not a practical limitation.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图与我们预期的结果一致。此外，我们可以看到`sigmoid(0) = 0.5`。那么，sigmoid函数有什么特别之处？这个函数的输出严格地限制在0和1之间。对于一个应该预测概率的函数来说，这个特性非常好，因为概率值也必须在0和1之间。技术上，概率值可以恰好等于0和1，而sigmoid函数永远不会是。但sigmoid函数的值可以接近0或1，这在实际中并不是一个限制。
- en: Recall that we described logistic regression as producing **predicted probabilities**
    of class membership, as opposed to directly predicting class membership. This
    enables a more flexible implementation of logistic regression, allowing the selection
    of the threshold probability. The sigmoid function is the source of these predicted
    probabilities. Shortly, we will see how the different features are used in the
    calculation of the predicted probabilities.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，我们将逻辑回归描述为生成**预测的类别概率**，而不是直接预测类别成员资格。这使得逻辑回归的实现更加灵活，可以选择阈值概率。sigmoid函数是这些预测概率的来源。稍后，我们将看到不同特征是如何用于计算预测概率的。
- en: Scope of Functions
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 函数的作用域
- en: 'As you begin to use functions, you should develop an awareness of the concept
    of `sigmoid` function, we created a variable, `Y`, inside the function. Variables
    created inside functions are different from those created outside functions. They
    are effectively created and destroyed within the function itself when it is called.
    These variables are said to be `Y` variable after using the `sigmoid` function:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始使用函数时，你应该对`sigmoid`函数的概念有所了解，我们在函数内部创建了一个变量`Y`。在函数内部创建的变量与在函数外部创建的变量不同。它们在函数被调用时会在函数内部有效地创建和销毁。这些变量在使用`sigmoid`函数后被称为`Y`变量：
- en: '![Figure 3.19: The Y variable not in the scope of the notebook'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.19：Y变量不在笔记本的作用域内'
- en: '](img/B16925_03_19.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_19.jpg)'
- en: 'Figure 3.19: The Y variable not in the scope of the notebook'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.19：Y变量不在笔记本的作用域内
- en: 'The `Y` variable is not in the **global** scope of the notebook. However, global
    variables created outside of functions are available within the local scope of
    functions, even if they are not inputted as parameters to the function. Here we
    demonstrate creating a variable outside of a function, which is global in scope,
    and then accessing it within a function. The function actually doesn''t take any
    parameters at all, but as you can see, it can work with the value of the global
    variable to create an output:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '`Y`变量不在笔记本的**全局**作用域中。然而，在函数外部创建的全局变量可以在函数的局部作用域内使用，即使它们没有作为参数传递给函数。在这里，我们展示了如何在函数外部创建一个全局变量，然后在函数内部访问它。这个函数实际上没有接受任何参数，但如你所见，它可以使用全局变量的值来生成输出：'
- en: '![Figure 3.20: Global variable available within the local scope of the function'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.20：全局变量在函数的局部作用域中可用'
- en: '](img/B16925_03_20.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_20.jpg)'
- en: 'Figure 3.20: Global variable available within the local scope of the function'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.20：全局变量在函数的局部作用域中可用
- en: Note
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '**More details on scope**'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '**更多关于作用域的细节**'
- en: 'The scope of variables can potentially be confusing but is good to know when
    you start making more advanced use of functions. While this knowledge isn''t required
    for the book, you may wish to get a more in-depth perspective on variable scope
    in Python here: [https://nbviewer.jupyter.org/github/rasbt/python_reference/blob/master/tutorials/scope_resolution_legb_rule.ipynb](https://nbviewer.jupyter.org/github/rasbt/python_reference/blob/master/tutorials/scope_resolution_legb_rule.ipynb).'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 变量的作用域可能会让人感到困惑，但当你开始更高级地使用函数时，了解作用域是非常有益的。虽然本书中并不要求了解这些内容，但你可能希望在这里了解更多关于Python中变量作用域的深度知识：[https://nbviewer.jupyter.org/github/rasbt/python_reference/blob/master/tutorials/scope_resolution_legb_rule.ipynb](https://nbviewer.jupyter.org/github/rasbt/python_reference/blob/master/tutorials/scope_resolution_legb_rule.ipynb)。
- en: '**Sigmoid curves in scientific applications**'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '**sigmoid曲线在科学应用中的应用**'
- en: Besides being fundamental to logistic regression, sigmoid curves are used in
    a variety of applications. In biology, they can be used to describe the growth
    of an organism, which starts slowly, then has a rapid phase, followed by a smooth
    tapering off as the final size is reached. Sigmoids can also be used to describe
    population growth, which has a similar trajectory, increasing rapidly but then
    slowing as the carrying capacity of the environment is reached.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在逻辑回归中是基础，S型曲线还广泛应用于各种领域。在生物学中，它们可以用来描述生物体的生长过程，首先是缓慢开始，然后进入快速阶段，最后以平滑的方式逐渐趋于稳定，直到最终大小达到。S型曲线也可以用来描述人口增长，其轨迹类似，快速增长后会减慢，直到环境的承载能力达到。
- en: Why Is Logistic Regression Considered a Linear Model?
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么逻辑回归被认为是线性模型？
- en: We mentioned previously that logistic regression is considered a `groupby`/`mean`
    of the `EDUCATION` feature in *Chapter 1*, *Data Exploration and Cleaning*, as
    well as for the `PAY_1` feature in this chapter, to see whether the default rates
    across values of these features exhibited a linear trend. While this is a good
    way to get a quick approximation of how "linear or not" these features may be,
    here we formalize the notion of why logistic regression is a linear model.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到，逻辑回归被认为是*第一章*《数据探索与清洗》中`EDUCATION`特征的`groupby`/`mean`，以及本章中`PAY_1`特征的`groupby`/`mean`，用来查看这些特征值之间的违约率是否表现出线性趋势。虽然这是一种快速近似判断这些特征是否“线性”的好方法，但在这里我们将形式化为什么逻辑回归是线性模型的概念。
- en: 'A model is considered linear if the transformation of features that is used
    to calculate the prediction is a **linear combination** of the features. The possibilities
    for a linear combination are that each feature can be multiplied by a numerical
    constant, these terms can be added together, and an additional constant can be
    added. For example, in a simple model with two features, *X*1 and *X*2, a linear
    combination would take the following form:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如果计算预测所使用的特征变换是特征的**线性组合**，则该模型被认为是线性的。线性组合的可能性是每个特征可以乘以一个数值常数，这些项可以相加，并且可以添加一个额外的常数。例如，在一个简单的包含两个特征的模型中，*X*1
    和 *X*2，线性组合的形式如下：
- en: '![Figure 3.21: Linear combination of X1 and X2'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.21：*X*1 和 *X*2 的线性组合'
- en: '](img/B16925_03_21.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_21.jpg)'
- en: 'Figure 3.21: Linear combination of X1 and X2'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.21：*X*1 和 *X*2 的线性组合
- en: The constants *𝜃*i can be any number, positive, negative, or zero, for *i =
    0, 1, and 2* (although if a coefficient is 0, this removes a feature from the
    linear combination). A familiar example of a linear transformation of one variable
    is a straight line with the equation *y = mx + b*, as discussed *Chapter 2*, *Introduction
    to Scikit-Learn and Model Evaluation*. In this case, *𝜃*o *= b* and *𝜃*1 *= m*.
    *𝜃*o is called the **intercept** of a linear combination, which should be familiar
    from algebra.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 常数*𝜃*i 可以是任何数值，正数、负数或零，*i = 0, 1, 和 2*（尽管如果某个系数为0，这将从线性组合中移除一个特征）。一个常见的线性变换的例子是单变量的直线方程
    *y = mx + b*，如在*第二章*《Scikit-Learn入门与模型评估》中讨论的那样。在这种情况下，*𝜃*o = *b*，*𝜃*1 = *m*。*𝜃*o
    被称为线性组合的**截距**，这在代数中应该是熟悉的概念。
- en: 'What kinds of things are "not allowed" in linear transformations? Any other
    mathematical expressions besides what was just described, such as the following:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性变换中“禁止”哪些操作？除了刚才描述的内容之外，任何其他数学表达式，如下所示：
- en: Multiplying a feature by itself; for example, *X*12 or *X*13\. These are called
    polynomial terms.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将特征与自身相乘；例如，*X*12 或 *X*13。这被称为多项式项。
- en: Multiplying features together; for example, *X*1*X*2\. These are called interactions.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将特征相乘；例如，*X*1*X*2。这被称为交互作用。
- en: Applying non-linear transformations to features; for example, log and square root.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对特征应用非线性变换；例如，对数和平方根。
- en: Other complex mathematical functions.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他复杂的数学函数。
- en: '"If then" types of statements. For example, "if *X*1 *> a*, then *y = b*."'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"如果...那么..."类型的语句。例如，"如果 *X*1 *> a*，那么 *y = b*"。'
- en: However, while these transformations are not part of the basic formulation of
    a linear combination, they could be added to a linear model by **engineering features**,
    for example, defining a new feature, *X*3 = *X*12.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，虽然这些变换不是线性组合的基本形式，但它们可以通过**特征工程**添加到线性模型中，例如定义一个新特征，*X*3 = *X*12。
- en: 'Earlier, we learned that the predictions of logistic regression, which take
    the form of probabilities, are made using the sigmoid function. Taking another
    look here, we see that this function is clearly non-linear:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们学过，逻辑回归的预测结果是概率形式，它们是通过sigmoid函数得出的。再看这里，我们可以清楚地看到这个函数是非线性的：
- en: '![Figure 3.22: Non-linear sigmoid function'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.22：非线性sigmoid函数'
- en: '](img/B16925_03_22.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_22.jpg)'
- en: 'Figure 3.22: Non-linear sigmoid function'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.22：非线性sigmoid函数
- en: 'Why, then, is logistic regression considered a linear model? It turns out that
    the answer to this question lies in a different formulation of the sigmoid equation,
    called the `logit` function. We can derive the `logit` function by solving the
    sigmoid function for *X*; in other words, finding the inverse of the sigmoid function.
    First, we set the sigmoid equal to *p*, which we interpret as the probability
    of observing the positive class, then solve for *X* as shown in the following:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么逻辑回归被认为是线性模型呢？事实证明，答案在于sigmoid方程的另一种表述形式，即`logit`函数。我们可以通过求解sigmoid函数的*X*来推导出`logit`函数；换句话说，就是找到sigmoid函数的逆函数。首先，我们将sigmoid设为*p*，我们将其解释为观察到正类的概率，然后按如下方式求解*X*：
- en: '![Figure 3.23: Solving for X'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.23：求解X'
- en: '](img/B16925_03_23.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_23.jpg)'
- en: 'Figure 3.23: Solving for X'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.23：求解X
- en: 'Here, we''ve used some laws of exponents and logs to solve for *X*. You may
    also see `logit` expressed as follows:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们利用了幂和对数的一些法则来求解*X*。你可能还会看到`logit`以以下形式表示：
- en: '![Figure 3.24: The logit function'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.24：logit函数'
- en: '](img/B16925_03_24.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_24.jpg)'
- en: 'Figure 3.24: The logit function'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.24：logit函数
- en: In this expression, the `logit` function is also called the **log odds**, because
    it is the natural logarithm of the **odds ratio**, *p/q*. Odds ratios may be familiar
    from the world of gambling, via phrases such as "the odds are 2 to 1 that team
    *a* will defeat team *b*."
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个表达式中，`logit`函数也被称为**对数几率**，因为它是**几率比**的自然对数，*p/q*。几率比在赌博世界中可能比较常见，例如“*a*队战胜*b*队的几率是2比1”。
- en: In general, what we've called capital *X* in these manipulations can stand for
    a linear combination of all the features. For example, this would be *X =* *𝜃*o
    *+* *𝜃*1*X*1 *+* *𝜃*2*X*2 in our simple case of two features. Logistic regression
    is considered a linear model because the features included in *X* are, in fact,
    only subject to a linear combination when the response variable is considered
    to be the log odds. This is an alternative way of formulating the problem, as
    compared to the sigmoid equation.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，我们在这些操作中所称的大写*X*可以代表所有特征的线性组合。例如，在我们这个简单的包含两个特征的案例中，*X =* *𝜃*o *+* *𝜃*1*X*1
    *+* *𝜃*2*X*2。逻辑回归被认为是线性模型，因为在考虑响应变量为对数几率时，包含在*X*中的特征实际上仅受限于线性组合。这是与sigmoid方程相比的一种问题表述方式。
- en: 'Putting the pieces together, the features *X*1, *X*2,…, *X*j look like this
    in the sigmoid equation version of logistic regression:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 将各部分组合在一起，特征*X*1、*X*2、…、*X*j在sigmoid方程版逻辑回归中是这样的：
- en: '![Figure 3.25: Sigmoid version of logistic regression'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.25：sigmoid版逻辑回归'
- en: '](img/B16925_03_25.jpg)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_25.jpg)'
- en: 'Figure 3.25: Sigmoid version of logistic regression'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.25：sigmoid版逻辑回归
- en: 'But they look like this in the log odds version, which is why logistic regression
    is called a linear model:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 但在对数几率版本中它们看起来是这样的，这也是为什么逻辑回归被称为线性模型：
- en: '![Figure 3.26: Log odds version of logistic regression'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.26：对数几率版逻辑回归'
- en: '](img/B16925_03_26.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_26.jpg)'
- en: 'Figure 3.26: Log odds version of logistic regression'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.26：对数几率版逻辑回归
- en: Because of this way of looking at logistic regression, ideally, the features
    of a logistic regression model would be **linear in the log odds** of the response
    variable. We will see what is meant by this in the following exercise.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从这种角度看待逻辑回归时，理想情况下，逻辑回归模型的特征应该是**在响应变量的对数几率上是线性的**。我们将在接下来的练习中看到这一点是什么意思。
- en: Logistic regression is part of a broader class of statistical models called
    **Generalized Linear Models** (**GLMs**). GLMs are connected to the fundamental
    concept of ordinary linear regression, which may have one feature (that is, the
    **line of best fit**, *y = mx + b*, for a single feature, *x*) or more than one
    in **multiple linear regression**. The mathematical connection between GLMs and
    linear regression is the **link function**. The link function of logistic regression
    is the logit function we just learned about.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是统计模型的一个更广泛类别，称为**广义线性模型**（**GLMs**）。广义线性模型与普通线性回归的基本概念有关，普通线性回归可能只有一个特征（即
    **最佳拟合线**，*y = mx + b*，对于单个特征 *x*）或多个特征，称为**多元线性回归**。广义线性模型与线性回归之间的数学联系是**连接函数**。逻辑回归的连接函数是我们刚刚学习的对数几率函数。
- en: 'Exercise 3.04: Examining the Appropriateness of Features for Logistic Regression'
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.04：检查特征在逻辑回归中的适用性
- en: 'In *Exercise 3.02*, *Visualizing the Relationship between the Features and
    Response Variable*, we plotted a `groupby`/`mean` of what might be the most important
    feature of the model, according to our exploration so far: the `PAY_1` feature.
    By grouping samples by the values of `PAY_1`, and then looking at the mean of
    the response variable, we are effectively looking at the probability, *p*, of
    default within each of these groups.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *练习 3.02*，*可视化特征与响应变量之间的关系* 中，我们绘制了可能是模型中最重要特征之一的 `PAY_1` 特征的 `groupby`/`mean`。通过按
    `PAY_1` 的值对样本进行分组，并查看响应变量的平均值，我们实际上是在查看每个组内的违约概率，*p*。
- en: 'In this exercise, we will evaluate the appropriateness of `PAY_1` for logistic
    regression. We will do this by examining the log odds of default within these
    groups to see whether the response variable is linear in the log odds, as logistic
    regression formally assumes. Perform the following steps to complete the exercise:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将评估`PAY_1`在逻辑回归中的适用性。我们通过检查这些组内的违约对数赔率来判断响应变量是否在对数赔率中是线性的，正如逻辑回归所正式假设的那样。完成以下步骤以完成本练习：
- en: Note
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Before beginning step 1 of this exercise, make sure that you have imported
    the necessary libraries. You can refer to the following notebook for the prerequisite
    steps: [https://packt.link/gtpF9](https://packt.link/gtpF9).'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始本练习的第 1 步之前，确保已经导入了必要的库。你可以参考以下笔记本中的先决步骤：[https://packt.link/gtpF9](https://packt.link/gtpF9)。
- en: 'Confirm you still have access to the variables from *Exercise 3.02*, *Visualizing
    the Relationship between the Features and Response Variable*, in your notebook
    by reviewing the DataFrame of the average value of the response variable for different
    values of `PAY_1` with this code:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确认你仍然可以访问 *练习 3.02*，*可视化特征与响应变量之间的关系* 中的变量，在笔记本中查看 `PAY_1` 不同值下响应变量的平均值的 DataFrame，使用以下代码：
- en: '[PRE39]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output should be as follows:'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '![Figure 3.27: Rates of default within groups of PAY_1 values as probabilities
    of default'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.27：按 PAY_1 值分组的违约率作为违约概率'
- en: '](img/B16925_03_27.jpg)'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_27.jpg)'
- en: 'Figure 3.27: Rates of default within groups of PAY_1 values as probabilities
    of default'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.27：按 PAY_1 值分组的违约率作为违约概率
- en: 'Extract the mean values of the response variable from these groups and put
    them in a variable, `p`, representing the probability of default:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这些组中提取响应变量的平均值，并将其放入一个变量 `p` 中，表示违约的概率：
- en: '[PRE40]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Create a probability, `q`, of not defaulting. Since there are only two possible
    outcomes in this binary problem, and probabilities of all outcomes always sum
    to 1, it is easy to calculate `q`. Also print the values of `p` and `q` to confirm:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个不违约的概率`q`。由于这是一个二元问题，且所有结果的概率和始终为 1，因此很容易计算出`q`。同时打印出`p`和`q`的值以确认：
- en: '[PRE41]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The output should be as follows:'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '![Figure 3.28: Calculating q from p'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.28：从 p 计算 q'
- en: '](img/B16925_03_28.jpg)'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_28.jpg)'
- en: 'Figure 3.28: Calculating q from p'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.28：从 p 计算 q
- en: 'Calculate the odds ratio from `p` and `q`, as well as the log odds, using the
    natural logarithm function from NumPy:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 NumPy 的自然对数函数从`p`和`q`计算赔率比和对数赔率：
- en: '[PRE42]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The output should look like this:'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '![Figure 3.29: Odds ratio and log odds'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.29：赔率比和对数赔率'
- en: '](img/B16925_03_29.jpg)'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_29.jpg)'
- en: 'Figure 3.29: Odds ratio and log odds'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.29：赔率比和对数赔率
- en: 'In order to plot the log odds against the values of the feature, we can get
    the feature values from the index of the DataFrame containing `groupby`/`mean`.
    You can show the index like this:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了绘制对数几率与特征值的关系，我们可以从包含`groupby`/`mean`的DataFrame的索引中获取特征值。你可以这样显示索引：
- en: '[PRE43]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'This should produce the following output:'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这应该会产生以下输出：
- en: '[PRE44]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Create a similar plot to what we have already done, to show the log odds against
    the values of the feature. Here is the code:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个类似我们已经做过的图表，展示对数几率与特征值之间的关系。以下是代码：
- en: '[PRE45]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The plot should look like this:'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图表应该如下所示：
- en: '![Figure 3.30: Log odds of default for values of PAY_1'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.30：PAY_1值的违约对数几率'
- en: '](img/B16925_03_30.jpg)'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_30.jpg)'
- en: 'Figure 3.30: Log odds of default for values of PAY_1'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.30：PAY_1值的违约对数几率
- en: We can see in this plot that the relationship between the log odds of the response
    variable and the `PAY_1` feature is not all that different from the relationship
    between the rate of default and this feature that we plotted in *Exercise 3.02*,
    *Visualizing the Relationship between the Features and Response Variable*. For
    this reason, if the "rate of default" is a simpler concept for you to communicate
    to the business partner, it may be preferable. However, in terms of understanding
    the workings of logistic regression, this plot shows exactly what is assumed to
    be linear.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从这个图中看到，响应变量的对数几率与`PAY_1`特征之间的关系，与我们在*练习3.02*中绘制的违约率与该特征之间的关系几乎没有什么不同，*可视化特征与响应变量之间的关系*。因此，如果“违约率”是一个更易于向业务伙伴传达的概念，那么它可能更合适。然而，在理解逻辑回归的工作原理方面，这个图正好展示了假定为线性的内容。
- en: '**Is a straight-line fit a good model for this data?**'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '**直线拟合是否是此数据的良好模型？**'
- en: It certainly seems like a "line of best fit" drawn on this plot would go up
    from left to right. At the same time, this data doesn't seem like it would result
    in a truly linear process. One way to look at this data is that the values -2,
    -1, and 0 seem like they lie in a different regime of log odds than the others.
    `PAY_1 = 1` is sort of intermediate, and the rest are mostly larger. It may be
    that engineered features based on this variable, or different ways of encoding
    the categories represented by -2, -1, and 0, would be more effective for modeling.
    Keep this in mind as we proceed to model this data with logistic regression and
    then other approaches later in the book.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来在这个图中，画一条“最佳拟合线”应该是从左下角到右上角的。同时，这些数据似乎并不会导致一个真正的线性过程。我们可以通过一种方式来看待这些数据，即-2、-1和0的值似乎落在了一个与其他值不同的对数几率范围内。`PAY_1
    = 1`处于一个中间值，而其余的值则较大。也许基于此变量的工程特征，或者以不同方式编码-2、-1和0所代表的类别，会对建模更有效。随着我们继续使用逻辑回归建模这些数据，并在本书后面介绍其他方法时，记住这一点。
- en: From Logistic Regression Coefficients to Predictions Using Sigmoid
  id: totrans-341
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从逻辑回归系数到使用Sigmoid的预测
- en: Before the next exercise, let's take a look at how the coefficients for logistic
    regression are used to calculate predicted probabilities, and ultimately make
    predictions for the class of the response variable.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习之前，我们先来看一下逻辑回归的系数是如何用来计算预测概率的，最终为响应变量的类别做出预测的。
- en: 'Recall that logistic regression predicts the probability of class membership,
    according to the sigmoid equation. In the case of two features with an intercept,
    the equation is as follows:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆一下，逻辑回归根据Sigmoid方程预测类成员的概率。在具有截距的两个特征的情况下，方程如下：
- en: '![Figure 3.31: Sigmoid function to predict the probability of class membership
    for two features'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.31：Sigmoid函数预测两个特征的类成员概率'
- en: '](img/B16925_03_31.jpg)'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_31.jpg)'
- en: 'Figure 3.31: Sigmoid function to predict the probability of class membership
    for two features'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.31：Sigmoid函数预测两个特征的类成员概率
- en: When you call the `.fit` method of a logistic regression model object in scikit-learn
    using the training data, the *𝜃*0, *𝜃*1, and *𝜃*2 parameters (intercept and coefficients)
    are estimated from this labeled training data. Effectively, scikit-learn figures
    out how to choose values for *𝜃*0, *𝜃*1, and *𝜃*2, so that it will classify as
    many training data points correctly as possible. We'll gain some insight into
    how this process works in the next chapter.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用训练数据调用scikit-learn中逻辑回归模型对象的`.fit`方法时，*𝜃*0、*𝜃*1和*𝜃*2参数（截距和系数）是从这些有标签的训练数据中估计出来的。实际上，scikit-learn会计算出如何选择*𝜃*0、*𝜃*1和*𝜃*2的值，以便尽可能准确地分类尽可能多的训练数据点。我们将在下一章中深入了解这个过程是如何运作的。
- en: When you call `.predict`, scikit-learn calculates predicted probabilities according
    to the fitted parameter values and the sigmoid equation. A given sample will then
    be classified as positive if *p ≥ 0.5*, and negative otherwise.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 当你调用 `.predict` 时，scikit-learn 会根据拟合的参数值和 sigmoid 方程计算预测的概率。给定的样本将在 *p ≥ 0.5*
    时被分类为正类，否则为负类。
- en: 'We know that the plot of the sigmoid equation looks like the following, which
    we can connect to the equation in *Figure 3.31* by making the substitution *X
    =* *𝜃*0 *+* *𝜃*1*X*1 *+* *𝜃*2*X*2:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，sigmoid 方程的图像如下所示，我们可以通过将 *X =* *𝜃*0 *+* *𝜃*1*X*1 *+* *𝜃*2*X*2 代入 *图 3.31*
    中的方程来进行连接：
- en: '![Figure 3.32: Predictions and true classes plotted together'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.32：预测与真实类别一起绘制'
- en: '](img/B16925_03_32.jpg)'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_03_32.jpg)'
- en: 'Figure 3.32: Predictions and true classes plotted together'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.32：预测与真实类别一起绘制
- en: 'Notice here that if *X =* *𝜃*o *+* *𝜃*1*X*1 *+* *𝜃*2*X*2 *≥ 0* on the *x* axis,
    then the predicted probability would be *p ≥ 0.5* on the *y* axis and the sample
    would be classified as positive. Otherwise, *p* *<* *0.5* and the sample would
    be classified as negative. We can use this observation to calculate a linear condition
    for positive prediction, in terms of the *X*1 and *X*2 features, using the coefficients
    and intercept. Solving the inequality for positive prediction, *X =* *𝜃*o *+*
    *𝜃*1*X*1 *+* *𝜃*2*X*2 *≥ 0*, for *X*2, we can obtain a linear inequality similar
    to a linear equation in *y = mx + b* form: *X*2 *≥ -(**𝜃*1*/**𝜃*2*)X*1 *- (**𝜃*o*/**𝜃*2*)*.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果 *X =* *𝜃*o *+* *𝜃*1*X*1 *+* *𝜃*2*X*2 *≥ 0* 时，在 *x* 轴上，则预测的概率为 *p ≥ 0.5*，该样本将被分类为正类。否则，*p*
    *<* *0.5*，样本将被分类为负类。我们可以利用这个观察结果，计算出一个线性条件来进行正向预测，基于 *X*1 和 *X*2 特征，使用系数和截距。解这个不等式，得到类似于
    *y = mx + b* 形式的线性不等式：*X*2 *≥ -(**𝜃*1*/**𝜃*2*)X*1 *- (**𝜃*o*/**𝜃*2*)*。
- en: This will help to see the linear decision boundary of logistic regression in
    the *X*1*-X*2 **feature space** in the following exercise.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 这将帮助在以下练习中看到逻辑回归的线性决策边界在 *X*1*-X*2 **特征空间** 中的表现。
- en: We have now learned, from a theoretical and mathematical perspective, why logistic
    regression is considered a linear model. We also examined a single feature and
    considered whether the assumption of linearity was appropriate. It is also important
    to understand the assumption of linearity, in terms of how flexible and powerful
    we can expect logistic regression to be. We explore this in the following exercise.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经从理论和数学的角度了解了为什么逻辑回归被认为是一个线性模型。我们还检查了单个特征，并考虑了线性假设是否合理。理解线性假设也很重要，这涉及到我们可以期望逻辑回归具有多大的灵活性和强大性。我们将在接下来的练习中探讨这一点。
- en: 'Exercise 3.05: Linear Decision Boundary of Logistic Regression'
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.05：逻辑回归的线性决策边界
- en: In this exercise, we illustrate the concept of a **decision boundary** for a
    binary classification problem. We use synthetic data to create a clear example
    of how the decision boundary of logistic regression looks in comparison to the
    training samples. We start by generating two features, *X*1 and *X*2, at random.
    Since there are two features, we can say that the data for this problem is two-dimensional.
    This makes it easy to visualize. The concepts we illustrate here generalize to
    cases of more than two features, such as the real-world datasets you're likely
    to see in your work; however, the decision boundary is harder to visualize in
    higher-dimensional spaces.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们展示了二分类问题的**决策边界**的概念。我们使用合成数据创建一个清晰的示例，展示逻辑回归的决策边界与训练样本的对比。我们首先随机生成两个特征，*X*1
    和 *X*2。由于有两个特征，我们可以说这个问题的数据是二维的，这使得可视化变得容易。我们在这里展示的概念可以推广到更多特征的情况，比如你在工作中可能会遇到的真实世界数据集；然而，决策边界在高维空间中更难以可视化。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: Note
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Before beginning step 1 of this exercise, make sure that you have imported
    the necessary libraries. You can refer to the following notebook for the prerequisite
    steps: [https://packt.link/35ge1](https://packt.link/35ge1).'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始此练习的第 1 步之前，请确保你已导入必要的库。你可以参考以下笔记本，获取前置步骤：[https://packt.link/35ge1](https://packt.link/35ge1)。
- en: 'Generate the features using the following code:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码生成特征：
- en: '[PRE46]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: You don't need to worry too much about why we selected the values we did; the
    plotting we do later should make it clear. Notice, however, that we have assigned
    the true class at the same time, by defining here which points (`X`1`, X`2) will
    be in the positive and negative classes. The result of this is that we have 20
    samples each in the positive and negative classes, for a total of 40 samples,
    and that we have two features for each sample. We show the first three values
    of each feature for both the positive and negative classes.
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你不需要过于担心我们选择这些值的原因；我们稍后绘制的图形应该能够让你理解。不过要注意，我们同时分配了真实类别，通过定义哪些点（`X`1`, X`2）将属于正类和负类，来进行这一操作。这样，我们就得到了每个类别各
    20 个样本，总共 40 个样本，并且每个样本有两个特征。我们展示了正类和负类每个特征的前三个值。
- en: 'The output should be the following:'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应为以下内容：
- en: '![Figure 3.33: Generating synthetic data for a binary classification problem'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.33：生成二分类问题的合成数据'
- en: '](img/B16925_03_33.jpg)'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_33.jpg)'
- en: 'Figure 3.33: Generating synthetic data for a binary classification problem'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.33：生成二分类问题的合成数据
- en: 'Plot this data, coloring the positive samples as red squares and the negative
    samples as blue *x*''s. The plotting code is as follows:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制这些数据，将正样本用红色方块表示，负样本用蓝色 *x* 形表示。绘图代码如下：
- en: '[PRE47]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The result should look like this:'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该如下所示：
- en: '![Figure 3.34: Generating synthetic data for a binary classification problem'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.34：生成二分类问题的合成数据'
- en: '](img/B16925_03_34.jpg)'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_34.jpg)'
- en: 'Figure 3.34: Generating synthetic data for a binary classification problem'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.34：生成二分类问题的合成数据
- en: In order to use our synthetic features with scikit-learn, we need to assemble
    them into a matrix. We use NumPy's `block` function for this, to create a 40 by
    2 matrix. There will be 40 rows because there are 40 total samples, and 2 columns
    because there are 2 features. We will arrange things so that the features for
    the positive samples come in the first 20 rows and those for the negative samples
    after that.
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了将我们的合成特征与 scikit-learn 一起使用，我们需要将它们组装成一个矩阵。我们使用 NumPy 的 `block` 函数来创建一个 40x2
    的矩阵。因为总共有 40 个样本，所以会有 40 行，且每个样本有两个特征，因此有 2 列。我们会将正类样本的特征放在前 20 行，负类样本的特征放在后 20
    行。
- en: 'Create a 40 by 2 matrix and then show the shape and the first 3 rows:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 40x2 的矩阵，然后显示其形状和前三行：
- en: '[PRE48]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The output should be as follows:'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE49]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: We also need a response variable to go with these features. We know how we defined
    them, but we need an array of `y` values to let scikit-learn know.
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还需要一个响应变量来与这些特征配合使用。我们已经知道它们是如何定义的，但我们还需要一个 `y` 数组来告诉 scikit-learn。
- en: 'Create a vertical stack (`vstack`) of 20 ones and then 20 zeros to match our
    arrangement of the features and reshape to the way that scikit-learn expects.
    Here is the code:'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个垂直堆叠（`vstack`）的 20 个 1 和 20 个 0，以匹配我们特征的排列方式，并重新调整形状以符合 scikit-learn 的要求。代码如下：
- en: '[PRE50]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'You will obtain the following output:'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将获得以下输出：
- en: '[PRE51]'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: At this point, we are ready to fit a logistic regression model to this data
    with scikit-learn. We will use all of the data as training data and examine how
    well a linear model is able to fit the data. The next few steps should be familiar
    from your work in earlier chapters on how to instantiate a model class and fit
    the model.
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前，我们准备使用 scikit-learn 来拟合一个逻辑回归模型。我们将使用所有数据作为训练数据，并观察线性模型如何拟合这些数据。接下来的几个步骤应该与你在前几章学习的如何实例化模型类并拟合模型的内容相似。
- en: 'First, import the model class using the following code:'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使用以下代码导入模型类：
- en: '[PRE52]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Now instantiate, indicating the `liblinear` solver, and show the model object
    using the following code:'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在实例化模型，指定使用 `liblinear` 求解器，并使用以下代码显示模型对象：
- en: '[PRE53]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output should be as follows:'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE54]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: We'll discuss some of the different solvers available for logistic regression
    in scikit-learn in *Chapter 4*, *The Bias-Variance Trade-Off*, but for now we'll
    use this one.
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将在 *第 4 章*《偏差-方差权衡》中讨论 scikit-learn 中不同求解器的使用方法，但现在我们将使用这个求解器。
- en: 'Now train the model on the synthetic data:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在在合成数据上训练模型：
- en: '[PRE55]'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '`.predict` method on the same samples we used for model training. Then, in
    order to add these predictions to the plot, we will create two lists of indices
    to use with the arrays, according to whether the prediction is 1 or 0\. See whether
    you can understand how we''ve used a list comprehension, including an `if` statement,
    to accomplish this.'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对我们用于模型训练的相同样本应用 `.predict` 方法。然后，为了将这些预测添加到图中，我们将根据预测值是1还是0，创建两个索引列表以与数组一起使用。看看你是否能理解我们是如何使用列表推导式，包括
    `if` 语句，来完成这一步的。
- en: 'Use this code to get predictions and separate them into indices of positive
    and negative class predictions. Show the indices of positive class predictions
    as a check:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用此代码获取预测值，并将其分离为正类和负类的索引。显示正类预测的索引作为检查：
- en: '[PRE56]'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The output should be as follows:'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE57]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'From the indices of positive predictions, we can already tell that not every
    sample in the training data was classified correctly: the positive samples were
    the first 20 samples, but there are indices outside of that range here. You may
    have already guessed that a linear decision boundary would not be able to perfectly
    classify this data, based on examining it. Now let''s put these predictions on
    the plot, in the form of squares and circles around each data point, colored according
    to positive and negative predictions, respectively: red for positive and blue
    for negative.'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从正预测的索引，我们可以已经看出，并非训练数据中的每个样本都被正确分类：正样本是前20个样本，但这里有超出这个范围的索引。你可能已经猜到，线性决策边界无法完美地对这些数据进行分类，因为观察它后会得出这个结论。现在，让我们将这些预测显示在图上，形式为每个数据点周围的方框和圆圈，分别按照正负预测进行着色：红色表示正类，蓝色表示负类。
- en: You can compare the color and shape of the inner symbols, the true labels of
    the data, to those of the outer symbols (predictions), to see which points were
    classified correctly or incorrectly.
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以比较内层符号的颜色和形状（数据的真实标签）与外层符号（预测标签），以查看哪些点被正确分类，哪些点被错误分类。
- en: 'Here is the plotting code:'
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是绘图代码：
- en: '[PRE58]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The plot should appear as follows:'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 绘图应该如下所示：
- en: '![Figure 3.35: Predictions and true classes plotted together'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.35：预测值和真实类别一起绘制'
- en: '](img/B16925_03_35.jpg)'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_35.jpg)'
- en: 'Figure 3.35: Predictions and true classes plotted together'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.35：预测值和真实类别一起绘制
- en: From the plot, it's apparent that the classifier struggles with data points
    that are close to where you may imagine the linear decision boundary to be; some
    of these may end up on the wrong side of that boundary. How might we figure out,
    and visualize, the actual location of the decision boundary? From the previous
    section, we know we can obtain the decision boundary of a logistic regression,
    in two-dimensional feature space, using the inequality *X*2 *≥ -(**𝜃*1*/**𝜃*2*)X*1
    *- (**𝜃*0*/**𝜃*2*)*. Since we've fitted the model here, we can retrieve the *𝜃*1
    and *𝜃*2 coefficients, as well as the *𝜃*0 intercept, to plug into this equation
    and create the plot.
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从图中可以看出，分类器在靠近线性决策边界位置的数据点上表现不佳；其中一些可能会出现在边界的另一侧。我们怎么做才能找出并可视化决策边界的实际位置呢？从前一节中，我们知道可以通过不等式
    *X*2 *≥ -(**𝜃*1*/**𝜃*2*)X*1 *- (**𝜃*0*/**𝜃*2*)* 来获取逻辑回归的决策边界，在二维特征空间中。既然我们已经拟合了模型，就可以检索
    *𝜃*1 和 *𝜃*2 的系数，以及 *𝜃*0 的截距，将这些值代入方程并绘制图表。
- en: 'Use this code to get the coefficients from the fitted model and print them:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用此代码从拟合的模型中获取系数并打印它们：
- en: '[PRE59]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The output should look like this:'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE60]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Use this code to get the intercept:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用此代码获取截距：
- en: '[PRE61]'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Now use the coefficients and intercept to define the linear decision boundary.
    This captures the dividing line of the inequality, *X*2 *≥ -(**𝜃*1*/**𝜃*2*)X*1
    *- (**𝜃*0*/**𝜃*2*)*:'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在使用系数和截距来定义线性决策边界。这个边界捕捉了不等式的分界线，*X*2 *≥ -(**𝜃*1*/**𝜃*2*)X*1 *- (**𝜃*0*/**𝜃*2*)*：
- en: '[PRE62]'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: To summarize the last few steps, after using the `.coef_` and `.intercept_`
    methods to retrieve the *𝜃*1 and *𝜃*2 model coefficients and the *𝜃*0 intercept,
    we then used these to create a line defined by two points, according to the equation
    we described for the decision boundary.
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 总结最后几步，在使用 `.coef_` 和 `.intercept_` 方法来获取 *𝜃*1 和 *𝜃*2 的模型系数以及 *𝜃*0 的截距之后，我们使用这些值根据我们描述的决策边界方程创建了一条由两点定义的线。
- en: 'Plot the decision boundary using the following code, with some adjustments
    to assign the correct labels for the legend, and to move the legend to a location
    (`loc`) outside a plot that is getting crowded:'
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码绘制决策边界，并做一些调整以分配正确的标签用于图例，同时将图例移动到图外的某个位置（`loc`），避免图表拥挤：
- en: '[PRE63]'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'You will obtain the following plot:'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将获得以下图形：
- en: '![Figure 3.36: True classes, predicted classes, and the decision boundary'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.36：真实类别、预测类别和决策边界'
- en: of a logistic regression
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 逻辑回归的
- en: '](img/B16925_03_36.jpg)'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_03_36.jpg)'
- en: 'Figure 3.36: True classes, predicted classes, and the decision boundary of
    a logistic regression'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.36：逻辑回归的真实类别、预测类别和决策边界
- en: '**How does the location of the decision boundary compare with where you thought
    it would be?**'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策边界的位置与你原本预想的有何不同？**'
- en: '**Can you see how a linear decision boundary will never perfectly classify
    this data?**'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '**你能看出线性决策边界永远无法完美分类这些数据吗？**'
- en: As a way around this, we could create **engineered features** from existing
    features here, such as polynomials or interactions, to allow for more complex,
    non-linear decision boundaries in a logistic regression. Or, we could use non-linear
    models such as random forest, which can also accomplish this, as we'll see later.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 为了绕过这个问题，我们可以从现有特征中创建**工程特征**，例如多项式或交互特征，以便在逻辑回归中允许更复杂的非线性决策边界。或者，我们可以使用非线性模型，如随机森林，后者也能实现这一点，稍后我们会看到。
- en: As a final note here, this example was easily visualized in two dimensions since
    there are only two features. In general, the decision boundary can be described
    by a **hyperplane**, which is the generalization of a straight line to multi-dimensional
    spaces. However, the restrictive nature of the linear decision boundary is still
    a factor for hyperplanes.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 最后需要注意的是，由于只有两个特征，这个例子可以很容易地在二维中进行可视化。通常，决策边界可以通过**超平面**来描述，它是直线在多维空间中的推广。然而，线性决策边界的限制性质仍然是超平面的一个因素。
- en: 'Activity 3.01: Fitting a Logistic Regression Model and Directly Using the Coefficients'
  id: totrans-428
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 3.01：拟合逻辑回归模型并直接使用系数
- en: 'In this activity, we''re going to train a logistic regression model on the
    two most important features we discovered in univariate feature exploration, as
    well as learning how to manually implement logistic regression using coefficients
    from the fitted model. This will show you how you could use logistic regression
    in a computing environment where scikit-learn may not be available, but the mathematical
    functions necessary to compute the sigmoid function are. On successful completion
    of the activity, you should observe that the calculated ROC AUC values using scikit-learn
    predictions and those obtained from manual predictions should be the same: approximately
    0.63.'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将训练一个逻辑回归模型，使用在单变量特征探索中发现的两个最重要的特征，并学习如何使用拟合模型中的系数手动实现逻辑回归。这将展示如何在没有scikit-learn环境的计算环境中使用逻辑回归，但可以计算sigmoid函数所需的数学函数。成功完成该活动后，你应该会发现，使用scikit-learn预测和手动预测计算的ROC
    AUC值应该是相同的：大约为0.63。
- en: 'Perform the following steps to complete the activity:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤完成活动：
- en: Create a train/test split (80/20) with `PAY_1` and `LIMIT_BAL` as features.
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个训练/测试划分（80/20），以`PAY_1`和`LIMIT_BAL`作为特征。
- en: Import `LogisticRegression`, with the default options, but set the solver to `'liblinear'`.
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`LogisticRegression`，使用默认选项，但将求解器设置为`'liblinear'`。
- en: Train on the training data and obtain predicted classes, as well as class probabilities,
    using the test data.
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上训练，并使用测试数据获取预测类别及类别概率。
- en: Pull out the coefficients and intercept from the trained model and manually
    calculate predicted probabilities. You'll need to add a column of ones to your
    features, to multiply by the intercept.
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从训练好的模型中提取系数和截距，并手动计算预测概率。你需要向特征中添加一列1，以便与截距相乘。
- en: Using a threshold of `0.5`, manually calculate predicted classes. Compare this
    to the class predictions outputted by scikit-learn.
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`0.5`的阈值，手动计算预测类别。与scikit-learn输出的类别预测进行比较。
- en: Calculate the ROC AUC using both scikit-learn's predicted probabilities and
    your manually predicted probabilities, and compare them.
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用scikit-learn的预测概率和手动预测的概率计算ROC AUC，并进行比较。
- en: Note
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Jupyter notebook containing the code for this activity can be found here:
    [https://packt.link/4FHec](https://packt.link/4FHec). This notebook contains only
    the Python code and corresponding outputs. The complete step-wise solution can
    be found via [this link](B16925_Solution_ePub.xhtml#_idTextAnchor153).'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含此活动代码的Jupyter笔记本可以在这里找到：[https://packt.link/4FHec](https://packt.link/4FHec)。该笔记本仅包含Python代码及相应输出。完整的逐步解决方案可以通过[此链接](B16925_Solution_ePub.xhtml#_idTextAnchor153)找到。
- en: Summary
  id: totrans-439
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have learned how to explore features one at a time, using
    univariate feature selection methods including Pearson correlation and an ANOVA
    F-test. While looking at features in this way does not always tell the whole story,
    since you are potentially missing out on important interactions between features,
    it is often a helpful step. Understanding the relationships between the most predictive
    features and the response variable, and creating effective visualizations around
    them, is a great way to communicate your findings to your client. We used customized
    plots, such as overlapping histograms created with Matplotlib, to create visualizations
    of the most important features.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何逐一探索特征，使用包括皮尔逊相关系数和ANOVA F检验在内的单变量特征选择方法。虽然以这种方式查看特征并不总是能揭示完整的故事，因为可能会忽略特征间的重要交互作用，但这通常是一个有用的步骤。理解最具预测性的特征与响应变量之间的关系，并围绕它们创建有效的可视化，是向客户传达你的发现的好方法。我们使用了定制的图形，比如使用**Matplotlib**创建的重叠直方图，来可视化最重要的特征。
- en: Then we began an in-depth description of how logistic regression works, exploring
    such topics as the sigmoid function, log odds, and the linear decision boundary.
    While logistic regression is one of the simplest classification models, and often
    is not as powerful as other methods, it is one of the most widely used and is
    the basis for more sophisticated models such as deep neural networks for classification.
    So, a detailed understanding of logistic regression can serve you well as you
    explore more advanced topics in machine learning. And, in some cases, a simple
    logistic regression may be all that's needed. All other things considered, the
    simplest model that satisfies the requirements is probably the best model.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们开始深入描述逻辑回归是如何工作的，探讨了如**sigmoid**函数、对数几率和线性决策边界等话题。虽然逻辑回归是最简单的分类模型之一，且通常不如其他方法强大，但它是应用最广泛的模型之一，并且是深度神经网络等更复杂分类模型的基础。因此，详细理解逻辑回归将帮助你在探索机器学习的更高级话题时提供帮助。而在某些情况下，简单的逻辑回归可能是唯一需要的模型。综合考虑所有因素，满足要求的最简单模型可能就是最好的模型。
- en: If you master the materials in this and the next chapter, you will be well prepared
    to use logistic regression in your work. In the next chapter, we'll build on the
    fundamentals we learned here, to see how coefficients are estimated for a logistic
    regression, as well as how logistic regression can be used effectively with large
    numbers of features and can also be used for feature selection.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你掌握了本章和下一章的内容，你将为在工作中使用逻辑回归做好充分准备。在下一章，我们将在这里学到的基础上进一步探讨，了解如何估计逻辑回归的系数，以及如何在特征数量较多的情况下有效使用逻辑回归，并用于特征选择。
