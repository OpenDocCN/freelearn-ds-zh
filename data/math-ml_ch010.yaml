- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Linear Transformations
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 线性变换
- en: ”Why do my eyes hurt?” ”You’ve never used them before.”
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “为什么我的眼睛痛？” “你以前从未使用过它们。”
- en: ''
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: — Morpheus to Neo, when waking up from the Matrix for the first time
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: — 莫非斯对尼奥说，当他第一次从矩阵中醒来时
- en: 'In most linear algebra courses, the curriculum is all about matrices. In machine
    learning, we work with them all the time. Here is the thing: matrices don’t tell
    the whole story. It is hard to understand the patterns by looking only at matrices.
    For instance, why is matrix multiplication defined in such a complex way as it
    is? Why are relations like B = T^(−1)AT important? Why are some matrices invertible
    and some are not?'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数线性代数课程中，课程内容都围绕矩阵展开。在机器学习中，我们一直在使用矩阵。问题是：矩阵并不能讲述整个故事。仅仅通过矩阵很难理解其中的模式。例如，为什么矩阵乘法定义得如此复杂？为什么像
    B = T^(−1)AT 这样的关系很重要？为什么有些矩阵是可逆的，有些则不是？
- en: 'To really understand what is going on, we have to look at what gives rise to
    matrices: linear transformations. Like for Neo, this might hurt a bit, but it
    will greatly reward us later down the line. Let’s get to it!'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 要真正理解发生了什么，我们必须看看什么导致了矩阵的产生：线性变换。就像对于尼奥一样，这可能有些痛苦，但从长远来看，它会给我们带来巨大的回报。让我们开始吧！
- en: 4.1 What is a linear transformation?
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 什么是线性变换？
- en: With the introduction of inner products, orthogonality, and orthogonal/orthonormal
    bases, we know everything about the structure of our feature spaces. However,
    in machine learning, our interest mainly lies in transforming the data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过引入内积、正交性以及正交/规范正交基，我们现在已经了解了特征空间的结构。然而，在机器学习中，我们的主要兴趣在于数据的变换。
- en: From this viewpoint, a neural network is just a function composed of smaller
    parts (known as layers), transforming the data to a new feature space in every
    step. One of the key components of models in machine learning are linear transformations.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个角度来看，神经网络只是一个由更小部分（称为层）组成的函数，在每一步中将数据转化为新的特征空间。机器学习模型中的一个关键组件就是线性变换。
- en: You probably encountered them as functions of the form f(x) = Ax, but this is
    only one way to look at them. This section will start from a geometric viewpoint,
    then move towards the algebraic representation that you are probably already familiar
    with. To understand how neural networks can learn powerful high-level representations
    of the data, looking at the geometry of transforms is essential.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能遇到过形式为 f(x) = Ax 的函数，但这只是其中的一种表现方式。本节将从几何视角开始，然后过渡到你可能已经熟悉的代数表示方式。要理解神经网络如何学习数据的强大高层表示，观察变换的几何性质至关重要。
- en: So, what linear transformations are? Let’s not hesitate a moment further, and
    jump into the definition right away!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，线性变换究竟是什么呢？让我们不再犹豫，直接进入定义吧！
- en: Definition 16\. (Linear transformations)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 16\.（线性变换）
- en: 'Let U and V be two vector spaces (over the same scalar field), and let f :
    U →V be a function between them. We say that f is linear if'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '设 U 和 V 为两个向量空间（在相同的标量域上），并且设 f : U →V 为它们之间的一个函数。如果 f 是线性的，我们说 f 满足'
- en: f( ax + by) = af(x) + bf(y)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: f( ax + by) = af(x) + bf(y)
- en: (4.1)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: （4.1）
- en: holds for all vectors x,y ∈U and all scalars a,b.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有向量 x、y ∈U 和所有标量 a、b，公式成立。
- en: 'This is why linear algebra is called linear algebra. In essence, a linear transformation
    is a mapping between two vector spaces that preserves the algebraic structure:
    addition and scalar multiplication. (Functions between vector spaces are often
    called transformations, so we will use this terminology.)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么线性代数被称为线性代数的原因。从本质上讲，线性变换是两个向量空间之间的一种映射，它保持代数结构不变：加法和标量乘法。（向量空间之间的函数通常称为变换，因此我们将使用这个术语。）
- en: Remark 5\.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 备注 5\.
- en: 'Linearity is essentially combining two properties in one: f(x + y) = f(x) +
    f(y) and f(ax) = af(x) for all vectors x,y and all scalars a. From these two,
    ([4.1](ch010.xhtml#x1-66002r16)) follows by'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 线性本质上是将两个性质结合在一起：对于所有向量 x、y 和所有标量 a，有 f(x + y) = f(x) + f(y) 和 f(ax) = af(x)。从这两个公式中，([4.1](ch010.xhtml#x1-66002r16))
    可以推出。
- en: '![f(ax + by) = f(ax) + f(by) = af(x)+ bf (y ). ](img/file308.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![f(ax + by) = f(ax) + f(by) = af(x)+ bf (y ). ](img/file308.png)'
- en: Two properties immediately jump out from the definition. First, since
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 定义中立刻显现出两个性质。首先，由于
- en: '![f(x) = f(x + 0) = f(x) + f(0), ](img/file309.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![f(x) = f(x + 0) = f(x) + f(0), ](img/file309.png)'
- en: f(0) = 0 holds for every linear transformation. In addition, the composition
    of linear transformations is still linear, as
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: f(0) = 0 对于每个线性变换都成立。此外，线性变换的复合仍然是线性的，如
- en: '![f (g(ax + by)) = f(ag(x)+ bg(y)) = af(g(x))+ bf(g(y)) ](img/file310.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![f (g(ax + by)) = f(ag(x)+ bg(y)) = af(g(x))+ bf(g(y)) ](img/file310.png)'
- en: shows for any linear f and g and scalars a and b.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任意的线性 f 和 g 以及标量 a 和 b，公式如下。
- en: As usual, let’s see some examples to build intuition.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，让我们看一些例子来建立直觉。
- en: Example 1\. For any scalar c, the scaling transformation f(x) = cx is linear.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 1\. 对于任意标量 c，缩放变换 f(x) = cx 是线性的。
- en: This is probably the simplest example out there, and it can be defined in all
    vector spaces.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是可能是最简单的例子，而且它可以在所有向量空间中定义。
- en: '![PIC](img/file311.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file311.png)'
- en: 'Figure 4.1: Scaling as a linear transformation'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1：作为线性变换的缩放
- en: 'It’s easy to see that scaling is linear:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易看出，缩放是线性的：
- en: '![c(ax + by) = c(ax)+ c(by) = a(cx)+ b(cy). ](img/file312.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![c(ax + by) = c(ax)+ c(by) = a(cx)+ b(cy). ](img/file312.png)'
- en: Example 2\. In ℝ², rotations around the origin by an angle α are also linear.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 2\. 在 ℝ² 中，绕原点的旋转角度 α 也是线性的。
- en: '![PIC](img/file313.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file313.png)'
- en: 'Figure 4.2: Rotation in the Euclidean plane as a linear transformation'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2：作为线性变换的欧几里得平面旋转
- en: 'To show that rotations are indeed linear, I pull the definition out from the
    hat: the rotation of a planar vector x = (x[1],x[2]) with the angle α is described
    by'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明旋转确实是线性的，我从帽子里拿出了定义：平面向量 x = (x[1], x[2]) 以角度 α 旋转可以用以下公式描述
- en: '![f(x) = (x1cosα − x2 sinα, x1sinα + x2cos α), ](img/file314.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![f(x) = (x1cosα − x2 sinα, x1sinα + x2cos α), ](img/file314.png)'
- en: from which ([16](ch010.xhtml#x1-66002r16)) is easily confirmed. I know that
    this looks like magic, but trust me, the rotation formula will be explained in
    detail. You can sweat it out with some basic trigonometry, or wait until we do
    this later with matrices.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从中（[16](ch010.xhtml#x1-66002r16)）可以很容易地确认。我知道这看起来像是魔法，但相信我，旋转公式会详细解释。你可以通过一些基本的三角学知识来推导，或者等到我们稍后使用矩阵来处理这个问题。
- en: In general, linear transformations have a strong connection with the geometry
    of the space. Later, we are going to study the linear transformations of ℝ² in
    detail, with an emphasis on geometric ones such as this. (Note that rotations
    are slightly more complicated in higher dimensions, as they will require an axis
    to rotate around.)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，线性变换与空间的几何结构有着紧密的联系。稍后我们将详细研究 ℝ² 的线性变换，重点讨论像这样的几何变换。（注意，在更高维度下，旋转会稍微复杂一些，因为它们需要一个旋转轴。）
- en: Example 3\. In any vector space V and a nonzero vector v ∈V , the translation
    defined by f(x) = x + v is not linear, as f(0) = v≠0.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 3\. 在任何向量空间 V 中，若存在非零向量 v ∈ V，定义为 f(x) = x + v 的平移不是线性的，因为 f(0) = v≠0。
- en: 'We’ll see more examples later in the section. For now, let’s move on to some
    general properties of linear transformations. For any linear transformation f
    : U →V , the image'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '我们稍后将在本节中看到更多例子。目前，让我们继续讨论线性变换的一些一般性质。对于任何线性变换 f : U → V，其像'
- en: '![im(f) = {v ∈ V : v = f (u) for some u ∈ U } ](img/file315.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![im(f) = {v ∈ V : v = f (u) 对某些 u ∈ U} ](img/file315.png)'
- en: 'is always a subspace Section [1.2.7](ch007.xhtml#subspaces) of V. This is easy
    to check: if ![v1, v2 ∈ im f ](img/file316.png), then there exist ![u1,u2 ∈ U
    ](img/file317.png) such that f(u[1]) = v[1] and f(u[2]) = v[2], as'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 总是 V 的一个子空间，见节[1.2.7](ch007.xhtml#subspaces)。这很容易验证：如果![v1, v2 ∈ im f ](img/file316.png)，那么存在![u1,u2
    ∈ U ](img/file317.png)，使得 f(u[1]) = v[1] 和 f(u[2]) = v[2]，如
- en: '![av1 + bv2 = af(u1)+ bf (u2 ) = f (au1 + bu2) ∈ im f. ](img/file318.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![av1 + bv2 = af(u1)+ bf (u2 ) = f (au1 + bu2) ∈ im f. ](img/file318.png)'
- en: To add one more level of abstraction, we will see that the set of all linear
    transformations form a vector space.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增加一个抽象的层次，我们将看到所有线性变换的集合形成了一个向量空间。
- en: Theorem 18\.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 18\。
- en: Let U and V be two vector spaces over the same field F. Then the set of all
    linear transformations
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 设 U 和 V 是两个在相同域 F 上的向量空间。那么，所有线性变换的集合
- en: '![L(U,V ) = {f : U → V | f is linear}](img/file319.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f 是线性的}](img/file319.png)'
- en: (4.2)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: (4.2)
- en: is also a vector space over F, with the usual definitions for function addition
    and scalar multiplication.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 也是一个定义在 F 上的向量空间，具有通常的函数加法和标量乘法定义。
- en: The proof of this is just a boring checklist, going through the items of the
    definition of vector spaces (Definition [2](ch007.xhtml#x1-20004r2)). I recommend
    you walk through it at least once to solidify your understanding of vector spaces,
    but there is really nothing special there.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 证明这个的过程只是一个无聊的检查清单，逐项检查向量空间定义中的条目（定义[2](ch007.xhtml#x1-20004r2)）。我建议你至少走一遍这个过程，以巩固你对向量空间的理解，但实际上并没有什么特别的地方。
- en: 4.1.1 Linear transformations and matrices
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.1 线性变换与矩阵
- en: The definition of linear transformations, as we saw, is a bit abstract. However,
    there is a simple and expressive way to characterize them.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，线性变换的定义有点抽象。然而，有一种简单且富有表现力的方式来刻画它们。
- en: 'To see this, let f : U →V be a linear transformation between two vector spaces
    U and V . Suppose that {u[1],…,u[m]} is a basis in U, while {v[1],…,v[n]} is a
    basis in V . Since every x ∈U can be written in the form'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '为了验证这一点，设 f : U →V 是两个向量空间 U 和 V 之间的线性变换。假设 {u[1]，…，u[m]} 是 U 中的基，而 {v[1]，…，v[n]}
    是 V 中的基。由于每个 x ∈U 都可以表示为'
- en: '![ m ∑ x = xiui, i=1 ](img/file320.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![ m ∑ x = xiui, i=1 ](img/file320.png)'
- en: the linearity of f implies
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: f 的线性性质意味着
- en: f( ∑ [j=1]^m x[j] u[j] ) = ∑ [j=1]^m x[j] f(u[j]),
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: f( ∑ [j=1]^m x[j] u[j] ) = ∑ [j=1]^m x[j] f(u[j])，
- en: (4.3)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: (4.3)
- en: meaning that f(x) is a linear combination of f(u[1]),…,f(u[m]). In other words,
    every linear transformation is completely determined by the images of basis vectors.
    To expand this idea, suppose that for every u[j], we have
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着 f(x) 是 f(u[1])，…，f(u[m]) 的线性组合。换句话说，每个线性变换完全由基向量的像决定。为了扩展这个想法，假设对于每个 u[j]，我们有
- en: '![ ∑n f(uj) = ai,jvi i=1 ](img/file323.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑n f(uj) = ai,jvi i=1 ](img/file323.png)'
- en: for some scalars a[i,j].
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些标量 a[i,j]。
- en: 'These n ×m numbers completely describe f. For notational simplicity, we store
    these in a n ×m-sized table called a matrix, which we’ll denote by A[f]:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这 n × m 个数完全描述了 f。为了简化符号，我们将它们存储在一个 n × m 大小的表格中，称为矩阵，记作 A[f]：
- en: '![ ⌊ ⌋ a1,1 a1,2 ... a1,m | | ||a2,1 a2,2 ... a2,m|| f ↔ Af = || .. .. ...
    .. || , ⌈ . . . ⌉ an,1 an,2 ... an,m ](img/file324.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ a1,1 a1,2 ... a1,m | | ||a2,1 a2,2 ... a2,m|| f ↔ Af = || .. .. ...
    .. || , ⌈ . . . ⌉ an,1 an,2 ... an,m ](img/file324.png)'
- en: meaning that linear transformations are represented by matrices. This connection
    is heavily utilized throughout machine learning.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着线性变换由矩阵表示。这个联系在机器学习中被广泛利用。
- en: Expanding ([4.3](ch010.xhtml#linear-transformations-and-matrices)) further,
    for every x = ∑ [j=1]^mx[j]u[j] we have
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步扩展（[4.3](ch010.xhtml#linear-transformations-and-matrices)），对于每个 x = ∑ [j=1]^m
    x[j]u[j]，我们有
- en: '![ ∑m f(x) = xjf(uj) j=1 ∑m ∑n = xj ai,jvi j=1 i=1 n ( m ) = ∑ ( ∑ a x ) v
    . i,j j i i=1 j=1 ](img/file325.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑m f(x) = xjf(uj) j=1 ∑m ∑n = xj ai,jvi j=1 i=1 n ( m ) = ∑ ( ∑ a x ) v
    . i,j j i i=1 j=1 ](img/file325.png)'
- en: 'Thus, the image of x can be expressed as A[f]x:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，x 的像可以表示为 A[f]x：
- en: '![ ⌊ ⌋ ⌊ ⌋ ⌊∑m ⌋ |a1,1 a1,2 ... a1,m | |x1 | | j=1 a1,jxj| |a2,1 a2,2 ... a2,m
    | |x2 | |∑m a2,jxj| f(x) = || . . . . || || . || = || j=1\. || . |⌈ .. .. .. ..
    |⌉ |⌈ .. |⌉ |⌈ .. |⌉ a a ... a , x ∑m a x n,1 n,2 n,m m j=1 n,j j ](img/file326.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌊ ⌋ ⌊∑m ⌋ |a1,1 a1,2 ... a1,m | |x1 | | j=1 a1,jxj| |a2,1 a2,2 ... a2,m
    | |x2 | |∑m a2,jxj| f(x) = || . . . . || || . || = || j=1\. || . |⌈ .. .. .. ..
    |⌉ |⌈ .. |⌉ |⌈ .. |⌉ a a ... a , x ∑m a x n,1 n,2 n,m m j=1 n,j j ](img/file326.png)'
- en: Two things to note here. First, we implicitly chose to represent vectors as
    columns instead of rows. This is a seriously impactful decision and will affect
    many of the computations later in this book. We’ll keep pointing it out.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两点需要注意。首先，我们隐式地选择了将向量表示为列向量而非行向量。这是一个非常重要的决定，稍后的许多计算都会受到这个选择的影响，我们会一直指出这一点。
- en: Second, the matrix representation depends on the choice of the basis! If, say,
    P = {p[1],…,p[n]}⊂U is the basis of our matrix, we denote this dependence in the
    subscript, writing A[f,P] .
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，矩阵表示依赖于基的选择！如果，例如，P = {p[1]，…，p[n]} ⊂ U 是我们的矩阵基，我们将在下标中表示这种依赖关系，写作 A[f,P]。
- en: To avoid confusion, we’ll almost exclusively define linear transformations by
    giving their matrices in the standard orthonormal basis. In practical scenarios,
    this makes it much easier to understand what is going on. So, whenever I write
    something like “let A be the matrix of a linear transformation f”, it is implictly
    assumed that A is written in the basis e[1] = (1,0,…,0),e[2] = (0,1,…,0),…,e[n]
    = (0,0,…,1).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免混淆，我们几乎总是通过给出标准正交基中的矩阵来定义线性变换。在实际应用中，这使得理解发生了什么变得更容易。所以，每当我写下类似“让 A 是线性变换
    f 的矩阵”的内容时，隐含的假设是 A 是在基 e[1] = (1,0,…,0)，e[2] = (0,1,…,0)，…，e[n] = (0,0,…,1) 中写的。
- en: 'On a philosophical note, have you heard about Plato’s allegory of the cave?
    In this thought experiment, people are assumed to be living in a cave constantly
    facing a single wall, only observing their shadows projected by a fire behind
    them. What they observe and use to build an internal representation of the world
    is very different from reality. Applying this analogy to linear algebra, matrices
    are the shadows that we observe and use in practical scenarios. In many introductory
    courses, linear transformations are hidden, and only matrix calculus is taught.
    My first exposition into the subject was similar: the first linear algebra course
    I took talked exclusively about matrices. It was as complicated and confusing
    as a math course can be. (Which, I can assure you, can be very complicated and
    confusing.) Later in my studies, everything clicked when I discovered that you
    could look at matrices from the perspective of linear transformations.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 从哲学的角度讲，你听说过柏拉图的洞穴寓言吗？在这个思想实验中，人们被假设生活在一个洞穴里，永远面对一面墙，只观察由他们身后火光投射的影像。他们所观察到的，用来构建世界的内部表征，与现实大相径庭。将这一类比应用到线性代数中，矩阵就是我们在实际场景中观察到并使用的影像。在许多入门课程中，线性变换被隐藏，只教授矩阵运算。我最初接触这个主题时也是如此：我上过的第一门线性代数课程完全讲解了矩阵。那门课复杂且令人困惑，堪称数学课程中的典型（而且，我可以保证，它确实是非常复杂和困惑的）。在我后来的学习中，当我发现可以从线性变换的角度看待矩阵时，一切都恍若豁然开朗。
- en: 'Without seeing what is behind matrices, it is impossible to master linear algebra.
    If my approach feels too abstract for you, keep this in mind: years later, when
    you are a practicing data scientist/machine learning engineer/researcher or whatever,
    going below the surface will pay huge dividends.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不深入了解矩阵背后的内容，是无法掌握线性代数的。如果我的方法对你来说太抽象，请记住这一点：多年后，当你成为一名实践中的数据科学家/机器学习工程师/研究员或者其他职业时，深入表面背后的内容会带来巨大的回报。
- en: 'Let’s get back on track and continue our discussion about linear transformations.
    The most commonly used matrix is the matrix of the identity transformation id
    : x→x. We’ll denote this by I. It is easy to see that'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们回到正题，继续讨论线性变换。最常用的矩阵是单位变换id : x→x的矩阵。我们用I来表示它。很容易看出'
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(3).png)(4.4)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f 是线性变换}](img/equation_(3).png)(4.4)'
- en: To summarize, for a matrix A, a linear transformation can be given by x→Ax.
    In fact, the mapping
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，对于一个矩阵A，一个线性变换可以通过x→Ax来表示。事实上，映射
- en: '![f ↦→ Af,P ](img/file330.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![f ↦→ Af,P ](img/file330.png)'
- en: defines a one-to-one correspondence between the space of linear transformations
    L(U,V ) defined by ([4.2](ch010.xhtml#x1-66010r18)) and the set of n ×m matrices,
    where n and m are the corresponding dimensions.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了线性变换空间L(U,V )（由[4.2](ch010.xhtml#x1-66010r18)定义）与n × m矩阵集之间的一个一一对应关系，其中n和m是对应的维度。
- en: 4.1.2 Matrix operations revisited
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.2 矩阵运算重温
- en: Functions can be added and composed. Because of the connection between linear
    transformations and matrices, matrix operations are inherited from the corresponding
    function operations.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 函数可以进行加法和复合操作。由于线性变换和矩阵之间的关系，矩阵运算继承了相应的函数运算。
- en: With this principle in mind, we defined matrix addition so that the the matrix
    of the sum of two linear transformations is the sum of the corresponding matrices.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个原则的指导下，我们定义了矩阵加法，使得两个线性变换的和对应的矩阵之和就是它们的矩阵之和。
- en: 'Mathematically speaking, if f,g : U →V are two linear transformations with
    matrices, f ↔︎A and g ↔︎B, then'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '从数学角度来看，假设f,g : U →V是两个具有矩阵的线性变换，f ↔︎A和g ↔︎B，则'
- en: '![ n (f + g)(u ) = f (u )+ g(u ) = ∑ (a + b )v . j j j i=1 i,j i,j i ](img/file331.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![ n (f + g)(u ) = f (u )+ g(u ) = ∑ (a + b )v . j j j i=1 i,j i,j i ](img/file331.png)'
- en: 'Thus, the corresponding matrices can be added together elementwise:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对应的矩阵可以按元素逐项相加：
- en: '![A + B = (ai,j + bi,j)n,m . i,j=1 ](img/file332.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![A + B = (ai,j + bi,j)n,m . i,j=1 ](img/file332.png)'
- en: Multiplication between matrices is defined by the composition of the corresponding
    transformations.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵之间的乘法通过对应变换的复合作用来定义。
- en: 'To see how, we study a special case first. (In general, it is a good idea to
    look at special cases first, as they often reduce the complexity and allow you
    to see patterns without information overload.) So, let f,g : U →U be two linear
    transformations, mapping U onto itself. To determine the elements of the matrix
    corresponding to f ∘g, we have to express f(g(u[j])) in terms of all the basis
    vectors u[1],…,u[n]. For this, we have'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '为了理解这个，我们首先研究一个特殊情况。（一般来说，首先看特殊情况是个好主意，因为它们通常可以减少复杂性，并帮助我们在没有信息过载的情况下看到模式。）因此，设
    f,g : U → U 是两个线性变换，将 U 映射到自身。为了确定对应于 f ∘ g 的矩阵元素，我们必须将 f(g(u[j])) 表示为所有基向量 u[1],…,u[n]
    的线性组合。为此，我们有：'
- en: '![ n (f g)(u ) = f(g(u )) = f(∑ b u ) j j k,j k n k=1 ∑ = bk,jf(uk) k=n1 n
    ∑ ∑ = bk,j ai,kui k=1 i=1 ∑n ∑n = ( ai,kbk,j)ui. i=1 k=1 ](img/file333.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![ n (f g)(u ) = f(g(u )) = f(∑ b u ) j j k,j k n k=1 ∑ = bk,jf(uk) k=n1 n
    ∑ ∑ = bk,j ai,kui k=1 i=1 ∑n ∑n = ( ai,kbk,j)ui. i=1 k=1 ](img/file333.png)'
- en: By considering how we defined a transformation’s matrix, the scalar (∑ [k=1]^na[i,k]b[k,j])
    is the element in the i-th row and j-th column of the matrix of f ∘g. Thus, matrix
    multiplication can be defined by
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 通过考虑我们如何定义变换的矩阵，标量 (∑ [k=1]^n a[i,k]b[k,j]) 是 f ∘ g 的矩阵中第 i 行、第 j 列的元素。因此，矩阵乘法可以定义为：
- en: '![ ( )n ∑n AB = ai,kbk,j . k=1 i,j=1 ](img/file334.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![ ( )n ∑n AB = ai,kbk,j . k=1 i,j=1 ](img/file334.png)'
- en: 'In the general case, we can only define the product of matrices if the corresponding
    linear transformations can be composed. That is, if f : U →V , then g must start
    from V . Translating this into the language of the matrices, the number of columns
    in A must match the number of rows in B. So, for any A ∈ℝ^(n×m) and B ∈ℝ^(m×l),
    their product is defined by'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '在一般情况下，只有当相应的线性变换可以组合时，我们才能定义矩阵的乘积。也就是说，如果 f : U → V，那么 g 必须从 V 开始。将其转化为矩阵语言，A
    的列数必须与 B 的行数相匹配。因此，对于任意的 A ∈ ℝ^(n×m) 和 B ∈ ℝ^(m×l)，它们的乘积定义为：'
- en: '![ ∑m AB = ( ai,kbk,j)n,l ∈ ℝn×l. k=1 i,j=1 ](img/file335.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑m AB = ( ai,kbk,j)n,l ∈ ℝn×l. k=1 i,j=1 ](img/file335.png)'
- en: 4.1.3 Inverting linear transformations
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.3 线性变换的逆
- en: Regarding linear transformations, the question of invertibility is extremely
    important. For example, have you encountered a system of equations like this?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 关于线性变换，逆变换的问题极其重要。例如，你是否遇到过这样的方程组？
- en: '![2x1 + x2 = 5 x1 − 3x2 = − 8 ](img/file336.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![2x1 + x2 = 5 x1 − 3x2 = − 8 ](img/file336.png)'
- en: If we define
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们定义：
- en: '![ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ 2 1 5 x1 A = ⌈ ⌉ , b = ⌈ ⌉ , x = ⌈ ⌉ , 1 − 3 − 8 x2 ](img/file337.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ 2 1 5 x1 A = ⌈ ⌉ , b = ⌈ ⌉ , x = ⌈ ⌉ , 1 − 3 − 8 x2 ](img/file337.png)'
- en: the above system can be written in the form Ax = b. These are called linear
    equations, modeling various processes from finance to biology.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 上述系统可以写成 Ax = b 的形式。这些称为线性方程，能够描述从金融到生物学的各种过程。
- en: How would you write the solution of such an equation? If there would be a matrix
    A^(−1) such that A^(−1)A is the identity matrix I (defined by ([4.4](ch010.xhtml#linear-transformations-and-matrices))),
    then multiplying the equation Ax = b from the left by A^(−1) would yield the solution
    in the form x = A^(−1)b.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如何写出这样方程的解呢？如果存在一个矩阵 A^(−1)，使得 A^(−1)A 是单位矩阵 I（由 ([4.4](ch010.xhtml#linear-transformations-and-matrices))
    定义），那么将方程 Ax = b 左乘 A^(−1) 会得到解的形式 x = A^(−1)b。
- en: The matrix A^(−1) is called the inverse matrix of A. It might not always exist,
    but when it does, it is extremely important for several reasons. We’ll talk about
    linear equations later, but first, let’s study the fundamentals of invertibility!
    Here is the general definition.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 A^(−1) 被称为 A 的逆矩阵。它可能并不总是存在，但当它存在时，它在多个方面都是非常重要的。我们稍后会讨论线性方程，但首先，让我们研究逆变换的基础！这是一般定义：
- en: Definition 17\. (Inverse of a linear transformation)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 17.（线性变换的逆）
- en: 'Let f : U →V be a linear transformation between the vector spaces U and V .
    We say that f is invertible if there is a linear transformation f^(−1) such that
    f^(−1) ∘f and f ∘f^(−1) are the identity functions; that is,'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : U → V 是在向量空间 U 和 V 之间的线性变换。如果存在一个线性变换 f^(−1)，使得 f^(−1) ∘ f 和 f ∘ f^(−1)
    是单位函数，即：'
- en: '![f− 1(f (u )) = u, − 1 f(f (v )) = v ](img/file338.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![f− 1(f (u )) = u, − 1 f(f (v )) = v ](img/file338.png)'
- en: holds for all u ∈U,v ∈V . f^(−1) is called the inverse of f.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 u ∈ U, v ∈ V 都成立。那么，f^(−1) 就叫做 f 的逆变换。
- en: Not all linear transformations are invertible. For instance, if f maps all vectors
    to the zero vector, you cannot define an inverse.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 不是所有的线性变换都有逆。例如，如果 f 将所有向量都映射到零向量，那么就无法定义逆变换。
- en: There are certain conditions that guarantee the existence of the inverse. One
    of the most important ones connects the concept of basis with invertibility.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些条件可以保证逆的存在。最重要的条件之一是将基的概念与可逆性联系起来。
- en: Theorem 19\. (Invertibility of linear transformations)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 19\. （线性变换的可逆性）
- en: 'Let f : U →V be a linear transformation and let u[1],…,u[n] be a basis in U.
    Then f is invertible if and only if f(u[1]),…,f(u[n]) is a basis in V .'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : U → V 是一个线性变换，且 u[1],…,u[n] 是 U 中的一个基。则 f 可逆当且仅当 f(u[1]),…,f(u[n]) 是
    V 中的一个基。'
- en: The following proof is straightforward, but can be a bit overwhelming. Feel
    free to skip this at the first reading, you can always revisit it later.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下证明是直接的，但可能有点复杂。第一次阅读时可以跳过，您可以稍后再回过头来看。
- en: Proof. As usual, the proof of the if and only if type theorems consist of two
    parts, as these statements involve two implications.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。像往常一样，if 和 only if 类型的定理的证明由两部分组成，因为这些陈述涉及两个推论。
- en: (a) First, we prove that f is invertible, then f(u[1]),…,f(u[n]) is a basis.
    That is, we need to show that f(u[1]),…,f(u[n]) is linearly independent and every
    y ∈V can be written as their linear combination.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 首先，我们证明 f 是可逆的，然后 f(u[1]),…,f(u[n]) 是一个基。也就是说，我们需要证明 f(u[1]),…,f(u[n]) 是线性无关的，并且每个
    y ∈V 都可以表示为它们的线性组合。
- en: Since f is invertible, f(0) = 0, moreover there are no nonzero vectors x ∈ U
    such that f(x) = 0\. In other words, 0 cannot be written as the nontrivial linear
    combination of f(u[1]),…,f(u[n]), from which Theorem [3](ch007.xhtml#x1-25003r3)
    implies the linear independence.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 f 是可逆的，f(0) = 0，此外没有非零向量 x ∈ U 使得 f(x) = 0。换句话说，0 不能表示为 f(u[1]),…,f(u[n])
    的非平凡线性组合，因此定理 [3](ch007.xhtml#x1-25003r3) 推导出线性无关性。
- en: On the other hand, invertibility implies that every ![y ∈ V ](img/file339.png)
    can be obtained as ![y = f(x) ](img/file340.png) for some ![x ∈ U ](img/file341.png).
    (With the choice ![x = f −1(y) ](img/file342.png).) As ![u1,...,un ](img/file343.png)
    is a basis, ![ ∑ x = ni=1xiui ](img/file344.png). Thus,
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，可逆性意味着每个 ![y ∈ V ](img/file339.png) 都可以表示为 ![y = f(x) ](img/file340.png)，其中
    ![x ∈ U ](img/file341.png)。 （选择 ![x = f −1(y) ](img/file342.png)。）由于 ![u1,...,un
    ](img/file343.png) 是一个基， ![ ∑ x = ni=1xiui ](img/file344.png)。因此，
- en: '![y = f(x) ∑n = f( xiui) i=1 ∑n = xif(ui), i=1 ](img/file345.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![y = f(x) ∑n = f( xiui) i=1 ∑n = xif(ui), i=1 ](img/file345.png)'
- en: showing that span(f(u[1]),…,f(u[n])) = V .
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 证明 span(f(u[1]),…,f(u[n])) = V。
- en: The linear independence f(u[1]),…,f(u[n]) and the fact that it spans V gives
    that it is indeed a basis.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 线性无关的 f(u[1]),…,f(u[n]) 以及它覆盖整个 V 的事实，证明它确实是一个基。
- en: '(b) Now we prove the other implication: if f(u[1]),…,f(u[n]) is a basis, then
    f is invertible.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 现在我们证明另一个推论：如果 f(u[1]),…,f(u[n]) 是一个基，那么 f 是可逆的。
- en: If f(u[1]),…,f(u[n]) is indeed a basis, then every y ∈V can be written as
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 f(u[1]),…,f(u[n]) 确实是一个基，那么每个 y ∈V 都可以表示为
- en: '![ n n ∑ ∑ y = yif (ui) = f( yiui), i=1 i=1 ](img/file346.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![ n n ∑ ∑ y = yif (ui) = f( yiui), i=1 i=1 ](img/file346.png)'
- en: which shows the surjectivity. Regarding the injectivity, if y = f(a) = f(b)
    for some a,b ∈U, then, since both a and b can be written as a linear combination
    of the u[i] basis vectors, we would have
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了满射性。关于单射性，如果 y = f(a) = f(b)，其中 a,b ∈U，那么，由于 a 和 b 都可以表示为 u[i] 基向量的线性组合，我们会得到
- en: '![ n n ∑ ∑ y = f(a) = f( aiui) = aif (ui) i=1 i=1 ](img/file347.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![ n n ∑ ∑ y = f(a) = f( aiui) = aif (ui) i=1 i=1 ](img/file347.png)'
- en: and
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 且
- en: '![ ∑n ∑n y = f(b) = f( biui) = yif(ui). i=1 i=1 ](img/file348.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑n ∑n y = f(b) = f( biui) = yif(ui). i=1 i=1 ](img/file348.png)'
- en: Thus, 0 = ∑ [i=1]^n(a[i]−b[i])u[i], and since u[1],…,u[n] is a basis in U, a[i]
    = b[i] must hold. Hence f is injective.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，0 = ∑ [i=1]^n(a[i]−b[i])u[i]，由于 u[1],…,u[n] 是 U 中的一个基，必须有 a[i] = b[i]。因此，f
    是单射的。
- en: 'A consequence of this theorem is that a linear transformation f : U →V is not
    invertible if the dimensions of U and V are different. We can look at invertibility
    from the aspect of matrices as well. For any A ∈ℝ^(n×n), if the corresponding
    linear transformation is invertible, there exists a matrix A^(−1) ∈ℝ^(n×n) such
    that A^(−1)A = AA^(−1) = I. If a matrix is not square, it is not invertible in
    the classical sense.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '这个定理的一个推论是，如果 U 和 V 的维数不同，那么线性变换 f : U → V 不是可逆的。我们也可以从矩阵的角度来看可逆性。对于任意 A ∈ℝ^(n×n)，如果对应的线性变换是可逆的，那么存在一个矩阵
    A^(−1) ∈ℝ^(n×n)，使得 A^(−1)A = AA^(−1) = I。如果一个矩阵不是方阵，它在经典意义下不可逆。'
- en: 4.1.4 The kernel and the image
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.4 核和像
- en: 'Regarding the invertibility of a linear transformation, two special sets play
    an essential role: the kernel and the image. Let’s see them!'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 关于线性变换的可逆性，有两个特殊的集合发挥着至关重要的作用：核（kernel）和像（image）。我们来看看它们！
- en: Definition 18\. (Kernel and image of linear transformations)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 18\. （线性变换的核与像）
- en: 'Let f : U →V be a linear transformation. Its image and kernel is defined by'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : U →V 是一个线性变换。其像和核分别定义为'
- en: '![im f := {f(u) : u ∈ U} ⊆ V ](img/file349.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![im f := {f(u) : u ∈ U} ⊆ V ](img/file349.png)'
- en: and
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![kerf := {u ∈ U : f(u ) = 0} ⊆ U. ](img/file350.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![kerf := {u ∈ U : f(u ) = 0} ⊆ U. ](img/file350.png)'
- en: Often, we write imA and kerA for some matrix A, referring to the linear transformation
    defined by x→Ax. Due to the linearity of f, it is easy to see that imf is a subspace
    of V and kerf is a subspace of U. As mentioned, they are closely connected with
    invertibility, as we shall see next.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们使用 imA 和 kerA 来表示某个矩阵 A 所定义的线性变换 x→Ax。由于 f 的线性性质，我们可以很容易地看出，imf 是 V 的一个子空间，kerf
    是 U 的一个子空间。如前所述，它们与可逆性密切相关，接下来我们将看到这一点。
- en: Theorem 20\. (Invertibility in terms of linear transformations)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 20. （关于线性变换的可逆性）
- en: 'Let f : U →V be a linear transformation.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : U →V 是一个线性变换。'
- en: (a) A is injective if and only if kerf = {0}.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: （a）A 是单射当且仅当 kerf = {0}。
- en: (b) A is surjective if and only if imf = V .
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: （b）A 是满射当且仅当 imf = V。
- en: (c) A is bijective (that is, invertible) if and only if kerf = {0}and imf =
    V .
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: （c）A 是双射（即可逆）当且仅当 kerf = {0} 且 imf = V。
- en: Proof. (a) If f is injective, there can only be one vector in U that is mapped
    to 0\. Since f(0) = 0 for any linear transformation, kerf = {0}.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。（a）如果 f 是单射，那么 U 中只能有一个向量映射到 0。由于对任何线性变换来说，f(0) = 0，因此 kerf = {0}。
- en: On the other hand, if there are two different vectors x,y ∈ U such that f(x)
    = f(y), then f(x−y) = f(x) −f(y) = 0, so x−y ∈ kerf. Thus, kerf = {0} implies
    x = y, which gives the injectivity.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果存在两个不同的向量 x, y ∈ U，使得 f(x) = f(y)，那么 f(x−y) = f(x) − f(y) = 0，因此 x−y
    ∈ kerf。于是，kerf = {0} 意味着 x = y，从而得出单射性。
- en: (b) This is just the definition of surjectivity.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: （b）这只是满射的定义。
- en: (c) This immediately follows from combining (a) and (b) above.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: （c）这立即可以通过结合上述（a）和（b）得出。
- en: Because matrices define linear transformations, it makes sense to talk about
    the inverse of a matrix.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 由于矩阵定义了线性变换，因此讨论矩阵的逆是有意义的。
- en: Algebraically speaking, the inverse of an A ∈ℝ^(n×n) is the matrix A^(−1) ∈ℝ^(n×n)
    such that A^(−1)A = AA^(−1) = I holds. The connection between linear transforms
    and matrices imply that A^(−1) is the matrix of f^(−1), so no surprise here.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 从代数的角度来看，A ∈ ℝ^(n×n) 的逆矩阵是 A^(−1) ∈ ℝ^(n×n)，满足 A^(−1)A = AA^(−1) = I。线性变换与矩阵之间的联系意味着
    A^(−1) 就是 f^(−1) 的矩阵，因此这里没有什么令人惊讶的。
- en: Don’t worry if this section about invertibility feels like a bit too much algebra.
    Later, when talking about the determinant of a transformation, we are going to
    study invertibility from a geometric perspective later in this chapter. In terms
    of matrices, later we are going to see a general method to calculate the inverse
    matrix in Section [5.1.6](ch011.xhtml#inverting-matrices). We’ll be there soon,
    but first, we take a look at how the choice of basis determines the matrix representation.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这一节关于可逆性的内容让你觉得有些代数上的复杂，不必担心。稍后在讲到变换的行列式时，我们将从几何角度研究可逆性。在矩阵方面，我们将在本章的第[5.1.6](ch011.xhtml#inverting-matrices)节中看到一种计算逆矩阵的通用方法。我们很快就会讲到，但首先，我们来看看基的选择如何决定矩阵表示。
- en: 4.2 Change of basis
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 基变换
- en: Previously in this section, we have seen that any linear transformation can
    be described with the images of the basis vectors (see Section [4.1.1](ch010.xhtml#linear-transformations-and-matrices)).
    This gave us the matrix representation that we use all the time. However, this
    very much depends on the choice of basis. Different bases yield different matrices
    for the same transformation.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节之前，我们已经看到，任何线性变换都可以通过基向量的像来描述（参见第[4.1.1](ch010.xhtml#linear-transformations-and-matrices)节）。这给了我们通常使用的矩阵表示。然而，这很大程度上取决于基的选择。不同的基会为同一个变换生成不同的矩阵。
- en: 'For instance, let’s take a look at f : ℝ² →ℝ², which maps e[1] = (1,0) to the
    vector (2,1) and e[2] = (0,1) to (1,2). Its matrix in the standard orthonormal
    basis E = {e[1],e[2]} is given by'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '比如，我们可以看一下 f : ℝ² → ℝ²，它将 e[1] = (1,0) 映射到向量 (2,1)，将 e[2] = (0,1) 映射到 (1,2)。在标准正交基
    E = {e[1],e[2]} 下，它的矩阵表示为'
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(4).png)(4.5)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f 是线性的}](img/equation_(4).png)(4.5)'
- en: '![PIC](img/file353.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file353.png)'
- en: 'Figure 4.3: The linear transformation f, defined by ([5.2](ch010.xhtml#change-of-basis))'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3：线性变换 f，由于基变换定义的（参见[5.2](ch010.xhtml#change-of-basis)）
- en: The effect of f is visualized in Figure [4.3](#).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: f 的作用在图 4.3 中可视化。
- en: What if we select a different basis, say P = {p[1] = (1,1),p[2] = (−1,1)}? With
    a quick calculation, we can check that
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择不同的基，比如 P = {p[1] = (1,1), p[2] = (−1,1)}，那么通过快速计算，我们可以检查到
- en: '![⌊ ⌋ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ |2 1| 1 3 |2 1| − 1 − 1 |⌈1 2|⌉ ⌈ ⌉ = ⌈ ⌉ , |⌈1 2|⌉
    ⌈ ⌉ = ⌈ ⌉ . 1 3 1 1 ](img/file354.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![⌊ ⌋ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ |2 1| 1 3 |2 1| − 1 − 1 |⌈1 2|⌉ ⌈ ⌉ = ⌈ ⌉ , |⌈1 2|⌉
    ⌈ ⌉ = ⌈ ⌉ . 1 3 1 1 ](img/file354.png)'
- en: In other words, f(p[1]) = 3p[1] + 0p[2] and f(p[2]) = 0p[1] + p[2]. This is
    visualized by Figure [4.4](#).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，f(p[1]) = 3p[1] + 0p[2] 和 f(p[2]) = 0p[1] + p[2]。这可以通过图形[4.4](#)来直观展示。
- en: '![PIC](img/file355.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file355.png)'
- en: 'Figure 4.4: The effect of f on p[1] = (1,1) and p[2] = (−1,1)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4：f 对 p[1] = (1,1) 和 p[2] = (−1,1) 的作用
- en: This means that if P = {p[1],p[2]} is our basis (thus, if writing (a,b) means
    ap[1] + bp[2]), the matrix of f becomes
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，如果 P = {p[1],p[2]} 是我们的基（因此，若写作 (a,b) 就意味着 ap[1] + bp[2]），则 f 的矩阵为
- en: '![ ⌊ ⌋ |3 0| Af,P = |⌈0 1|⌉ . ](img/file356.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ |3 0| Af,P = |⌈0 1|⌉ . ](img/file356.png)'
- en: In this form, A[f,P] is a diagonal matrix. (That is, its elements below and
    above the diagonal are zero.) As you can see, having the right basis can significantly
    simplify the linear transformation. For instance, in n dimensions, applying a
    transformation in diagonal form requires only n operations, as
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种形式下，A[f,P] 是一个对角矩阵。（也就是说，它的对角线下方和上方的元素是零。）如你所见，选择正确的基可以显著简化线性变换。例如，在 n 维空间中，应用对角矩阵形式的变换只需要进行
    n 次操作，因为
- en: '![⌊ ⌋⌊ ⌋ ⌊ ⌋ d1 0 ... 0 x1 d1x1 || 0 d ... 0 |||| x || || d x || || 2 ||||
    2|| = || 2 2|| |⌈ ... ... ... ... |⌉|⌈ ...|⌉ |⌈ ... |⌉ 0 0 ... dn xn dnxn ](img/file357.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![⌊ ⌋⌊ ⌋ ⌊ ⌋ d1 0 ... 0 x1 d1x1 || 0 d ... 0 |||| x || || d x || || 2 ||||
    2|| = || 2 2|| |⌈ ... ... ... ... |⌉|⌈ ...|⌉ |⌈ ... |⌉ 0 0 ... dn xn dnxn ](img/file357.png)'
- en: Otherwise, n² operations are needed. So, we can save a lot there.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，可能需要 n² 次操作。因此，我们可以节省很多计算。
- en: 4.2.1 The transformation matrix
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.1 变换矩阵
- en: 'We have just seen that the matrix of a linear transformation depends on our
    choice of basis. However, there is a special relation between matrices of the
    same transformation. We’ll explore this next. Let f : U →U be a linear transformation,
    and let P = {p[1],…,p[n]} and Q = {q[1],…,q[n] be two bases. As before, A[f,S]
    denotes the matrix of f in some basis S.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '我们刚才看到，线性变换的矩阵依赖于我们选择的基。然而，对于同一变换的矩阵之间存在一种特殊的关系。我们接下来将探讨这一点。设 f : U → U 是一个线性变换，P
    = {p[1],…,p[n]} 和 Q = {q[1],…,q[n]} 是两个基。如前所述，A[f,S] 表示在某基 S 中 f 的矩阵。'
- en: Suppose that we know A[f,P] , but we have our vectors represented in terms of
    the other basis Q. How do we calculate the images our vectors under the linear
    transformation? A natural idea is to first transform our vector representations
    from Q to P, apply A[f,P] , then transform the representations back. In the following,
    we are going to make this precise.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们知道 A[f,P]，但是我们的向量是通过另一组基 Q 来表示的。我们如何计算在该线性变换下向量的像呢？一种自然的思路是，首先将向量从 Q 基变换到
    P 基，应用 A[f,P]，然后再将表示转换回来。接下来，我们将精确地描述这一过程。
- en: 'Let ![t : U → U ](img/file358.png) be a transformation defined by ![pi ↦→ qi
    ](img/file359.png) for all ![i ∈ {1,...,n } ](img/file360.png). (In other words,
    ![t ](img/file361.png) maps one set of basis vectors to another.) Since ![P ](img/file362.png)
    and ![Q ](img/file363.png) are bases (so the sets are linearly independent), ![t
    ](img/file364.png) is invertible.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '设 ![t : U → U ](img/file358.png) 是一个变换，定义为 ![pi ↦→ qi ](img/file359.png)，适用于所有
    ![i ∈ {1,...,n } ](img/file360.png)。 （换句话说，![t ](img/file361.png) 将一组基向量映射到另一组。）由于
    ![P ](img/file362.png) 和 ![Q ](img/file363.png) 是基（因此这些集合是线性无关的），所以 ![t ](img/file364.png)
    是可逆的。'
- en: Suppose that the matrix ![ Q Af,Q = (ai,j)ni,j=1 ](img/file365.png) is known
    to us, that is,
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 假设矩阵 ![ Q Af,Q = (ai,j)ni,j=1 ](img/file365.png) 已知，即
- en: '![ ∑n Q f(qj) = Af,Qqj = ai,jqi i=1 ](img/file366.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑n Q f(qj) = Af,Qqj = ai,jqi i=1 ](img/file366.png)'
- en: holds for all ![j ](img/file367.png). So, we have
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 ![j ](img/file367.png) 都成立。因此，我们有
- en: '![ −1 −1 (t ft)(pj ) = t f(qj) ∑n = t−1( aQi,jqi) i=1 ∑n = aQi,jt−1(qi) i=1
    ∑n = aQi,jpi. i=1 ](img/file368.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![ −1 −1 (t ft)(pj ) = t f(qj) ∑n = t−1( aQi,jqi) i=1 ∑n = aQi,jt−1(qi) i=1
    ∑n = aQi,jpi. i=1 ](img/file368.png)'
- en: In other words, the matrix of the composed transformation t^(−1)ft in the basis
    P is the same as the matrix of f in Q. In terms of formulas,
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，在基 P 中，组合变换 t^(−1)ft 的矩阵与基 Q 中 f 的矩阵相同。用公式表示，
- en: T^(−1) A [f,P] T = A[f,Q],
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: T^(−1) A [f,P] T = A[f,Q]，
- en: (4.6)
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: (4.6)
- en: where T denotes the matrix of t in P. (For notational simplicity, we omit the
    subscript. Most often, we don’t care what base it is in.)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 T 表示 t 在基 P 中的矩阵。（为了简化符号，我们省略了下标。通常，我们并不关心变换在哪个基下进行。）
- en: We’ll call T the change of basis matrix. These types of relations are prevalent
    in linear algebra, so we’ll take the time to introduce a definition formally.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 T 称为基变换矩阵。这类关系在线性代数中很常见，因此我们将花时间正式介绍这个定义。
- en: Definition 19\. (Similar matrices)
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 19.（相似矩阵）
- en: Let A,B ∈ℝ^(n×n) be two arbitrary matrices. A and B are called similar if there
    exists a matrix T ∈ℝ^(n×n) such that
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 设 A,B ∈ℝ^(n×n) 为两个任意矩阵。如果存在一个矩阵 T ∈ℝ^(n×n)，使得 A 和 B 称为相似矩阵，则有
- en: '![ − 1 B = T AT ](img/file369.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![ − 1 B = T AT ](img/file369.png)'
- en: holds. We call mappings of the form A→T^(−1)AT similarity transformations.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 成立。我们称形式为 A→T^(−1)AT 的映射为相似变换。
- en: In these terms, ([4.6](ch010.xhtml#the-transformation-matrix)) says that the
    matrices of a given linear transformation are all similar to each other.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 用这些术语，（[4.6](ch010.xhtml#the-transformation-matrix)）说明了给定线性变换的矩阵彼此相似。
- en: With this under our belt, we can finish up with the example ([4.5](ch010.xhtml#change-of-basis)).
    In this case, T and T^(−1) can be written as
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握了这些，我们可以完成例子（[4.5](ch010.xhtml#change-of-basis)）。在这种情况下，T 和 T^(−1) 可以写作
- en: '![ ⌊ ⌋ ⌊ ⌋ | 1 − 1| | 1∕2 1∕2| T = |⌈ 1 1|⌉ , T −1 = |⌈− 1∕2 1∕2|⌉ . ](img/file371.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌊ ⌋ | 1 − 1| | 1∕2 1∕2| T = |⌈ 1 1|⌉ , T −1 = |⌈− 1∕2 1∕2|⌉ . ](img/file371.png)'
- en: (Later, we’ll see a general method to compute the inverse of any matrix, but
    for now, you can verify this by hand.) Thus,
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: （稍后，我们将看到计算任何矩阵的逆的一般方法，但现在，你可以手动验证这一点。）因此，
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(5).png)(4.7)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f 是线性的}](img/equation_(5).png)(4.7)'
- en: or equivalently,
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 或等价地，
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(6).png)(4.8)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f 是线性的}](img/equation_(6).png)(4.8)'
- en: Figure [4.5](#) shows what ([4.8](#)) looks like in geometric terms.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [4.5](#) 显示了 ([4.8](#)) 在几何上的表现。
- en: '![PIC](img/file380.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file380.png)'
- en: 'Figure 4.5: Change of basis, illustrated'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5：基变换示意图
- en: 'From this example, we can see that a properly selected similarity transformation
    can diagonalize certain matrices. Is this a coincidence? Spoiler alert: no. In
    Chapter [7](ch013.xhtml#matrix-factorizations), we will see exactly when and how
    this can be done.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个例子中，我们可以看到，正确选择的相似变换能够对某些矩阵进行对角化。这是巧合吗？剧透：不是的。在第 [7](ch013.xhtml#matrix-factorizations)
    章中，我们将精确了解何时以及如何做到这一点。
- en: I know, this is a bit too abstract. As always, examples illustrate a concept
    best, so let’s see some!
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道，这有点抽象。正如往常一样，示例能最好地阐明一个概念，所以我们来看一些示例！
- en: 4.3 Linear transformations in the Euclidean plane
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 欧几里得平面中的线性变换
- en: We have just seen that a linear transformation can be described by the image
    of a basis set. From a geometric viewpoint, they are functions mapping [parallelepipeds](https://en.wikipedia.org/wiki/Parallelepiped)
    to parallelepipeds.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到，线性变换可以通过基集的映射来描述。从几何角度来看，它们是将[平行六面体](https://en.wikipedia.org/wiki/Parallelepiped)映射到平行六面体的函数。
- en: Because of the linearity, you can imagine this as distorting the grid determined
    by the bases.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 由于是线性变换，你可以将其想象为扭曲由基向量确定的网格。
- en: '![PIC](img/file381.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file381.png)'
- en: 'Figure 4.6: How linear transforms distort the grid determined by the basis
    vectors'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6：线性变换如何扭曲由基向量确定的网格
- en: 'In two dimensions, we have seen a few examples of geometric maps such as scaling
    and rotation as linear transformations. Now we can put them into matrix form.
    There are five of them in particular that we will study: stretching, shearing,
    rotation, reflection, and projection.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在二维中，我们已经看到了几个几何映射的例子，例如缩放和旋转，它们作为线性变换。现在我们可以将它们转化为矩阵形式。我们将研究其中的五种：拉伸、剪切、旋转、反射和投影。
- en: These simple transformations are not only essential to build intuition, but
    they are also frequently applied in computer vision. Flipping, rotating, and stretching
    are essential parts of image augmentation pipelines, greatly enhancing the performance
    of models.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这些简单的变换不仅对建立直觉至关重要，而且在计算机视觉中也经常应用。翻转、旋转和拉伸是图像增强管道的关键部分，能够显著提升模型的性能。
- en: 4.3.1 Stretching
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.1 拉伸
- en: The simplest one is a generalization of scaling. We have seen a variant of this
    in Example 1 above (see Section [4.1](ch010.xhtml#what-is-a-linear-transformation)).
    In matrix form, this is given by
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的一个是缩放的推广。我们已经在上面的示例 1 中看到了这种变体（见第 [4.1](ch010.xhtml#what-is-a-linear-transformation)
    节）。在矩阵形式下，这可以表示为
- en: '![ ⌊ ⌋ c1 0 A = ⌈ ⌉ , c1,c2 ∈ ℝ. 0 c2 ](img/file382.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ c1 0 A = ⌈ ⌉ , c1,c2 ∈ ℝ. 0 c2 ](img/file382.png)'
- en: Linear transformations such as this can be visualized by plotting the image
    of the unit square determined by the standard basis e[1] = (1,0),e[2] = (0,1).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这类线性变换可以通过绘制由标准基 e[1] = (1,0)，e[2] = (0,1) 确定的单位正方形的图像来可视化。
- en: '![PIC](img/file383.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file383.png)'
- en: 'Figure 4.7: Stretching'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7：拉伸
- en: 4.3.2 Rotations
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.2 旋转
- en: Rotations are given by the matrix
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 旋转由矩阵给出
- en: '![ ⌊ ⌋ cosα − sinα R α = ⌈ ⌉. sinα cosα ](img/file384.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ cosα − sinα R α = ⌈ ⌉. sinα cosα ](img/file384.png)'
- en: To see why, recall that each column of the transformation’s matrix describes
    the image of the basis vectors. The rotation of (1,0) is given by (cosα,sinα),
    while the rotation of (0,1) is (cos(α + π∕2),sin(α + π∕2)). This is illustrated
    by Figure 4.8.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解为什么，回想一下变换矩阵的每一列描述了基向量的图像。旋转 (1,0) 给出的结果是 (cosα, sinα)，而旋转 (0,1) 给出的结果是 (cos(α
    + π∕2), sin(α + π∕2))。这一点在图4.8中有所说明。
- en: '![PIC](img/file385.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file385.png)'
- en: 'Figure 4.8: The rotation matrix explained'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8：旋转矩阵说明
- en: Like above, we can visualize the image of the unit square to gain a geometric
    insight into what is happening.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 就像上面一样，我们可以通过可视化单位正方形的图像，来获得对发生的几何学理解。
- en: '![PIC](img/file386.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file386.png)'
- en: 'Figure 4.9: Rotation'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9：旋转
- en: 4.3.3 Shearing
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.3 剪切
- en: Another essential geometric transform is shearing, which is frequently applied
    in physics. A shearing force ([https://en.wikipedia.org/wiki/Shear_force](https://en.wikipedia.org/wiki/Shear_force))
    is a pair of forces with opposite directions, acting on the same body.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的几何变换是剪切，这在物理学中有广泛应用。剪切力（[https://en.wikipedia.org/wiki/Shear_force](https://en.wikipedia.org/wiki/Shear_force)）是一对方向相反的力作用于同一物体。
- en: '![PIC](img/file387.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file387.png)'
- en: 'Figure 4.10: Shearing'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.10：剪切
- en: Its matrix is given in the form
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 它的矩阵以如下形式给出
- en: '![ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ Sx = ⌈1 kx⌉ , Sy = ⌈ 1 0⌉, S = ⌈1 kx⌉ , 0 1 ky 1 ky 1 ](img/file388.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ Sx = ⌈1 kx⌉ , Sy = ⌈ 1 0⌉, S = ⌈1 kx⌉ , 0 1 ky 1 ky 1 ](img/file388.png)'
- en: where S[x], S[y], and S represent shearing transformations in the x, y, and
    in both directions.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 S[x]、S[y] 和 S 代表在 x、y 方向及两者方向上的剪切变换。
- en: 4.3.4 Reflection
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.4 反射
- en: Until this point, all the transformations we have seen in the Euclidean plane
    preserved the “orientation” of the space. However, this is not always the case.
    The transformation given by the matrices
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在欧几里得平面上看到的所有变换都保持了空间的“方向性”。然而，情况并非总是如此。由以下矩阵给出的变换
- en: '![ ⌊ ⌋ ⌊ ⌋ − 1 0 1 0 R1 = ⌈ ⌉ , R2 = ⌈ ⌉ 0 1 0 − 1 ](img/file389.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌊ ⌋ − 1 0 1 0 R1 = ⌈ ⌉ , R2 = ⌈ ⌉ 0 1 0 − 1 ](img/file389.png)'
- en: act as reflections with respect to the x and the y axes.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 相对于 x 轴和 y 轴，它们充当反射。
- en: '![PIC](img/file390.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file390.png)'
- en: 'Figure 4.11: Reflection'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11：反射
- en: When combined with a rotation, we can use reflections to flip bases. For instance,
    the transformation maps e[1] to e[2] and e[2] to e[1].
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 当与旋转结合使用时，我们可以利用反射来翻转基向量。例如，变换将 e[1] 映射到 e[2]，并将 e[2] 映射到 e[1]。
- en: '![ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ R = ⌈0 − 1⌉ ⌈1 0⌉ = ⌈0 1⌉ 1 0 0 − 1 1 0 ◟--◝◜--◞ ◟---◝◜--◞ rotation
    with π∕2 =R2 ](img/file391.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ R = ⌈0 − 1⌉ ⌈1 0⌉ = ⌈0 1⌉ 1 0 0 − 1 1 0 ◟--◝◜--◞ ◟---◝◜--◞ 旋转
    π∕2 =R2 ](img/file391.png)'
- en: '![PIC](img/file392.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file392.png)'
- en: 'Figure 4.12: Swapping e[1] and e[2] is a reflection and rotation'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12：交换 e[1] 和 e[2] 是反射和旋转
- en: These types of transformations play an essential role in understanding determinants,
    as we will soon see in the next chapter.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类型的变换在理解行列式时起着至关重要的作用，正如我们将在下一章中看到的那样。
- en: In general, reflections can be easily defined in higher dimensional spaces.
    For instance,
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，反射可以很容易地定义在更高维空间中。例如，
- en: '![ ⌊ ⌋ 1 0 0 R = ||0 1 0 || ⌈ ⌉ 0 0 − 1 ](img/file393.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ 1 0 0 R = ||0 1 0 || ⌈ ⌉ 0 0 − 1 ](img/file393.png)'
- en: 'is a reflection in ℝ³ that flips e[3] to the opposite direction. It is just
    like looking in the mirror: it turns left to right and right to left.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 是 ℝ³ 中的一个反射，它将 e[3] 翻转到相反的方向。这就像照镜子：它把左变右，把右变左。
- en: Reflections can flip orientations multiple times. The transformation given by
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 反射可以多次翻转方向。由以下变换给出的
- en: '![ ⌊ ⌋ 1 0 0 R = || || ⌈0 − 1 0⌉ 0 0 − 1 ](img/file394.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ 1 0 0 R = || || ⌈0 − 1 0⌉ 0 0 − 1 ](img/file394.png)'
- en: flips e[2] and e[3], changing the orientation twice. Later, we’ll see that the
    “number of changes in orientation” of a given transformation is one of its essential
    descriptors.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 翻转 e[2] 和 e[3]，改变了方向两次。稍后我们将看到，给定变换的“方向变化次数”是其一个重要的描述性特征。
- en: 4.3.5 Orthogonal projection
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.5 正交投影
- en: One of the most important transformations (not only in two dimensions) is the
    orthogonal projection. We have seen this already when talking about inner products
    and their geometric representation in Section [2.2.3](ch008.xhtml#the-geometric-interpretation-of-inner-products).
    By taking a closer look, it turns out that they are linear transformations.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个最重要的变换（不仅仅是在二维空间中）是正交投影。我们已经在讨论内积及其几何表示时提到过这一点，在[2.2.3节](ch008.xhtml#the-geometric-interpretation-of-inner-products)中有讲解。仔细观察会发现，它们是线性变换。
- en: '![PIC](img/file395.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file395.png)'
- en: 'Figure 4.13: Orthogonal projection'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13：正交投影
- en: Recall from ([3.2.3](ch008.xhtml#x1-45003r3.2.3)) that the orthogonal projection
    of x to some y can be written as
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆一下（[3.2.3节](ch008.xhtml#x1-45003r3.2.3)），x到某个y的正交投影可以写成
- en: '![proj (x) = ⟨x,y⟩y. y ⟨y,y⟩ ](img/file396.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![proj(x) = ⟨x,y⟩y. y ⟨y,y⟩](img/file396.png)'
- en: The bilinearity of ⟨⋅,⋅⟩ immediately implies that proj[y](x) is also linear.
    With a bit of algebra, we can rewrite this in terms of matrices. We have
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: ⟨⋅,⋅⟩的双线性特性立即意味着proj[y](x)也是线性的。通过一些代数，我们可以用矩阵的形式重新写出这个公式。我们有
- en: '![projy(x) = ⟨x,y-⟩y ⟨y,y ⟩ ⌊ ⌋ = x1y1-+-x2y2⌈y1 ⌉ ∥y ∥2 y2 ⌊ ⌋ ⌊ ⌋ 1 y21 y1y2
    x1 = ----2⌈ 2 ⌉ ⌈ ⌉ ∥y ∥ y1y2 y2 x2 1 = ----2yyT x, ∥y ∥ ](img/file397.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![projy(x) = ⟨x,y-⟩y ⟨y,y ⟩ ⌊ ⌋ = x1y1-+-x2y2⌈y1 ⌉ ∥y ∥2 y2 ⌊ ⌋ ⌊ ⌋ 1 y21 y1y2
    x1 = ----2⌈ 2 ⌉ ⌈ ⌉ ∥y ∥ y1y2 y2 x2 1 = ----2yyT x, ∥y ∥ ](img/file397.png)'
- en: thus,
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，
- en: '![ ⌊ ⌋ 1 y2 y y projy = ----2⌈ 1 1 2⌉ ∥y ∥ y1y2 y22 1 = ----2yyT x ∥y ∥ ](img/file398.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ 1 y2 y y projy = ----2⌈ 1 1 2⌉ ∥y ∥ y1y2 y22 1 = ----2yyT x ∥y ∥ ](img/file398.png)'
- en: Notice that
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到
- en: '![ y2 projy(e2) = y1 projy(e1), ](img/file399.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![ y2 projy(e2) = y1 projy(e1), ](img/file399.png)'
- en: so the images of the standard basis vectors are not linearly independent. As
    a consequence, the image of the plane under proj[y] is span(y), which is a one-dimensional
    subspace. From this example, we can see that the image of a vector space under
    a linear transformation is not necessarily of the same dimension as the starting
    space.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 所以标准基向量的像不是线性无关的。结果，平面在proj[y]下的像是span(y)，这是一个一维子空间。通过这个例子，我们可以看到，线性变换下的向量空间的像不一定与起始空间的维度相同。
- en: With these examples and knowledge under our belt, we have a basic understanding
    of linear transformations, the most basic building blocks of neural networks.
    In the next section, we will study how linear transformations affect the geometric
    structure of the vector space.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些例子和所掌握的知识，我们对线性变换有了基本的理解，这也是神经网络最基本的构建块。在下一节中，我们将研究线性变换如何影响向量空间的几何结构。
- en: 4.4 Determinants, or how linear transformations affect volume
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 行列式，或者线性变换如何影响体积
- en: In Section [4.3](ch010.xhtml#linear-transformations-in-the-euclidean-plane),
    we have seen that linear transformations (Definition [16](ch010.xhtml#x1-66002r16))
    can be thought of as distorting the grid determined by the basis vectors.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[4.3节](ch010.xhtml#linear-transformations-in-the-euclidean-plane)中，我们已经看到，线性变换（定义[16](ch010.xhtml#x1-66002r16)）可以看作是扭曲由基向量决定的网格。
- en: Following our geometric intuition, we suspect that measuring how much a transformation
    distorts volume and distance can provide some valuable insight. As we will see
    in this chapter, this is exactly the case. Transformations that preserve distance
    or norm are special, giving rise to methods such as Principal Component Analysis.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 跟随我们的几何直觉，我们怀疑，测量变换如何扭曲体积和距离能够提供一些有价值的洞察。正如我们在本章中所见，确实如此。保持距离或范数不变的变换是特殊的，这也催生了主成分分析等方法。
- en: 4.4.1 How linear transformations scale the area
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.1 线性变换如何缩放面积
- en: Let’s go back to the Euclidean plane one more time. Consider any linear transformation
    A, mapping the unit square to a parallelogram.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再回到欧几里得平面。考虑任何线性变换A，将单位正方形映射到一个平行四边形。
- en: '![PIC](img/file400.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file400.png)'
- en: 'Figure 4.14: Image of the unit square under a linear transformation'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14：单位正方形在线性变换下的像
- en: The area of this parallelogram describes how A scales the unit square. Let’s
    call it λ for now; that is,
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这个平行四边形的面积描述了A如何缩放单位正方形。暂时将其称为λ，即，
- en: '![area(A (C )) = λ ⋅area(C), ](img/file401.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![area(A(C)) = λ ⋅area(C), ](img/file401.png)'
- en: where C = [0,1] × [0,1] is the unit square, and A(C) is its image
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 其中C = [0,1] × [0,1]是单位正方形，A(C)是其像
- en: '![A(C ) := {Ax : x ∈ C }. ](img/file402.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![A(C) := {Ax : x ∈ C}. ](img/file402.png)'
- en: Due to linearity, λ also matches the scaling ratio between the area of any rectangle
    (with parallel sides to the coordinate axes) and its image under A. As Figure
    4.15 shows, we can approximate any planar object as the union of rectangles.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 由于线性性，λ也符合任何矩形（其边与坐标轴平行）面积与其在A下像的比例。如图4.15所示，我们可以将任何平面物体近似为矩形的并集。
- en: 'If all rectangles are scaled by λ, then unions of rectangles also scale by
    that factor. Thus, it follows that λ is also the scaling ratio between any planar
    object E and its image A(E) = {Ax : x ∈E}.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '如果所有矩形都被λ缩放，那么矩形的并集也会按该比例缩放。因此，λ也就是任何平面物体E与其像A(E) = {Ax : x ∈E}之间的缩放比例。'
- en: '![PIC](img/file403.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file403.png)'
- en: 'Figure 4.15: Approximating planar objects with a union of rectangles'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.15：用矩形并集近似平面物体
- en: 'This quantity λ reveals a lot about the transformation itself, but there is
    a question remaining: how can we calculate it?'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数量λ揭示了变换本身的很多信息，但仍然有一个问题：我们如何计算它？
- en: Suppose that our linear transformation is given by
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的线性变换由以下给出：
- en: '![ ⌊ ⌋ x y A = ⌈ 1 1⌉ , x2 y2 ](img/file404.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ x y A = ⌈ 1 1⌉ , x2 y2 ](img/file404.png)'
- en: thus its columns x = (x[1],x[2]) and y = (y[1],y[2]) describe the two sides
    of the parallelogram. This is the image of the unit square.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，其列向量x = (x[1],x[2])和y = (y[1],y[2])描述了平行四边形的两条边。这是单位正方形的图像。
- en: '![PIC](img/file405.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file405.png)'
- en: 'Figure 4.16: Image of the unit square under a linear transformation'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.16：线性变换下单位正方形的图像
- en: Our area scaling factor λ equals the area of this parallelogram, so our goal
    is to calculate this.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的面积缩放因子λ等于这个平行四边形的面积，所以我们的目标是计算这个。
- en: The area of any parallelogram can be calculated by multiplying the length of
    the base (∥x∥ in this case) with the height h. (You can easily see this by cutting
    off a triangle at the right side of the parallelogram and putting it to the left
    side, rearranging it as a rectangle.) h is unknown, but with basic trigonometry,
    we can see that h = sinα∥y∥, where α is the angle between x and y.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 任何平行四边形的面积都可以通过将底边的长度（此处为∥x∥）与高度h相乘来计算。（你可以通过在平行四边形的右侧切去一个三角形并将其放到左侧，重新排列成一个矩形来轻松看到这一点。）h是未知的，但通过基础三角学，我们可以看到h
    = sinα∥y∥，其中α是x和y之间的角度。
- en: Thus,
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，
- en: '![area = sin α∥y∥∥x ∥. ](img/file406.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![area = sin α∥y∥∥x ∥. ](img/file406.png)'
- en: This is almost the dot product of x and y. (Recall that the dot product can
    be written as ⟨x,y⟩ = ∥x∥∥y∥cosα.) However, the sinα part is not a match.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这几乎是x和y的点积。（回想一下，点积可以表示为⟨x,y⟩ = ∥x∥∥y∥cosα。）然而，sinα部分并不匹配。
- en: Fortunately, there is a clever trick we can use to turn this into a dot product!
    Since sinα = cos(α −![π 2](img/file408.png)), we have
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们可以使用一个巧妙的技巧将其转换为点积！由于sinα = cos(α −![π 2](img/file408.png))，我们有
- en: '![ π- area = cos(α− 2)∥x∥∥y ∥. ](img/file410.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![ π- area = cos(α− 2)∥x∥∥y ∥. ](img/file410.png)'
- en: The issue is the angle between x and y is not α −![π 2](img/file411.png). However,
    we can solve this easily by applying a rotation (Section [4.3.2](ch010.xhtml#rotations)).
    Applying the transformation
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，x和y之间的角度不是α −![π 2](img/file411.png)。然而，我们可以通过应用旋转来轻松解决这个问题（第[4.3.2](ch010.xhtml#rotations)节）。应用变换
- en: '![ ⌊ ⌋ 0 1 R = ⌈ ⌉, − 1 0 ](img/file412.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ 0 1 R = ⌈ ⌉, − 1 0 ](img/file412.png)'
- en: we obtain
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到
- en: '![y = Ry = (y,− y ). rot 2 1 ](img/file413.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![y = Ry = (y,− y ). rot 2 1 ](img/file413.png)'
- en: Since ![∥yrot∥ = ∥y∥ ](img/file414.png), we have
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 由于![∥yrot∥ = ∥y∥ ](img/file414.png)，我们有
- en: '![area = sin α∥y∥∥x ∥ π = cos(α − 2)∥x ∥∥y∥ π = cos(α − 2)∥x ∥∥yrot∥ = ⟨x,yrot⟩.
    ](img/file415.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![area = sin α∥y∥∥x ∥ π = cos(α − 2)∥x ∥∥y∥ π = cos(α − 2)∥x ∥∥yrot∥ = ⟨x,yrot⟩.
    ](img/file415.png)'
- en: 'The quantity ⟨x,y[rot]⟩ can be calculated using only the elements of the matrix
    A:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 数量⟨x,y[rot]⟩可以仅使用矩阵A的元素来计算：
- en: '![⟨x, yrot⟩ = x1y2 − x2y1\. ](img/file416.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![⟨x, yrot⟩ = x1y2 − x2y1\. ](img/file416.png)'
- en: Notice that ⟨x,y[rot]⟩ can be negative! This happens when the angle between
    y = Ae[2] and x = Ae[1], measured from a counter-clockwise direction, is larger
    than π, as this implies cos(α −![π 2](img/file418.png))/span>0\.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，⟨x,y[rot]⟩可能为负！当y = Ae[2]和x = Ae[1]之间的角度，从逆时针方向测量时，大于π时，就会发生这种情况，因为这意味着cos(α
    −![π 2](img/file418.png))/span>0\。
- en: Hence, the quantity ⟨x,y[rot]⟩ is called the signed area of the parallelogram.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，⟨x,y[rot]⟩被称为平行四边形的带符号面积。
- en: In two dimensions, we call this the determinant of the linear transformation.
    That is, for any given linear transformation/matrix A ∈ℝ^(2×2), its determinant
    is defined by
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在二维空间中，我们称之为线性变换的行列式。也就是说，对于任何给定的线性变换/矩阵A ∈ℝ^(2×2)，其行列式定义为
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(7).png)(4.9)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(7).png)(4.9)'
- en: The determinant is often written as jAj, but we’ll avoid this notation. We’ll
    deal with determinants for any matrix A ∈ℝ^(n×n), but let’s stay with the 2 ×
    2 case just a bit to build intuition.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 行列式通常写作jAj，但我们将避免使用这种符号。我们将处理任何矩阵A ∈ℝ^(n×n)的行列式，但为了直观起见，我们先保持在2 × 2的情况。
- en: 'The determinant also reveals the orientation of the vectors: positive determinant
    means positive orientation, negative determinant means negative orientation. (Intuitively,
    positive orientation means that the angle measured from x to y in a counter-clockwise
    direction is between 0 and π; equivalently, the angle measured from x to y in
    a clockwise direction is between π and 2π.) This is demonstrated in Figure 4.17
    below.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 行列式还揭示了向量的方向性：正行列式表示正方向，负行列式表示负方向。（直观地说，正方向意味着从x到y的角度在逆时针方向上位于0到π之间；等价地，顺时针方向上从x到y的角度在π到2π之间。）这一点在下图4.17中得到了体现。
- en: '![PIC](img/file421.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file421.png)'
- en: 'Figure 4.17: Orientation of two vectors in the plane'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.17：平面中两个向量的方向性
- en: Overall,
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，
- en: area(A(E)) = |detA|area(E)
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: area(A(E)) = |detA|area(E)
- en: (4.10)
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: (4.10)
- en: holds, where E ⊆ℝ² is a planar object, and
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 成立，其中E ⊆ℝ²是一个平面对象，且
- en: '![A (E) = {Ax : x ∈ E } ](img/file424.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![A (E) = {Ax : x ∈ E } ](img/file424.png)'
- en: is the image of E under the transformation A.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 是变换A下E的像。
- en: Even though we have only shown ([5.4.1](#)) in two dimensions, this holds in
    general. (Although we don’t know how to define the determinant there yet.)
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们只展示了二维空间中的([5.4.1](#))，但这在一般情况下是成立的。（尽管我们尚未知道如何在其他维度定义行列式。）
- en: So, if e[1] and e[2] is a basis on the plane, equations ([5.4.1](#)) and ([5.4.1](#))
    tell us that the determinant in two dimensions equals to
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果e[1]和e[2]是平面上的一组基，方程式([5.4.1](#))和([5.4.1](#))告诉我们二维空间中的行列式等于
- en: '![det A = orientation(Ae ,Ae )× area(Ae ,Ae ) 1 2 1 2 ](img/file425.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![det A = orientation(Ae ,Ae )× area(Ae ,Ae ) 1 2 1 2 ](img/file425.png)'
- en: Based on the example of the Euclidean plane, we have built enough geometric
    intuition on understanding how linear transformations distort volume and change
    the orientation of the space. These are described by the concept of determinants,
    which we have defined in the special case ([5.4.1](#)). We are going to move on
    to study the concept in its full generality.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 基于欧几里得平面的示例，我们已经建立了足够的几何直觉来理解线性变换如何扭曲体积并改变空间的方向。这些是通过行列式的概念来描述的，我们已经在特殊情况下([5.4.1](#))定义了行列式。接下来，我们将继续研究行列式的完整一般性概念。
- en: To introduce the formal definition of the determinant, we will take a route
    that is different from the usual. Most commonly, the determinant of a linear transformation
    A is defined straight away with a complicated formula, then all of its geometric
    properties are shown.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 为了引入行列式的正式定义，我们将采用不同于常规的路径。最常见的做法是直接用一个复杂的公式定义线性变换A的行列式，然后展示其所有几何性质。
- en: Instead of this, we will deduce the determinant formula by generalizing the
    geometric notion we have learned in the previous section. Here, we are roughly
    going to follow the outline of Linear Algebra and Its Applications by Peter D.
    Lax.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 与其如此，我们将通过推广我们在前一节学到的几何概念来推导行列式公式。在这里，我们大致按照Peter D. Lax的《线性代数及其应用》的大纲进行。
- en: We set the foundations by introducing some key notations. Let
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过引入一些关键符号奠定了基础。设
- en: '![A = (ai,j)ni,j=1 ∈ ℝn ×n ](img/file426.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![A = (ai,j)ni,j=1 ∈ ℝn ×n ](img/file426.png)'
- en: be a matrix with columns a[1],…,a[n]. When we introduced the notion of matrices
    as linear transformations in Section [4.1.1](ch010.xhtml#linear-transformations-and-matrices)
    , we saw that the i-th column is the image of the i-th basis vector. For simplicity,
    let’s assume that e[1],e[2],…,e[n] is the standard orthonormal basis, that is,
    e[i] is the vector whose i-th coordinate is 1 and the rest is 0\. Thus, Ae[i]
    = a[i].
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 设矩阵为具有列a[1],…,a[n]的矩阵。当我们在[4.1.1节](ch010.xhtml#linear-transformations-and-matrices)引入矩阵作为线性变换的概念时，我们看到第i列是第i个基向量的像。为了简便起见，假设e[1],e[2],…,e[n]是标准正交归一基，即e[i]是第i个坐标为1，其余坐标为0的向量。因此，Ae[i]
    = a[i]。
- en: During our explorations in the Euclidean plane Section [4.3](ch010.xhtml#linear-transformations-in-the-euclidean-plane),
    we have seen that the determinant is the orientation of the images of basis vectors,
    times the area of the parallelogram defined by them. Following this logic, we
    could define the determinant for n ×n matrices by
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们对欧几里得平面[4.3节](ch010.xhtml#linear-transformations-in-the-euclidean-plane)的探索中，我们已经看到行列式是基向量像的方向与它们所定义的平行四边形面积的乘积。按照这个逻辑，我们可以通过以下方式定义n×n矩阵的行列式
- en: '![det A = orientation(Ae1,...,Aen )× volume(Ae1, ...,Aen ) ](img/file427.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![det A = orientation(Ae1,...,Aen )× volume(Ae1, ...,Aen ) ](img/file427.png)'
- en: Two questions surface immediately. First, how do we define the orientation of
    multiple vectors in the n-dimensional space? Second, how can we even calculate
    the area?
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 很快出现了两个问题。首先，如何在 n 维空间中定义多个向量的方向？其次，我们如何计算面积？
- en: 'Instead of finding the answers for these questions, we are going to add a twist
    into the story: first, we’ll find a convenient formula for determinants, then
    use it to define orientation.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不是要找到这些问题的答案，而是要给故事增加一点曲折：首先，我们将找到一个方便的行列式公式，然后用它来定义方向。
- en: 4.4.2 The multi-linearity of determinants
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.2 行列式的多线性
- en: To make the relation between the determinant and the columns of the matrix a[i]
    = Ae[i] more explicit, we’ll write
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更明确地表示行列式与矩阵列 a[i] = Ae[i] 之间的关系，我们将写作
- en: '![det A = det(a1,...,an ). ](img/file428.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![det A = det(a1,...,an ). ](img/file428.png)'
- en: 'Thinking about determinants this way, det is just a function of multiple variables:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个角度思考行列式，det 只是多个变量的一个函数：
- en: '![det : ℝn × ⋅⋅⋅× ℝn → ℝ. ◟-----◝◜----◞ n times ](img/file429.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![det : ℝn × ⋅⋅⋅× ℝn → ℝ. ◟-----◝◜----◞ n times ](img/file429.png)'
- en: 'Good news: det(a[1],…,a[n]) is linear in each variable. That is,'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是：det(a[1],…,a[n]) 在每个变量上都是线性的。也就是说，
- en: '![det(a1,...,αai+ βbi,...an) = α det(a1,...,ai,...an )+β det(a1,...,bi,...an)
    ](img/file430.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![det(a1,...,αai+ βbi,...an) = α det(a1,...,ai,...an )+β det(a1,...,bi,...an)
    ](img/file430.png)'
- en: holds. We are not going to prove this, but as the determinant represents the
    signed volume, you can convince yourself by checking out Figure 4.18.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 这是成立的。我们不会证明这一点，但由于行列式代表的是带符号的体积，你可以通过查看图 4.18 来自我验证。
- en: '![PIC](img/file431.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file431.png)'
- en: 'Figure 4.18: The multilinearity of det(a[1],a[2])'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.18：det(a[1],a[2]) 的多线性
- en: A consequence of linearity is that we can express the determinant as a linear
    combination of determinants for the standard basis vectors e[1],…,e[n]. For instance,
    consider the following. Since
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 线性性的一个结果是，我们可以将行列式表示为标准基向量 e[1],…,e[n] 的行列式的线性组合。例如，考虑以下内容。因为
- en: '![ n Ae = a = ∑ a e, 1 1 i,1 i i=1 ](img/file432.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![ n Ae = a = ∑ a e, 1 1 i,1 i i=1 ](img/file432.png)'
- en: we have
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到
- en: '![ n ∑ det(a1,a2,...,an) = ai,1 det(ei,a2,...,an). i=1 ](img/file433.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![ n ∑ det(a1,a2,...,an) = ai,1 det(ei,a2,...,an). i=1 ](img/file433.png)'
- en: Going one step further and using that
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 再进一步，利用
- en: '![ ∑n a2 = aj,2ej, j=1 ](img/file434.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑n a2 = aj,2ej, j=1 ](img/file434.png)'
- en: we start noticing a pattern. With the linearity, we have
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始注意到一个规律。借助线性性，我们得到
- en: det(a[1], a[2],…, a[n]) = ∑ [i=1]^n ∑ [j=1]^n a[i,1] a[j,2] det(e[i], e[j],
    a[3],…, a[n]).
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: det(a[1], a[2],…, a[n]) = ∑ [i=1]^n ∑ [j=1]^n a[i,1] a[j,2] det(e[i], e[j],
    a[3],…, a[n])。
- en: (4.11)
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: (4.11)
- en: We can see that the row indices in the coefficients a[i,1]a[j,2] match the indices
    of e[k]-s in det(e[i],e[j],a[3],…,a[n]). In the general case, this pattern can
    be formalized in terms of permutations; that is, orderings of the set {1,2,…,n}.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，系数 a[i,1]a[j,2] 中的行索引与 det(e[i],e[j],a[3],…,a[n]) 中的 e[k] 的索引相匹配。在一般情况下，这个模式可以通过置换来形式化；即，{1,2,…,n}
    集合的排列。
- en: You can imagine a permutation as a function σ mapping {1,2,…,n} to itself in
    a way that for every j ∈{1,2,…,n}, there is exactly one i ∈{1,2,…,n} with σ(i)
    = j. In other words, you take every integer between 1 and n, and putting them
    in an order. The set of all possible permutations on {1,2,…,n} is denoted by S[n].
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将置换想象成一个函数 σ，它将 {1,2,…,n} 映射到自身，使得对于每个 j ∈{1,2,…,n}，都有一个 i ∈{1,2,…,n}，使得
    σ(i) = j。换句话说，你把从 1 到 n 的每个整数按某种顺序排列。{1,2,…,n} 上的所有可能置换的集合用 S[n] 表示。
- en: Continuing ([5.4.2](#)) and further expanding the determinant of A, we have
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 继续 ([5.4.2](#)) 并进一步展开 A 的行列式，我们得到
- en: '![ ∑ ∏n det(a1,...,an) = [ aσ(i),i]det(eσ(1),...,eσ(n)). σ∈Sn i=1 ](img/file435.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑ ∏n det(a1,...,an) = [ aσ(i),i]det(eσ(1),...,eσ(n)). σ∈Sn i=1 ](img/file435.png)'
- en: This formula is not the easiest one to understand. You can think about each
    term ∏ [i=1]^na[σ(i),i] as placing n chess rooks on an n×n board such that none
    of them can capture each other.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式并不是最容易理解的。你可以把每一项 ∏ [i=1]^n a[σ(i),i] 想象成把 n 个棋子放置在一个 n×n 的棋盘上，使得它们互不攻击。
- en: '![PIC](img/file436.png) Figure 4.19: The anatomy of the term a[σ(1)1]⋅⋅⋅a[σ(n)n]'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '![PIC](img/file436.png) 图 4.19：项 a[σ(1)1]⋅⋅⋅a[σ(n)n] 的解剖'
- en: The formula
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 公式
- en: '![∑ [∏n ] aσ(i),i det(eσ(1),...,e σ(n)) σ∈Sn i=1 ](img/file438.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![∑ [∏n ] aσ(i),i det(eσ(1),...,e σ(n)) σ∈Sn i=1 ](img/file438.png)'
- en: combines all the possible ways we can do this.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 结合了我们可以这样做的所有可能方式。
- en: 'There is only one thing left: calculating det(e[σ(1)],…,e[σ(n)]).'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 只剩下一件事：计算 det(e[σ(1)],…,e[σ(n)])。
- en: Remember when we discussed the combination of reflections and rotations in the
    Euclidean plane (Section [4.3.4](ch010.xhtml#reflection))? The transformation
    determined by e[i]→e[σ(i)] is similar to that. When talking about permutations,
    it’s good to know that each one can be obtained by switching two elements at a
    time. The number of transpositions - that is, permutations affecting two elements
    - in a permutation is called the sign of σ. In the context of our linear transformation
    e[i]→e[σ(i)], the number of transpositions in σ is the number of reflections required
    and sign(σ) is the orientation of (e[σ(1)],…,e[σ(n)]).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们在讨论欧几里得平面中的反射和旋转的组合时（第[4.3.4](ch010.xhtml#reflection)节）吗？由 e[i]→e[σ(i)]
    确定的变换与此类似。当谈到排列时，了解每个排列都可以通过一次交换两个元素得到是很有用的。在排列中，交换两个元素的次数——也就是影响两个元素的排列——被称为
    σ 的符号。在我们讨论的线性变换 e[i]→e[σ(i)] 中，σ 的交换次数就是所需反射的次数，sign(σ) 是 (e[σ(1)],…,e[σ(n)])
    的方向。
- en: Thus, with these, we can finally give a formal definition for determinants and
    the orientation.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，借助这些，我们终于可以为行列式和方向给出一个正式的定义。
- en: Definition 20\. (Determinants and orientation)
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 20. （行列式与方向）
- en: Let A ∈ℝ^(n×n) be an arbitrary matrix and let a[i] ∈ℝ^n be its i-th column.
    The determinant of A is defined by
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 设 A ∈ℝ^(n×n) 为任意矩阵，a[i] ∈ℝ^n 为它的第 i 列。A 的行列式定义为
- en: detA = det( a[1],…, a[n]) = ∑ [σ∈S[n]] sign(σ) [ ∏ [i=1]^n a [σ(i),i] ],
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: detA = det( a[1],…, a[n]) = ∑ [σ∈S[n]] sign(σ) [ ∏ [i=1]^n a [σ(i),i] ],
- en: (4.12)
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: (4.12)
- en: and the orientation of the vectors a[1],…,a[n] is
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 以及向量 a[1],…,a[n] 的方向是
- en: '![orientation(a1,...,an ) := sign(detA ). ](img/file443.png)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![orientation(a1,...,an ) := sign(detA ). ](img/file443.png)'
- en: 'When the det notation is not convenient, we denote determinants by putting
    the elements of the matrix inside a big absolute value sign:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 当 det 表示法不方便时，我们通过将矩阵的元素放入一个大的绝对值符号中来表示行列式：
- en: '![ || || ||a1,1 a1,2 ... a1,n|| |a2,1 a2,2 ... a2,n| detA = || . . . . ||.
    || .. .. .. .. || || || an,1 an,2 ... an,n ](img/file444.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![ || || ||a1,1 a1,2 ... a1,n|| |a2,1 a2,2 ... a2,n| detA = || . . . . ||.
    || .. .. .. .. || || || an,1 an,2 ... an,n ](img/file444.png)'
- en: When I was a young math student, the determinant formula ([4.12](ch010.xhtml#x1-81006r20))
    was presented as-is in my first linear algebra class. Without explaining the connection
    to volume and orientation, it took me years to properly understand it. I still
    think that the determinant is one of the most complex concepts in linear algebra,
    especially when presented without a geometric motivation for the definition.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 当我还是一名年轻的数学学生时，行列式公式（[4.12](ch010.xhtml#x1-81006r20)）是我在第一节线性代数课上直接看到的。没有解释它与体积和方向的联系，我花了几年时间才真正理解它。我依然认为，行列式是线性代数中最复杂的概念之一，尤其是在没有几何动机的情况下进行定义时。
- en: 'Now that you have a basic understanding of the determinant, you might ask:
    how can we calculate it in practice? Summing over the set of all permutations
    and calculating their sign is not an easy operation from a computational perspective.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经对行列式有了基本的理解，你可能会问：我们如何在实践中计算行列式呢？对所有排列求和并计算它们的符号，从计算角度来看并不是一项简单的操作。
- en: 'Good news: there is a recursive formula for the determinant. Bad news: for
    an n×n matrix, it involves n pieces of (n − 1) × (n − 1) matrices. Still, it is
    a big step from the permutation formula. Let’s see it!'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是：行列式有一个递归公式。坏消息是：对于一个 n×n 的矩阵，它涉及 n 个 (n − 1) × (n − 1) 的矩阵。尽管如此，相比于排列公式，这已经是一个很大的进步了。让我们来看看！
- en: Theorem 21\. (Recursive formula for determinants)
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 21. （行列式的递归公式）
- en: Let A ∈ℝ^(n×n) be an arbitrary square matrix. Then
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 设 A ∈ℝ^(n×n) 为任意方阵。那么
- en: detA = ∑ [j=1]^n (−1)^(j+1) a [1,j] detA[1,j],
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: detA = ∑ [j=1]^n (−1)^(j+1) a [1,j] detA[1,j],
- en: '4.13'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '4.13'
- en: where A[i,j] is the (n − 1) × (n − 1) matrix obtained from A by removing its
    i-th row and j-th column.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 A[i,j] 是从 A 中通过去除其第 i 行和第 j 列得到的 (n − 1) × (n − 1) 矩阵。
- en: 'Instead of a proof, we are going to provide an example to demonstrate the formula.
    For 3 × 3 matrices, this is how it looks:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不提供证明，而是通过一个例子来演示这个公式。对于 3 × 3 的矩阵，它看起来是这样的：
- en: '![| | ||a b c|| || || || || || || || || ||e f|| ||d f|| ||d e|| ||d e f||=
    a ||h i||− b||g i||+ c||g h||. |g h i| ](img/file445.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![| | ||a b c|| || || || || || || || || ||e f|| ||d f|| ||d e|| ||d e f||=
    a ||h i||− b||g i||+ c||g h||. |g h i| ](img/file445.png)'
- en: Now that we have both the geometric intuition and the recursive formula, let’s
    see the most important properties of the determinants!
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们既有几何直觉，又有递归公式，让我们来看看行列式的最重要的性质！
- en: 4.4.3 Fundamental properties of the determinants
  id: totrans-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.3 行列式的基本性质
- en: When working with determinants, we prefer to create basic building blocks and
    rules for combining them. (As we have seen with this pattern so many times, even
    when deducing the ([4.12](ch010.xhtml#x1-81006r20)).) These rules are manifested
    by the fundamental properties of determinants, which we will discuss now.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算行列式时，我们更倾向于构造基本的构建模块和组合规则。（正如我们多次见到的模式，即使在推导 ([4.12](ch010.xhtml#x1-81006r20))
    时也是如此。）这些规则由行列式的基本性质体现，我们现在将讨论这些基本性质。
- en: The first property is concerned with the relation of composition and the determinant.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个性质涉及到复合与行列式的关系。
- en: Theorem 22\. (The product of determinants)
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 22\. （行列式的乘积）
- en: ∈ℝ^(n×n) be two matrices. Then
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: ∈ℝ^(n×n) 是两个矩阵。那么
- en: detAB = detAdetB.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: detAB = detAdetB。
- en: (4.14)
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: （4.14）
- en: The equation ([4.14](ch010.xhtml#x1-82002r22)) is called the determinant product
    rule, and its proof involves some heavy computations based on the formulas ([4.12](ch010.xhtml#x1-81006r20))
    and ([4.13](ch010.xhtml#x1-81009r21)). Instead of providing a fully fleshed-out
    proof, I’ll give an intuitive explanation. After all, we want to build algorithms
    using mathematics, not building mathematics.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式 ([4.14](ch010.xhtml#x1-82002r22)) 被称为行列式乘积法则，它的证明涉及一些基于公式 ([4.12](ch010.xhtml#x1-81006r20))
    和 ([4.13](ch010.xhtml#x1-81009r21)) 的复杂计算。我们不提供完整的证明，而是给出一个直观的解释。毕竟，我们希望用数学构建算法，而不是构建数学。
- en: So, the explanation of detAB = detAdetB is quite simple. If we think about the
    matrices A,B ∈ℝ^(n×n) as linear transformations, we have just seen that detA and
    detB determine how they scale the unit cube.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，detAB = detAdetB 的解释非常简单。如果我们把矩阵 A,B ∈ℝ^(n×n) 看作是线性变换，我们刚刚看到 detA 和 detB
    决定了它们如何缩放单位立方体。
- en: Since the composition of these linear transformations is the matrix product
    AB, the linear transformation AB scales the unit cube to a parallelepiped with
    signed volume detAdetB. (Because applying AB is the same as applying B first,
    then applying A on the result.)
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些线性变换的组合是矩阵乘积 AB，线性变换 AB 将单位立方体缩放为带符号体积 detAdetB 的平行六面体。（因为应用 AB 相当于先应用 B，再在结果上应用
    A。）
- en: Thus, by our understanding of the determinant, as the scaling factor of AB is
    also detAB, ([4.14](ch010.xhtml#x1-82002r22)) holds.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过我们对行列式的理解，由于 AB 的缩放因子也是 detAB，（[4.14](ch010.xhtml#x1-82002r22)）成立。
- en: We can do the actual proof of this, for example, by induction based on the recursive
    formula ([4.13](ch010.xhtml#x1-81009r21)), leading to a long and involved calculation.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过递归公式 ([4.13](ch010.xhtml#x1-81009r21)) 进行实际证明，从而得到一个长而复杂的计算过程。
- en: An immediate corollary of the product rule is a special relation between the
    determinants of a matrix and its inverse.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 乘积法则的一个直接推论是矩阵的行列式与其逆矩阵之间的特殊关系。
- en: Theorem 23\.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 23\。
- en: Let A ∈ℝ^(n×n) be an arbitrary invertible matrix. Then
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 设 A ∈ℝ^(n×n) 是一个任意可逆矩阵。那么
- en: '![detA −1 = (det A)−1\. ](img/file446.png)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![detA −1 = (det A)−1\. ](img/file446.png)'
- en: Proof. Using the product rule, we have
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。使用乘积法则，我们有
- en: '![1 = detI = detAA −1 = (det A)(detA −1), ](img/file447.png)'
  id: totrans-382
  prefs: []
  type: TYPE_IMG
  zh: '![1 = detI = detAA −1 = (det A)(detA −1), ](img/file447.png)'
- en: from which the theorem follows.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 从而得出定理。
- en: Because of this, we can also conclude that the determinant is preserved by the
    similarity relation.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个原因，我们也可以得出结论，行列式在相似关系下保持不变。
- en: Theorem 24\.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 24\。
- en: Let A,B ∈ ℝ^(n×n) be two similar matrices with B = T^(−1)AT for some T ∈ℝ^(n×n).
    Then
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 设 A,B ∈ ℝ^(n×n) 是两个相似矩阵，且 B = T^(−1)AT，其中 T ∈ℝ^(n×n)。则
- en: '![detA = detB. ](img/file448.png)'
  id: totrans-387
  prefs: []
  type: TYPE_IMG
  zh: '![detA = detB. ](img/file448.png)'
- en: Proof. This simply follows from
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。这个结论直接跟随于
- en: '![ −1 detB = det T AT = det T−1 detA detT = det A, ](img/file449.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![ −1 detB = det T AT = det T−1 detA detT = det A, ](img/file449.png)'
- en: which is what we had to show.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们需要证明的。
- en: 'Another important consequence is that the determinant is independent of the
    basis the matrix is in. If A : U →U is a linear transformation, and P = {p[1],…,p[n]}
    and R = {r[1],…,r[n]} are two bases of U, then we know that the matrices of the
    transformation are related (Section [4.2.1](ch010.xhtml#the-transformation-matrix))
    by'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '另一个重要的结论是行列式与矩阵所处的基底无关。如果 A : U →U 是一个线性变换，且 P = {p[1],…,p[n]} 和 R = {r[1],…,r[n]}
    是 U 的两个基底，那么我们知道，变换的矩阵（第 [4.2.1](ch010.xhtml#the-transformation-matrix) 节）之间的关系为'
- en: '![AP = T−1ART, ](img/file450.png)'
  id: totrans-392
  prefs: []
  type: TYPE_IMG
  zh: '![AP = T−1ART, ](img/file450.png)'
- en: where A[S] is the matrix of the transformation A in a basis S and T ∈ℝ^(n×n)
    is the change of basis matrix (Section [4.2.1](ch010.xhtml#the-transformation-matrix)).
    The previous theorem implies that detA[P] = detA[R]. Thus, the determinant is
    properly defined for linear transformations, not just matrices!
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 其中A[S]是变换A在基S下的矩阵，T ∈ℝ^(n×n)是基变换矩阵（第[4.2.1](ch010.xhtml#the-transformation-matrix)节）。前面的定理意味着detA[P]
    = detA[R]。因此，行列式不仅仅是矩阵的定义，它也适用于线性变换！
- en: 'There is an essential duality relation regarding determinants: you can swap
    the rows and columns of a matrix, keeping all determinant-related identities true.'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 关于行列式，有一个重要的对偶关系：你可以交换矩阵的行和列，同时保持所有与行列式相关的恒等式成立。
- en: Theorem 25\.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 25\。
- en: Let A ∈ℝ^(n×n) be an arbitrary matrix. Then
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 设A ∈ℝ^(n×n)是一个任意矩阵。那么
- en: '![detA = detAT . ](img/file451.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![detA = detAT . ](img/file451.png)'
- en: Proof. Suppose that A = (a[i,j])[i,j=1]^n. Let’s denote the elements of its
    transpose by a[i,j]^t = a[j,i]. According to ([4.12](ch010.xhtml#x1-81006r20)),
    we have
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。假设A = (a[i,j])[i,j=1]^n。我们用a[i,j]^t = a[j,i]表示其转置矩阵的元素。根据([4.12](ch010.xhtml#x1-81006r20))，我们有
- en: '![ T ∑ ∏n t detA = sign (σ ) aσ(i),i σ∈Sn i=1 ∑ ∏n = sign (σ ) ai,σ(i). σ∈Sn
    i=1 ](img/file452.png)'
  id: totrans-399
  prefs: []
  type: TYPE_IMG
  zh: '![ T ∑ ∏n t detA = sign (σ ) aσ(i),i σ∈Sn i=1 ∑ ∏n = sign (σ ) ai,σ(i). σ∈Sn
    i=1 ](img/file452.png)'
- en: Now comes the trick. Since the product ∏ [i=1]^na[i,σ(i)] iterates through all
    i-s, and the order of the terms doesn’t matter, we might as well order the terms
    as i = σ^(−1)(1),…,σ^(−1)(n). Since
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来一个技巧。由于积∏ [i=1]^n a[i,σ(i)]遍历所有的i，并且项的顺序不重要，我们可以将项的顺序排列为i = σ^(−1)(1),…,σ^(−1)(n)。由于
- en: '![sign(σ −1) = sign(σ), ](img/file453.png)'
  id: totrans-401
  prefs: []
  type: TYPE_IMG
  zh: '![sign(σ −1) = sign(σ), ](img/file453.png)'
- en: by continuing the above calculation, we have
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 继续上述计算，我们得到
- en: '![ n n ∑ sign(σ)∏ a = ∑ sign(σ−1)∏ a . i,σ(i) σ− 1(j),j σ∈Sn i=1 σ∈Sn j=1 ](img/file454.png)'
  id: totrans-403
  prefs: []
  type: TYPE_IMG
  zh: '![ n n ∑ sign(σ)∏ a = ∑ sign(σ−1)∏ a . i,σ(i) σ− 1(j),j σ∈Sn i=1 σ∈Sn j=1 ](img/file454.png)'
- en: Because every permutation is invertible and σ→σ^(−1) is a bijection, summing
    over σ ∈S[n] is the same as summing over σ^(−1) ∈S[n].
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 因为每个置换都是可逆的，并且σ→σ^(−1)是一个双射，因此对σ ∈S[n]求和与对σ^(−1) ∈S[n]求和是一样的。
- en: Combining all of the above, we obtain that
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 综合上述所有内容，我们得到
- en: '![ ∑ ∏n detA = sign(σ−1) aj,σ−1(j) σ∈Sn j=1 n = ∑ sign(σ)∏ a σ(j),j σ∈Sn j=1
    = detAT . ](img/file456.png)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑ ∏n detA = sign(σ−1) aj,σ−1(j) σ∈Sn j=1 n = ∑ sign(σ)∏ a σ(j),j σ∈Sn j=1
    = detAT . ](img/file456.png)'
- en: which is what we had to show.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们需要证明的内容。
- en: Theorem 26\.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 26\。
- en: Let A ∈ℝ^(n×n) be an arbitrary matrix and let A^(i,j) denote the matrix which
    can be obtained by swapping the i-th and j-th column of A. Then
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 设A ∈ℝ^(n×n)是一个任意矩阵，设A^(i,j)表示通过交换A的第i列和第j列得到的矩阵。那么
- en: '![detAi,j = − detA, ](img/file457.png)'
  id: totrans-410
  prefs: []
  type: TYPE_IMG
  zh: '![detAi,j = − detA, ](img/file457.png)'
- en: or in other words, swapping any two columns of A will change the sign of the
    determinant. Similarly, swapping two rows also changes the sign of the determinant.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，交换A的任何两列会改变行列式的符号。类似地，交换两行也会改变行列式的符号。
- en: Proof. This follows from a clever application of ([4.14](ch010.xhtml#x1-82002r22)),
    noticing that A^(i,j) = AI^(i,j), where I^(i,j) is obtained from the identity
    matrix by swapping its i-th and j-th column. detI^(i,j) is a determinant of the
    form det(e[σ(1)],…,e[σ(n)]), where σ is a permutation simply swapping i and j.
    (That is, σ is a transposition.) Thus,
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。这个结论可以通过巧妙应用([4.14](ch010.xhtml#x1-82002r22))得到，注意到A^(i,j) = AI^(i,j)，其中I^(i,j)是通过交换单位矩阵的第i列和第j列得到的。detI^(i,j)是形如det(e[σ(1)],…,e[σ(n)])的行列式，其中σ是一个简单交换i和j的置换。（即σ是一个置换）。因此，
- en: '![ i,j i,j detA = detA det I = − detA, ](img/file458.png)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
  zh: '![ i,j i,j detA = detA det I = − detA, ](img/file458.png)'
- en: which is what we had to show.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们需要证明的内容。
- en: Regarding swapping rows, we can apply the previous result because transposing
    a matrix preserves the determinant.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 关于交换行，我们可以应用前面的结果，因为转置矩阵保持行列式不变。
- en: As a consequence, matrices with two matching rows have a zero determinant.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，具有两个相同的行的矩阵行列式为零。
- en: Theorem 27\.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 27\。
- en: Let ![A ∈ ℝn ×n ](img/file459.png) be a matrix that has two identical rows or
    columns. Then ![detA = 0 ](img/file460.png).
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 设![A ∈ ℝn ×n ](img/file459.png)是一个具有两个相同的行或列的矩阵。那么![detA = 0 ](img/file460.png)。
- en: Proof. Suppose that the ![i ](img/file461.png)-th and the ![j ](img/file462.png)-th
    columns are matching. Since the two columns are equal, ![detAi,j = det A ](img/file463.png).
    However, applying the previous theorem (which states that swapping two columns
    changes the sign of the determinant), we obtain ![ i,j detA = − detA ](img/file464.png).
    This can only be true if ![detA = 0 ](img/file465.png).
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。假设 ![i ](img/file461.png)-th 和 ![j ](img/file462.png)-th 列是相同的。由于这两列相等，![detAi,j
    = det A ](img/file463.png)。然而，应用之前的定理（即交换两列会改变行列式的符号），我们得到 ![ i,j detA = − detA
    ](img/file464.png)。只有当 ![detA = 0 ](img/file465.png) 时，这才成立。
- en: Again, transposing the matrix gives the statement for rows.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，转置矩阵给出了行的结论。
- en: As yet another consequence, we obtain an essential connection between linearly
    dependent vector systems and determinants.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个结果，我们得到线性相关的向量系统与行列式之间的重要联系。
- en: Theorem 28\.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 28。
- en: Let ![A ∈ ℝn×n ](img/file466.png) be a matrix. Then its columns are linearly
    dependent if and only if ![detA = 0 ](img/file467.png). Similarly, the rows of
    ![A ](img/file468.png) are linearly dependent if and only if ![detA = 0 ](img/file469.png).
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 设 ![A ∈ ℝn×n ](img/file466.png) 是一个矩阵。则其列是线性相关的，当且仅当 ![detA = 0 ](img/file467.png)。类似地，矩阵
    ![A ](img/file468.png) 的行是线性相关的，当且仅当 ![detA = 0 ](img/file469.png)。
- en: Proof. (i) First, we are going to show that linearly dependent columns (or rows)
    imply detA = 0\. As usual, let’s denote the columns of A as a[1],…,a[n] and for
    the sake of simplicity, assume that
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。(i) 首先，我们将证明线性相关的列（或行）意味着 detA = 0。像往常一样，设 A 的列为 a[1],…,a[n]，为了简便起见，假设
- en: '![ n ∑ a1 = αiai. i=2 ](img/file470.png)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![ n ∑ a1 = αiai. i=2 ](img/file470.png)'
- en: Since the determinant is a linear function of the columns, we have
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 由于行列式是列的线性函数，我们得到
- en: '![ n ∑ det(a1,a2,...,an) = αidet(ai,a2,...,an ). i=2 ](img/file471.png)'
  id: totrans-427
  prefs: []
  type: TYPE_IMG
  zh: '![ n ∑ det(a1,a2,...,an) = αidet(ai,a2,...,an ). i=2 ](img/file471.png)'
- en: Because of the previous theorem, all terms det(a[i],a[2],…,a[n]) are zero, implying
    detA = 0, which is what we had to show. If the rows are linearly dependent, we
    apply the above to obtain that detA = detA^T = 0.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 根据之前的定理，所有项 det(a[i],a[2],…,a[n]) 都为零，这意味着 detA = 0，这就是我们需要证明的。如果行是线性相关的，我们可以应用上述内容得到
    detA = detA^T = 0。
- en: Now, let’s show that detA = 0 means linearly dependent columns. Instead of the
    exact proof, which is rather involved, we should have an intuitive explanation
    instead.
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们证明 detA = 0 意味着列是线性相关的。与其提供一个非常复杂的精确证明，不如给出一个直观的解释。
- en: Recall that the determinant is orientation times volume of the parallelepiped
    given by the columns. Since the orientation is ±1, detA implies that the volume
    of the parallelepiped is 0\. This can only happen if the n columns lie in an n
    − 1-dimensional subspace, meaning that they are linearly dependent.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾行列式是由列向量所给出的平行六面体的方向和体积之积。由于方向是 ±1，detA 意味着平行六面体的体积为 0。只有当 n 列向量位于一个 n − 1
    维的子空间中时，这才可能发生，也就是说，它们是线性相关的。
- en: We can immediately apply this to get the following result.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以立即应用这个结果得到以下结论。
- en: Corollary 2\.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 推论 2。
- en: Let A ∈ ℝ^(n×n) be a matrix with a constant zero column (or row). Then detA
    = 0.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 设 A ∈ ℝ^(n×n) 为一个矩阵，其中有一列（或一行）是常数零列（或零行）。则 detA = 0。
- en: As the determinant is the signed volume of the basis vectors’ image, it can
    be zero in certain cases. These transformations are rather special. When can it
    happen? Let’s go back to the Euclidean plane to build some intuition.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 由于行列式是基向量像的带符号体积，它在某些情况下可以为零。这些变换是非常特殊的。什么时候会发生这种情况呢？让我们回到欧几里得平面，构建一些直观的理解。
- en: There, we have
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们得到
- en: '![|| || ||x1 y1|| ||x y || = x1y2 − x2y1 = 0, 2 2 ](img/file472.png)'
  id: totrans-436
  prefs: []
  type: TYPE_IMG
  zh: '![|| || ||x1 y1|| ||x y || = x1y2 − x2y1 = 0, 2 2 ](img/file472.png)'
- en: 'or in other words, ![x1 y1-](img/file473.png) = ![x2 y2-](img/file474.png).
    There is one more interpretation of this: the vector (y[1],y[2]) is a scalar multiple
    of (x[1],x[2]); that is, they are colinear, meaning that they lie on the same
    line through the origin. Thinking in terms of linear transformations, this means
    that the images of e[1] and e[2] lie on a subspace of ℝ². As we shall see next,
    this is closely connected with the invertibility of the transformation.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 或换句话说，![x1 y1-](img/file473.png) = ![x2 y2-](img/file474.png)。还有一种解释：向量 (y[1],y[2])
    是 (x[1],x[2]) 的标量倍；也就是说，它们是共线的，意味着它们位于通过原点的同一条直线上。从线性变换的角度来看，这意味着 e[1] 和 e[2]
    的像位于 ℝ² 的一个子空间中。正如我们接下来将看到的，这与变换的可逆性密切相关。
- en: Theorem 29\. (Invertibility and the determinants) The linear transformation
    ![A ∈ ℝn×n ](img/file475.png) is invertible if and only if ![detA ⁄= 0 ](img/file476.png).
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 29.（可逆性与行列式）线性变换![A ∈ ℝn×n ](img/file475.png)是可逆的，当且仅当![detA ⁄= 0 ](img/file476.png)。
- en: Proof. When we introduced the concept of invertibility (Definition [17](ch010.xhtml#x1-69002r17)),
    we saw that ![A ](img/file477.png) is invertible if and only if its columns ![a1,...,an
    ](img/file478.png) form a basis. Thus, they are linearly independent.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。当我们引入可逆性的概念（定义[17](ch010.xhtml#x1-69002r17)）时，我们看到！[A ](img/file477.png)只有在其列！[a1,...,an
    ](img/file478.png)构成基时才可逆。因此，它们是线性独立的。
- en: Since linear independence (Definition [3](ch007.xhtml#x1-23002r3)) of columns
    is equivalent to a nonzero determinant, the result follows.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 由于列的线性独立性（定义[3](ch007.xhtml#x1-23002r3)）等同于行列式非零，因此结果成立。
- en: 4.5 Summary
  id: totrans-441
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 小结
- en: So, do your eyes hurt after finally using them for the first time? Mine sure
    did when I first learned about matrices as linear transformations. Here’s a part
    where the abstract viewpoint pays off for the first time, and trust me, it’ll
    pay even more dividends later.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你的眼睛在第一次使用它们之后会疼吗？我第一次学习矩阵作为线性变换时肯定是疼的。这是抽象观点第一次显示出其价值的地方，相信我，后来它将带来更多的回报。
- en: Let’s recap this chapter quickly.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速回顾一下这一章。
- en: 'We’ve learned that besides a table of numbers, a matrix can represent linear
    transformations:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学到，除了数字表格，矩阵还可以表示线性变换：
- en: '![ ⌊ ⌋ ⌊ ⌋ ⌊ ∑m ⌋ a1,1 a1,2 ... a1,m x1 j=1a1,jxj || a a ... a || || x || ||
    ∑m a x || Ax = || 2,.1 2.,2 2,m. || || .2|| = || j=1.2,j j|| , |⌈ .. .. ... ..
    |⌉ |⌈ .. |⌉ |⌈ .. |⌉ ∑m an,1 an,2 ... an,m, xm j=1an,jxj ](img/file479.png)'
  id: totrans-445
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌊ ⌋ ⌊ ∑m ⌋ a1,1 a1,2 ... a1,m x1 j=1a1,jxj || a a ... a || || x || ||
    ∑m a x || Ax = || 2,.1 2.,2 2,m. || || .2|| = || j=1.2,j j|| , |⌈ .. .. ... ..
    |⌉ |⌈ .. |⌉ |⌈ .. |⌉ ∑m an,1 an,2 ... an,m, xm j=1an,jxj ](img/file479.png)'
- en: where the columns of A describe the images of the basis vectors under the linear
    transformation x →Ax.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，A的列描述了基向量在线性变换x →Ax下的像。
- en: Why on Earth is this useful for us? Think of mathematics as a problem-solving
    tool. The crux of problem-solving is often finding the proper representation of
    our objects of interest. Looking at matrices as a way to transform data gives
    us the much-needed geometric perspective, opening up a whole new avenue of methods.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这对我们有用呢？把数学看作一种解决问题的工具。解决问题的关键往往是找到我们感兴趣的对象的合适表示。把矩阵看作是一种变换数据的方法，给我们提供了急需的几何视角，开启了一整套新的方法。
- en: When looking at matrices this way, we quickly understand why matrix multiplication
    is defined as it is. The definition
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式看矩阵，我们很快就能理解为什么矩阵乘法会按这种方式定义。定义是
- en: '![ ∑l n,m AB = ( ai,kbk,j)i,j=1 k=1 ](img/file480.png)'
  id: totrans-449
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑l n,m AB = ( ai,kbk,j)i,j=1 k=1 ](img/file480.png)'
- en: 'is daunting at first, but from the perspective of linear transformations, it’s
    all revealed to be a simple composition: first, we apply the transformation B,
    then A.'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 起初看起来令人畏惧，但从线性变换的角度来看，它都揭示出是一个简单的复合：首先应用变换B，然后是A。
- en: 'Be careful, though: linear transformations and matrices are not exactly the
    same, as the matrix representation depends on the underlying basis of our vector
    space. (See, I told you that bases are going to be useful.)'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 然而要小心：线性变换和矩阵并不完全相同，因为矩阵表示依赖于我们向量空间的基础（基）。(看吧，我早就告诉过你，基是有用的。)
- en: Matrices also possess an important quantity called determinants, originally
    defined by the mind-boggingly complex formula
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵还具有一个重要的量，叫做行列式，最初由复杂的公式定义
- en: '![ ∑ ∏n det(a1,...,an) = [ aσ(i),i]det(eσ(1),...,eσ(n)), σ∈Sn i=1 ](img/file481.png)'
  id: totrans-453
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑ ∏n det(a1,...,an) = [ aσ(i),i]det(eσ(1),...,eσ(n)), σ∈Sn i=1 ](img/file481.png)'
- en: but an investigation exploiting our newfound geometric perspective reveals that
    the determinant simply describes how much the linear transformation distorts the
    volume of the domain space, and how it changes the orientation of the basis vectors.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，通过利用我们新获得的几何视角的研究发现，行列式只是描述了线性变换如何扭曲领域空间的体积，以及它如何改变基向量的方向。
- en: For us machine learning practitioners, making the conceptual jump from matrices
    to linear transformations is the more interesting one. (As opposed to the theory,
    where we often learn about linear transformations first, matrices second.) For
    instance, this allows us to see a layer in a neural network as stretching, rotating,
    shearing, and potentially reflecting the feature space.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们这些机器学习的从业者来说，从矩阵到线性变换的概念跃迁是更有趣的（与理论学习相比，在理论中我们通常先学习线性变换，再学习矩阵）。 例如，这让我们能够将神经网络中的一层看作是对特征空间的拉伸、旋转、剪切，甚至可能是反射。
- en: 'In the next chapter, we’ll revisit matrices from a slightly different perspective:
    systems of equations. Of course, everything is connected, and we’ll end up where
    we started, looking at what we know from a higher perspective. This is because
    learning is a spiral, and we are ascending fast.'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将从一个略有不同的角度重新审视矩阵：方程组。 当然，一切都是相互联系的，我们最终会回到原点，从更高的视角看我们所知道的知识。 这是因为学习是一个螺旋过程，我们正在快速上升。
- en: 4.6 Problems
  id: totrans-457
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 问题
- en: Problem 1\. Show that if A ∈ℝ^(n×n) is an invertible matrix, then
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 1\. 证明如果A ∈ℝ^(n×n)是可逆矩阵，则
- en: '![ −1 T T −1 (A ) = (A ) . ](img/file482.png)'
  id: totrans-459
  prefs: []
  type: TYPE_IMG
  zh: '![ −1 T T −1 (A ) = (A ) . ](img/file482.png)'
- en: Problem 2\. Let R[α] be the two-dimensional rotation matrix defined by
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 2\. 设R[α]为二维旋转矩阵，由以下定义：
- en: '![ ⌊ ⌋ ⌈cosα − sinα ⌉ R α = sinα cosα . ](img/file483.png)'
  id: totrans-461
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌈cosα − sinα ⌉ R α = sinα cosα . ](img/file483.png)'
- en: Show that R[α]R[β] = R[α+β].
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 证明R[α]R[β] = R[α+β]。
- en: Problem 3\. Let A = (a[i,j])[i,j=1]^n ∈ℝ^(n×n) be a matrix and let D ∈ℝ^(n×n)
    be a diagonal matrix defined by
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 3\. 设A = (a[i,j])[i,j=1]^n ∈ℝ^(n×n)为矩阵，D ∈ℝ^(n×n)为对角矩阵，定义如下：
- en: '![ ⌊ ⌋ | d1 0 ... 0 | D = |⌈ 0 d2 ... 0 |⌉ , 0 0 ... dn ](img/file484.png)'
  id: totrans-464
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ | d1 0 ... 0 | D = |⌈ 0 d2 ... 0 |⌉ , 0 0 ... dn ](img/file484.png)'
- en: where all of its elements are zero outside the diagonal. Show that
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 其中所有元素在对角线外均为零。证明
- en: '![ ⌊ ⌋ d1a1,1 d2a1,2 ... dna1,n || || DA = || d1a2,1 d2a2,2 ... dna2,n || |⌈
    ... ... ... ... |⌉ d1an,1 d2an,2 ... dnan,n ](img/file485.png)'
  id: totrans-466
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ d1a1,1 d2a1,2 ... dna1,n || || DA = || d1a2,1 d2a2,2 ... dna2,n || |⌈
    ... ... ... ... |⌉ d1an,1 d2an,2 ... dnan,n ](img/file485.png)'
- en: and
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![ ⌊ ⌋ |d1a1,1 d1a1,2 ... d1a1,n| |d2a2,1 d2a2,2 ... d2a2,n| AD = || . . .
    . || . |⌈ .. .. .. .. |⌉ dnan,1 dnan,2 ... dnan,n ](img/file486.png)'
  id: totrans-468
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ |d1a1,1 d1a1,2 ... d1a1,n| |d2a2,1 d2a2,2 ... d2a2,n| AD = || . . .
    . || . |⌈ .. .. .. .. |⌉ dnan,1 dnan,2 ... dnan,n ](img/file486.png)'
- en: Problem 4\. Let ∥⋅∥ be a norm on ℝ^n, and let A ∈ℝ^(n×n) be an arbitrary matrix.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 4\. 设∥⋅∥为ℝ^n上的范数，A ∈ℝ^(n×n)为任意矩阵。
- en: Show that A is invertible if and only if the function
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 证明A是可逆的当且仅当该函数
- en: '![∥x∥∗ := ∥Ax ∥ ](img/file487.png)'
  id: totrans-471
  prefs: []
  type: TYPE_IMG
  zh: '![∥x∥∗ := ∥Ax ∥ ](img/file487.png)'
- en: is a norm on ℝ^n.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 是ℝ^n上的一个范数。
- en: 'Problem 5\. Let U be a normed space and f : U →U be a linear transformation.'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: '问题 5\. 设U是一个有范空间，f : U →U是一个线性变换。'
- en: If
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 如果
- en: '![∥x ∥∗ := ∥f(x)∥ ](img/file488.png)'
  id: totrans-475
  prefs: []
  type: TYPE_IMG
  zh: '![∥x ∥∗ := ∥f(x)∥ ](img/file488.png)'
- en: is a norm, is f necessarily invertible?
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 是一个范数，f是否一定可逆？
- en: 'Hint: Consider the vector space ℝ[x] with the norm'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：考虑向量空间ℝ[x]，其范数为
- en: '![ n n ∑ 2 1∕2 ∑ i ∥p∥ = ( pi) , p(x) = pix i=0 i=0 ](img/file489.png)'
  id: totrans-478
  prefs: []
  type: TYPE_IMG
  zh: '![ n n ∑ 2 1∕2 ∑ i ∥p∥ = ( pi) , p(x) = pix i=0 i=0 ](img/file489.png)'
- en: 'and the linear transformation f : p(x)→xp(x).'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: '以及线性变换f : p(x)→xp(x)。'
- en: Problem 6\. Let ⟨⋅,⋅,⟩ be an inner product on ℝ^n. Show that there is a matrix
    A ∈ℝ^(n×n) such that
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 6\. 设⟨⋅,⋅,⟩为ℝ^n上的内积。证明存在矩阵A ∈ℝ^(n×n)，使得
- en: '![⟨x,y ⟩ = xT Ay, x,y ∈ ℝn. ](img/file491.png)'
  id: totrans-481
  prefs: []
  type: TYPE_IMG
  zh: '![⟨x,y ⟩ = xT Ay, x,y ∈ ℝn. ](img/file491.png)'
- en: (Recall that we treat vectors x,y ∈ℝ^n as column vectors.)
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: （回想一下，我们将向量x, y ∈ℝ^n视为列向量。）
- en: Problem 7\. Let A ∈ℝ^(n×n) be a matrix. A is called positive definite if x^T
    Ax/span>0 for every nonzero x ∈ℝ^n.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 7\. 设A ∈ℝ^(n×n)为矩阵。如果x^T Ax/span>0对所有非零x ∈ℝ^n成立，则A称为正定矩阵。
- en: Show that A is positive definite if and only if
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 证明A是正定的当且仅当
- en: '![⟨x,y⟩ := xTAy ](img/file492.png)'
  id: totrans-485
  prefs: []
  type: TYPE_IMG
  zh: '![⟨x,y⟩ := xTAy ](img/file492.png)'
- en: is an inner product.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 是一个内积。
- en: Problem 8\. Let A ∈ℝ^(n×m) be a matrix, and denote its columns by a[1],…,a[n]
    ∈ℝ^n.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 8\. 设A ∈ℝ^(n×m)为矩阵，并将其列向量记为a[1],…,a[n] ∈ℝ^n。
- en: (a) Show that for all x ∈ℝ^m, we have Ax ∈ span(a[1],…,a[n]).
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 证明对于所有x ∈ℝ^m，我们有Ax ∈ span(a[1],…,a[n])。
- en: (b) Let B ∈ℝ^(m×k), and denote the columns of AB by v[1],…,v[k] ∈ℝ^n. Show that
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 设B ∈ℝ^(m×k)，并将AB的列记为v[1],…,v[k] ∈ℝ^n。证明
- en: '![v1,...,vk ∈ span(a1,...,an). ](img/file493.png)'
  id: totrans-490
  prefs: []
  type: TYPE_IMG
  zh: '![v1,...,vk ∈ span(a1,...,an). ](img/file493.png)'
- en: Problem 9\. Let A ∈ℝ^(n×n) be a matrix. Show that
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 9\. 设A ∈ℝ^(n×n)为矩阵。证明
- en: '![⟨Ax, y⟩ = ⟨x,AT y⟩ ](img/file494.png)'
  id: totrans-492
  prefs: []
  type: TYPE_IMG
  zh: '![⟨Ax, y⟩ = ⟨x,AT y⟩ ](img/file494.png)'
- en: holds for all x,y ∈ℝ^n, where ⟨⋅,⋅⟩ is the Euclidean inner product.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 对所有x, y ∈ℝ^n成立，其中⟨⋅,⋅⟩为欧几里得内积。
- en: Problem 10\. Calculate the determinant of
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 10\. 计算以下矩阵的行列式：
- en: '![ ⌊1 2 3⌋ | | A = |⌈4 5 6|⌉ . 7 8 9 ](img/file495.png)'
  id: totrans-495
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊1 2 3⌋ | | A = |⌈4 5 6|⌉ . 7 8 9 ](img/file495.png)'
- en: Problem 11\. Let A ∈ℝ^(n×n) be a matrix and let c ∈ℝ be a constant.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 11\. 设 A ∈ℝ^(n×n) 为矩阵，c ∈ℝ 为常数。
- en: (a) Show that
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 证明
- en: '![| | ||a1,1 ... ca1,i ... a1,n || ||a ... ca ... a || || 2.,1 .2,i 2.,n ||=
    cdetA || .. ... .. ... .. || || || an,1 ... can,i ... an,n ](img/file496.png)'
  id: totrans-498
  prefs: []
  type: TYPE_IMG
  zh: '![| | ||a1,1 ... ca1,i ... a1,n || ||a ... ca ... a || || 2.,1 .2,i 2.,n ||=
    cdetA || .. ... .. ... .. || || || an,1 ... can,i ... an,n ](img/file496.png)'
- en: holds for all i = 1,…,n.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 对所有 i = 1,…,n 成立。
- en: (b) Show that
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 证明
- en: '![| | ||a1,1 a1,2 ... a1,n || || . . . . || | .. .. .. .. | ||ca ca ... ca
    ||= cdet A || .i,1 i.,2 .i,n|| || .. .. ... .. || || || an,1 an,2 ... an,n ](img/file497.png)'
  id: totrans-501
  prefs: []
  type: TYPE_IMG
  zh: '![| | ||a1,1 a1,2 ... a1,n || || . . . . || | .. .. .. .. | ||ca ca ... ca
    ||= cdet A || .i,1 i.,2 .i,n|| || .. .. ... .. || || || an,1 an,2 ... an,n ](img/file497.png)'
- en: holds for all i = 1,…,n and
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 对所有 i = 1,…,n 成立，并且
- en: (c) Show that
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 证明
- en: '![det(cA ) = cndet A. ](img/file498.png)'
  id: totrans-504
  prefs: []
  type: TYPE_IMG
  zh: '![det(cA ) = cndet A. ](img/file498.png)'
- en: Problem 12\. Let A ∈ℝ^(n×n) be an upper triangular matrix. (That is, all elements
    below the diagonal are zero.) Show that
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 12\. 设 A ∈ℝ^(n×n) 为上三角矩阵。（即，所有对角线以下的元素为零。）证明
- en: '![ ∏n detA = ai,i. i=1 ](img/file499.png)'
  id: totrans-506
  prefs: []
  type: TYPE_IMG
  zh: '![ ∏n detA = ai,i. i=1 ](img/file499.png)'
- en: Show that the same holds for lower triangular matrices. (That is, matrices where
    elements above the diagonal are zero.)
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 证明对下三角矩阵同样成立。（即，矩阵中对角线以上的元素为零。）
- en: Problem 13\. Let M ∈ℝ^(n×m) be a matrix with the block structure
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 13\. 设 M ∈ℝ^(n×m) 为具有区块结构的矩阵
- en: '![ ⌊ ⌋ ⌈A B ⌉ M = 0 C , ](img/file500.png)'
  id: totrans-509
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌈A B ⌉ M = 0 C , ](img/file500.png)'
- en: where A ∈ℝ^(k×k), B ∈ℝ^(k×l), and C ∈ℝ^(l×l).
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 A ∈ℝ^(k×k), B ∈ℝ^(k×l), C ∈ℝ^(l×l)。
- en: Show that
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 证明
- en: '![detM = detA detC. ](img/file501.png)'
  id: totrans-512
  prefs: []
  type: TYPE_IMG
  zh: '![detM = detA detC. ](img/file501.png)'
- en: Join our community on Discord
  id: totrans-513
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: Read this book alongside other users, Machine Learning experts, and the author
    himself. Ask questions, provide solutions to other readers, chat with the author
    via Ask Me Anything sessions, and much more. Scan the QR code or visit the link
    to join the community. [https://packt.link/math](https://packt.link/math)
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他用户、机器学习专家和作者本人一起阅读本书。提问、为其他读者提供解决方案，通过“问我任何问题”环节与作者交流，更多内容尽在其中。扫描二维码或访问链接加入社区。[https://packt.link/math](https://packt.link/math)
- en: '![PIC](img/file1.png)'
  id: totrans-515
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1.png)'
