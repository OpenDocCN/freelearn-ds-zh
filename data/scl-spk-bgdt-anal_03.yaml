- en: Functional Programming Concepts
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式编程概念
- en: '"Object-oriented programming makes code understandable by encapsulating moving
    parts. Functional programming makes code understandable by minimizing moving parts."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “面向对象编程通过封装移动部分使代码易于理解。函数式编程通过最小化移动部分使代码易于理解。”
- en: '- Michael Feathers'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- 迈克尔·费瑟斯'
- en: 'Using Scala and Spark is a very good combination for learning big data analytics.
    However, along with the OOP paradigm, we also need to know-how why functional
    concepts are important for writing Spark applications that eventually analyze
    your data. As mentioned in the previous chapters, Scala supports two programming
    paradigms: the Object-Oriented Programming paradigm and the Functional programming
    concepts. In [Chapter 2](part0058.html#1NA0K1-21aec46d8593429cacea59dbdcd64e1c),
    *Object-Oriented Scala*, we explored the OOP paradigm in which we have seen how
    to represent real-world objects in blueprints (classes) and then instantiate them
    into objects having real memory representation.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Scala和Spark是学习大数据分析的一个非常好的组合。然而，在面向对象编程（OOP）范式的基础上，我们还需要了解为什么函数式编程（FP）概念对于编写Spark应用程序、最终分析数据非常重要。如前几章所述，Scala支持两种编程范式：面向对象编程范式和函数式编程概念。在[第2章](part0058.html#1NA0K1-21aec46d8593429cacea59dbdcd64e1c)，*面向对象的Scala*中，我们探讨了面向对象编程范式，学习了如何在蓝图（类）中表示现实世界中的对象，并将其实例化为具有实际内存表示的对象。
- en: In this chapter, we will focus on the second paradigm (i.e. functional programming).
    We will see what functional programming is and how Scala supports it, why it matters,
    and the related advantages of using this concept. More specifically, we will learn
    several topics, such as why Scala is an arsenal for the data scientist, why it
    is important to learn the Spark paradigm, pure functions, and **higher-order functions**
    (**HOFs**). A real-life use case using HOF will also be shown in this chapter.
    Then, we will see how to handle exceptions in the higher-order functions outside
    collections using the standard library of Scala. Finally, we will learn how functional
    Scala affects an object's mutability.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点讨论第二种范式（即函数式编程）。我们将了解什么是函数式编程，Scala是如何支持它的，为什么它如此重要，以及使用这一概念的相关优势。更具体地说，我们将学习几个主题，例如为什么Scala是数据科学家的强大工具，为什么学习Spark范式很重要，纯函数和**高阶函数**（**HOFs**）。本章还将展示一个使用HOF的实际案例。然后，我们将学习如何在Scala的标准库中处理集合之外的高阶函数中的异常。最后，我们将了解函数式Scala如何影响对象的可变性。
- en: 'In a nutshell, the following topics will be covered in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本章将涵盖以下主题：
- en: Introduction to functional programming
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数式编程简介
- en: Functional Scala for the data scientists
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家的函数式Scala
- en: Why functional programming and Scala are important for learning Spark?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么函数式编程和Scala对学习Spark至关重要？
- en: Pure functions and higher-order functions
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纯函数与高阶函数
- en: 'Using higher-order functions: A real-life use case'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用高阶函数：一个实际的使用案例
- en: Error handling in functional Scala
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数式Scala中的错误处理
- en: Functional programming and data mutability
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数式编程与数据的可变性
- en: Introduction to functional programming
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式编程简介
- en: In computer science, `functional programming` (FP) is a programming paradigm
    and a unique style of building the structure and elements of computer programs.
    This uniqueness helps treat the computation as the evaluation of mathematical
    functions and avoids changing-state and mutable data. Thus, by using the FP concept,
    you can learn to code in your own style that ensures the immutability of your
    data. In other words, FP is about writing pure functions, about removing hidden
    inputs and outputs as far as we can, so that as much of our code as possible *just*
    describes a relationship between inputs and outputs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机科学中，`函数式编程`（FP）是一种编程范式，它是一种构建计算机程序结构和元素的独特风格。这种独特性有助于将计算视为数学函数的求值，避免了状态变化和可变数据。因此，通过使用FP概念，你可以学习如何以确保数据不可变的方式编写代码。换句话说，FP是编写纯函数的编程方法，是尽可能去除隐式输入和输出，使得我们的代码尽可能*只是*描述输入与输出之间的关系。
- en: This is not a new concept but the `Lambda Calculus`, which provides the basis
    of FP, was first introduced in the 1930s. However, in the realm of programming
    language, the term functional programming refers to a new style of declarative
    programming paradigm that means programming can be done with the help of control,
    declarations, or expressions instead of classical statements commonly used in
    an old programming language, such as C.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是一个新概念，但`λ演算`（Lambda Calculus），它为函数式编程提供了基础，最早是在 1930 年代提出的。然而，在编程语言的领域中，函数式编程这个术语指的是一种新的声明式编程范式，意味着编程可以借助控制、声明或表达式来完成，而不是像传统编程语言（例如
    C）中常用的经典语句。
- en: Advantages of functional programming
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式编程的优势
- en: There are some exciting and cool features in FP paradigms such as `composition`,
    `pipelining`, and `higher order functions` that help to avoid writing unfunctional
    code. Alternatively, at least later on, this helps translate a unfunctional program
    into a functional style towards an imperative one. Finally, now let's see how
    we can define the term functional programming from the computer science perspective.
    Functional programming is a common computer science concept in which computations
    and the building structure of the program are treated as if you are evaluating
    mathematical functions that support immutable data and avoid state change. In
    functional programming, each function has the same mapping or output for the same
    input argument values.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数式编程范式中，有一些令人兴奋和酷的特性，比如`组合`、`管道`和`高阶函数`，它们有助于避免编写不符合函数式编程的代码。或者，至少后来能帮助将不符合函数式的程序转换成一种面向命令式的函数式风格。最后，现在让我们从计算机科学的角度来看函数式编程的定义。函数式编程是计算机科学中的一个常见概念，其中计算和程序的构建结构被视为在评估支持不可变数据并避免状态变化的数学函数。在函数式编程中，每个函数对于相同的输入参数值都有相同的映射或输出。
- en: With the need for a complex software comes the need for good structured programs
    and software that are not difficult to write and are debuggable. We also need
    to write extendable code that will save us programming costs in the future and
    can contribute to easy writing and debugging of the code; even more modular software
    that is easy to extend and requires less programming efforts. Due to the latter
    contribution of functional programming, modularity, functional programming is
    considered as a great advantage for software development.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 随着复杂软件需求的增加，我们也需要良好结构的程序和不难编写且可调试的软件。我们还需要编写可扩展的代码，这样可以在未来节省编程成本，并且能为代码的编写和调试带来便利；甚至需要更多模块化的软件，这种软件易于扩展并且编程工作量更小。由于函数式编程的模块化特性，函数式编程被认为是软件开发中的一大优势。
- en: 'In functional programming, there is a basic building block in its structure
    called functions without side effects (or at least very few) in most of your code.
    Without side effects, the order of evaluation really doesn''t matter. When it
    comes to programming languages views, there are methods to force a particular
    order. In some FP languages (for example, eager languages such as Scheme), which
    have no evaluation order on arguments, you could nest these expressions in their
    own lambda forms as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数式编程中，其结构中有一个基本构建块，叫做无副作用的函数（或者至少是副作用非常少的函数），大多数代码都遵循这一原则。没有副作用时，求值顺序真的不重要。关于编程语言的视角，有一些方法可以强制特定的求值顺序。在某些函数式编程语言中（例如，像
    Scheme 这样的贪心语言），它们对参数没有求值顺序的限制，你可以像下面这样将这些表达式嵌套在自己的 lambda 表达式中：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In functional programming, writing mathematical functions in which the execution
    order doesn't matter usually makes your code more readable. Sometimes, one will
    argue that we need functions with side effects to be there as well. Actually,
    this is one of the major disadvantages of most functional programming languages
    since it's typically difficult to write functions that don't require any I/O;
    on the other hand, these function that requires I/O are difficult to implement
    in functional programming. From *Figure 1*, it can be seen that Scala is also
    a hybrid language that evolved by taking features from imperative languages such
    as Java and functional language such as Lisp.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数式编程中，编写数学函数时，执行顺序无关紧要，通常能使代码更具可读性。有时，人们会争辩说，我们也需要有副作用的函数。事实上，这是大多数函数式编程语言的一个主要缺点，因为通常很难编写不需要任何
    I/O 的函数；另一方面，这些需要 I/O 的函数在函数式编程中实现起来也很困难。从*图 1*中可以看出，Scala 也是一种混合语言，通过融合命令式语言（如
    Java）和函数式语言（如 Lisp）的特性演变而来。
- en: But fortunately, here we are dealing with a mixed language in which object-oriented
    and functional programming paradigms are allowed and hence writing such functions
    that require I/O is quite easy. Functional programming also has major advantages
    over basic programming, such as comprehensions and caching.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但幸运的是，在这里我们处理的是一种混合语言，允许面向对象和函数式编程范式，因此编写需要I/O的函数变得相当容易。函数式编程相较于基础编程也有重大优势，比如理解和缓存。
- en: One of the major advantages of functional programming is brevity because with
    functional programming you can write more compact and concise code. Also, concurrency
    is considered one of the major advantages, which is done more easily in functional
    programming. Therefore, functional languages such as Scala provide many other
    features and tools that encourage coders to make an entire paradigm shift to a
    more mathematical way of thinking.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式编程的一个主要优势是简洁，因为在函数式编程中，你可以编写更紧凑、更简洁的代码。此外，并发性被认为是一个主要优势，它在函数式编程中更容易实现。因此，像Scala这样的函数式语言提供了许多其他功能和工具，鼓励程序员做出整个范式转变，转向更数学化的思维方式。
- en: '![](img/00062.jpeg)**Figure 1:** Shows a conceptual view of using functional
    programming concepts'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/00062.jpeg)**图 1：** 展示了使用函数式编程概念的概念视图'
- en: 'By narrowing the focus to only a small number of composable abstract concepts,
    such as functions, function composition, and abstract algebra, FP concept provides
    several advantages over other paradigms. For example:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将焦点缩小到只有少数几个可组合的抽象概念，例如函数、函数组合和抽象代数，函数式编程概念提供了比其他范式更多的优势。例如：
- en: '**Closer alignment to mathematical thinking:** You tend to spell out your ideas
    in a format close to mathematical definitions rather than iterative programs.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更接近数学思维：** 你倾向于以接近数学定义的格式表达你的想法，而不是通过迭代程序。'
- en: '**No (or at least fewer) side effects:** Your functions do not influence other
    functions, which is great for concurrency and parallelization, and also for debugging.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无（或至少更少）副作用：** 你的函数不会影响其他函数，这对并发性和并行化非常有利，同时也有助于调试。'
- en: '**Fewer lines of code without sacrificing conceptual clarity:** Lisp is more
    powerful than non-functional languages. Although it''s true that you need to spend
    a greater proportion of your project thinking than writing, you will probably
    find that you are more productive eventually.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少代码行数而不牺牲概念的清晰度：** Lisp比非函数式语言更强大。虽然确实需要在项目中花费更多的时间思考而不是编写代码，但最终你可能会发现你变得更高效。'
- en: For these exciting features, functional programming achieves significant expressive
    power. For example, machine learning algorithms can take hundreds of lines of
    imperative code to implement yet they can be defined in just a handful of equations.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些令人兴奋的特性，函数式编程具有显著的表达能力。例如，机器学习算法可能需要数百行命令式代码来实现，而它们可以仅通过少数几个方程式来定义。
- en: Functional Scala for the data scientists
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学家的函数式Scala
- en: For performing interactive data cleaning, processing, munging, and analysis,
    many data scientists use R or Python as their favorite tool. However, there are
    many data scientists who tend to get very attached to their favorite tool--that
    is, Python or R and try to solve all data analytics problems or jobs using that
    tool. Thus, introducing them to a new tool can be very challenging in most circumstances
    as the new tool has more syntax and a new set of patterns to learn before using
    the new tool to solve their purpose.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于进行交互式数据清理、处理、变换和分析，许多数据科学家使用R或Python作为他们最喜欢的工具。然而，也有许多数据科学家倾向于非常依赖他们最喜欢的工具——即Python或R，并试图用这个工具解决所有的数据分析问题。因此，在大多数情况下，向他们介绍一种新工具可能是非常具有挑战性的，因为新工具有更多的语法和一套新的模式需要学习，然后才能用新工具解决他们的目的。
- en: 'There are other APIs in Spark written in Python and R such as PySpark and SparkR
    respectively that allow you to use them from Python or R. However, most Spark
    books and online examples are written in Scala. Arguably, we think that learning
    how to work with Spark using the same language on which the Spark code has been
    written will give you many advantages over Java, Python, or R as a data scientist:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Spark中还有其他用Python和R编写的API，例如PySpark和SparkR，分别允许你从Python或R中使用它们。然而，大多数Spark的书籍和在线示例都是用Scala编写的。可以说，我们认为学习如何使用Spark并使用与Spark代码编写相同语言的方式，将为你作为数据科学家提供比Java、Python或R更多的优势：
- en: Better performance and removes the data processing overhead
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供更好的性能并去除数据处理的开销
- en: Provides access to the latest and greatest features of Spark
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供访问Spark最新和最强大功能的能力
- en: Helps to understand the Spark philosophy in a transparent way
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有助于以透明的方式理解Spark的哲学
- en: Analyzing data means that you are writing Scala code to retrieve data from the
    cluster using Spark and its APIs (that is, SparkR, SparkSQL, Spark Streaming,
    Spark MLlib, and Spark GraphX). Alternatively, you're developing a Spark application
    using Scala to manipulate that data locally on your own machine. In both cases,
    Scala is your real friend and will pay you dividends in time.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析意味着你正在编写Scala代码，使用Spark及其API（如SparkR、SparkSQL、Spark Streaming、Spark MLlib和Spark
    GraphX）从集群中提取数据。或者，你正在使用Scala开发一个Spark应用程序，在你自己的机器上本地处理数据。在这两种情况下，Scala都是你真正的伙伴，并且能在时间上为你带来回报。
- en: Why FP and Scala for learning Spark?
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择函数式编程和Scala来学习Spark？
- en: In this section, we will discuss why we will learn Spark to solve our data analytics
    problem. We will then discuss why the functional programming concepts in Scala
    are particularly important to make data analysis easier for the data scientists.
    We will also discuss the Spark programming model and its ecosystem to make them
    clearer.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论为什么要学习Spark来解决我们的数据分析问题。接着，我们将讨论为什么Scala中的函数式编程概念对于数据科学家来说尤其重要，它可以使数据分析变得更加简单。我们还将讨论Spark的编程模型及其生态系统，帮助大家更清楚地理解。
- en: Why Spark?
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择Spark？
- en: 'Spark is a lightning fast cluster computing framework and is mainly designed
    for fast computations. Spark is based on the Hadoop MapReduce model and uses MapReduce
    in more forms and types of computation, such as interactive queries and stream
    processing. One of the main features of Spark is in-memory processing, which helps
    increase the performance and processing speed of an application. Spark supports
    a wide range of applications and workloads, such as the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Spark是一个极速的集群计算框架，主要设计用于快速计算。Spark基于Hadoop的MapReduce模型，并在更多形式和类型的计算中使用MapReduce，例如交互式查询和流处理。Spark的主要特性之一是内存计算，它帮助提高应用程序的性能和处理速度。Spark支持广泛的应用程序和工作负载，如下所示：
- en: Batch-based applications
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于批处理的应用
- en: Iterative algorithms that were not possible to run fast before
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代算法，在以前无法快速运行的情况下
- en: Interactive query and streaming
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交互式查询和流处理
- en: 'Also, it doesn''t require much time for you to learn Spark and implement it
    in your applications without the need to understand the inner details of concurrency
    and distributed systems. Spark was implemented in 2009 at AMPLab of UC Berkeley.
    In 2010, they decided to make it open source. Then, Spark became an Apache release
    in 2013 and since then Spark has been considered as the most famous/used Apache-released
    software. Apache Spark became very famous because of its features:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，学习Spark并将其应用于你的程序并不需要花费太多时间，也不需要深入理解并发和分布式系统的内部细节。Spark是在2009年由UC Berkeley的AMPLab团队实现的，2010年他们决定将其开源。之后，Spark于2013年成为Apache项目，从那时起，Spark一直被认为是最著名和最常用的Apache开源软件。Apache
    Spark因其以下特性而声名显赫：
- en: '**Fast computations**: Spark helps you to run applications that are faster
    than Hadoop because of its golden feature--in-memory processing.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速计算**：由于其独特的内存计算特性，Spark能够帮助你比Hadoop更快地运行应用程序。'
- en: '**Support for multiple programming languages**: Apache Spark provides wrappers
    and built-in APIs in different languages such as Scala, Java, Python, or even
    R.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持多种编程语言**：Apache Spark为不同的编程语言提供了封装和内置API，如Scala、Java、Python，甚至R。'
- en: '**More analytics**: As mentioned earlier, Spark supports MapReduce operations
    and it also supports more advanced analytics such as **machine learning** (**MLlib**),
    data streaming, and algorithms for graph processing.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更多分析功能**：如前所述，Spark支持MapReduce操作，同时也支持更高级的分析功能，如**机器学习**（**MLlib**）、数据流处理和图形处理算法。'
- en: 'As mentioned earlier, Spark is built on top of the Hadoop software and you
    can deploy Spark in different ways:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Spark是构建在Hadoop软件之上的，你可以以不同的方式部署Spark：
- en: '**Standalone cluster**: This means that Spark will run on top of **Hadoop Distributed
    File System** (**HDFS**) and space will actually be allocated to HDFS. Spark and
    MapReduce will run side by side to serve all the Spark jobs.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**独立集群**：这意味着Spark将运行在**Hadoop分布式文件系统**（**HDFS**）之上，并将空间实际分配给HDFS。Spark和MapReduce将并行运行，以服务所有Spark作业。'
- en: '**Hadoop YARN cluster**: This means that Spark simply runs on YARN without
    any root privileges or pre-installations.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop YARN集群**：这意味着Spark可以直接在YARN上运行，无需任何根权限或预先安装。'
- en: '**Mesos cluster**: When a driver program creates a Spark job and starts assigning
    related tasks for scheduling, Mesos determines which computing nodes will handle
    which tasks. We assume that you have already configured and installed Mesos on
    your machine.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mesos 集群**：当驱动程序创建一个 Spark 作业并开始为调度分配相关任务时，Mesos 会决定哪些计算节点将处理哪些任务。我们假设你已经在你的机器上配置并安装了
    Mesos。'
- en: '**Deploy on pay-as-you-go cluster**: You can deploy Spark jobs in real cluster
    mode on AWS EC2\. To make your applications run on Spark cluster mode and for
    better scalability, you can consider **Amazon Elastic Compute Cloud** (**EC2**)
    services as **Infrastructure as a Service** (**IaaS**) or **Platform as a Service**
    (**PaaS**).'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**按需付费集群部署**：你可以在 AWS EC2 上以真实集群模式部署 Spark 作业。为了让应用在 Spark 集群模式下运行并提高可扩展性，你可以考虑将**亚马逊弹性计算云**（**EC2**）服务作为**基础设施即服务**（**IaaS**）或**平台即服务**（**PaaS**）。'
- en: Refer to [Chapter 17](part0511.html#F7AFE1-21aec46d8593429cacea59dbdcd64e1c),
    *Time to Go to ClusterLand - Deploying Spark on a Cluster* and [Chapter 18](part0550.html#GCGLC1-21aec46d8593429cacea59dbdcd64e1c),
    *Testing and Debugging Spark* for how to deploy your data analytics application
    using Scala and Spark on a real cluster.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考[第17章](part0511.html#F7AFE1-21aec46d8593429cacea59dbdcd64e1c)，*前往 ClusterLand
    - 在集群上部署 Spark* 和[第18章](part0550.html#GCGLC1-21aec46d8593429cacea59dbdcd64e1c)，*在集群上测试和调试
    Spark*，了解如何使用 Scala 和 Spark 在真实集群上部署数据分析应用程序。
- en: Scala and the Spark programming model
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala 和 Spark 编程模型
- en: 'Spark programming starts with a dataset or a few, usually residing in some
    form of distributed and persistent storage such as HDFS. A typical RDD programming
    model that Spark provides can be described as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 编程从一个数据集或几个数据集开始，通常位于某种形式的分布式持久化存储中，例如 HDFS。Spark 提供的典型 RDD 编程模型可以描述如下：
- en: From an environment variable, Spark context (the Spark shell provides you with
    a Spark Context or you can make your own, this will be described later in this
    chapter) creates an initial data reference RDD object.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从环境变量中，Spark 上下文（Spark Shell 为你提供了 Spark 上下文，或者你可以自己创建，稍后将在本章中讨论）创建一个初始数据引用的
    RDD 对象。
- en: Transform the initial RDD to create more RDD objects following the functional
    programming style (to be discussed later on).
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换初始 RDD，创建更多的 RDD 对象，遵循函数式编程风格（稍后会讨论）。
- en: Send the code, algorithms, or applications from the driver program to the cluster
    manager nodes. Then, the cluster manager provides a copy to each computing node.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将代码、算法或应用程序从驱动程序发送到集群管理器节点，然后集群管理器会将副本提供给每个计算节点。
- en: Computing nodes hold a reference to the RDDs in their partition (again, the
    driver program also holds a data reference). However, computing nodes could have
    the input dataset provided by the cluster manager as well.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算节点持有其分区中 RDD 的引用（同样，驱动程序也持有数据引用）。然而，计算节点也可以由集群管理器提供输入数据集。
- en: After a transformation (via either narrow or wider transformation), the result
    to be generated is a brand new RDD, since the original one will not be mutated.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经过一次转换（无论是狭义转换还是宽义转换）后，生成的结果是一个全新的 RDD，因为原始的 RDD 不会被修改。
- en: Finally, the RDD object or more (specifically, data reference) is materialized
    through an action to dump the RDD into the storage.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终，RDD 对象或更多（具体来说，是数据引用）通过一个动作进行物化，将 RDD 转储到存储中。
- en: The driver program can ask the computing nodes for a chunk of results for the
    analysis or visualization of a program.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 驱动程序可以请求计算节点提供一部分结果，用于程序的分析或可视化。
- en: Wait! So far we have moved smoothly. We suppose you will ship your application
    code to the computing nodes in the cluster. Still, you will have to upload or
    send the input datasets to the cluster to be distributed among the computing nodes.
    Even during the bulk upload, you will have to transfer the data across the network.
    We also argue that the size of the application code and results are negligible
    or trivial. Another obstacle is if you want Spark to process the data at scale
    computation, it might require data objects to be merged from multiple partitions
    first. This means we will need to shuffle data among the worker/computing nodes
    that is usually done by `partition()`, `intersection()`, and `join()` transformation
    operations.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 等等！到目前为止，我们已经顺利进行。我们假设你会将应用程序代码发送到集群中的计算节点。但是，你仍然需要将输入数据集上传或发送到集群中，以便在计算节点之间进行分发。即使在批量上传时，你也需要通过网络传输数据。我们还认为，应用程序代码和结果的大小是可以忽略不计的或微不足道的。另一个障碍是，如果你希望
    Spark 进行大规模数据处理，可能需要先将数据对象从多个分区合并。这意味着我们需要在工作节点/计算节点之间进行数据洗牌，通常通过 `partition()`、`intersection()`
    和 `join()` 等转换操作来实现。
- en: Scala and the Spark ecosystem
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala 和 Spark 生态系统
- en: To provide more enhancement and additional big data processing capabilities,
    Spark can be configured and run on top of existing Hadoop-based clusters. The
    core APIs in Spark, on the other hand, are written in Java, Scala, Python, and
    R. Compared to MapReduce, with the more general and powerful programming model,
    Spark also provides several libraries that are part of the Spark ecosystems for
    additional capabilities for general-purpose data processing and analytics, graph
    processing, large-scale structured SQL, and **Machine Learning** (**ML**) areas.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供更多增强功能和大数据处理能力，Spark 可以配置并运行在现有的基于 Hadoop 的集群上。另一方面，Spark 中的核心 API 是用 Java、Scala、Python
    和 R 编写的。与 MapReduce 相比，Spark 提供了更通用、更强大的编程模型，并且提供了多个库，这些库是 Spark 生态系统的一部分，能够为通用数据处理与分析、大规模结构化
    SQL、图形处理和 **机器学习**（**ML**）等领域提供附加能力。
- en: "The Spark ecosystem consists of the following components as shown (for details\
    \ please refer [Chapter 16\uFEFF](part0480.html#E9OE01-21aec46d8593429cacea59dbdcd64e1c),\
    \ *Spark Tuning*):"
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 生态系统由以下组件组成，如所示（详细信息请参见 [第16章](part0480.html#E9OE01-21aec46d8593429cacea59dbdcd64e1c)，*Spark
    调优*）：
- en: '**Apache Spark core**: This is the underlying engine for the Spark platform
    on which all the other functionalities are built. Also, it''s the one that provides
    in-memory processing.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Spark 核心**：这是 Spark 平台的底层引擎，所有其他功能都基于它构建。此外，它还提供内存处理功能。'
- en: '**Spark SQL**: As mentioned Spark core is the underlying engine and all the
    other components or features are built upon it. Spark SQL is the Spark component
    that provides support for different data structures (structured and semi-structured
    data).'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark SQL**：正如之前所提到的，Spark 核心是底层引擎，所有其他组件或功能都是基于它构建的。Spark SQL 是 Spark 组件之一，提供对不同数据结构（结构化和半结构化数据）的支持。'
- en: '**Spark streaming**: This component is responsible for streaming data for analytics
    and converts them into mini batches that can be used later on for analytics.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark Streaming**：这个组件负责流式数据分析，并将其转换成可以后续用于分析的小批次数据。'
- en: '**MLlib (Machine Learning Library)**: MLlib is a machine learning framework
    that supports lots of ML algorithms in a distributed fashion.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLlib（机器学习库）**：MLlib 是一个机器学习框架，支持以分布式方式实现许多机器学习算法。'
- en: '**GraphX**: A distributed graph framework built on top of Spark to express
    user-defined graph components in a parallel fashion.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GraphX**：一个分布式图框架，构建在 Spark 之上，以并行方式表达用户定义的图形组件。'
- en: As mentioned earlier, most functional programming languages allow the user to
    write nice, modular, and extensible code. Also, functional programming encourages
    safe ways of programming by writing functions that look like mathematical functions.
    Now, how did Spark make all the APIs work as a single unit? It was possible because
    of the advancement in the hardware and of course, the functional programming concepts.
    Since adding syntactic sugar to easily do lambda expressions is not sufficient
    to make a language functional, this is just the start.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，大多数函数式编程语言允许用户编写优雅、模块化和可扩展的代码。此外，函数式编程通过编写看起来像数学函数的函数，鼓励安全的编程方式。那么，Spark
    是如何使所有的 API 工作成为一个整体的呢？这得益于硬件的进步，以及当然，还有函数式编程的概念。因为简单地为语言增加语法糖以便轻松使用 lambda 表达式并不足以让一种语言具备函数式编程特性，这仅仅是一个开始。
- en: Although the RDD concept in Spark works quite well, there are many use cases
    where it's a bit complicated due to its immutability. For the following example
    which is the classic example of calculating an average, make the source code robust
    and readable; of course, to reduce the overall cost, one does not want to first
    compute totals, then counts, even if the data is cached in the main memory.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Spark中的RDD概念运作得很好，但在许多使用案例中，由于其不可变性，情况会变得有些复杂。对于以下计算平均值的经典示例，要使源代码更健壮和可读；当然，为了降低总体成本，人们不希望先计算总和，再计算计数，即使数据已缓存于主内存中。
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The DataFrames API (this will be discussed in the later chapters in detail)
    produces equally terse and readable code where the functional API fits well for
    most use cases and minimizes the MapReduce stages; there are many shuffles that
    can cost dramatically and the key reasons for this are as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrames API（这将在后面的章节中详细讨论）生成的代码同样简洁且可读，其中函数式API适用于大多数使用场景，最小化了MapReduce阶段；有许多shuffle操作可能导致显著的性能开销，导致这种情况的主要原因如下：
- en: Large code bases require static typing to eliminate trivial mistakes, such as
    *aeg* instead of *age* instantly
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型代码库需要静态类型来消除琐碎的错误，比如*ae*代替*age*这样的错误
- en: Complex code requires transparent APIs to communicate design clearly
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂代码需要透明的API来清晰地传达设计
- en: 2x speed-ups in the DataFrames API via under-the-hood mutation can be equally
    achieved by encapsulating state via OOP and using mapPartitions and combineByKey
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过幕后变异，DataFrames API可以实现2倍的加速，这也可以通过封装状态的OOP和使用mapPartitions与combineByKey来实现
- en: Flexibility and Scala features are required to build functionality quickly
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建功能快速的灵活性和Scala特性是必需的
- en: The combination of OOP and FP with Spark can make a pretty hard problem easier
    in Barclays. For example, in Barclays, recently an application called Insights
    Engine has been developed to execute an arbitrary number N of near-arbitrary SQL-like
    queries. The application can execute them in a way that can scale with increasing
    N.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在Barclays，OOP和FP的结合可以使一些本来非常困难的问题变得更加简单。例如，在Barclays，最近开发了一个名为Insights Engine的应用程序，它可以执行任意数量的接近任意的类似SQL查询。该应用程序能够以可扩展的方式执行这些查询，随着N的增加而扩展。
- en: Now let's talk about pure functions, higher order functions, and anonymous functions,
    which are the three important concepts in the functional programming of Scala.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们谈谈纯函数、高阶函数和匿名函数，这三者是Scala函数式编程中的三个重要概念。
- en: Pure functions and higher-order functions
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 纯函数与高阶函数
- en: 'From the computer science perspective, functions can have many forms such as
    first order functions, higher-order functions, or pure functions. This is also
    true from the mathematics point of view. Using a higher-order function is a function
    one of the following can be performed:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 从计算机科学的角度来看，函数可以有多种形式，例如一阶函数、高阶函数或纯函数。从数学角度来看也是如此。使用高阶函数时，以下某一操作可以执行：
- en: Takes one or more functions as arguments to do some operations
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接受一个或多个函数作为参数，执行某些操作
- en: Returns a function as its result
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回一个函数作为其结果
- en: All other functions except the higher-order functions are first-order functions.
    However, from the mathematics point of view, higher-order functions are also called
    **operators** or **functionals**. On the other hand, if the return value of a
    function is only determined by its input and of course without observable side
    effects, it is called a **pure function**.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 除高阶函数外，所有其他函数都是一阶函数。然而，从数学角度来看，高阶函数也被称为**运算符**或**泛函数**。另一方面，如果一个函数的返回值仅由其输入决定，并且当然没有可观察的副作用，则称为**纯函数**。
- en: In this section, we will briefly discuss why and how to use different functional
    paradigms in Scala. Especially, pure functions, and higher-order functions will
    be discussed. At the end of this section, a brief overview of using anonymous
    functions will also be provided since this is used frequently while developing
    a Spark application using Scala.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们将简要讨论为什么以及如何在Scala中使用不同的函数式范式。特别是，纯函数和高阶函数将被讨论。在本节末尾，我们还将简要概述如何使用匿名函数，因为在使用Scala开发Spark应用时，这个概念非常常见。
- en: Pure functions
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 纯函数
- en: One of the most important principles of functional programming is pure functions.
    So what are pure functions and why do we care about them? In this section, we
    will address this important feature of functional programming. One of the best
    practices of functional programming is to implement your programs such that the
    core of your program/application is made from pure functions and all the I/O functions
    or side effects such as network overhead and exceptions are in an exposed external
    layer.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式编程中最重要的原则之一是纯函数。那么，什么是纯函数，为什么我们要关心它们？在本节中，我们将探讨函数式编程中的这一重要特性。函数式编程的最佳实践之一是实现程序，使得程序/应用程序的核心由纯函数构成，而所有I/O函数或副作用（如网络开销和异常）则位于外部公开层。
- en: So what are the benefits of pure functions? Pure functions are normally smaller
    than normal functions (although it depends on other factors such as programming
    language) and even easier to interpret and understand for the human brain because
    it looks like a mathematical function.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，纯函数有什么好处呢？纯函数通常比普通函数小（尽管这取决于其他因素，比如编程语言），而且对于人脑来说，它们更容易理解和解释，因为它们看起来像一个数学函数。
- en: 'Yet, you might argue against this since most developers still find imperative
    programming more understandable! Pure functions are much easier to implement and
    test. Let''s demonstrate this by an example. Suppose we have the following two
    separate functions:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可能会反驳这一点，因为大多数开发人员仍然觉得命令式编程更容易理解！纯函数更容易实现和测试。让我们通过一个例子来演示这一点。假设我们有以下两个独立的函数：
- en: '[PRE2]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'So in the previous two examples, if you want to test the `pureFunc` pure function,
    we just assert the return value that''s coming from the pure function with what
    we are expecting based on our input such as:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在前面的两个例子中，如果你想测试`pureFunc`纯函数，我们只需断言从纯函数返回的值与我们基于输入预期的值相符，如：
- en: '[PRE3]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'But on the other side, if we wanted to test our `notpureFunc` impure function
    then we need to redirect the standard output and then apply assertion on it. The
    next practical tip is that functional programming makes programmers more productive
    because, as mentioned earlier, pure functions are smaller and easier to write
    and you can easily compose them together. Also, the duplication of code is minimal
    and you can easily reuse your code. Now let''s demonstrate this advantage with
    a better example. Consider these two functions:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，另一方面，如果我们想测试我们的`notpureFunc`非纯函数，那么我们需要重定向标准输出并对其应用断言。下一个实用技巧是，函数式编程使程序员更加高效，因为，如前所述，纯函数更小，更容易编写，并且你可以轻松地将它们组合在一起。除此之外，代码重复最小，你可以轻松地重用你的代码。现在，让我们通过一个更好的例子来演示这一优势。考虑这两个函数：
- en: '[PRE4]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'However, there might be side effects of mutability; using a pure function (that
    is, without mutability) helps us reason about and test code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，可能会有可变性带来的副作用；使用纯函数（即没有可变性）有助于我们推理和测试代码：
- en: '[PRE5]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This one is advantageous and very easy to interpret and use. However, let''s
    see another example:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法具有优势，非常容易解释和使用。然而，让我们来看另一个例子：
- en: '[PRE6]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, consider how confusing this could be: what will be the output in a multithreaded
    environment? As you can see, we can easily use our pure function, `pureMul`, to
    multiply any sequence of numbers, unlike our `notpureMul` impure function. Let''s
    demonstrate this by the following example:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑一下这可能会有多混乱：在多线程环境中，输出会是什么？如你所见，我们可以轻松使用我们的纯函数`pureMul`来乘以任何数字序列，这与我们的`notpureMul`非纯函数不同。让我们通过以下例子来演示这一点：
- en: '[PRE7]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The complete code for the preceding examples can be shown as follows (methods
    were called using some real values):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例的完整代码如下（方法已使用一些实际值进行调用）：
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As discussed earlier, you can consider pure functions as one of the most important
    features of functional programming and as a best practice; you need to build the
    core of your application using pure functions.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，你可以将纯函数视为函数式编程中最重要的特性之一，并作为最佳实践；你需要用纯函数构建应用程序的核心。
- en: 'Functions versus methods:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 函数与方法：
- en: 'In the programming realm, a **function** is a piece of code called by a name.
    Data (as an argument or as a parameter) can be passed to operate on and can return
    data (optionally). All data passed to a function is passed explicitly. A **method,**
    on the other hand, is also a piece of code that is called by a name too. However,
    a method is always associated with an object. Sounds similar? Well! In most cases,
    a method is identical to a function except for two key differences:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在编程领域，**函数**是通过名称调用的一段代码。数据（作为参数或作为参数）可以传递给函数进行操作，并且可以返回数据（可选）。所有传递给函数的数据都是显式传递的。另一方面，**方法**也是通过名称调用的一段代码。然而，方法总是与一个对象相关联。听起来相似吗？嗯！在大多数情况下，方法与函数是相同的，只有两个关键的区别：
- en: 1\. A method is implicitly passed the object on which it was called.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 方法隐式地接收它被调用的对象。
- en: 2\. A method is able to operate on data that is contained within the class.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 方法能够对包含在类中的数据进行操作。
- en: It is already stated in the previous chapter that an object is an instance of
    a class--the class is the definition, the object is an instance of that data.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中已经说明了，对象是类的实例——类是定义，对象是该数据的实例。
- en: Now it's time to learn about higher-order functions. However, before that, we
    should learn one more important concept in functional Scala--**anonymous functions**.
    Through this, we will also learn how to use the lambda expression with functional
    Scala.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是学习高阶函数的时候了。不过，在此之前，我们应该先了解函数式 Scala 中的另一个重要概念——**匿名函数**。通过这个概念，我们还将学习如何在函数式
    Scala 中使用 lambda 表达式。
- en: Anonymous functions
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 匿名函数
- en: 'Sometimes in your code, you don''t want to define a function prior to its usage,
    maybe because you will use it in one place. In functional programming, there''s
    a type of function that is very suitable to this situation. It''s called an anonymous
    function. Let''s demonstrate the use of anonymous functions using the previous
    example of transferring money:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，在你的代码中，你不想在使用之前定义一个函数，可能是因为你只会在某一个地方使用它。在函数式编程中，有一种非常适合这种情况的函数类型，叫做匿名函数。让我们通过之前的转账示例来演示匿名函数的使用：
- en: '[PRE10]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, let''s call the `TransferMoney()` method with some real value as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用一些实际值来调用 `TransferMoney()` 方法，如下所示：
- en: '[PRE11]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Lambda expression:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 表达式：
- en: 'As already stated, Scala supports first-class functions, which means functions
    can be expressed in function-literal syntax as well; functions can be represented
    by objects, called function values. Try the following expression, it creates a
    successor function for integers:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Scala 支持一等函数，这意味着函数也可以通过函数字面量语法表达；函数可以通过对象来表示，被称为函数值。尝试以下表达式，它为整数创建了一个后继函数：
- en: '`scala> var apply = (x:Int) => x+1`'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`scala> var apply = (x:Int) => x+1`'
- en: '`apply: Int => Int = <function1>`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`apply: Int => Int = <function1>`'
- en: 'The apply variable is now a function that can be used in the usual way as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，apply 变量已经是一个可以像往常一样使用的函数，如下所示：
- en: '`scala> var x = apply(7)`'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`scala> var x = apply(7)`'
- en: '`x: Int = 8`'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`x: Int = 8`'
- en: 'What we have done here is simply use the core of a function: the argument list
    followed by the function arrow and the body of the function. This one is not black
    magic but a full-fledged function, only without a given name--that is, anonymous.
    If you define a function this way, there will be no way to refer to that function
    afterward and hence you couldn''t call that function afterward because without
    a name it''s an anonymous one. Also, we have a so-called **lambda expression**!
    It''s just the pure, anonymous definition of a function.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里所做的就是简单地使用了函数的核心部分：参数列表，接着是函数箭头以及函数体。这并不是黑魔法，而是一个完整的函数，只不过没有给定名称——也就是匿名函数。如果你以这种方式定义一个函数，那么之后就无法引用该函数，因此你无法在之后调用它，因为没有名称，它是匿名的。同时，我们还看到了所谓的**lambda
    表达式**！它就是函数的纯粹匿名定义。
- en: 'The output of the preceding code is as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'So, in the previous example instead of declaring a separate `callback` function,
    we passed an anonymous function directly and it did the same job just like the
    `bankFee` function. You can also omit the type in the anonymous function and it
    will be directly inferred based on the passed argument like this:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，在之前的示例中，我们没有声明一个单独的 `callback` 函数，而是直接传递了一个匿名函数，它完成了与 `bankFee` 函数相同的工作。你也可以省略匿名函数中的类型，它将根据传递的参数直接推断出来，像这样：
- en: '[PRE13]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '[PRE14]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s demonstrate the previous example on the Scala shell as shown in the
    following screenshot:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在Scala shell中展示前面的例子，如下截图所示：
- en: '![](img/00066.jpeg)**Figure 6:** Use of the anonymous function in Scala'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/00066.jpeg)**图6：** 在Scala中使用匿名函数'
- en: Some programming languages that have functional support use the name lambda
    function instead of anonymous function.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一些支持函数式编程的编程语言使用“lambda函数”这个名称来代替匿名函数。
- en: Higher-order functions
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高阶函数
- en: In Scala's functional programming, you are allowed to pass functions as parameters
    and even return a function as a result from another function; this defines what
    are called higher-order functions.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在Scala的函数式编程中，你可以将函数作为参数传递，甚至可以将一个函数作为结果从另一个函数返回；这就是所谓的高阶函数。
- en: 'Let''s demonstrate this feature by an example. Consider the following function
    `testHOF` that takes another function `func` and then applies this function to
    its second argument value:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来演示这个特性。考虑以下函数`testHOF`，它接受另一个函数`func`，然后将该函数应用于它的第二个参数值：
- en: '[PRE15]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: After demonstrating the basics of Scala's functional programming, now we are
    ready to move to more complex cases of functional programming. As mentioned earlier,
    we can define a higher-order function as a function that accepts other functions
    as arguments and it returns them as a result. If you are coming from an object-oriented
    programming background, you will find it very a different approach, but it will
    become easier to understand as we go on.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在演示了Scala函数式编程的基础后，现在我们准备进入更复杂的函数式编程案例。如前所述，我们可以将高阶函数定义为接受其他函数作为参数并返回它们的结果。如果你来自面向对象编程的背景，你会发现这是一种非常不同的方法，但随着我们继续深入，它会变得更容易理解。
- en: 'Let''s start by defining a simple function:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义一个简单的函数开始：
- en: '[PRE16]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The previous function is a very simple one. It''s a function that accepts an
    Int value and then returns a quarter of this value in a `Double` type. Let''s
    define another simple function:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的函数是一个非常简单的函数。它接受一个`Int`值，并返回该值的四分之一，类型为`Double`。让我们定义另一个简单函数：
- en: '[PRE17]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The second function `addTwo` is more trivial than the first one. It accepts
    an `Int` value and then adds 2 to it. As you can see, these two functions have
    something in common. Both of them accept `Int` and return another processed value
    that we can call `AnyVal`. Now, let''s define a higher-order function that accepts
    another function among its parameters:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个函数`addTwo`比第一个函数更简单。它接受一个`Int`值，然后加2。正如你所看到的，这两个函数有一些相同之处。它们都接受`Int`并返回另一个处理过的值，我们可以称之为`AnyVal`。现在，让我们定义一个接受另一个函数作为参数的高阶函数：
- en: '[PRE18]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see, the preceding function `applyFuncOnRange` accepts two `Int`
    values that work as a beginning and end to a sequence and it accepts a function
    that has the `Int => AnyVal` signature just like the previously defined simple
    functions (`quarterMakder` and `addTwo`). Now let's demonstrate our previous higher-order
    function by passing one of the two simple functions to it as a third argument
    (if you want to pass your own function then make sure that it has the same signature
    `Int => AnyVal`).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，前面的函数`applyFuncOnRange`接受两个`Int`值，作为序列的开始和结束，并接受一个具有`Int => AnyVal`签名的函数，就像之前定义的简单函数（`quarterMakder`和`addTwo`）。现在，让我们通过将两个简单函数中的一个作为第三个参数传递给它，来展示我们之前的高阶函数（如果你想传递自己的函数，确保它具有相同的签名`Int
    => AnyVal`）。
- en: '**Scala syntax for loop with ranges:** The simplest syntax of using a for loop
    with ranges in Scala is:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**Scala的范围for循环语法：** 使用Scala范围的for循环的最简单语法是：'
- en: '`for( var x <- range ){`'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '`for( var x <- range ){`'
- en: '`statement(s)`'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`statement(s)`'
- en: '`}`'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`}`'
- en: 'Here, the `range` could be a range of numbers and is represented as `i` to
    `j` or sometimes like `i` until `j`. The left-arrow `←` operator is called a generator
    because it''s generating individual values from a range. Let''s see a concrete
    example of this feature:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`range`可以是一个数字范围，表示为`i`到`j`，有时也像`i`直到`j`。左箭头`←`运算符被称为生成器，因为它从范围中生成单个值。让我们通过一个具体的例子来展示这一特性：
- en: '`object UsingRangeWithForLoop {`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`object UsingRangeWithForLoop {`'
- en: '`def main(args: Array[String]):Unit= {`'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`def main(args: Array[String]):Unit= {`'
- en: '`var i = 0;`'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`var i = 0;`'
- en: '`// for loop execution with a range`'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`// 使用范围的for循环执行`'
- en: '`for( i <- 1 to 10){`'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`for( i <- 1 to 10){`'
- en: '`println( "Value of i: " + i )`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`println( "i的值: " + i )`'
- en: '`}`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`}`'
- en: '`}`'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`}`'
- en: '`}`'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`}`'
- en: 'The output of the preceding code is as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '`Value of i: 1`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`i的值: 1`'
- en: '`Value of i: 2`'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`i的值: 2`'
- en: '`Value of i: 3`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`i的值: 3`'
- en: '`Value of i: 4`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`i的值: 4`'
- en: '`Value of i: 5`'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`i的值: 5`'
- en: '`Value of i: 6`'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`i的值: 6`'
- en: '`Value of i: 7`'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`i的值: 7`'
- en: '`Value of i: 8`'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`i 的值：8`'
- en: '`Value of i: 9`'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`i 的值：9`'
- en: '`Value of i: 10`'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`i 的值：10`'
- en: 'Let''s first define our functions before starting to use them as shown in the
    following screenshot:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始使用这些函数之前，让我们首先定义它们，如下图所示：
- en: '![](img/00070.jpeg)**Figure 2:** An example of defining a higher-order function
    in Scala'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/00070.jpeg)**图 2：** 在 Scala 中定义高阶函数的示例'
- en: 'Now, let''s start by calling our higher-order function `applyFuncOnRange` and
    passing the `quarterMaker` function as a third argument:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始调用我们的高阶函数 `applyFuncOnRange` 并将 `quarterMaker` 函数作为第三个参数传递：
- en: '![](img/00074.jpeg)**Figure 3:** Calling a higher-order function'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/00074.jpeg)**图 3：** 调用高阶函数'
- en: 'We can even apply the other function `addTwo` since it has the same signature
    as shown in the following screenshot:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以应用另一个函数 `addTwo`，因为它具有与上图所示相同的签名：
- en: '![](img/00079.jpeg)**Figure 4:** An alternative way of calling a higher-order
    function'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/00079.jpeg)**图 4：** 调用高阶函数的另一种方式'
- en: 'Before going into more examples, let''s define what''s called a callback function.
    A callback function is a function that can be passed as an argument to another
    function. Other functions are simply normal functions. Let''s demonstrate more
    examples of using different callback functions. Consider the following higher-order
    function, which is responsible for transferring a specific amount of money from
    your account:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步讲解其他示例之前，我们先定义一下回调函数。回调函数是可以作为参数传递给其他函数的函数。其他函数则是普通函数。我们将通过更多的示例来演示如何使用不同的回调函数。考虑以下高阶函数，它负责从你的账户转账指定金额：
- en: '[PRE19]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After calling the `TransferMoney` function on 100:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在对 100 调用 `TransferMoney` 函数之后：
- en: '[PRE20]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下所示：
- en: '[PRE21]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: From a functional programming point of view, this code is not ready to be integrated
    into the banking system because you need to apply different validations on the
    money parameters, such as it has to be positive and greater than the specific
    amount specified by the bank. However, here we are just demonstrating the use
    of high-order functions and callback functions.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 从函数式编程的角度来看，这段代码尚未准备好集成到银行系统中，因为你需要对金额参数进行不同的验证，例如它必须是正数并且大于银行指定的特定金额。然而，在这里我们仅仅是演示高阶函数和回调函数的使用。
- en: 'So, this example works as follows: you want to transfer a specific amount of
    money to another bank account or money agent. The bank has a specific fee to be
    applied depending on the amount that you are transferring and here comes the role
    of the callback function. It takes the amount of money to transfer and applies
    the bank fee to it in order to come up with the total amount.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这个示例的工作原理如下：你想将一定金额的资金转账到另一个银行账户或钱款代理人。银行会根据你转账的金额收取特定费用，这时回调函数发挥了作用。它获取要转账的金额，并应用银行费用，以计算出总金额。
- en: 'The `TransferMoney` function takes two parameters: the first one is the money
    to be transferred and the second one is a callback function with the signature
    `Double => Double` that the function applies to the money argument to determine
    the bank fee over the transferred money.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`TransferMoney` 函数接受两个参数：第一个是要转账的金额，第二个是一个回调函数，其签名为 `Double => Double`，该函数应用于金额参数以确定转账金额的银行费用。'
- en: '![](img/00083.jpeg)**Figure 5:** Calling and giving extra power to the higher-order
    function'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/00083.jpeg)**图 5：** 调用并为高阶函数提供额外的功能'
- en: 'The complete source code of the preceding examples can be seen as follows (we
    called the methods using some real values):'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例的完整源代码如下所示（我们使用一些实际值来调用方法）：
- en: '[PRE22]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下所示：
- en: '[PRE23]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: By using callback functions, you are giving extra power to the higher-order
    function; so, it's a very powerful mechanism to make your program more elegant,
    flexible, and efficient.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用回调函数，你给高阶函数提供了额外的功能；因此，这是一个非常强大的机制，可以使你的程序更加优雅、灵活和高效。
- en: Function as a return value
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数作为返回值
- en: 'As mentioned, higher-order functions also support returning a function as a
    result. Let''s demonstrate this by an example:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，高阶函数还支持返回一个函数作为结果。我们通过一个示例来演示这一点：
- en: '[PRE24]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The preceding code segment will produce the following output:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码片段将输出以下内容：
- en: '[PRE25]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let''s run the previous example as shown in the following screenshot; it shows
    how to use the function as a return value:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行之前的示例，如下图所示；它展示了如何将函数作为返回值使用：
- en: '![](img/00087.jpeg)**Figure 7:** Function as a return value'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/00087.jpeg)**图 7：** 函数作为返回值'
- en: 'The complete code of the preceding example can be seen as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 前面示例的完整代码如下：
- en: '[PRE26]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '[PRE27]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Now before stopping our discussion on HFO, let's see a real-life example, that
    is, currying using HFO.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束我们关于高阶函数的讨论之前，来看看一个实际的例子，也就是使用高阶函数进行柯里化。
- en: Using higher-order functions
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用高阶函数
- en: 'Suppose you work in a restaurant as a chef and one of your colleagues ask you
    a question: Implement a **HOF** (**higher-order function**) that performs currying.
    Looking for clues? Suppose you have the following two signatures for your HOF:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在餐厅做厨师，某个同事问你一个问题：实现一个**高阶函数**（**HOF**）来执行柯里化。需要线索吗？假设你有以下两个高阶函数的签名：
- en: '[PRE28]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Similarly, implement a function that performs uncurrying as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，按如下方式实现一个执行反柯里化的函数：
- en: '[PRE29]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, how could you use HOFs to perform the currying operation? Well, you could
    create a trait that encapsulates the signatures of two HOFs (that is, curry and
    uncurry) as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如何使用高阶函数来执行柯里化操作呢？你可以创建一个特征，它封装了两个高阶函数（即柯里化和反柯里化）的签名，如下所示：
- en: '[PRE30]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, you can implement and extend this trait as an object as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以按照以下方式实现并扩展这个特征作为一个对象：
- en: '[PRE31]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here I have implemented the uncurry first since it's easier. The two curly braces
    after the equals sign are an anonymous function literal for taking two arguments
    (that is, `a` and `b` of types `X` and `Y` respectively). Then, these two arguments
    can be used in a function that also returns a function. Then, it passes the second
    argument to the returned function. Finally, it returns the value of the second
    function. The second function literal takes one argument and returns a new function,
    that is, `curry()`. Eventually, it returns a function when called returns another
    function.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我先实现了反柯里化，因为它更简单。等号后面的两个大括号是一个匿名函数字面量，用来接受两个参数（即类型为 `X` 和 `Y` 的 `a` 和 `b`）。然后，这两个参数可以用于一个返回函数的函数中。接着，它将第二个参数传递给返回的函数。最后，返回第二个函数的值。第二个函数字面量接受一个参数并返回一个新函数，也就是
    `curry()`。最终，当调用时，它返回一个函数，而该函数再返回另一个函数。
- en: 'Now it comes: how to use the preceding object that extends the base trait in
    a real-life implementation. Here''s an example:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来看看如何在实际应用中使用前面的对象，该对象扩展了基础特征。这里有一个例子：
- en: '[PRE32]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In the preceding object and inside the main method:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的对象中以及主方法内部：
- en: The `addSpicy` holds a function that takes a long as a type and adds 1 to it
    and then prints 4.0.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`addSpicy` 保存了一个函数，该函数接受一个长整型并将其加 1，然后打印出 4.0。'
- en: The `increment` holds a function which takes a long as a type and adds 2 to
    it and finally prints 3.0.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`increment` 保存了一个函数，该函数接受一个长整型并将其加 2，最后打印出 3.0。'
- en: The `unspicedAdd` holds a function which adds 1 and takes a long as type. Finally,
    it prints 7.0.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unspicedAdd` 保存了一个函数，该函数将 1 加到一个长整型上，最后打印出 7.0。'
- en: 'The output of the preceding code is as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '[PRE33]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In mathematics and computer science, currying is the technique of translating
    the evaluation of a function that takes multiple arguments (or a tuple of arguments)
    into evaluating a sequence of functions, each with a a single argument. Currying
    is related to, but not the same as, partial application:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学和计算机科学中，柯里化是一种技术，它将一个接受多个参数（或一个元组的参数）的函数的求值转换为一系列函数的求值，每个函数只接受一个参数。柯里化与部分应用相关，但不同于部分应用：
- en: '**Currying:** Currying is useful in both practical and theoretical settings.
    In functional programming languages, and many others, it provides a way of automatically
    managing how arguments are passed to functions and exceptions. In theoretical
    computer science, it provides a way to study functions with multiple arguments
    in simpler theoretical models, which provide only one argument.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**柯里化：** 柯里化在实践和理论环境中都非常有用。在函数式编程语言以及许多其他编程语言中，柯里化提供了一种自动管理函数参数传递和异常的方式。在理论计算机科学中，它提供了一种简化理论模型的方式来研究具有多个参数的函数，这些模型只接受一个参数。'
- en: '**Uncurrying:** Uncurrying is the dual transformation to currying, and can
    be seen as a form of defunctionalization. It takes a function `f` whose return
    value is another function `g` and yields a new function `f′` that takes as parameters
    the arguments for both `f` and `g`, and returns, as a result, the application
    of `f` and subsequently, `g`, to those arguments. The process can be iterated.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**去柯里化：** 去柯里化是柯里化的对偶变换，可以看作是一种去功能化的形式。它接收一个返回值为另一个函数 `g` 的函数 `f`，并生成一个新的函数
    `f′`，该函数接受 `f` 和 `g` 的参数，并返回 `f` 和随后 `g` 对这些参数的应用。这个过程可以反复进行。'
- en: So far, we have seen how to deal with pure, higher-order, and anonymous functions
    in Scala. Now, let's have a brief overview on how to extend the higher-order function
    using `Throw`, `Try`, `Either`, and `Future` in the following section.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了如何处理 Scala 中的纯函数、高阶函数和匿名函数。接下来，我们简要概述如何使用 `Throw`、`Try`、`Either`
    和 `Future` 扩展高阶函数。
- en: Error handling in functional Scala
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式 Scala 中的错误处理
- en: So far, we focused on ensuring that the body of a Scala function does what it's
    supposed to and doesn't do anything else (that is, an error or exception). Now,
    in order to make use of any programming and to avoid producing error-prone code
    then you need to know how to catch exceptions and handle errors in this language.
    We will see how to extend higher-order functions outside collections using some
    special features of Scala such as `Try`, `Either`, and `Future`.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们专注于确保 Scala 函数的主体完成预定任务且不执行其他操作（即不出现错误或异常）。现在，为了有效使用编程并避免生成易出错的代码，你需要了解如何捕获异常并处理语言中的错误。我们将看到如何利用
    Scala 的一些特殊功能，如 `Try`、`Either` 和 `Future`，扩展高阶函数，超出集合的范围。
- en: Failure and exceptions in Scala
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala 中的失败和异常
- en: 'At first, let''s define what we mean by failures in general (source: [https://tersesystems.com/2012/12/27/error-handling-in-scala/](https://tersesystems.com/2012/12/27/error-handling-in-scala/)):'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义一般情况下的失败含义（来源：[https://tersesystems.com/2012/12/27/error-handling-in-scala/](https://tersesystems.com/2012/12/27/error-handling-in-scala/)）：
- en: '**Unexpected internal failure**: The operation fails as the result of an unfulfilled
    expectation, such as a null pointer reference, violated assertions, or simply
    bad state'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**意外的内部失败：** 操作因未满足的期望而失败，例如空指针引用、违反的断言或简单的错误状态。'
- en: '**Expected internal failure**: The operation fails deliberately as a result
    of internal state, that is, a blacklist or circuit breaker'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预期的内部失败：** 操作故意由于内部状态而失败，例如黑名单或断路器。'
- en: '**Expected external failure**: The operation fails because it is told to process
    some raw input, and will fail if the raw input cannot be processed'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预期的外部失败：** 操作因为被要求处理某些原始输入而失败，如果原始输入无法处理，则会失败。'
- en: '**Unexpected external failure**: The operation fails because a resource that
    the system depends on is not there: there''s a loose file handle, the database
    connection fails, or the network is down'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**意外的外部失败：** 操作因系统依赖的资源不存在而失败：例如文件句柄丢失、数据库连接失败或网络中断。'
- en: 'Unfortunately, there are no concrete ways of stopping failures unless the failures
    are due to some manageable exceptions. On the other hand, Scala makes *checked
    versus unchecked* very simple: it doesn''t have checked exceptions. All exceptions
    are unchecked in Scala, even `SQLException` and `IOException`, and so on. Now
    let''s see how to handle such exceptions at least.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，除非失败源于某些可管理的异常，否则没有具体方法可以停止失败。另一方面，Scala 使得*已检查与未检查*变得非常简单：它没有已检查的异常。在
    Scala 中，所有异常都是未检查的，甚至是 `SQLException` 和 `IOException` 等。因此，接下来我们将看看如何至少处理这些异常。
- en: Throwing exceptions
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 抛出异常
- en: 'A Scala method can throw an exception because of the unexpected workflow. You
    create an exception object and then you throw it with the throw keyword as follows.
    For example:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 方法可能会因意外的工作流而抛出异常。你可以创建一个异常对象，然后使用 `throw` 关键字抛出它，示例如下：
- en: '[PRE34]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Note that the primary goal of using exception handling is not to produce friendly
    messages but to exit the normal flow of your Scala program.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，使用异常处理的主要目标不是生成友好的消息，而是中断 Scala 程序的正常流程。
- en: Catching exception using try and catch
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 `try` 和 `catch` 捕获异常
- en: 'Scala allows you to try/catch any exception in a single block and then perform
    pattern matching against it using case blocks. The basic syntax of using `try...catch`
    in Scala is as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 允许你在一个代码块中使用 `try...catch` 捕获任何异常，并使用 `case` 块对其进行模式匹配。使用 `try...catch`
    的基本语法如下：
- en: '[PRE35]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Thus, if you throw an exception, then you need to use the `try...catch` block
    in order to handle it nicely without crashing with an internal exception message:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你抛出异常，那么你需要使用`try...catch`块来优雅地处理它，而不会崩溃并显示内部异常消息：
- en: '[PRE36]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If there''s no file named `data.txt`, in the path/data under your project tree,
    you will experience `FileNotFoundException` as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在你的项目树的路径/data下没有名为`data.txt`的文件，你将遇到如下的`FileNotFoundException`：
- en: 'The output of the preceding code is as follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '[PRE37]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Now, let's have a brief example of using the `finally` clause in Scala to make
    the `try...catch` block complete.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一个简单的示例来展示如何在 Scala 中使用`finally`子句，以使`try...catch`块完整。
- en: Finally
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后
- en: 'Suppose you want to execute your code regardless of an exception being thrown
    or not, then you should use the `finally` clause. You can place it inside the
    `try block` as follows. Here is an example:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你希望无论是否抛出异常，都执行你的代码，那么你应该使用`finally`子句。你可以像下面这样将它放在`try块`内部。以下是一个示例：
- en: '[PRE38]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, here''s the complete example of using `try...catch...finally`:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这是使用`try...catch...finally`的完整示例：
- en: '[PRE39]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '[PRE40]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Next, we will discuss another powerful feature in Scala called `Either`.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论 Scala 中的另一个强大特性——`Either`。
- en: Creating an Either
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个Either
- en: '`Either[X, Y]` is an instance that contains either an instance of `X` or an
    instance of `Y` but not both. We call these subtypes left and right of Either.
    Creating an Either is trivial. But it''s very powerful sometimes to use it in
    your program:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '`Either[X, Y]`是一个实例，它包含`X`或`Y`中的一个实例，但不能同时包含两个实例。我们将这两个子类型称为Either的左侧和右侧。创建一个Either很简单。但有时在程序中使用它是非常强大的：'
- en: '[PRE41]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, if we pass any arbitrary URL that doesn''t contain `xxx` then we will
    get a `Scala.io.Source` wrapped in a `Right` subtype. If the URL contains `xxx`,
    then we will get a `String` wrapped in a `Left` subtype. To make the preceding
    statement clearer, let''s see the output of the preceding code segment:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们传递任何不包含`xxx`的任意 URL，我们将得到一个被`Right`子类型封装的`Scala.io.Source`。如果 URL 包含`xxx`，那么我们将得到一个被`Left`子类型封装的`String`。为了让前述语句更清楚，让我们看看前面代码段的输出：
- en: '[PRE42]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Next, we will explore another interesting feature of Scala called `Future` that
    is used to execute tasks in a non-blocking way. This is also a better way to handle
    the results when they finish.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探索 Scala 的另一个有趣特性——`Future`，它用于以非阻塞的方式执行任务。这也是在任务完成后处理结果的更好方法。
- en: Future
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Future
- en: If you simply want to run tasks in a non-blocking way and need a way to handle
    the results when they finish, Scala provides you with Futures, for example, if
    you want to make multiple web service calls in a parallel fashion and work with
    the results after the web service handles all these calls. An example of using
    Future is provided in the following section.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仅仅想以非阻塞的方式运行任务，并且需要在任务完成后处理结果，Scala为你提供了Futures。例如，如果你想并行地进行多个 Web 服务调用，并在
    Web 服务处理完所有这些调用后与结果一起工作。以下部分将提供一个使用 Future 的示例。
- en: Run one task, but block
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行一个任务，但进行阻塞
- en: 'The following example demonstrates how to create a Future and then block the
    sequence of execution in order to wait for its result. Creating Futures is trivial.
    You just need to pass it to the code that you want. The following example performs
    2+2 in the future and then returns the results:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了如何创建一个 Future，然后通过阻塞执行序列来等待其结果。创建 Futures 很简单。你只需要将它传递给你想要的代码。以下示例在未来执行2+2，然后返回结果：
- en: '[PRE43]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The `Await.result` method waits up to 2 seconds till the `Future` returns the
    result; if it doesn''t return the result within 2 seconds, it throws the following
    exception you might want to handle or catch:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '`Await.result`方法等待最多2秒，直到`Future`返回结果；如果它在2秒内没有返回结果，它会抛出以下异常，你可能想要处理或捕获该异常：'
- en: '[PRE44]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: It's time to wrap up this chapter. However, I would like to take the chance
    to discuss an important view of mine about functional programming with Scala and
    object mutability.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候总结这一章了。然而，我想借此机会讨论一下我对 Scala 中函数式编程与对象可变性的重要看法。
- en: Functional programming and data mutability
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式编程与数据可变性
- en: Pure functional programming is one of the best practices in functional programming
    and you should stick to it. Writing pure functions will make your programming
    life easier and you will be able to write code that's easy to maintain and extend.
    Also, if you want to parallelize your code then it will be easier to do so if
    you write pure functions.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 纯函数式编程是函数式编程中的最佳实践之一，你应该坚持使用它。编写纯函数将使你的编程生活更加轻松，你将能够编写易于维护和扩展的代码。此外，如果你希望并行化代码，编写纯函数将使这一过程更加简单。
- en: If you're an FP purist, one drawback of using functional programming in Scala
    is that Scala supports both OOP and FP (see *Figure 1*), and therefore it's possible
    to mix the two coding styles in the same code base. In this chapter, we have seen
    several examples showing that writing pure functions is easy. However, combining
    them into a complete application is difficult. You might agree that advanced topics
    such as monads make FP intimidating.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一个函数式编程（FP）的纯粹主义者，使用 Scala 进行函数式编程的一个缺点是 Scala 同时支持面向对象编程（OOP）和函数式编程（FP）（见*图
    1*），因此有可能在同一代码库中混合使用这两种编程风格。在本章中，我们看到了几个例子，展示了编写纯函数是容易的。然而，将它们组合成一个完整的应用程序却很困难。你可能会同意，像单子这样的高级主题使得函数式编程看起来令人畏惧。
- en: I talked to many people and they think that the recursion doesn't feel reasonably
    natural. When you use immutable objects, you can never mutate them with something
    else. There aren't times when you are allowed to do that. That's the whole point
    of immutable objects! Sometimes what I have experienced is that a pure function
    and data input or output really mixes up. However, when you need to mutate, you
    can create a copy of the object containing your mutated field. Thus, theoretically,
    there's no need to *mix up*. Lastly, using only immutable values and recursion
    can potentially lead to performance problems in terms of CPU usage and RAM.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我和很多人谈过，他们认为递归并不自然。当你使用不可变对象时，你永远不能用其他方式修改它们。你不会有任何时刻允许这样做。这就是不可变对象的关键所在！有时候，我发现纯函数和数据的输入或输出会混淆。然而，当你需要修改时，你可以创建一个包含你修改过字段的对象副本。因此，从理论上讲，*不会混淆*。最后，只有使用不可变值和递归可能会导致
    CPU 使用和内存的性能问题。
- en: Summary
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have explored some functional programming concepts in Scala.
    We have seen what functional programming is and how Scala supports it, why it
    matters, and the advantages of using functional concepts. We have seen why learning
    FP concepts is important in learning the Spark paradigm. Pure functions, anonymous
    functions, and higher-order functions were discussed with suitable examples. Later
    in this chapter, we saw how to handle exceptions in the higher-order functions
    outside collections using the standard library of Scala. Finally, we discussed
    how functional Scala affects object mutability.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了一些 Scala 中的函数式编程概念。我们了解了什么是函数式编程以及 Scala 如何支持它，为什么它很重要，以及使用函数式概念的优点。我们还看到了学习函数式编程概念对学习
    Spark 范式的重要性。我们讨论了纯函数、匿名函数和高阶函数，并通过适当的例子进行了讲解。接着，在本章后面，我们讨论了如何使用 Scala 的标准库在集合外的高阶函数中处理异常。最后，我们讨论了函数式
    Scala 如何影响对象的可变性。
- en: In the next chapter, we will provide an in-depth analysis on the Collections
    API, one of the most prominent features of the standard library.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将对标准库中最突出特性之一——集合 API 进行深入分析。
