- en: Designing a Machine Learning System
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计一个机器学习系统
- en: In this chapter, we will design a high-level architecture for an intelligent,
    distributed machine learning system that uses Spark as its core computation engine.
    The problem we will focus on will be taking the existing architecture for a web-based
    business and redesigning it to use automated machine learning systems to power
    key areas of the business.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将为一个智能的、分布式的机器学习系统设计一个高层架构，该系统以Spark作为其核心计算引擎。我们将专注于采用自动化机器学习系统来支持业务的关键领域，对现有的基于Web的业务架构进行重新设计。
- en: Before we dig deeper into our scenario, we will spend some time understanding
    what machine learning is.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入研究我们的场景之前，我们将花一些时间了解机器学习是什么。
- en: 'Then we will:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将：
- en: Introduce a hypothetical business scenario
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍一个假设的业务场景
- en: Provide an overview of the current architecture
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供当前架构的概述
- en: Explore various ways in which machine learning systems can enhance or replace
    certain business functions
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索机器学习系统可以增强或替代某些业务功能的各种方式
- en: Provide a new architecture based on these ideas
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于这些想法提供一个新的架构
- en: 'A modern large-scale data environment includes the following requirements:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现代大规模数据环境包括以下要求：
- en: It must integrate with the other components of the system, especially with data
    collection and storage systems, analytics and reporting, and frontend applications
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它必须与系统的其他组件集成，特别是与数据收集和存储系统、分析和报告以及前端应用程序集成
- en: It should be easily scalable and independent of the rest of the architecture.
    Ideally, this should be in the form of horizontal as well as vertical scalability
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该易于扩展，并且独立于其他架构。理想情况下，这应该以水平和垂直可扩展的形式存在
- en: It should allow efficient computation with respect to the type of workload in
    mind, that is, machine learning and iterative analytics applications
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该允许对所考虑的工作负载类型进行有效的计算，即机器学习和迭代分析应用
- en: If possible, it should support both batch and real-time workload
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可能的话，它应该支持批处理和实时工作负载
- en: As a framework, Spark meets these criteria. However, we must ensure that the
    machine learning systems designed on Spark also meet this criteria. There is no
    good in implementing an algorithm that ends up having bottlenecks that cause our
    system to fail in terms of one or more of these requirements.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个框架，Spark符合这些标准。然而，我们必须确保在Spark上设计的机器学习系统也符合这些标准。实施一个最终导致我们的系统在这些要求中的一个或多个方面失败的算法是没有意义的。
- en: What is Machine Learning?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: Machine learning is a subfield of data mining. While data mining has been around
    for more than 50+ years, machine learning is a subset where a large cluster of
    machines is used to analyze and extract knowledge from large datasets.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是数据挖掘的一个子领域。虽然数据挖掘已经存在了50多年，但机器学习是一个子集，其中使用大量机器来分析和从大型数据集中提取知识。
- en: Machine learning is closely related to computational statistics. It has strong
    ties to mathematical optimization; it provides methods, theory, and application
    domains to the field. Machine learning is employed in various types of computing
    tasks where designing and programming explicit algorithms are infeasible. Example
    applications are spam filtering, **optical character recognition** (**OCR**),
    search engine, and computer vision. Machine learning is sometimes combined with
    data mining, which focuses more on exploratory data analysis and is known as unsupervised
    learning.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习与计算统计密切相关。它与数学优化有着密切的联系；它为该领域提供了方法、理论和应用领域。机器学习被应用于各种类型的计算任务，其中设计和编程明确算法是不可行的。示例应用包括垃圾邮件过滤、光学字符识别（OCR）、搜索引擎和计算机视觉。机器学习有时与数据挖掘结合使用，后者更注重探索性数据分析，被称为无监督学习。
- en: Machine learning systems can be classified into three categories, depending
    on the nature of the learning signal available to a learning system. Learning
    algorithm discovers structure from the input provided. It can have a goal (hidden
    patterns), or it could be a means try to find features.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 根据学习系统可用的学习信号的性质，机器学习系统可以分为三类。学习算法从提供的输入中发现结构。它可以有一个目标（隐藏的模式），或者它可以是一种试图找到特征的手段。
- en: '**Unsupervised learning**: No labels of outputs are given to the learning system.
    It finds structure on its own from the inputs given to'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习：学习系统没有给出输出的标签。它自己从给定的输入中找到结构
- en: '**Supervised learning**: The system is presented with inputs and desired outputs
    by a human and the goal is to learn a model to map inputs to outputs'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习：系统由人类提供输入和期望的输出，目标是学习一个模型将输入映射到输出
- en: '**Reinforcement learning**: The system interacts with an environment in which
    it performs a stated goal without a human explicitly telling it whether it has
    come close to its goal'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习：系统与环境互动，在没有人明确告诉它是否接近目标的情况下，执行一个规定的目标
- en: In the later sections, we will map supervised and unsupervised learning to various
    chapters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在后面的章节中，我们将把监督学习和无监督学习映射到各个章节。
- en: Introducing MovieStream
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍MovieStream
- en: To better illustrate the design of our architecture, we will introduce a practical
    scenario. Let's assume that we have just been appointed to head the data science
    team of MovieStream, a fictitious Internet business that streams movies and television
    shows to its users.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地说明我们架构的设计，我们将介绍一个实际的场景。假设我们刚刚被任命为MovieStream的数据科学团队负责人，MovieStream是一个虚构的互联网业务，向用户提供流媒体电影和电视节目。
- en: 'MovieStream system is outlined in the following diagram:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: MovieStream系统概述如下图所示：
- en: '![](img/image_03_001.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_03_001.png)'
- en: MovieStream's current architecture
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: MovieStream的当前架构
- en: As we can see in the preceding diagram, currently, MovieStream's content editorial
    team is responsible for deciding which movies and shows are promoted and shown
    in various parts of the site. They are also responsible for creating the content
    for MovieStream's bulk marketing campaigns, which include e-mail and other direct
    marketing channels. Currently, MovieStream collects basic data on what titles
    are viewed by users on an aggregate basis and has access to some demographic data
    collected from users when they sign up to the service. In addition, they have
    access to some basic metadata about the titles in their catalog.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的图表中所看到的，目前，MovieStream的内容编辑团队负责决定在网站的各个部分推广和展示哪些电影和节目。他们还负责为MovieStream的大规模营销活动创建内容，其中包括电子邮件和其他直接营销渠道。目前，MovieStream基本上收集了用户在聚合基础上观看的标题的基本数据，并且可以访问用户在注册服务时收集的一些人口统计数据。此外，他们可以访问其目录中标题的一些基本元数据。
- en: MovieStream can handle many of the functions currently handled by the content
    team in an automated manner.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: MovieStream可以以自动化的方式处理许多目前由内容团队处理的功能。
- en: Business use cases for a machine learning system
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习系统的业务用例
- en: Perhaps the first question we should answer is, *Why* *to use machine learning
    at all?*
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 也许我们应该回答的第一个问题是，“为什么要使用机器学习？”
- en: 'Why doesn''t MovieStream simply continue with human-driven decisions? There
    are many reasons to use machine learning (and certainly some reasons not to),
    but the most important ones are mentioned here:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么MovieStream不简单地继续人为决策？使用机器学习有许多原因（当然也有一些原因不使用），但最重要的原因在这里提到：
- en: The scale of data involved means that full human involvement quickly becomes
    infeasible as MovieStream grows
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 涉及的数据规模意味着随着MovieStream的增长，完全依赖人类参与很快变得不可行。
- en: Model-driven approaches such as machine learning and statistics can often benefit
    from uncovering patterns that cannot be seen by humans (due to the size and complexity
    of the datasets)
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于模型驱动的方法，如机器学习和统计学，通常可以从数据集的规模和复杂性导致人类无法发现的模式中受益。
- en: Model-driven approaches can avoid human and emotional biases (as long as the
    correct processes are carefully applied)
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型驱动的方法可以避免人为和情感偏见（只要正确的流程得到仔细应用）。
- en: However, there is no reason why both model-driven and human-driven processes
    and decision making cannot coexist. For example, many machine learning systems
    rely on receiving labeled data in order to train models. Often, labeling such
    data is costly, time consuming, and requires human input. A good example of this
    is classifying textual data into categories or assigning a sentiment indicator
    to the text. Many real-world systems use some form of human-driven system to generate
    labels for such data (or at least part of it) to provide training data to models.
    These models are then used to make predictions in the live system at a larger
    scale.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并没有理由为什么模型驱动和人为驱动的流程和决策不能共存。例如，许多机器学习系统依赖于接收标记数据来训练模型。通常，标记这样的数据是昂贵的、耗时的，并需要人类的输入。这种情况的一个很好的例子是将文本数据分类到类别中或为文本分配情感指标。许多现实世界的系统使用某种形式的人为驱动系统来为这样的数据生成标签（或至少部分）以为模型提供训练数据。然后这些模型用于在更大规模的实时系统中进行预测。
- en: In the context of MovieStream, we need not fear that our machine learning system
    will make the content team redundant. Indeed, we will see that our aim is to lift
    the burden of time-consuming tasks where machine learning might be able to perform
    better while providing tools to allow the team to better understand the users
    and content. This might, for example, help them in selecting which new content
    to acquire for the catalog (which involves a significant amount of cost and is,
    therefore, a critical aspect of the business).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在MovieStream的背景下，我们不必担心我们的机器学习系统会使内容团队变得多余。事实上，我们将看到我们的目标是减轻耗时的任务负担，让机器学习能够更好地执行，同时提供工具让团队更好地了解用户和内容。例如，这可能帮助他们选择要为目录获取的新内容（这涉及相当大的成本，因此是业务的关键方面）。
- en: Personalization
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 个性化
- en: Perhaps one of the most important potential applications of machine learning
    in MovieStream's business is personalization. Generally speaking, personalization
    refers to adapting the experience of a user and the content presented to them
    based on various factors, which might include user behavior data as well as external
    factors.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在MovieStream业务中，机器学习最重要的潜在应用之一是个性化。一般来说，个性化是指根据各种因素调整用户的体验和呈现给他们的内容，这些因素可能包括用户行为数据以及外部因素。
- en: '**Recommendations** are essentially a subset of personalization. Recommendation
    generally refers to presenting a user with a list of items that we hope the user
    will be interested in. Recommendations might be used in web pages (for example,
    recommendation-related products), via e-mails or other direct marketing channels,
    via mobile apps, and so on.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**推荐**本质上是个性化的一个子集。推荐通常指向用户呈现一系列我们希望用户感兴趣的项目。推荐可以用于网页（例如，相关产品的推荐），通过电子邮件或其他直接营销渠道，通过移动应用程序等等。'
- en: Personalization is very similar to recommendations, but while recommendations
    are usually focused on an *explicit* presentation of products or content to the
    user, personalization is more generic and, often, more *implicit*. For example,
    applying personalization to search on the MovieStream site might allow us to adapt
    the search results for a given user, based on the data available about that user.
    This might include recommendation-based data (in the case of a search for products
    or content) but might also include various other factors such as geolocation and
    past search history. It might not be apparent to the user that the search results
    are adapted to their specific profile; this is why personalization tends to be
    more implicit.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 个性化与推荐非常相似，但推荐通常专注于向用户明确呈现产品或内容，而个性化更加通用，通常更加隐含。例如，将个性化应用于MovieStream网站的搜索可能允许我们根据关于用户的可用数据，调整给定用户的搜索结果。这可能包括基于推荐的数据（在搜索产品或内容的情况下），但也可能包括各种其他因素，如地理位置和过去的搜索历史。用户可能不会意识到搜索结果是针对其特定配置文件进行调整；这就是为什么个性化往往更加隐含。
- en: Targeted marketing and customer segmentation
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定向营销和客户分割
- en: In a manner similar to recommendations, targeted marketing uses a model to select
    what to target at users. While generally recommendations and personalization are
    focused on a one-to-one situation, segmentation approaches might try to assign
    users into groups based on characteristics and, possibly, behavioral data. The
    approach might be fairly simple or might involve approaches that try to assign
    users into groups based on characteristics and, possibly, behavioral data. The
    approach might be fairly simple or might involve a machine-learning model such
    as clustering. Either way, the result is a set of segment assignments that might
    allow us to understand the broad characteristics of each group of users, what
    makes them similar to each other within a group, and what makes them different
    from others in different groups.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 与推荐类似，定向营销使用模型来选择针对用户的目标。虽然通常推荐和个性化专注于一对一的情况，分割方法可能会尝试根据特征和可能的行为数据将用户分配到组中。这种方法可能相当简单，也可能涉及尝试根据特征和可能的行为数据将用户分配到组中的机器学习模型，如聚类。无论哪种方式，结果都是一组分段分配，这可能使我们能够了解每个用户组的广泛特征，了解在组内使他们相似的因素，以及了解使他们与其他组中的其他人不同的因素。
- en: This could help MovieStream to better understand the drivers of user behavior
    and might also allow a broader targeting approach where groups are targeted as
    opposed to (or more likely, in addition to) direct one-to-one targeting with personalization.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以帮助MovieStream更好地了解用户行为的驱动因素，也可能允许更广泛的定位方法，其中以组为目标，而不是（或更可能是，除了）个性化的直接一对一定位。
- en: These methods can also help when we don't necessarily have labeled data available
    (as is the case with certain user and content profile data), but we still wish
    to perform more focused targeting than a complete one-size-fits-all approach.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法也可以在我们不一定有标记数据可用的情况下（例如某些用户和内容配置文件数据），但我们仍希望执行比完全一刀切方法更加集中的定位时提供帮助。
- en: Predictive modeling and analytics
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测建模和分析
- en: A third area where machine learning can be applied is in predictive analytics.
    This is a very broad term, and in some ways, it encompasses recommendations, personalization,
    and targeting too. In this context, since recommendations and segmentation are
    somewhat distinct, we use the term **predictive modeling** to refer to other models
    that seek to make predictions. An example of this can be a model that predicts
    the potential viewing activity and revenue of new titles before any data is available
    on how popular the title might be. MovieStream can use past activity and revenue
    data, together with content attributes, to create a regression model that can
    be used to make predictions for brand new titles.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习可以应用的第三个领域是预测分析。这是一个非常广泛的术语，在某种程度上，它也包括推荐、个性化和定位。在这种情况下，由于推荐和分割有些不同，我们使用术语“预测建模”来指代寻求进行预测的其他模型。一个例子是一个模型，可以在任何关于标题可能受欢迎程度的数据可用之前，预测新标题的潜在观看活动和收入。MovieStream可以利用过去的活动和收入数据，以及内容属性，创建一个回归模型，可以用来预测全新标题的情况。
- en: As another example, we can use a **classification model** to automatically assign
    tags, keywords, or categories to new titles for which we only have partial data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是，我们可以使用分类模型自动为我们只有部分数据的新标题分配标签、关键词或类别。
- en: Types of machine learning models
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型的类型
- en: While we have one example, there are many other examples, some of which we will
    touch on in the relevant chapters when we introduce each machine learning task.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们有一个例子，但还有许多其他例子，其中一些我们将在相关章节中介绍每个机器学习任务时进行介绍。
- en: 'However, we can broadly divide the preceding use cases and methods into two
    categories of machine learning:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以广泛地将前述用例和方法分为两类机器学习：
- en: '**Supervised learning**: These types of models use labeled data to learn. Recommendation
    engines, regression, and classification are examples of supervised learning methods.
    The labels in these models can be user--movie ratings (for the recommendation),
    movie tags (in the case of the preceding classification example), or revenue figures
    (for regression). We will cover supervised learning models in [Chapter 4](d3bf76a8-26be-4db7-8310-b936d220407e.xhtml),
    *Building a Recommendation Engine with Spark*, [Chapter 6](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml),
    *Building a Classification Model with Spark*, and [Chapter 7](5df7d44a-d025-448b-826d-75c44ee7a165.xhtml),
    *Building a Regression Model with Spark*.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**：这些类型的模型使用标记数据进行学习。推荐引擎、回归和分类是监督学习方法的例子。这些模型中的标签可以是用户-电影评分（用于推荐）、电影标签（在前述分类示例中）、或收入数字（用于回归）。我们将在[第4章](d3bf76a8-26be-4db7-8310-b936d220407e.xhtml)中介绍监督学习模型，*使用Spark构建推荐引擎*，[第6章](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml)，*使用Spark构建分类模型*，和[第7章](5df7d44a-d025-448b-826d-75c44ee7a165.xhtml)，*使用Spark构建回归模型*。'
- en: '**Unsupervised learning**: When a model does not require labeled data, we refer
    to unsupervised learning. These types of models try to learn or extract some underlying
    structure in the data or reduce the data down to its most important features.
    Clustering, dimensionality reduction, and some forms of feature extraction, such
    as text processing, are all unsupervised techniques and will be dealt with in
    [Chapter 8](7b684d30-421c-4874-a5e6-6f6d57d93405.xhtml), *Building a Clustering
    Model with Spark*, [Chapter 9](a164696f-86f1-4ed6-919d-d24a2f29385f.xhtml), *Dimensionality
    Reduction with Spark*, and [Chapter 10](789e8b8c-28e8-444d-92a6-aace3a4dfdd6.xhtml),
    *Advanced Text Processing with Spark*.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**：当模型不需要标记数据时，我们称之为无监督学习。这些类型的模型试图学习或提取数据中的一些潜在结构，或将数据减少到其最重要的特征。聚类、降维和一些形式的特征提取，如文本处理，都是无监督技术，将在[第8章](7b684d30-421c-4874-a5e6-6f6d57d93405.xhtml)，*使用Spark构建聚类模型*，[第9章](a164696f-86f1-4ed6-919d-d24a2f29385f.xhtml)，*使用Spark进行降维*，和[第10章](789e8b8c-28e8-444d-92a6-aace3a4dfdd6.xhtml)，*使用Spark进行高级文本处理*中进行讨论。'
- en: The components of a data-driven machine learning system
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据驱动机器学习系统的组件
- en: The high-level components of our machine learning system are outlined in the
    following diagram. This diagram illustrates the machine learning pipeline from
    which we obtain data and in which we store data. We then transform it into a form
    that is usable as input to a machine learning model; train, test, and refine our
    model; and then, deploy the final model to our production system. The process
    is then repeated as new data is generated.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们机器学习系统的高级组件如下图所示。该图说明了我们获取数据和存储数据的机器学习流程。然后我们将其转换为可用作机器学习模型输入的形式；训练、测试和改进我们的模型；然后将最终模型部署到我们的生产系统。随着新数据的生成，该过程将重复进行。
- en: '![](img/image_03_002.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_03_002.png)'
- en: A general machine-learning pipeline
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一个通用的机器学习流程
- en: Data ingestion and storage
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据摄入和存储
- en: The first step in our machine learning pipeline will be taking in the data that
    we require for training our models. Like many other businesses, MovieStream's
    data is typically generated by user activity, other systems (this is commonly
    referred to as machine-generated data), and external sources (for example, the
    time of day and weather during a particular user's visit to the site).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们机器学习流程的第一步将是获取我们训练模型所需的数据。与许多其他企业一样，MovieStream的数据通常由用户活动、其他系统（通常称为机器生成的数据）和外部来源（例如某个用户访问网站时的时间和天气）生成。
- en: This data can be ingested in various ways, for example, gathering user activity
    data from the browser and mobile application event logs or accessing external
    web APIs to collect data on geolocation or weather.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据可以通过各种方式进行摄入，例如从浏览器和移动应用事件日志中收集用户活动数据，或访问外部Web API来收集地理位置或天气数据。
- en: Once the collection mechanisms are in place, the data usually needs to be stored.
    This includes the raw data, data resulting from intermediate processing, and final
    model results to be used in production.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦收集机制就位，通常需要存储数据。这包括原始数据、中间处理产生的数据以及最终模型结果，用于生产环境中。
- en: Data storage can be complex and involve a wide variety of systems, including
    HDFS, Amazon S3, and other filesystems; SQL databases such as MySQL or PostgreSQL;
    distributed NoSQL data stores such as HBase, Cassandra, and DynamoDB; and search
    engines such as Solr or Elasticsearch to stream data systems such as Kafka, Flume,
    or Amazon Kinesis.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 数据存储可能会很复杂，涉及各种系统，包括HDFS、Amazon S3和其他文件系统；诸如MySQL或PostgreSQL的SQL数据库；分布式NoSQL数据存储，如HBase、Cassandra和DynamoDB；以及Solr或Elasticsearch等搜索引擎，用于流数据系统，如Kafka、Flume或Amazon
    Kinesis。
- en: For the purposes of this book, we will assume that the relevant data is available
    to us, so we will focus on the processing and modeling steps in the following
    pipeline.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本书的目的，我们将假设相关数据对我们可用，因此我们将专注于以下流程中的处理和建模步骤。
- en: Data cleansing and transformation
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清洗和转换
- en: The majority of machine learning algorithms operate on features, which are typically
    numerical representations of the input variables that will be used for the model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习算法都是基于特征操作的，这些特征通常是输入变量的数值表示，将用于模型。
- en: While we might want to spend the majority of our time exploring machine learning
    models, data collected via various systems and sources in the preceding ingestion
    step is, in most cases, in a raw form. For example, we might log user events such
    as details of when a user views the information page for a movie, when they watch
    a movie, or when they provide some other feedback. We might also collect external
    information such as the location of the user (as provided through their IP address,
    for example). These event logs will typically contain some combination of textual
    and numeric information about the event (and also, perhaps, other forms of data
    such as images or audio).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可能希望花费大部分时间探索机器学习模型，但通过前面的摄入步骤从各种系统和来源收集的数据，在大多数情况下都是以原始形式存在的。例如，我们可能记录用户事件，比如用户何时查看电影信息页面、观看电影或提供其他反馈的详细信息。我们还可能收集外部信息，比如用户的位置（例如通过他们的IP地址提供）。这些事件日志通常会包含有关事件的文本和数字信息的组合（也可能包括其他形式的数据，如图像或音频）。
- en: 'In order to use this raw data in our models, in almost all cases, we need to
    perform preprocessing, which might include:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在我们的模型中使用原始数据，在几乎所有情况下，我们需要进行预处理，这可能包括：
- en: '**Filtering data**: Let''s assume that we want to create a model from a subset
    of raw data, such as only the most recent few months of activity data or only
    events that match certain criteria.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过滤数据**：假设我们想要从原始数据的子集创建模型，比如只使用最近几个月的活动数据或只使用符合某些条件的事件。'
- en: '**Dealing with missing, incomplete, or corrupted data**: Many real-world datasets
    are incomplete in some way. This might include data that is missing (for example,
    due to a missing user input) or data that is incorrect or flawed (for example,
    due to an error in data ingestion or storage, technical issues or bugs, or software
    or hardware failure). We might need to filter out bad data or alternatively decide
    a method to fill in missing data points (such as using the average value from
    the dataset for missing points, for example).'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理缺失、不完整或损坏的数据**：许多真实世界的数据集在某种程度上是不完整的。这可能包括缺失的数据（例如由于缺少用户输入）或不正确或有缺陷的数据（例如由于数据摄入或存储错误、技术问题或错误、软件或硬件故障）。我们可能需要过滤掉不良数据，或者决定一种方法来填补缺失的数据点（例如使用数据集的平均值来填补缺失点）。'
- en: '**Dealing with potential anomalies, errors, and outliers**: Erroneous or outlier
    data might skew the results of model training, so we might wish to filter these
    cases out or use techniques that are able to deal with outliers.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理潜在的异常、错误和离群值**：错误或离群值的数据可能会扭曲模型训练的结果，因此我们可能希望过滤这些情况或使用能够处理离群值的技术。'
- en: '**Joining together disparate data sources**: For example, we might need to
    match up the event data for each user with different internal data sources, such
    as user profiles, as well as external data, such as geolocation, weather, and
    economic data.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合并不同的数据源**：例如，我们可能需要将每个用户的事件数据与不同的内部数据源（如用户资料）以及外部数据（如地理位置、天气和经济数据）进行匹配。'
- en: '**Aggregating data**: Certain models might require input data that is aggregated
    in some way, such as computing the sum of a number of different event types per
    user.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合数据**：某些模型可能需要以某种方式聚合的输入数据，比如计算每个用户的不同事件类型的总和。'
- en: 'Once we have performed initial preprocessing on our data, we often need to
    transform the data into a representation that is suitable for machine learning
    models. For many model types, this representation will take the form of a vector
    or matrix structure that contains numerical data. Common challenges during data
    transformation and feature extraction include:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们对数据进行了初始预处理，通常需要将数据转换为适合机器学习模型的表示形式。对于许多模型类型，这种表示形式将采用包含数值数据的向量或矩阵结构。数据转换和特征提取过程中常见的挑战包括：
- en: Taking categorical data (such as country for geolocation or category for a movie)
    and encoding it in a numerical representation.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将分类数据（如地理位置的国家或电影的类别）编码为数值表示。
- en: Extracting useful features from text data.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本数据中提取有用的特征。
- en: Dealing with image or audio data.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理图像或音频数据。
- en: Converting numerical data into categorical data to reduce the number of values
    a variable can take on. An example of this is converting a variable for age into
    buckets (such as 25-35, 45-55, and so on).
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数值数据转换为分类数据，以减少变量可以取值的数量。一个例子是将年龄变量转换为区间（比如25-35，45-55等）。
- en: Transforming numerical features; for example, applying a log transformation
    to a numerical variable can help deal with variables that take on a very large
    range of values.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换数值特征；例如，对数值变量应用对数变换可以帮助处理取值范围非常大的变量。
- en: Normalizing and standardizing numerical features ensures that all the different
    input variables for a model have a consistent scale. Many machine learning models
    require standardized input to work properly.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数值特征进行归一化和标准化，确保模型的所有不同输入变量具有一致的尺度。许多机器学习模型需要标准化的输入才能正常工作。
- en: Feature engineering, which is the process of combining or transforming the existing
    variables to create new features. For example, we can create a new variable that
    is the average of some other data, such as the average number of times a user
    watches a movie.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程，即将现有变量组合或转换为新特征的过程。例如，我们可以创建一个新变量，即某些其他数据的平均值，比如用户观看电影的平均次数。
- en: We will cover all of these techniques through the examples in this book.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过本书中的示例涵盖所有这些技术。
- en: This data-cleansing, exploration, aggregation, and transformation steps can
    be carried out using both Spark's core API functions as well as the SparkSQL engine,
    not to mention other external Scala, Java, or Python libraries. We can take advantage
    of Spark's Hadoop compatibility to read data from and write data to the various
    storage systems mentioned earlier.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据清洗、探索、聚合和转换步骤可以使用Spark的核心API函数以及SparkSQL引擎来进行，更不用说其他外部的Scala、Java或Python库。我们可以利用Spark的Hadoop兼容性从各种存储系统中读取数据并写入数据。
- en: We can also leverage Spark streaming in case the streaming input is involved.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果涉及流式输入，我们还可以利用Spark流处理。
- en: Model training and testing loop
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练和测试循环
- en: Once we have our training data in a form that is suitable for our model, we
    can proceed with the model's training and testing phase. During this phase, we
    are primarily concerned with model selection. This can refer to choosing the best
    modeling approach for our task, or the best parameter settings for a given model.
    In fact, the term model selection often refers to both of these processes, as,
    in many cases, we might wish to try out various models and select the best performing
    model (with the best performing parameter settings for each model). It is also
    common to explore the application of combinations of different models (known as
    ensemble methods) in this phase.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的训练数据适合我们的模型，我们可以进行模型的训练和测试阶段。在这个阶段，我们主要关注模型选择。这可以是选择最适合我们任务的建模方法，或者给定模型的最佳参数设置。事实上，模型选择这个术语通常指的是这两个过程，因为在许多情况下，我们可能希望尝试各种模型，并选择表现最佳的模型（每个模型的最佳参数设置）。在这个阶段，探索不同模型的组合（称为集成方法）也很常见。
- en: This is typically a fairly straightforward process of running our chosen model
    on our training dataset and testing its performance on a test dataset (that is,
    a set of data that is held out for the evaluation of the model that the model
    has not seen in the training phase). This process is referred to as cross-validation.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是一个相当简单的过程，即在训练数据集上运行我们选择的模型，并在测试数据集上测试其性能（即一组数据，用于评估模型在训练阶段未见过的模型）。这个过程被称为交叉验证。
- en: Sometimes, the model tends to overfit or doesn't converge fully depending on
    the type of the dataset and the number of Iterations used.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，模型会出现过拟合或者不完全收敛，这取决于数据集的类型和使用的迭代次数。
- en: Using Ensemble methods such as Gradient Boosted Trees and Random forest are
    techniques used in ML and Spark to avoid overfitting.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 使用集成方法，如梯度提升树和随机森林，是避免过拟合的机器学习和Spark中使用的技术。
- en: However, due to the large scale of data we are typically working with, it is
    often useful to carry out this initial train-test loop on a smaller representative
    sample of our full dataset or perform model selection using parallel methods where
    possible.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于我们通常处理的数据规模很大，通常有必要在我们完整数据集的一个较小代表样本上进行这个初始的训练-测试循环，或者在可能的情况下使用并行方法进行模型选择。
- en: For this part of the pipeline, Spark's built-in machine learning library, MLlib,
    is a perfect fit. We will focus most of our attention in this book on the model
    training, evaluation, and cross-validation steps for various machine learning
    techniques, using MLlib and Spark's core features.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于管道的这一部分，Spark内置的机器学习库MLlib非常合适。在本书中，我们将主要关注使用MLlib和Spark的核心功能，对各种机器学习技术进行模型训练、评估和交叉验证步骤。
- en: Model deployment and integration
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型部署和集成
- en: Once we have found the optimal train-test loop, we might still face the task
    of deploying the model to a production system so that it can be used to make actionable
    predictions.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦找到了最佳的训练-测试循环，我们可能仍然面临将模型部署到生产系统的任务，以便用于进行可操作的预测。
- en: Usually, this process involves exporting the trained model to a central data
    store from where the production-serving system can obtain the latest version.
    Thus, the live system *refreshes* the model periodically as a new model is trained.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这个过程涉及将训练好的模型导出到一个中央数据存储中，生产系统可以从中获取最新版本。因此，实时系统会定期更新模型，以便使用新训练的模型。
- en: Model monitoring and feedback
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型监控和反馈
- en: It is critically important to monitor the performance of our machine learning
    system in production. Once we deploy our optimal-trained model, we wish to understand
    how it is doing in the "wild". Is it performing as we expect on new, unseen data?
    Is its accuracy good enough? The reality is, regardless of how much model selection
    and tuning we try to do in the earlier phases, the only way to measure true performance
    is to observe what happens in our production system.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中监控机器学习系统的性能非常重要。一旦部署了最佳训练的模型，我们希望了解它在“野外”的表现。它在新的、未见过的数据上表现如我们所期望的吗？它的准确性是否足够？事实上，无论我们在早期阶段进行了多少模型选择和调整，衡量真正性能的唯一方法是观察在生产系统中发生的情况。
- en: In addition to the batch mode model creation, there are also models built with
    Spark streaming which are real-time in nature.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 除了批处理模式的模型创建外，还有使用Spark流处理构建的实时模型。
- en: Also, bear in mind that model accuracy and predictive performance is only one
    aspect of a real-world system. Usually, we are concerned with other metrics related
    to business performance (for example, revenue and profitability) or user experience
    (such as the time spent on our site and how active our users are overall). In
    most cases, we cannot easily map model-predictive performance to these business
    metrics. The accuracy of a recommendation or targeting system might be important,
    but it relates only indirectly to the true metrics we are concerned about, namely,
    whether we are improving user experience, activity, and ultimately, revenue.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，请记住，模型准确度和预测性能只是现实世界系统的一个方面。通常，我们关注与业务绩效相关的其他指标（例如收入和盈利能力）或用户体验（例如在我们网站上花费的时间以及我们的用户总体活跃度）。在大多数情况下，我们无法轻易将模型预测性能与这些业务指标相匹配。推荐或定位系统的准确性可能很重要，但它只间接与我们关心的真正指标相关，即我们是否正在改善用户体验、活动性和最终收入。
- en: So, in real-world systems, we should monitor both model-accuracy metrics as
    well as business metrics. If possible, we should be able to experiment with different
    models running in production to allow us to optimize against these business metrics
    by making changes to the models. This is often done using live split tests. However,
    doing this correctly is not an easy task, and live testing and experimentation
    is expensive, in the sense that mistakes, poor performance, and using baseline
    models (they provide a control against which we test our production models) can
    negatively impact user experience and revenue.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在现实世界的系统中，我们应该监控模型准确度指标以及业务指标。如果可能的话，我们应该能够在生产中尝试不同的模型，以便通过对模型进行更改来优化这些业务指标。这通常是通过实时分割测试来完成的。然而，正确地进行这项工作并不容易，实时测试和实验是昂贵的，因为错误、性能不佳以及使用基准模型（它们提供了我们测试生产模型的对照）可能会对用户体验和收入产生负面影响。
- en: Another important aspect of this phase is **model feedback**. This is the process
    where the predictions of our model feed through into user behavior; this, in turn,
    feeds through into our model. In a real-world system, our models are essentially
    influencing their own future training data by impacting decision-making and potential
    user behavior.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段的另一个重要方面是**模型反馈**。这是我们的模型预测通过用户行为反馈到模型的过程。在现实世界的系统中，我们的模型实质上通过影响决策和潜在用户行为来影响自己未来的训练数据。
- en: For example, if we have deployed a recommendation system, then, by making recommendations,
    we might be influencing user behavior because we are only allowing users a limited
    selection of choices. We hope that this selection is relevant for our model; however,
    this feedback loop, in turn, can influence our model's training data. This, in
    turn, feeds back into real-world performance. It is possible to get into an ever-narrowing
    feedback loop; ultimately, this can negatively affect both model accuracy and
    our important business metrics.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们部署了一个推荐系统，那么通过推荐，我们可能会影响用户行为，因为我们只允许用户有限的选择。我们希望这个选择对我们的模型是相关的；然而，这种反馈循环反过来又会影响我们模型的训练数据。这又反过来影响现实世界的性能。可能会陷入一个不断变窄的反馈循环；最终，这可能会对模型准确度和我们重要的业务指标产生负面影响。
- en: Fortunately, there are mechanisms by which we can try to limit the potential
    negative impact of this feedback loop. These include providing some unbiased training
    data by having a small portion of data coming from users who are not exposed to
    our models or by being principled in the way we balance exploration, to learn
    more about our data, and exploitation, to use what we have learned to improve
    our system's performance.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们有一些机制可以尝试限制这种反馈循环的潜在负面影响。这些机制包括通过让一小部分来自未接触我们模型的用户的数据提供一些无偏的训练数据，或者在探索和开发的平衡方式上保持原则，以了解更多关于我们的数据，以及利用我们所学到的知识来改善系统的性能。
- en: We will briefly cover in [Chapter 11](80797b8a-39cd-42af-861b-401da1bf728d.xhtml),
    *Real-time Machine Learning with Spark Streaming*.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第11章](80797b8a-39cd-42af-861b-401da1bf728d.xhtml)中简要介绍*使用Spark Streaming进行实时机器学习*。
- en: Batch versus real time
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批处理与实时
- en: In the previous sections, we outlined the common batch processing approach,
    where the model is retrained using all data or a subset of all data, periodically.
    As the preceding pipeline takes some time to complete, it might not be possible
    to use this approach to update models immediately as new data arrives.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们概述了常见的批处理方法，即使用所有数据或所有数据的子集定期重新训练模型。由于前面的管道需要一些时间才能完成，因此可能无法使用这种方法立即更新模型以适应新数据的到来。
- en: While we will be mostly covering batch machine learning approaches in this book,
    there is a class of machine learning algorithms known as **online learning**;
    they update immediately as new data is fed into the model, thus enabling a real-time
    system. A common example is an online-optimization algorithm for a linear model,
    such as stochastic gradient descent. We can learn this algorithm using examples.
    The advantages of these methods are that the system can react very quickly to
    new information and also that the system can adapt to changes in the underlying
    behavior (that is, if the characteristics and distribution of the input data are
    changing over time, which is almost always the case in real-world situations).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在本书中我们将主要介绍批处理机器学习方法，但有一类被称为**在线学习**的机器学习算法；它们在新数据被馈送到模型时立即更新，从而实现实时系统。一个常见的例子是线性模型的在线优化算法，比如随机梯度下降。我们可以通过示例学习这个算法。这些方法的优势在于系统可以非常快速地对新信息做出反应，同时系统可以适应底层行为的变化（即，如果输入数据的特征和分布随时间变化，这在现实世界的情况下几乎总是发生的）。
- en: However, online-learning models come with their own unique challenges in a production
    context. For example, it might be difficult to ingest and transform data in real-time.
    It can also be complex to properly perform model selection in a purely online
    setting. The latency of the online training and the model selection and deployment
    phases might be too high for true real-time requirements (for example, in online
    advertising, latency requirements are measured in single-digit milliseconds).
    Finally, batch-oriented frameworks might make it awkward to handle real-time processes
    of a streaming nature.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在生产环境中，在线学习模型也面临着自己独特的挑战。例如，实时摄取和转换数据可能很困难。在纯在线设置中进行适当的模型选择也可能很复杂。在线培训和模型选择和部署阶段的延迟可能对真实实时需求来说太高（例如，在在线广告中，延迟要求以两位数毫秒为单位）。最后，面向批处理的框架可能使处理流式处理的实时过程变得尴尬。
- en: Fortunately, Spark's real-time stream processing is a good potential fit for
    real-time machine learning workflows. We will explore Spark Streaming and online
    learning in [Chapter 11](80797b8a-39cd-42af-861b-401da1bf728d.xhtml), *Real-time
    Machine Learning with Spark Streaming*
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Spark的实时流处理非常适合实时机器学习工作流。我们将在[第11章](80797b8a-39cd-42af-861b-401da1bf728d.xhtml)中探讨Spark
    Streaming和在线学习，*使用Spark Streaming进行实时机器学习*
- en: Due to the complexities inherent in a true real-time machine learning system,
    in practice, many systems target near real-time operations. This is essentially
    a hybrid approach where models are not necessarily updated immediately as new
    data arrives; instead, the new data is collected into mini batches of a small
    set of training data. These mini batches can be fed to an online-learning algorithm.
    In many cases, this approach is combined with a periodic batch process that might
    recompute the model on the entire dataset and perform more complex processing
    and model selection. This can help ensure that the real-time model does not degrade
    over time.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 由于真实实时机器学习系统固有的复杂性，在实践中，许多系统针对近实时操作。这本质上是一种混合方法，其中模型不一定在新数据到达时立即更新；相反，新数据被收集到一小组训练数据的小批次中。这些小批次可以被馈送到在线学习算法中。在许多情况下，这种方法与定期批处理过程相结合，该过程可能在整个数据集上重新计算模型并执行更复杂的处理和模型选择。这可以确保实时模型不会随着时间的推移而退化。
- en: Another similar approach involves making approximate updates to a more complex
    model as new data arrives while recomputing the entire model in a batch process
    periodically. In this way, the model can learn from new data, with a short delay
    (usually measured in seconds or, perhaps, a few minutes), but will become more
    and more inaccurate over time due to the approximation applied. The periodic recomputation
    takes care of this by retraining the model on all available data.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种类似的方法涉及对更复杂的模型进行近似更新，以便在新数据到达时，定期以批处理过程重新计算整个模型。通过这种方式，模型可以从新数据中学习，但由于应用了近似值，随着时间的推移，模型会变得越来越不准确。定期重新计算通过在所有可用数据上重新训练模型来解决这个问题。
- en: Data Pipeline in Apache Spark
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark中的数据管道
- en: 'As we have seen the movie lens use case, it is quite common to run a sequence
    of machine learning algorithms to process and learn from data. Another example
    is a simple text document processing workflow, which can include several stages:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的电影镜头用例，运行一系列机器学习算法来处理和学习数据是非常常见的。另一个例子是简单的文本文档处理工作流，其中可以包括几个阶段：
- en: Split the document's text into words
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文档的文本拆分成单词
- en: Convert the document's words into a numerical feature vector
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文档的单词转换为数字特征向量
- en: Learn a prediction model from feature vectors and labels
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从特征向量和标签中学习预测模型
- en: Spark MLlib represents such a workflow as a Pipeline; it consists of Pipeline
    Stages in sequence (Transformers and Estimators), which are run in a specific
    order.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib将这样的工作流表示为管道；它由顺序的管道阶段（转换器和估计器）组成，这些阶段按特定顺序运行。
- en: A Pipeline is specified as a sequence of stages. Each stage is a Transformer
    or an Estimator. Transform converts one data frame into another. Estimator, on
    the other hand, is a learning algorithm. Pipeline stages are run in order, and
    the input DataFrame is transformed as it passes through each stage.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 管道被指定为一系列阶段。每个阶段都是一个转换器或一个估计器。转换器将一个数据框转换为另一个数据框。另一方面，估计器是一个学习算法。管道阶段按顺序运行，并且输入数据框在通过每个阶段时进行转换。
- en: In Transformer stages, the `transform()` method is called on the DataFrame.
    For Estimator stages, the `fit()` method is called to produce a Transformer (which
    becomes part of the PipelineModel or fitted Pipeline). The transformer's `transform()`
    method is executed on the DataFrame.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在转换器阶段，对数据框调用`transform()`方法。对于估计器阶段，调用`fit()`方法以生成一个转换器（它成为PipelineModel或拟合管道的一部分）。转换器的`transform()`方法在数据框上执行。
- en: An architecture for a machine learning system
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习系统的架构
- en: 'Now that we have explored how our machine learning system might work in the
    context of MovieStream, we can outline a possible architecture for our system:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了我们的机器学习系统在MovieStream环境中可能的工作方式，我们可以为我们的系统概述一个可能的架构：
- en: '![](img/image_03_003.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_03_003.png)'
- en: MovieStream's future architecture
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: MovieStream的未来架构
- en: 'As we can see, our system incorporates the machine learning pipeline outlined
    in the preceding diagram; this system also includes:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们的系统包含了前面图表中概述的机器学习管道；该系统还包括：
- en: Collecting data about users, their behavior, and our content titles
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集关于用户、他们的行为和我们的内容标题的数据
- en: Transforming this data into features
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将这些数据转换为特征
- en: Training our models, including our training-testing and model-selection phases
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练我们的模型，包括我们的训练测试和模型选择阶段
- en: Deploying the trained models to both our live model-serving system as well as
    using these models for offline processes
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将训练好的模型部署到我们的实时模型服务系统以及将这些模型用于离线流程
- en: Feeding back the model results into the MovieStream website through recommendation
    and targeting pages
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过推荐和定位页面将模型结果反馈到MovieStream网站
- en: Feeding back the model results into MovieStream's personalized marketing channels
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型结果反馈到MovieStream的个性化营销渠道
- en: Using the offline models to provide tools to MovieStream's various teams to
    better understand user behavior, characteristics of the content catalogue, and
    drivers of revenue for the business
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用离线模型为MovieStream的各个团队提供工具，以更好地了解用户行为、内容目录的特征和业务收入的驱动因素
- en: In the next section, we digress a little from Movie Stream and give an overview
    of MLlib-Spark's machine learning module.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们稍微偏离了Movie Stream，概述了MLlib-Spark的机器学习模块。
- en: Spark MLlib
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark MLlib
- en: Apache Spark is an open-source platform for large dataset processing. It is
    well suited for iterative machine learning tasks as it leverages in-memory data
    structures such as RDDs. MLlib is Spark's machine learning library. MLlib provides
    functionality for various learning algorithms-supervised and unsupervised. It
    includes various statistical and linear algebra optimizations. It is shipped along
    with Apache Spark and hence saves on installation headaches like some other libraries.
    MLlib supports several higher languages such as Scala, Java, Python and R. It
    also provides a high-level API to build machine-learning pipelines.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark是一个用于大型数据集处理的开源平台。它非常适合迭代的机器学习任务，因为它利用了RDD等内存数据结构。MLlib是Spark的机器学习库。MLlib提供了各种学习算法的功能-监督和无监督。它包括各种统计和线性代数优化。它与Apache
    Spark一起发布，因此可以避免像其他库那样的安装问题。MLlib支持Scala、Java、Python和R等多种高级语言。它还提供了一个高级API来构建机器学习管道。
- en: MLlib's integration with Spark has quite a few benefits. Spark is designed for
    iterative computation cycles; it enables efficient implementation platform for
    large machine learning algorithms, as these algorithms are themselves iterative.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib与Spark的集成有很多好处。Spark设计用于迭代计算周期；它为大型机器学习算法提供了高效的实现平台，因为这些算法本身就是迭代的。
- en: Any improvement in Spark's data structures results in direct gains for MLlib.
    Spark's large community contributions have helped bring new algorithms to MLlib
    faster.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Spark数据结构的任何改进都会直接为MLlib带来收益。Spark庞大的社区贡献帮助加快了新算法对MLlib的引入。
- en: Spark also has other APIs such as Pipeline APIs GraphX, which can be used in
    conjunction with MLlib; it makes building interesting use cases on top of MLlib
    easier.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Spark还有其他API，如Pipeline API GraphX，可以与MLlib一起使用；它使得在MLlib之上构建有趣的用例更容易。
- en: Performance improvements in Spark ML over Spark MLlib
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark ML在Spark MLlib上的性能改进
- en: Spark 2.0 uses Tungsten Engine, which is built using ideas of modern compilers
    and MPP databases. It emits optimized bytecode at runtime, which collapses the
    query into a single function. Hence, there is no need for virtual function calls.
    It also uses CPU registers to store intermediate data. This technique has been
    called whole stage code generation.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 2.0使用了Tungsten引擎，该引擎利用了现代编译器和MPP数据库的思想。它在运行时发出优化的字节码，将查询折叠成一个单一函数。因此，不需要虚拟函数调用。它还使用CPU寄存器来存储中间数据。这种技术被称为整体阶段代码生成。
- en: '![](img/image_03_004.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_03_004.png)'
- en: 'Reference : https://databricks.com/blog/2016/05/11/apache-spark-2-0-technical-preview-easier-faster-and-smarter.htmlSource:
    https://databricks.com/blog/2016/05/11/apache-spark-2-0-technical-preview-easier-faster-and-smarter.html'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 参考：https://databricks.com/blog/2016/05/11/apache-spark-2-0-technical-preview-easier-faster-and-smarter.html来源：https://databricks.com/blog/2016/05/11/apache-spark-2-0-technical-preview-easier-faster-and-smarter.html
- en: 'The upcoming table and graph show single function improvements between Spark
    1.6 and Spark 2.0:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 即将出现的表格和图表显示了Spark 1.6和Spark 2.0之间单函数改进的情况：
- en: '![](img/image_03_005.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_03_005.png)'
- en: Chart comparing Performance improvements in Single line functions between Spark
    1.6 and Spark 2.0
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 比较Spark 1.6和Spark 2.0之间单行函数性能改进的图表
- en: '![](img/image_03_006.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_03_006.png)'
- en: Table comparing Performance improvements in Single line functions between Spark
    1.6 and Spark 2.0.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 比较Spark 1.6和Spark 2.0之间单行函数性能改进的表格。
- en: Comparing algorithms supported by MLlib
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较MLlib支持的算法
- en: In this section, we look at various algorithms supported by MLlib versions.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看一下MLlib版本支持的各种算法。
- en: Classification
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类
- en: In 1.6, there are over 10 algorithms supported for classification, whereas when
    Spark MLversion 1.0 was announced, only 3 algorithms were supported.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在1.6版本中，支持超过10种分类算法，而当Spark ML版本1.0发布时，只支持3种算法。
- en: '![](img/image_03_007.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_03_007.png)'
- en: Clustering
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: There has been quite a bit of investment in Clustering algorithms, moving from
    1 algo support in 1.0.0 to supporting 6 implementations in 1.6.0.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在聚类算法方面进行了相当大的投资，从1.0.0的1种算法支持到1.6.0的6种实现支持。
- en: '![](img/image_03_008.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_03_008.png)'
- en: Regression
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归
- en: Traditionally, regression was not the main area of focus but has become of late
    with 3-4 new algorithms from 1.2.0 version to 1.3.0 version.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，回归并不是主要关注的领域，但最近已经成为焦点，从1.2.0版本到1.3.0版本新增了3-4个新算法。
- en: '![](img/image_03_009.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_03_009.png)'
- en: MLlib supported methods and developer APIs
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLlib支持的方法和开发者API
- en: MLlib provides fast and distributed implementations of learning algorithms,
    including various linear models, Naive Bayes, SVM, and Ensembles of Decision Trees
    (also known as Random Forests) for classification and regression problems, alternating.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib提供了学习算法的快速和分布式实现，包括各种线性模型、朴素贝叶斯、支持向量机和决策树集成（也称为随机森林）用于分类和回归问题，交替进行。
- en: '**Least Squares** (explicit and implicit feedback) are used for collaborative
    filtering. It also supports k-means clustering and **principal component analysis**
    (**PCA**) for clustering and dimensionality reduction.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**最小二乘法**（显式和隐式反馈）用于协同过滤。它还支持k均值聚类和**主成分分析**（**PCA**）用于聚类和降维。'
- en: The library provides some low-level primitives and basic utilities for convex
    optimization ([http://spark.apache.org/docs/latest/mllib-optimization.html](http://spark.apache.org/docs/latest/mllib-optimization.html)),
    distributed linear algebra (with support for Vectors and Matrix), statistical
    analysis (using Breeze and also native functions), and feature extraction, and
    supports various I/O formats, including native support for LIBSVM format.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 该库提供了一些低级原语和基本实用程序，用于凸优化（[http://spark.apache.org/docs/latest/mllib-optimization.html](http://spark.apache.org/docs/latest/mllib-optimization.html)）、分布式线性代数（支持向量和矩阵）、统计分析（使用Breeze和本地函数）、特征提取，并支持各种I/O格式，包括对LIBSVM格式的本机支持。
- en: 'It also supports data integration via Spark SQL as well as PMML ([https://en.wikipedia.org/wiki/Predictive_Model_Markup_Language](https://en.wikipedia.org/wiki/Predictive_Model_Markup_Language))
    (Guazzelli et al., 2009). You can find more information about PMML support at
    this link: [https://spark.apache.org/docs/1.6.0/mllib-pmml-model-export.html](https://spark.apache.org/docs/1.6.0/mllib-pmml-model-export.html).'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 它还支持通过Spark SQL和PMML（[https://en.wikipedia.org/wiki/Predictive_Model_Markup_Language](https://en.wikipedia.org/wiki/Predictive_Model_Markup_Language)）（Guazzelli等人，2009）进行数据集成。您可以在此链接找到有关PMML支持的更多信息：[https://spark.apache.org/docs/1.6.0/mllib-pmml-model-export.html](https://spark.apache.org/docs/1.6.0/mllib-pmml-model-export.html)。
- en: '**Algorithmic Optimizations** involves MLlib that includes many optimizations
    to support efficient distributed learning and prediction.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**算法优化**涉及MLlib包括许多优化，以支持高效的分布式学习和预测。'
- en: 'The ALS algorithm for recommendation makes use of blocking to reduce JVM garbage
    collection overhead and to utilize higher-level linear algebra operations. Decision
    trees use ideas from the PLANET project (reference: [http://dl.acm.org/citation.cfm?id=1687569](http://dl.acm.org/citation.cfm?id=1687569)),
    such as data-dependent feature discretization to reduce communication costs, and
    tree ensembles parallelize learning both within trees and across trees.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 用于推荐的ALS算法利用了阻塞来减少JVM垃圾收集开销，并利用更高级别的线性代数操作。决策树使用了来自PLANET项目的想法（参考：[http://dl.acm.org/citation.cfm?id=1687569](http://dl.acm.org/citation.cfm?id=1687569)），例如数据相关的特征离散化以减少通信成本，以及树集成在树内和树间并行学习。
- en: Generalized linear models are learned using optimization algorithms, which parallelize
    gradient computation, using fast C++-based linear algebra libraries for worker.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 广义线性模型是使用优化算法学习的，这些算法并行计算梯度，使用快速的基于C++的线性代数库进行工作。
- en: '**Computations**. Algorithms benefit from efficient communication primitives.
    In particular, tree-structured aggregation prevents the driver from being a bottleneck.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 计算。算法受益于高效的通信原语。特别是，树形聚合可以防止驱动程序成为瓶颈。
- en: Model updates are combined partially on a small set of executors. These are
    then sent to the driver. This implementation reduces the load the driver has to
    handle. Tests showed that these functions reduce the aggregation time by an order
    of magnitude, especially on datasets with a large number of partitions.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 模型更新部分地组合在一小组执行器上。然后将它们发送到驱动程序。这种实现减少了驱动程序需要处理的负载。测试表明，这些功能将聚合时间缩短了一个数量级，特别是在具有大量分区的数据集上。
- en: '(Reference: [https://databricks.com/blog/2014/09/22/spark-1-1-mllib-performance-improvements.html](https://databricks.com/blog/2014/09/22/spark-1-1-mllib-performance-improvements.html))'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: （参考：[https://databricks.com/blog/2014/09/22/spark-1-1-mllib-performance-improvements.html](https://databricks.com/blog/2014/09/22/spark-1-1-mllib-performance-improvements.html)）
- en: '**Pipeline API** includes practical machine learning pipelines that often involve
    a sequence of data preprocessing, feature extraction, model fitting, and validation
    stages.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pipeline API**包括实用的机器学习管道，通常涉及一系列数据预处理、特征提取、模型拟合和验证阶段。'
- en: Most of the machine learning libraries do not provide native support for the
    diverse set of functionalities for pipeline construction. When handling large-scale
    datasets, the process of wiring together an end-to-end pipeline is both labor-intensive
    and expensive from the perspective of network overheads.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习库不提供对管道构建的各种功能的本机支持。在处理大规模数据集时，将端到端管道连接在一起的过程在网络开销的角度来看既费力又昂贵。
- en: '**Leveraging Spark''s ecosystem**: MLlib includes a package aimed to address
    these concerns.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**利用Spark的生态系统**：MLlib包括一个旨在解决这些问题的包。'
- en: The `spark.ml` package eases the development and tuning of multistage learning
    pipelines by providing a uniform set of high-level APIs ([http://arxiv.org/pdf/1505.06807.pdf](http://arxiv.org/pdf/1505.06807.pdf)).
    It includes APIs that enable users to swap out a standard learning approach in
    place of their specialized algorithms.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`spark.ml`包通过提供一组统一的高级API（[http://arxiv.org/pdf/1505.06807.pdf](http://arxiv.org/pdf/1505.06807.pdf)）来简化多阶段学习管道的开发和调优。它包括使用户能够在其专门的算法中替换标准学习方法的API。'
- en: Spark Integration
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark集成
- en: MLlib benefits from the components within the Spark ecosystem. Spark core provides
    an execution engine with over 80 operators for transforming data (data cleaning
    and featurization).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib受益于Spark生态系统中的组件。Spark核心提供了一个执行引擎，其中包含超过80个用于转换数据（数据清洗和特征化）的操作符。
- en: MLlib uses other high-level libraries packaged with Spark-like Spark SQL. It
    provides integration data functionality, SQL, and structured data processing,
    which simplifies data cleaning and preprocessing. It supports the DataFrame abstraction,
    which is fundamental to the `spark.ml` package.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib使用了与Spark打包在一起的其他高级库，如Spark SQL。它提供了集成数据功能、SQL和结构化数据处理，简化了数据清洗和预处理。它支持DataFrame抽象，这对于`spark.ml`包是基本的。
- en: '**GraphX** ([https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-gonzalez.pdf](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-gonzalez.pdf))
    supports large-scale graph processing and has a powerful API for implementing
    learning algorithms that can be viewed as large sparse graph problems, for example,
    LDA.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**GraphX**（[https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-gonzalez.pdf](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-gonzalez.pdf)）支持大规模图处理，并具有强大的API，用于实现可以视为大型稀疏图问题的学习算法，例如LDA。'
- en: '**Spark Streaming** ([https://www.cs.berkeley.edu/~matei/papers/2013/sosp_spark_streaming.pdf](https://www.cs.berkeley.edu/~matei/papers/2013/sosp_spark_streaming.pdf))
    allows processing of real-time data streams and enabling the development of learning
    algorithms which are online, as in Freeman (2015). We will cover streaming in
    some of the later chapters of this book.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**Spark Streaming**（[https://www.cs.berkeley.edu/~matei/papers/2013/sosp_spark_streaming.pdf](https://www.cs.berkeley.edu/~matei/papers/2013/sosp_spark_streaming.pdf)）允许处理实时数据流，并支持在线学习算法的开发，就像Freeman（2015）中所述。我们将在本书的一些后续章节中涵盖流处理。'
- en: MLlib vision
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLlib愿景
- en: MLlib's vision is to provide a scalable machine learning platform, which can
    handle large datasets at scale and fastest processing time as compared to the
    existing systems such as Hadoop.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib的愿景是提供一个可扩展的机器学习平台，可以处理大规模数据集，并且相对于现有系统（如Hadoop）具有更快的处理时间。
- en: It also strives to provide support for as many algorithms as possible in the
    domain of supervised and unsupervised learning classification, regression such
    as Classification, Regression, and clustering.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 它还努力为监督和无监督学习分类、回归和聚类等领域尽可能多的算法提供支持。
- en: MLlib versions compared
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLlib版本比较
- en: In this section, we will compare various versions of MLlib and new functionality,
    which has been added.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将比较各个版本的MLlib和新增的功能。
- en: Spark 1.6 to 2.0
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark 1.6到2.0
- en: The DataFrame-based API will be the primary API.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 基于DataFrame的API将成为主要API。
- en: The RDD-based API is entering maintenance mode. The MLlib guide ([http://spark.apache.org/docs/2.0.0/ml-guide.html](http://spark.apache.org/docs/2.0.0/ml-guide.html))
    provides more details.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 基于RDD的API正在进入维护模式。MLlib指南（[http://spark.apache.org/docs/2.0.0/ml-guide.html](http://spark.apache.org/docs/2.0.0/ml-guide.html)）提供了更多细节。
- en: 'The following are the new features introduced in Spark 2.0:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是Spark 2.0中引入的新功能：
- en: '**ML persistence**: The DataFrames-based API provides support for saving and
    loading ML models and Pipelines in Scala, Java, Python, and R'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ML持久性**：基于DataFrames的API支持在Scala、Java、Python和R中保存和加载ML模型和管道'
- en: '**MLlib in R**: SparkR offers MLlib APIs for generalized linear models, naive
    Bayes, k-means clustering, and survival regression in this release'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**R中的MLlib**：SparkR在此版本中提供了MLlib的API，用于广义线性模型、朴素贝叶斯、k均值聚类和生存回归'
- en: '**Python**: PySpark in 2.0 supports new MLlib algorithms, LDA, Generalized
    Linear Regression, Gaussian Mixture Model, among others'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Python**：2.0中的PySpark支持新的MLlib算法，如LDA、广义线性回归、高斯混合模型等'
- en: Algorithms added to DataFrames-based API are GMM, Bisecting K-Means clustering,
    MaxAbsScaler feature transformer.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 基于DataFrames的API新增了GMM、二分K均值聚类、MaxAbsScaler特征转换器。
- en: Summary
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learnt about the components that are inherent in a data-driven,
    automated machine learning system. We also outlined how a possible high-level
    architecture for such a system might look in a real-world situation. We also got
    an overview of MLlib-Spark's machine learning library-compared to other machine
    learning implementations from a performance perspective. In the end, we looked
    at new features in various versions of Spark starting from Spark 1.6 to Spark
    2.0.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了数据驱动的自动化机器学习系统中固有的组件。我们还概述了这样一个系统在现实世界中可能的高层架构。我们还从性能的角度对MLlib-Spark的机器学习库与其他机器学习实现进行了概述。最后，我们看了一下从Spark
    1.6到Spark 2.0各个版本的新功能。
- en: In next chapter, we shall discuss how to obtain publicly-available datasets
    for common machine learning tasks. We will also explore general concepts to process,
    clean, and transform data so that it can be used to train a machine learning model.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何获取常见机器学习任务的公开可用数据集。我们还将探讨处理、清洗和转换数据的一般概念，以便用于训练机器学习模型。
