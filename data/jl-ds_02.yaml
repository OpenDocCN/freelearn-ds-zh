- en: Chapter 2. Data Munging
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章 数据清洗
- en: It is said that around 50% of the data scientist's time goes into transforming
    raw data into a usable format. Raw data can be in any format or size. It can be
    structured like RDBMS, semi-structured like CSV, or unstructured like regular
    text files. These contain some valuable information. And to extract that information,
    it has to be converted into a data structure or a usable format from which an
    algorithm can find valuable insights. Therefore, usable format refers to the data
    in a model that can be consumed in the data science process. This usable format
    differs from use case to use case.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 据说数据科学家的大约50%的时间都用于将原始数据转换为可用格式。原始数据可以是任何格式或大小。它可以是像关系数据库管理系统（RDBMS）这样的结构化数据，像CSV这样的半结构化数据，或像普通文本文件这样的非结构化数据。这些数据包含一些有价值的信息。为了提取这些信息，必须将其转换为一种数据结构或可用格式，供算法从中发现有价值的见解。因此，可用格式指的是可以在数据科学过程中被使用的模型中的数据。这种可用格式根据使用案例的不同而有所不同。
- en: 'This chapter will guide you through data munging, or the process of preparing
    the data. It covers the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将指导你完成数据清洗过程，或者说是数据准备过程。内容包括以下主题：
- en: What is data munging?
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是数据清洗？
- en: DataFrames.jl
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrames.jl
- en: Uploading data from a file
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文件上传数据
- en: Finding the required data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找所需数据
- en: Joins and indexing
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联接和索引
- en: Split-Apply-Combine strategy
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割-应用-合并策略
- en: Reshaping the data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据重塑
- en: Formula (ModelFrame and ModelMatrix)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公式（ModelFrame 和 ModelMatrix）
- en: PooledDataArray
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PooledDataArray
- en: Web scraping
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络抓取
- en: What is data munging?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是数据清洗？
- en: Munging comes from the term "munge," which was coined by some students of Massachusetts
    Institute of Technology, USA. It is considered one of the most essential parts
    of the data science process; it involves collecting, aggregating, cleaning, and
    organizing the data to be consumed by the algorithms designed to make discoveries
    or to create models. This involves numerous steps, including extracting data from
    the data source and then parsing or transforming the data into a predefined data
    structure. Data munging is also referred to as data wrangling.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清洗一词来源于“munge”一词，该词由美国麻省理工学院（MIT）的一些学生创造。它被认为是数据科学过程中最基本的部分之一；它涉及收集、聚合、清理和组织数据，以供设计好的算法进行发现或创建模型。这包括多个步骤，其中包括从数据源提取数据，然后将数据解析或转换为预定义的数据结构。数据清洗也被称为数据整理。
- en: The data munging process
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据清洗过程
- en: So what's the data munging process? As mentioned, data can be in any format
    and the data science process may require data from multiple sources. This data
    aggregation phase includes scraping it from websites, downloading thousands of
    `.txt` or `.log` files, or gathering the data from RDBMS or NoSQL data stores.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么是数据清洗过程呢？如前所述，数据可以是任何格式，且数据科学过程可能需要来自多个来源的数据。这个数据聚合阶段包括从网站抓取数据、下载成千上万的`.txt`或`.log`文件，或从关系数据库管理系统（RDBMS）或NoSQL数据存储中收集数据。
- en: It is very rare to find data in a format that can be used directly by the data
    science process. The data received is generally in a format unsuitable for modeling
    and analysis. Generally, algorithms require data to be stored in a tabular format
    or in matrices. This phase of converting the gathered raw data into the required
    format can get very complex and time consuming. But this phase creates the foundation
    of the sophisticated data analysis that can now be done.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 很少能找到可以直接用于数据科学过程的数据格式。收到的数据通常是不适合建模和分析的格式。通常，算法需要数据以表格格式或矩阵形式存储。将收集到的原始数据转换为所需格式的阶段可能非常复杂且耗时。但这个阶段为现在可以进行的复杂数据分析打下了基础。
- en: It is good to define the structure of the data that you will be feeding the
    algorithms in advance. This data structure is defined according to the nature
    of the problem. The algorithms that you have designed or will be designing should
    not just be able to accept this format of data, but they should also be able to
    easily identify the patterns, find the outliers, make discoveries, or meet whatever
    the desired outcomes are.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 提前定义将输入到算法中的数据结构是很好的做法。这个数据结构是根据问题的性质定义的。你设计或将要设计的算法不仅要能够接受这种格式的数据，还应该能够轻松识别模式，找到异常值，做出发现，或满足任何所需的结果。
- en: After defining how the data will be structured, you define the process to achieve
    that. This is like a pipeline that will accept some forms of data and will give
    out meaningful data in a predefined format. This phase consists of various steps.
    These steps include converting data from one form to another, which may or may
    not require string operations or regular expressions, and finding the missing
    values and outliers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义数据的结构之后，您需要定义实现该结构的过程。这就像一个管道，接受某些形式的数据，并以预定义的格式输出有意义的数据。这个阶段包含多个步骤。这些步骤包括将数据从一种形式转换为另一种形式，这可能需要也可能不需要字符串操作或正则表达式，并且需要找到缺失值和异常值。
- en: Generally, data science problems revolve around two kinds of data. These two
    kinds of data will be either categorical or numerical. Categorical data comes
    with labels. These labels are formed by some group of values. For example, we
    can treat weather with categorical features. Weather can be sunny, cloudy, rainy,
    foggy, or snowy. These labels are formed when the underlying values are associated
    with one of the groups of the data (which comes under a label). These labels have
    some unique characteristics and we may not be able to apply arithmetic operations
    on them.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，数据科学问题涉及两种类型的数据。这两种数据将是分类数据或数值数据。分类数据带有标签。这些标签由一组值组成。例如，我们可以将天气视为具有分类特征的数据。天气可以是晴天、多云、下雨、雾霾或雪天。当底层值与数据中的某一组（属于一个标签）关联时，就会形成这些标签。这些标签具有一些独特的特性，我们可能无法对它们进行算术运算。
- en: Numerical data is much more common, for example, temperature. Temperature will
    be in floating-point numbers and we can certainly apply mathematical operations
    on it. Every value is comparable with other values in the dataset, so we can say
    that they have a direct relation with each other.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数值数据更为常见，例如温度。温度将以浮动点数表示，我们当然可以对其应用数学运算。每个值都可以与数据集中的其他值进行比较，因此我们可以说它们彼此之间有直接的关系。
- en: What is a DataFrame?
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 DataFrame？
- en: A DataFrame is a data structure that has labeled columns, which individually
    may have different data types. Like a SQL table or a spreadsheet, it has two dimensions.
    It can also be thought of as a list of dictionaries, but fundamentally, it is
    different.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 是一种数据结构，具有标签化的列，每一列可能具有不同的数据类型。像 SQL 表格或电子表格一样，它具有二维结构。它也可以被看作是一个字典的列表，但从根本上讲，它是不同的。
- en: DataFrames are the recommended data structure for statistical analysis. Julia
    provides a package called `DataFrames.jl` , which have all necessary functions
    to work with DataFrames.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrames 是进行统计分析时推荐的数据结构。Julia 提供了一个名为 `DataFrames.jl` 的包，它包含了所有必要的函数来处理 DataFrame。
- en: 'Julia''s package, DataFrames, provides three data types:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Julia 的 DataFrames 包提供了三种数据类型：
- en: '`NA`: A missing value in Julia is represented by a specific data type, `NA.`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NA`：在 Julia 中，缺失值通过一个特定的数据类型 `NA` 表示。'
- en: '`DataArray`: The array type defined in the standard Julia library, though it
    has many features, doesn''t provide any specific functionalities for data analysis.
    DataArray provided in `DataFrames.jl` provides such features (for example, if
    we required to store in an array some missing values).'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DataArray`：在标准 Julia 库中定义的数组类型，尽管它具有许多功能，但并未提供任何专门用于数据分析的功能。`DataFrames.jl`
    中提供的 DataArray 提供了这些功能（例如，如果我们需要在数组中存储缺失值）。'
- en: '`DataFrame`: DataFrame is 2-D data structure, like spreadsheets. It is much
    like R or pandas''s DataFrames, and provides many functionalities to represent
    and analyze data.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DataFrame`：DataFrame 是一个二维数据结构，像电子表格一样。它非常类似于 R 或 pandas 的 DataFrame，提供了许多功能来表示和分析数据。'
- en: The NA data type and its importance
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NA 数据类型及其重要性
- en: In the real world, we come across data with missing values. It is very common
    but it's not provided in Julia by default. This functionality is added using the
    `DataFrames.jl` package. The DataFrames package brings with it DataArray packages,
    which provide NA data type. Multiple dispatch is one of the most powerful features
    of Julia and NA is one such example. Julia has NA type, which provides the singleton
    object NA that we are using to represent missing values.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，我们常常遇到带有缺失值的数据。这是非常常见的，但 Julia 默认情况下并不提供这一功能。这个功能是通过 `DataFrames.jl`
    包来添加的。DataFrames 包带来了 DataArray 包，它提供了 NA 数据类型。多重派发是 Julia 最强大的特性之一，NA 就是一个例子。Julia
    有 NA 类型，提供了一个单例对象 NA，我们用它来表示缺失值。
- en: Why is the NA data type needed?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么需要 NA 数据类型？
- en: 'Suppose, for example, we have a dataset having floating-point numbers:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个包含浮动点数的数据集：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This will create a six-element `Array{Float64,1}`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个六元素的 `Array{Float64,1}`。
- en: 'Now, suppose this dataset has a missing value at position [1]. That means instead
    of 1.1, there is no value. This cannot be represented by the array type in Julia.
    When we try to assign an NA value, we get this error:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设这个数据集在位置[1]处有一个缺失值。这意味着，1.1的位置没有值。这不能通过Julia的数组类型表示。当我们尝试分配一个NA值时，会出现这个错误：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Therefore, right now we cannot add `NA` values to the array that we have created.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，目前我们无法将`NA`值添加到我们创建的数组中。
- en: 'So, to load the data into an array that does have `NA` values, we use `DataArray.`
    This enables us to have NA values in our dataset:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，为了将数据加载到包含`NA`值的数组中，我们使用`DataArray`。这使我们能够在数据集中包含NA值：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This will create a six-element `DataArrays.DataArray{Float64,1}`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个六元素的`DataArrays.DataArray{Float64,1}`。
- en: 'So, when we try to have an `NA` value, it gives us:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，当我们尝试包含`NA`值时，它会返回：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Therefore, by using DataArrays, we can handle missing data. One more feature
    provided is that NA doesn't always affect functions applied on the particular
    dataset. So, the method that doesn't involve an NA value or is not affected by
    it can be applied on the dataset. If it does involve the NA value, then it will
    give NA as the result.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过使用DataArrays，我们可以处理缺失数据。另一个提供的功能是，NA值并不总是影响应用于特定数据集的函数。因此，那些不涉及NA值或不受其影响的方法可以应用于数据集。如果涉及NA值，那么结果将是NA。
- en: 'In the following example, we are applying the mean function and `true || x`.
    The mean function doesn''t work as it involves an NA value, but `true || x` works
    as expected:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们正在应用均值函数和`true || x`。由于涉及NA值，均值函数无法正常工作，而`true || x`则按预期工作：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: DataArray – a series-like data structure
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DataArray – 类似系列的数据结构
- en: In the previous section, we discussed how DataArrays are used to store datasets
    containing missing (NA) values, as Julia's standard Array type cannot do so.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一部分中，我们讨论了如何使用DataArrays来存储包含缺失（NA）值的数据集，因为Julia的标准数组类型无法做到这一点。
- en: There are other features similar to Julia's Array type. Type aliases of Vector
    (one-dimensional Array type) and Matrix (two-dimensional Array type) are DataVector
    and DataMatrix provided by DataArray.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些与Julia的数组类型类似的特性。DataArray提供了Vector（一维数组类型）和Matrix（二维数组类型）的类型别名，分别是DataVector和DataMatrix。
- en: 'Creating a 1-D DataArray is similar to creating an Array:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个一维DataArray类似于创建一个数组：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here, we have NA values, unlike in Arrays. Similarly, we can create a 2-D DataArray,
    which will be a DataMatrix:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有NA值，不像数组中那样。类似地，我们可以创建一个二维DataArray，它将是一个DataMatrix。
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the previous example, to the calculate mean, we used slicing. This is not
    a convenient method to remove or not to consider the NA values while applying
    a function. A much better way is to use `dropna`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们通过切片来计算均值。这并不是一个方便的方式来在应用函数时忽略或排除NA值。一个更好的方法是使用`dropna`：
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: DataFrames – tabular data structures
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DataFrames – 表格数据结构
- en: 'Arguably, this is the most important and commonly used data type in statistical
    computing, whether it is in R (data.frame) or Python (Pandas). This is due to
    the fact that all the real-world data is mostly in tabular or spreadsheet-like
    format. This cannot be represented by a simple DataArray:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，这在统计计算中是最重要且最常用的数据类型，无论是在R（data.frame）中，还是在Python（Pandas）中。这是因为所有现实世界中的数据大多数以表格或类似电子表格的格式存在。这个格式不能仅通过简单的DataArray表示：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![DataFrames – tabular data structures](img/B05321_02_01.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![DataFrames – 表格数据结构](img/B05321_02_01.jpg)'
- en: 'This dataset, for example, can''t be represented using DataArray. The given
    dataset has the following features because it cannot be represented by DataArray:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这个数据集不能通过DataArray表示。给定的数据集具有以下特征，因此无法由DataArray表示：
- en: This dataset has different types of data in different columns. These different
    data types in different columns cannot be represented using a matrix. Matrix can
    only contain values of one type.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个数据集在不同的列中包含不同类型的数据。不同列中的不同数据类型无法通过矩阵表示。矩阵只能包含一种类型的值。
- en: It is a tabular data structure and records have relations with other records
    in the same row of different columns. Therefore, it is a must that all the columns
    are of the same length. Vectors cannot be used because same-length columns cannot
    be enforced using them. Therefore, a column in DataFrame is represented by DataArray.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是一个表格数据结构，记录与同一行中不同列的其他记录有关。因此，所有列必须具有相同的长度。不能使用向量，因为它们无法强制确保列的长度相同。因此，DataFrame中的一列由DataArray表示。
- en: In the preceding example, we can see that the columns are labeled. This labeling
    helps us to easily become familiar with the data and access it without the need
    to remember its exact positions. So, the columns are accessible using numerical
    indices and also by their label.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们可以看到列已被标记。这个标记帮助我们轻松熟悉数据并在无需记住精确位置的情况下访问它。因此，可以通过数字索引以及列标签来访问这些列。
- en: Therefore, due to these reasons, the DataFrames package is used. So, DataFrames
    are used to represent tabular data having DataArrays as columns.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，出于这些原因，使用了 DataFrames 包。DataFrames 用于表示具有 DataArrays 作为列的表格数据。
- en: 'In the given example, we constructed a DataFrame by:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定的例子中，我们通过以下方式构建了一个 DataFrame：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Using the keyword arguments, column names can be defined.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用关键字参数，可以定义列名称。
- en: 'Let''s take another example by constructing a new DataFrame:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过构建一个新的 DataFrame 来举个例子：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To find out the size of the DataFrame created, we use the size function:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看创建的 DataFrame 的大小，我们使用 size 函数：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, `10` refers to the number of rows and `2` refers to the number of columns.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`10`指的是行数，`2`指的是列数。
- en: 'To view the first few lines of the dataset, we use `head()`, and for the last
    few lines, we use the `tail()` function:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看数据集的前几行，我们使用`head()`，要查看最后几行，我们使用`tail()`函数：
- en: '[PRE12]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![DataFrames – tabular data structures](img/B05321_02_02.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![DataFrames – 表格数据结构](img/B05321_02_02.jpg)'
- en: As we have given names to the columns of the DataFrame, these can be accessed
    using these names.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已为 DataFrame 的列命名，因此可以通过这些名称来访问它们。
- en: 'For example:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This simplifies access to the columns as we can give meaningful names to real-world
    datasets that have numerous columns without the need to remember their numeric
    indices.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这简化了对列的访问，因为我们可以为具有多个列的现实世界数据集赋予有意义的名称，而无需记住它们的数字索引。
- en: 'If needed, we can also rename using these columns by using the rename function:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，我们还可以使用`rename`函数通过这些列来重命名：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If there is a need to rename multiple columns, then it is done by using this:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要重命名多个列，可以使用以下方法：
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: But right now, we are sticking to old column names for ease of use.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在，为了方便起见，我们仍然使用旧的列名。
- en: 'Julia also provides a function called `describe()`, which summarizes the entire
    dataset. For a dataset with many columns, it can turn out to be very useful:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Julia 还提供了一个名为`describe()`的函数，可以概述整个数据集。对于包含许多列的数据集，它会非常有用：
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Installation and using DataFrames.jl
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装并使用 DataFrames.jl
- en: 'Installation is quite straightforward as it is a registered Julia package:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 安装非常简单，因为它是一个注册的 Julia 包：
- en: '[PRE17]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This adds all the required packages to the current namespace. To use the `DataFrames`
    package:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这将所有必需的包添加到当前命名空间。要使用`DataFrames`包：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'It is also good to have classical datasets that are common for learning purposes.
    These datasets can be found in the `RDatasets` package:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 还应该有一些常用于学习的经典数据集。这些数据集可以在`RDatasets`包中找到：
- en: '[PRE19]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The list of the R packages available can be found using:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的 R 包列表可以通过以下方式找到：
- en: '[PRE20]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here, you can see this:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，你可以看到这个：
- en: '[PRE21]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It contains datasets available to R. To use this `dataset`, simply use the
    following:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 它包含了可供R使用的数据集。要使用这个`dataset`，只需使用以下代码：
- en: '[PRE22]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Here, dataset is the function that takes two arguments.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`dataset`是一个接受两个参数的函数。
- en: The first argument is the name of the package and the second is the name of
    the dataset that we want to load.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数是包的名称，第二个参数是我们要加载的数据集的名称。
- en: 'In the following example, we loaded the famous iris dataset into the memory.
    You can see that the `dataset()` function has returned a DataFrame. The dataset
    contains five columns: `SepalLength`, `SepalWidth`, `PetalLength`, `PetalWidth`,
    and `Species`. It is quite easy to understand the data. A large number of samples
    have been taken for every species, and the length and width of sepal and petal
    have been measured, which can be used later to distinguish between them:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下例子中，我们将著名的鸢尾花数据集加载到内存中。你可以看到`dataset()`函数返回了一个 DataFrame。该数据集包含五列：`SepalLength`、`SepalWidth`、`PetalLength`、`PetalWidth`和`Species`。数据非常容易理解。每个物种都有大量的样本，且测量了萼片和花瓣的长度和宽度，这些数据可以用于后续区分物种：
- en: '![Installation and using DataFrames.jl](img/B05321_02_03.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![安装并使用 DataFrames.jl](img/B05321_02_03.jpg)'
- en: Actual data science problems generally do not deal with the artificial randomly
    generated data or data read through the command line. But they work on data that
    is loaded from files or any other external source. These files can have data in
    any format and we may have to process it before loading it to the dataframe.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的数据科学问题通常不会处理人工随机生成的数据或通过命令行读取的数据。而是处理从文件或任何其他外部来源加载的数据。这些文件可以包含任何格式的数据，我们可能需要在加载到数据框之前对其进行处理。
- en: Julia provides a `readtable()` function that can be used to read a tabular file
    in a dataframe. Generally, we come across datasets in comma-separated or tab-separated
    formats (CSV or TSV). The `readtable()` works perfectly with them.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Julia 提供了一个 `readtable()` 函数，可以用来读取数据框中的表格文件。通常，我们会遇到逗号分隔或制表符分隔的格式（CSV 或 TSV）。`readtable()`
    能很好地处理这些格式。
- en: We can give the location of the file as UTF8String and the separator type to
    the readtable() function as arguments. The default separator type is comma (',')
    for CSV, tab ('\t') for TSV, and whitespace (' ') for WSV.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将文件的位置作为 UTF8String 和分隔符类型作为参数传递给 `readtable()` 函数。默认的分隔符类型是逗号（','）用于 CSV，制表符（'\t'）用于
    TSV，空格（' '）用于 WSV。
- en: In the following example, we load the sample iris dataset into a dataframe using
    the `readtable()` function.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们使用 `readtable()` 函数将示例 iris 数据集加载到数据框中。
- en: Although the iris dataset is available in the RDatasets package, we will download
    the CSV to work with the external datasets. The iris CSV can be downloaded from
    [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/datasets/data/iris.csv](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/datasets/data/iris.csv).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 iris 数据集可以在 RDatasets 包中找到，但我们将下载 CSV 文件以处理外部数据集。可以从 [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/datasets/data/iris.csv](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/datasets/data/iris.csv)
    下载 iris CSV。
- en: 'Remember to put the downloaded CSV into the current working directory (from
    where the REPL was started—generally it is the `~/home/<username>` directory):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住将下载的 CSV 文件放入当前工作目录（即从 REPL 启动的目录—通常是 `~/home/<username>` 目录）：
- en: '[PRE23]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: It is the same dataset that we used in the previous example, but now we are
    loading the data from a CSV file.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们在前一个示例中使用的相同数据集，但现在我们是从 CSV 文件加载数据。
- en: 'The `readtable()` is used in a similar way for other text-based datasets such
    as TSV, WSV, or TXT. Suppose the same iris dataset is in TSV, WSV, or TXT format.
    It will be used in a similar way:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他基于文本的数据集，如 TSV、WSV 或 TXT，`readtable()` 也以类似的方式使用。假设相同的 iris 数据集在 TSV、WSV
    或 TXT 格式中，它的使用方式是类似的：
- en: '[PRE24]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'And for example, if we have a dataset without a header and separated by `;`,
    we would use `readtable()` as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 举例来说，如果我们有一个没有头部且以 `;` 分隔的数据集，我们可以如下使用 `readtable()`：
- en: '[PRE25]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The `readtable()` exploits Julia''s functionality of multiple dispatch and
    has been implemented with different method behaviors:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`readtable()` 利用了 Julia 的多重分派功能，并已根据不同的方法行为进行实现：'
- en: '[PRE26]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We can see that there are three methods for the `readtable()` function.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到 `readtable()` 函数有三种方法。
- en: 'These methods implement some of the advanced options to ease the loading and
    to support various kinds of data formats:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法实现了一些高级选项，以简化加载并支持各种数据格式：
- en: '`header::Bool`: In the iris example we used, we had headers such as Sepal Length,
    Sepal Width, and so on, which makes it easier to describe the data. But headers
    are not always available in the dataset. The default value of `header` is `true`;
    therefore, whenever headers are not available, we pass the argument as false.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`header::Bool`：在我们使用的 iris 示例中，数据集包含如花萼长度、花萼宽度等头部信息，这使得描述数据更加容易。但数据集并不总是有头部信息。`header`
    的默认值是 `true`；因此，当没有头部信息时，我们将该参数设置为 false。'
- en: '`separator::Char`: Data in a file must have been organized in the file in a
    way to form a tabular structure. This is generally by using `,`, `\t`, `;`, or
    combinations of these sometimes. The `readtable()` guesses the separator type
    by the extension of the file, but it is a good practice to provide it manually.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`separator::Char`：文件中的数据必须按照一定的方式组织，以形成表格结构。这通常是通过使用 `,`、`\t`、`;` 或这些符号的组合来实现的。`readtable()`
    根据文件扩展名猜测分隔符类型，但手动提供分隔符是一个好习惯。'
- en: '`nastrings::Vector{ASCIIString}`: Suppose there are missing values or some
    other values and we want NA to replace them. This is done using nastrings. By
    default, it takes empty records and replaces them with NA.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nastrings::Vector{ASCIIString}`：假设存在缺失值或其他值，我们希望用 NA 替换它们。通过 nastrings 可以实现这一点。默认情况下，它会将空记录替换为
    NA。'
- en: '`truestrings::Vector{ASCIIString}`: This transforms the strings to Boolean,
    true. It is used when we want a set of strings to be treated as true in the dataset.
    By default, `True`, `true`, `T`, and `t` are transformed if no argument is given.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truestrings::Vector{ASCIIString}`: 这将字符串转换为布尔值 true。当我们希望数据集中一组字符串被视为 true
    时使用。默认情况下，如果没有参数指定，`True`、`true`、`T` 和 `t` 会被转换为 true。'
- en: '`falsestrings::Vector{ASCIIString}`: This works just like truestrings but transforms
    the strings to Boolean, false. By default, `False`, `false`, `F`, and `f` are
    transformed if no argument is given.'
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`falsestrings::Vector{ASCIIString}`: 这与 truestrings 类似，但将字符串转换为布尔值 false。默认情况下，如果没有传递参数，`False`、`false`、`F`
    和 `f` 会被转换为 false。'
- en: '`nrows::Int`: If we want only a specific number of rows to be read by `readtable()`,
    we use nrows as the argument. By default, it is `-1`, which means that `readtable()`
    will read the whole file.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nrows::Int`: 如果我们只想由 `readtable()` 读取特定数量的行，则使用 nrows 作为参数。默认情况下为 `-1`，这意味着
    `readtable()` 将读取整个文件。'
- en: '`names::Vector{Symbol}`: If we want some specific names for our columns, different
    from what is mentioned in the header, then we use names. Here, we pass a vector
    having the names of the columns that we want to use. By default, it is `[]`, which
    means the names in the headers should be used if they are there; otherwise, the
    numeric indices must be used.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`names::Vector{Symbol}`: 如果我们希望为列指定特定名称，而不使用文件头中提到的名称，则使用 names。在这里，我们传递一个包含要使用的列名称的向量。默认情况下，它是
    `[]`，这意味着如果存在文件头，则应使用其中的名称；否则必须使用数值索引。'
- en: '`eltypes::Vector{DataType}`: We can specify the column types by passing a vector,
    by using eltypes. It is an empty vector (`[]`) by default if nothing is passed.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eltypes::Vector{DataType}`: 我们可以通过传递一个向量来指定列的类型，使用 eltypes。如果没有传递任何内容，默认情况下它是一个空向量（`[]`）。'
- en: '`allowcomments::Bool`: In the dataset, we may have records having comments
    with them. These comments can be ignored. By default, it is `false`.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`allowcomments::Bool`: 在数据集中，可能会有带有注释的记录。这些注释可以被忽略。默认情况下为 `false`。'
- en: '`commentmark::Char`: If we are using allowcomments, we will also have to mention
    the character (symbol) where the comment starts. By default, it is `#`.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commentmark::Char`: 如果我们使用 allowcomments，还必须指定注释开始的字符（符号）。默认情况下为 `#`。'
- en: '`ignorepadding::Bool`: Our dataset might not be as perfect as we want. The
    records may contain whitespace characters on either side. This can be ignored
    using ignorepadding. By default, it is true.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignorepadding::Bool`: 我们的数据集可能不如我们希望的那样完美。记录可能包含左右两侧的空白字符。可以使用 ignorepadding
    忽略这些空白。默认情况下为 true。'
- en: '`skipstart::Int`: Our dataset can have some rows describing the data with the
    header that we might not want, or we just want to skip the first few rows. This
    is done by skipstart, by specifying the number of rows to skip. By default, it
    is 0 and will read the entire file.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skipstart::Int`: 我们的数据集可能包含一些描述数据的行，而我们可能不需要或者只想跳过开头的几行。通过 skipstart 指定要跳过的行数来实现这一点。默认情况下为
    0，将读取整个文件。'
- en: '`skiprows::Vector{Int}`: If want to skip some specific rows in the data then
    skiprows is used. We only need to specify the indices of the rows in a vector
    that we want to skip. By default, it is `[]` and will read the entire file.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skiprows::Vector{Int}`: 如果想要跳过数据中的特定行，则使用 skiprows。我们只需在一个向量中指定要跳过的行的索引。默认情况下为
    `[]`，将读取整个文件。'
- en: '`skipblanks::Bool`: As mentioned earlier, our dataset may not be perfect. There
    can be some blank lines if we have scraped the data from the Web or extracted
    the data from other sources. We can skip these blank lines by using skipblanks.
    By default it is true, but we can choose otherwise if we do not want it.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skipblanks::Bool`: 正如前面提到的，我们的数据集可能不完美。如果我们从网页上抓取数据或从其他来源提取数据，可能会有一些空白行。我们可以使用
    skipblanks 跳过这些空白行。默认情况下为 true，但如果不想要，则可以选择其他设置。'
- en: '`encoding::Symbol`: We can specify the encoding of the file if it is other
    than UTF8.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoding::Symbol`: 如果文件的编码不是 UTF8，我们可以指定文件的编码。'
- en: Writing the data to a file
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将数据写入文件
- en: We may also want to output our results or transform a dataset and store it in
    a file. In Julia we do this by using the `writetable()` function. It is very similar
    to the `readtable()` function that we discussed in the last section.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也许希望输出结果或转换数据集并将其存储到文件中。在 Julia 中，我们使用 `writetable()` 函数来实现这一点。它与我们在上一节讨论的
    `readtable()` 函数非常相似。
- en: 'For example, we want to write the `df_iris_sample` dataframe into a CSV file:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们想将 `df_iris_sample` 数据框写入 CSV 文件：
- en: '[PRE27]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This is the way of writing to a file with the default set of arguments. One
    visible difference is that we are passing the dataframe that we want to write
    with the name of the file that we want to write to.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种使用默认参数集写入文件的方式。一个明显的区别是，我们传递了我们想要写入的文件名以及数据框（dataframe）。
- en: '`writetable()` also accepts various arguments such as `readtable()`.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`writetable()`同样接受各种参数，类似于`readtable()`。'
- en: 'We could have also written the previous statement like this with the separator
    defined:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以像这样定义分隔符来编写之前的语句：
- en: '[PRE28]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Similarly, we can have a header and quote marks in the arguments.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们也可以在参数中设置标题和引号。
- en: Working with DataFrames
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用DataFrames
- en: We will follow or inherit some of the traditional strategies to manipulate the
    data. We will go through these strategies and methods in this section and discuss
    how and why they are important to data science.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遵循或继承一些传统的数据操作策略。在本节中，我们将讨论这些策略和方法，并探讨它们在数据科学中的重要性。
- en: Understanding DataFrames joins
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解DataFrames连接
- en: While working with multiple datasets, we often need to merge the datasets in
    a particular fashion to make the analysis easier or to use it with a particular
    function.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理多个数据集时，我们通常需要以特定的方式合并数据集，以便更容易进行分析或与特定的函数配合使用。
- en: We will be using the *Road Safety Data* published by the Department for Transport,
    UK, and it is open under the OGL-Open Government Licence.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用由英国交通部发布的*道路安全数据*，该数据开放，适用OGL-开放政府许可。
- en: 'The datasets can be found here: [https://data.gov.uk/dataset/road-accidents-safety-data](https://data.gov.uk/dataset/road-accidents-safety-data).'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以在这里找到：[https://data.gov.uk/dataset/road-accidents-safety-data](https://data.gov.uk/dataset/road-accidents-safety-data)。
- en: 'We will be using two datasets:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用两个数据集：
- en: 'Road Safety: Accidents 2015'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 道路安全：2015年事故数据
- en: 'Road Safety: Vehicles 2015'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 道路安全：2015年车辆数据
- en: Note
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '`DfTRoadSafety_Accidents_2015` contains columns such as `Accident_Index`, `Location_Easting_OSGR`,
    `Location_Northing_OSGR`, `Longitude`, `Latitude`, `Police_Force`, `Accident_Severity`,
    `Number_of_Vehicles`, `Number_of_Casualties`, `Date`, `Day_of_Week`, `Time`, and
    so on. `DfTRoadSafety_Vehicles_2015` contains columns such as `Accident_Index`,
    `Vehicle_Reference`, `Vehicle_Type`, `Towing_and_Articulation`, `Vehicle_Manoeuvre`,
    `Vehicle_Location-Restricted_Lane`, `Junction_Location`, `Skidding_and_Overturning`,
    `Hit_Object_in_Carriageway`, and so on.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`DfTRoadSafety_Accidents_2015`包含的列有`Accident_Index`、`Location_Easting_OSGR`、`Location_Northing_OSGR`、`Longitude`、`Latitude`、`Police_Force`、`Accident_Severity`、`Number_of_Vehicles`、`Number_of_Casualties`、`Date`、`Day_of_Week`、`Time`等。`DfTRoadSafety_Vehicles_2015`包含的列有`Accident_Index`、`Vehicle_Reference`、`Vehicle_Type`、`Towing_and_Articulation`、`Vehicle_Manoeuvre`、`Vehicle_Location-Restricted_Lane`、`Junction_Location`、`Skidding_and_Overturning`、`Hit_Object_in_Carriageway`等。'
- en: We can see that `Accident_Index` is a common field and is unique. It is used
    as the index in the dataset.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到`Accident_Index`是一个共同的字段，并且是唯一的。它被用作数据集的索引。
- en: 'First we will be making the DataFrames package available and then we will load
    the data. We load the data into two different dataframes using the readtable function
    that we discussed earlier:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使DataFrames包可用，然后加载数据。我们使用之前讨论过的`readtable`函数将数据加载到两个不同的数据框中：
- en: '[PRE29]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![Understanding DataFrames joins](img/image_02_004.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![理解DataFrames连接](img/image_02_004.jpg)'
- en: The first dataset is loaded into the DataFrame and we try getting information
    about the dataset using `head`. It gives a few starting columns.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个数据集已经加载到DataFrame中，我们尝试使用`head`获取数据集的信息。它会显示一些起始的列。
- en: 'If we are more interested in knowing the names of the columns, we can use the
    `names` function:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们更关心列的名称，可以使用`names`函数：
- en: '[PRE30]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Similarly, we will be loading the second dataset in a dataframe:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们将在一个数据框中加载第二个数据集：
- en: '[PRE31]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The second dataset is loaded into the memory.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个数据集已经加载到内存中。
- en: 'Later we will delve deeper, but for now let''s do a full join between the two
    datasets. A join between these two datasets will tell us which accident involved
    which vehicles:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后我们将深入探讨，但现在我们先进行两个数据集的全连接操作。对这两个数据集进行连接将告诉我们哪起事故涉及了哪些车辆：
- en: '[PRE32]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![Understanding DataFrames joins](img/image_02_005.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![理解DataFrames连接](img/image_02_005.jpg)'
- en: We can see that the full join has worked. Now we have the data, which can tell
    us the time of the accident, the location of the vehicle, and many more details.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到全连接（full join）已经成功执行。现在我们得到了数据，可以告诉我们事故发生的时间、车辆的位置以及更多细节。
- en: The benefit is that the join is really easy to do and is really quick, even
    over large datasets.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这个好处是，连接操作非常简单，甚至在处理大数据集时也非常快速。
- en: 'We have read about other joins available in relation databases. Julia''s DataFrames
    package provides these joins too:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了关系数据库中其他可用的连接类型。Julia 的 DataFrames 包也提供了这些连接：
- en: '**Inner join**: The output, which is the DataFrame, contains only those rows
    that have keys in both the dataframes.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内连接**：输出的 DataFrame 仅包含在两个 DataFrame 中都存在的键对应的行。'
- en: '**Left join**: The output DataFrame has the rows for keys that are present
    in the first (left) DataFrame, irrespective of them being present in the second
    (right) DataFrame.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**左连接**：输出的 DataFrame 包含第一个（左）DataFrame 中存在的键的行，无论这些键是否存在于第二个（右）DataFrame 中。'
- en: '**Right join**: The output DataFrame has the rows for keys that are present
    in the second (right) DataFrame, irrespective of them being present in the first
    (left) DataFrame.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**右连接**：输出的 DataFrame 包含第二个（右）DataFrame 中存在的键的行，无论这些键是否存在于第一个（左）DataFrame 中。'
- en: '**Outer join**: The output DataFrame has the rows for the keys that are present
    in the first or second DataFrame, which we are joining.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外连接**：输出的 DataFrame 包含第一个或第二个 DataFrame 中存在的键的行，这些键是我们要连接的。'
- en: '**Semi join**: The output DataFrame has only the rows from the first (left)
    DataFrame for the keys that are present in both the first (left) and second (right)
    DataFrames. The output contains only rows from the first DataFrame.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**半连接**：输出的 DataFrame 仅包含在第一个（左）DataFrame 中的那些键，且这些键在第一个（左）和第二个（右）DataFrame
    中都存在。输出只包含来自第一个 DataFrame 的行。'
- en: '**Anti join**: The output DataFrame has the rows for keys that are present
    in the first (left) DataFrame but rows for the same keys are not present in the
    second (right) DataFrame. The output contains only rows from the first DataFrame.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反连接**：输出的 DataFrame 包含第一个（左）DataFrame 中存在的键的行，但这些键在第二个（右）DataFrame 中没有对应的行。输出仅包含来自第一个
    DataFrame 的行。'
- en: '**Cross join**: The output DataFrame has the rows that are the Cartesian product
    of the rows from the first DataFrame (left) and the second DataFrame (right).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交叉连接**：输出的 DataFrame 包含来自第一个 DataFrame（左）和第二个 DataFrame（右）的行的笛卡尔积。'
- en: 'Cross join doesn''t involve a key; therefore it is used like this:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉连接不涉及键；因此它的使用方式如下：
- en: '[PRE33]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Here we have used the `kind` argument to pass the type of join that we want.
    Other joins are also done using this argument.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用 `kind` 参数传递我们想要的连接类型。其他连接也是通过这个参数来完成的。
- en: The kind of join that we want to use is done using the `kind` argument.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要使用的连接类型是通过 `kind` 参数来指定的。
- en: 'Let''s understand this using a simpler dataset. We will create a dataframe
    and will apply different joins on it:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个更简单的数据集来理解这一点。我们将创建一个 DataFrame，并在其上应用不同的连接：
- en: '[PRE34]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'For left join, we can use:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于左连接，我们可以使用：
- en: '[PRE35]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This created two dataframes having 10 rows. The first dataframe, df1, has three
    columns: `ID`, `City`, and `RandomValue1`. The second dataframe has df2 with three
    columns: `ID`, `City`, and `RandomValue2`.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这创建了两个具有 10 行的 DataFrame。第一个 DataFrame df1 有三列：`ID`、`City` 和 `RandomValue1`。第二个
    DataFrame df2 也有三列：`ID`、`City` 和 `RandomValue2`。
- en: 'Applying full join, we can use:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 应用全连接时，我们可以使用：
- en: '[PRE36]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We have used two columns to apply the join.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了两列来应用连接。
- en: 'This will generate:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成：
- en: '![Understanding DataFrames joins](img/image_02_006.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![理解 DataFrame 连接](img/image_02_006.jpg)'
- en: Other joins can also be applied using the `kind` argument. Let's go through
    our old dataset of accidents and vehicles.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 其他连接也可以通过 `kind` 参数应用。让我们回顾一下我们之前的事故和车辆数据集。
- en: 'The different joins using `kind` are:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `kind` 的不同连接是：
- en: '[PRE37]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The Split-Apply-Combine strategy
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分割-应用-合并策略
- en: 'A paper was published by Hadley Wickham (Wickham, Hadley. "The split-apply-combine
    strategy for data analysis." *Journal of Statistical Software* 40.1 (2011): 1-29),
    defining the Split-Apply-Combine strategy for data analysis. In this paper, he
    explained why it is good to break up a big problem into manageable pieces, independently
    operate on each piece, obtain the necessary results, and then put all the pieces
    back together.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 'Hadley Wickham 发表了一篇论文（Wickham, Hadley. "The split-apply-combine strategy for
    data analysis." *Journal of Statistical Software* 40.1 (2011): 1-29），定义了数据分析的分割-应用-合并策略。在这篇论文中，他解释了为什么将一个大问题分解成易于管理的小部分，独立地对每个部分进行操作，获取所需结果，然后再将所有部分组合起来是好的。'
- en: This is needed when a dataset contains a large number of columns and for some
    operations all the columns are not necessary. It is better to split the dataset
    and then apply the necessary functions; and we can always put the dataset back
    together.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据集包含大量列时，并且在某些操作中并不需要所有列时，就需要这样做。最好是将数据集拆分，然后应用必要的函数；我们可以随时将数据集重新合并。
- en: 'This is done using the by function by takes three arguments:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过 `by` 函数完成的，`by` 接受三个参数：
- en: DataFrame (this is the dataframe that we would be splitting)
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrame（这是我们将要分割的 DataFrame）
- en: The column name (or numerical index) on which the DataFrame would be split
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于分割 DataFrame 的列名（或数值索引）
- en: A function that can be applied on every subset of the DataFrame
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以应用于 DataFrame 每个子集的函数
- en: 'Let''s try to apply by to our same dataset:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试将 `by` 应用到我们的相同数据集：
- en: '![The Split-Apply-Combine strategy](img/B05321_02_07.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![拆分-应用-合并策略](img/B05321_02_07.jpg)'
- en: 'The `aggregate()` function provides an alternative to apply the Split-Apply-Combine
    strategy. The `aggregate()` function uses the same three arguments:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '`aggregate()` 函数提供了一种替代方法来应用 Split-Apply-Combine 策略。`aggregate()` 函数使用相同的三个参数：'
- en: DataFrame (this is the DataFrame that we would be splitting)
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrame（这是我们将要分割的 DataFrame）
- en: The column name (or numerical index) on which the DataFrame would be split
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于分割 DataFrame 的列名（或数值索引）
- en: A function that can be applied on the every subset of the DataFrame
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以应用于 DataFrame 每个子集的函数
- en: The function provided in the third argument is applied to every column, which
    wasn't used in splitting up the DataFrame.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个参数中提供的函数会应用于每一列，所有未用于分割 DataFrame 的列都会应用该函数。
- en: Reshaping the data
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重塑数据
- en: The use case may require data to be in a different shape than we currently have.
    To facilitate this, Julia provides reshaping of the data.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 使用案例可能要求数据以不同于当前的形状存在。为了方便这一点，Julia 提供了数据的重塑功能。
- en: 'Let''s use the same dataset that we were using, but before that let''s check
    the size of the dataset:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用相同的数据集，但在此之前先检查一下数据集的大小：
- en: '[PRE38]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We can see that there are greater than 100,000 rows. Although we can work on
    this data, for simplicity of understanding, let's take a smaller dataset.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到数据行数大于 100,000。尽管我们可以处理这些数据，但为了便于理解，我们将使用一个较小的数据集。
- en: Datasets provided in RDataset are always good to start with. We will use the
    tried and tested iris dataset for this.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: RDataset 提供的数据集总是很好的起点。我们将使用经过验证的 iris 数据集。
- en: 'We will import `RDatasets` and `DataFrames` (if we have started a new terminal
    session):'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将导入 `RDatasets` 和 `DataFrames`（如果我们开始了一个新的终端会话）：
- en: '[PRE39]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Then, we will load the iris dataset into a `DataFrame`. We can see that the
    dataset has 150 rows and 5 columns:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将加载 iris 数据集到 `DataFrame` 中。我们可以看到数据集有 150 行和 5 列：
- en: '![Reshaping the data](img/B05321_02_08.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/B05321_02_08.jpg)'
- en: Now we use the `stack()` function to reshape the dataset. Let's use it without
    any arguments except the DataFrame.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用 `stack()` 函数来重塑数据集。让我们只传递 DataFrame 作为唯一参数来使用它。
- en: 'Stack works by creating a dataframe for categorical variables with all of the
    information one by one:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '`stack` 通过为分类变量创建一个逐项包含所有信息的 DataFrame 来工作：'
- en: '![Reshaping the data](img/B05321_02_09.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/B05321_02_09.jpg)'
- en: 'We can see that our dataset has been stacked. Here we have stacked all the
    columns. We can also provide specific columns to stack:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到我们的数据集已经堆叠。这里我们已经堆叠了所有的列。我们还可以提供特定的列进行堆叠：
- en: '[PRE40]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The second argument depicts the columns that we want to stack. We can see in
    the result that column 1 to 4 have been stacked, which means we have reshaped
    the dataset into a new dataframe:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数表示我们想要堆叠的列。我们可以在结果中看到第 1 到第 4 列已被堆叠，这意味着我们已经将数据集重塑为一个新的 DataFrame：
- en: '[PRE41]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![Reshaping the data](img/image_02_010.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/image_02_010.jpg)'
- en: We can see that there is a new column `:id`. That's the identifier of the stacked
    dataframe. Its value is repeated the number of times the rows are repeated.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到有一个新的列`:id`，这是堆叠数据框的标识符。它的值是按行重复的次数。
- en: As all the columns are included in the resultant DataFrame, there is repetition
    for some columns. These columns are actually the identifiers for this DataFrame
    and are denoted by the column (`id`). Other than the identifiers column (`:id`),
    there are two more columns, `:variable` and `:values`. These are the columns that
    actually contain the stacked values.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有列都包含在结果 DataFrame 中，因此某些列会重复。这些列实际上是此 DataFrame 的标识符，用列(`id`)表示。除了标识符列(`:id`)，还有两列，`:variable`
    和 `:values`。这些列实际上包含了堆叠的值。
- en: '![Reshaping the data](img/image_02_011.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/image_02_011.jpg)'
- en: We can also provide a third argument (optional). This is the column whose values
    are repeated. Using this, we can specify which column to include and which not
    to include.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以提供第三个参数（可选）。这是值会重复的列。通过这个参数，我们可以指定要包括哪些列，哪些列不包括。
- en: '![Reshaping the data](img/B05321_02_12.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/B05321_02_12.jpg)'
- en: 'The `melt()` function is similar to the stack function but has some special
    features. Here we need to specify the identifier columns and the rest are stacked:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '`melt()` 函数类似于 stack 函数，但具有一些特殊功能。在这里，我们需要指定标识符列，其余的列会被堆叠：'
- en: '[PRE42]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![Reshaping the data](img/B05321_02_13.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/B05321_02_13.jpg)'
- en: The remaining columns are stacked with the assumption that they contain measured
    variables.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的列假设包含已测量的变量，并被堆叠。
- en: 'Opposite to stack and melt is unstack, which is used to convert from a long
    format to wide format. We need to specify the identifier columns and variable/value
    columns to the unstack function:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 与 stack 和 melt 相反的是 unstack，它用于将数据从长格式转换为宽格式。我们需要指定标识符列和变量/值列给 unstack 函数：
- en: '[PRE43]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![Reshaping the data](img/B05321_02_14.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/B05321_02_14.jpg)'
- en: '`:id` (identifier) in the arguments of the unstack can be skipped if the remaining
    columns are unique:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 unstack 函数的其余列是唯一的，可以省略参数中的 `:id`（标识符）：
- en: '[PRE44]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '`meltdf` and `stackdf` are two additional functions that work like melt and
    stack but also provide a view into the original wide DataFrame:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`meltdf` 和 `stackdf` 是两个附加函数，它们的作用类似于 melt 和 stack，但同时也提供了对原始宽格式 DataFrame
    的视图：'
- en: '[PRE45]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![Reshaping the data](img/B05321_02_15.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/B05321_02_15.jpg)'
- en: This seems exactly similar to the stack function, but we can see the difference
    by looking at their storage representation.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来和 stack 函数非常相似，但通过查看它们的存储表示，我们可以看到区别。
- en: 'To look at the storage representation, dump is used. Let''s apply it to the
    stack function:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看存储表示，可以使用 dump。让我们将其应用于 stack 函数：
- en: '![Reshaping the data](img/B05321_02_16.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/B05321_02_16.jpg)'
- en: Here, we can see that `:variable` is of type `Array(Symbol,(600,))`
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到 `:variable` 的类型为 `Array(Symbol,(600,))`
- en: '`:value` is of type `DataArrays.DataArray{Float64,1}(600)`'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:value` 的类型为 `DataArrays.DataArray{Float64,1}(600)`'
- en: Identifier (`:Species`) is of type `DataArrays.PooledDataArray{ASCIIString,UInt8,1}(600)`
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标识符（`:Species`）的类型为 `DataArrays.PooledDataArray{ASCIIString,UInt8,1}(600)`
- en: 'Now, we will look at the storage representation of `stackdf`:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将查看 `stackdf` 的存储表示：
- en: '![Reshaping the data](img/B05321_02_17.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/B05321_02_17.jpg)'
- en: 'Here, we can see that:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到：
- en: '`:variable` is of type `DataFrames.RepeatedVector{Symbol}`. Variable is repeated
    n times, where n refers to the number of rows in the original `AbstractDataFrame`.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:variable` 的类型为 `DataFrames.RepeatedVector{Symbol}`。变量被重复 n 次，其中 n 是原始 `AbstractDataFrame`
    中的行数。'
- en: '`:value` is of type `DataFrames.StackedVector`. This facilitates the view of
    the columns stacked together as in the original DataFrame.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:value` 的类型为 `DataFrames.StackedVector`。这便于查看原始 DataFrame 中堆叠在一起的列。'
- en: 'Identifier (`:Species`) is of type `Species: DataFrames.RepeatedVector{ASCIIString}`.
    The original column is repeated n times where n is the number of the columns stacked.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '标识符（`:Species`）的类型为 `Species: DataFrames.RepeatedVector{ASCIIString}`。原始列被重复
    n 次，其中 n 是堆叠的列数。'
- en: Using these AbstractVectors, we are now able to create views, thus saving memory
    by using this implementation.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些 AbstractVectors，我们现在能够创建视图，从而通过这种实现节省内存。
- en: Reshaping functions don't provide the capabilities to perform aggregation. So
    to perform aggregation, a combination of the Split-Apply-Combine strategy with
    reshaping is used.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 重塑函数不提供执行聚合的功能。因此，为了进行聚合，需要将拆分-应用-合并（Split-Apply-Combine）策略与重塑结合使用。
- en: 'We will use `iris_stack`:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `iris_stack`：
- en: '[PRE46]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![Reshaping the data](img/B05321_02_18.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/B05321_02_18.jpg)'
- en: Here, we created a new column having the mean values of the columns according
    to the species. We can now unstack this.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个新的列，根据物种计算各列的均值。现在我们可以对其进行反转。
- en: '![Reshaping the data](img/B05321_02_19.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![重塑数据](img/B05321_02_19.jpg)'
- en: Sorting a dataset
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 排序数据集
- en: Sorting is one of the most used techniques in data analysis. Sorting is facilitated
    in Julia by calling the `sort` or `sort!` function.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 排序是数据分析中最常用的技术之一。排序在 Julia 中通过调用 `sort` 或 `sort!` 函数来实现。
- en: The difference between the `sort` and `sort!` is that `sort!` works in-place,
    which sorts the actual array rather than creating a copy.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '`sort` 和 `sort!` 的区别在于，`sort!` 是就地排序，它直接对原始数组进行排序，而不是创建副本。'
- en: 'Let''s use the `sort!` function on the iris dataset:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在鸢尾花数据集上使用 `sort!` 函数：
- en: '![Sorting a dataset](img/B05321_02_20.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![排序数据集](img/B05321_02_20.jpg)'
- en: We can see that the columns are not sorted according to `[:SepalLength, :SepalWidth,
    :PetalLength, :PetalWidth]`. But these are actually sorted according to the :Species
    column.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这些列并不是按照 `[:SepalLength, :SepalWidth, :PetalLength, :PetalWidth]` 排序的，但它们实际上是按
    :Species 列排序的。
- en: 'The sorting function takes some arguments and provides a few features. For
    example, to sort in reverse, we have:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 排序函数接受一些参数，并提供一些功能。例如，要反向排序，我们可以：
- en: '[PRE47]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'To sort some specific columns, we have:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 要对某些特定列进行排序，我们可以：
- en: '[PRE48]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: We can also use the by function with `sort!` to apply another function on the
    DataFrame or the single column.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 `sort!` 的 by 函数，在 DataFrame 或单个列上应用其他函数。
- en: '![Sorting a dataset](img/B05321_02_21.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![排序数据集](img/B05321_02_21.jpg)'
- en: '`order` is used to specify ordering a specific column amongst a set of columns.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '`order` 用于指定在一组列中对特定列进行排序。'
- en: Formula - a special data type for mathematical expressions
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 公式 - 数学表达式的特殊数据类型
- en: Data science involves various statistical formulas to get insights from data.
    The creation and application of these formulas is one of the core processes of
    data science. It maps input variables with some function and mathematical expression
    to an output.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学涉及使用各种统计公式从数据中提取洞察。这些公式的创建和应用是数据科学的核心过程之一。它将输入变量通过某些函数和数学表达式映射到输出。
- en: 'Julia facilitates this by providing a formula type in the `DataFrame` package,
    which is used with the symbol `~`. `~` is a binary operator. For example:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: Julia 通过在 `DataFrame` 包中提供一种公式类型来简化这一过程，它与符号 `~` 一起使用。`~` 是一个二元操作符。例如：
- en: '[PRE49]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: For statistical modeling, it is recommended to use ModelMatrix, which constructs
    a Matrix{Float64}, making it more suited to fit in a statistical model. Formula
    can also be used to transform to a ModelFrame object from a DataFrame, which is
    a wrapper over it, to meet the needs of statistical modeling.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 对于统计建模，建议使用 ModelMatrix，它构建一个 Matrix{Float64}，使其更适合于统计模型的拟合。Formula 也可以用来从 DataFrame
    转换为 ModelFrame 对象，这是它的包装器，满足统计建模的需求。
- en: 'Create a dataframe with random values:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个包含随机值的数据框：
- en: '![Formula - a special data type for mathematical expressions](img/B05321_02_22.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![公式 - 数学表达式的特殊数据类型](img/B05321_02_22.jpg)'
- en: 'Use formula to transform it into a `ModelFrame` object:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 使用公式将其转换为 `ModelFrame` 对象：
- en: '![Formula - a special data type for mathematical expressions](img/B05321_02_23.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![公式 - 数学表达式的特殊数据类型](img/B05321_02_23.jpg)'
- en: 'Creating a `ModelMatrix` from a `ModelFrame` is quite easy:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 从 `ModelFrame` 创建 `ModelMatrix` 很容易：
- en: '![Formula - a special data type for mathematical expressions](img/B05321_02_24.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![公式 - 数学表达式的特殊数据类型](img/B05321_02_24.jpg)'
- en: There is an extra column containing only `value = 1.0`. It is used in a regression
    model to fit an intercept term.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一列仅包含 `value = 1.0`。它用于回归模型中拟合截距项。
- en: Pooling data
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 汇总数据
- en: To analyze huge datasets efficiently, PooledDataArray is used. DataArray uses
    an encoding that represents a full string for every entry of a vector. This is
    not very efficient, especially for large datasets and memory-intensive algorithms.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 为了高效地分析庞大的数据集，使用 PooledDataArray。DataArray 使用一种编码方式，为向量的每个条目表示一个完整的字符串。这种方式效率较低，特别是在处理大数据集和内存密集型算法时。
- en: 'Our use case more often deals with factors involving a small number of levels:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的使用案例更常涉及包含少量水平的因子：
- en: '![Pooling data](img/B05321_02_25.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![汇总数据](img/B05321_02_25.jpg)'
- en: '`PooledDataArray` uses indices in a small pool of levels instead of strings
    to represent data efficiently.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '`PooledDataArray` 使用一个较小的水平池中的索引，而不是使用字符串来高效地表示数据。'
- en: '![Pooling data](img/B05321_02_26.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![汇总数据](img/B05321_02_26.jpg)'
- en: '`PooledDataArray` also provides us with the functionality to find out the levels
    of the factor using the levels function:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '`PooledDataArray` 还提供了一个功能，可以使用 levels 函数来查找因子的水平：'
- en: '![Pooling data](img/B05321_02_27.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![汇总数据](img/B05321_02_27.jpg)'
- en: '`PooledDataArray` even provides a compact function to efficiently use memory:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '`PooledDataArray` 甚至提供了一个紧凑型函数来高效使用内存：'
- en: '[PRE50]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Then, it provides a pool function for converting a single column when factors
    are encoded not in `PooledDataArray` columns but in DataArray or DataFrame:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它提供了一个池函数，用于在因子未在 `PooledDataArray` 列中编码，而是在 DataArray 或 DataFrame 中编码时转换单列数据：
- en: '[PRE51]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![Pooling data](img/B05321_02_28.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![汇总数据](img/B05321_02_28.jpg)'
- en: '`PooledDataArray` facilitates the analysis of categorical data, as columns
    in ModelMatrix are treated as 0-1 indicator columns. Each of the levels of PooledDataArray
    is associated with one column.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '`PooledDataArray` 促进了类别数据的分析，因为 ModelMatrix 中的列被当作 0-1 指示符列。PooledDataArray
    的每个水平都与一列相关联。'
- en: Web scraping
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络抓取
- en: Real-world use cases also include scraping data from the Web for analysis. Let's
    build a small web scraper to fetch Reddit posts.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的使用案例还包括从网络抓取数据进行分析。让我们构建一个小型的网页抓取器来获取 Reddit 帖子。
- en: 'For this, we will need the JSON and Requests packages:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将需要 JSON 和 Requests 包：
- en: '[PRE52]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Here, we defined a URL from where we will be scraping the data. We are scraping
    from Julia's section on Reddit.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们定义了一个 URL，从这个 URL 中抓取数据。我们从 Reddit 上的 Julia 部分进行抓取。
- en: 'Then, we are getting the content from the defined URL using the get function
    from the Requests package. We can see that we''ve got response 200 OK with the
    data:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用 Requests 包中的 get 函数从定义的 URL 获取内容。我们可以看到已经得到了响应 200 OK，并获得了数据：
- en: '[PRE53]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: We then parse the JSON data received using the JSON parser provided by the JSON
    package of Julia. We can now start reading the record.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 Julia 的 JSON 包提供的 JSON 解析器来解析接收到的 JSON 数据。现在我们可以开始读取记录了。
- en: '![Web scraping](img/B05321_02_29.jpg)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![Web scraping](img/B05321_02_29.jpg)'
- en: We can store the data received in an Array or DataFrame (depending on the use
    case and ease of use). Here, we are using an Array to store the parsed data. We
    can check the data stored in an Array.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将接收到的数据存储在数组或数据框（DataFrame）中（具体取决于使用场景和易用性）。在这里，我们使用数组来存储解析后的数据。我们可以检查存储在数组中的数据。
- en: '![Web scraping](img/B05321_02_30.jpg)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![Web scraping](img/B05321_02_30.jpg)'
- en: Suppose we only need to see the title of these posts and know what we have scraped;
    we just need to know in which column they are.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们只需要查看这些帖子的标题并知道我们抓取了什么；我们只需要知道它们在哪一列。
- en: '![Web scraping](img/B05321_02_31.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![Web scraping](img/B05321_02_31.jpg)'
- en: We can now see the title of the Reddit posts. But what if we had too many columns
    or we had some missing values? DataFrames would definitely be a better option.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以看到 Reddit 帖子的标题。但如果我们有太多列，或者存在缺失值怎么办？使用 DataFrames 会是更好的选择。
- en: Summary
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we learned what data munging is and why it is necessary for
    data science. Julia provides functionalities to facilitate data munging with the
    DataFrames.jl package, with features such as these:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了数据清洗（data munging）是什么，以及为什么它对于数据科学是必要的。Julia 提供了通过 DataFrames.jl 包来简化数据清洗的功能，其中包括以下特点：
- en: '`NA`: A missing value in Julia is represented by a specific data type, NA.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NA`：Julia 中的缺失值由一种特定的数据类型表示，即 NA。'
- en: '`DataArray`: DataArray provided in the `DataFrames.jl` provides features such
    as allowing us to store some missing values in an array.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DataArray`：`DataFrames.jl` 提供的 DataArray 特性，如允许我们在数组中存储缺失值。'
- en: '`DataFrame`: DataFrame is 2-D data structure like spreadsheets. It is very
    similar to R or pandas''s dataframes, and provides many functionalities to represent
    and analyze data. DataFrames has many features well suited for data analysis and
    statistical modeling.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DataFrame`：DataFrame 是一种二维数据结构，类似于电子表格。它与 R 或 pandas 的数据框类似，并提供了许多功能来表示和分析数据。DataFrames
    拥有许多非常适合数据分析和统计建模的特性。'
- en: A dataset can have different types of data in different columns.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个数据集可以在不同的列中包含不同类型的数据。
- en: Records have a relation with other records in the same row of different columns
    of the same length.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录与同一行中不同列的其他记录有关系，并且它们的长度相同。
- en: Columns can be labeled. Labeling helps us to easily become familiar with the
    data and access it without the need to remember their numerical indices.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列可以被标记。标记可以帮助我们轻松地熟悉数据，并且无需记住列的数字索引就能访问它们。
- en: We learned about importing data from a file using the `readtable()` function
    and exporting data to a file. The `readtable()` function provides flexibility
    when using many arguments.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了如何使用 `readtable()` 函数从文件导入数据并将数据导出到文件。`readtable()` 函数在使用多个参数时提供了灵活性。
- en: We also explored joining of datasets, such as RDBMS tables. Julia provides various
    joins that we can exploit according to our use case.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还探讨了数据集的连接，如 RDBMS 表。Julia 提供了多种连接方式，我们可以根据实际需求加以利用。
- en: We discussed the Split-Apply-Combine Strategy, one of the most widely used techniques
    deployed by data scientists, and why it is needed. We went through reshaping or
    pivoting data using stack and melt (stackdf, meltdf) functions and explored the
    various possibilities involved. We were also introduced to `PooledDataArray` and
    learned why it is required for efficient memory management.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了数据科学家广泛使用的 Split-Apply-Combine 策略，以及为什么它是必要的。我们通过 stack 和 melt（stackdf、meltdf）函数探讨了数据的重塑或旋转，并探索了其中的各种可能性。我们还介绍了
    `PooledDataArray`，并学习了它在内存管理中的重要性。
- en: We were introduced to web scraping, which is sometimes a must for a data scientist
    to gather data. We also used the Requests package to fetch an HTTP response.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了网页抓取技术，这对于数据科学家来说，有时是收集数据的必要手段。我们还使用了 Requests 包来获取 HTTP 响应。
- en: References
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[http://julia.readthedocs.org/en/latest/manual/](http://julia.readthedocs.org/en/latest/manual/)'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://julia.readthedocs.org/en/latest/manual/](http://julia.readthedocs.org/en/latest/manual/)'
- en: '[http://dataframesjl.readthedocs.io/en/latest/](http://dataframesjl.readthedocs.io/en/latest/)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://dataframesjl.readthedocs.io/en/latest/](http://dataframesjl.readthedocs.io/en/latest/)'
- en: '[https://data.gov.uk/dataset/road-accidents-safety-data](https://data.gov.uk/dataset/road-accidents-safety-data)'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://data.gov.uk/dataset/road-accidents-safety-data](https://data.gov.uk/dataset/road-accidents-safety-data)'
- en: 'Wickham, Hadley. "The split-apply-combine strategy for data analysis." *Journal
    of Statistical Software* 40.1 (2011): 1-29'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wickham, Hadley. "数据分析的分割-应用-合并策略。" *《统计软件杂志》* 40.1 (2011): 1-29'
