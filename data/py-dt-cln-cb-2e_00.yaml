- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: 'This book is a practical guide to data cleaning, broadly defined as all tasks
    necessary to prepare data for analysis. It is organized by the tasks usually completed
    during the data-cleaning process: importing data, viewing data diagnostically,
    identifying outliers and unexpected values, imputing values, tidying data, and
    so on. Each recipe walks the reader from raw data through the completion of a
    specific data-cleaning task.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是一本关于数据清理的实用指南，广义上定义为所有为分析准备数据所需的任务。它按照数据清理过程中的常见任务进行组织：导入数据、诊断性查看数据、识别离群值和意外值、填补缺失值、整理数据等。每个实例都会引导读者从原始数据处理到完成特定的数据清理任务。
- en: There are already a number of very good pandas books. Unsurprisingly, there
    is some overlap between those texts and this one. However, the emphasis here is
    different. I focus as much on the why as on the how in this book.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 市面上已经有一些非常好的 pandas 书籍。不出所料，这些书籍和本书有一些内容重叠。然而，本书的重点不同。我在本书中不仅关注“如何做”，也同样重视“为什么这么做”。
- en: Since pandas is still relatively new, the lessons I have learned about cleaning
    data have been shaped by my experiences with other tools. Before settling into
    my current work routine with Python and R about 10 years ago, I relied mostly
    on C# and T-SQL in the early 2000s, SAS and Stata in the 90s, and FORTRAN and
    Pascal in the 80s. Most readers of this text probably have experience with a variety
    of data-cleaning and analysis tools. In many ways the specific tool is less significant
    than the data preparation task and the attributes of the data. I would have covered
    pretty much the same topics if I had been asked to write *The SAS Data Cleaning
    Cookbook* or *The R Data Cleaning Cookbook*. I just take a Python/pandas-specific
    approach to the same data-cleaning challenges that analysts have faced for decades.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 pandas 仍然相对较新，我在数据清理方面学到的经验，受到了我使用其他工具时的影响。在大约 10 年前我定居于现在的 Python 和 R 工作方式之前，我在
    2000 年代初期主要依赖 C# 和 T-SQL，90 年代使用 SAS 和 Stata，80 年代使用 FORTRAN 和 Pascal。本书的大多数读者可能都对多种数据清理和分析工具有一定经验。从许多方面来看，特定工具的重要性不如数据准备任务和数据的属性。我如果被要求编写《SAS
    数据清理手册》或《R 数据清理手册》，也会覆盖几乎相同的内容。我只是用 Python/pandas 特定的方法来处理几十年来分析师们一直面临的相同数据清理挑战。
- en: I start each chapter with how to think about the particular data-cleaning task
    at hand before discussing how to approach it with a tool from the Python ecosystem—pandas,
    NumPy, Matplotlib, and so on. This is reinforced in each recipe by a discussion
    of the implications of what we are uncovering in the data. I try to connect tool
    to purpose. For example, concepts like skewness and kurtosis matter as much for
    handling outliers as does knowing how to update pandas Series values.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我在每一章的开始部分都会介绍如何思考当前手头的数据清理任务，然后再讨论如何使用 Python 生态系统中的工具——pandas、NumPy、Matplotlib
    等来处理。每个实例中都会通过讨论我们在数据中揭示的内容的含义来加深这一点。我尽量将工具与目标联系起来。例如，像偏度和峰度这样的概念对于处理离群值的重要性，和了解如何更新
    pandas Series 的值一样。
- en: New in the Second Edition
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二版新增内容
- en: Readers of the first edition will recognize that this book is substantially
    longer than that one. That is partly because there are two new chapters—a chapter
    devoted to treating missing values and another one on pre-processing data for
    predictive analysis. The insufficient coverage of missing values, and the absence
    of coverage of pre-processing data for machine learning applications were important
    omissions. The pre-processing coverage is further improved by new recipes on data
    pipelines in the final chapter that take the reader from raw data to model evaluation.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 第一版的读者会发现，本书比第一版长了很多。这部分是因为增加了两个新章节——一个专门讲解缺失值处理，另一个讲解数据预处理在预测分析中的应用。第一版对缺失值的覆盖不足，以及没有涉及机器学习应用中数据预处理的内容，是重要的遗漏。数据预处理的内容通过最后一章关于数据管道的新实例得到了进一步改进，帮助读者从原始数据到模型评估。
- en: The recipes in all chapters have been revised. This is to make sure that they
    all work well with the most recent versions of pandas. pandas went from version
    1.5.3 to 2.2.1 during the writing of this book. I have tried to make sure that
    all code works fine on all versions of pandas released from January 2023 through
    February 2024\. Since AI tools are becoming increasingly common in our work, I
    have included discussion of OpenAI tools in four of the chapters. Altogether,
    22 of the 82 recipes are new. All of the datasets used have also been updated.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有章节的食谱都进行了修订。这是为了确保它们能够与最新版本的pandas兼容。在本书编写期间，pandas从1.5.3版本更新到了2.2.1版本。我已尽力确保所有代码在2023年1月到2024年2月期间发布的所有pandas版本上都能正常工作。由于AI工具在我们的工作中越来越普遍，我在四章中加入了OpenAI工具的讨论。总的来说，82个食谱中有22个是新的。所有使用的数据集也进行了更新。
- en: Who this book is for
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适合的读者
- en: I had multiple audiences in mind as I wrote this book, but I most consistently
    thought about a dear friend of mine who bought a Transact-SQL book 30 years ago
    and quickly developed great confidence in her database work, ultimately building
    a career around those skills. I would love it if someone just starting their career
    as a data scientist or analyst worked through this book and had a similar experience
    as my friend. More than anything else, I want you to feel good and excited about
    what you can do as a result of reading this book.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在写这本书时，我考虑了多个读者群体，但我最常想到的是我的一位亲密朋友。30年前，她购买了一本Transact-SQL书籍，很快便在数据库工作中建立了极大的信心，并最终围绕这些技能建立了职业生涯。如果一位刚开始做数据科学家或分析师的新人，通过本书也能有我朋友那样的经历，我会非常高兴。最重要的是，我希望你在阅读完本书后能对自己所能做的事情感到高兴和兴奋。
- en: I also hope this book will be a useful reference for folks who have been doing
    this kind of work for a while. Here, I imagine someone opening the book and wondering
    to themself, “What’s an approach to handling missing data that maintains the variance
    of my variable?”
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我也希望本书能为那些从事此类工作一段时间的朋友提供有价值的参考。在这里，我设想有人翻开书，心里想：“有哪些处理缺失数据的方法能够保持我变量的方差？”
- en: In keeping with the hands-on nature of this text, every bit of output is reproducible
    with code in this book. I also stuck to a rule throughout, even when it was challenging.
    Every recipe starts with raw data largely unchanged from the original downloaded
    file. You go from data file to better prepared data in each recipe. If you have
    forgotten how a particular object was created, all you will ever need to do is
    turn back a page or two to see.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书实践性的特点保持一致，书中的每一段输出都可以通过代码重现。我在写作过程中也始终遵循一个规则，即使遇到挑战也没有改变：每个食谱都从基本未改变的原始数据开始。你将从数据文件开始，一步步得到更好处理的数据。如果你忘记了某个对象是如何创建的，只需翻回几页就能找到。
- en: Readers who have some knowledge of pandas and NumPy will have an easier time
    with some code blocks, as will folks with some knowledge of Python and introductory
    statistics. None of that is essential though. There are just some recipes you
    might want to pause over longer.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些pandas和NumPy基础的读者会更容易理解某些代码块，了解Python和基础统计的读者也会有一些帮助。不过这些都不是必须的。只是有些食谱你可能需要停下来多想一会儿。
- en: What this book covers
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容
- en: '*Chapter 1*, *Anticipating Data Cleaning Issues When Importing Tabular Data
    with pandas*, explores tools for loading CSV files, Excel files, relational database
    tables, SAS, SPSS, Stata, and R files into pandas DataFrames.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*第一章*，*在使用pandas导入表格数据时预见数据清理问题*，探讨了将CSV文件、Excel文件、关系数据库表、SAS、SPSS、Stata和R文件加载到pandas
    DataFrame中的工具。'
- en: '*Chapter 2*, *Anticipating Data Cleaning Issues When Working with HTML, JSON,
    and Spark Data*, discusses techniques for reading and normalizing JSON data, web
    scraping, and working with big data using Spark. It also explores techniques for
    persisting data, including with versioning.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*第二章*，*处理HTML、JSON和Spark数据时预见数据清理问题*，讨论了读取和标准化JSON数据、网页抓取以及使用Spark处理大数据的技术。它还探讨了数据持久化技术，包括版本控制。'
- en: '*Chapter 3*, *Taking the Measure of Your Data*, introduces common techniques
    for navigating around a DataFrame, selecting columns and rows, and generating
    summary statistics. The use of OpenAI tools for examining dataset structure and
    generating statistics is introduced.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*第三章*，*衡量你的数据*，介绍了在DataFrame中导航、选择列和行以及生成摘要统计信息的常见技术。还介绍了使用OpenAI工具检查数据集结构和生成统计信息。'
- en: '*Chapter 4*, *Identifying Outliers in Subsets of Data*, explores a wide range
    of strategies to identify outliers across a whole DataFrame and by selected groups.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*第4章*，*在数据子集中过滤异常值*，探索了识别整个DataFrame及选定组中的异常值的广泛策略。'
- en: '*Chapter 5*, *Using Visualizations for the Identification of Unexpected Values*,
    demonstrates the use of the Matplotlib and Seaborn tools to visualize how key
    variables are distributed, including with histograms, boxplots, scatter plots,
    line plots, and violin plots.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*第5章*，*使用可视化识别意外值*，展示了如何使用Matplotlib和Seaborn工具可视化关键变量的分布，包括直方图、箱线图、散点图、折线图和小提琴图。'
- en: '*Chapter 6*, *Cleaning and Exploring Data with Series Operations*, discusses
    updating pandas Series with scalars, arithmetic operations, and conditional statements
    based on the values of one or more Series.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*第6章*，*使用Series操作清理和探索数据*，讨论了如何使用标量、算术运算和基于一个或多个Series的条件语句更新pandas Series。'
- en: '*Chapter 7*, *Identifying and Fixing Missing Values*, goes over strategies
    for identifying missing values across rows and columns, and over subsets of data.
    It explores strategies for imputing values, such as setting values to the overall
    mean or the mean for a given category and forward filling. It also examines multivariate
    techniques for imputing values for missing values and discusses when they are
    appropriate.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*第7章*，*识别和修复缺失值*，介绍了识别行、列和数据子集中的缺失值的策略。探讨了填充缺失值的策略，例如设置为总体均值或某一类别的均值以及前向填充。还研究了多变量填充缺失值的技术，并讨论了它们的适用情况。'
- en: '*Chapter 8*, *Encoding, Transforming, and Scaling Features*, covers a range
    of variable transformation techniques to prepare features and targets for predictive
    analysis. This includes the most common kinds of encoding—one-hot, ordinal, and
    hashing encoding; transformations to improve the distribution of variables; and
    binning and scaling approaches to address skewness, kurtosis, and outliers and
    to adjust for features with widely different ranges.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*第8章*，*编码、转换和缩放特征*，涵盖了各种变量转换技术，用于为预测分析准备特征和目标。这包括最常见的编码类型——独热编码、序数编码和哈希编码；改善变量分布的转换；以及用于解决偏态、峰态和异常值问题的分箱和缩放方法，还可以调整特征范围差异较大的情况。'
- en: '*Chapter 9*, *Fixing Messy Data When Aggregating*, demonstrates multiple approaches
    to aggregating data by group, including looping through data with `itertuples`
    or NumPy arrays, dropping duplicate rows, and using pandas’ groupby and pivot
    tables. It also discusses when to choose one approach over the others.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*第9章*，*聚合数据时修复杂乱数据*，展示了通过分组聚合数据的多种方法，包括使用`itertuples`或NumPy数组遍历数据、删除重复行，以及使用pandas的groupby和透视表。还讨论了何时选择一种方法而非其他方法。'
- en: '*Chapter 10*, *Addressing Data Issues When Combining DataFrames*, examines
    different strategies for concatenating and merging data, and how to anticipate
    common data challenges when combining data.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*第10章*，*合并DataFrame时处理数据问题*，探讨了连接和合并数据的不同策略，以及如何预测在合并数据时可能遇到的常见数据挑战。'
- en: '*Chapter 11*, *Tidying and Reshaping Data*, introduces several strategies for
    de-duplicating, stacking, melting, and pivoting data.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*第11章*，*整理和重塑数据*，介绍了几种去重、堆叠、熔化和透视数据的策略。'
- en: '*Chapter 12*, *Automate Data Cleaning with User-Defined Functions and Classes
    and Pipelines*, examines how to turn many of the techniques from the first 11
    chapters into reuseable code.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*第12章*，*使用用户定义函数、类和管道自动化数据清理*，探讨了如何将前11章中的许多技术转化为可复用的代码。'
- en: Download the example code files
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: The code bundle for the book is hosted on GitHub at [https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码包托管在GitHub上，地址为：[https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition)。我们还在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)提供了来自我们丰富书籍和视频目录的其他代码包。快来看看吧！
- en: Download the color images
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载彩色图像
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://packt.link/gbp/9781803239873](https://packt.link/gbp/9781803239873).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一个PDF文件，其中包含本书中使用的截图/图表的彩色图像。你可以在这里下载：[https://packt.link/gbp/9781803239873](https://packt.link/gbp/9781803239873)。
- en: Conventions used
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了许多文本约定。
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “Mount the downloaded `WebStorm-10*.dmg` disk image
    file as another disk in your system.”'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`Code in text`：指文本中的代码词汇、数据库表名、文件夹名称、文件名、文件扩展名、路径名、虚拟网址、用户输入和Twitter账号。例如：“将下载的`WebStorm-10*.dmg`磁盘映像文件挂载为系统中的另一个磁盘。”'
- en: 'A block of code is set as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块如下所示：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Any output from the code will appear like this:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的任何输出将显示如下：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: “Select **System info** from the **Administration** panel.”'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要词汇或屏幕上显示的文字。例如，菜单或对话框中的词汇将以这种方式出现在文本中。以下是一个示例：“从**系统信息**中选择**管理**面板。”'
- en: Warnings or important notes appear like this.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要说明如下所示。
- en: Tips and tricks appear like this.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和技巧如下所示。
- en: Get in touch
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与我们联系
- en: Feedback from our readers is always welcome.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们欢迎读者的反馈。
- en: '**General feedback**: Email `feedback@packtpub.com` and mention the book’s
    title in the subject of your message. If you have questions about any aspect of
    this book, please email us at `questions@packtpub.com`.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：请发送电子邮件至`feedback@packtpub.com`，并在邮件主题中提及书名。如果您对本书的任何方面有疑问，请通过`questions@packtpub.com`与我们联系。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you reported this to us. Please visit [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    click **Submit Errata**, and fill in the form.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已经尽力确保内容的准确性，但错误难免。如果您在本书中发现了错误，欢迎您向我们报告。请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，点击**提交勘误**并填写表单。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packtpub.com` with a
    link to the material.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果你在互联网上发现任何我们作品的非法复制版本，请提供其位置地址或网站名称，我们将不胜感激。请通过`copyright@packtpub.com`与我们联系，并附上该材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [http://authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个主题领域有专业知识，并且有兴趣撰写或参与写作书籍，请访问[http://authors.packtpub.com](http://authors.packtpub.com)。'
- en: Share your thoughts
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分享您的想法
- en: Once you’ve read *Python Data Cleaning Cookbook, Second Edition*, we’d love
    to hear your thoughts! Please [click here to go straight to the Amazon review
    page](https://packt.link/r/1803239875) for this book and share your feedback.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完*Python数据清理食谱（第二版）*后，我们很乐意听听您的想法！请[点击这里直接访问亚马逊评论页面](https://packt.link/r/1803239875)并分享您的反馈。
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您的评价对我们和技术社区非常重要，并将帮助我们确保提供卓越的优质内容。
- en: Download a free PDF copy of this book
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载本书的免费PDF副本
- en: Thanks for purchasing this book!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您购买本书！
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您喜欢在旅途中阅读，但又无法随身携带纸质书籍吗？
- en: Is your eBook purchase not compatible with the device of your choice?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你的电子书购买是否与您选择的设备不兼容？
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心，现在购买每本Packt书籍时，您都能免费获得该书的无DRM版PDF。
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何地方、任何设备上阅读。直接从您最喜爱的技术书籍中搜索、复制和粘贴代码到您的应用程序中。
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 特权不仅限于此，您还可以获得独家折扣、新闻通讯和每日发送到您邮箱的精彩免费内容。
- en: 'Follow these simple steps to get the benefits:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下简单步骤获取好处：
- en: 'Scan the QR code or visit the link below:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扫描二维码或访问以下链接：
- en: '![](img/B18596_Free_PDF_QR.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_Free_PDF_QR.png)'
- en: https://packt.link/free-ebook/9781803239873
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: https://packt.link/free-ebook/9781803239873
- en: Submit your proof of purchase.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交您的购买凭证。
- en: That’s it! We’ll send your free PDF and other benefits to your email directly.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就是这样！我们会将您的免费PDF和其他福利直接发送到您的邮箱。
