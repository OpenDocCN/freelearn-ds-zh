- en: Chapter 5. High-Performance and Parallel Computing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 章. 高性能与并行计算
- en: A recurring argument against using Python for high-performance numerical computing
    is that this language is slow, because it is dynamic and interpreted. A compiled
    lower-level language such as C can often be orders of magnitude faster. We exposed
    a first counterargument in [Chapter 3](ch03.html "Chapter 3. Numerical Computing
    with IPython"), *Numerical Computing with IPython*, with the notion of **vectorization**
    . Operations on NumPy arrays can be almost as fast as C because slow Python loops
    are transparently replaced with fast C loops. Sometimes though, it may happen
    that vectorization is impossible or difficult to implement on some complex algorithms.
    In these cases, there are fortunately solutions other than throwing away all Python
    code and coding everything again in C. We will introduce some of these solutions
    in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 一个反复出现的观点是，Python 不适合高性能数值计算，因为它是一种动态语言并且是解释型的，速度较慢。像 C 这样的编译型低级语言通常可以快几个数量级。我们在[第
    3 章](ch03.html "第 3 章. 使用 IPython 进行数值计算")，*使用 IPython 进行数值计算*中提出了第一个反驳，**向量化**的概念。对
    NumPy 数组的操作几乎可以和 C 一样快，因为缓慢的 Python 循环会被快速的 C 循环透明替换。然而，有时某些复杂算法可能无法进行向量化，或者实现起来很困难。在这种情况下，幸运的是，除了抛弃所有的
    Python 代码并重新用 C 编写一遍外，还有其他解决方案。我们将在本章中介绍其中的一些解决方案。
- en: First, one can take advantage of the multiple cores that are now present in
    any computer. A standard Python process normally runs on a single core, but it
    is possible to distribute tasks across multiple cores and even multiple computers
    in parallel. This is particularly easy to do with IPython. MPI can also be easily
    used with a few lines of code.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，可以利用现代计算机中普遍存在的多个核心。标准的 Python 进程通常只在单个核心上运行，但可以将任务分布到多个核心，甚至多个计算机上并行处理。使用
    IPython 实现这一点特别简单。MPI 也可以通过几行代码轻松使用。
- en: 'Another popular solution is to first detect the time-critical section of a
    Python algorithm and then replace it with C code. Typically, only a very small
    section of the Python code is responsible for most of the algorithm''s duration,
    so that it is possible to keep the rest of the code in Python. **Cython** is an
    external package which makes this task easier than it sounds: it offers a superset
    of Python that is compiled and that can be seamlessly integrated within Python
    code. It is particularly convenient to use it with IPython.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个流行的解决方案是首先检测 Python 算法中时间关键部分，然后用 C 代码替换它。通常，只有 Python 代码中的一小部分负责大部分算法的运行时间，因此可以将其余的代码保持为
    Python 代码。**Cython** 是一个外部包，它使得这一任务比看起来要容易得多：它提供了一个 Python 的超集，经过编译后，可以无缝地集成到
    Python 代码中。与 IPython 一起使用时，它尤其方便。
- en: 'At the end of this chapter, we will have discussed:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，我们将讨论以下内容：
- en: How to distribute independent functions across several cores from IPython
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何通过 IPython 将独立的函数分布到多个核心
- en: How to easily use MPI from IPython
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何轻松地从 IPython 使用 MPI
- en: How to convert Python code in C with Cython using a cell magic
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用单元魔法将 Python 代码转换为 C 代码
- en: How to use NumPy arrays in Cython for making your code orders of magnitude faster
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 Cython 中使用 NumPy 数组使你的代码快几个数量级
- en: Interactive task parallelization
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交互式任务并行化
- en: In this section, we will see how to distribute tasks across different cores
    with IPython.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何通过 IPython 将任务分配到不同的核心上。
- en: Parallel computing in Python
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python 中的并行计算
- en: 'Python''s native support of parallel computing features leaves much to be desired.
    A long-standing issue is that CPython implements a **Global Interpreter Lock**
    (**GIL**), which, as quoted from the official CPython documentation, is:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Python 对并行计算特性的原生支持还有很大改进空间。一个长期存在的问题是，CPython 实现了 **全局解释器锁** (**GIL**)，根据官方
    CPython 文档的描述，它是：
- en: '"...a mutex that prevents multiple native threads from executing Python bytecodes
    at once."'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '"...一个互斥锁，防止多个原生线程同时执行 Python 字节码。"'
- en: The GIL is necessary because CPython's memory management is not thread-safe,
    but a major drawback is that it can prevent multithreaded CPython programs from
    taking full advantage of multicore processors.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: GIL 是必需的，因为 CPython 的内存管理不是线程安全的，但一个主要的缺点是，它会阻止多线程的 CPython 程序充分利用多核处理器。
- en: Note
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Python''s GIL**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python 的 GIL**'
- en: 'The interested reader can find more information about Python''s GIL in the
    following references:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 有兴趣的读者可以在以下参考资料中找到有关 Python GIL 的更多信息：
- en: '[http://wiki.python.org/moin/GlobalInterpreterLock](http://wiki.python.org/moin/GlobalInterpreterLock)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://wiki.python.org/moin/GlobalInterpreterLock](http://wiki.python.org/moin/GlobalInterpreterLock)'
- en: '[http://www.dabeaz.com/python/UnderstandingGIL.pdf](http://www.dabeaz.com/python/UnderstandingGIL.pdf)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.dabeaz.com/python/UnderstandingGIL.pdf](http://www.dabeaz.com/python/UnderstandingGIL.pdf)'
- en: Some linear algebraic functions in NumPy may take advantage of multicore processors
    by releasing the GIL, if NumPy is compiled with the appropriate libraries (ATLAS,
    MKL, and so on). Otherwise, distributing tasks across different *processes* instead
    of different *threads* is the typical way of doing parallel computing with Python.
    As processes do not share the same memory space, some kind of inter-process communication
    needs to be implemented, for example, using Python's native **multiprocessing**
    module. A more powerful but more complex solution is to use **Message Passing
    Interface** (**MPI**).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 中的一些线性代数函数可能通过释放 GIL 来利用多核处理器，前提是 NumPy 已经与适当的库（如 ATLAS、MKL 等）一起编译。否则，使用不同的
    *进程* 而不是不同的 *线程* 来分配任务，是使用 Python 进行并行计算的典型方式。由于进程不共享同一内存空间，因此需要实现某种进程间通信，例如，使用
    Python 的原生 **multiprocessing** 模块。一种更强大但更复杂的解决方案是使用 **消息传递接口** (**MPI**)。
- en: IPython is particularly well-adapted to both solutions, and we will discuss
    them in this section. It provides a powerful and general architecture for parallel
    computing. Several IPython engines can run on different cores and/or different
    computers. Independent tasks can be easily and evenly distributed, thanks to **load
    balancing** . Data can be transferred from one engine to the other, making complex
    distributed algorithms possible from IPython.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: IPython 特别适合这两种解决方案，我们将在本节中讨论它们。它提供了一个强大而通用的并行计算架构。多个 IPython 引擎可以运行在不同的核心和/或不同的计算机上。独立任务可以轻松且均匀地分配，得益于
    **负载均衡**。数据可以从一个引擎传输到另一个引擎，这使得通过 IPython 实现复杂的分布式算法成为可能。
- en: Parallel computing is a particularly hard topic, and we will only cover the
    most basic aspects here.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 并行计算是一个特别困难的话题，我们这里只覆盖最基础的内容。
- en: Distributing tasks on multiple cores
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在多个核心上分配任务
- en: The parallel computing features of IPython are extensive and highly customizable,
    but we will only show the simplest way of using them here. In addition, we will
    focus on the interactive usage of parallel computing, since that is the essence
    of IPython.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: IPython 的并行计算功能非常丰富且高度可定制，但我们这里只展示最简单的使用方式。此外，我们将重点讨论并行计算的交互式使用，因为这正是 IPython
    的精髓所在。
- en: 'There are several steps to distribute code across multiple cores on one computer:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在一台计算机上分配代码到多个核心的步骤如下：
- en: Launch several IPython engines (typically one per processor).
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动多个 IPython 引擎（通常每个处理器一个）。
- en: Create a `Client` object that acts as a proxy to these engines.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `Client` 对象，它充当这些引擎的代理。
- en: Use the client to launch tasks on the engines and retrieve the results.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用客户端在引擎上启动任务并获取结果。
- en: 'Tasks can be launched synchronously or asynchronously:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 任务可以同步或异步启动：
- en: With **synchronous** (or blocking) tasks, the client blocks right after the
    tasks have started, and returns the tasks' results when they have finished.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 **同步**（或阻塞）任务时，客户端在任务启动后会阻塞，并在任务完成时返回结果。
- en: With **asynchronous** (non-blocking) tasks, the client returns an `ASyncResult`
    object immediately after the tasks have started. This object can be used to poll
    the task statuses asynchronously and to retrieve the results at any time after
    they have finished.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 **异步**（非阻塞）任务时，客户端在任务启动后立即返回一个 `ASyncResult` 对象。该对象可以用来异步轮询任务状态，并在任务完成后随时获取结果。
- en: Starting the engines
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启动引擎
- en: The simplest way of starting the engines is to call in a system shell `ipcluster
    start` command. By default, this command will start one engine per core on the
    local machine. The number of engines can be specified with the `-n` option, for
    example, `ipcluster start -n 2` to start two engines. You can see the other available
    options with `ipcluster -h` and `ipcluster start -h`. In addition, the notebook
    has a panel named **Clusters** where you can launch and stop engines through a
    web interface.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 启动引擎的最简单方法是在系统 shell 中调用 `ipcluster start` 命令。默认情况下，该命令会在本地机器的每个核心上启动一个引擎。可以通过
    `-n` 选项指定引擎的数量，例如，`ipcluster start -n 2` 启动两个引擎。你可以通过 `ipcluster -h` 和 `ipcluster
    start -h` 查看其他可用选项。此外，Notebook 中有一个名为 **Clusters** 的面板，可以通过 Web 界面启动和停止引擎。
- en: Creating a Client instance
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个 Client 实例
- en: A client is used to send tasks to the engines. In an IPython console or in the
    notebook, we first need to import the `Client` class from the `parallel` subpackage.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端用于将任务发送到引擎。在IPython控制台或笔记本中，我们首先需要从`parallel`子包中导入`Client`类。
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The next step is to create a `Client` instance.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建一个`Client`实例。
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'IPython automatically detects the running engines. To check the number of running
    engines, we can do the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: IPython会自动检测正在运行的引擎。要检查正在运行的引擎数目，我们可以执行以下操作：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `ids` attribute of the client gives the identifiers of the running engines.
    Here, there are two running engines on the local machine (it has a dual-core processing
    unit).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端的`ids`属性提供了运行中引擎的标识符。在这里，本地计算机上有两个正在运行的引擎（它具有双核处理单元）。
- en: Using the parallel magic
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用并行魔法
- en: The easiest way of sending tasks to the engines from IPython is to use the `%px`
    magic. It executes a single Python command on the engines.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 从IPython发送任务到引擎的最简单方法是使用`%px`魔法。它在引擎上执行单个Python命令。
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: By default, the command executes on all running engines and in synchronous mode.
    There are several ways to specify which engine(s) to target.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，命令会在所有运行中的引擎上执行，并且是同步模式。有几种方法可以指定要针对哪个引擎进行操作。
- en: 'The first possibility is to use the `%pxconfig` magic command:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个可能性是使用`%pxconfig`魔法命令：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `--targets` option accepts an index or a slice object, for example, `::2`
    for all engines with even indices. Here, we target only the second engine. All
    subsequent calls to `%px` will be executed on the specified targets.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`--targets`选项接受一个索引或切片对象，例如，`::2`表示所有偶数索引的引擎。这里，我们只指定第二个引擎。所有后续对`%px`的调用将在指定的目标上执行。'
- en: 'An equivalent method is to use the `%%px` cell magic:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个等效的方法是使用`%%px`单元魔法：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The options of `%%px` apply to the whole cell, which is particularly convenient
    in the notebook.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`%%px`的选项适用于整个单元，这在笔记本中尤其方便。'
- en: Another available option is the **blocking mode** . By default, the `%px` magic
    assumes a blocking mode. To enable the **non-blocking mode** , we can use the
    `--noblock` option.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可用的选项是**阻塞模式**。默认情况下，`%px`魔法假设是阻塞模式。要启用**非阻塞模式**，我们可以使用`--noblock`选项。
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The task then executes asynchronously. The `%pxresult` magic command blocks
    the interpreter until the task has finished, and returns the result.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 任务随后会异步执行。`%pxresult`魔法命令会阻塞解释器，直到任务完成，并返回结果。
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parallel map
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并行映射
- en: The built-in `map` function applies a Python function to a sequence element-by-element.
    IPython provides a parallel `map` function, which is semantically equivalent,
    but dispatches the different tasks across the different engines. It is the simplest
    way to distribute tasks across multiple cores.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 内置的`map`函数按元素依次将Python函数应用于序列。IPython提供了一个并行的`map`函数，它语义上等价，但将不同的任务分派到不同的引擎上。这是将任务分发到多个核心的最简单方法。
- en: Creating a view
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建视图
- en: 'To use it, we first need to get a view to the engines, using the `Client` instance.
    A **view** represents one or several engines, and is obtained with an indexing
    syntax on the client. For example, to get a view on all engines, we use the following
    command:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用它，我们首先需要使用`Client`实例获取一个引擎的视图。**视图**表示一个或多个引擎，并通过在客户端上的索引语法获取。例如，要获取所有引擎的视图，我们可以使用以下命令：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The view can then be used to launch tasks on the engines. Also, we can import
    packages on the engines with the `sync_imports()` method:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，视图可以用于在引擎上启动任务。此外，我们还可以使用`sync_imports()`方法在引擎上导入包：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Synchronous map
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 同步映射
- en: 'Let''s define the following simple function:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义以下简单函数：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This function accepts a number and waits for one second before returning its
    square. To execute the function synchronously on all numbers between zero and
    nine, and using our two engines (so, using two CPUs), we can use the `v.map_sync()`
    method:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数接受一个数字，并在返回其平方之前等待一秒钟。要在零到九之间的所有数字上同步执行该函数，并使用我们的两个引擎（即使用两个CPU），我们可以使用`v.map_sync()`方法：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We obtain a list of results after a few seconds. Here, each engine has processed
    five tasks, for a total of 10 tasks:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在几秒钟后获得一组结果。这里，每个引擎处理了五个任务，共计10个任务：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Asynchronous map
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 异步映射
- en: 'To execute the function asynchronously on the list of arguments, we can use
    the `v.map()` method:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要异步执行该函数并传递参数列表，我们可以使用`v.map()`方法：
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `r` variable is an `ASyncResult` object, with several attributes and methods
    that can be used to poll information about the progress, the elapsed time, and
    to get the tasks' results. The `elapsed` attribute returns, at any time, the elapsed
    time since the tasks began. The `serial_time` attribute is only available after
    the tasks have finished, and returns the cumulative time spent on all tasks across
    all engines. The `ready()` method returns, at any time, a value indicating whether
    the tasks have finished or not. The `get()` method blocks until the tasks have
    finished, and returns the results.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`r`变量是一个`ASyncResult`对象，具有多个属性和方法，可以用来轮询任务的进度、已用时间，并获取任务的结果。`elapsed`属性返回任务开始以来的已用时间。`serial_time`属性仅在任务完成后可用，返回所有任务在所有引擎上累计花费的时间。`ready()`方法随时返回一个值，表示任务是否完成。`get()`方法会阻塞直到任务完成，并返回结果。'
- en: A practical example – Monte Carlo simulations
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个实际的例子 – 蒙特卡罗模拟
- en: 'To illustrate the parallel computing possibilities offered by IPython, we will
    consider a new example. We want to estimate the Pi constant using *Monte Carlo
    simulations*. The principle is that if *n* points are randomly and uniformly sampled
    within a square of edge 1, the proportion of points that have a distance smaller
    than 1 from a fixed corner tends to *Pi/4*, if the number of points *n* tends
    to infinity. The following figure illustrates this fact:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明IPython提供的并行计算可能性，我们将考虑一个新的例子。我们想使用*蒙特卡罗模拟*来估算圆周率π。原理是，如果在边长为1的正方形内随机且均匀地采样*n*个点，那么当*n*趋近于无穷大时，距离一个固定角落小于1的点的比例趋近于*π/4*。下图说明了这一事实：
- en: '![A practical example – Monte Carlo simulations](img/9932_05_01.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![一个实际的例子 – 蒙特卡罗模拟](img/9932_05_01.jpg)'
- en: Estimation of Pi using a Monte-Carlo simulation
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用蒙特卡罗模拟估算圆周率π
- en: This is a particular example of a *Monte Carlo simulation*, which repeats a
    random experiment a large number of times, and takes an average at the end to
    estimate some quantity of interest that would be difficult to obtain with a deterministic
    method. Monte Carlo simulations are widespread in science, engineering, and finance.
    They are particularly convenient to parallelize, as it is generally a matter of
    executing the exact same function independently a large number of times.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个特定的*蒙特卡罗模拟*例子，它通过重复进行大量的随机实验，最后取平均值来估算某些难以通过确定性方法获得的量。蒙特卡罗模拟广泛应用于科学、工程和金融领域。它们特别适合并行化，因为通常只是独立执行相同的函数很多次。
- en: Here, we will use this random experiment to estimate Pi. The precision obtained
    with this method is known to be low, and there are numerous methods that are far
    more efficient and precise. But, this example will be sufficient for introducing
    the parallel computing features of IPython.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用这个随机实验来估算圆周率π。使用这种方法获得的精度较低，而且还有许多方法更加高效且精确。但这个示例足以介绍IPython的并行计算特性。
- en: First, we will write the Python code that executes the simulation. The `sample`
    function generates *n* points in the cube and returns the number of points that
    lie within the quarter disc.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将编写执行模拟的Python代码。`sample`函数在立方体内生成*n*个点，并返回位于四分之一圆盘内的点的数量。
- en: '[PRE14]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Since the *n*-long vector inside the parentheses is a mask array (that is, it
    contains Boolean values), its sum is the number of `True` values, that is, the
    number of points with an Euclidean distance from 0, smaller than 1.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 由于括号内的*n*长向量是一个掩码数组（即它包含布尔值），它的和就是`True`值的数量，也就是与0的欧几里得距离小于1的点的数量。
- en: 'Now, to estimate Pi, we just need to multiply `sample(n)` by `4/n`:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，要估算圆周率π，我们只需要将`sample(n)`乘以`4/n`即可：
- en: '[PRE15]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Since the real value of Pi is 3.1415926535..., we see that there are two correct
    digits (for this particular code execution) with one million points. We will now
    distribute this task on several cores. Assuming several engines have been started,
    for example, with `ipcluster start`, here is how we can parallelize the code:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 由于圆周率π的真实值是3.1415926535...，我们看到在一百万个点的情况下（对于这次特定的代码执行）有两个正确的数字。接下来我们将把这个任务分配到多个核心上。假设已经启动了多个引擎，例如使用`ipcluster
    start`，下面是如何并行化代码：
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here, `len(v)` is the number of engines. We call the sample function `len(v)`
    times with the same argument `n`. The sum of all results is the total number of
    red points, and the total number of points is `n * len(v)`. Finally, we obtain
    the estimation of Pi with the same previous formula.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`len(v)` 是引擎的数量。我们使用相同的参数 `n` 调用样本函数 `len(v)` 次。所有结果的总和是红点的总数，点的总数是 `n *
    len(v)`。最后，我们使用前述公式得到 Pi 的估计。
- en: Using MPI with IPython
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 IPython 中的 MPI
- en: MPI is a famous standardized message passing system that is particularly efficient
    for parallel computing. We will assume that an MPI implementation is installed
    on your system (such as **Open-MPI**, [http://www.open-mpi.org](http://www.open-mpi.org)),
    as well as the **mpi4py** package for using MPI from Python ([http://mpi4py.scipy.org](http://mpi4py.scipy.org)).
    Information about how to install MPI can be found on these websites.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: MPI 是一种著名的标准化消息传递系统，特别适用于并行计算。我们假设 MPI 实现已经安装在您的系统上（如 **Open-MPI**，[http://www.open-mpi.org](http://www.open-mpi.org))，以及用于从
    Python 使用 MPI 的 **mpi4py** 包 ([http://mpi4py.scipy.org](http://mpi4py.scipy.org))。关于如何安装
    MPI 的信息可以在这些网站上找到。
- en: Note
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**MPI on Windows**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**Windows 上的 MPI**'
- en: If you are on Windows, a possibility is to install Microsoft's MPI implementation
    available in the HPC Pack ([http://www.microsoft.com/en-us/download/details.aspx?id=36045](http://www.microsoft.com/en-us/download/details.aspx?id=36045)).
    Also, you may be interested in the Python Tools for Visual Studio ([http://pytools.codeplex.com](http://pytools.codeplex.com)),
    which lets you turn Visual Studio into a Python IDE. It offers native support
    for IPython, and has been specifically designed for high-performance computing
    with MPI.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用的是 Windows，一种可能性是安装 Microsoft 的 MPI 实现，该实现可在 HPC Pack 中找到 ([http://www.microsoft.com/en-us/download/details.aspx?id=36045](http://www.microsoft.com/en-us/download/details.aspx?id=36045))。此外，您可能对
    Python Tools for Visual Studio ([http://pytools.codeplex.com](http://pytools.codeplex.com))
    感兴趣，它可以将 Visual Studio 转变为 Python IDE。它提供了对 IPython 的原生支持，并专门设计用于 MPI 的高性能计算。
- en: 'First, we need to create a specific IPython profile for MPI. Type in the following
    command in a shell:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要为 MPI 创建一个特定的 IPython 配置文件。在 shell 中输入以下命令：
- en: '[PRE17]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, edit the file `IPYTHONDIR/profile_mpi/ipcluster_config.py` (`IPYTHONDIR`
    is generally `~/.ipython`) and add the following line:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，编辑文件 `IPYTHONDIR/profile_mpi/ipcluster_config.py`（`IPYTHONDIR` 通常为 `~/.ipython`）并添加以下行：
- en: '[PRE18]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, to launch the cluster with four engines, type in the following command:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，要启动带有四个引擎的集群，请在 shell 中输入以下命令：
- en: '[PRE19]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To use MPI with IPython, we first need to write a function using MPI through
    mpi4py. In this example, we will compute the sum of all integers between 1 and
    16 in parallel, across four cores. Let''s write, in a file named `psum.py`, the
    following code:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 IPython 中使用 MPI，我们首先需要通过 mpi4py 编写一个使用 MPI 的函数。在这个例子中，我们将在四个核心上并行计算从 1 到
    16 的所有整数的总和。让我们在名为 `psum.py` 的文件中编写以下代码：
- en: '[PRE20]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Finally, we can use this function interactively in IPython as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 IPython 中可以交互地使用此函数，如下所示：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'More details about how to use MPI with IPython can be found on the following
    webpage from the official IPython documentation (where this example comes from):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何在 IPython 中使用 MPI 的更多详细信息可以在官方 IPython 文档中的以下网页找到（这个例子来自于这里）：
- en: '[http://ipython.org/ipython-doc/stable/parallel/parallel_mpi.html](http://ipython.org/ipython-doc/stable/parallel/parallel_mpi.html)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://ipython.org/ipython-doc/stable/parallel/parallel_mpi.html](http://ipython.org/ipython-doc/stable/parallel/parallel_mpi.html)'
- en: Advanced parallel computing features of IPython
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IPython 的高级并行计算特性
- en: 'We covered only the very basics of the parallel computing features available
    in IPython. More advanced features include the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅覆盖了 IPython 中可用的并行计算特性的基础知识。更高级的特性包括以下内容：
- en: Dynamic load balancing
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态负载均衡
- en: Pushing and pulling objects across engines
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在引擎之间推送和拉取对象
- en: Running engines on different computers, optionally using SSH tunnels
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同计算机上运行引擎，可选地使用 SSH 隧道
- en: Using IPython on an Amazon EC2 cluster with StarCluster
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Amazon EC2 集群中使用 StarCluster 运行 IPython
- en: Storing all requests and results in a database
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有请求和结果存储在数据库中
- en: Managing task dependencies with a Directed Acyclic Graph (DAG)
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用有向无环图 (DAG) 管理任务依赖关系
- en: These features are far beyond the scope of this book. Interested readers can
    find details about all those features in the official IPython documentation.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特性远超出本书的范围。有兴趣的读者可以在官方 IPython 文档中找到关于所有这些特性的详细信息。
- en: Using C in IPython with Cython
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 IPython 中使用 C 语言和 Cython
- en: 'Distributing independent tasks across several cores is the easiest way to take
    advantage of the parallel capabilities of modern computers, thereby reducing the
    total execution time twofold or more. However, some algorithms cannot be easily
    split into independent subtasks. In addition, it may happen that the algorithm
    itself is far too slow in Python because it involves nested loops that cannot
    be vectorized. In this situation, a very interesting option could be to code a
    small but critical section of the code in C so as to considerably reduce the Python
    overhead. This solution does not involve any parallel computing feature, but it
    still allows to considerably improve the efficiency of a Python script. Additionally,
    nothing prevents using both techniques: partial C compilation and parallel computing
    with IPython.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 将独立任务分配到多个核心是利用现代计算机并行能力的最简单方式，从而将总执行时间减少一倍或更多。然而，有些算法无法轻易拆分成独立的子任务。此外，某些算法可能在
    Python 中非常缓慢，因为它涉及到无法向量化的嵌套循环。在这种情况下，一个非常有趣的选择是将代码中的一个小而关键的部分用 C 语言编写，以显著减少 Python
    的开销。这个解决方案并不涉及任何并行计算特性，但仍然可以显著提高 Python 脚本的效率。此外，没有什么能阻止同时使用这两种技术：部分 C 编译和使用 IPython
    进行并行计算。
- en: The Cython package allows the compiling of a portion of the Python code without
    even converting it explicitly in C; it proposes an extended syntax in Python to
    call C functions and to define C types. The code in question is, then, automatically
    converted in C, compiled, and can then be used transparently from Python. In some
    situations when only pure Python code is possible, and when vectorization with
    NumPy is out of reach due to the particular nature of the algorithms, the speed
    improvement can be drastic and can reach several orders of magnitude.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Cython 包允许在不显式转换为 C 代码的情况下编译部分 Python 代码；它提供了在 Python 中调用 C 函数和定义 C 类型的扩展语法。相关的代码会被自动转换成
    C 编译，并可以透明地从 Python 中使用。在某些情况下，当只能使用纯 Python 代码，并且由于算法的特殊性质无法使用 NumPy 进行向量化时，速度提升可能会非常显著，达到几个数量级。
- en: In this section, we will see how to use Cython interactively in IPython. We
    will also look at an example of a pure Python function implementing a numerical
    algorithm, which can be compiled with Cython without too much effort for an execution
    more than 300 times faster.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何在 IPython 中交互式地使用 Cython。我们还将查看一个纯 Python 函数实现的数值算法示例，该算法可以通过 Cython
    编译，执行速度比原来快超过 300 倍。
- en: Installing and configuring Cython
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装和配置 Cython
- en: The Cython package is a bit more difficult to install than the other packages.
    The reason is that using Cython means compiling C code, which obviously requires
    a C compiler (for example the popular GNU C Compiler **gcc**). On Linux, gcc is
    already available or easily installable with the package manager, for example
    with `sudo apt-get install build-essential` on Ubuntu or Debian. On OS X, a possibility
    is to install Apple XCode. On Windows, you can install MinGW ([http://www.mingw.org](http://www.mingw.org)),
    which is an open-source distribution of gcc. Then, Cython can be installed as
    the other packages (see [Chapter 1](ch01.html "Chapter 1. Getting Started with
    IPython"), *Getting started with IPython*). More information can be found at [http://wiki.cython.org/Installing](http://wiki.cython.org/Installing).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Cython 包的安装比其他包稍微困难一些。原因是使用 Cython 需要编译 C 代码，这显然需要一个 C 编译器（例如流行的 GNU C 编译器 **gcc**）。在
    Linux 上，gcc 已经可以使用，或者通过包管理器轻松安装，例如在 Ubuntu 或 Debian 上使用 `sudo apt-get install
    build-essential`。在 OS X 上，可以选择安装 Apple XCode。在 Windows 上，可以安装 MinGW（[http://www.mingw.org](http://www.mingw.org)），它是
    gcc 的一个开源发行版。然后，Cython 可以像安装其他包一样进行安装（见 [第1章](ch01.html "第1章：开始使用 IPython")，*开始使用
    IPython*）。更多信息可以在 [http://wiki.cython.org/Installing](http://wiki.cython.org/Installing)
    找到。
- en: Note
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Configuring MinGW and Cython on Windows**'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**在 Windows 上配置 MinGW 和 Cython**'
- en: On Windows, depending on the version of MinGW, error messages may appear when
    compiling Cython code. To fix this bug, you may need to open `C:\Python27\Lib\distutils\cygwinccompiler.py`
    (or a similar path depending on your specific configuration) and replace all occurrences
    of `-mno-cygwin` with `""` (empty string).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，根据 MinGW 的版本，编译 Cython 代码时可能会出现错误信息。要修复此 bug，您可能需要打开 `C:\Python27\Lib\distutils\cygwinccompiler.py`（或根据您的具体配置类似路径），然后将所有
    `-mno-cygwin` 的出现替换为空字符串 `""`。
- en: 'Also, make sure that `C:\MinGW\bin` is in the `PATH` environment variable.
    Finally, you may need to edit (or create) the file `C:\Python27\Lib\distutils\distutils.cfg`
    and add the following lines of code:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，确保 `C:\MinGW\bin` 在 `PATH` 环境变量中。最后，可能需要编辑（或创建）文件 `C:\Python27\Lib\distutils\distutils.cfg`
    并添加以下几行代码：
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: You can find more information at [http://wiki.cython.org/InstallingOnWindows](http://wiki.cython.org/InstallingOnWindows).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [http://wiki.cython.org/InstallingOnWindows](http://wiki.cython.org/InstallingOnWindows)
    上找到更多信息。
- en: Using Cython from IPython
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 IPython 中使用 Cython
- en: With Cython, the code is generally written in a `.pyx` file, which is converted
    in C by Cython. Then, the resulting C program is compiled by the C compiler into
    a `.so` file (on Linux) or a `.pyd` file (on Windows), which can be normally imported
    in Python.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Cython 时，代码通常写在 `.pyx` 文件中，该文件通过 Cython 转换为 C 代码。然后，生成的 C 程序由 C 编译器编译成 `.so`
    文件（在 Linux 上）或 `.pyd` 文件（在 Windows 上），可以在 Python 中正常导入。
- en: This process typically involves a `distutils setup.py` script which specifies
    the files to be compiled and also the different compiler options. Because this
    step is not particularly difficult, we will not cover it here. Rather, we will
    show how Cython can be easily used from IPython. The advantage is that the Cython
    and C compilations happen automatically uder the hood and do not require a manual
    `setup.py` script. The IPython notebook is particularly useful here, as it is
    far more convenient to write multiline code in it than in the console.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程通常涉及一个 `distutils setup.py` 脚本，该脚本指定了需要编译的文件和不同的编译器选项。由于这个步骤并不特别困难，我们在这里不会详细介绍。相反，我们将展示如何在
    IPython 中轻松使用 Cython。其优点在于 Cython 和 C 编译过程会在后台自动完成，无需手动编写 `setup.py` 脚本。IPython
    笔记本在这里尤其有用，因为它比控制台更方便编写多行代码。
- en: Here we will show how to use the `%%cython` cell magic to execute Cython code
    from IPython. The first step is to load the `cythonmagic` extension.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将展示如何使用 `%%cython` 单元魔法从 IPython 中执行 Cython 代码。第一步是加载 `cythonmagic` 扩展。
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Then, the `%%cython` cell magic allows to write Cython code that will be automatically
    compiled. The functions defined in the cell become available in the interactive
    session, and can be used normally from Python.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`%%cython` 单元魔法允许编写会自动编译的 Cython 代码。单元中定义的函数将在交互式会话中可用，并且可以像普通 Python 函数一样使用。
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here, the call to `square(10)` involves the call to a compiled C function which
    computes the square of the number.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，调用 `square(10)` 涉及调用一个编译的 C 函数，该函数计算数字的平方。
- en: Accelerating a pure Python algorithm with Cython
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Cython 加速纯 Python 算法
- en: Here, we will see how a pure Python algorithm involving nested loops can be
    converted in Cython for an interesting 10-fold speed improvement. This algorithm
    is the **Sieve of Eratosthenes** , a multi-millennial algorithm for finding all
    the prime integers less than a fixed number. This very classic algorithm consists
    of starting from all integers between 2 and *n*, and progressively removing the
    multiples of the prime numbers found so far. At the end of the algorithm, only
    the prime numbers remain. We will implement this algorithm in Python and show
    how it can be converted in Cython.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将看到如何将一个包含嵌套循环的纯 Python 算法转换为 Cython，从而实现大约 10 倍的速度提升。这个算法是**厄拉托斯特尼筛法**，一个用于寻找小于固定数字的所有素数的千年算法。这个非常经典的算法的过程是从
    2 到 *n* 之间的所有整数开始，逐步去除已找到的素数的倍数。在算法结束时，剩下的就是素数。我们将用 Python 实现这个算法，并展示如何将其转换为 Cython。
- en: Pure Python version
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 纯 Python 版本
- en: The algorithm is a dozen-lines long in pure Python. This implementation could
    be improved and shortened in many ways (a one-liner algorithm exists!), but it
    will be sufficient for this example as we will mostly be interested in the *relative*
    execution times of the pure Python and Cython versions.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在纯 Python 中，该算法仅由十几行代码组成。这个实现可以通过多种方式进行改进和简化（实际上可以用一行代码实现！），但对于这个示例来说，它已经足够，因为我们主要关注的是纯
    Python 和 Cython 版本的*相对*执行时间。
- en: '[PRE25]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `primes` variable contains Boolean values indicating whether the associated
    index is prime or not. We initialize it with only `0` and `1` being composite
    (non-prime), using the definition that a positive integer is prime if and only
    if it has exactly two positive divisors. Then, at each iteration over `i`, we
    will mark more and more numbers as composite numbers, without changing the prime
    ones. Every `i` represents a prime number, and the iteration over `k` allows to
    mark all multiples of `i` as composite numbers. At the end, we return the list
    of indices that are `True`, that is, all prime numbers less than `n`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`primes`变量包含布尔值，用于指示关联的索引是否是素数。我们初始化时，只将`0`和`1`标记为合数（非素数），并使用“如果且仅如果一个正整数恰好有两个正除数，则它是素数”这一定义。然后，在每次对`i`的迭代中，我们会标记更多的数为合数，而不会改变素数。每个`i`代表一个素数，`k`的迭代则会将所有`i`的倍数标记为合数。最后，我们返回所有`True`的索引，也就是所有小于`n`的素数。'
- en: 'Now, let''s take a look at the execution time of this function:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下这个函数的执行时间：
- en: '[PRE26]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We will try to speed up this function using Cython.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试使用Cython加速这个函数。
- en: Naïve Cython conversion
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 初级Cython转换
- en: As a first attempt, we will simply use the exact same code in Cython.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一次尝试，我们将直接使用相同的Cython代码。
- en: '[PRE27]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We achieve 70 percent speed improvement here just by adding `%%cython` at the
    top of the cell, but we can do much better by giving type information to Cython.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅通过在单元格顶部添加`%%cython`，就实现了70%的速度提升，但如果我们为Cython提供类型信息，性能可以更好。
- en: Adding C types
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加C类型
- en: The speed improvement in the previous example was modest because the local variables
    are dynamically-typed Python variables. It means that the Python overhead due
    to its dynamic nature is still responsible for an important performance discrepancy
    as compared to pure C code. We can improve the performance by converting the Python
    variables into C variables with the `cdef` keyword.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个例子中的速度提升比较温和，因为局部变量是动态类型的Python变量。这意味着，由于Python的动态特性，其开销仍然是与纯C代码相比导致性能差异的重要原因。我们可以通过使用`cdef`关键字将Python变量转换为C变量，从而提高性能。
- en: '[PRE28]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'There are three changes compared to the naïve version: the `n` argument is
    statically declared as an integer, and the local variables `i` and `k` are now
    declared as C integer variables. The speed improvement is, then, much more interesting:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 相较于初级版本，有三个变化：`n`参数被静态声明为整数，局部变量`i`和`k`现在声明为C整数变量。因此，性能提升更加明显：
- en: '[PRE29]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This function is now 10 times faster than the pure Python version, just by using
    the `%%cython` magic and a few type declarations. This result might even be improved
    with more adequate data structures.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 仅通过使用`%%cython`魔法和一些类型声明，这个函数现在比纯Python版本快了10倍。通过更合适的数据结构，结果可能还会得到进一步的优化。
- en: In general, knowing the portion of the code that would be advantageously converted
    in Cython for a major speed improvement, requires some knowledge about the Python
    internals and, more importantly, requires performing extensive profiling. Python
    loops (especially nested loops), Python function calls, and high-level data structure
    manipulations inside tight loops are classical targets for Cython optimizations.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，知道哪些代码部分在转换为Cython后能显著提升性能，需要对Python的内部机制有一定了解，更重要的是，需要进行广泛的性能分析。Python循环（尤其是嵌套循环）、Python函数调用以及在紧密循环中操作高层数据结构，都是Cython优化的经典目标。
- en: Using NumPy and Cython
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用NumPy和Cython
- en: In this section, we will show how to integrate NumPy arrays with Cython code.
    We will also see how calls to Python functions inside tight loops can be vastly
    optimized by converting the Python functions into C functions.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示如何将NumPy数组与Cython代码结合使用。我们还将看到如何通过将Python函数转换为C函数，显著优化在紧密循环中对Python函数的调用。
- en: Python version
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python版本
- en: Here, we will use an example of a **stochastic process simulation**, namely
    a Brownian motion. This process describes the trajectory of a particle starting
    at `x=0`, and making random steps of `+dx` or `-dx` at each discrete time step,
    with `dx` being a small constant. This type of process appears frequently in finance,
    economy, physics, biology, and so on.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将通过一个**随机过程模拟**的示例来演示，具体是布朗运动。该过程描述了一个粒子从`x=0`出发，在每个离散时间步长上进行`+dx`或`-dx`的随机步伐，其中`dx`是一个小常数。这种类型的过程在金融、经济、物理学、生物学等领域中都很常见。
- en: This specific process can be simulated very efficiently with NumPy's `cumsum()`
    and `rand()` functions. However, more complex processes may need to be simulated,
    for example, some models require instantaneous jumps when the position reaches
    a threshold. In these cases, vectorization is not an option and a manual loop
    is, therefore, unavoidable.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定的过程可以通过NumPy的`cumsum()`和`rand()`函数非常高效地模拟。然而，更复杂的过程可能需要进行模拟，例如一些模型要求在位置达到某个阈值时进行瞬时跳跃。在这些情况下，向量化不是一种选择，因此手动循环是不可避免的。
- en: '[PRE30]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `step` function returns a random `+1` or `-1` value. It uses NumPy''s `sign()`
    and `rand()` functions. In the `sim1()` function, the trajectory is first initialized
    as a NumPy vector with zeros. Then, at each iteration, a new random step is added
    to the trajectory. The `then` function returns the full trajectory. The following
    is an example of a trajectory:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`step`函数返回一个随机的`+1`或`-1`值。它使用了NumPy的`sign()`和`rand()`函数。在`sim1()`函数中，轨迹首先被初始化为一个全为零的NumPy向量。然后，在每次迭代中，会向轨迹中添加一个新的随机步长。`then`函数返回完整的轨迹。以下是一个轨迹的示例：'
- en: '[PRE31]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![Python version](img/9932_05_02.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![Python版本](img/9932_05_02.jpg)'
- en: Simulation of a Brownian motion
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 布朗运动的模拟
- en: Let's take a look to the execution time of this function.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个函数的执行时间。
- en: '[PRE32]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Cython version
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Cython版本
- en: For the Cython version, we will do two things. First, we will add C types for
    all local variables as well as for the NumPy array containing the trajectory.
    Also, we will convert the `step()` function to a pure C function that does not
    call any NumPy function. We will rather call pure C functions that are defined
    in the C standard library.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Cython版本，我们将做两件事。首先，我们将为所有局部变量以及包含轨迹的NumPy数组添加C类型。同时，我们将把`step()`函数转换为一个纯C函数，该函数不调用任何NumPy函数。我们将调用在C标准库中定义的纯C函数。
- en: '[PRE33]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We first need to import the standard NumPy library as well as a special C library,
    also called `NumPy`, which is part of the Cython package, with `cimport`. We define
    the NumPy dtype `double` and the corresponding C dtype `double_t` with `ctypedef`.
    It allows to define the exact type of the `x` array at compile-time rather than
    execution-time, resulting in major speed improvements. The number of dimensions
    of `x` is also specified inside the `sim2()` function. All local variables are
    defined as C variables with C types.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要导入标准的NumPy库，以及一个特殊的C库，也叫做`NumPy`，它是Cython包的一部分，通过`cimport`引入。我们定义了NumPy的数据类型`double`和相应的C数据类型`double_t`，使用`ctypedef`。这允许在编译时而非执行时定义`x`数组的确切类型，从而大幅提高速度。`x`的维度数也在`sim2()`函数内指定。所有局部变量都被定义为C类型的C变量。
- en: The `step()` function has been entirely rewritten. It is now a pure C function
    (defined with `cdef`). It uses the `rand()` function of the C standard library,
    which returns a random number between 0 and `RAND_MAX`. The `round()` function
    of the `math` library is also used to generate a random `+1` or `-1` value.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`step()`函数已被完全重写。现在它是一个纯C函数（使用`cdef`定义）。它使用C标准库中的`rand()`函数，该函数返回一个介于0和`RAND_MAX`之间的随机数。`math`库中的`round()`函数也被用来生成一个随机的`+1`或`-1`值。'
- en: 'Let''s check the execution time of the `sim2()` function:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来检查一下`sim2()`函数的执行时间：
- en: '[PRE34]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The Cython version is 370 times faster than the Python version. The main reason
    for this dramatic speed improvement is that the Cython version uses only pure
    C code. All variables are C variables, and the calls to step, which previously
    required costly calls to a Python function, now only involve calls to a pure C
    function, thereby reducing considerably the Python overhead inside the loop.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Cython版本比Python版本快370倍。这一剧烈的速度提升的主要原因在于Cython版本仅使用纯C代码。所有变量都是C变量，之前需要调用Python函数的`step`函数，现在只需要调用纯C函数，这大大减少了循环中Python的开销。
- en: More advanced options for accelerating Python code
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加速Python代码的更高级选项
- en: Cython can also be used to interface existing C code or libraries with Python,
    but we won't cover this use case here.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Cython还可以用来将现有的C代码或库与Python接口，但我们在这里不讨论这种用例。
- en: Apart from Cython, there are other packages that accelerate Python code. `SciPy.weave`
    ([http://www.scipy.org/Weave](http://www.scipy.org/Weave)) is a SciPy subpackage
    that allows the inclusion of C/C++ code within Python code. **Numba** ([http://numba.pydata.org/](http://numba.pydata.org/))
    uses just-in-time LLVM compilation to accelerate a pure Python code considerably
    by compiling it dynamically and transparently. It integrates nicely with NumPy
    arrays. Its installation requires llvmpy and meta.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 Cython 之外，还有其他一些加速 Python 代码的包。`SciPy.weave` ([http://www.scipy.org/Weave](http://www.scipy.org/Weave))
    是 SciPy 的一个子包，允许将 C/C++ 代码嵌入到 Python 代码中。**Numba** ([http://numba.pydata.org/](http://numba.pydata.org/))
    使用即时编译的 LLVM 技术，通过动态和透明地编译纯 Python 代码，从而显著加速其执行。它与 NumPy 数组有很好的兼容性。安装时需要 llvmpy
    和 meta。
- en: Related projects include **Theano** ([http://deeplearning.net/software/theano/](http://deeplearning.net/software/theano/)),
    which allows to define, optimize, and evaluate mathematical expressions on arrays
    very efficiently by compiling them transparently on the CPU or on the graphics
    card. Similarly, **Numexpr** ([https://code.google.com/p/numexpr/](https://code.google.com/p/numexpr/))
    can compile array expressions and take advantage of vectorized CPU instructions
    and multi-core processors.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 相关项目包括 **Theano** ([http://deeplearning.net/software/theano/](http://deeplearning.net/software/theano/))，它通过在
    CPU 或显卡上透明地编译数学表达式，使得在数组上定义、优化和评估这些表达式变得非常高效。同样，**Numexpr** ([https://code.google.com/p/numexpr/](https://code.google.com/p/numexpr/))
    可以编译数组表达式，并利用矢量化 CPU 指令和多核处理器的优势。
- en: '**Blaze** ([http://blaze.pydata.org/](http://blaze.pydata.org/)) is a project
    that is still in early development at the time of writing, and aims at combining
    all these dynamic compilation technologies together into a unified framework.
    It will also extend the notion of multidimensional array by allowing type and
    shape heterogeneity, missing values, labeled dimensions (such as in Pandas), and
    so on. Being developed by the creators of NumPy, it is likely to be a central
    project in the Python computing community in the near future.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**Blaze** ([http://blaze.pydata.org/](http://blaze.pydata.org/)) 是一个仍处于早期开发阶段的项目，旨在将所有这些动态编译技术整合到一个统一的框架中。它还将通过允许类型和形状的异质性、缺失值、标记维度（如在
    Pandas 中）等，扩展多维数组的概念。由 NumPy 的创建者开发，它有望在不久的将来成为 Python 计算社区的一个核心项目。'
- en: Finally, **PyOpenCL** ([http://mathema.tician.de/software/pyopencl](http://mathema.tician.de/software/pyopencl))
    and **PyCUDA** ([http://mathema.tician.de/software/pycuda](http://mathema.tician.de/software/pycuda))
    are Python wrappers to OpenCL and CUDA. These libraries implement C-like, low-level
    languages that can be compiled on modern graphics cards for taking advantage of
    their massively parallel architecture. Indeed, graphics cards contain hundreds
    of specialized cores that can process a function very efficiently on a large number
    of elements (**Single Instruction Multiple Data** (**SIMD**) paradigm). The speed
    improvement can be more than one order of magnitude faster compared to pure C
    code. **OpenCL** is an open standard language, whereas **CUDA** is a proprietary
    language owned by Nvidia Corporation. CUDA code runs on Nvidia cards only, whereas
    OpenCL is supported by most graphics cards as well as most CPUs. In the latter
    case, the same code is compiled on the CPU and takes advantage of multi-core processors
    and vectorized instructions.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，**PyOpenCL** ([http://mathema.tician.de/software/pyopencl](http://mathema.tician.de/software/pyopencl))
    和 **PyCUDA** ([http://mathema.tician.de/software/pycuda](http://mathema.tician.de/software/pycuda))
    是 OpenCL 和 CUDA 的 Python 封装库。这些库实现了类似 C 的低级语言，可以在现代显卡上编译，利用其大规模并行架构。事实上，显卡包含数百个专用核心，可以非常高效地处理大量元素的函数（**单指令多数据**
    (**SIMD**) 模式）。与纯 C 代码相比，速度提升可能达到一个数量级以上。**OpenCL** 是一种开放标准语言，而 **CUDA** 是由 Nvidia
    公司拥有的专有语言。CUDA 代码仅能在 Nvidia 显卡上运行，而 OpenCL 则得到大多数显卡和大多数 CPU 的支持。在后者的情况下，相同的代码会在
    CPU 上编译，并利用多核处理器和矢量化指令。
- en: Summary
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we introduced two approaches to accelerate Python code: bypassing
    the Python overhead by converting the Python code into lower-level C code, or
    taking advantage of multi-core processors by distributing Python code across multiple
    computing units. Both approaches can even be used simultaneously. IPython considerably
    simplifies these techniques. Parallel computing and Cython can be used without
    IPython, but they require more boilerplate code.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了两种加速Python代码的方法：通过将Python代码转换为低级C代码来绕过Python的开销，或者通过将Python代码分布到多个计算单元上，利用多核处理器的优势。两种方法甚至可以同时使用。IPython大大简化了这些技术。虽然并行计算和Cython可以在没有IPython的情况下使用，但它们需要更多的样板代码。
- en: In the next chapter, we will explore some advanced options to customize IPython.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨一些高级选项来定制IPython。
