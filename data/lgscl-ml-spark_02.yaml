- en: Chapter 2. Machine Learning Best Practices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 机器学习最佳实践
- en: 'The purpose of this chapter is to provide a conceptual introduction to statistical
    **machine learning** (**ML**) techniques for those who might not normally be exposed
    to such approaches during their typical required statistical training. This chapter
    also aims to take a newcomer from minimal knowledge of machine learning all the
    way to a knowledgeable practitioner in a few steps. The second part of the chapter
    is focused on giving some recommendations for choosing the right machine learning
    algorithms depending on the application types and requirements. It will then lead
    through some best practices when applying large-scale machine learning pipelines. In
    a nutshell, the following topics will be discussed in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是为那些在典型的统计培训中可能不会接触到这些方法的人提供统计机器学习（ML）技术的概念介绍。本章还旨在通过几个步骤，将新手从对机器学习的最小知识带到了解的实践者。本章的第二部分侧重于根据应用类型和要求选择合适的机器学习算法的一些建议。然后，它将引导人们在应用大规模机器学习流程时遵循一些最佳实践。简而言之，本章将讨论以下主题：
- en: What is machine learning?
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: Machine learning tasks
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习任务
- en: Practical machine learning problems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际机器学习问题
- en: Large scale machine learning APIs in Spark
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark中的大规模机器学习API
- en: Practical machine learning best practices
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际机器学习最佳实践
- en: Choosing the right algorithm for your application
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为您的应用选择合适的算法
- en: What is machine learning?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: In this section, we will try to define the term machine learning from the computer
    science, statistics and data analytical perspectives. Then we will show the steps
    of analytical machine learning applications. Finally, we will discuss some typical
    and emerging machine learning tasks and then name some practical machine learning
    problems that need to be addressed.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将尝试从计算机科学、统计学和数据分析的角度定义机器学习这个术语。然后我们将展示分析机器学习应用的步骤。最后，我们将讨论一些典型和新兴的机器学习任务，并列举一些需要解决的实际机器学习问题。
- en: Machine learning in modern literature
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现代文献中的机器学习
- en: 'Let''s see how a renowned professor of machine learning, Tom Mitchell, Chair
    of the CMU Machine Learning Department and Professor at the Carnegie Mellon University
    defines the term machine learning in his literature (*Tom M. Mitchell, The Discipline
    of Machine Learning, CMU-ML-06-108, July 2006*, [http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf](http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看机器学习著名教授Tom Mitchell是如何定义机器学习这个术语的。他是CMU机器学习系主任，也是卡内基梅隆大学的教授。在他的文献中（*Tom
    M. Mitchell, The Discipline of Machine Learning, CMU-ML-06-108, July 2006*，[http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf](http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)）中定义了机器学习这个术语：
- en: '*Machine Learning is a natural outgrowth of the intersection of Computer Science
    and Statistics. We might say the defining question of Computer Science is ''How
    can we build machines that solve problems, and which problems are inherently tractable/intractable?''
    The question that largely defines Statistics is ''What can be inferred from data
    plus a set of modelling assumptions, with what reliability?'' The defining question
    for Machine Learning builds on both, but it is a distinct question. Whereas Computer
    Science has focused primarily on how to manually program computers, Machine Learning
    focuses on the question of how to get computers to program themselves (from experience
    plus some initial structure). Whereas Statistics has focused primarily on what
    conclusions can be inferred from data, Machine Learning incorporates additional
    questions about what computational architectures and algorithms can be used to
    most effectively capture, store, index, retrieve and merge these data, how multiple
    learning subtasks can be orchestrated in a larger system, and questions of computational
    tractability.*'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*机器学习是计算机科学和统计学交叉的自然产物。我们可以说，计算机科学的定义性问题是“我们如何构建解决问题的机器，哪些问题本质上是可解的/不可解的？”统计学的定义性问题主要是“在数据加上一组建模假设的情况下，可以推断出什么，以及推断的可靠性是什么？”机器学习的定义性问题建立在这两者之上，但它是一个独特的问题。计算机科学主要关注如何手动编程计算机，而机器学习关注的是如何让计算机自己编程（从经验中加上一些初始结构）。统计学主要关注从数据中可以推断出什么结论，而机器学习还包括关于如何最有效地捕获、存储、索引、检索和合并这些数据的计算架构和算法，以及如何在更大的系统中协调多个学习子任务，以及计算可解性的问题。*'
- en: We believe that this definition from Prof. Tom is self-explanatory. However,
    we will provide some clearer understanding of machine learning in the next two
    sub-sections from the computer science, statistics, and data analytical perspectives.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信Tom教授的这个定义是不言自明的。然而，我们将在接下来的两个小节中从计算机科学、统计学和数据分析的角度提供对机器学习的更清晰的理解。
- en: Tip
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'Interested readers should follow other resources to get more insights about
    machine learning and its theoretical perspective. Here we have provided some links
    as follows: *Machine learning*: [https://en.wikipedia.org/wiki/Machine_learning](https://en.wikipedia.org/wiki/Machine_learning).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 感兴趣的读者应该查阅其他资源，以获取有关机器学习及其理论视角的更多见解。在这里，我们提供了一些链接如下：*机器学习*：[https://en.wikipedia.org/wiki/Machine_learning](https://en.wikipedia.org/wiki/Machine_learning)。
- en: '*Machine learning: what it is and why matters* - [http://www.sas.com/en_us/insights/analytics/machine-learning.html](http://www.sas.com/en_us/insights/analytics/machine-learning.html).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*机器学习：它是什么，为什么重要* - [http://www.sas.com/en_us/insights/analytics/machine-learning.html](http://www.sas.com/en_us/insights/analytics/machine-learning.html)。'
- en: '*A Gentle Introduction To Machine Learning*: [https://www.youtube.com/watch?v=NOm1zA_Cats](https://www.youtube.com/watch?v=NOm1zA_Cats).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*机器学习的初步介绍*：[https://www.youtube.com/watch?v=NOm1zA_Cats](https://www.youtube.com/watch?v=NOm1zA_Cats)。'
- en: '*What is machine learning, and how does it work*: [https://www.youtube.com/watch?v=elojMnjn4kk](https://www.youtube.com/watch?v=elojMnjn4kk).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*什么是机器学习，它是如何工作的*：[https://www.youtube.com/watch?v=elojMnjn4kk](https://www.youtube.com/watch?v=elojMnjn4kk)。'
- en: '*Introduction to Data Analysis using Machine Learning*: [https://www.youtube.com/watch?v=U4IYsLgNgoY](https://www.youtube.com/watch?v=U4IYsLgNgoY).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用机器学习进行数据分析入门*：[https://www.youtube.com/watch?v=U4IYsLgNgoY](https://www.youtube.com/watch?v=U4IYsLgNgoY)。'
- en: Machine learning and computer science
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习和计算机科学
- en: Machine learning is a branch of computer science that studies the design of
    algorithms that can learn from its heuristics that typically evolved from the
    study of pattern recognition and computational learning theory in artificial intelligence.
    An interesting question came into the mind of Alan Turing about the machine, which
    is, *Can a machine think?* In fact, there are some good reasons to believe a sufficiently
    complex machine could one day pass the unrestricted Turing test; let's postpone
    this question until the Turing test, but gets passed. However, machines can learn
    at least. Subsequently, Arthur Samuel was the first man who defined the term **machine
    learning** as a f*ield of study that gives computers the ability to learn without
    being explicitly programmed* in 1959\. Typical machine learning tasks are concept
    learning, predictive modeling, classification, regression, clustering, dimensionality
    reduction, recommender system, deep learning and finding useful patterns from
    the large-scale dataset.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是计算机科学的一个分支，研究可以从启发式学习中学习的算法，这通常源自于模式识别和人工智能中的计算学习理论。艾伦·图灵脑海中出现了一个有趣的问题，即*机器能思考吗？*实际上，有一些很好的理由相信一个足够复杂的机器有一天可以通过无限制的图灵测试；让我们推迟这个问题，直到图灵测试通过。然而，机器至少可以学习。随后，阿瑟·塞缪尔是第一个在1959年将术语**机器学习**定义为*一种研究领域，使计算机能够在没有明确编程的情况下学习*的人。典型的机器学习任务包括概念学习、预测建模、分类、回归、聚类、降维、推荐系统、深度学习以及从大规模数据集中找到有用模式。
- en: The ultimate goal is to improve the learning in such a way that it becomes automatic,
    so that no human interactions are needed any more, or the level of human interaction
    is reduced as much as possible. Although machine learning is sometimes conflated
    with **Knowledge Discovery and Data Mining** (**KDDM**), the latter sub-field
    on the other hand focuses more on exploratory data analysis and is known as unsupervised
    learning - such as clustering analysis, anomaly detection, **Artificial Neural
    Networks** (**ANN**), and so on.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最终目标是通过改进学习方式使其变得自动化，以至于不再需要人类干预，或者尽可能减少人类干预的程度。尽管机器学习有时与**知识发现和数据挖掘**（**KDDM**）混淆，但后者更专注于探索性数据分析，被称为无监督学习
    - 例如聚类分析、异常检测、**人工神经网络**（**ANN**）等。
- en: Other machine learning techniques include supervised learning, where a learning
    algorithm analyzes the training data and produces an inferred function that can
    be used for mapping new examples towards prediction. Classification and regression
    analysis are two typical examples of supervised learning. Reinforcement learning,
    on the other hand, is inspired by behaviorist psychology (see also [https://en.wikipedia.org/wiki/Behaviorism](https://en.wikipedia.org/wiki/Behaviorism)),
    which is is typically concerned with how a software agent performs an action in
    a new *environment* by maximizing the `reward` function. Dynamic programming and
    intelligent agent are two examples of reinforcement learning.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 其他机器学习技术包括监督学习，其中学习算法分析训练数据并生成可用于映射新示例进行预测的推断函数。分类和回归分析是监督学习的两个典型示例。另一方面，强化学习受行为主义心理学（参见[https://en.wikipedia.org/wiki/Behaviorism](https://en.wikipedia.org/wiki/Behaviorism)）的启发，通常关注软件代理如何通过最大化`奖励`函数在新的*环境*中执行动作。动态规划和智能代理是强化学习的两个示例。
- en: Typical machine learning applications can be classified into scientific knowledge
    discovery and more commercial applications, ranging from Robotic or **Human Computer
    Interaction** (**HCI**) to anti-spam filtering and recommender systems.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的机器学习应用可以分为科学知识发现和更多商业应用，从机器人或**人机交互**（**HCI**）到反垃圾邮件过滤和推荐系统。
- en: Machine learning in statistics and data analytics
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 统计学和数据分析中的机器学习
- en: Machine learning reconnoitres the study and construction of algorithms (see
    also [https://en.wikipedia.org/wiki/Algorithm](https://en.wikipedia.org/wiki/Algorithm))
    that can learn (see also [https://en.wikipedia.org/wiki/Learning](https://en.wikipedia.org/wiki/Learning))
    from the heuristics and make meaningful predictions on data. However, in order
    to make data-driven predictions or decisions, such algorithms operate by building
    a model (see also [https://en.wikipedia.org/wiki/Mathematical_model](https://en.wikipedia.org/wiki/Mathematical_model))
    from training datasets, quicker than following a stringently static program or
    instructions. Machine learning is also closely related and often overlaps with
    the nature of computational statistics. Computational statistics is, on the other
    hand, an applied field of statistics that focuses on making predictions through
    a computerised approach. In addition, it has strong stalemates to mathematical
    optimisation, which delivers methods and computing tasks along with theory and
    application domains. The tasks that are not feasible in mathematics due to the
    demands for a strong background knowledge of mathematics, machine learning suits
    best and can be applied as the alternative to that.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是研究和构建算法的学科（参见[https://en.wikipedia.org/wiki/Algorithm](https://en.wikipedia.org/wiki/Algorithm)），这些算法可以从启发式学习（参见[https://en.wikipedia.org/wiki/Learning](https://en.wikipedia.org/wiki/Learning)）并对数据进行有意义的预测。然而，为了进行数据驱动的预测或决策，这些算法通过从训练数据集中构建模型（参见[https://en.wikipedia.org/wiki/Mathematical_model](https://en.wikipedia.org/wiki/Mathematical_model)）来操作，比严格遵循静态程序或指令更快。机器学习也与计算统计学密切相关并经常重叠。另一方面，计算统计学是统计学的一个应用领域，专注于通过计算机化方法进行预测。此外，它与数学优化有着密切的关系，提供了方法和计算任务以及理论和应用领域。由于对数学背景知识的强烈需求，数学中不可行的任务最适合机器学习，并可以作为替代方法应用。
- en: 'Within the field of data analytics, on the other hand, machine learning is
    a method used to devise complex models and algorithms that advance themselves
    towards prediction for a future outcome. These analytical models allow researchers,
    data scientists, engineers, and analysts to produce reliable, repeatable, and
    reproducible results and mine hidden insights through learning from past relationships
    (heuristics) and trends in the data. Again we will refer to a famous definition
    from Prof. Tom, where he explained what learning really means from the computer
    science perspective in the literature (*Tom M. Mitchell, The Discipline of Machine
    Learning, CMU-ML-06-108, July 2006*, [http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf](http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在数据分析领域，机器学习是一种用于设计复杂模型和算法的方法，这些模型和算法朝着预测未来结果的方向发展。这些分析模型允许研究人员、数据科学家、工程师和分析师通过从过去的关系（启发式）和数据中的趋势中学习来产生可靠、可重复和可再现的结果，并挖掘隐藏的见解。我们再次引用Tom教授的著名定义，他在文献中解释了从计算机科学的角度来看学习的真正含义（*Tom
    M. Mitchell, The Discipline of Machine Learning, CMU-ML-06-108, July 2006*, [http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf](http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)）：
- en: '*A computer program is said to learn from experience E with respect to some
    class of tasks T and performance measure P, if its performance at tasks in T,
    as measured by P, improves with experience E.*'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*如果一个计算机程序在某类任务T上的表现，根据性能度量P，随着经验E的积累而提高，那么就可以说它在任务T上从经验E中学习。*'
- en: 'Therefore, we can conclude that a computer program or machines can:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以得出结论，计算机程序或机器可以：
- en: Learn from data and histories
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据和历史中学习
- en: Can be improved with experience
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以通过经验进行改进
- en: Interactively enhance a model that can be used to predict the outcomes of questions
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交互式地增强模型，以用于预测问题的结果
- en: 'Furthermore, the following diagram helps us to understand the whole process
    of machine learning:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以下图表帮助我们理解机器学习的整个过程：
- en: '![Machine learning in statistics and data analytics](img/00109.jpeg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![统计学和数据分析中的机器学习](img/00109.jpeg)'
- en: 'Figure 1: Machine learning at a glance.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：一览机器学习。
- en: Typical machine learning workflow
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 典型的机器学习工作流程
- en: 'A typical machine learning application involving several steps from input,
    processing to output that form a scientific workflow is shown in Figure 2\. The
    following steps are involved in typical machine learning applications:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的机器学习应用包括从输入、处理到输出的几个步骤，形成了一个科学工作流程，如图2所示。典型的机器学习应用涉及以下步骤：
- en: Load the sample data.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载样本数据。
- en: Parse the data into the input format for the algorithm.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据解析成算法的输入格式。
- en: Pre-process the data and handle the missing values.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理数据并处理缺失值。
- en: Split the data into two sets, one for building the model (training dataset)
    and one for testing the model (test dataset or validation dataset).
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分成两组，一组用于构建模型（训练数据集），另一组用于测试模型（测试数据集或验证数据集）。
- en: Run the algorithm to build or train your ML model.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行算法来构建或训练您的机器学习模型。
- en: Make predictions with the training data and observe the results.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练数据进行预测并观察结果。
- en: Test and evaluate the model with the test data or alternatively validate the
    model with some cross-validator technique using the third dataset, called the
    validation dataset.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用测试数据测试和评估模型，或者使用第三个数据集（验证数据集）使用交叉验证技术验证模型。
- en: Tune the model for better performance and accuracy.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整模型以获得更好的性能和准确性。
- en: Scale-up the model so that it can handle massive datasets in the future.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展模型，以便将来能处理大规模数据集。
- en: Deploy the ML model in commercialization:![Typical machine learning workflow](img/00069.jpeg)
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在商业化中部署机器学习模型：![典型的机器学习工作流程](img/00069.jpeg)
- en: 'Figure 2: Machine learning workflow.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：机器学习工作流程。
- en: Often the machine learning algorithms have some ways to handle the skewness
    in the datasets; that skewness can sometimes be immensely skewed though. In step
    4, the experimental dataset is split often into a training set and test sets randomly,
    which is called sampling. The training dataset is used to train the model, whereas
    the test dataset is used to evaluate the performance of the best model at the
    very end. The better practice is to use the training dataset as much as you can
    to increase the generalization performance. On the other side, it is recommended
    to use the test dataset only once to avoid the overfitting and underfitting problem
    while computing the prediction error and the related metrics.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，机器学习算法有一些方法来处理数据集中的偏斜；这种偏斜有时可能非常严重。在第4步中，实验数据集通常被随机分成训练集和测试集，这被称为抽样。训练数据集用于训练模型，而测试数据集用于评估最佳模型的性能。更好的做法是尽可能多地使用训练数据集，以提高泛化性能。另一方面，建议只使用测试数据集一次，以避免在计算预测误差和相关指标时出现过拟合和欠拟合问题。
- en: Tip
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Overfitting is a statistical property by which random error and noise is described
    apart from the normal and underlying relationships. It mostly occurs when there
    are too many hyperparameters relative to the number of observations or features.
    Under fitting on the other hand refers to a model that can neither model the training
    data nor generalize to new data towards the model evaluation or adaptability.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合是一种统计特性，描述了除了正常和基础关系之外的随机误差和噪音。当超参数相对于观察值或特征的数量过多时，它通常会发生。另一方面，欠拟合是指既不能对训练数据建模，也不能对新数据进行泛化，以适应模型评估或适应性。
- en: However, these steps consist of several techniques and we will discuss those
    in [Chapter 5](part0043_split_000.html#190862-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 5.  Supervised and Unsupervised Learning by Examples"), *Supervised and
    Unsupervised Learning by Examples* in detail. Step 9 and 10 are usually considered
    as advanced steps, and they consequently will be discussed in later chapters.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些步骤包括几种技术，我们将在[第5章](part0043_split_000.html#190862-0b803698e2de424b8aa3c56ad52b005d
    "第5章。通过示例进行监督和无监督学习")中详细讨论这些技术。第9步和第10步通常被认为是高级步骤，因此它们将在后面的章节中讨论。
- en: Machine learning tasks
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习任务
- en: 'Machine learning tasks or machine learning processes are typically classified
    into three broad categories, depending on the nature of the learning feedback
    available to a learning system. Supervised learning, unsupervised learning, and
    reinforcement learning; these three kinds of machine learning tasks are shown
    in *Figure 3*, and will be discussed in this section:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习任务或机器学习过程通常根据学习系统可用的学习反馈的性质分为三类。监督学习、无监督学习和强化学习；这三种机器学习任务在*图3*中显示，并将在本节中讨论：
- en: '![Machine learning tasks](img/00112.jpeg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习任务](img/00112.jpeg)'
- en: 'Figure 3: Machine learning tasks.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：机器学习任务。
- en: Supervised learning
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习
- en: A **supervised learning** application makes predictions based on a set of examples,
    and the goal is to learn general rules that map inputs to outputs aligning with
    the real world. For example, a dataset for spam filtering usually contains spam
    messages as well as non-spam messages. Therefore, we could know which messages
    in a training set are spams or non-spams. Nevertheless, we might have the opportunity
    to use this information to train our model in order to classify new and unseen
    messages. Figure 4 shows the schematic diagram of the supervised learning.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**监督学习**应用程序基于一组示例进行预测，其目标是学习将输入映射到与现实世界一致的输出的一般规则。例如，用于垃圾邮件过滤的数据集通常包含垃圾邮件和非垃圾邮件。因此，我们可以知道训练集中哪些消息是垃圾邮件或非垃圾邮件。然而，我们可能有机会使用这些信息来训练我们的模型，以便对新的和未见过的消息进行分类。图4显示了监督学习的示意图。'
- en: 'In other words, the dataset for training the ML model in this case is labeled
    with the value of interest and a supervised learning algorithm looks for patterns
    in those value labels. After the algorithm has found the required patterns, those
    patterns can be used to make predictions for unlabeled test data. This is the
    most popular and useful type of machine learning tasks, which is not an exception
    for Spark as well, where most of the algorithms are a supervised learning technique:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，在这种情况下，用于训练机器学习模型的数据集带有感兴趣的值标签，并且监督学习算法会寻找这些值标签中的模式。算法找到所需的模式后，这些模式可以用于对未标记的测试数据进行预测。这是最流行和有用的机器学习任务类型，对于Spark也不例外，其中大多数算法都是监督学习技术：
- en: '![Supervised learning](img/00122.jpeg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![监督学习](img/00122.jpeg)'
- en: 'Figure 4: Supervised learning in action.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：监督学习实例。
- en: Unsupervised learning
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习
- en: In **unsupervised learning**, data points have no labels related or in other
    words, the correct classes of the training dataset in unsupervised learning are
    unknown, as shown in *Figure 5*. As a result, classes have to be inferred from
    the unstructured datasets, which implies that the goal of an unsupervised learning
    algorithm is to pre-process the data in some structured ways by describing its
    structure.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在**无监督学习**中，数据点没有相关的标签，或者换句话说，在无监督学习的训练数据集中，正确的类别是未知的，如*图5*所示。因此，类别必须从非结构化数据集中推断出来，这意味着无监督学习算法的目标是通过描述其结构来对数据进行预处理。
- en: To overcome this obstacle in unsupervised learning, clustering techniques are
    used typically to group the unlabeled samples based on certain similarity measures,
    mining hidden patterns towards feature learning. More technically, we can write
    down a generative model, and then tell the data to find parameters that explain
    the data to us. Now what will happen next if we are not satisfied with the possibility
    of this elucidation? The answer is that we should tell the data to do it again
    until we are using some efficient algorithms or techniques.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服无监督学习中的这一障碍，通常使用聚类技术来基于某些相似性度量对未标记的样本进行分组，挖掘隐藏模式以进行特征学习。更技术上地说，我们可以编写一个生成模型，然后告诉数据找到解释数据的参数。现在，如果我们对这种阐释的可能性不满意，接下来会发生什么？答案是，我们应该告诉数据再做一次，直到我们使用一些有效的算法或技术为止。
- en: Now a new question may arise in your mind, why do we have to put labels on the
    data? Or cannot we just appreciate the data in its current order recognizing that
    each datum is unique and pre snowflake? In other words, with a little supervision,
    our data can grow up to be whatever it wants to be! So why should the unlabeled
    data be taken into consideration too?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可能会产生一个新的问题，为什么我们必须在数据上贴标签？或者我们不能只欣赏当前顺序的数据，认识到每个数据都是独特的，就像雪花一样？换句话说，通过一点监督，我们的数据可以成长为任何它想成为的东西！那么为什么未标记的数据也应该被考虑进来呢？
- en: 'Well, there are some deeper issues regarding this. For example, most of the
    variation in the data comes from phenomena that are irrelevant to our desired
    labeling scheme. A more realistic example would be how Gmail classifies e-mails
    as spam and ham using the supervised learning technique, where the data might
    use its parameters to explain its semantics, when all we care about is its syntactic
    properties:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，关于这个问题还有一些更深层次的问题。例如，数据中的大部分变化来自于与我们所期望的标记方案无关的现象。一个更现实的例子是Gmail如何使用监督学习技术将电子邮件分类为垃圾邮件和正常邮件，其中数据可能使用其参数来解释其语义，而我们关心的只是其句法属性：
- en: '![Unsupervised learning](img/00134.jpeg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![无监督学习](img/00134.jpeg)'
- en: 'Figure 5: Unsupervised learning.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：无监督学习。
- en: Reinforcement learning
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化学习
- en: '**Reinforcement learning** is the technique where the model itself learns from
    a series of actions or behaviors. Complexity of datasets or sample complexity
    is very important in the reinforcement learning needed for the algorithms to learn
    a target function successfully. Moreover, in response to each data point for achieving
    the ultimate goal, maximization of the reward function should be ensured while
    interacting with an external environment, as demonstrated in *Figure 6*. To make
    the maximization easier, the reward function can either be exploited by penalizing
    the bad actions or rewarding for the good actions.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习**是一种技术，模型本身从一系列行为或行为中学习。在强化学习中，数据集的复杂性或样本复杂性对于算法成功学习目标函数非常重要。此外，为了实现最终目标，与外部环境互动时应确保最大化奖励函数，如*图6*所示。为了使最大化更容易，奖励函数可以通过惩罚不良行为或奖励良好行为来利用。'
- en: 'In order to achieve the highest reward, the algorithm should be modified with
    a strategy that also allows the machine or software agent to learn its behavior
    periodically. These behaviors can be learned once and for all, or the machine
    learning model can keep adapting as times passes:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得最高的奖励，算法应该通过策略进行修改，也允许机器或软件代理定期学习其行为。这些行为可以一劳永逸地学习，或者随着时间的推移，机器学习模型可以不断适应：
- en: '![Reinforcement learning](img/00143.jpeg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![强化学习](img/00143.jpeg)'
- en: 'Figure 6: Reinforcement learning.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：强化学习。
- en: For example, reinforcement learning is common in robotics; the algorithm must
    choose the robot's next action based on a set of sensor readings. It is also a
    natural fit for **Internet of Things** (**IoT**) applications, where a computer
    program interacts with a dynamic environment in which it must perform a certain
    goal, without an explicit mentor. Another example is the game **Flappy Bird**,
    which has been trained to play itself.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，强化学习在机器人技术中很常见；算法必须基于一组传感器读数选择机器人的下一个动作。它也是**物联网**（**IoT**）应用的自然选择，其中计算机程序与动态环境进行交互，必须实现某个目标，而没有明确的导师。另一个例子是游戏**Flappy
    Bird**，它已经被训练成自己玩。
- en: Recommender system
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐系统
- en: 'A recommender system is an emerging application, which is a subclass of information
    filtering system use for making a prediction of the rating or preference from
    the users that they usually provide to an item. The concept of recommender systems
    has become very common in recent years and subsequently applied in different applications.
    The most popular ones are probably products (for examples, movies, music, books,
    research articles, news, search queries, social tags, and so on). Recommender
    systems can be typed into four categories typically:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是一种新兴应用，是信息过滤系统的子类，用于预测用户通常对项目提供的评分或偏好。最近几年推荐系统的概念变得非常普遍，并随后应用于不同的应用程序。最流行的可能是产品（例如电影、音乐、书籍、研究文章、新闻、搜索查询、社交标签等）。推荐系统通常可以分为四类：
- en: Collaborative filtering system, where accumulation of a consumer's preferences
    and recommendations to other users is based on likeness in behavioral patterns.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协同过滤系统，其中消费者的偏好和对其他用户的推荐是基于行为模式的相似性积累。
- en: Content-based systems, where the supervised machine learning is used to persuade
    a classifier to distinguish between interesting and uninteresting items for the
    users.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于内容的系统，其中使用监督机器学习来说服分类器区分用户感兴趣和不感兴趣的项目。
- en: Hybrid recommender systems is a recent research and hybrid approach (that is,
    combining collaborative filtering and content-based filtering). Netflix is a good
    example of such a recommendation system that uses **Restricted Boltzmann Machines**
    (**RBM**) and a form of the Matrix Factorization algorithm for large movie databases,
    such as IMDb. This recommendation, which simply recommends movies or dramas or
    streaming by comparing the watching and searching habits of similar users, is
    called rating prediction.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合推荐系统是最近的研究和混合方法（即，结合协同过滤和基于内容的过滤）。Netflix是这样一个推荐系统的良好例子，它使用**受限玻尔兹曼机**（**RBM**）和一种矩阵分解算法来处理大型电影数据库，如IMDb。这种推荐，通过比较相似用户的观看和搜索习惯简单地推荐电影或戏剧或流媒体，被称为评分预测。
- en: Knowledge-based systems, where knowledge about users and products is used to
    reason what fulfills the user's requirements, using the perception tree, decision
    support systems, and case-based reasoning.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于知识的系统，其中使用有关用户和产品的知识来推理满足用户需求的内容，使用感知树、决策支持系统和基于案例的推理。
- en: Semi-supervised learning
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 半监督学习
- en: 'Between supervised and unsupervised learning, there is a small place for **semi-supervised
    learning**; where the ML model usually receives an incomplete training signal.
    More statistically, the ML model receives a training set with some of the target
    outputs missing. The semi-supervised learning is more or less assumption-based
    and often uses three kinds of assumption algorithms as the learning algorithm
    for the unlabeled datasets. The following assumptions are used: smoothness, cluster,
    and manifold assumption.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在**监督学习**和**无监督学习**之间，有一个小小的地方是**半监督学习**；在这种情况下，机器学习模型通常接收不完整的训练信号。更具体地说，机器学习模型接收到一组目标输出部分缺失的训练集。半监督学习更多地基于假设，并且通常使用三种假设算法作为未标记数据集的学习算法。使用以下假设：平滑性、聚类和流形假设。
- en: In other words, semi-supervised learning can furthermore be denoted as a **weakly
    supervised** or **bootstrapping** technique for using the hidden wealth of unlabeled
    examples to enhance the learning from a small amount of labeled data. Emerging
    examples include *semi-supervised expectation minimization, and concept learning
    in human cognition and transitive SVMs*.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，半监督学习还可以被称为**弱监督**或**自举**技术，用于利用未标记示例的隐藏财富来增强从少量标记数据中学习。新兴示例包括*半监督期望最小化和人类认知中的概念学习以及传递SVM*。
- en: Practical machine learning problems
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际机器学习问题
- en: What does machine learning really mean? We already saw some convincing definitions
    of this term as well as the meaning of the term *learning* at the very beginning
    of this chapter. However, the reality is machine learning itself is defined by
    the problems to be resolved. In this section, we will first emphasize the machine
    learning classes and then we will list some well-known and popularly-used examples
    of real world machine learning problems. The typical classes include classification,
    clustering, rule extraction, and regression, which will all be discussed.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习到底是什么意思？我们在本章的开头已经看到了一些令人信服的对这个术语的定义，以及术语“学习”的含义。然而，机器学习本身的定义取决于要解决的问题。在本节中，我们将首先强调机器学习的类别，然后列举一些现实世界中广为人知和广泛使用的机器学习问题的例子。典型的类别包括分类、聚类、规则提取和回归，这些都将被讨论。
- en: In addition, we will also discuss those problems based on the main taxonomy
    of standard machine learning problems. This is important, since knowing the type
    of problems we could face allows us to think about the data we need. Another important
    fact is that before knowing some practical machine learning problems, you might
    face difficulties in having an idea about developing your machine learning applications.
    In other words, to know the problem we need to know the data in the very first
    place. Therefore, the types of algorithm and their optimality to be addressed
    will be discussed throughout this chapter; data manipulation, however, will be
    discussed to dig-down the problems in [Chapter 3](part0031_split_000.html#TI1E2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 3. Understanding the Problem by Understanding the Data"), *Understanding
    the Problem by Understanding the Data*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将讨论基于标准机器学习问题的主要分类法的问题。这很重要，因为了解我们可能面临的问题类型可以让我们考虑我们需要的数据。另一个重要的事实是，在了解一些实际的机器学习问题之前，你可能会在开发机器学习应用程序的想法上遇到困难。换句话说，要知道问题，我们首先需要了解数据。因此，本章将讨论算法的类型及其优化问题；数据处理将在[第三章](part0031_split_000.html#TI1E2-0b803698e2de424b8aa3c56ad52b005d
    "第三章。通过了解数据来理解问题")中进行讨论，*通过了解数据来理解问题*。
- en: Machine learning classes
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习类别
- en: The problem classes we mentioned above are standards for most of the problems
    we refer to in everyday life while doing and applying machine learning techniques.
    However, knowing only the ML classes is not enough we also need to know what type
    of problems machines are learning, since you will find many problems that are
    simply problem solving that does not help a ML model or agent to learn at all.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们上面提到的问题类别是我们在日常生活中使用和应用机器学习技术时所指的大多数问题的标准。然而，仅仅知道机器学习类别是不够的，我们还需要知道机器正在学习什么类型的问题，因为你会发现许多问题只是简单的问题解决，并没有帮助机器学习模型或代理进行学习。
- en: 'When you think a problem is a machine learning problem, more technically, you
    are thinking of a decision problem that needs to be modeled from data that could
    be termed as a machine learning problem. In other words, as a data scientist or
    human expert, if you have enough time to answer a particular question by knowing
    the available dataset, you can more or less apply a suitable machine learning
    problem. Therefore, we can assume that a solvable problem using some ML algorithms
    would have mainly two parts - the data itself, which could be used to point to
    specific observations of the problem, and secondly the quantitative measurement
    of the quality of an available solution. Once you have succeeded in identifing
    a problem as an ML problem, you would probably be able to think about what types
    of problems you could formulate with it easily, or the type of aftermath your
    client will be asking for, or what sorts of requirements are to be satisfied.
    As already stated in the above section, the more frequently used machine learning
    classes are: classification, clustering, regression, and rule extraction. We will
    now provide a short overview of each class.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当你认为一个问题是一个机器学习问题时，更准确地说，你在考虑一个需要从数据中建模的决策问题，这可以被称为一个机器学习问题。换句话说，作为数据科学家或人类专家，如果你有足够的时间通过了解可用的数据集来回答一个特定的问题，你可以或多或少地应用一个合适的机器学习问题。因此，我们可以假设使用一些机器学习算法可以解决的问题主要有两个部分
    - 数据本身，可以用来指向问题的特定观察结果，以及可用解决方案的质量的定量测量。一旦你成功地将一个问题确定为机器学习问题，你可能能够思考如何轻松地制定出什么类型的问题，或者你的客户将会要求什么样的后果，或者需要满足什么样的要求。正如上面所述，更常用的机器学习类别包括：分类、聚类、回归和规则提取。我们现在将对每个类别进行简要概述。
- en: Classification and clustering
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类和聚类
- en: If the experimental dataset is labeled, it means a class has been assigned to
    it already. For instance, spam/non-spam during spam e-mail detection or fraud/non-fraud
    during credit card fraud identification. However, if the dataset based on which
    the fundamental decision will be made or modeled is unlabeled, new labels need
    to be made manually or algorithmically. This might be difficult, and can be thought
    of a judgment problem. On the contrary, sculpting the differences or resemblances
    between several groups might be computationally harder.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果实验数据集已经标记，这意味着已经为其分配了一个类别。例如，在垃圾邮件检测中的垃圾邮件/非垃圾邮件，或者在信用卡欺诈识别中的欺诈/非欺诈。然而，如果基本决策的数据集是未标记的，新的标签需要手动或算法地制作。这可能很困难，可以被视为一个判断问题。相反，雕刻出几个群体之间的差异或相似之处可能在计算上更加困难。
- en: Clustering, on the other hand, handles the data that is not labeled or un-labeled.
    However, it still can be divided into groups based on similarity and other measures
    of natural structure in the data you have. Organizing pictures from a digital
    album by faces only without names could be an example, where the human users like
    us have to assign names to groups manually. Again, the same computational complexity
    might arise to label multiple image files manually; we will provide some examples
    in later chapters of how Spark provides several APIs to solve these issues.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，聚类处理的是未标记或无标记的数据。然而，它仍然可以根据相似性和数据中的自然结构的其他度量来分成组。将数字相册中的图片仅按面孔组织起来而不带有姓名可能是一个例子，人类用户必须手动为组分配名称。同样，手动标记多个图像文件可能会产生相同的计算复杂性；我们将在后面的章节中提供一些示例，说明Spark如何提供多个API来解决这些问题。
- en: Rule extraction and regression
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规则提取和回归
- en: From the given dataset, propositional rules can be generated by means of antecedent
    and consequent in the *if...then* style that defines the behavior of a machine
    learning agent. This type of rule generation technique is commonly referred to
    as *rule extraction*. You might be wondering if such rules might exist, however,
    they are typically not directed. That means the methods used to discover statistically
    meaningful or statistically significant relationships between attributes in your
    data.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定的数据集中，可以通过前提和结论以*if...then*的方式生成命题规则，定义了机器学习代理的行为。这种规则生成技术通常被称为*规则提取*。你可能会想知道这样的规则是否存在，然而，它们通常不是有针对性的。这意味着用于发现数据中属性之间的统计显著或统计相关关系的方法。
- en: An example of rule extraction is the mining association rules between items
    from business oriented transactional databases. Non-technically, a practical example
    could be the discovery of the relationship or association between the purchase
    of beer and diapers, which is illustrative of the desire and opportunity for the
    customers. However, some situation, might arise where some predictions out of
    the rules or data are not necessarily involved directly.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 规则提取的一个例子是在面向业务的事务性数据库中挖掘项目之间的关联规则。非技术上，一个实际的例子可能是发现啤酒购买和尿布购买之间的关系或关联，这说明了顾客的愿望和机会。然而，可能会出现一些预测不一定直接涉及规则或数据的情况。
- en: Now let's talk about the regression where the data is labeled with a real value.
    To be more exact, some floating point value rather than having labels in the data.
    The easiest way to understand an example would be time series data similar to
    the price of a stock or currency that changes over time. In these types of data,
    the regression task is to make a prediction for new and unpredicted data by some
    regression modeling techniques.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们谈谈回归，其中数据带有实际值的标签。更确切地说，一些浮点值而不是数据中的标签。理解一个例子的最简单方法是时间序列数据，类似于股票或货币随时间变化的价格。在这些类型的数据中，回归任务是通过一些回归建模技术对新的和不可预测的数据进行预测。
- en: Most widely used machine learning problems
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最广泛使用的机器学习问题
- en: 'You will find an extensive amount of examples of the use of machine learning
    related problems in daily life, since they solve the difficult parts of the available
    problems that are widely used techniques or algorithms. We often use many desktop
    or web-based applications that solve your problems out of the data even without
    knowing that what underlying techniques have been used. You will be wondered to
    know that many of them actually use widely used machine learning algorithms to
    make your life easier. There are many machine learning problems around. Here we
    will mention some example problems that really represent what machine learning
    is all about:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现在日常生活中使用机器学习相关问题的大量例子，因为它们解决了广泛使用的技术或算法中的困难部分。我们经常使用许多桌面或基于网络的应用程序，即使不知道使用了哪些基础技术，也可以解决你的问题。你会惊讶地发现，其中许多实际上使用了广泛使用的机器学习算法，使你的生活更轻松。周围有许多机器学习问题。在这里，我们将提到一些真正代表机器学习的例子问题：
- en: '**Spam detection or spam filtering**: Given some e-mails in an inbox, the task
    is to identify those e-mails that are spam and those that are non-spam (often
    called ham) e-mail messages. Now the challenging part is to develop an ML application
    that can be applied so that it can identify only the non-spam e-mails to stay
    in the inbox. and move the spam emails to the corresponding spam folder or delete
    them permanently from the email account. A typical example could be what you may
    do while using Gmail manually, but if you have an ML application, that application
    will do it automatically.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垃圾邮件检测或垃圾邮件过滤**：给定收件箱中的一些电子邮件，任务是识别哪些电子邮件是垃圾邮件，哪些是非垃圾邮件（通常称为正常）电子邮件。现在具有挑战性的部分是开发一个可以应用的ML应用，以便它只能识别非垃圾邮件电子邮件留在收件箱中，并将垃圾邮件移动到相应的垃圾邮件文件夹中，或者永久从电子邮件帐户中删除它们。一个典型的例子可能是在使用Gmail时手动执行的操作，但如果你有一个ML应用程序，该应用程序将自动执行。'
- en: '**Anomaly detection or outlier detection**: The anomaly detection deals with
    the identification of items, events, or observations that are unexpected or non-confirming
    to the expected patterns in a dataset; in other words, the identification of suspect
    patterns. The most common example is network anomaly detection using some machine
    learning applications. Now the challenging task is to develop an ML application
    that can be applied successfully to simply identify the unusual data points from
    the data propagating across the network.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常检测或异常值检测**：异常检测涉及识别数据集中意外或不符合预期模式的项目、事件或观察结果；换句话说，是怀疑模式的识别。最常见的例子是使用一些机器学习应用进行网络异常检测。现在具有挑战性的任务是开发一个可以成功应用于简单识别网络中传播的异常数据点的ML应用。'
- en: '**Credit card fraud detection**: Credit card fraud is very common nowadays.
    Stealing credit card related information from online shopping and using it in
    an illegal way happens in many countries. Suppose you have a transactional database
    for a customer for a particular month. Now the challenging task is to develop
    an ML application to identify those transactions that were made by the customer
    themselves and those done by others illegally.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用卡欺诈检测：信用卡欺诈现在非常普遍。从网上购物中窃取信用卡相关信息，并以非法方式使用在许多国家都有发生。假设你有一个客户一个月的交易数据库。现在具有挑战性的任务是开发一个机器学习应用程序，以识别客户自己进行的交易和他人非法进行的交易。
- en: '**Voice recognition**: Recognizing a voice and converting it into a corresponding
    text command and later performing some actions, as an intelligent agent does.
    The most widely used applications include Apple Siri, Samsung S-Voice, Amazon''s
    Echo (consumer space), and Microsoft Cortana (especially because Cortana has SDKs
    for extensibility and integration, and so on). Another example would be locking
    or unlocking your smartphone by using the recognised voice.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音识别：识别声音并将其转换为相应的文本命令，然后执行一些操作，就像智能代理一样。最常用的应用包括苹果的Siri，三星的S-Voice，亚马逊的Echo（消费领域）和微软的Cortana（特别是因为Cortana具有用于可扩展性和集成等的SDK）。另一个例子是使用识别的声音来锁定或解锁智能手机。
- en: '**Digit/character recognition**: Suppose you have a handwritten zip code or
    address or message on/inside an envelope, now the task of digit/character recognition
    is to identify and classify the digits or characters for each handwritten character
    that is made by different people. An efficient ML application could help in this
    regard to read and understand handwritten zip codes or characters and sort the
    contents of the envelope by the geographic region, or more technically, by the
    image segmentations.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字/字符识别：假设你有一个手写的邮政编码、地址或信件，现在数字/字符识别的任务是识别和分类每个不同人写的手写字符的数字或字符。一个高效的机器学习应用可以帮助阅读和理解手写的邮政编码或字符，并按地理区域或更技术上的说法，按图像分割对信封内容进行分类。
- en: '**Internet of Things**: Large-scale sensor data analytics for prediction and
    classification from real-time streamed data. For example, smart living room monitoring
    including water level checking, room temperature checking, home appliances controlling,
    and so on.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物联网：大规模传感器数据分析，用于实时流数据的预测和分类。例如，智能客厅监控，包括水位检测，室温检测，家用电器控制等。
- en: '**Gaming analytics**: Analytics for sports, games, and console-based gaming
    profiles in order to predict upsell and target in-app purchases and modifications.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 游戏分析：用于预测升级销售和针对应用内购买和修改的体育、游戏和基于控制台的游戏档案分析
- en: '**Face detection**: Given a digital photo album of hundreds or thousands of
    photographs, the task is to identify those photos that resemble a given person.
    An efficient ML application, in this case, could help to organise photos by person.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸检测：给定数百或数千张照片的数字相册，任务是识别与给定人相似的照片。在这种情况下，高效的机器学习应用可以帮助按人员组织照片。
- en: '**Product recommendation**: Provided a purchase history of a customer along
    with a large inventory of products, the target is to identify those products that
    the customer will likely be interested in purchasing with an ML system. Business
    and tech giants such as Amazon, Facebook, and Google Plus have this recommended
    feature for the users.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品推荐：根据客户的购买历史和大量的产品库存，目标是识别客户可能有兴趣购买的产品。亚马逊、Facebook和Google Plus等商业和科技巨头为用户提供了这一推荐功能。
- en: '**Stock trading**: Given the current and historical prices for a stock market,
    predict whether stock should be bought or sold in order to profit with the help
    of an ML system.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 股票交易：根据股票市场的当前和历史价格，预测是否应该买入或卖出股票，以便利用机器学习系统获利。
- en: 'The following are some examples of machine learning that are emerging and the
    demands of current research:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些新兴的机器学习示例和当前研究的需求：
- en: '**Privacy preserving data mining**: Mining customer''s purchase rules from
    the maximal frequent pattern and association rules from business oriented retail
    databases to increase purchases in the future'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐私保护数据挖掘：从面向业务的零售数据库中挖掘最大频繁模式和关联规则，以增加未来的购买
- en: '**Author name disambiguation**: Disambiguation performance is evaluated with
    manual verification of random samples of pairs from clustering results from a
    list of authors from a set of given publications'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作者姓名消歧：使用手动验证从给定出版物集合的作者列表的聚类结果中的随机样本来评估消歧性能
- en: '**Recommendation systems**: Recommender system based on click stream data using
    association rule mining'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统：基于点击流数据的推荐系统，使用关联规则挖掘
- en: '**Text mining**: Plagiarism checking from a given text corpus for example'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本挖掘：例如，从给定的文本语料库中检查抄袭
- en: '**Sentiment analysis**: A lot of decisions these days are being made by business
    and tech companies based on the opinion of others, and it will be a good place
    to innovate machine learning'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感分析：如今很多商业和科技公司的决策都是基于他人的意见，这将是创新机器学习的好地方
- en: '**Speech understanding**: Given an utterance from a user, the target is to
    identify the specific request made by the user. A model of this problem would
    allow a program to understand and make an attempt to fulfill that request. For
    example, iPhone with Siri and Samsung Voice Recorder in meeting mode have this
    feature implemented'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音理解：给定用户的话语，目标是识别用户提出的具体请求。这个问题的模型将允许程序理解并尝试满足该请求。例如，iPhone的Siri和三星的语音记录器在会议模式下都实现了这个功能
- en: Some of these problems are the hardest problems in artificial intelligence,
    natural language processing, and computer vision that can be addressed and solved
    using ML algorithms. Similarly, we will try to develop some ML applications emphasizing
    these problems in upcoming chapters.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些问题是人工智能、自然语言处理和计算机视觉中最困难的问题，可以使用机器学习算法来解决。同样，我们将尝试开发一些强调这些问题的机器学习应用程序，在接下来的章节中进行讨论。
- en: Large scale machine learning APIs in Spark
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark中的大规模机器学习API
- en: In this section, we will describe two key concepts introduced by the Spark machine
    learning libraries (Spark MLlib and Spark ML) and the most widely used implemented
    algorithms that align with the supervised and unsupervised learning techniques
    we discussed in the above sections.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述Spark机器学习库（Spark MLlib和Spark ML）引入的两个关键概念，以及与我们在上述部分讨论的监督和无监督学习技术相一致的最常用的实现算法。
- en: Spark machine learning libraries
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Spark机器学习库
- en: As already stated, in the pre-Spark era, big data modelers typically used to
    build their ML models using statistical languages such as R, STATA, and SAS. Then
    the data engineers used to re-implement the same model in Java, for example, to
    deploy on Hadoop.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在Spark时代之前，大数据建模者通常使用统计语言（如R、STATA和SAS）构建他们的机器学习模型。然后数据工程师通常会重新用Java等语言实现相同的模型，以部署在Hadoop上。
- en: However, this kind of workflow lacks efficiency, scalability, throughput, and
    accuracy as well as extended execution time.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种工作流程缺乏效率、可扩展性、吞吐量和准确性，以及延长的执行时间。
- en: 'Using Spark, the same ML model can be re-built, adopted, and deployed, making
    the whole workflow much more efficient, robust, and faster, which allows you to
    provide hands-on insight to increase the performance. The Spark machine learning
    libraries are divided into two packages: Spark MLlib (`spark.mllib`) and Spark
    ML (`spark.ml`).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Spark，可以重新构建、采用和部署相同的机器学习模型，使整个工作流程更加高效、稳健和快速，从而使您能够提供实时洞察力以提高性能。Spark机器学习库分为两个包：Spark
    MLlib（`spark.mllib`）和Spark ML（`spark.ml`）。
- en: Spark MLlib
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Spark MLlib
- en: 'MLlib is Spark''s scalable machine learning library, which is the extension
    of the Spark Core API that provides a library of easy to use machine learning
    algorithms. Algorithms are implemented and written in Java, Scala, and Python.
    Spark provides support for local vectors and matrix data types stored on a single
    machine, as well as distributed matrices backed by one or multiple RDDs:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib是Spark的可扩展机器学习库，它是Spark Core API的扩展，提供了一系列易于使用的机器学习算法库。算法是用Java、Scala和Python实现和编写的。Spark支持存储在单台机器上的本地向量和矩阵数据类型，以及由一个或多个RDD支持的分布式矩阵：
- en: '| **Spark MLlib** |   |   |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| **Spark MLlib** |   |   |'
- en: '| **ML tasks** | **Discrete** | **Continuous** |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| **ML任务** | **离散** | **连续** |'
- en: '| Supervised | Classification:Logistic regressionand regularized variantsLinear
    SVMNaïve BayesDecision treesRandom forestsGradient-boosted trees | Regression:Linear
    regressionand regularized variantsLinear least squaresLasso and ridge regressionIsotonic
    regression |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 监督 | 分类：逻辑回归及其正则化变体线性支持向量机朴素贝叶斯决策树随机森林梯度提升树 | 回归：线性回归及其正则化变体线性最小二乘Lasso和岭回归等距回归
    |'
- en: '| Unsupervised | Clustering:K-meansGaussian matrix**Power iteration clustering**
    (**PIC**)**Latent Dirichlet Allocation** (**LDA**)Bisecting K-meansStreaming K-means
    | Dimensionality reduction, matrix factorization:Principal components analysisSingular
    value decompositionAlternate least square |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 无监督 | 聚类：K均值高斯矩阵幂迭代聚类（PIC）潜在狄利克雷分配（LDA）二分K均值流式K均值 | 降维、矩阵分解：主成分分析奇异值分解交替最小二乘
    |'
- en: '| Reinforcement | N/A | N/A |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 强化 | N/A | N/A |'
- en: '| Recommender systems | Collaborative filtering:Netflix recommendation | N/A
    |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 推荐系统 | 协同过滤：Netflix推荐 | N/A |'
- en: 'Table 1: Spark MLlib at a glance.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：一览Spark MLlib。
- en: '**Legend**: Continuous: making predictions about continuous variables, for
    example, prediction of the maximum temperature for the upcoming days'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图例**：连续：对连续变量进行预测，例如，预测未来几天的最高温度'
- en: '**Discrete**: Assigning discrete class labels to particular observations as
    outcomes of a prediction, for example, in weather forecasting it could be the
    prediction of a sunny, rainy, or snowy day'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离散：将离散的类标签分配给特定观察结果作为预测的结果，例如，在天气预报中，可以预测晴天、雨天或雪天
- en: The beauty of Spark MLlib is numerous. For example, the algorithms implemented
    using Scala, Java, and Python are highly-scalable and leverage Spark's ability
    to work with a massive amount of data. They are fast towards designed for parallel
    computing with in-memory based operation, which is 100 times faster compared to
    MapReduce data processing (they also support disk-based operation that is 10 times
    faster than what MapReduce has as normal data processing) using Dataset, DataFrame,
    or **Directed Acyclic Graph** (**DAG**)-based RDD APIs.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib的美妙之处在于众多。例如，使用Scala、Java和Python实现的算法具有高度可扩展性，并利用Spark处理大量数据的能力。它们设计快速，用于并行计算，基于内存的操作比MapReduce数据处理快100倍（它们还支持基于磁盘的操作，比MapReduce普通数据处理快10倍），使用Dataset、DataFrame或基于有向无环图（DAG）的RDD
    API。
- en: They are also diverse, since they cover common machine learning algorithms for
    regression analysis, classification, clustering, recommender systems, text analytics,
    frequent pattern mining, and they obviously cover all the steps required to build
    scalable machine learning applications.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 它们也是多样的，因为它们涵盖了用于回归分析、分类、聚类、推荐系统、文本分析、频繁模式挖掘的常见机器学习算法，显然也涵盖了构建可扩展机器学习应用程序所需的所有步骤。
- en: Spark ML
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Spark ML
- en: Spark ML adds a new set of machine learning APIs to let users quickly assemble
    and configure practical machine learning pipelines on top of Datasets. Spark ML
    targets to offer a uniform set of high-level APIs built on top of DataFrames rather
    than RDDs that help users create and tune practical machine learning pipelines.
    Spark ML API standardizes machine learning algorithms to make the learning tasks
    easier to combine multiple algorithms into a single pipeline or data workflow
    for data scientists.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML添加了一组新的机器学习API，让用户可以快速组装和配置实用的机器学习管道，构建在数据集之上。Spark ML旨在提供一组统一的高级API，构建在DataFrame而不是RDD之上，帮助用户创建和调整实用的机器学习管道。Spark
    ML API标准化了机器学习算法，使学习任务更容易将多个算法组合成单个管道或数据工作流，供数据科学家使用。
- en: 'Spark ML uses the concept of DataFrame (although it''s obsolete in Java but
    still the main programming interface in Python and R), which is introduced in
    the Spark 1.3.0 release from Spark SQL as machine learning Datasets. The Datasets
    hold diverse data types such as columns storing text, feature vectors, and true
    labels for the data. In addition to this, Spark ML also uses the transformer to
    transform one DataFrame into another or vice-versa, where the concept of the estimator
    is used to fit on a DataFrame to produce a new transformer. The pipeline API,
    on the other hand, can restrain multiple transformers and estimators together
    to specify an ML data-workflow. The concept of the parameter was introduced to
    specify all the transformers and estimators to share a common API under an umbrella
    during the development of an ML application:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML使用DataFrame的概念（尽管在Java中已经过时，但仍然是Python和R中的主要编程接口），这是在Spark 1.3.0版本中从Spark
    SQL引入的机器学习数据集。数据集包含各种数据类型，例如存储文本、特征向量和数据的真实标签的列。除此之外，Spark ML还使用转换器将一个DataFrame转换为另一个，反之亦然，其中估计器的概念用于在DataFrame上拟合以生成新的转换器。另一方面，管道API可以将多个转换器和估计器一起约束，以指定一个ML数据工作流。参数的概念是在开发ML应用程序期间引入的，用于指定所有转换器和估计器在一个统一的API下共享一个公共API：
- en: '| **Spark ML** |   |   |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| **Spark ML** |   |   |'
- en: '| **ML tasks** | **Discrete** | **Continuous** |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| **ML任务** | **离散** | **连续** |'
- en: '| Supervised | Classification:Logistic regressionDecision tree classifierRandom
    forest classifierGradient-boosted tree classifierMultilayer perception classifierOne-vs-Rest
    classifier | Regression:Linear regressionDecision tree regressionRandom forest
    regressionGradient-boosted tree regressionSurvival regression |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 监督 | 分类：逻辑回归决策树分类器随机森林分类器梯度提升树分类器多层感知分类器一对多分类器 | 回归：线性回归决策树回归随机森林回归梯度提升树回归生存回归
    |'
- en: '| Unsupervised | Clustering:K-means**Latent Dirichlet allocation** (**LDA**)
    | Tree Ensembles:Random forestsGradient-boosted Trees |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 无监督 | 聚类：K均值潜在狄利克雷分配（LDA） | 树集成：随机森林梯度提升树 |'
- en: '| Reinforcement | N/A | N/A |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 强化 | N/A | N/A |'
- en: '| Recommender systems | N/A | N/A |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 推荐系统 | N/A | N/A |'
- en: 'Table 2: Spark ML at a glance (legend same as Table 1).'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：一览Spark ML（图例与表1相同）。
- en: As shown in table 2, Spark ML also provides several classifications, regression,
    decision trees, and tree ensembles as well as a clustering algorithm implemented
    for developing ML pipelines on top of DataFrames. The optimization algorithm under
    active implementation is called **Orthant-Wise Limited-memory QuasiNewton** (**OWL-QN**),
    which is also an advanced algorithm that is an extension of L-BFGS that can effectively
    handle L1 regularization and elastic net (see also at Spark ML Advanced topic,
    [https://spark.apache.org/docs/latest/ml-advanced.html](https://spark.apache.org/docs/latest/ml-advanced.html)).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如表2所示，Spark ML还提供了几种分类、回归、决策树和树集成，以及用于在DataFrame上开发ML管道的聚类算法。正在积极实施的优化算法称为**正交有限内存拟牛顿**（**OWL-QN**），这也是一种高级算法，是L-BFGS的扩展，可以有效处理L1正则化和弹性网（也请参阅Spark
    ML高级主题，[https://spark.apache.org/docs/latest/ml-advanced.html](https://spark.apache.org/docs/latest/ml-advanced.html)）。
- en: Important notes for practitioners
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从业者的重要说明
- en: However, currently only Pearson's and Spearman's correlation are supported and
    more are to be added in future Spark releases. Unlike the other statistical functions,
    stratified sampling is also supported by Spark and it can be performed on RDDs
    as key-value pairs; however, some functionalities are yet to be added to Python
    developers. Currently there are no reinforcement learning algorithm modules in
    Spark Machine Learning libraries (please refer to *Table 1* and *Table 2*). The
    current implementation of Spark MLlib provides a parallel implementation of FP-growth
    for mining frequent patterns and the association rules. However, you will have
    to customize the algorithm for mining maximal frequent patterns accordingly. We
    will provide a scalable ML application for mining privacy preserving maximal frequent
    pattern in upcoming chapters.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，目前仅支持Pearson和Spearman的相关性，并且将在未来的Spark版本中添加更多。与其他统计函数不同，Spark还支持分层抽样，可以在RDD上作为键值对执行；但是，一些功能尚未添加到Python开发人员。目前在Spark机器学习库中没有强化学习算法模块（请参阅*表1*和*表2*）。Spark
    MLlib的当前实现提供了FP-growth的并行实现，用于挖掘频繁模式和关联规则。但是，您将需要根据需要自定义算法来挖掘最大频繁模式。我们将在即将到来的章节中提供一个可扩展的ML应用程序，用于挖掘隐私保护的最大频繁模式。
- en: Another fact is that the current implementation of the collaborative based recommendation
    system in Spark does not support the use of real time stream data, however, in
    later chapters we will try to show a practical recommender system based on click
    stream data using association rule mining (see Mitchell, Tom M. *The Discipline
    of Machine Learning*, 2006, [http://www.cs.cmu.edu/](http://www.cs.cmu.edu/).
    CMU. Web. Dec. 2014). However, some algorithms are not available or are yet to
    be added to Spark ML, most notably dimensionality reduction is such an example.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个事实是，Spark中协同推荐系统的当前实现不支持实时流数据的使用，然而，在后面的章节中，我们将尝试基于点击流数据使用关联规则挖掘来展示一个实际的推荐系统（参见Mitchell,
    Tom M. *机器学习的学科*，2006年，[http://www.cs.cmu.edu/](http://www.cs.cmu.edu/)。CMU. Web.
    2014年12月）。然而，一些算法尚未添加到Spark ML中，最值得注意的是降维是一个例子。
- en: However, developers can seamlessly combine the implementation of these techniques
    found in Spark MLlib with the rest of the algorithms found in Spark ML as hybrid
    or interoperable ML applications. Spark's neural networks and perception are brain-inspired
    learning algorithms covering multiclass, two-class, and regression problems that
    are not yet implemented in Spark ML APIs.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，开发人员可以无缝地将Spark MLlib中找到的这些技术的实现与Spark ML中找到的其他算法结合起来，作为混合或可互操作的ML应用程序。 Spark的神经网络和感知是基于大脑的学习算法，涵盖了多类、双类和回归问题，这些问题在Spark
    ML API中尚未实现。
- en: Practical machine learning best practices
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际机器学习最佳实践
- en: 'In this section, we will describe some good machine learning practices that
    need to be followed before developing a machine learning application of particular
    interest, as described in *Figure 7*:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述在开发特定兴趣的机器学习应用程序之前需要遵循的一些良好的机器学习实践，如*图7*所示：
- en: '![Practical machine learning best practices](img/00156.jpeg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![实际机器学习最佳实践](img/00156.jpeg)'
- en: 'Figure 7: Machine learning systematic process.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：机器学习系统化流程。
- en: 'A scalable and accurate ML application demand for following a systematic approach
    to its development from problem definition to presenting results can be summarized
    into four steps: problem definition and formulation, data preparation, finding
    suitable algorithms for machine learning, and finally, presenting the results
    after the machine learning model deployment. Well, these steps can be depicted
    as shown in *Figure 6*.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展和准确的ML应用需求，需要从问题定义到呈现结果的开发中遵循系统化的方法，可以总结为四个步骤：问题定义和制定、数据准备、寻找适合的机器学习算法，最后，在机器学习模型部署后呈现结果。嗯，这些步骤可以如*图6*所示。
- en: Best practice before developing an ML application
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在开发ML应用程序之前的最佳实践
- en: 'The learning of a machine learning system can be formulated as the sum of representation,
    evaluation, and optimisation. In other words, according to Pedro D et al. (Pedro
    Domingos, *A Few Useful Things to Know about Machine Learning*, [https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)):'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统的学习可以被公式化为表示、评估和优化的总和。换句话说，根据Pedro D等人的说法（Pedro Domingos，*关于机器学习的一些有用的东西*，[https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)）：
- en: '*Learning = Representation + Evaluation + Optimization*'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '*学习=表示+评估+优化*'
- en: Taking this formulation into consideration, we will provide some recommendations
    for practitioners before getting into ML application development.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这个公式，我们将在进入ML应用程序开发之前为从业者提供一些建议。
- en: Good machine learning and data science worth huge
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 良好的机器学习和数据科学价值巨大
- en: 'So what do we need for an effective machine learning applications development?
    We actually need four arsenals before we start developing an ML application; including:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，在开发有效的机器学习应用程序之前，我们需要什么？实际上，在开始开发ML应用程序之前，我们需要四种武器，包括：
- en: The data primitives (or the experimental data to be more frank).
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据基元（或更坦率地说，实验数据）。
- en: A pipeline synthesis tool (to understand the data and control flow during the
    machine learning steps).
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管道综合工具（用于理解机器学习步骤中的数据和控制流）。
- en: An effective and robust error analysis tools.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有效和健壮的错误分析工具。
- en: A verification or validation tool (to verify or validate the prediction accuracy
    or performance of the ML model). However, most importantly, without some strong
    theoretical basement with good data science that is worth a huge amount, the whole
    process will be in vain. In fact, many data scientists and machine learning experts
    often quote something like this statement: *if you can pose your problem as a
    simple optimization problem then you is almost done* (see *Data Analytics & R*,
    [http://advanceddataanalytics.net/2015/01/31/condensed-news-7/](http://advanceddataanalytics.net/2015/01/31/condensed-news-7/)).
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证或验证工具（用于验证或验证ML模型的预测准确性或性能）。然而，最重要的是，如果没有一些具有良好数据科学的强大理论基础，整个过程将是徒劳的。事实上，许多数据科学家和机器学习专家经常引用类似于这样的声明：*如果你能将你的问题提出为一个简单的优化问题，那么你几乎已经完成了*（见*数据分析与R*，[http://advanceddataanalytics.net/2015/01/31/condensed-news-7/](http://advanceddataanalytics.net/2015/01/31/condensed-news-7/)）。
- en: That means before you start your machine learning voyage, if you can identify
    if your problem is a machine learning problem, you will be able to find some suitable
    algorithms to develop your ML application altogether. Of course, in practice,
    most machine learning applications can't be changed into simple optimization problems.
    Therefore, it's the duty of a data scientist like you to manage and maintain complex
    datasets. After that, you will have to handle other issues such as the analytical
    problems that evolve when engineering the machine learning pipeline to tackle
    those issues we mentioned earlier.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在开始机器学习之前，如果你能确定你的问题是一个机器学习问题，你将能够找到一些合适的算法来一起开发你的ML应用。当然，在实践中，大多数机器学习应用无法转化为简单的优化问题。因此，像你这样的数据科学家的职责是管理和维护复杂的数据集。之后，你将不得不处理其他问题，比如在工程化机器学习管道时出现的分析问题，以解决我们之前提到的那些问题。
- en: 'Therefore, the best practice is to use Spark MLlib, Spark ML, GraphX, and Spark
    Core APIs along with the best practice data science heuristics for developing
    your machine learning applications together. Now you might think of getting benefits
    out of it; yes, the benefits are obvious, and they are as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最佳实践是使用Spark MLlib、Spark ML、GraphX和Spark Core API以及最佳实践的数据科学启发式方法来共同开发您的机器学习应用程序。现在你可能会想从中获益；是的，好处是显而易见的，它们如下：
- en: Built-in distributed algorithms
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置的分布式算法
- en: In-memory and disk-based data computation and processing
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存和基于磁盘的数据计算和处理
- en: In-memory capabilities for iterative workloads
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代工作负载的内存能力
- en: Algorithmic accuracy and performance
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法的准确性和性能
- en: Faster data cleaning, feature engineering and feature selection, training, and
    testing
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更快的数据清理、特征工程和特征选择、训练和测试
- en: Real-time visualization of the predictive results
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测结果的实时可视化
- en: Tuning towards better performance
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朝着更好的性能调整
- en: Adaptability for new datasets
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适应新数据集
- en: Scalability with the increasing datasets
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着数据集的增加而扩展性
- en: Best practice – feature engineering and algorithmic performance
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最佳实践-特征工程和算法性能
- en: In best practice, feature engineering should be considered as one of the most
    important parts of machine learning. The thing is to find a better representation
    of features out of the experimental dataset non-technically. In parallel to this,
    which learning algorithms or techniques are to be used are also important. Parameter
    tuning, of course in addition, however, the final choice is more about  experimentation
    through the ML model you will be developing.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在最佳实践中，特征工程应被视为机器学习中最重要的部分之一。关键是在实验数据集中非技术性地找到特征的更好表示。与此同时，使用哪些学习算法或技术也很重要。参数调整当然也很重要，但最终的选择更多取决于您将要开发的ML模型的实验。
- en: In practice, however, it is trivial to grasp the naive performance baseline
    by means of an **out-of-the-box** method (also referred to as functionality or
    **OOTB** in short, which is a feature of a product of interest that works straight
    away after installing or configuring) and good data pre-processing. Therefore,
    you might be doing it continually in order to know where the baseline is and whether
    this performance is of a satisfactory level or good enough for your requirements.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，通过“开箱即用”方法（也称为功能性或OOTB，是指产品安装或配置后立即可用的功能）和良好的数据预处理，轻松掌握天真的性能基线是微不足道的。因此，您可能会不断地这样做，以了解基线在哪里，以及这种性能是否达到了令人满意的水平或足够满足您的要求。
- en: Once you've trained all of your out-of-the-box methods, it's always recommended
    and is a good idea to try bagging them together. Moreover, in order to solve the
    ML problems, very often you might need to know the reality that computationally
    hard problems (shown in section 2, for example) need either domain-specific knowledge
    or lots of digging down in the data or both. Consequently, the combination of
    a widely accepted feature engineering technique and domain-specific knowledge
    would help your ML algorithm/application/system to solve prediction related problems.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您训练了所有的开箱即用方法，总是建议并且是一个好主意将它们一起尝试。此外，为了解决ML问题，您可能经常需要知道计算上困难的问题（例如第2节中所示）需要领域特定的知识或大量挖掘数据或两者兼而有之。因此，广泛接受的特征工程技术和领域特定知识的结合将有助于您的ML算法/应用/系统解决与预测相关的问题。
- en: In a nutshell, if you have the required dataset and a robust algorithm that
    can take the advantages of the dataset by learning the complex features, it's
    almost guaranteed that you will be successful. Furthermore, sometimes domain experts
    might be wrong in selecting the good features; therefore, incorporation of multiple
    domain experts (problem domain expert), more well-structured data, and ML expertise
    is always helpful.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，如果您拥有所需的数据集和一个强大的算法，可以利用数据集学习复杂的特征，几乎可以保证您会成功。此外，有时领域专家在选择好的特征时可能会出错；因此，多个领域专家（问题领域专家）、更结构化的数据和ML专业知识的整合总是有帮助的。
- en: Last but not least, sometimes it is recommended from our side to consider the
    error rate rather than only the accuracy. For example, suppose an ML system with
    99% accuracy and 50% errors is worse than the one with 90% accuracy but 25% errors,
    for example.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，有时我们建议考虑错误率而不仅仅是准确性。例如，假设一个ML系统的准确率为99%，错误率为50%，比起准确率为90%，错误率为25%的系统更糟糕。
- en: Beware of overfitting and underfitting
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意过拟合和欠拟合
- en: 'A common mistake often made by novice data scientists is subject to the overfitting
    issue that might evolve while building your ML model by hearing without generalizing.
    More technically, if you evaluate your model on the training data instead of test
    or validated data, you probably won''t be able to articulate whether your model
    is overfitting or not. The common symptoms are:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 初学者数据科学家经常犯的一个常见错误是在构建ML模型时受到过拟合问题的影响，这可能是由于听而不是泛化。更具体地说，如果您在训练数据上评估模型而不是测试或验证数据，您可能无法确定您的模型是否过拟合。常见的症状包括：
- en: Predictive accuracy of the data used for training can be over accurate (that
    is, sometimes even 100%)
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于训练的数据的预测准确性可能过高（有时甚至达到100%）
- en: And the model might show a little better compared to the random prediction for
    new data
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并且与新数据相比，模型可能会稍微好一些
- en: 'Sometimes the ML model itself becomes under-fit for a particular tuning or
    data point, which means the model has become too simplistic. Our recommendation
    (like others as well we believe) is as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 有时ML模型本身对特定调整或数据点变得欠拟合，这意味着模型变得过于简单。我们的建议（我们相信其他人也是如此）如下：
- en: Split the dataset into two sets to detect overfitting situations, the first
    one being for training and model selection, called the training set; the second
    one is the test set for evaluating the model stated in place of the ML workflow
    section
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集分为两组以检测过拟合情况，第一组用于训练和模型选择，称为训练集；第二组是用于评估模型的测试集，取代了ML工作流程部分中所述的模型。
- en: Alternatively, you also could void the overfitting by consuming simpler models
    (for example, linear classifiers in preference to Gaussian kernel SVM) or by swelling
    the regularisation parameters of your ML model (if available)
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者，您还可以通过使用更简单的模型（例如，线性分类器优先于高斯核SVM）或通过增加ML模型的正则化参数（如果可用）来避免过拟合。
- en: Tune the model with a correct data value of parameters to avoid both overfitting
    as well as underfitting
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整模型的参数值以避免过拟合和欠拟合
- en: 'Hastie et al. (Hastie Trevor, Tibshirani Robert, Friedman Jerome, *The Elements
    of Statistical Learning: Data Mining, Inference, and Prediction*, Second Edition,
    2009) on the other hand, have recommended splitting the large-scale dataset into
    three sets: Training set (50%), Validation set (25%), and Test set (25%) (roughly).
    They also suggested building the model using the training set and calculating
    the prediction errors using the validation set. The test set was recommended to
    be used to assess the generalization error of the final model.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Hastie等人（Hastie Trevor，Tibshirani Robert，Friedman Jerome，《统计学习的要素：数据挖掘、推断和预测》，第二版，2009年）建议将大规模数据集分为三组：训练集（50%）、验证集（25%）和测试集（25%）（大致）。他们还建议使用训练集构建模型，并使用验证集计算预测误差。建议使用测试集来评估最终模型的泛化误差。
- en: If the amount of labeled data available during the supervised learning is smaller,
    it is not recommended to split the datasets. In that case, use cross-validation
    or Train split techniques (this will be discussed in [Chapter 7](part0059_split_000.html#1O8H62-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 7. Tuning Machine Learning Models"), *Tuning Machine Learning Models,*
    with several examples). More specifically, divide the data set into 10 parts of
    (roughly) equal size, after that for each of these ten parts, train the classifier
    iteratively and use the 10th part to test the model.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在监督学习期间可用的标记数据量较小，则不建议拆分数据集。在这种情况下，使用交叉验证或训练拆分技术（将在[第7章](part0059_split_000.html#1O8H62-0b803698e2de424b8aa3c56ad52b005d
    "第7章。调整机器学习模型")中讨论，*调整机器学习模型*，并附有几个示例）。更具体地说，将数据集分为大致相等的10部分，然后对这10部分中的每一部分进行迭代训练分类器，并使用第10部分来测试模型。
- en: Stay tuned and combining Spark MLlib with Spark ML
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保持关注并将Spark MLlib与Spark ML结合使用
- en: The first step of the pipeline designing is to create the building blocks (as
    a directed or undirected graph consisting of nodes and edges) and make a link
    between those blocks. Nevertheless, as a data scientist, you should be focused
    on scaling and optimizing nodes (primitives) too, so that you are able to scale-up
    your application for handling large-scale datasets in the later stage to make
    your ML pipeline consistently perform. The pipeline process will also help you
    to make your model adaptive for new datasets. However, some of these primitives
    might be explicitly defined to particular domains and data types (for example,
    text, images, video, audio, and spatiotemporal).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 管道设计的第一步是创建构建模块（作为由节点和边组成的有向或无向图）并在这些模块之间建立联系。然而，作为数据科学家，您还应专注于扩展和优化节点（基元），以便在后期处理大规模数据集时能够扩展应用程序，使您的ML管道始终保持高性能。管道过程还将帮助您使您的模型适应新数据集。然而，其中一些基元可能会明确定义为特定领域和数据类型（例如文本、图像、视频、音频和时空数据）。
- en: 'And beyond these types of data, the primitives should also be working for the
    general purpose domain statistics or mathematics. The casting of your ML model
    in terms of these primitives will make your workflow more transparent, interpretable,
    accessible, and explainable. A recent example would be the ML-Matrix, which is
    a distributed matrix library that can be used on top of Spark:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些类型的数据之外，基元还应适用于通用领域的统计学或数学。将您的ML模型转换为这些基元的形式将使您的工作流程更加透明、可解释、可访问和可解释。最近的一个例子是ML-Matrix，它是一个可以在Spark之上使用的分布式矩阵库：
- en: '![Stay tuned and combining Spark MLlib with Spark ML](img/00133.jpeg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![保持关注并将Spark MLlib与Spark ML结合使用](img/00133.jpeg)'
- en: 'Figure 8: Stay tune and interoperate ML, MLlib, and GraphX.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：保持关注并使ML、MLlib和GraphX互操作。
- en: As we already stated in the previous section, as a developer you can seamlessly
    combine the implementation techniques in Spark MLlib along with the algorithms
    developed in Spark ML, Spark SQL, GraphX, and Spark Streaming as hybrid or interoperable
    ML applications on top of RDD, DataFrame, and Datasets, as shown in Figure 8\.
    For example, an IoT-based real-time application could be developed using a hybrid
    model. Therefore, the recommendation here is to stay tuned or synchronized with
    the latest technologies around you for the betterment of your ML application.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中已经提到的，作为开发人员，您可以无缝地将Spark MLlib中的实现技术与Spark ML、Spark SQL、GraphX和Spark
    Streaming中开发的算法结合起来，作为基于RDD、DataFrame和Datasets的混合或可互操作的ML应用程序，如图8所示。例如，可以使用混合模型开发基于物联网的实时应用程序。因此，建议您与您周围的最新技术保持同步，以改进您的ML应用程序。
- en: Making ML applications modular and simplifying pipeline synthesis
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使ML应用程序模块化并简化管道合成
- en: Another good and often used practice when building your ML pipeline is to make
    the ML system modular. Some supervised learning problems can be solved using very
    simple models commonly referred to as generalized linear models. However, it depends
    on the data you will be using and others simply don't.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建ML管道时的另一个常用做法是使ML系统模块化。一些监督学习问题可以使用常称为广义线性模型的非常简单的模型来解决。然而，这取决于您将要使用的数据，有些数据可能不适用于这些模型。
- en: 'Therefore, to conglomerates a series of simple linear binary classifiers, try
    to employ a lightweight modular architecture. This might be at the workflow stems
    or at the algorithms level. The advantages are obvious, since the modular architecture
    of your application handles massive amounts of data flow in a parallel and distributed
    way. Consequently, we suggest you have the three key innovative mechanisms: weighted
    threshold sampling, logistic calibration, and intelligent data partitioning as
    mentioned in the literature (for example, Yu Jin; Nick Duffield; Jeffrey Erman;
    Patrick Haffner; Subhabrata Sen; Zhi Li Zhang, *A Modular Machine Learning System
    for Flow-Level Traffic Classification in Large Networks*, ACM Transactions on
    Knowledge Discovery from Data, V-6, Issue-1, March 2012). The target is to achieve
    scalability and high-throughput while attaining a high accuracy of the predicted
    results from your ML application/system. While primitives can serve as building
    blocks, you still need some other tools that enable users to build ML pipelines.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，要将一系列简单的线性二元分类器合并成一个轻量级的模块化架构。这可能是在工作流程或算法级别。优势是显而易见的，因为应用程序的模块化架构以并行和分布式的方式处理大量数据流。因此，我们建议您采用文献中提到的三种关键创新机制：加权阈值抽样、逻辑校准和智能数据分区（例如，Yu
    Jin；Nick Duffield；Jeffrey Erman；Patrick Haffner；Subhabrata Sen；Zhi Li Zhang，《大型网络中基于流级流量分类的模块化机器学习系统》，ACM数据发现知识交易，V-6，Issue-1，2012年3月）。目标是在实现高吞吐量的同时，实现ML应用/系统预测结果的高准确性。虽然原语可以作为构建块，但您仍需要其他工具来使用户能够构建ML管道。
- en: Subsequently, workflow tools have become more common these days, and such tools
    exist for data engineers, data scientists, and even for business analysts such
    as Alteryx, RapidMiner, Alpine Data, and Dataiku. At this point, we are talking
    about and stressing the business analysts since at the very last phase your target
    customer will be a business company who will value your ML model, right? The latest
    release of Spark comes with Spark ML APIs for building machine learning pipelines
    and making a domain specific language (see [https://en.wikipedia.org/wiki/Domain-specific_language](https://en.wikipedia.org/wiki/Domain-specific_language))
    for pipelines.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，工作流程工具如今变得更加普遍，这些工具适用于数据工程师、数据科学家，甚至适用于业务分析师，如Alteryx、RapidMiner、Alpine Data和Dataiku。在这一点上，我们谈论并强调业务分析师，因为在最后阶段，您的目标客户将是一家重视您的ML模型的商业公司，对吧？Spark的最新版本配备了用于构建机器学习管道的Spark
    ML API，并制定了领域特定语言（参见[https://en.wikipedia.org/wiki/Domain-specific_language](https://en.wikipedia.org/wiki/Domain-specific_language)）用于管道。
- en: Thinking of an innovative ML system
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 思考一个创新的ML系统
- en: However, in order to develop the algorithms to learn the ML models continuously
    with the help of available data, the viewpoint behind the machine learning is
    to automate the creation of analytical models. Unremittingly evolving models produce
    increasingly positive results and reduce the need for human interaction. This
    enables the ML models to automatically produce reliable and repeatable predictions.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了开发算法以利用可用数据持续学习ML模型，机器学习背后的观点是自动化分析模型的创建。不断发展的模型产生越来越积极的结果，并减少了对人类干预的需求。这使得ML模型能够自动产生可靠且可重复的预测。
- en: More technically, suppose you are planning to develop a recommender system using
    ML algorithms. So, what is the target of developing that recommender system? And
    what are some innovative ideas for product development in machine learning? These
    two are typical questions that should be considered before you start developing
    your ML application or system. Consistent innovation might be challenging, especially
    when stirring advancing with new ideas, it can also be tough to comprehend where
    the greatest benefit lies. Machine learning can provision innovation from end
    to end of a variety of paths, such as determining weaknesses with current products,
    predictive analysis, or identifying previously concealed patterns.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，假设您计划使用ML算法开发推荐系统。那么，开发该推荐系统的目标是什么？在机器学习产品开发方面有哪些创新的想法？这两个问题在您开始开发ML应用程序或系统之前应该考虑。持续的创新可能具有挑战性，特别是在推动新想法的同时，理解最大利益所在也可能很困难。机器学习可以通过各种途径提供创新，例如确定当前产品的弱点、预测分析或识别以前隐藏的模式。
- en: 'As a result, you will have to think of large-scale computing to train your
    ML model offline, and later on your recommender system has to be able to work
    as a conventional search engine analysis for online recommendations. Thus, your
    ML application will be valued by a business company if your system:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您将不得不考虑大规模计算来离线训练您的ML模型，随后您的推荐系统必须能够像传统的搜索引擎分析一样进行在线推荐。因此，如果您的系统：
- en: Can forecast buying items using your machine learning application
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用您的机器学习应用程序预测购买商品
- en: Can do product analysis
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以进行产品分析
- en: Can work as an emerging trend in production
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以作为生产中的新趋势
- en: Thinking and becoming smarter about Big Data complexities
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 思考并变得更加聪明，以应对大数据的复杂性
- en: As shown in Figure 9, new business models are the unavoidable extension of the
    available data utilisation, so consideration of big data and its business values
    can make the business analyst's job, life and thinking smarter, which results
    in your targeted company delivering value to customers. In addition to this, you
    will also have to investigate (analyze to be more exact) rival or better companies.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 如图9所示，新的商业模式是可利用数据的不可避免的延伸，因此考虑大数据及其商业价值可以使业务分析师的工作、生活和思维更加智能，从而使您的目标公司为客户提供价值。除此之外，您还需要调查（更准确地说是分析）竞争对手或更好的公司。
- en: Now the question is, how do you collect and use enterprise data? Big data is
    not only about the size (volume), it is also related to its velocity, veracity,
    variety, and value. For these types of complexities, for example, velocity can
    be addressed using Spark Streaming since streaming-based data is also big data
    that needs a real-time analytical approach. Other parameters such as volume and
    variety can be handled using Spark Core and Spark MLlib/ML towards big data processing.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的问题是，你如何收集和使用企业数据？大数据不仅仅是关于大小（容量），它还与速度、真实性、多样性和价值有关。对于这些类型的复杂性，例如，速度可以使用Spark
    Streaming来解决，因为基于流的数据也是需要实时分析的大数据。其他参数，如容量和多样性，可以使用Spark Core和Spark MLlib/ML来处理大数据处理。
- en: 'Well, you will have to manage the data by hook or by crook. If you are able
    to manage the data, the insights from the data can really shake up the way businesses
    operate with the useful features of big data:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，你必须想方设法管理数据。如果你能够管理数据，那么从数据中获得的见解可以真正改变企业运营的方式，利用大数据的有用特征：
- en: '![Thinking and becoming smarter about Big Data complexities](img/00013.jpeg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![思考和更加智能地处理大数据复杂性](img/00013.jpeg)'
- en: 'Figure 9: Machine learning in Big Data best practice.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：大数据最佳实践中的机器学习。
- en: 'At this point, data alone is not enough (see Pedro Domingos, *A Few Useful
    Things to Know about Machine Learning,* [https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)),
    but extracting meaningful features from the data and putting semantics of data
    into the model is more important. This is like what most of the tech giants such
    as LinkedIn are developing through large-scale machine learning frameworks from
    feature targeting for their community, which is more or less a supervised learning
    technique. The workflow is as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，仅有数据是不够的（参见Pedro Domingos，《关于机器学习的一些有用知识》，[https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)），但是从数据中提取有意义的特征并将数据的语义放入模型更为重要。这就像LinkedIn等大多数科技巨头正在通过大规模机器学习框架开发的社区特征定位一样，这多多少少是一种监督学习技术。工作流程如下：
- en: Fetch the data, extract the feature, and set the target
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取数据，提取特征，并设置目标
- en: Feature and target join
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征和目标连接
- en: Create a snapshot from the concatenated data
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从连接数据创建一个快照
- en: 'Partition the snapshot into two parts: training set and test set'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将快照分成两部分：训练集和测试集
- en: From the training set, prepare the sample data by sampling techniques
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从训练集中，通过采样技术准备样本数据
- en: Train the model using the sampled data
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用采样数据训练模型
- en: Scoring
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评分
- en: Evaluate the model from the previously developed persistent model, as well as
    the test data prepared in step 4
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从先前开发的持久模型以及步骤4中准备的测试数据中评估模型。
- en: If the best model is found
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果找到了最佳模型
- en: Deploy the model for the target audience
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为目标受众部署模型
- en: So what's next? Your model also should be adaptable to large-scale dynamic data
    such as real-time streaming IoT data PLUS real-time feedback is also important
    so that your ML system can learn from the mistakes. The next sub-section discusses
    that.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 那么接下来呢？你的模型也应该适应大规模动态数据，比如实时流式物联网数据，而且实时反馈也很重要，这样你的ML系统才能从错误中学习。下一小节将讨论这一点。
- en: Applying machine learning to dynamic data
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将机器学习应用于动态数据
- en: The reasons are obvious, since machine learning brings concrete and dynamic
    aspects to IoT projects. Recently, machine learning has experienced a pep talk
    in popularity amongst industrial companies and they profit out of the box. As
    a result, all but every IT vendor are precipitously announcing IoT platforms and
    consulting services. But achieving financial benefits through IoT data is not
    an easy job. Moreover, many businesses have failed to clearly determine what areas
    will change with the implementation of an IoT strategy.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 原因是显而易见的，因为机器学习为物联网项目带来了具体和动态的方面。最近，机器学习在工业公司中的受欢迎程度有所提高，他们从中获利。因此，几乎每个IT供应商都在急速宣布物联网平台和咨询服务。但是通过物联网数据实现财务收益并不是一件容易的工作。此外，许多企业未能清楚地确定实施物联网战略将改变哪些领域。
- en: Considering these positive and negative issues together, your ML model should
    adapt to large dynamic data since the large-scale data means billions of records,
    large feature spaces, and low positive rates from the sparsity issue. Nevertheless,
    data is dynamic so consequently, the ML models have to be adaptive enough; otherwise
    you will have to face a bad experience or be lost in the black hole.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 综合考虑这些积极和消极的问题，你的ML模型应该适应大规模动态数据，因为大规模数据意味着数十亿条记录、大特征空间和来自稀疏问题的低正率。然而，数据是动态的，因此ML模型必须足够适应；否则你将面临糟糕的体验或者迷失在黑洞中。
- en: Best practice after developing an ML application
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发ML应用程序后的最佳实践
- en: 'The typical steps that are best practice after an ML model/system has been
    developed are: visualization for understanding the predictive values, model validation,
    error and accuracy analysis, model tuning, model adapting, and scaling up for
    handling large-scale datasets with ease.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型/系统开发后的最佳实践步骤包括：可视化以理解预测值，模型验证，错误和准确性分析，模型调整，模型适应和扩展以便轻松处理大规模数据集。
- en: How to enable real-time ML visualization
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何实现实时ML可视化
- en: 'Visualization provides an interactive interface to stay tune the ML model itself.
    Therefore, without visualizing the predictive results, it merely becomes difficult
    to further improve the performance of an ML application. The best practice could
    be something like this:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化提供了一个交互界面，以保持ML模型本身的关注。因此，如果不可视化预测结果，进一步改善ML应用程序的性能将变得困难。最佳实践可能是这样的：
- en: Incorporate some third-party tools along with GraphX for your visualization
    for large-scale graph related data (more to be discussed in *[Chapter 9](part0073_split_000.html#25JP22-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 9.  Advanced Machine Learning with Streaming and Graph Data")*, *Advanced
    Machine Learning with Streaming and Graph Data*)
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了可视化大规模图形相关数据，可以将一些第三方工具与GraphX结合起来（更多内容将在*[第9章](part0073_split_000.html#25JP22-0b803698e2de424b8aa3c56ad52b005d
    "第9章。流式和图形数据的高级机器学习")*中讨论，*流式和图形数据的高级机器学习*)
- en: 'For non-graph data, a call-back interface for the Spark ML algorithm to send
    and receive messages by incorporating other tools like Apache Kafka:'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于非图形数据，Spark ML算法可以通过集成其他工具如Apache Kafka来发送和接收消息的回调接口：
- en: Algorithms decide when and what message to send
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法决定何时发送什么消息
- en: Algorithms don't care how the message is delivered
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法不关心消息是如何传递的
- en: 'A task channel to handle the message delivery service from the Spark Driver
    program to Spark Client or Spark cluster nodes. The task channel would be communicating
    using Spark Core at a lower level of abstraction:'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个任务通道用于处理从Spark驱动程序到Spark客户端或Spark集群节点的消息传递服务。任务通道将使用Spark核心在更低的抽象级别进行通信：
- en: It does not care about the content of the message or recipient of the message
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不关心消息的内容或消息的接收者
- en: 'The message is delivered from Spark Client to the browser or visualization
    client:'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息从Spark客户端传递到浏览器或可视化客户端：
- en: We recommend using HTML5 **Server-Sent Events** (**SSE**) and HTTP Chunked Response
    (PUSH) together. Incorporation of Spark with this type of technology will be discussed
    in [Chapter 10](part0079_split_000.html#2BASE2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 10.  Configuring and Working with External Libraries"), *Configuring
    and Working with External Libraries*
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们建议同时使用HTML5的**服务器发送事件**（SSE）和HTTP分块响应（PUSH）。将Spark与这种类型的技术结合起来将在[第10章](part0079_split_000.html#2BASE2-0b803698e2de424b8aa3c56ad52b005d
    "第10章。配置和使用外部库")中讨论，*配置和使用外部库*
- en: Pull is possible; however, it requires a message queue
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拉取是可能的；然而，它需要一个消息队列
- en: Visualization using JavaScript frameworks such as `Plot.ly` (please refer to
    [https://plot.ly/](https://plot.ly/)) and `D3.js` (please refer to [https://d3js.org/](https://d3js.org/))
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用JavaScript框架进行可视化，比如`Plot.ly`（请参考[https://plot.ly/](https://plot.ly/)）和`D3.js`（请参考[https://d3js.org/](https://d3js.org/)）
- en: Do some error analysis
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进行一些错误分析
- en: As algorithms become more prevalent, we need better tools for building complex
    hitherto, robust, and stable machine learning systems. A popular distributed framework
    like Apache Spark takes these ideas to extremely large datasets for the wider
    audience. Therefore, it would be better if we could bind approximation errors
    and convergence rates for the layered pipelines.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 随着算法变得更加普遍，我们需要更好的工具来构建复杂的、稳健的和稳定的机器学习系统。像Apache Spark这样的流行分布式框架将这些想法应用到了更广泛的大型数据集中。因此，如果我们能够绑定分层管道的近似误差和收敛速度，那将更好。
- en: Assuming we can compute error bars for nodes, the next step would be to have
    a mechanism for extracting error bars for these pipelines. However, in practice,
    when the ML model is deployed for the production, we might need tools to confirm
    that the pipeline will work and will not do make malfunction or stop halfway through and
    that it can provide some expected measure of the errors.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们可以计算节点的误差范围，下一步将是为这些管道提取误差范围的机制。然而，在实践中，当ML模型部署到生产环境时，我们可能需要工具来确认管道将正常工作，不会出现故障或中途停止，并且可以提供一些预期的错误度量。
- en: Keeping your ML application tuned
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保持你的ML应用程序调优
- en: Devising one or two algorithms that perform solidly well on a simple problem
    can be considered as a good kick-off. However, sometimes you may be thirsty to
    get the best accuracy, by even sacrificing your valuable time and available computational
    resources. This would be a smarter way, and it will help you not only to squeeze
    out extra performance, but also to improve the results in terms of accuracy that
    you were receiving out of the machine learning algorithms you designed previously.
    In order to do that, when you tune the model and related algorithm, essentially,
    you must have a high confidence in the results.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 设计一个或两个在简单问题上表现良好的算法可以被认为是一个良好的开端。然而，有时你可能渴望获得最佳的准确性，甚至会牺牲宝贵的时间和可用的计算资源。这将是一个更明智的方式，它不仅可以帮助你挤出额外的性能，还可以改善你之前设计的机器学习算法的准确性结果。为了做到这一点，当你调整模型和相关算法时，你必须对结果有很高的信心。
- en: Obviously, those results will be available after you specify the testing and
    validation. This means you should only be using those techniques that reduce the
    variance of the performance measure so that you can assess the algorithms that
    are running more smoothly.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这些结果将在你指定测试和验证之后可用。这意味着你应该只使用那些减少性能测量方差的技术，以便评估那些运行更顺利的算法。
- en: 'In parallel, like most data practitioners, we also suggest you to use the cross-validation
    technique (also often called rotation estimation) with a reasonably high number
    of folds (that is, K-fold cross-validation, where a single subsample is used as
    the validation dataset for testing the model itself , and the remaining K-1 subsamples
    are used to train the data). Although the exact number of folds, or K, depends
    on your dataset, however, 10-fold cross-validation is commonly used, but most
    often the value of K remains unfixed. We will mention three strategies here that
    you will need to tune your machine learning model:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数数据从业者一样，我们还建议您使用交叉验证技术（也经常称为旋转估计），并且使用相当高数量的折叠（即K折交叉验证，其中一个子样本用作验证数据集，用于测试模型本身，其余的K-1个子样本用于训练数据）。尽管折叠的确切数量，或K，取决于你的数据集，但是10折交叉验证通常被使用，但是K的值通常是不固定的。我们将在这里提到三种策略，你需要调整你的机器学习模型：
- en: '**Algorithm tuning**: Makes your machine learning algorithm parameterized.
    After that, adjust the value of those parameters (if they have multiple parameters)
    to influence the outcome of the overall learning process.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**算法调优**：使您的机器学习算法参数化。然后，调整这些参数的值（如果它们有多个参数）以影响整个学习过程的结果。'
- en: '**Ensembles**: Sometimes it is good to be naïve! Therefore, in order to get
    improved results, keep trying to combine the outcomes from multiple machine learning
    methods or algorithms.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成**：有时候天真是好的！因此，为了获得改进的结果，不断尝试将多个机器学习方法或算法的结果结合起来。'
- en: '**Extreme feature engineering**: If your data has complex and multi-dimensional
    structures embedded in it, ML algorithms know how to find and exploit it to make
    decisions.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**极端特征工程**：如果您的数据中嵌入了复杂和多维结构，ML算法知道如何找到并利用它来做出决策。'
- en: Keeping your ML application adaptive and scale-up
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使您的ML应用程序适应和扩展
- en: 'As shown in Figure 10, the adaptive learning conglomerates the previous generations
    of rule-based, simple machine learning, and deep learning approaches to machine
    intelligence according to Rob Munro:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如图10所示，自适应学习根据Rob Munro的说法，将基于规则的、简单的机器学习和深度学习方法融合到机器智能中。
- en: '![Keeping your ML application adaptive and scale-up](img/00026.jpeg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![使您的ML应用程序适应和扩展](img/00026.jpeg)'
- en: 'Figure 10: Four generation of machine intelligence (Figure courtesy of Rob
    Munro).'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：机器智能的四代（图由Rob Munro提供）。
- en: 'The fourth generation of machine learning: adaptive learning, (`http://idibon.com/the-fourth-generation-of-machine-learning-adaptive-learning/#comment-175958`).'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的第四代：自适应学习，(`http://idibon.com/the-fourth-generation-of-machine-learning-adaptive-learning/#comment-175958`)。
- en: 'Research also shows that adaptive learning is 95% accurate in predicting people''s
    intention to purchase a car, for example (please refer to Rob Munro, *The fourth
    generation of machine learning: Adaptive learning*, `http://idibon.com/the-fourth-generation-of-machine-learning-adaptive-learning/#comment-175958`).
    Moreover, if your ML application is adaptive with the new environment and new
    data, it is expected that if enough infrastructure is provided, your ML system
    can be scaled-up for the increasing data loads.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 研究还表明，自适应学习在预测人们购买汽车的意图方面准确率达到95%（请参阅Rob Munro，《机器学习的第四代：自适应学习》，`http://idibon.com/the-fourth-generation-of-machine-learning-adaptive-learning/#comment-175958`）。此外，如果您的ML应用程序能够适应新环境和新数据，那么只要提供足够的基础设施，预计您的ML系统可以扩展以处理不断增加的数据负载。
- en: Choosing the right algorithm for your application
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为您的应用程序选择正确的算法
- en: '*What machine learning algorithm should I use?* is a very frequently asked
    question for the Naive machine learning practitioners, but the answer is always
    i*t depends on*. More elaborately:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '*我应该使用什么机器学习算法？*对于天真的机器学习从业者来说，这是一个非常常见的问题，但答案总是*取决于*。更详细地说：'
- en: It depends on the volume, quality, complexity, and the nature of the data that
    has to be tested/used
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这取决于要测试/使用的数据的数量、质量、复杂性和性质
- en: It depends on external environments and parameters such as your computing system's
    configuration or underlying infrastructures
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这取决于外部环境和参数，例如您的计算系统配置或基础设施
- en: It depends on what you want to do with the answer
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这取决于您想要用答案做什么
- en: It depends on how the mathematical and statistical formulation of the algorithm
    was translated into machine instructions for the computer
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这取决于算法的数学和统计公式如何被转化为计算机的机器指令
- en: And it depends on how much time you have
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这取决于你有多少时间
- en: '*Figure 11* provides a complete work-flow for choosing the right algorithm
    for your ML problem. However, note that some tricks might not work-flow depending
    upon data and problem types:![Choosing the right algorithm for your application](img/00039.jpeg)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图11*提供了选择解决ML问题的正确算法的完整工作流程。但是，请注意，某些技巧可能会根据数据和问题类型而不起作用：![为您的应用程序选择正确的算法](img/00039.jpeg)'
- en: 'Figure 11: A work-flow for choosing the right algorithm'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：选择正确算法的工作流程
- en: 'The reality is, even the most experienced data scientists or data engineers
    can''t give a straight recommendation about which ML algorithm performs best before
    trying them all together. Most of the statements of agreement/disagreement begins
    with *It depends on...hmm...*Habitually, you might be contemplative if there are
    cheat sheets of machine learning algorithms and if so, how to use that cheat sheet.
    Several data scientists we talked to said that the only sure way to find the very
    best algorithm is to try all of them; therefore, there is no shortcut dude! Let''s
    make it clear, suppose you do have a set of data and you want to do some clustering.
    Thus, technically, this could be classification or regression if your data is
    labeled/unlabeled or values or training set data. Now, the first concern that
    evolves in your mind is:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，即使是最有经验的数据科学家或数据工程师在尝试所有算法之前也无法给出哪种ML算法在性能上表现最佳的明确建议。大多数一致/不一致的陈述都以*取决于...嗯...*开始。习惯上，您可能会思考是否有机器学习算法的备忘单，如果有的话，如何使用该备忘单。我们与几位数据科学家交谈时，他们表示找到最佳算法的唯一方法是尝试所有算法；因此，没有捷径！让我们明确一下，假设您有一组数据，并且想要进行一些聚类。因此，从技术上讲，这可能是分类或回归，如果您的数据是标记/未标记的或值或训练集数据。现在，您脑海中首先出现的问题是：
- en: Which factors should I consider before choosing an appropriate algorithm? Or
    should I just choose an algorithm randomly?
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在选择适当的算法之前，我应该考虑哪些因素？还是我应该随机选择一个算法？
- en: How do I choose any data pre-processing algorithm or tools that can be applied
    to my data?
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我如何选择可以应用于我的数据的任何数据预处理算法或工具？
- en: What sort of feature engineering techniques should I be using to extract the
    useful features?
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我应该使用什么样的特征工程技术来提取有用的特征？
- en: What factors can improve the performance of my ML model?
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些因素可以提高我的ML模型的性能？
- en: How can I adopt my ML application for new data types?
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我如何为新数据类型采用我的ML应用程序？
- en: Can I scale-up my ML application for large-scale datasets? And so on.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我可以将我的ML应用程序扩展到大规模数据集吗？等等。
- en: You will always expect the best answer that is much more justified and explains
    everything that someone should consider. In this section, we will try to answer
    these questions with our little machine learning knowledge.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 您总是期望得到更合理的最佳答案，并解释应考虑的一切。在本节中，我们将尝试用我们的一点机器学习知识来回答这些问题。
- en: Considerations when choosing an algorithm
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在选择算法时的考虑
- en: 'The recommendation or suggestions we are providing here are for the novice
    data scientist with learner machine learning to expert data scientists who are
    trying to choose an optimal algorithm to start with the Spark ML APIs. That means,
    it makes some overviews and oversimplifications, but it will point you in a safe
    direction, believe us! Suppose you are planning to develop an ML system to answer
    the following question based on the rule:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里提供的建议或建议是给初学者数据科学家和尝试选择Spark ML API的最佳算法的专家数据科学家。这意味着它做了一些概述和过度简化，但它会指引您朝着安全的方向，相信我们！假设您计划开发一个ML系统来回答以下问题基于规则：
- en: '`IF` feature X has property Z `THEN` do Y'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IF`特征X具有属性Z`THEN`执行Y'
- en: 'Affirmatively, there should be such rules:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 肯定地，应该有这样的规则：
- en: IF X `THEN` it is sensible to try Y using property Z and avoid W
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果X`THEN`，尝试使用属性Z并避免W是明智的
- en: 'However, what is sensible and what is not depends on:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，什么是明智的，什么不是取决于：
- en: Your application and the expected complexity of the problem.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的应用程序和问题的预期复杂性。
- en: Size of the data set (that is, how many rows/columns, how many independent cases).
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的大小（即有多少行/列，有多少独立案例）。
- en: Is your dataset labeled or unlabeled?
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的数据集是否有标签或无标签？
- en: Type of data and the kind of measurement, since different nature of data suggests
    a different order or structure, right?
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据类型和测量类型，因为不同类型的数据暗示着不同的顺序或结构，对吧？
- en: And obviously in practice your experience in applying different methods efficiently
    and intelligently.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显然，在实践中，您在应用不同方法时的经验是高效和智能的。
- en: 'Moreover, if you want to have a general answer to a general problem, we recommend
    the Elements of Statistical Learning (Hastie Trevor, Tibshirani Robert, Friedman
    Jerome, *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*,
    Second Edition, 2009) for a fresh start. Nevertheless, we also recommend going
    with the following algorithmic properties that:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果您想对一般问题得到一般答案，我们建议初学者从《统计学习的要素》（Hastie Trevor，Tibshirani Robert，Friedman
    Jerome，*统计学习的要素：数据挖掘、推断和预测*，第二版，2009）开始。然而，我们还建议遵循以下算法属性：
- en: Show excellent accuracy
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展示出色的准确性
- en: Have fast training times
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有快速的训练时间
- en: And the use of linearity
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及线性的使用
- en: Accuracy
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准确性
- en: Getting the most accurate results from your ML application isn't always indispensable.
    Depending on what you want to use it for, sometimes an approximation is adequate
    enough. If the situation is something like this, you may be able to reduce the
    processing time drastically by incorporating the better-estimated methods. When
    you are familiar with the workflow with the Spark machine learning APIs, you will
    enjoy the advantage of having more approximation methods, because those approximation
    methods will tend to avoid the overfitting problem out of your ML model automatically.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 从您的ML应用程序中获得最准确的结果并非总是不可或缺的。根据您想要将其用于的情况，有时近似也足够。如果情况是这样，您可以通过合并更好估计的方法来大幅减少处理时间。当您熟悉Spark机器学习API的工作流程时，您将享受到拥有更多近似方法的优势，因为这些近似方法将自动倾向于避免您的ML模型中的过度拟合问题。
- en: Training time
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练时间
- en: The execution time requires finishing the data preprocessing or building the
    model and varies a great deal across different algorithms, the inherited complexities,
    and of course the robustness. The training time is often closely related to the
    accuracy. In addition, often you will discover that some of the algorithms you
    will be using are elusive to the number of data points compared to others. However,
    when your time is sufficient and especially when the dataset is larger, for doing
    all the formalities, it can get-up-and-go the choice of algorithm. Therefore,
    if you are concerned particularly with the time, try to sacrifice the accuracy
    or performance and use a simple algorithm that fulfils your minimum requirements.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 执行时间需要完成数据预处理或构建模型，并且在不同算法、继承复杂性和鲁棒性之间变化很大。训练时间通常与准确性密切相关。此外，您经常会发现，与其他算法相比，您将使用的一些算法对数据点的数量是难以捉摸的。然而，当您的时间足够充裕，特别是当数据集较大时，为了完成所有的程序，选择算法可能会变得轻松。因此，如果您特别关注时间，尝试牺牲准确性或性能，并使用满足您最低要求的简单算法。
- en: Linearity
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性
- en: There are many machine learning algorithms developed recently that make use
    of linearity (also available in the Spark MLlib and Spark ML). For example, the
    linear classification algorithms allow classes to be separated by plotting a differentiating
    straight line or otherwise by the higher-dimensional equivalents of the datasets.
    A linear regression algorithm, on the other hand, assumes that data trends follow
    a simple straight line. This assumption is not naive for some machine learning
    problems; however, there might be some other cases where the accuracy will be
    down. Despite their hazards, linear algorithms are very popular for the data engineers
    or data scientists as the first line of the outbreak. Moreover, these algorithms
    also tend to be algorithmically simple and fast to train your models during the
    whole process.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 最近开发了许多利用线性的机器学习算法（也可在Spark MLlib和Spark ML中使用）。例如，线性分类算法允许通过绘制区分直线或数据集的高维等价物来分离类别。另一方面，线性回归算法假设数据趋势遵循简单的直线。对于一些机器学习问题，这种假设并不天真；然而，在其他一些情况下，准确性可能会下降。尽管存在危险，线性算法对于数据工程师或数据科学家来说是首选。此外，这些算法在整个训练过程中也倾向于算法简单且训练速度快。
- en: Talking to your data when choosing an algorithm
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在选择算法时与您的数据交谈
- en: 'You will find many machine learning datasets available for free here at [http://machinelearningmastery.com/tour-of-real-world-machine-learning-problems/](http://machinelearningmastery.com/tour-of-real-world-machine-learning-problems/)
    or at the UC Irvine Machine Learning Repository (at [http://archive.ics.uci.edu/ml/](http://archive.ics.uci.edu/ml/)).
    The following data properties should also be placed first:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[http://machinelearningmastery.com/tour-of-real-world-machine-learning-problems/](http://machinelearningmastery.com/tour-of-real-world-machine-learning-problems/)或UC
    Irvine机器学习库（[http://archive.ics.uci.edu/ml/](http://archive.ics.uci.edu/ml/)）免费找到许多机器学习数据集。还应首先考虑以下数据属性：
- en: Number of parameters
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数数量
- en: Number of features
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征数量
- en: Size of the training dataset
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据集的大小
- en: Number of parameters
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参数数量
- en: Parameters or data properties are the handholds for a data scientist like you
    that gets to turn when setting up an algorithm. They are numbers that affect the
    algorithm's performance, such as error tolerance or the number of iterations,
    or options between variants of how the algorithm acts. The training time and accuracy
    of the algorithm can sometimes be quite sensitive to getting the right settings.
    Typically, algorithms with a large number of parameters require trial and error
    to find an optimal combination.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 参数或数据属性是像你这样的数据科学家在设置算法时可以调整的手段。它们是影响算法性能的数字，例如误差容限或迭代次数，或者是算法行为的变体之间的选项。算法的训练时间和准确性有时对于找到合适的设置非常敏感。通常，具有大量参数的算法需要通过试错来找到最佳组合。
- en: Despite the fact that this is a great way to span the parameter space, the model
    building or training time increases exponentially with the increased number of
    parameters. This is a dilemma as well as a time-performance trade-off. The positive
    sides are having many parameters characteristically indicates greater flexibility
    of the ML algorithms. And secondly, your ML application achieves much better accuracy.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是跨越参数空间的好方法，但随着参数数量的增加，模型构建或训练时间呈指数增长。这既是一个困境，也是一个时间性能的权衡。积极的一面是，拥有许多参数通常表示机器学习算法的更大灵活性。其次，你的机器学习应用可以获得更好的准确性。
- en: How large is your training set?
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的训练集有多大？
- en: If your training set is smaller, high bias with low variance classifiers such
    as Naive Bayes have an advantage over low bias with high variance classifiers
    such as kNN. Therefore, the latter will over fit. But low bias with high variance
    classifiers, on the other hand, start to win out as your training set grows linearly
    or exponentially since they have lower asymptotic errors. This is because high
    bias classifiers aren't powerful enough to provide accurate models. You can also
    think of this as a trade-off between generative models versus discriminative model
    distinction.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的训练集较小，偏差较高且方差较低的分类器（如朴素贝叶斯）比偏差较低且方差较高的分类器（如kNN）具有优势。因此，后者会过拟合。但是，偏差较低且方差较高的分类器在你的训练集线性或指数增长时开始占优势，因为它们具有更低的渐近误差。这是因为高偏差的分类器不足以提供准确的模型。你也可以将其视为生成模型与判别模型之间的权衡。
- en: Number of features
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征数量
- en: For certain types of experimental datasets, the number of extracted features
    can be very large compared to the number of data points itself. This is often
    the case with genomics, biomedical, or textual data. A large number of features
    can swamp some learning algorithms, making training time ridiculously high. Support
    vector machines are particularly well suited in this case for its high accuracy,
    nice theoretical guarantees regarding overfitting, and an appropriate kernel.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些类型的实验数据集，提取的特征数量可能与数据点数量本身相比非常大。这在基因组学、生物医学或文本数据中经常发生。大量特征可能会淹没一些学习算法，使训练时间变得非常长。支持向量机在这种情况下特别适用，因为它具有高准确性、关于过拟合的良好理论保证以及适当的核函数。
- en: Special notes on widely used ML algorithms
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 广泛使用的机器学习算法的特殊说明
- en: In this section, we will provide some special notes for the most commonly used
    machine learning algorithm or techniques. The techniques we will emphasis are
    logistic regression, linear regression, recommender system, SVM, decision tree,
    random forest, Bayesian method and decision forests, decision jungles, and variants. Table
    3 shows the pros and cons of some widely used algorithms including where and when
    to chose these algorithms.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将为最常用的机器学习算法或技术提供一些特殊说明。我们将重点介绍的技术包括逻辑回归、线性回归、推荐系统、支持向量机、决策树、随机森林、贝叶斯方法和决策森林、决策丛林以及变种。表3显示了一些广泛使用的算法的优缺点，包括何时选择这些算法。
- en: '| **Algorithm** | **Pros** | **Cons** | **Better at** |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| **算法** | **优点** | **缺点** | **擅长** |'
- en: '| **Linear regression (LR)** | Very fast and often runs in a constant timeEasy
    to understand the modellingLess prone to overfitting and underfitting Intrinsically
    simpleVery fast so less model building timeLess prone to overfitting and underfittingHas
    low variance | Often unable for complex data modellingOften unable to conceptualize
    the nonlinear relationships without transforming the input DatasetNot suitable
    for complex modellingWorks better with only single decision boundary Requires
    large sample size to achieve stable resultsHigh bias | Numerical dataset with
    large collection of featuresWidely used in biological, behavioral and social sciences
    to predict possible relationships among variablesWorks well for numerical as well
    as categorical variablesUsed in various fields, including the medical and social
    sciences |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| **线性回归（LR）** | 非常快，通常在恒定时间内运行易于理解建模不太容易过拟合和欠拟合本质上简单速度非常快，因此建模时间较短不太容易过拟合和欠拟合方差较低
    | 通常无法进行复杂的数据建模无法概念化非线性关系，需要转换输入数据集不适合复杂建模仅适用于单一决策边界需要大样本量才能获得稳定的结果偏差较高 | 具有大量特征的数值数据集广泛用于生物学、行为学和社会科学，以预测变量之间可能的关系对数值和分类变量都有效用于医学和社会科学等各个领域
    |'
- en: '| **Decision trees (DT)** |  Less model building and prediction timeRobust
    against the noise and missing valuesHigh accuracy | Interpretation is hard with
    large and complex treesDuplication may occur within the same sub-treePossible
    issues with diagonal decision boundaries |  Targeting high accurate classificationMedical
    diagnosis and prognosisCredit risk analytics |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 决策树（DT） | 模型构建和预测时间较短，对噪声和缺失值具有鲁棒性，准确性高 | 大型和复杂树的解释困难，同一子树内可能出现重复，对角决策边界可能存在问题
    | 针对高准确的分类、医学诊断和预后、信用风险分析 |'
- en: '| **Neural networks (NN)** |  Extremely powerful and robustCapable of modelling
    very complex relationshipsCan be working without knowing the underlying data |
    Highly overfitting and underfitting proneHigh training and prediction timeComputationally
    expensive requiring significant computing powerModel is not readable or reusable
    |  Image processingVideo processingHuman-intelligenceRoboticsDeep learning |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 神经网络（NN） | 非常强大和稳健，能够建模非常复杂的关系，可以在不知道基础数据的情况下工作 | 容易过拟合和欠拟合，训练和预测时间长，计算成本高，模型不可读或可重复使用
    | 图像处理、视频处理、人工智能、机器人、深度学习 |'
- en: '| **Random forest (RF)** | Good for bagged treesLow varianceHigh accuracyCan
    handle the overfitting problem | Not as easy to visually and interpretHigh training
    and prediction time | When dealing with multiple features which may be correlatedBiomedical
    diagnosis and prognosisCan be applied both for classification and regression |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林（RF） | 适用于装袋树，方差低，准确性高，可以处理过拟合问题 | 不易直观解释，训练和预测时间长 | 处理可能相关的多个特征、生物医学诊断和预后、可用于分类和回归
    |'
- en: '| **Support vector machines (SVM)** | High accuracy | Susceptible to overfitting
    and underfittingNo numerical stabilityComputationally expensive requiring large
    computing power | Image classificationHandwriting recognition |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 支持向量机（SVM） | 准确性高 | 容易过拟合和欠拟合，数值稳定性差，计算成本高，需要大量计算资源 | 图像分类、手写识别 |'
- en: '| **K-nearest neighbors (K-NN)** | Simple and powerfulLazy training involvedCan
    be applied for both multiclass classification and regression | High training and
    prediction timeNeed to have accurate distance functionLow performance with high
    dimensional dataset | Low-dimensional datasetsAnomaly detection like outlier detectionFault
    detection in semiconductorGene expressionProtein-protein interaction |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| K最近邻（K-NN） | 简单而强大，需要懒惰训练，可用于多类分类和回归 | 训练和预测时间长，需要准确的距离函数，高维数据集性能低 | 低维数据集、异常检测、半导体故障检测、基因表达、蛋白质相互作用
    |'
- en: '| **K-means** | Linear execution timePerform better than hierarchical clusteringExcellent
    with hyper-spherical  clusters | Repeatable and lack consistencyRequires prior
    knowledge of K | Is not a good choice if the natural clusters occurring in the
    dataset are non-sphericalGood for large dataset |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: K-means | 线性执行时间表现优于分层聚类，对超球状聚类效果更好 | 可重复但缺乏一致性，需要先验知识 | 如果数据集中出现的自然聚类是非球状的，则不是一个好选择，适用于大型数据集
    |
- en: '| **Latent Dirichilet Allocation (LDA)** | Can be applied for large-scale text
    datasetsCan overcome the overfitting problem of pLSACan be applied for both document
    classification and clustering through topic modelling | Cannot be applied with
    high dimensional and complex texts databasesRequires the specification of the
    number of topicsCannot find the granularity at optimum levelHierarchical Dirichlet
    Process (HDP) is the better choice | Document classification and clustering through
    topic modelling from large-scale text datasetCan be applied in NLP and other text
    analytics |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 潜在狄利克雷分配（LDA） | 可应用于大规模文本数据集，可以克服pLSA的过拟合问题，可用于文档分类和通过主题建模进行聚类 | 不能应用于高维和复杂的文本数据库，需要指定主题数量，无法找到最佳级别，层次狄利克雷过程（HDP）是更好的选择
    | 从大规模文本数据集中进行文档分类和通过主题建模进行聚类，可应用于自然语言处理和其他文本分析 |'
- en: '| **Naive Bayes (NB)** | Computationally fastSimple to implementWorks well
    with high dimensionsCan handle missing valuesIs adaptable since the model can
    be modified with new training data without rebuilding the model | Relies on independence
    assumption so performs badly if the assumption does not metRelatively low accuracy
    | When data has lots of missing valuesDependencies of features from each other
    are similar between featuresSpam filtering and classificationClassifying a news
    article about technology, politics, or sportsText mining |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 朴素贝叶斯（NB） | 计算速度快，实现简单，适用于高维数据，可以处理缺失值，适应性强，模型可以根据新的训练数据进行修改而无需重建 | 依赖独立性假设，如果假设不成立则表现不佳，准确性相对较低
    | 当数据有大量缺失值、特征之间的依赖关系类似、垃圾邮件过滤和分类、对科技、政治或体育新闻文章进行分类、文本挖掘 |'
- en: '| **Singular Value decomposition (SVD) and Principal Component Analysis (PCA)**
    | Reflects the real intuitions about the dataAllows estimation probabilities in
    high-dimensional dataDramatic reduction in size of dataBoth are based on strong
    linear algebra | Too expensive for many applications like Twitter and web analyticsDisastrous
    for task with fine-grained classesNeed proper understanding of the linearityOften
    complexity is cubicComputationally slower | SVD is applied for low-rank matrix
    approximation, image processing, bioinformatics,  signal processing,  NLPPCA is
    used for interest rate derivatives portfolios, neuroscience and so onBoth are
    suitable for the dataset having high dimension and multivariate data |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 奇异值分解（SVD）和主成分分析（PCA） | 反映了关于数据的真实直觉，可以在高维数据中估计概率，数据大小显著减少，两者都基于强大的线性代数 |
    对于像Twitter和网络分析这样的许多应用来说太昂贵，对于细粒度类别的任务来说灾难性，需要正确理解线性性，复杂度通常是立方的，计算速度较慢 | SVD用于低秩矩阵逼近、图像处理、生物信息学、信号处理、NLP，PCA用于利率衍生品投资组合、神经科学等，两者都适用于具有高维和多变量数据的数据集
    |'
- en: 'Table 3: Pros and cons of some widely used algorithms'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：一些广泛使用算法的优缺点
- en: Logistic regression and linear regression
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 逻辑回归和线性回归
- en: Logistic regression is a powerful tool developed around the globe for its two-class
    and multiclass classification since it's fast as well as simple. The fact is that
    it uses an *S*-shaped curve instead of a straight line. making it a natural fit
    for partitioning data into groups. It provides linear class boundaries, so that
    when you use it, make sure a linear approximation is something you can survive
    with. Unlike the decision trees or SVMs, you also have a nice probabilistic interpretation,
    so you will be able to update your model to adapt for new datasets easily.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一种强大的工具，因为它快速且简单，已在全球范围内用于两类和多类分类。事实上，它使用*S*形曲线而不是直线，使其自然适合将数据分成组。它提供线性类边界，因此在使用它时，请确保线性逼近是您可以接受的。与决策树或SVM不同，它还具有良好的概率解释，因此您将能够轻松更新模型以适应新数据集。
- en: Therefore, the recommendation is, use it if you want to have a flavor of probabilistic
    framework or if you expect to receive more training data in the future to be incorporated
    into your model. As mentioned previously, linear regression fits a line, plane,
    or hyperplane to the dataset. It's a workhorse, simple and fast, but it may be
    overly simplistic for some problems.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，建议使用它，如果您希望体验概率框架的味道，或者期望将来获得更多的训练数据并将其纳入您的模型。如前所述，线性回归将一条直线、平面或超平面拟合到数据集。它是一个实用、简单且快速的工具，但对于某些问题可能过于简单。
- en: Recommendation systems
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推荐系统
- en: We already talked about the accuracy and performance issues of mostly used ML
    algorithms and tools. However, beyond the accuracy research on recommender systems
    is concern about finding another environmental factor or/and parameter diversity.
    Therefore, a recommendation system with good accuracy and higher intra-list diversity
    will be the winner. As a result, your product will be precious to your target
    customers. It would be, however, more effective to let the users re-rate the items,
    rather than showing new items only. If your clients have some extra requirements
    that need to be fulfilled, such as privacy or security, your system has to be
    able to deal with the privacy related issues.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了大多数常用的机器学习算法和工具的准确性和性能问题。然而，除了准确性研究之外，对推荐系统的另一个关注点是寻找其他环境因素和/或参数多样性。因此，一个准确性高且列表内多样性高的推荐系统将是赢家。因此，您的产品将对目标客户非常宝贵。然而，让用户重新对物品进行评分，而不仅仅是显示新物品，可能会更有效。如果您的客户有一些需要满足的额外要求，比如隐私或安全性，您的系统必须能够处理与隐私相关的问题。
- en: This is particularly important because customers have to provide some personal
    information as well, so it is recommended not to expose that sensitive information
    publicly.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点特别重要，因为客户必须提供一些个人信息，因此建议不要公开这些敏感信息。
- en: Building user profiles using some robust techniques or algorithms such as collaborative
    filtering, on the other hand, could be problematic from the privacy perspective.
    Moreover, research in this area has found that user demographics information may
    influence how satisfied the other users are with recommendations (see also in
    Joeran Beel, Stefan Langer, Andreas Nürnberger, Marcel Genzmehr, *The Impact of
    Demographics (Age and Gender) and Other User Characteristics on Evaluating Recommender
    Systems*. In Trond Aalberg and Milena Dobreva and Christos Papatheodorou and Giannis
    Tsakonas and Charles Farrugia. *Proceedings of the 17th International Conference
    on Theory and Practice of Digital Libraries, Springer, pp. 400-404, Retrieved
    1 November 2013*).
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用一些强大的技术或算法（如协同过滤）来构建用户档案可能会从隐私角度带来问题。此外，该领域的研究发现，用户人口统计信息可能会影响其他用户对推荐的满意程度（另请参阅Joeran
    Beel、Stefan Langer、Andreas Nürnberger、Marcel Genzmehr，《人口统计信息（年龄和性别）和其他用户特征对评估推荐系统的影响》，在Trond
    Aalberg和Milena Dobreva和Christos Papatheodorou和Giannis Tsakonas和Charles Farrugia的《第17届数字图书馆理论与实践国际会议论文集》，Springer，第400-404页，2013年11月1日检索）。
- en: Although the serendipity is a crucial measure of how surprising the recommendations
    are, ultimately trust needs to be built using the recommender system. This can
    be made possible by explaining how it generates the recommendations, and why it
    recommends an item even with little demographic information, from the user.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管偶然性是衡量推荐有多么令人惊讶的关键指标，但最终建立信任还是需要通过推荐系统。这可以通过解释它是如何生成推荐的，以及为什么会推荐一个物品，即使用户的人口统计信息很少，来实现。
- en: 'Therefore, if the user does not trust the system at all, they will not provide
    any demographic information or will not re-rate the items. A SVMs, according to
    *Cowley et al*. (G. C. Cawley and N. L. C. Talbot, *Over-fitting in model selection
    and subsequent selection bias in performance evaluation, Journal of Machine Learning
    Research, vol. 11, pp. 2079-2107, July 2010*), there are several advantages of
    Support Vector Machines:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果用户根本不信任系统，他们将不会提供任何人口统计信息，也不会重新对物品进行评分。根据*Cowley等人*（G.C.Cawley和N.L.C.Talbot，《模型选择中的过拟合和性能评估中的后续选择偏差》，《机器学习研究杂志》，第11卷，第2079-2107页，2010年7月），支持向量机有几个优点：
- en: You can tackle the problem of the over-fitting problem since SVMs provide you
    with a regularization parameter
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以通过SVM提供的正则化参数来解决过拟合问题
- en: SVM use the kernel trick that helps to build the machine learning model via
    engineering the kernel with ease
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVM使用核技巧来帮助轻松构建机器学习模型
- en: An SVM algorithm is developed, designed, and defined based on a convex optimization
    problem, therefore, there is no concept of local minima
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVM算法是基于凸优化问题开发、设计和定义的，因此没有局部最小值的概念
- en: It is a ballpark figure to a bound on the test error rate, where there is a
    significant and well-studied theory that works
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个对测试错误率的边界的大致估计，其中有一个重要且深入研究的理论可以发挥作用
- en: 'These promising features of SVM really would help you, and it is suggested
    that it should be used frequently. On the other hand, the cons are:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: SVM的这些有前途的特性确实会帮助您，建议经常使用。另一方面，缺点是：
- en: The theory only can really cover determination of the parameters for a given
    value of the regularization and kernel parameters. Therefore, you could only choose
    the kernel.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理论只能真正涵盖对给定的正则化和核参数值的参数确定。因此，你只能选择核。
- en: There might be a worse scenario as well, where the kernel model itself can be
    quite sensitive to over-fitting during the model selection criterion.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 也可能存在更糟糕的情况，核模型本身在模型选择标准期间可能非常敏感于过拟合。
- en: Decision trees
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 决策树
- en: 'Decision trees are cool because of their usability they are easy to interpret
    and explain the machine learning problem around. In parallel, they can easily
    be handled for the feature related interactions. Most importantly, they are often
    non-parametric. Therefore, even if you are an ordinary data scientist with limited
    working proficiencies, you don''t need to be worried about the issues such as
    outliers, parameter setting, and tuning. Sometimes fundamentally, you can relay
    with the decision trees so that they will make your stress for handling issue
    of the data linearity, or more technically, whether your data is linearly separable
    or not, you need not be worried. On the contrary, there are some cons as well.
    For example:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树很酷，因为它们易于解释和解释围绕机器学习问题。与此同时，它们可以很容易地处理与特征相关的交互。最重要的是，它们通常是非参数的。因此，即使你是一个工作能力有限的普通数据科学家，你也不需要担心异常值、参数设置和调整等问题。有时，基本上，你可以依赖决策树，这样它们将减轻你处理数据线性问题的压力，或者更技术上说，你的数据是否是线性可分的，你不需要担心。相反，也有一些缺点。例如：
- en: In some cases, the decision tree will not be suitable, sometimes they don't
    support online learning for real-time datasets. In that case, you have to rebuild
    your tree when new examples or datasets come; more technically, gaining model
    adaptability would not be possible.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在某些情况下，决策树可能不合适，有时它们不支持实时数据集的在线学习。在这种情况下，当出现新的示例或数据集时，你必须重新构建你的树；更技术上说，获得模型的适应性是不可能的。
- en: Secondly, if you are not aware, they will easily become over-fitting.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，如果你没有意识到，它们很容易过拟合。
- en: Random forests
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 随机森林
- en: Random forests are quite popular and are a winner for the data scientist, since
    they are divine for a package with plenty of classification problems. They are
    usually slightly ahead of SVMs in terms of usability and have faster operation
    for most of the classification problems. In addition to this, they are also scalable
    when increasing the datasets you have available. In parallel, you don't need to
    be worried about tuning a cluster of parameters. On the contrary, you need to
    take care of many parameters and tuning when handling your data.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林非常受欢迎，对于数据科学家来说是一个赢家，因为它们对于大量分类问题来说是非常好用的。它们通常在可用性方面略领先于支持向量机，并且对于大多数分类问题的操作速度更快。此外，它们在增加可用数据集时也是可扩展的。与此同时，你不需要担心调整一系列参数。相反，当处理数据时，你需要关注许多参数和调整。
- en: Decision forests, decision jungles, and variants
  id: totrans-347
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 决策森林、决策丛林和变体
- en: Decision forests, decision jungles, and boosted decision trees are all based
    on decision trees, a foundational machine learning concept that is less used.
    There are many variants of decision trees are there; nonetheless, they all do
    the same thing, which is subdividing the feature space into regions with the same
    label. In order to avoid the over-fitting problem, a large set of trees are constructed
    with mathematical and statistical formulations, where the trees are not correlated
    at all.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 决策森林、决策丛林和提升决策树都是基于决策树的，决策树是一个基础的机器学习概念，使用较少。决策树有许多变体；尽管如此，它们都做同样的事情，即将特征空间细分为具有相同标签的区域。为了避免过拟合问题，使用数学和统计公式构建了大量的树，这些树之间没有任何相关性。
- en: The average of this is referred to as a decision forest; which is a tree that
    avoids the overfitting problem as stated earlier. However, the disadvantage is
    that decision forests can use a lot of memory. Decision jungles, on the other
    hand, are a variant that consume less memory by sacrificing a slightly longer
    training time. Fortunately, the boosted decision trees avoid overfitting by limiting
    the number of subdivision and the number of permitted data points in each region.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 其平均值被称为决策森林；这是一种避免过拟合问题的树，如前所述。然而，决策森林可能会使用大量内存。另一方面，决策丛林是一种通过牺牲略长的训练时间来消耗较少内存的变体。幸运的是，提升决策树通过限制分区的数量和每个区域允许的数据点数量来避免过拟合。
- en: Bayesian methods
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 贝叶斯方法
- en: When the experimental or sample dataset size is large, the Bayesian method often
    provides results for parametric models that are very similar to the results produced
    by other classical statistical methods. Some potential advantages of using the
    Bayesian method was summarized by Elam et al (W. T. Elam, B. Scruggs, F. Eggert,
    and J. A. Nicolosi, *Advantages and Disadvantages of Methods for Obtaining XRF
    NET Intensities*, Copyright ©JCPDS-International Centre for Diffraction Data 2011
    ISSN 1097-0002). For example, it provides a natural way of combining prior information
    with data. Therefore, as a data scientist, you can incorporate that past information
    regarding the parameters and form a prior distribution for future analysis for
    new datasets. It also provides inferences that are conditional on the data without
    the need of asymptotic approximation of the algorithm.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 当实验或样本数据集规模较大时，贝叶斯方法通常会为参数模型提供与其他经典统计方法产生的结果非常相似的结果。使用贝叶斯方法的一些潜在优势由Elam等人总结（W.T.
    Elam, B. Scruggs, F. Eggert, and J.A. Nicolosi，《获取XRF NET强度方法的优缺点》，版权所有©JCPDS-国际衍射数据中心2011
    ISSN 1097-0002）。例如，它提供了一种将先验信息与数据结合的自然方式。因此，作为一名数据科学家，你可以将过去关于参数的信息并入未来分析新数据集的先验分布。它还提供了在不需要算法渐近逼近的情况下，条件于数据的推断。
- en: It provides some suitable settings for a wide range of models, such as hierarchical
    models and missing data problems. There are also disadvantages of using Bayesian
    analysis. For example, it does not tell you how to select a prior over world models
    or even that there is no correct way to choose a prior. Therefore, if you do not
    proceed with caution, you might generate many false positive or false negative
    results that often come with a high computational cost, if the number of parameters
    in a model is large.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 它为各种模型提供了一些合适的设置，比如层次模型和缺失数据问题。使用贝叶斯分析也有一些缺点。例如，它不告诉你如何选择先验世界模型，甚至没有正确选择先验的方法。因此，如果你不小心进行，你可能会产生许多伪阳性或伪阴性的结果，这往往伴随着高昂的计算成本，如果模型中的参数数量很大的话。
- en: Summary
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This ends our rather quick tour of machine learning and the best practice that
    needs to be followed. Although we have tried to cover some of the most basic things
    to remember, suitable data often beats better algorithms and better demand. Most
    importantly, to design good features out of your data might take a long time;
    however, it would very much aid you. However, if you have a large-scale dataset
    to be applied to your machine learning algorithms or model, whichever classification,
    clustering, or regression algorithm you use might not be a matter of fact concerning
    the machine learning classes and their respective classification performance.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了我们对机器学习和需要遵循的最佳实践的相当快速的介绍。虽然我们试图涵盖一些最基本的要点，但合适的数据往往胜过更好的算法和更高的需求。最重要的是，从数据中设计出好的特征可能需要很长时间；然而，这将对你非常有帮助。然而，如果你有一个大规模的数据集要应用到你的机器学习算法或模型中，无论你使用哪种分类、聚类或回归算法，都可能不是关于机器学习类别及其相应的分类性能的事实。
- en: Therefore, it would be a wise decision to choose an appropriate machine learning
    algorithm that can fulfill requirements such as speed, memory usage, throughput,
    scalability, or usability. In addition to going over what we said in the sections
    above, if you are really concerned about achieving the accuracy, you should undoubtedly
    try a group of different classifiers to find the best one using the cross-validation
    technique or just use an ensemble method to choose them alltogether.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，选择一个能够满足速度、内存使用、吞吐量、可扩展性或可用性等要求的合适的机器学习算法将是一个明智的决定。除了我们在上面的部分中所说的内容之外，如果你真的关心准确性，你应该毫无疑问地尝试一组不同的分类器，使用交叉验证技术找到最佳的一个，或者使用集成方法来一起选择它们。
- en: You can also be motivated and take a lesson from the Netflix Prize PLUS. We
    spoke at length about the Spark machine learning APIs, some best practice in ML
    application development, machine learning tasks and classes, some widely used
    best practices, and so on. However, we have not shown in depth analysis of the
    machine learning techniques. We intend to talk about this in more detail in [Chapter
    4](part0038_split_000.html#147LC2-5afe140a04e845e0842b44be7971e11a "Chapter 4. Extracting
    Knowledge through Feature Engineering"), *Extracting Knowledge through Feature
    Engineering*.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以从Netflix Prize PLUS中得到启发并吸取教训。我们详细讨论了Spark机器学习API、ML应用开发中的一些最佳实践、机器学习任务和类别、一些广泛使用的最佳实践等等。然而，我们并没有深入分析机器学习技术。我们打算在[第4章](part0038_split_000.html#147LC2-5afe140a04e845e0842b44be7971e11a
    "第4章。通过特征工程提取知识")中更详细地讨论这个问题，*通过特征工程提取知识*。
- en: In the next chapter, we will cover in detail the DataFrame, Dataset, and **Resilient
    Distributed Dataset** (**RDD**) APIs for working with structured data targeting
    to provide a basic understanding of machine learning problems with the available
    data. Therefore, at the end, you will be able to apply from basic to complex data
    manipulation with ease.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将详细介绍DataFrame、Dataset和**Resilient Distributed Dataset**（**RDD**）API，以处理结构化数据，旨在提供对可用数据进行机器学习问题的基本理解。因此，最终，你将能够轻松地应用从基本到复杂的数据操作。
