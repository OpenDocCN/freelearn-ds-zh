- en: '1'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '1'
- en: Jupyter Fundamentals
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jupyter 基础
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Describe Jupyter Notebooks and how they are used for data analysis
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述 Jupyter Notebooks 及其如何用于数据分析
- en: Describe the features of Jupyter Notebooks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述 Jupyter Notebooks 的特点
- en: Use Python data science libraries
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 数据科学库
- en: Perform simple exploratory data analysis
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行简单的探索性数据分析
- en: In this chapter, you will learn and implement the fundamental features of the
    Jupyter notebook by completing several hands-on erxercises.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将通过完成几个动手实践练习，学习并实现 Jupyter Notebook 的基本功能。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: Jupyter Notebooks are one of the most important tools for data scientists using
    Python. This is because they're an ideal environment for developing reproducible
    data analysis pipelines. Data can be loaded, transformed, and modeled all inside
    a single Notebook, where it's quick and easy to test out code and explore ideas
    along the way. Furthermore, all of this can be documented "inline" using formatted
    text, so you can make notes for yourself or even produce a structured report.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebooks 是 Python 数据科学家最重要的工具之一。这是因为它们是开发可复现的数据分析管道的理想环境。数据可以在同一个 Notebook
    中加载、转换和建模，在这个过程中，测试代码和探索想法变得又快又简单。此外，所有这些都可以使用格式化文本进行“内联”文档记录，这样你可以为自己做笔记，甚至生成结构化报告。
- en: Other comparable platforms - for example, RStudio or Spyder - present the user
    with multiple windows, which promote arduous tasks such as copy and pasting code
    around and rerunning code that has already been executed. These tools also tend
    to involve **Read Eval Prompt Loops** (**REPLs**) where code is run in a terminal
    session that has saved memory. This type of development environment is bad for
    reproducibility and not ideal for development either. Jupyter Notebooks solve
    all these issues by giving the user a single window where code snippets are executed
    and outputs are displayed inline. This lets users develop code efficiently and
    allows them to look back at previous work for reference, or even to make alterations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 其他类似的平台——例如 RStudio 或 Spyder——向用户提供多个窗口，这样会增加诸如复制粘贴代码和重新执行已运行代码等繁琐任务的难度。这些工具通常还涉及
    **读取评估提示循环**（**REPLs**），其中代码在一个保存了内存的终端会话中运行。这种开发环境不利于可复现性，也不适合开发。Jupyter Notebooks
    通过提供一个单一窗口来解决所有这些问题，在该窗口中，代码片段被执行，输出结果会内联显示。这使得用户可以高效地开发代码，并能够回顾之前的工作，作为参考或进行修改。
- en: We'll start the chapter by explaining exactly what Jupyter Notebooks are and
    continue to discuss why they are so popular among data scientists. Then, we'll
    open a Notebook together and go through some exercises to learn how the platform
    is used. Finally, we'll dive into our first analysis and perform an exploratory
    analysis in
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从解释 Jupyter Notebooks 的真正含义开始，并继续讨论它们为何在数据科学家中如此受欢迎。接下来，我们将一起打开一个 Notebook，进行一些练习，学习如何使用该平台。最后，我们将深入到我们的第一个分析，并进行探索性分析。
- en: Basic Functionality and Features
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基本功能和特点
- en: In this section, we first demonstrate the usefulness of Jupyter Notebooks with
    examples and through discussion. Then, in order to cover the fundamentals of Jupyter
    Notebooks for beginners, we'll see the basic usage of them in terms of launching
    and interacting with the platform. For those who have used Jupyter Notebooks before,
    this will be mostly a review; however, you will certainly see new things in this
    topic as well.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们首先通过示例和讨论演示 Jupyter Notebooks 的实用性。然后，为了覆盖 Jupyter Notebooks 的基础知识，我们将展示如何启动和使用该平台，帮助初学者理解其基本用法。对于那些曾经使用过
    Jupyter Notebooks 的人来说，这将主要是一次复习；不过，你也一定会在本主题中看到一些新的内容。
- en: What is a Jupyter Notebook and Why is it Useful?
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是 Jupyter Notebook，为什么它有用？
- en: 'Jupyter Notebooks are locally run web applications which contain live code,
    equations, figures, interactive apps, and **Markdown** text. The standard language
    is Python, and that''s what we''ll be using for this book; however, note that
    a variety of alternatives are supported. This includes the other dominant data
    science language, R:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebooks 是本地运行的 Web 应用程序，包含实时代码、方程式、图形、交互式应用程序以及 **Markdown** 文本。标准编程语言是
    Python，这也是本书中使用的语言；然而，请注意，它也支持多种其他语言，包括数据科学领域的另一大主流语言 R：
- en: '![Figure 1.1: Jupyter Notebook sample workbook](img/C13018_01_01.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.1：Jupyter Notebook 示例工作簿](img/C13018_01_01.jpg)'
- en: 'Figure 1.1: Jupyter Notebook sample workbook'
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.1：Jupyter Notebook 示例工作簿
- en: Those familiar with R will know about R Markdown. `README.md` **Markdown** file.
    This format is useful for basic text formatting. It's comparable to HTML but allows
    for much less customization.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉 R 的人应该知道 R Markdown。`README.md` **Markdown** 文件。这种格式适用于基本的文本格式化。它类似于 HTML，但允许的自定义选项较少。
- en: 'Commonly used symbols in **Markdown** include hashes (#) to make text into
    a heading, square and round brackets to insert hyperlinks, and stars to create
    italicized or bold text:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**Markdown** 中常用的符号包括井号（#）用来创建标题，方括号和圆括号用来插入超链接，星号用来创建斜体或粗体文本：'
- en: '![Figure 1.2: Sample Markdown document](img/C13018_01_02.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2：示例 Markdown 文档](img/C13018_01_02.jpg)'
- en: 'Figure 1.2: Sample Markdown document'
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.2：示例 Markdown 文档
- en: Having seen the basics of Markdown, let's come back to R Markdown, where **Markdown**
    text can be written alongside executable code. Jupyter Notebooks offer the equivalent
    functionality for Python, although, as we'll see, they function quite differently
    than R **Markdown** documents. For example, R **Markdown** assumes you are writing
    **Markdown** unless otherwise specified, whereas Jupyter Notebooks assume you
    are inputting code. This makes it more appealing to use Jupyter Notebooks for
    rapid development and testing.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了 Markdown 的基础知识后，让我们回到 R Markdown，其中 **Markdown** 文本可以与可执行代码一起编写。Jupyter
    Notebooks 为 Python 提供了等效的功能，尽管正如我们将看到的，它们的工作方式与 R **Markdown** 文档有很大不同。例如，R **Markdown**
    假设你是在写 **Markdown**，除非另有说明，而 Jupyter Notebooks 假设你输入的是代码。这使得 Jupyter Notebooks
    更适合用于快速开发和测试。
- en: 'From a data science perspective, there are two primary types for a Jupyter
    Notebook depending on how they are used: lab-style and deliverable.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据科学的角度来看，Jupyter Notebook 主要有两种类型，取决于其使用方式：实验室风格和交付式。
- en: Lab-style Notebooks are meant to serve as the programming analog of research
    journals. These should contain all the work you've done to load, process, analyze,
    and model the data. The idea here is to document everything you've done for future
    reference, so it's usually not advisable to delete or alter previous lab-style
    Notebooks. It's also a good idea to accumulate multiple date-stamped versions
    of the Notebook as you progress through the analysis, in case you want to look
    back at previous states.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 实验室风格 Notebooks 是用来作为编程版的研究期刊。这些 Notebooks 应包含你加载、处理、分析和建模数据的所有工作。其理念是记录下你做过的每一步，以便将来参考，因此通常不建议删除或修改之前的实验室风格
    Notebooks。同时，随着分析的推进，积累多个带有时间戳的 Notebook 版本也是一个好主意，这样你就可以在需要时回顾之前的状态。
- en: Deliverable Notebooks are intended to be presentable and should contain only
    select parts of the lab-style Notebooks. For example, this could be an interesting
    discovery to share with your colleagues, an in-depth report of your analysis for
    a manager, or a summary of the key findings for stakeholders.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 交付式 Notebooks 旨在呈现内容，应该仅包含实验室风格 Notebooks 的一部分内容。例如，这可以是一个有趣的发现，供你与同事分享；也可以是为经理准备的深入分析报告，或是为利益相关者总结的关键发现。
- en: In either case, an important concept is reproducibility. If you've been diligent
    in documenting your software versions, anyone receiving the reports will be able
    to rerun the Notebook and compute the same results as you did. In the scientific
    community, where reproducibility is becoming increasingly difficult, this is a
    breath of fresh air.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是哪种情况，一个重要的概念是可重现性。如果你在记录软件版本时很细心，那么任何收到报告的人都可以重新运行 Notebook 并计算出与你相同的结果。在科学界，可重现性变得越来越困难，这无疑是一个令人耳目一新的做法。
- en: Navigating the Platform
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导航平台
- en: Now, we are going to open up a Jupyter Notebook and start to learn the interface.
    Here, we will assume you have no prior knowledge of the platform and go over the
    basic usage.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将打开一个 Jupyter Notebook，开始学习其界面。在这里，我们假设你对该平台没有任何先前的了解，并将讲解基本的使用方法。
- en: 'Exercise 1: Introducing Jupyter Notebooks'
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 1：介绍 Jupyter Notebooks
- en: Navigate to the companion material directory in the terminal
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中导航到配套材料目录
- en: Note
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'Unix machines such as Mac or Linux, command-line navigation can be done using
    `ls` to display directory contents and `cd` to change directories. On Windows
    machines, use `dir` to display directory contents and use cd to change directories
    instead. If, for example, you want to change the drive from C: to D:, you should
    execute d: to change drives.'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '在 Unix 系统如 Mac 或 Linux 上，可以使用 `ls` 显示目录内容，使用 `cd` 切换目录。在 Windows 系统上，使用 `dir`
    显示目录内容，使用 `cd` 切换目录。如果你想将驱动器从 C: 切换到 D:，可以执行 d: 来切换驱动器。'
- en: 'Start a new local Notebook server here by typing the following into the terminal:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中输入以下命令以启动新的本地Notebook服务器：
- en: '[PRE0]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A new window or tab of your default browser will open the Notebook Dashboard
    to the working directory. Here, you will see a list of folders and files contained
    therein.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 默认浏览器将会打开一个新的窗口或标签页，显示工作目录中的Notebook仪表板。在这里，你将看到其中包含的文件夹和文件列表。
- en: Click on a folder to navigate to that particular path and open a file by clicking
    on it. Although its main use is editing IPYNB Notebook files, Jupyter functions
    as a standard text editor as well.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击一个文件夹以导航到那个特定的路径，然后点击一个文件打开它。虽然它的主要用途是编辑IPYNB Notebook文件，Jupyter也可以作为一个标准的文本编辑器使用。
- en: 'Reopen the terminal window used to launch the app. We can see the `NotebookApp`
    being run on a local server. In particular, you should see a line like this:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新打开用来启动应用程序的终端窗口。我们可以看到`NotebookApp`正在本地服务器上运行。特别是，你应该能看到类似这样的行：
- en: '[PRE1]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Going to that HTTP address will load the app in your browser window, as was
    done automatically when starting the app. Closing the window does not stop the
    app; this should be done from the terminal by typing *Ctrl* + *C*.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 访问该HTTP地址将会在浏览器窗口中加载应用程序，就像在启动应用时自动执行的那样。关闭窗口并不会停止应用程序；应该通过在终端中输入*Ctrl* + *C*来停止。
- en: Close the app by typing *Ctrl* + *C* in the terminal. You may also have to confirm
    by entering `y`. Close the web browser window as well.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中按*Ctrl* + *C*关闭应用程序。你也可能需要通过输入`y`来确认。也请关闭网页浏览器窗口。
- en: 'Load the list of available options by running the following code:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码加载可用选项列表：
- en: '[PRE2]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Open the `NotebookApp` at local port `9000` by running the following:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令，在本地端口`9000`打开`NotebookApp`：
- en: '[PRE3]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Click **New** in the upper-right corner of the Jupyter Dashboard and select
    a kernel from the drop-down menu (that is, select something in the **Notebooks**
    section):![Figure 1.3: Selecting a kernel from the drop down menu](img/C13018_01_03.jpg)'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Jupyter仪表板的右上角点击**新建**，然后从下拉菜单中选择一个内核（即，在**Notebooks**部分选择一个）：![图1.3：从下拉菜单中选择一个内核](img/C13018_01_03.jpg)
- en: 'Figure 1.3: Selecting a kernel from the drop down menu'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.3：从下拉菜单中选择一个内核
- en: This is the primary method of creating a new Jupyter Notebook.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是创建新Jupyter Notebook的主要方法。
- en: Kernels provide programming language support for the Notebook. If you have installed
    Python with Anaconda, that version should be the default kernel. Conda virtual
    environments will also be available here.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 内核为Notebook提供编程语言支持。如果你通过Anaconda安装了Python，那么该版本应为默认内核。Conda虚拟环境也将在这里可用。
- en: Note
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'Virtual environments are a great tool for managing multiple projects on the
    same machine. Each virtual environment may contain a different version of Python
    and external libraries. Python has built-in virtual environments; however, the
    Conda virtual environment integrates better with Jupyter Notebooks and boasts
    other nice features. The documentation is available at: [https://conda.io/docs/user-guide/tasks/manage-environments.html](https://conda.io/docs/user-guide/tasks/manage-environments.html).'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虚拟环境是管理同一台机器上多个项目的一个很好的工具。每个虚拟环境可能包含不同版本的Python和外部库。Python内置有虚拟环境；然而，Conda虚拟环境与Jupyter
    Notebooks的集成更好，并且有其他一些优点。文档可以在此查看：[https://conda.io/docs/user-guide/tasks/manage-environments.html](https://conda.io/docs/user-guide/tasks/manage-environments.html)。
- en: With the newly created blank Notebook, click the top cell and type `print('hello
    world')`, or any other code snippet that writes to the screen.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新创建的空白Notebook中，点击顶部的单元格并输入`print('hello world')`，或者任何其他会输出到屏幕的代码片段。
- en: Click the cell and press *Shift* + *Enter* or select `stdout` or `stderr` output
    from the code will be displayed beneath as the cell runs. Furthermore, the string
    representation of the object written in the final line will be displayed as well.
    This is very handy, especially for displaying tables, but sometimes we don't want
    the final object to be displayed. In such cases, a semicolon (;) can be added
    to the end of the line to suppress the display. New cells expect and run code
    input by default; however, they can be changed to render **Markdown** instead.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击单元格并按*Shift* + *Enter*，或者选择`stdout`或`stderr`输出，代码运行后会在下面显示结果。此外，最后一行写入的对象的字符串表示也会显示出来。这非常方便，特别是用于显示表格，但有时我们不希望显示最后的对象。在这种情况下，可以在行尾添加分号（;）来抑制显示。新单元格默认期望并运行代码输入；不过，它们也可以改为渲染**Markdown**。
- en: 'Click an empty cell and change it to accept the Markdown-formatted text. This
    can be done from the drop-down menu icon in the toolbar or by selecting **Markdown**
    from the **Cell** menu. Write some text in here (any text will do), making sure
    to utilize Markdown formatting symbols such as #.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '点击一个空白单元格并将其更改为接受 Markdown 格式的文本。这可以通过工具栏中的下拉菜单图标或通过在**单元格**菜单中选择**Markdown**来完成。在这里写一些文本（任何文本都可以），确保使用
    Markdown 格式符号，如 #。'
- en: 'Scroll to the **Play** icon in the tool bar:![Figure 1.4: Jupyter Notebook
    tool bar](img/C13018_01_04.jpg)'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到工具栏中的**播放**图标：![图 1.4：Jupyter Notebook 工具栏](img/C13018_01_04.jpg)
- en: 'Figure 1.4: Jupyter Notebook tool bar'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.4：Jupyter Notebook 工具栏
- en: This can be used to run cells. As we'll see later, however, it's handier to
    use the keyboard shortcut *Shift* + *Enter* to run cells.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以用来运行单元格。然而，正如我们稍后所看到的，使用键盘快捷键*Shift* + *Enter*来运行单元格更为方便。
- en: 'Right next to this is a **Stop** icon, which can be used to stop cells from
    running. This is useful, for example, if a cell is taking too long to run:'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 紧挨着这个按钮的是**停止**图标，可以用来停止单元格的运行。例如，如果某个单元格运行得太慢时，这个功能会非常有用：
- en: '![Figure 1.5: Stop icon in Jupyter Notebooks'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.5：Jupyter Notebook 中的停止图标](img/C13018_01_05_2.jpg)'
- en: '](img/C13018_01_05_2.jpg)'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_05_2.jpg)'
- en: 'Figure 1.5: Stop icon in Jupyter Notebooks'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.5：Jupyter Notebook 中的停止图标
- en: 'New cells can be manually added from the **Insert** menu:'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以通过**插入**菜单手动添加新单元格：
- en: '![Figure 1.6: Adding new cells from the Insert menu in Jupyter Notebooks](img/C13018_01_06.jpg)'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.6：在 Jupyter Notebook 中通过插入菜单添加新单元格](img/C13018_01_06.jpg)'
- en: 'Figure 1.6: Adding new cells from the Insert menu in Jupyter Notebooks'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.6：在 Jupyter Notebook 中通过插入菜单添加新单元格
- en: 'Cells can be copied, pasted, and deleted using icons or by selecting options
    from the **Edit** menu:'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 单元格可以使用图标或通过在**编辑**菜单中选择选项来复制、粘贴和删除：
- en: '![Figure 1.7: Edit Menu in the Jupyter Notebooks](img/C13018_01_07.jpg)'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.7：Jupyter Notebook 中的编辑菜单](img/C13018_01_07.jpg)'
- en: 'Figure 1.7: Edit Menu in the Jupyter Notebooks'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.7：Jupyter Notebook 中的编辑菜单
- en: '![Figure 1.8: Cutting and copying cells in Jupyter Notebooks](img/C13018_01_08.jpg)'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.8：在 Jupyter Notebook 中剪切和复制单元格](img/C13018_01_08.jpg)'
- en: 'Figure 1.8: Cutting and copying cells in Jupyter Notebooks'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.8：在 Jupyter Notebook 中剪切和复制单元格
- en: 'Cells can also be moved up and down this way:'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 单元格也可以通过这种方式上下移动：
- en: '![Figure 1.9: Moving cells up and down in Jupyter Notebooks](img/C13018_01_09.jpg)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.9：在 Jupyter Notebook 中上下移动单元格](img/C13018_01_09.jpg)'
- en: 'Figure 1.9: Moving cells up and down in Jupyter Notebooks'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.9：在 Jupyter Notebook 中上下移动单元格
- en: 'There are useful options under the **Cell** menu to run a group of cells or
    the entire Notebook:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在**单元格**菜单下有一些有用的选项，可以运行一组单元格或整个 Notebook：
- en: '![Figure 1.10: Running Cells in Jupyter Notebooks](img/C13018_01_10.jpg)'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.10：在 Jupyter Notebook 中运行单元格](img/C13018_01_10.jpg)'
- en: 'Figure 1.10: Running cells in Jupyter Notebooks'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.10：在 Jupyter Notebook 中运行单元格
- en: 'Experiment with the toolbar options to move cells up and down, insert new cells,
    and delete cells. An important thing to understand about these Notebooks is the
    shared memory between cells. It''s quite simple: every cell existing on the sheet
    has access to the global set of variables. So, for example, a function defined
    in one cell could be called from any other, and the same applies to variables.
    As one would expect, anything within the scope of a function will not be a global
    variable and can only be accessed from within that specific function.'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尝试使用工具栏选项来移动单元格、插入新单元格和删除单元格。关于这些 Notebook 需要理解的一个重要事项是单元格之间共享内存。其实很简单：每个存在于表单上的单元格都可以访问全局变量集。例如，在一个单元格中定义的函数可以从任何其他单元格中调用，变量也是如此。正如预期的那样，函数范围内的任何内容都不会是全局变量，只能在该特定函数内访问。
- en: Open the **Kernel** menu to see the selections. The **Kernel** menu is useful
    for stopping script executions and restarting the Notebook if the kernel dies.
    Kernels can also be swapped here at any time, but it is unadvisable to use multiple
    kernels for a single Notebook due to reproducibility concerns.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开**内核**菜单以查看选项。**内核**菜单对于停止脚本执行以及在内核崩溃时重启 Notebook 很有用。内核也可以随时在这里切换，但由于可重复性问题，不建议为一个
    Notebook 使用多个内核。
- en: Open the **File** menu to see the selections. The **File** menu contains options
    for downloading the Notebook in various formats. In particular, it's recommended
    to save an HTML version of your Notebook, where the content is rendered statically
    and can be opened and viewed "as you would expect" in web browsers.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开**文件**菜单以查看选项。**文件**菜单包含将 Notebook 下载为各种格式的选项。特别是，建议保存 Notebook 的 HTML 版本，在该版本中内容静态呈现，并且可以像在网页浏览器中一样打开和查看。
- en: The Notebook name will be displayed in the upper-left corner. New Notebooks
    will automatically be named **Untitled**.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Notebook 的名称将在左上角显示。新的 Notebook 会自动命名为 **未命名**。
- en: Change the name of your IPYNB Notebook file by clicking on the current name
    in the upper-left corner and typing the new name. Then, save the file.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击左上角当前名称，修改你的 IPYNB Notebook 文件名，并输入新名称。然后保存文件。
- en: Close the current tab in your web browser (exiting the Notebook) and go to the
    **Jupyter Dashboard** tab, which should still be open. (If it's not open, then
    reload it by copy and pasting the HTTP link from the terminal.)
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭当前浏览器标签页（退出 Notebook），然后转到应该仍然打开的 **Jupyter 仪表盘** 标签页。（如果没有打开，可以通过复制并粘贴终端中的
    HTTP 链接来重新加载它。）
- en: Since we didn't shut down the Notebook, and we just saved and exited, it will
    have a green book symbol next to its name in the **Files** section of the Jupyter
    Dashboard and will be listed as **Running** on the right side next to the last
    modified date. Notebooks can be shut down from here.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于我们没有关闭 Notebook，而且只是保存并退出，它将在 Jupyter 仪表盘的 **文件** 部分的文件名旁边显示绿色书本符号，并且在右侧的最后修改日期旁边标注为
    **运行中**。Notebook 可以从这里关闭。
- en: 'Quit the Notebook you have been working on by selecting it (checkbox to the
    left of the name), and then click the orange **Shutdown** button:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过选择你正在工作的 Notebook（勾选名称左侧的复选框），然后点击橙色的 **关闭** 按钮来退出 Notebook：
- en: Note
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注
- en: Read through the basic keyboard shortcuts and test them.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阅读基础的键盘快捷键并进行测试。
- en: '![Figure 1.11: Shutting down the Jupyter notebook'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.11：关闭 Jupyter Notebook](img/C13018_01_11.jpg)'
- en: '](img/C13018_01_11.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_11.jpg)'
- en: 'Figure 1.11: Shutting down the Jupyter notebook'
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.11：关闭 Jupyter Notebook
- en: Note
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注
- en: If you plan to spend a lot of time working with Jupyter Notebooks, it's worthwhile
    to learn the keyboard shortcuts. This will speed up your workflow considerably.
    Particularly useful commands to learn are the shortcuts for manually adding new
    cells and converting cells from code to Markdown formatting. Click on **Keyboard
    Shortcuts** from the **Help** menu to see how.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算花很多时间使用 Jupyter Notebook，学习键盘快捷键是很值得的。这将显著加快你的工作流程。特别有用的命令是手动添加新单元的快捷键，以及将单元从代码转换为
    Markdown 格式的快捷键。点击 **帮助** 菜单中的 **键盘快捷键** 查看如何操作。
- en: Jupyter Features
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Jupyter 功能
- en: Jupyter has many appealing features that make for efficient Python programming.
    These include an assortment of things, from methods for viewing docstrings to
    executing Bash commands. We will explore some of these features in this section.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter 拥有许多吸引人的功能，使 Python 编程更加高效。这些功能包括从查看文档字符串到执行 Bash 命令的各种方法。我们将在本节中探索其中的一些功能。
- en: Note
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注
- en: 'The official IPython documentation can be found here: [http://ipython.readthedocs.io/en/stable/](http://ipython.readthedocs.io/en/stable/).
    It has details on the features we will discuss here and others.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 官方的 IPython 文档可以在这里找到：[http://ipython.readthedocs.io/en/stable/](http://ipython.readthedocs.io/en/stable/)。其中包含我们将在这里讨论的功能及其他内容的详细信息。
- en: 'Exercise 2: Implementing Jupyter''s Most Useful Features'
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 2：实现 Jupyter 最有用的功能
- en: Navigate to the `lesson-1` directory from the Jupyter Dashboard and open `lesson-1-workbook.ipynb`
    by selecting it.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Jupyter 仪表盘中导航到 `lesson-1` 目录，并通过选择打开 `lesson-1-workbook.ipynb`。
- en: The standard file extension for Jupyter Notebooks is `.ipynb`, which was introduced
    back when they were called IPython Notebooks.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Jupyter Notebook 的标准文件扩展名是 `.ipynb`，它是在 Jupyter 还被称为 IPython Notebook 时引入的。
- en: 'Scroll down to `Subtopic C: Jupyter Features` in the Jupyter Notebook.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '滚动到 Jupyter Notebook 中的 `Subtopic C: Jupyter Features` 部分。'
- en: We start by reviewing the basic keyboard shortcuts. These are especially helpful
    to avoid having to use the mouse so often, which will greatly speed up the workflow.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首先回顾基本的键盘快捷键。它们特别有助于避免频繁使用鼠标，从而大大加快工作流程。
- en: You can get help by adding a question mark to the end of any object and running
    the cell. Jupyter finds the docstring for that object and returns it in a pop-out
    window at the bottom of the app.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以通过在任何对象后面加上问号并运行单元来获取帮助。Jupyter 会找到该对象的文档字符串，并在应用程序底部弹出窗口中显示它。
- en: 'Run the **Getting Help** cell and check how Jupyter displays the docstrings
    at the bottom of the Notebook. Add a cell in this section and get help on the
    object of your choice:![Figure 1.12: Getting help in Jupyter Notebooks](img/C13018_01_12.jpg)'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 **获取帮助** 单元，查看 Jupyter 如何在 Notebook 底部显示文档字符串。在此部分添加一个单元，并获取你选择的对象的帮助：![图
    1.12：在 Jupyter Notebook 中获取帮助](img/C13018_01_12.jpg)
- en: 'Figure 1.12: Getting help in Jupyter Notebooks'
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.12：在 Jupyter Notebook 中获取帮助
- en: 'Click an empty code cell in the **Tab Completion** section. Type import (including
    the space after) and then press the **Tab** key:![Figure 1.13: Tab completion
    in Jupyter Notebooks](img/C13018_01_13.jpg)'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Tab 完成** 部分的一个空白代码单元格。输入 import（包括后面的空格），然后按下 **Tab** 键：![图 1.13：Jupyter
    Notebook 中的 Tab 完成](img/C13018_01_13.jpg)
- en: 'Figure 1.13: Tab completion in Jupyter Notebooks'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.13：Jupyter Notebook 中的 Tab 完成
- en: The above action listed all the available modules for import.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述操作列出了所有可供导入的模块。
- en: 'Tab completion can be used for the following: **list available modules when
    importing external libraries**; **list available modules of imported external
    libraries**; **function and variable completion**. This can be especially useful
    when you need to know the available input arguments for a module, when exploring
    a new library, to discover new modules, or simply to speed up workflow. They will
    save time writing out variable names or functions and reduce bugs from typos.
    The tab completion works so well that you may have difficulty coding Python in
    other editors after today!'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Tab 完成功能可以用于以下场景：**列出导入外部库时可用的模块**；**列出导入的外部库中的可用模块**；**函数和变量的自动补全**。当你需要了解模块的可用输入参数，探索新库，发现新模块，或者简单地加速工作流程时，这尤其有用。它们可以节省编写变量名或函数的时间，减少因拼写错误导致的
    bug。Tab 完成功能如此强大，以至于今天之后，你可能在其他编辑器中编写 Python 代码时会遇到困难！
- en: 'Scroll to the Jupyter Magic Functions section and run the cells containing
    `%lsmagic` and `%matplotlib` inline:![Figure 1.14: Jupyter Magic functions](img/C13018_01_14.jpg)'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到 Jupyter 魔法函数部分，并运行包含 `%lsmagic` 和 `%matplotlib inline` 的单元格：![图 1.14：Jupyter
    魔法函数](img/C13018_01_14.jpg)
- en: 'Figure 1.14: Jupyter Magic functions'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.14：Jupyter 魔法函数
- en: The percent signs, % and %%, are one of the basic features of Jupyter Notebook
    and are called magic commands. Magics starting with `%%` will apply to the entire
    cell, and magics starting with `%` will only apply to that line.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 百分号 `%` 和 `%%` 是 Jupyter Notebook 的基本功能之一，称为魔法命令。以 `%%` 开头的魔法命令会应用于整个单元格，而以
    `%` 开头的魔法命令只会应用于该行。
- en: '`%lsmagic` lists the available options. We will discuss and show examples of
    some of the most useful ones. The most common magic command you will probably
    see is `%matplotlib` inline, which allows matplotlib figures to be displayed in
    the Notebook without having to explicitly use `plt.show()`.'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`%lsmagic` 列出了可用的选项。我们将讨论并展示一些最有用的示例。你可能最常见的魔法命令是 `%matplotlib inline`，它允许在
    Jupyter Notebook 中显示 matplotlib 图形，而无需显式使用 `plt.show()`。'
- en: 'The timing functions are very handy and come in two varieties: a standard timer
    (`%time` or `%%time`) and a timer that measures the average runtime of many iterations
    (`%timeit` and `%%timeit`).'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 定时功能非常实用，有两种类型：标准计时器（`%time` 或 `%%time`）和测量多个迭代平均运行时间的计时器（`%timeit` 和 `%%timeit`）。
- en: Note
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Notice how list comprehensions are quicker than loops in Python. This can be
    seen by comparing the wall time for the first and second cell, where the same
    calculation is done significantly faster with the list comprehension.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，列表推导在 Python 中比循环更快。这可以通过比较第一个和第二个单元格的墙时间来看，其中相同的计算在列表推导中显著更快。
- en: Run the cells in the `pwd`), what's in the directory (`ls`), make new folders
    (`mkdir`), and write file contents (`cat`/`head`/`tail`).
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 `pwd` 的单元格，查看目录中的内容（`ls`），创建新文件夹（`mkdir`），以及写入文件内容（`cat`/`head`/`tail`）。
- en: Run the first cell in the **Using bash** in the notebook section.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在笔记本的 **使用 bash** 部分运行第一个单元格。
- en: 'This cell writes some text to a file in the working directory, prints the directory
    contents, prints an empty line, and then writes back the contents of the newly
    created file before removing it:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格会将一些文本写入工作目录中的文件，打印目录内容，打印空行，然后写回新创建的文件内容并删除该文件：
- en: '![Figure 1.15: Using Bash in Jupyter Notebooks](img/C13018_01_15.jpg)'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.15：在 Jupyter Notebook 中使用 Bash](img/C13018_01_15.jpg)'
- en: 'Figure 1.15: Using Bash in Jupyter Notebooks'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.15：在 Jupyter Notebook 中使用 Bash
- en: Run the cells containing only `ls` and `pwd`.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行仅包含 `ls` 和 `pwd` 的单元格。
- en: Note how we did not have to explicitly use the Bash magic command for these
    to work. There are plenty of external magic commands that can be installed. A
    popular one is `ipython-sql`, which allows for SQL code to be executed in cells.
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，我们无需显式使用 Bash 魔法命令，这些命令仍然可以正常工作。还有很多可以安装的外部魔法命令。一个流行的魔法命令是 `ipython-sql`，它允许在单元格中执行
    SQL 代码。
- en: 'Open a new terminal window and execute the following code to install ipython-sql:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的终端窗口，并执行以下代码来安装 ipython-sql：
- en: '[PRE4]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Figure 1.16: Installing ipython-sql using pip'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.16：使用 pip 安装 ipython-sql](img/C13018_01_16.jpg)'
- en: '](img/C13018_01_16.jpg)'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_16.jpg)'
- en: 'Figure 1.16: Installing ipython-sql using pip'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.16：通过pip安装ipython-sql
- en: 'Run the `%load_ext sql` cell to load the external command into the Notebook:![Figure
    1.17: Loading sql in Jupyter Notebooks'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`%load_ext sql`单元格将外部命令加载到Notebook中：![图 1.17：在Jupyter Notebook中加载sql
- en: '](img/C13018_01_17.jpg)'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_17.jpg)'
- en: 'Figure 1.17: Loading sql in Jupyter Notebooks'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.17：在Jupyter Notebook中加载sql
- en: This allows for connections to remote databases so that queries can be executed
    (and thereby documented) right inside the Notebook.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这允许连接到远程数据库，以便可以在Notebook中直接执行（并因此记录）查询。
- en: 'Run the cell containing the SQL sample query:![Figure 1.18: Running a sample
    SQL query'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行包含SQL示例查询的单元格：![图 1.18：运行示例SQL查询
- en: '](img/C13018_01_18.jpg)'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_18.jpg)'
- en: 'Figure 1.18: Running a sample SQL query'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.18：运行示例SQL查询
- en: Here, we first connect to the local sqlite source; however, this line could
    instead point to a specific database on a local or remote server. Then, we execute
    a simple `SELECT` to show how the cell has been converted to run SQL code instead
    of Python.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们首先连接到本地sqlite源；然而，这行代码也可以指向本地或远程服务器上的特定数据库。然后，我们执行一个简单的`SELECT`查询，展示如何将单元格转换为运行SQL代码而非Python代码。
- en: 'Install the version documentation tool now from the terminal using `pip`. Open
    up a new window and run the following code:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在从终端使用`pip`安装版本文档工具。打开一个新窗口并运行以下代码：
- en: '[PRE5]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Once installed, it can then be imported into any Notebook using `%load_ext version_information`.
    Finally, once loaded, it can be used to display the versions of each piece of
    software in the Notebook.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 安装完成后，可以通过`%load_ext version_information`将其导入到任何Notebook中。最后，一旦加载，它可以用来显示Notebook中每个软件的版本信息。
- en: The `%version_information commands helps with documentation`, but it does not
    come as standard with Jupyter. Like the SQL example we just saw, it can be installed
    from the command line with `pip`.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`%version_information`命令有助于文档编写，但它并不是Jupyter的标准功能。就像我们刚才看到的SQL示例一样，可以通过`pip`从命令行安装。'
- en: 'Run the cell that loads and calls the `version_information` command:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行加载并调用`version_information`命令的单元格：
- en: '![Figure 1.19: Version Information in Jupyter'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.19：Jupyter中的版本信息'
- en: '](img/C13018_01_19.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_19.jpg)'
- en: 'Figure 1.19: Version Information in Jupyter'
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.19：Jupyter中的版本信息
- en: Converting a Jupyter Notebook to a Python Script
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将Jupyter Notebook转换为Python脚本
- en: You can convert a Jupyter Notebook to a Python script. This is equivalent to
    copying and pasting the contents of each code cell into a single `.py` file. The
    Markdown sections are also included as comments.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将Jupyter Notebook转换为Python脚本。这相当于将每个代码单元格的内容复制并粘贴到一个`.py`文件中。Markdown部分也将作为注释包含其中。
- en: 'The conversion can be done from the `NotebookApp` or in the command line as
    follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 转换可以通过`NotebookApp`或命令行完成，如下所示：
- en: '[PRE6]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Figure 1.20: Converting a Jupyter Notebook into a Python Script'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.20：将Jupyter Notebook转换为Python脚本'
- en: '](img/C13018_01_20.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_20.jpg)'
- en: 'Figure 1.20: Converting a Jupyter Notebook into a Python Script'
  id: totrans-148
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.20：将Jupyter Notebook转换为Python脚本
- en: This is useful, for example, when you want to determine the library requirements
    for a Notebook using a tool such as `pipreqs`. This tool determines the libraries
    used in a project and exports them into a `requirements.txt` file (and it can
    be installed by running pip install `pipreqs`).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这在例如当你想使用`pipreqs`等工具来确定Notebook的库需求时非常有用。该工具确定项目中使用的库并将其导出到`requirements.txt`文件中（可以通过运行`pip
    install pipreqs`来安装）。
- en: 'The command is called from outside the folder containing your `.py` files.
    For example, if the `.py` files are inside a folder called `lesson-1`, you could
    do the following:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 命令从包含`.py`文件的文件夹外部调用。例如，如果`.py`文件位于名为`lesson-1`的文件夹中，可以执行以下操作：
- en: '[PRE7]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Figure 1.21: Determining library requirements using pipreqs'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.21：使用pipreqs确定库需求'
- en: '](img/C13018_01_21.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_21.jpg)'
- en: 'Figure 1.21: Determining library requirements using pipreqs'
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.21：使用pipreqs确定库需求
- en: 'The resulting `requirements.txt` file for `lesson-1-workbook.ipynb` looks like
    this:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 对`lesson-1-workbook.ipynb`的结果`requirements.txt`文件如下所示：
- en: '[PRE8]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Python Libraries
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python库
- en: Having now seen all the basics of Jupyter Notebooks, and even some more advanced
    features, we'll shift our attention to the Python libraries we'll be using in
    this book. Libraries, in general, extend the default set of Python functions.
    Examples of commonly used standard libraries are `datetime`, `time`, and `os`.
    These are called standard libraries because they come standard with every installation
    of Python.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了 Jupyter Notebooks 的所有基础知识，甚至一些更高级的功能后，我们将把注意力转向本书中将使用的 Python 库。库通常扩展了默认的
    Python 函数集。常用的标准库示例有 `datetime`、`time` 和 `os`。这些被称为标准库，因为它们在每次安装 Python 时都会默认包含。
- en: For data science with Python, the most important libraries are external, which
    means they do not come standard with Python.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Python 数据科学来说，最重要的库是外部库，也就是说，它们并不包含在 Python 的标准库中。
- en: The external data science libraries we'll be using in this book are NumPy, Pandas,
    Seaborn, matplotlib, scikit-learn, Requests, and Bokeh.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中我们将使用的外部数据科学库有：NumPy、Pandas、Seaborn、matplotlib、scikit-learn、Requests 和 Bokeh。
- en: Note
  id: totrans-161
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'A word of caution: It''s a good idea to import libraries using industry standards,
    for example, import numpy as np; this way, your code is more readable. Try to
    avoid doing things such as from numpy import *, as you may unwittingly overwrite
    functions. Furthermore, it''s often nice to have modules linked to the library
    via a dot (.) for code readability.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一句：最好按照行业标准导入库，例如，`import numpy as np`；这样代码更具可读性。尽量避免使用 `from numpy import
    *`，因为你可能会不小心覆盖函数。此外，通常将模块与库通过点（.）连接在一起，这样代码的可读性更好。
- en: Let's briefly introduce each.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要介绍一下每个库。
- en: '**NumPy** offers multi-dimensional data structures (arrays) on which operations
    can be performed far quicker than standard Python data structures (for example,
    lists). This is done in part by performing operations in the background using
    C. NumPy also offers various mathematical and data manipulation functions.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy** 提供了多维数据结构（数组），其操作速度比标准的 Python 数据结构（例如列表）要快得多。这部分是通过使用 C 在后台执行操作来实现的。NumPy
    还提供了各种数学和数据处理功能。'
- en: '`NaN` entries and computing statistical descriptions of the data. Working with
    Pandas DataFrames will be a big focus of this book.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NaN` 条目和计算数据的统计描述。本书将重点介绍 Pandas DataFrame 的使用。'
- en: '**Matplotlib** is a plotting tool inspired by the MATLAB platform. Those familiar
    with R can think of it as Python''s version of ggplot. It''s the most popular
    Python library for plotting figures and allows for a high level of customization.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib** 是一个受 MATLAB 平台启发的绘图工具。熟悉 R 的人可以将其视为 Python 版本的 ggplot。它是最流行的
    Python 绘图库，允许高度的自定义。'
- en: '**Seaborn** works as an extension to matplotlib, where various plotting tools
    useful for data science are included. Generally speaking, this allows for analysis
    to be done much faster than if you were to create the same things *manually* with
    libraries such as matplotlib and scikit-learn.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Seaborn** 是 matplotlib 的扩展，其中包括了许多对于数据科学非常有用的绘图工具。一般来说，这使得分析工作比使用像 matplotlib
    和 scikit-learn 这样的库手动创建相同的图形要更快。'
- en: '**scikit-learn** is the most commonly used machine learning library. It offers
    top-of-the-line algorithms and a very elegant API where models are instantiated
    and then *fit* with data. It also provides data processing modules and other tools
    useful for predictive analytics.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**scikit-learn** 是最常用的机器学习库。它提供了顶级的算法和非常优雅的 API，其中模型被实例化后，使用数据进行 *拟合*。它还提供数据处理模块和其他对于预测分析有用的工具。'
- en: '**Requests** is the go-to library for making HTTP requests. It makes it straightforward
    to get HTML from web pages and interface with APIs. For parsing the HTML, many
    choose BeautifulSoup4, which we will also cover in this book.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Requests** 是进行 HTTP 请求的首选库。它使得从网页获取 HTML 内容以及与 API 进行交互变得非常简单。对于 HTML 的解析，许多人选择使用
    BeautifulSoup4，这本书中也会涉及到它。'
- en: '**Bokeh** is an interactive visualization library. It functions similar to
    matplotlib, but allows us to add hover, zoom, click, and use other interactive
    tools to our plots. It also allows us to render and play with the plots inside
    our Jupyter Notebook.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Bokeh** 是一个交互式可视化库。它的功能类似于 matplotlib，但允许我们向图表中添加悬停、缩放、点击等交互工具。它还允许我们在 Jupyter
    Notebook 中渲染和操作图表。'
- en: Having introduced these libraries, let's go back to our Notebook and load them,
    by running the `import` statements. This will lead us into our first analysis,
    where we finally start working with a dataset.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍完这些库之后，让我们回到 Notebook，并通过运行 `import` 语句来加载它们。这将引导我们进入第一次分析，开始使用数据集。
- en: 'Exercise 3: Importing the External Libraries and Setting Up the Plotting Environment'
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3：导入外部库并设置绘图环境
- en: 'Open up the `lesson 1` Jupyter Notebook and scroll to the `Subtopic D: Python
    Libraries` section.'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '打开 `lesson 1` Jupyter Notebook，并滚动到 `Subtopic D: Python Libraries` 部分。'
- en: Just like for regular Python scripts, libraries can be imported into the Notebook
    at any time. It's best practice to put the majority of the packages you use at
    the top of the file. Sometimes it makes sense to load things midway through the
    Notebook and that is completely fine.
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 就像常规的 Python 脚本一样，库可以随时导入到 Notebook 中。最好的做法是将大多数使用的包放在文件的顶部。有时，在 Notebook 中间加载库也是有意义的，完全没问题。
- en: 'Run the cells to import the external libraries and set the plotting options:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行单元格以导入外部库并设置绘图选项：
- en: '![Figure 1.22: Importing Python libraries'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.22：导入 Python 库'
- en: '](img/C13018_01_22.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_22.jpg)'
- en: 'Figure 1.22: Importing Python libraries'
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.22：导入 Python 库
- en: 'For a nice Notebook setup, it''s often useful to set various options along
    with the imports at the top. For example, the following can be run to change the
    figure appearance to something more aesthetically pleasing than the matplotlib
    and Seaborn defaults:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个良好的 Notebook 设置，通常将各种选项和导入放在顶部非常有用。例如，下面的代码可以运行，改变图形的外观，使其看起来比 matplotlib
    和 Seaborn 的默认设置更具美感：
- en: '[PRE9]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: So far in this book, we've gone over the basics of using Jupyter Notebooks for
    data science. We started by exploring the platform and finding our way around
    the interface. Then, we discussed the most useful features, which include tab
    completion and magic functions. Finally, we introduced the Python libraries we'll
    be using in this book.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本书中，我们已经介绍了使用 Jupyter Notebook 进行数据科学的基础知识。我们从探索平台并熟悉界面开始。接着，我们讨论了最有用的特性，包括选项卡补全和魔法函数。最后，我们介绍了本书中将要使用的
    Python 库。
- en: The next section will be very interactive as we perform our first analysis together
    using the Jupyter Notebook.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分将非常互动，我们将一起使用 Jupyter Notebook 进行第一次分析。
- en: Our First Analysis - The Boston Housing Dataset
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的第一次分析 - 波士顿房价数据集
- en: So far, this chapter has focused on the features and basic usage of Jupyter.
    Now, we'll put this into practice and do some data exploration and analysis.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本章已集中介绍了 Jupyter 的特性和基本使用方法。现在，我们将付诸实践，进行一些数据探索和分析。
- en: The dataset we'll look at in this section is the so-called Boston housing dataset.
    It contains US census data concerning houses in various areas around the city
    of Boston. Each sample corresponds to a unique area and has about a dozen measures.
    We should think of samples as rows and measures as columns. The data was first
    published in 1978 and is quite small, containing only about 500 samples.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 本节我们将查看的 数据集 是所谓的波士顿房价数据集。它包含了有关波士顿市区各个地区的美国人口普查数据。每个样本对应一个独特的地区，并且有大约十几个测量值。我们应该把样本看作行，把测量值看作列。该数据集首次发布于
    1978 年，非常小，只有大约 500 个样本。
- en: Now that we know something about the context of the dataset, let's decide on
    a rough plan for the exploration and analysis. If applicable, this plan would
    accommodate the relevant question(s) under study. In this case, the goal is not
    to answer a question but to instead show Jupyter in action and illustrate some
    basic data analysis methods.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了数据集的背景，接下来让我们决定一个大致的探索和分析计划。如果适用，这个计划将包括相关的研究问题。在这种情况下，目标不是回答一个问题，而是展示
    Jupyter 的实际应用，并说明一些基本的数据分析方法。
- en: 'Our general approach to this analysis will be to do the following:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对这个分析的总体方法将是：
- en: Load the data into Jupyter using a Pandas DataFrame
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Pandas DataFrame 将数据加载到 Jupyter 中
- en: Quantitatively understand the features
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定量理解特征
- en: Look for patterns and generate questions
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找模式并生成问题
- en: Answer the questions to the problems
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回答问题以解决问题
- en: Loading the Data into Jupyter Using a Pandas DataFrame
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Pandas DataFrame 将数据加载到 Jupyter 中
- en: Oftentimes, data is stored in tables, which means it can be saved as a **comma-separated
    variable** (**CSV**) file. This format, and many others, can be read into Python
    as a DataFrame object, using the Pandas library. Other common formats include
    **tab-separated variable** (**TSV**), SQL tables, and JSON data structures. Indeed,
    Pandas has support for all of these. In this example, however, we are not going
    to load the data this way because the dataset is available directly through scikit-learn.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 数据通常以表格形式存储，这意味着它可以保存为**逗号分隔值**（**CSV**）文件。此格式和其他许多格式可以通过 Pandas 库读取为 DataFrame
    对象。其他常见的格式包括**制表符分隔变量**（**TSV**）、SQL 表格和 JSON 数据结构。事实上，Pandas 支持所有这些格式。不过，在本示例中，我们不打算通过这种方式加载数据，因为数据集可以直接通过
    scikit-learn 获得。
- en: Note
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: An important part after loading data for analysis is ensuring that it's clean.
    For example, we would generally need to deal with missing data and ensure that
    all columns have the correct datatypes. The dataset we use in this section has
    already been cleaned, so we will not need to worry about this. However, we'll
    see messier data in the second chapter and explore techniques for dealing with
    it.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据进行分析后的一个重要部分是确保数据的清洁。例如，我们通常需要处理缺失数据，并确保所有列的数据类型正确。本节中使用的数据集已经清理过，因此我们不需要担心这一点。然而，在第二章中我们将看到更混乱的数据，并探索处理这些数据的技术。
- en: 'Exercise 4: Loading the Boston Housing Dataset'
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 4：加载波士顿房价数据集
- en: 'Scroll to `Subtopic A` of `Topic B: Our first Analysis: the Boston Housing
    Dataset` in chapter 1 of the Jupyter Notebook.'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '滚动到 Jupyter Notebook 第1章中 `Topic B: 我们的第一次分析：波士顿房价数据集` 的 `Subtopic A` 部分。'
- en: The Boston housing dataset can be accessed from the `sklearn.datasets` module
    using the `load_boston` method.
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以通过 `sklearn.datasets` 模块使用 `load_boston` 方法访问波士顿房价数据集。
- en: 'Run the first two cells in this section to load the Boston dataset and see
    the `datastructures` type:![Figure 1.23: Loading the Boston dataset'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行本节中的前两个单元格以加载波士顿数据集，并查看`datastructures`类型：![图 1.23：加载波士顿数据集](img/C13018_01_23.jpg)
- en: '](img/C13018_01_23.jpg)'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_23.jpg)'
- en: 'Figure 1.23: Loading the Boston dataset'
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.23：加载波士顿数据集
- en: The output of the second cell tells us that it's a scikit-learn `Bunch` object.
    Let's get some more information about that to understand what we are dealing with.
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二个单元格的输出告诉我们它是一个 scikit-learn 的`Bunch`对象。让我们进一步了解它，以便理解我们正在处理的内容。
- en: 'Run the next cell to import the base object from scikit-learn `utils` and print
    the docstring in our Notebook:![Figure 1.24: Importing base objects and printing
    the docstring'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行下一个单元格以从 scikit-learn `utils` 导入基础对象，并在我们的笔记本中打印文档字符串：![图 1.24：导入基础对象并打印文档字符串](img/C13018_01_24.jpg)
- en: '](img/C13018_01_24.jpg)'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_24.jpg)'
- en: 'Figure 1.24: Importing base objects and printing the docstring'
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.24：导入基础对象并打印文档字符串
- en: 'Print the field names (that is, the keys to the dictionary) by running the
    next cell. We find these fields to be self-explanatory: `[''DESCR'', ''target'',
    ''data'', ''feature_names'']`.'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行下一个单元格打印字段名称（即字典的键）。我们发现这些字段是自解释的：`['DESCR', 'target', 'data', 'feature_names']`。
- en: Run the next cell to print the dataset description contained in `boston['DESCR']`.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行下一个单元格以打印 `boston['DESCR']` 中包含的数据集描述。
- en: 'Note that in this call, we explicitly want to print the field value so that
    the Notebook renders the content in a more readable format than the string representation
    (that is, if we just type `boston[''DESCR'']` without wrapping it in a `print`
    statement). We then see the dataset information as we''ve previously summarized:'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，在此调用中，我们明确希望打印字段值，以便笔记本以比字符串表示更易读的格式呈现内容（即，如果我们只是输入 `boston['DESCR']` 而不将其包裹在
    `print` 语句中）。然后我们可以看到如前所述的数据集信息：
- en: '[PRE10]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Briefly read through the feature descriptions and/or describe them yourself.
    For the purposes of this tutorial, the most important fields to understand are
    `Attribute` `Information`). We will use this as reference during our analysis.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 简要阅读特征描述和/或自行描述它们。对于本教程来说，最重要的字段是`Attribute` `Information`。我们将在分析过程中以此为参考。
- en: Note
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'For the complete code, refer to the following: [https://bit.ly/2EL11cW](https://bit.ly/2EL11cW)'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完整代码请参考以下链接：[https://bit.ly/2EL11cW](https://bit.ly/2EL11cW)
- en: 'Now, we are going to create a Pandas DataFrame that contains the data. This
    is beneficial for a few reasons: all of our data will be contained in one object,
    there are useful and computationally efficient DataFrame methods we can use, and
    other libraries such as Seaborn have tools that integrate nicely with DataFrames.'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们将创建一个包含数据的 Pandas DataFrame。这样做有几个好处：所有数据都将存储在一个对象中，我们可以使用有用且计算效率高的 DataFrame
    方法，此外，像 Seaborn 这样的其他库也能很好地与 DataFrame 集成。
- en: In this case, we will create our DataFrame with the standard constructor method.
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将使用标准构造方法创建 DataFrame。
- en: 'Run the cell where Pandas is imported and the docstring is retrieved for `pd.DataFrame:`![Figure
    1.25: Retrieving the docstring for pd.DataFrame'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行导入 Pandas 并检索 `pd.DataFrame` 文档字符串的单元格：![图 1.25：检索 pd.DataFrame 的文档字符串
- en: '](img/C13018_01_25.jpg)'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_25.jpg)'
- en: 'Figure 1.25: Retrieving the docstring for pd.DataFrame'
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.25：检索 pd.DataFrame 的文档字符串
- en: The docstring reveals the DataFrame input parameters. We want to feed in `boston['data']`
    for the data and use `boston['feature_names']` for the headers.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文档字符串揭示了 DataFrame 输入参数。我们希望将 `boston['data']` 作为数据输入，并使用 `boston['feature_names']`
    作为列名。
- en: 'Run the next few cells to print the data, its shape, and the feature names:![Figure
    1.26: Printing data, shape, and feature names'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行接下来的几个单元格，打印数据、其形状和特征名：![图 1.26：打印数据、形状和特征名
- en: '](img/C13018_01_26.jpg)'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_26.jpg)'
- en: 'Figure 1.26: Printing data, shape, and feature names'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.26：打印数据、形状和特征名
- en: Looking at the output, we see that our data is in a 2D NumPy array. Running
    the command `boston['data'].shape` returns the length (number of samples) and
    the number of features as the first and second outputs, respectively.
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从输出中，我们看到数据是一个二维的 NumPy 数组。运行命令 `boston['data'].shape` 会返回长度（样本数）和特征数量，分别作为第一个和第二个输出。
- en: 'Load the data into a Pandas DataFrame `df` by running the following:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码将数据加载到 Pandas DataFrame `df` 中：
- en: '[PRE11]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In machine learning, the variable that is being modeled is called the target
    variable; it's what you are trying to predict given the features. For this dataset,
    the suggested target is **MEDV**, the median house value in 1,000s of dollars.
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在机器学习中，被建模的变量称为目标变量；它是你试图根据特征预测的内容。对于这个数据集，建议的目标是 **MEDV**，即以千美元为单位的房屋中位数价格。
- en: 'Run the next cell to see the shape of the target:![Figure 1.27: Code for viewing
    the shape of the target'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行下一个单元格查看目标的形状：![图 1.27：查看目标形状的代码
- en: '](img/C13018_01_27.jpg)'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_27.jpg)'
- en: 'Figure 1.27: Code for viewing the shape of the target'
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.27：查看目标形状的代码
- en: We see that it has the same length as the features, which is what we expect.
    It can therefore be added as a new column to the DataFrame.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们看到它的长度与特征相同，这是我们预期的。因此，可以将其作为新列添加到 DataFrame 中。
- en: 'Add the target variable to df by running the cell with the following:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码将目标变量添加到 df 中：
- en: '[PRE12]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Move the target variable to the front of `df` by running the cell with the
    following code:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码，将目标变量移到 `df` 的前面：
- en: '[PRE13]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This is done to distinguish the target from our features by storing it to the
    front of our DataFrame.
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这样做是为了通过将目标存储在 DataFrame 的前面，区分目标和特征。
- en: Here, we introduce a dummy variable `y` to hold a copy of the target column
    before removing it from the DataFrame. We then use the Pandas concatenation function
    to combine it with the remaining DataFrame along the 1st axis (as opposed to the
    0th axis, which combines rows).
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们引入一个虚拟变量 `y` 来保存目标列的副本，然后将其从 DataFrame 中移除。接着，我们使用 Pandas 的连接函数将其与剩余的
    DataFrame 沿着第 1 轴（而不是第 0 轴，即行方向）连接。
- en: Note
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You will often see dot notation used to reference DataFrame columns. For example,
    previously we could have done `y = df.MEDV.copy()`. This does not work for deleting
    columns, however; `del df.MEDV` would raise an error.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将经常看到使用点表示法来引用 DataFrame 的列。例如，之前我们可以使用 `y = df.MEDV.copy()`。然而，这种方法无法删除列；`del
    df.MEDV` 会引发错误。
- en: 'Implement `df.head()` or `df.tail()` to glimpse the data and `len(df)` to verify
    that number of samples is what we expect. Run the next few cells to see the head,
    tail, and length of `df`:![Figure 1.28: Printing the head of the data frame df'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现 `df.head()` 或 `df.tail()` 来查看数据，使用 `len(df)` 来验证样本数量是否符合预期。运行接下来的几个单元格查看
    `df` 的头部、尾部和长度：![图 1.28：打印数据框 df 的前几行
- en: '](img/C13018_01_28.jpg)'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_28.jpg)'
- en: 'Figure 1.28: Printing the head of the data frame df'
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.28：打印数据框 df 的前几行
- en: '![Figure 1.29: Printing the tail of data frame df'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.29：打印数据框 df 的尾部'
- en: '](img/C13018_01_29.jpg)'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_29.jpg)'
- en: 'Figure 1.29: Printing the tail of data frame df'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.29：打印数据框 df 的尾部
- en: Each row is labeled with an index value, as seen in bold on the left side of
    the table. By default, these are a set of integers starting at 0 and incrementing
    by one for each row.
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每一行都有一个索引值，如表格左侧加粗显示的数字。默认情况下，这些索引是从 0 开始的整数，并且每行递增 1。
- en: Printing `df.dtypes` will show the datatype contained within each column. Run
    the next cell to see the datatypes of each column. For this dataset, we see that
    every field is a float and therefore most likely a continuous variable, including
    the target. This means that predicting the target variable is a regression problem.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印 `df.dtypes` 会显示每一列所包含的数据类型。运行下一个单元格查看每列的数据类型。对于这个数据集，我们看到每个字段都是浮动类型，因此很可能是连续变量，包括目标变量。这意味着预测目标变量是一个回归问题。
- en: 'Run `df.isnull()` to clean the dataset as Pandas automatically sets missing
    data as `NaN` values. To get the number of `NaN` values per column, we can do
    `df.isnull().sum()`:![Figure 1.30: Cleaning the dataset by identifying NaN values'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 `df.isnull()` 来清理数据集，因为 Pandas 会自动将缺失数据设置为 `NaN` 值。要获取每列的 `NaN` 值数量，可以执行
    `df.isnull().sum()`：![图 1.30：通过识别 NaN 值清理数据集
- en: '](img/C13018_01_30.jpg)'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_30.jpg)'
- en: 'Figure 1.30: Cleaning the dataset by identifying NaN values'
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.30：通过识别 NaN 值清理数据集
- en: '`df.isnull()` returns a Boolean frame of the same length as `df`.'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`df.isnull()` 返回一个与 `df` 长度相同的布尔值框架。'
- en: For this dataset, we see there are no `NaN` values, which means we have no immediate
    work to do in cleaning the data and can move on.
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于这个数据集，我们看到没有 `NaN` 值，这意味着我们不需要立即清理数据，可以继续进行后续操作。
- en: 'Remove some columns by running the cell that contains the following code:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行包含以下代码的单元格来移除一些列：
- en: '[PRE14]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This is done to simplify the analysis. We will focus on the remaining columns
    in more detail.
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这样做是为了简化分析。接下来，我们将更详细地关注剩余的列。
- en: Data Exploration
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据探索
- en: Since this is an entirely new dataset that we've never seen before, the first
    goal here is to understand the data. We've already seen the textual description
    of the data, which is important for qualitative understanding. We'll now compute
    a quantitative description.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个我们之前从未见过的新数据集，首要任务是理解数据。我们已经看到过数据的文本描述，这是理解数据的定性信息。接下来，我们将进行定量描述。
- en: 'Exercise 5: Analyzing the Boston Housing Dataset'
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 5：分析波士顿住房数据集
- en: 'Navigate to `Subtopic B: Data exploration` in the Jupyter Notebook and run
    the cell containing `df.describe()`:![Figure 1.31: Computation and output of statistical
    properties'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jupyter Notebook 中导航到 `子主题 B：数据探索`，并运行包含 `df.describe()` 的单元格：![图 1.31：统计属性的计算及输出
- en: '](img/C13018_01_31.jpg)'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_31.jpg)'
- en: 'Figure 1.31: Computation and output of statistical properties'
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.31：统计属性的计算及输出
- en: This computes various properties including the mean, standard deviation, minimum,
    and maximum for each column. This table gives a high-level idea of how everything
    is distributed. Note that we have taken the transform of the result by adding
    a `.T` to the output; this swaps the rows and columns.
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这会计算每列的各种统计属性，包括均值、标准差、最小值和最大值。这个表格提供了一个关于所有数据分布的总体概念。请注意，我们通过在输出结果后添加 `.T`
    来转换结果，这会交换行和列。
- en: Going forward with the analysis, we will specify a set of columns to focus on.
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在继续分析之前，我们将指定一组重点关注的列。
- en: 'Run the cell where these "focus columns" are defined:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行包含定义“重点列”内容的单元格：
- en: '[PRE15]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Display the aforementioned subset of columns of the DataFrame by running `df[cols].head()`:![Figure
    1.32: Displaying focus columns'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行 `df[cols].head()` 来显示上述数据框的子集：![图 1.32：显示重点列
- en: '](img/C13018_01_32.jpg)'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_32.jpg)'
- en: 'Figure 1.32: Displaying focus columns'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.32：显示重点列
- en: 'As a reminder, let''s recall what each of these columns is. From the dataset
    documentation, we have the following:'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了提醒自己，我们回顾一下每一列的含义。根据数据集文档，我们有以下信息：
- en: '[PRE16]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: To look for patterns in this data, we can start by calculating the pairwise
    correlations using `pd.DataFrame.corr`.
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了在数据中寻找模式，我们可以从计算成对相关性开始，使用 `pd.DataFrame.corr`。
- en: 'Calculate the pairwise correlations for our selected columns by running the
    cell containing the following code:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行包含以下代码的单元格来计算选定列的成对相关性：
- en: '[PRE17]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![Figure 1.33: Pairwise calculation of correlation'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.33：成对计算相关性'
- en: '](img/C13018_01_33.jpg)'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_33.jpg)'
- en: 'Figure 1.33: Pairwise calculation of correlation'
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.33：成对计算相关性
- en: This resulting table shows the correlation score between each set of values.
    Large positive scores indicate a strong positive (that is, in the same direction)
    correlation. As expected, we see maximum values of 1 on the diagonal.
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个结果表格显示了每一组值之间的相关性得分。较大的正得分表示强正相关（即方向相同）。如预期所示，我们在对角线看到最大值为 1。
- en: 'By default, Pandas calculates the standard correlation coefficient for each
    pair, which is also called the Pearson coefficient. This is defined as the covariance
    between two variables, divided by the product of their standard deviations:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 默认情况下，Pandas 会计算每对值的标准相关系数，这也叫做 Pearson 系数。其定义为两个变量的协方差除以它们标准差的乘积：
- en: '![](img/C13018_01_56.jpg)'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C13018_01_56.jpg)'
- en: 'The covariance, in turn, is defned as follows:'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 协方差的定义如下：
- en: '![](img/C13018_01_57.jpg)'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C13018_01_57.jpg)'
- en: Here, n is the number of samples, xi and yi are the individual samples being
    summed over, and X and Y are the means of each set.
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，n 是样本数量，xi 和 yi 是被求和的单个样本，X 和 Y 分别是每组数据的均值。
- en: Instead of straining our eyes to look at the preceding table, it's nicer to
    visualize it with a heatmap. This can be done easily with Seaborn.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与其使劲眯眼去看前面的表格，使用热图来可视化数据会更为直观。这可以通过 Seaborn 很容易实现。
- en: 'Run the next cell to initialize the plotting environment, as discussed earlier
    in the chapter. Then, to create the heatmap, run the cell containing the following
    code:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行下一个单元格来初始化绘图环境，正如本章前面所讨论的。然后，为了创建热图，运行包含以下代码的单元格：
- en: '[PRE18]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![Figure 1.34: Plot of the heat map for all variables'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.34：所有变量的热图绘制'
- en: '](img/C13018_01_34.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_34.jpg)'
- en: 'Figure 1.34: Plot of the heat map for all variables'
  id: totrans-287
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.34：所有变量的热图绘制
- en: We call `sns.heatmap` and pass the pairwise correlation matrix as input. We
    use a custom color palette here to override the Seaborn default. The function
    returns a `matplotlib.axes` object which is referenced by the variable `ax`.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调用 `sns.heatmap` 并将配对相关矩阵作为输入。我们使用自定义的色彩调色板来覆盖 Seaborn 的默认设置。该函数返回一个 `matplotlib.axes`
    对象，并由变量 `ax` 引用。
- en: The final figure is then saved as a high resolution PNG to the `figures` folder.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的图表会以高分辨率 PNG 格式保存到 `figures` 文件夹中。
- en: For the final step in our dataset exploration exercise, we'll visualize our
    data using Seaborn's `pairplot` function.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们数据集探索的最后一步，我们将使用 Seaborn 的 `pairplot` 函数来可视化数据。
- en: 'Visualize the DataFrame using Seaborn''s `pairplot` function. Run the cell
    containing the following code:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Seaborn 的 `pairplot` 函数可视化数据框。运行以下代码所在的单元格：
- en: '[PRE19]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![Figure 1.35: Data visualization using Seaborn'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.35：使用 Seaborn 进行数据可视化'
- en: '](img/C13018_01_35.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_35.jpg)'
- en: 'Figure 1.35: Data visualization using Seaborn'
  id: totrans-295
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.35：使用 Seaborn 进行数据可视化
- en: Note
  id: totrans-296
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Note that unsupervised learning techniques are outside the scope of this book.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，无监督学习技术超出了本书的讨论范围。
- en: 'Looking at the histograms on the diagonal, we see the following:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 查看对角线上的直方图，我们可以看到以下内容：
- en: '**a**: **RM** and **MEDV** have the closest shape to normal distributions.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '**a**：**RM** 和 **MEDV** 的分布形态最接近正态分布。'
- en: '**b**: **AGE** is skewed to the left and **LSTAT** is skewed to the right (this
    mayseem counterintuitive but skew is defined in terms of where the mean is positioned
    in relation to the max).'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '**b**：**AGE** 向左偏斜，**LSTAT** 向右偏斜（这可能看起来违反直觉，但偏斜是指均值相对于最大值的位置）。'
- en: '**c**: For **TAX**, we find a large amount of the distribution is around 700\.
    This is also evident from the scatter plots.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '**c**：对于 **TAX**，我们发现分布的大部分集中在 700 左右。这一点从散点图中也能看出来。'
- en: Taking a closer look at the `df.describe()`, the min and max of **MDEV** was
    5k and 50k, respectively. This suggests that median house values in the dataset
    were capped at 50k.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 详细查看 `df.describe()` 后，**MDEV** 的最小值和最大值分别为 5k 和 50k。这表明数据集中中位数房价的上限为 50k。
- en: Introduction to Predictive Analytics with Jupyter Notebooks
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Jupyter Notebooks 进行预测分析简介
- en: Continuing our analysis of the Boston housing dataset, we can see that it presents
    us with a regression problem where we predict a continuous target variable given
    a set of features. In particular, we'll be predicting the median house value (**MEDV**).
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 继续分析波士顿住房数据集，我们可以看到它为我们提供了一个回归问题，要求根据一组特征预测连续的目标变量。特别地，我们将预测中位数房价（**MEDV**）。
- en: We'll train models that take only one feature as input to make this prediction.
    This way, the models will be conceptually simple to understand and we can focus
    more on the technical details of the scikit-learn API. Then, in the next chapter,
    you'll be more comfortable dealing with the relatively complicated models.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将训练只使用一个特征作为输入的模型来进行预测。通过这种方式，模型在概念上会比较简单，便于理解，我们可以更加专注于 scikit-learn API
    的技术细节。然后，在下一章，你将能更轻松地处理相对复杂的模型。
- en: 'Exercise 6: Applying Linear Models With Seaborn and Scikit-learn'
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 6：使用 Seaborn 和 Scikit-learn 应用线性模型
- en: 'Scroll to `Subtopic C: Introduction to predictive analytics` in the Jupyter
    Notebook and look just above at the pairplot we created in the previous section.
    In particular, look at the scatter plots in the bottom-left corner:![Figure 1.36:
    Scatter plots for MEDV and LSTAT'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '滚动到 Jupyter Notebook 中的`子话题 C: 预测分析简介`，并查看上方我们在前一部分中创建的 pairplot。特别是，查看左下角的散点图：![图
    1.36：MEDV 和 LSTAT 的散点图'
- en: '](img/C13018_01_36.jpg)'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_36.jpg)'
- en: 'Figure 1.36: Scatter plots for MEDV and LSTAT'
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.36：MEDV 和 LSTAT 的散点图
- en: 'Note how the number of rooms per house (**RM**) and the % of the population
    that is lower class (**LSTAT**) are highly correlated with the median house value
    (**MDEV**). Let''s pose the following question: how well can we predict **MDEV**
    given these variables?'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，每个房屋的房间数 (**RM**) 和人口中属于低收入阶层的百分比 (**LSTAT**) 与中位房价 (**MDEV**) 高度相关。让我们提出以下问题：基于这些变量，我们能多好地预测
    **MDEV**？
- en: To help answer this, let's first visualize the relationships using Seaborn.
    We will draw the scatter plots along with the line of best fit linear models.
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了帮助回答这个问题，让我们首先使用 Seaborn 可视化这些关系。我们将绘制散点图并加上最佳拟合线性模型。
- en: 'Draw scatter plots along with the linear models by running the cell that contains
    the following:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行包含以下内容的单元格，绘制带有线性模型的散点图：
- en: '[PRE20]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![Figure 1.37: Drawing scatter plots using linear models'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.37：使用线性模型绘制散点图'
- en: '](img/C13018_01_37.jpg)'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_37.jpg)'
- en: 'Figure 1.37: Drawing scatter plots using linear models'
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.37：使用线性模型绘制散点图
- en: The line of best fit is calculated by minimizing the ordinary least squares
    error function, something Seaborn does automatically when we call the `regplot`
    function. Also note the shaded areas around the lines, which represent 95% confidence
    intervals.
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最佳拟合线是通过最小化普通最小二乘误差函数计算得出的，这是 Seaborn 在我们调用 `regplot` 函数时自动完成的。还要注意线条周围的阴影区域，它们表示
    95% 的置信区间。
- en: Note
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: These 95% confidence intervals are calculated by taking the standard deviation
    of data in bins perpendicular to the line of best fit, effectively determining
    the confidence intervals at each point along the line of best fit. In practice,
    this involves Seaborn bootstrapping the data, a process where new data is created
    through random sampling with replacement. The number of bootstrapped samples is
    automatically determined based on the size of the dataset, but can be manually
    set as well by passing the `n_boot` argument.
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些 95% 置信区间是通过计算与最佳拟合线垂直的每个数据区间的标准差来确定的，实际上是确定每个点的置信区间。在实践中，这涉及到 Seaborn 对数据进行自助抽样处理，这是通过随机抽样并且允许重复的方式生成新数据。自助抽样的样本数量是根据数据集的大小自动确定的，但也可以通过传递
    `n_boot` 参数手动设置。
- en: 'Plot the residuals using Seaborn by running the cell containing the following:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下单元格，使用 Seaborn 绘制残差图：
- en: '[PRE21]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![Figure 1.38: Plotting residuals using Seaborn'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.38：使用 Seaborn 绘制残差图'
- en: '](img/C13018_01_38.jpg)'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_38.jpg)'
- en: 'Figure 1.38: Plotting residuals using Seaborn'
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.38：使用 Seaborn 绘制残差图
- en: Each point on these residual plots is the difference between that sample (`y`)
    and the linear model prediction (`ŷ`). Residuals greater than zero are data points
    that would be underestimated by the model. Likewise, residuals less than zero
    are data points that would be overestimated by the model.
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些残差图上的每个点代表该样本 (`y`) 和线性模型预测值 (`ŷ`) 之间的差异。大于零的残差表示模型会低估这些数据点。反之，低于零的残差则表示模型会高估这些数据点。
- en: Patterns in these plots can indicate suboptimal modeling. In each preceding
    case, we see diagonally arranged scatter points in the positive region. These
    are caused by the $50,000 cap on **MEDV**. The **RM** data is clustered nicely
    around 0, which indicates a good fit. On the other hand, **LSTAT** appears to
    be clustered lower than 0.
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些图中的模式可能表明建模效果不佳。在每个前述案例中，我们看到正区间内呈对角线排列的散点。这些是由于 **MEDV** 被限制在 $50,000 上限所造成的。**RM**
    数据较好地聚集在 0 附近，表示拟合良好。另一方面，**LSTAT** 数据似乎聚集在低于 0 的位置。
- en: 'Define a function using sci-kit learn that calculates the line of best fit
    and mean squared error, by running the cell that contains the following:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个使用scikit-learn的函数来计算最佳拟合线和均方误差，方法是运行包含以下内容的单元格：
- en: '[PRE22]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Note
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'For complete code, refer to the following: [https://bit.ly/2JgPZdU](https://bit.ly/2JgPZdU)'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完整代码请参见以下链接：[https://bit.ly/2JgPZdU](https://bit.ly/2JgPZdU)
- en: In the `get_mse` function, we first assign the variables `y` and `x` to the
    target MDEV and the dependent feature, respectively. These are cast as NumPy arrays
    by calling the `values` attribute. The dependent features array is reshaped to
    the format expected by scikit-learn; this is only necessary when modeling a one-dimensional
    feature space. The model is then instantiated and fitted on the data. For linear
    regression, the fitting consists of computing the model parameters using the ordinary
    least squares method (minimizing the sum of squared errors for each sample). Finally,
    after determining the parameters, we predict the target variable and use the results
    to calculate the **MSE**.
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在`get_mse`函数中，我们首先将变量`y`和`x`分别分配给目标MDEV和自变量特征。这些变量通过调用`values`属性被转换为NumPy数组。自变量特征数组被重塑为scikit-learn期望的格式；当建模一维特征空间时，只有在这种情况下才需要重塑。然后，模型被实例化并在数据上进行拟合。对于线性回归，拟合过程包括使用普通最小二乘法计算模型参数（最小化每个样本的误差平方和）。最后，在确定参数后，我们预测目标变量并使用结果计算**MSE**。
- en: 'Call the `get_mse` function for both **RM** and **LSTAT**, by running the cell
    containing the following:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行包含以下内容的单元格，调用`get_mse`函数来处理**RM**和**LSTAT**：
- en: '[PRE23]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![Figure 1.39: Calling the get_mse function for RM and LSTAT'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.39：调用`get_mse`函数计算RM和LSTAT'
- en: '](img/C13018_01_39.jpg)'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_39.jpg)'
- en: 'Figure 1.39: Calling the get_mse function for RM and LSTAT'
  id: totrans-336
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.39：调用`get_mse`函数计算RM和LSTAT
- en: Comparing the **MSE**, it turns out the error is slightly lower for **LSTAT**.
    Looking back to the scatter plots, however, it appears that we might have even
    better success using a polynomial model for **LSTAT**. In the next activity, we
    will test this by computing a third-order polynomial model with scikit-learn.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 比较**MSE**，结果显示**LSTAT**的误差略低。然而，回顾散点图，我们可能会发现使用多项式模型对**LSTAT**进行建模会更成功。在接下来的活动中，我们将通过使用scikit-learn计算一个三次多项式模型来验证这一点。
- en: 'Forgetting about our Boston housing dataset for a minute, consider another
    real-world situation where you might employ polynomial regression. The following
    example is modeling weather data. In the following plot, we see temperatures (lines)
    and precipitations (bars) for Vancouver, BC, Canada:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时忘记波士顿住房数据集，考虑另一个可能会用到多项式回归的实际情况。以下是一个建模天气数据的示例。在接下来的图表中，我们可以看到温哥华（加拿大BC省）的温度（线条）和降水量（条形）：
- en: '![Figure 1.40: Visualizing weather data for Vancouver, Canada'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.40：可视化温哥华（加拿大）的天气数据'
- en: '](img/C13018_01_40.jpg)'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_40.jpg)'
- en: 'Figure 1.40: Visualizing weather data for Vancouver, Canada'
  id: totrans-341
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.40：可视化温哥华（加拿大）的天气数据
- en: Any of these fields are likely to be fit quite well by a fourth-order polynomial.
    This would be a very valuable model to have, for example, if you were interested
    in predicting the temperature or precipitation for a continuous range of dates.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这些字段中的任何一个都可能非常适合由四次多项式进行拟合。如果你对预测某个连续日期范围内的温度或降水量感兴趣，那么这个模型会非常有价值。
- en: Note
  id: totrans-343
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find the data source for this here: [http://climate.weather.gc.ca/climate_normals/results_e.](http://climate.weather.gc.ca/climate_normals/results_e.html?stnID=888)html?stnID=888.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在此找到数据源：[http://climate.weather.gc.ca/climate_normals/results_e.](http://climate.weather.gc.ca/climate_normals/results_e.html?stnID=888)html?stnID=888。
- en: 'Activity 1: Building a Third-Order Polynomial Model'
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 1：构建三次多项式模型
- en: 'Shifting our attention back to the Boston housing dataset, we would like to
    build a third-order polynomial model to compare against the linear one. Recall
    the actual problem we are trying to solve: predicting the median house value,
    given the lower class population percentage. This model could benefit a prospective
    Boston house purchaser who cares about how much of their community would be lower
    class.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 将注意力重新转回波士顿住房数据集，我们希望构建一个三次多项式模型来与线性模型进行比较。回想一下我们要解决的实际问题：给定低收入人口的百分比，预测中位数房价。这个模型对潜在的波士顿购房者会有帮助，尤其是那些关心自己社区低收入人口比例的人。
- en: 'Our aim is to use scikit-learn to fit a polynomial regression model to predict
    the median house value (**MEDV**), given the **LSTAT** values. We are hoping to
    build a model that has a lower mean-squared error (**MSE**). In order to achieve
    this, the following steps have to be executed:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是使用scikit-learn拟合一个多项式回归模型，以预测中位数房屋价值（**MEDV**），给定**LSTAT**值。我们希望构建一个具有较低均方误差（**MSE**）的模型。为了实现这一目标，需要执行以下步骤：
- en: Scroll to the empty cells at the bottom of `Subtopic C` in your Jupyter Notebook.
    These will be found beneath the linear-model `Activity` heading.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到`Subtopic C`下方Jupyter Notebook中的空单元格。这些单元格位于线性模型`Activity`标题下方。
- en: Note
  id: totrans-349
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You should fill these empty cells in with code as we complete the activity.
    You may need to insert new cells as these become filled up; please do so as needed.
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在我们完成活动时，您应该使用代码填充这些空单元格。随着单元格填充，您可能需要插入新的单元格；请根据需要进行操作。
- en: Pull out our dependent feature from and target variable from `df`.
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`df`中提取我们的依赖特征和目标变量。
- en: Verify what `x` looks like by printing the first three samples.
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过打印前三个样本，验证`x`的样子。
- en: Transform `x` into "polynomial features" by importing the appropriate transformation
    tool from scikit-
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过从scikit-learn导入适当的转换工具，将`x`转换为“多项式特征”。
- en: Transform the `x`) by running the `fit_transform` method and build the polynomial
    feature set.
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行`fit_transform`方法并构建多项式特征集，转换`x`。
- en: Verify what `x_poly` looks like by printing the first few samples.
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过打印前几个样本，验证`x_poly`的样子。
- en: Import the `LinearRegression` class and build our linear classification model
    the same way as done while calculating the MSE.
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`LinearRegression`类，并像计算MSE时一样构建我们的线性分类模型。
- en: Extract the coefficients and print the polynomial model.
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取系数并打印多项式模型。
- en: Determine the predicted values for each sample and calculate the residuals.
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定每个样本的预测值并计算残差。
- en: Print some of the residual values.
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印一些残差值。
- en: Print the MSE for the third-order polynomial model.
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印三阶多项式模型的MSE。
- en: Plot the polynomial model along with the samples.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制多项式模型及其样本。
- en: Plot the residuals.
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制残差。
- en: Note
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The detailed steps along with the solutions are presented in the *Appendix A*
    (pg. no. 144).
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 详细步骤和解决方案见*附录A*（第144页）。
- en: Having successfully modeled the data using a polynomial model, let's finish
    up this chapter by looking at categorical features. In particular, we are going
    to build a set of categorical features and use them to explore the dataset in
    more detail.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 成功使用多项式模型建模数据后，让我们通过查看分类特征来结束这一章。特别是，我们将构建一组分类特征，并使用它们更详细地探索数据集。
- en: Using Categorical Features for Segmentation Analysis
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用分类特征进行分段分析
- en: Often, we find datasets where there are a mix of continuous and categorical
    fields. In such cases, we can learn about our data and find patterns by segmenting
    the continuous variables with the categorical fields.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们会遇到包含连续字段和分类字段的数据集。在这种情况下，我们可以通过将连续变量与分类字段结合来学习数据并发现模式。
- en: As a specific example, imagine you are evaluating the return on investment from
    an ad campaign. The data you have access to contain measures of some calculated
    **return on investment** (**ROI**) metric. These values were calculated and recorded
    daily and you are analyzing data from the previous year. You have been tasked
    with finding data-driven insights on ways to improve the ad campaign. Looking
    at the ROI daily time series, you see a weekly oscillation in the data. Segmenting
    by day of the week, you find the following ROI distributions (where 0 represents
    the first day of the week and 6 represents the last).
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个具体示例，假设你正在评估广告活动的投资回报率。你能访问的数据包含一些计算得到的**投资回报率**（**ROI**）指标。这些值是每日计算并记录的，你正在分析去年的数据。你的任务是从数据中获取可操作的见解，找出改进广告活动的方法。在查看ROI的每日时间序列时，你会看到数据中的每周波动。通过按星期几分段，你发现了以下ROI分布（其中0代表一周的第一天，6代表最后一天）。
- en: '![Figure 1.48: A sample violin plot for return on investment'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.48：投资回报率的示例小提琴图'
- en: '](img/C13018_01_48.jpg)'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_48.jpg)'
- en: 'Figure 1.41: A sample violin plot for return on investment'
  id: totrans-371
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.41：投资回报率的示例小提琴图
- en: Since we don't have any categorical fields in the Boston housing dataset we
    are working with, we'll create one by effectively discretizing a continuous field.
    In our case, this will involve binning the data into "low", "medium", and "high"
    categories. It's important to note that we are not simply creating a categorical
    data field to illustrate the data analysis concepts in this section. As will be
    seen, doing this can reveal insights from the data that would otherwise be difficult
    to notice or altogether unavailable.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在使用的波士顿住房数据集中没有任何类别字段，我们将通过有效地离散化一个连续字段来创建一个。在我们的例子中，这将涉及将数据分为“低”、“中”和“高”三个类别。需要注意的是，我们并非单纯地创建一个类别数据字段来说明本节中的数据分析概念。正如我们将看到的那样，做这件事可以揭示一些数据中的洞察，这些洞察否则可能会难以察觉或完全无法获取。
- en: 'Exercise 7: Creating Categorical Fields From Continuous Variables and Make
    Segmented Visualizations'
  id: totrans-373
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 7：从连续变量创建类别字段并制作分段可视化
- en: 'Scroll up to the pairplot in the Jupyter Notebook where we compared **MEDV**,
    **LSTAT**, **TAX**, **AGE**, and **RM**:![Figure 1.49: A comparison of plots for
    MEDV, LSTAT, TAX, AGE, and RM'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向上滚动到Jupyter Notebook中的pairplot，我们比较了**MEDV**、**LSTAT**、**TAX**、**AGE**和**RM**：!
- en: '](img/C13018_01_49.jpg)'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_49.jpg)'
- en: 'Figure 1.42: A comparison of plots for MEDV, LSTAT, TAX, AGE, and RM'
  id: totrans-376
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.42：MEDV、LSTAT、TAX、AGE 和 RM 的图表比较
- en: Take a look at the panels containing **AGE**. As a reminder, this feature is
    defined as the proportion of *owner-occupied units built prior to 1940*. We are
    going to convert this feature to a categorical variable. Once it's been converted,
    we'll be able to replot this figure with each panel segmented by color according
    to the age category.
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看一下包含**AGE**（年龄）的面板。提醒一下，这个特征被定义为*1940年之前建成的业主自住单元的比例*。我们将把这个特征转换为一个类别变量。转换后，我们将能够重新绘制这个图，每个面板根据年龄类别通过颜色进行分段。
- en: 'Scroll down to `Subtopic D: Building and exploring categorical features` and
    click into the first cell. Type and execute the following to plot the `kde_kws={''lw'':
    0}` in order to bypass plotting the kernel density estimate in the preceding figure.'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '向下滚动到`Subtopic D: Building and exploring categorical features`并点击第一个单元格。输入并执行以下命令以绘制`kde_kws={''lw'':
    0}`，以跳过前图中的核密度估计图。'
- en: Looking at the plot, there are very few samples with low **AGE**, whereas there
    are far more with a very large **AGE**. This is indicated by the steepness of
    the distribution on the far right-hand side.
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看这个图，低**AGE**（年龄）样本非常少，而**AGE**较大的样本则多得多。这可以从分布在最右侧的陡峭度看出来。
- en: 'The red lines indicate 1/3 and 2/3 points in the distribution. Looking at the
    places where our distribution intercepts these horizontal lines, we can see that
    only about 33% of the samples have **AGE** less than 55 and 33% of the samples
    have **AGE** greater than 90! In other words, a third of the housing communities
    have less than 55% of homes built prior to 1940\. These would be considered relatively
    new communities. On the other end of the spectrum, another third of the housing
    communities have over 90% of homes built prior to 1940\. These would be considered
    very old. We''ll use the places where the red horizontal lines intercept the distribution
    as a guide to split the feature into categories: **Relatively New**, **Relatively
    Old**, and **Very Old**.'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 红线表示分布中的1/3和2/3点。观察分布与这些水平线的交点，我们可以看到，只有大约33%的样本**AGE**小于55，33%的样本**AGE**大于90！换句话说，三分之一的住宅区有不到55%的房屋是在1940年之前建成的。这些可以视为相对较新的社区。另一方面，另三分之一的住宅区有超过90%的房屋是在1940年之前建成的。这些被认为是非常老的社区。我们将使用红色水平线与分布交点的位置作为指南，将该特征分为：**相对较新**、**相对较旧**和**非常旧**三个类别。
- en: 'Create a new categorical feature and set the segmentation points by running
    the following code:'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的类别特征，并通过运行以下代码设置分割点：
- en: '[PRE24]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here, we are using the very handy Pandas method apply, which applies a function
    to a given column or set of columns. The function being applied, in this case
    `get_age_category`, should take one argument representing a row of data and return
    one value for the new column. In this case, the row of data being passed is just
    a single value, the `pd.Series.str` can accomplish the same thing much faster.
    Therefore, it's advised to avoid using it if possible, especially when working
    with large datasets. We'll see some examples of vectorized methods in the upcoming
    chapter.
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用了非常方便的Pandas方法apply，它将一个函数应用于给定的列或一组列。在这种情况下，应用的函数是`get_age_category`，它应该接受表示数据行的一个参数，并为新列返回一个值。在这种情况下，传递的数据行只是一个单独的值，`pd.Series.str`可以更快地完成同样的事情。因此，建议避免使用它，特别是在处理大型数据集时。在即将来临的章节中，我们将看到一些矢量化方法的示例。
- en: 'Verify the number of samples we''ve grouped into each age category by typing
    `df.groupby(''AGE_category'').size()` into a new cell and running it:![Figure
    1.51: Verifying the grouping of variables'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在新的单元格中键入`df.groupby('AGE_category').size()`并运行来验证我们已经分组到每个年龄类别中的样本数：![图 1.51：验证变量的分组
- en: '](img/C13018_01_51.jpg)'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_51.jpg)'
- en: 'Figure 1.44: Verifying the grouping of variables'
  id: totrans-386
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.44：验证变量的分组
- en: Looking at the result, it can be seen that two class sizes are fairly equal,
    and the `AGE_category`.
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从结果来看，可以看到两个类大小相当，而`AGE_category`。
- en: 'Construct a violin plot by running the following code:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码构建小提琴图：
- en: '[PRE25]'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![Figure 1.52: Violin plot for AGE_category and MEDV'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.52：AGE_category 和 MEDV 的小提琴图'
- en: '](img/C13018_01_52.jpg)'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_52.jpg)'
- en: 'Figure 1.45: Violin plot for AGE_category and MEDV'
  id: totrans-392
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.45：AGE_category 和 MEDV 的小提琴图
- en: The violin plot shows a kernel density estimate of the median house value distribution
    for each age category. We see that they all resemble a normal distribution. The
    Very Old group contains the lowest median house value samples and has a relatively
    large width, whereas the other groups are more tightly centered around their average.
    The young group is skewed to the high end, which is evident from the enlarged
    right half and position of the white dot in the thick black line within the body
    of the distribution.
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 小提琴图显示了每个年龄类别中位房屋价值分布的核密度估计。我们看到它们都类似于正态分布。非常老的组包含最低的中位房屋价值样本，并具有相对较大的宽度，而其他组则更紧密地围绕它们的平均值。年轻组偏向于高端，这可以从分布体内的厚黑线中的白色点的右侧扩展和位置看出。
- en: This white dot represents the mean and the thick black line spans roughly 50%
    of the population (it fills to the first quantile on either side of the white
    dot). The thin black line represents boxplot whiskers and spans 95% of the population.
    This inner visualization can be modified to show the individual data points instead
    by passing `inner='point'` to `sns.violinplot()`. Let's do that now.
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个白色点表示均值，而厚黑线大致跨越了人口的 50%（填充到白色点两侧的第一个四分位数）。细黑线表示箱线图的须，跨越了人口的 95%。可以通过向`sns.violinplot()`传递`inner='point'`来修改这个内部可视化，我们现在来做一下。
- en: 'Re-construct the violin plot adding the `inner=''point''` argument to the `sns.violinplot`
    call:![Figure 1.53: Violin plot for AGE_category and MEDV with the inner = ''point''
    argument'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新构建小提琴图，在`sns.violinplot`调用中添加`inner='point'`参数：![图 1.53：AGE_category 和 MEDV
    的小提琴图，内部设置为 'point' 参数
- en: '](img/C13018_01_53.jpg)'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_53.jpg)'
- en: 'Figure 1.46: Violin plot for AGE_category and MEDV with the inner = ''point''
    argument'
  id: totrans-397
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.46：AGE_category 和 MEDV 的小提琴图，内部设置为 'point' 参数
- en: It's good to make plots like this for test purposes in order to see how the
    underlying data connects to the visual. We can see, for example, how there are
    no median house values lower than roughly $16,000 for the **Relatively New** segment,
    and therefore the distribution tail actually contains no data. Due to the small
    size of our dataset (only about 500 rows), we can see this is the case for each
    segment.
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了测试目的，制作这样的图表是很好的，以便看到底层数据如何连接到视觉。例如，我们可以看到对于**相对新**部分，没有中位数低于大约 $16,000 的房屋价值数据，因此分布尾部实际上不包含数据。由于我们数据集很小（只有约
    500 行），我们可以看到每个段落都是这样的情况。
- en: 'Re-construct the pairplot from earlier, but now include color labels for each
    `hue` argument, as follows:'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新构建先前的pairplot，但现在包括每个`hue`参数的颜色标签，如下所示：
- en: '[PRE26]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![Figure 1.54: Re-constructing pairplot for all variables using color labels
    for AGE'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.54：使用年龄颜色标签重新构建所有变量的pairplot'
- en: '](img/C13018_01_54.jpg)'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13018_01_54.jpg)'
- en: 'Figure 1.47: Re-constructing pairplot for all variables using color labels
    for AGE'
  id: totrans-403
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.47：使用AGE的颜色标签重新构建所有变量的pairplot
- en: Looking at the histograms, the underlying distributions of each segment appear
    similar for **RM** and **TAX**. The **LSTAT** distributions, on the other hand,
    look more distinct. We can focus on them in more detail by again using a violin plot.
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从直方图来看，**RM**和**TAX**每个区段的基础分布相似。另一方面，**LSTAT**的分布看起来更加不同。我们可以通过再次使用小提琴图，进一步关注这些差异。
- en: 'Re-construct a violin plot comparing the LSTAT distributions for each `AGE_category`
    segment:'
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新构建一个小提琴图，比较每个`AGE_category`区段的LSTAT分布：
- en: '![Figure 1.55: Re-constructed violin plots for comparing LSTAT distributions
    for the AGE_category'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.55：重新构建的小提琴图，用于比较AGE_category区段的LSTAT分布'
- en: '](img/C13018_01_55.jpg)'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13018_01_55.jpg)'
- en: 'Figure 1.48: Re-constructed violin plots for comparing LSTAT distributions
    for the AGE_category'
  id: totrans-408
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.48：重新构建的小提琴图，用于比较AGE_category区段的LSTAT分布
- en: Unlike the **MEDV** violin plot, where each distribution had roughly the same
    width, here we see the width increasing along with **AGE**. Communities with primarily
    old houses (the **Very Old** segment) contain anywhere from very few to many lower
    class residents, whereas **Relatively New** communities are much more likely to
    be predominantly higher class, with over 95% of samples having less lower class
    percentages than the **Very Old** communities. This makes sense, because **Relatively
    New** neighborhoods would be more expensive.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 与**MEDV**小提琴图不同，后者每个分布大致相同宽度，在这里我们看到宽度随着**AGE**的增大而增加。以老旧房屋为主的社区（**Very Old**区段）包含的低阶层居民从很少到很多不等，而**Relatively
    New**社区则更有可能以高阶层为主，超过95%的样本低阶层比例低于**Very Old**社区。这是合理的，因为**Relatively New**社区的房价较贵。
- en: Summary
  id: totrans-410
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you have seen the fundamentals of data analysis in Jupyter.
    We began with usage instructions and features of Jupyter such as magic functions
    and tab completion. Then, transitioning to data-science-specific material, we
    introduced the most important libraries for data science with Python.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你已经了解了Jupyter中数据分析的基本概念。我们从Jupyter的使用说明和功能开始，比如魔法函数和自动补全。然后，转到数据科学相关的内容，我们介绍了Python数据科学中最重要的库。
- en: In the latter half of the chapter, we ran an exploratory analysis in a live
    Jupyter Notebook. Here, we used visual assists such as scatter plots, histograms,
    and violin plots to deepen our understanding of the data. We also performed simple
    predictive modeling, a topic which will be the focus of the following chapter
    in this book.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后半部分，我们在实时Jupyter Notebook中进行了探索性分析。在这里，我们使用了散点图、直方图和小提琴图等可视化工具，加深了对数据的理解。我们还进行了简单的预测建模，这也是本书下一章的重点内容。
- en: In the next chapter, we will discuss how to approach predictive analytics, what
    things to consider when preparing the data for modeling, and how to implement
    and compare a variety of models using Jupyter Notebooks.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何进行预测分析，准备数据建模时需要考虑的事项，以及如何在Jupyter Notebooks中实现和比较各种模型。
