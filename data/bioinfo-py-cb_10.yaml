- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Bioinformatics Pipelines
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生物信息学管道
- en: Pipelines are fundamental within any data science environment. Data processing
    is never a single task. Many pipelines are implemented via ad hoc scripts. This
    can be done in a useful way, but in many cases, they fail several fundamental
    viewpoints, chiefly reproducibility, maintainability, and extensibility.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 管道在任何数据科学环境中都至关重要。数据处理从来不是一项单一的任务。许多管道是通过临时脚本实现的。虽然这种方式可以有效使用，但在许多情况下，它们未能满足几个基本视角，主要是可重复性、可维护性和可扩展性。
- en: 'In bioinformatics, you can find three main types of pipeline system:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物信息学中，您可以找到三种主要类型的管道系统：
- en: Frameworks such as Galaxy ([https://usegalaxy.org](https://usegalaxy.org)),
    which are geared toward users, that is, they expose easy-to-use user interfaces
    and hide most of the underlying machinery.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像 Galaxy ([https://usegalaxy.org](https://usegalaxy.org)) 这样的框架，专为用户设计，即它们提供了易于使用的用户界面，并隐藏了大部分底层机制。
- en: Programmatic workflows – geared toward code interfaces that, while generic,
    originate from the bioinformatics space. Two examples are Snakemake ([https://snakemake.readthedocs.io/](https://snakemake.readthedocs.io/))
    and Nextflow ([https://www.nextflow.io/](https://www.nextflow.io/)).
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编程工作流 — 针对代码接口的工作流，虽然是通用的，但来源于生物信息学领域。两个例子是 Snakemake ([https://snakemake.readthedocs.io/](https://snakemake.readthedocs.io/))
    和 Nextflow ([https://www.nextflow.io/](https://www.nextflow.io/))。
- en: Totally generic workflow systems such as Apache Airflow ([https://airflow.incubator.apache.org/](https://airflow.incubator.apache.org/)),
    which take a less data-centric approach to workflow management.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全通用的工作流系统，例如 Apache Airflow ([https://airflow.incubator.apache.org/](https://airflow.incubator.apache.org/))，它采用一种不太以数据为中心的工作流管理方式。
- en: In this chapter, we will discuss Galaxy, which is especially important for bioinformaticians
    supporting users that are less inclined to code their own solutions. While you
    may not be a typical user of these pipeline systems, you might still have to support
    them. Fortunately, Galaxy provides APIs, which will be our main focus.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论 Galaxy，尤其是对于那些支持不太倾向于编写代码解决方案的用户的生物信息学专家而言，Galaxy 尤为重要。虽然您可能不是这些管道系统的典型用户，但您仍然可能需要为它们提供支持。幸运的是，Galaxy
    提供了 API，这是我们主要关注的内容。
- en: We will also be discussing Snakemake and Nextflow as generic workflow tools
    with programmatic interfaces that originated in the bioinformatics space. We will
    cover both tools, as they are the most common in the field. We will solve a similar
    bioinformatics problem using both Snakemake and Nextflow. We will get a taste
    of both frameworks and hopefully be able to decide on a favorite.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将讨论 Snakemake 和 Nextflow 作为通用工作流工具，这些工具有编程接口，最初来源于生物信息学领域。我们将涵盖这两种工具，因为它们是该领域中最常见的工具。我们将用
    Snakemake 和 Nextflow 解决一个类似的生物信息学问题。我们将体验这两个框架，并希望能够决定哪个是我们的最爱。
- en: The code for these recipes is presented not as notebooks, but as Python scripts
    available in the `Chapter09` directory of the book’s repository.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这些配方的代码不是以笔记本的形式呈现，而是作为 Python 脚本，存放在本书仓库的`Chapter09`目录下。
- en: 'In this chapter, you will find recipes for the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，您将找到以下配方：
- en: Introducing Galaxy servers
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 Galaxy 服务器
- en: Accessing Galaxy using the API
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 API 访问 Galaxy
- en: Developing a variant analysis pipeline with Snakemake
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Snakemake 开发变异分析管道
- en: Developing a variant analysis pipeline with Nextflow
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Nextflow 开发变异分析管道
- en: Introducing Galaxy servers
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Galaxy 服务器
- en: Galaxy ([https://galaxyproject.org/tutorials/g101/](https://galaxyproject.org/tutorials/g101/))
    is an open source system that empowers non-computational users to do computational
    biology. It is the most widely used, user-friendly pipeline system available.
    Galaxy can be installed on a server by any user, but there are also plenty of
    other servers on the web with public access, the flagship being [http://usegalaxy.org](http://usegalaxy.org).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Galaxy ([https://galaxyproject.org/tutorials/g101/](https://galaxyproject.org/tutorials/g101/))
    是一个开源系统，旨在帮助非计算用户进行计算生物学研究。它是目前最广泛使用且用户友好的管道系统。任何用户都可以在服务器上安装 Galaxy，但网络上也有许多公开访问的其他服务器，其中最著名的是
    [http://usegalaxy.org](http://usegalaxy.org)。
- en: 'Our focus in the following recipes will be the programming side of Galaxy:
    interfacing using the Galaxy API and developing a Galaxy tool to extend its functionality.
    Before you start, you are strongly advised to approach Galaxy as a user. You can
    do this by creating a free account at [http://usegalaxy.org](http://usegalaxy.org),
    and playing around with it a bit. Reaching a level of understanding that includes
    knowledge of the workflows is recommended.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来食谱的重点将是Galaxy的编程方面：使用Galaxy API进行接口连接，以及开发Galaxy工具以扩展其功能。在开始之前，强烈建议你先作为用户使用Galaxy。你可以通过在[http://usegalaxy.org](http://usegalaxy.org)创建一个免费账户并稍作体验来实现这一点。建议你了解工作流的基本知识。
- en: Getting ready
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'In this recipe, we will carry out a local installation of a Galaxy server using
    Docker. As such, a local Docker installation is required. The level of complexity
    will vary across operating systems: easy on Linux, medium on macOS, and medium
    to hard on Windows.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在此食谱中，我们将使用Docker在本地安装Galaxy服务器。因此，需要一个本地Docker安装。不同操作系统的复杂度不同：在Linux上容易，在macOS上中等，在Windows上中到难。
- en: This installation is recommended for the next two recipes but you may also be
    able to use existing public servers. Note that the interfaces of public servers
    can change over time, so what works today may not work tomorrow. Instructions
    on how to use public servers for the next two recipes are available in the *There’s
    more...* section.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 此安装推荐用于接下来的两个食谱，但你也可以使用现有的公共服务器。请注意，公共服务器的接口可能会随时间变化，因此今天有效的内容明天可能会失效。如何使用公共服务器来执行接下来的两个食谱的说明，详见*更多信息...*部分。
- en: How to do it…
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Take a look at the following steps. These assume that you have a Docker-enabled
    command line:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下步骤。这些步骤假设你已经启用了Docker命令行：
- en: 'First, we pull the Galaxy Docker image with the following command:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们使用以下命令拉取Galaxy Docker镜像：
- en: '[PRE0]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This will pull Björn Grüning’s amazing Docker Galaxy image. Use the `20.09`
    label, as shown in the preceding command; anything more recent could break this
    recipe and the next recipe.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这将拉取Björn Grüning的精彩Docker Galaxy镜像。请使用`20.09`标签，如前面命令所示；任何更新的版本可能会破坏此食谱和下一个食谱。
- en: Create a directory on your system. This directory will hold the persistent output
    of the Docker container across runs.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在系统上创建一个目录。此目录将保存Docker容器在多次运行中的持久输出。
- en: Note
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Docker containers are transient with regard to disk space. This means that when
    you stop the container, all disk changes will be lost. This can be solved by mounting
    volumes from the host on Docker, as in the next step. All content in the mounted
    volumes will persist.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Docker容器对于磁盘空间是临时的。这意味着当你停止容器时，所有磁盘上的更改都会丢失。可以通过在Docker中挂载来自主机的卷来解决此问题，如下一个步骤所示。挂载卷中的所有内容将会持久化。
- en: 'We can now run the image with the following command:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以通过以下命令运行镜像：
- en: '[PRE1]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Replace `YOUR_DIRECTORY` with the full path to the directory that you created
    in *step 2*. If the preceding command fails, make sure you have permission to
    run Docker. This will vary across operating systems.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 将`YOUR_DIRECTORY`替换为你在*步骤 2*中创建的目录的完整路径。如果前面的命令失败，请确保你有权限运行Docker。不同操作系统的权限设置可能不同。
- en: Check the content of `YOUR_DIRECTORY`. The first time the image runs, it will
    create all of the files needed for persistent execution across Docker runs. That
    means maintaining user databases, datasets, and workflows.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查`YOUR_DIRECTORY`中的内容。第一次运行镜像时，它会创建所有需要的文件，以便在Docker运行之间持久化执行。这意味着会保持用户数据库、数据集和工作流。
- en: 'Point your browser to `http://localhost:8080`. If you get any errors, wait
    a few seconds. You should see the following screen:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 将浏览器指向`http://localhost:8080`。如果遇到任何错误，稍等几秒钟。你应该能看到如下屏幕：
- en: '![Figure 9.1 - The Galaxy Docker home page ](img/B17942_09_01.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图9.1 - Galaxy Docker首页](img/B17942_09_01.jpg)'
- en: Figure 9.1 - The Galaxy Docker home page
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 - Galaxy Docker首页
- en: 'Now log in (see the top bar) with the default username and password combination:
    `admin` and `password`.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在使用默认的用户名和密码组合：`admin`和`password`，登录（参见顶部栏）。
- en: From the top menu, choose **User**, and inside, choose **Preferences**.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从顶部菜单中选择**用户**，然后选择**首选项**。
- en: Now, choose **Manage API Key**.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，选择**管理API密钥**。
- en: 'Do not change the API key. The purpose of the preceding exercise is for you
    to know where the API key is. In real scenarios, you will have to go to this screen
    to get your key. Just note the API key: `fakekey`. In normal situations, this
    will be an MD5 hash, by the way.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 不要更改API密钥。前面的练习目的是让你知道API密钥的位置。在实际场景中，你需要进入这个页面获取你的密钥。请记下API密钥：`fakekey`。顺便说一句，正常情况下，这将是一个MD5哈希。
- en: 'So, at this stage, we have our server installed with the following (default)
    credentials: the user as `admin`, password as `password`, and API key as `fakekey`.
    The access point is `localhost:8080`.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经在服务器上安装了以下（默认）凭据：用户为`admin`，密码为`password`，API密钥为`fakekey`。访问点是`localhost:8080`。
- en: There’s more
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容
- en: The way Björn Grüning’s image is going to be used throughout this chapter is
    quite simple; after all, this is not a book on system administration or DevOps,
    but a programming one. If you visit [https://github.com/bgruening/docker-galaxy-stable](https://github.com/bgruening/docker-galaxy-stable),
    you will see that there is an infinite number of ways to configure the image,
    and all are well documented. Our simple approach here works for our development
    purposes.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Björn Grüning的镜像将在本章中使用的方式相当简单；毕竟，这不是一本关于系统管理或DevOps的书，而是一本关于编程的书。如果你访问[https://github.com/bgruening/docker-galaxy-stable](https://github.com/bgruening/docker-galaxy-stable)，你会看到有无数种配置镜像的方式，而且都有详细的文档。在这里，我们简单的方法足够满足我们的开发需求。
- en: 'If you don’t want to install Galaxy on your local computer, you can use a public
    server such as [https://usegalaxy.org](https://usegalaxy.org) to do the next recipe.
    It is not 100% foolproof, as services change over time, but it will probably be
    very close. Take the following steps:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不想在本地计算机上安装Galaxy，可以使用公共服务器，例如[https://usegalaxy.org](https://usegalaxy.org)来进行下一步操作。这个方法不是100%万无一失的，因为服务会随时间变化，但它可能会非常接近。请按以下步骤进行：
- en: Create an account on a public server ([https://usegalaxy.org](https://usegalaxy.org)
    or other).
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在公共服务器上创建一个帐户（[https://usegalaxy.org](https://usegalaxy.org)或其他服务器）。
- en: Follow the previous instructions for accessing your API key.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请按照之前的说明获取你的API密钥。
- en: In the next recipe, you will have to replace the host, user, password, and API
    key.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个步骤中，你需要替换主机、用户、密码和API密钥。
- en: Accessing Galaxy using the API
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用API访问Galaxy
- en: While Galaxy’s main use case is via an easy-to-use web interface, it also provides
    a REST API for programmatic access. There are interfaces provided in several languages,
    for example, Python support is available from BioBlend ([https://bioblend.readthedocs.io](https://bioblend.readthedocs.io)).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Galaxy的主要用法是通过易于使用的Web界面，但它也提供了一个REST API供程序化访问。它提供了多种语言的接口，例如，Python支持可以通过BioBlend获得([https://bioblend.readthedocs.io](https://bioblend.readthedocs.io))。
- en: Here, we are going to develop a script that will load a BED file into Galaxy
    and call a tool to convert it to GFF format. We will load the file using Galaxy’s
    FTP server.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将开发一个脚本，加载一个BED文件到Galaxy，并调用一个工具将其转换为GFF格式。我们将通过Galaxy的FTP服务器加载文件。
- en: Getting ready
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: If you did not go through the previous recipe, please read the corresponding
    *There’s more...* section. The code was tested in a local server, as prepared
    in the preceding recipe, so it might require some adaptations if you run it against
    a public server.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有完成前面的步骤，请阅读相应的*更多内容...*部分。代码已在前面步骤中准备的本地服务器上进行了测试，因此如果你在公共服务器上运行，可能需要进行一些调整。
- en: 'Our code will need to authenticate itself against the Galaxy server in order
    to perform the necessary operations. Because security is an important issue, this
    recipe will not be totally naive with regard to it. Our script will be configured
    via a YAML file, for example:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的代码将需要在Galaxy服务器上进行身份验证，以执行必要的操作。由于安全性是一个重要问题，本教程在这方面不会完全天真。我们的脚本将通过YAML文件进行配置，例如：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Our script will not accept this file as plain text, but it will require it
    to be encrypted. That being said, there is a big hole in our security plan: we
    will be using HTTP (instead of HTTPS), which means that passwords will pass in
    the clear over the network. Obviously, this is a bad solution, but space considerations
    put a limit on what we can do (especially in the preceding recipe). Really secure
    solutions will require HTTPS.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的脚本不会接受这个文件作为纯文本，而是要求它被加密。也就是说，我们的安全计划中存在一个大漏洞：我们将使用HTTP（而不是HTTPS），这意味着密码将在网络上传输时以明文形式发送。显然，这不是一个好的解决方案，但考虑到空间的限制，我们只能做到这一点（特别是在前面的步骤中）。真正安全的解决方案需要使用HTTPS。
- en: 'We will need a script that takes a YAML file and generates an encrypted version:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要一个脚本，该脚本接受一个YAML文件并生成加密版本：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The preceding file can be found at `Chapter09/pipelines/galaxy/encrypt.py` in
    the GitHub repository.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的文件可以在GitHub仓库中的`Chapter09/pipelines/galaxy/encrypt.py`找到。
- en: You will need to input a password for encryption.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 你将需要输入一个密码来进行加密。
- en: 'The preceding code is not Galaxy-related: it reads a `YAML` file and encrypts
    it with a password supplied by the user. It uses the `cryptography` module encryption
    and `ruaml.yaml` for `YAML` processing. Two files are output: the encrypted `YAML`
    file and the `salt` file for encryption. For security reasons, the `salt` file
    should not be public.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码与Galaxy无关：它读取一个`YAML`文件，并使用用户提供的密码进行加密。它使用`cryptography`模块进行加密，并用`ruaml.yaml`处理`YAML`文件。输出两个文件：加密后的`YAML`文件和加密用的`salt`文件。出于安全考虑，`salt`文件不应公开。
- en: This approach to securing credentials is far from sophisticated; it is mostly
    illustrative that you have to be careful with your code when dealing with authentication
    tokens. There are far more instances on the web of hardcoded security credentials.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这种保护凭证的方法远非复杂；它主要是为了说明在处理认证令牌时，你必须小心代码中硬编码的安全凭证。在网络上有很多硬编码安全凭证的实例。
- en: How to do it…
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Take a look at the following steps, which can be found in `Chapter09/pipelines/galaxy/api.py`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下步骤，它们可以在`Chapter09/pipelines/galaxy/api.py`中找到：
- en: 'We start by decrypting our configuration file. We need to supply a password:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从解密我们的配置文件开始。我们需要提供一个密码：
- en: '[PRE4]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The last line summarizes it all: the `YAML` module will load the configuration
    from a decrypted file. Note that we also read `salt` in order to be able to decrypt
    the file.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一行总结了所有内容：`YAML`模块将从解密后的文件中加载配置。请注意，我们还读取了`salt`，以便能够解密文件。
- en: 'We’ll now get all configuration variables, prepare the server URL, and specify
    the name of the Galaxy history that we will be creating (`bioinf_example`):'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将获取所有配置变量，准备服务器URL，并指定我们将要创建的Galaxy历史记录的名称（`bioinf_example`）：
- en: '[PRE5]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, we are able to connect to the Galaxy server:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们能够连接到Galaxy服务器：
- en: '[PRE6]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We will now list all `histories` available:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将列出所有可用的`历史记录`：
- en: '[PRE7]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: On the first execution, you will get an unnamed history, but on the other executions,
    you will also get `bioinf_example`, which we will delete at this stage so that
    we start with a clean slate.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次执行时，你将获得一个未命名的历史记录，但在之后的执行中，你还将获得`bioinf_example`，我们将在此阶段删除它，以便从干净的状态开始。
- en: 'Afterward, we create the `bioinf_example` history :'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们创建了`bioinf_example`历史记录：
- en: '[PRE8]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If you want, you can check on the web interface, and you will find the new history
    there.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，你可以在Web界面上检查，你会在那里看到新的历史记录。
- en: 'We are going to upload the file now; this requires an SFTP connection. The
    file is supplied with this code:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将上传文件；这需要一个SFTP连接。文件通过以下代码提供：
- en: '[PRE9]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We will now tell Galaxy to load the file on the FTP server into its internal
    database:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将告诉Galaxy将FTP服务器上的文件加载到其内部数据库中：
- en: '[PRE10]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let’s summarize the contents of our history:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们总结一下我们历史记录的内容：
- en: '[PRE11]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We only have one entry:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只有一个条目：
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let’s inspect the metadata for our `BED` file:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查一下`BED`文件的元数据：
- en: '[PRE13]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The result consists of the following:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 结果包括以下内容：
- en: '[PRE14]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let’s turn our attention to the existing tools on the server and get metadata
    about them:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将注意力转向服务器上现有的工具，并获取有关它们的元数据：
- en: '[PRE15]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This will print a long list of tools.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出一个长长的工具列表。
- en: 'Now let’s get some information about our tool:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们获取一些关于我们工具的信息：
- en: '[PRE16]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The tool’s name was available in the preceding step. Note that we get the first
    element of a list as, in theory, there could be more than one version of the tool
    installed. The abridged output is as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 工具的名称在前面的步骤中可用。请注意，我们获取的是列表中的第一个元素，因为理论上可能安装了多个版本的工具。简化后的输出如下：
- en: '[PRE17]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Finally, let’s run a tool to convert our `BED` file into `GFF`:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们运行一个工具，将我们的`BED`文件转换为`GFF`：
- en: '[PRE18]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The parameters of the tool can be inspected in the preceding step. If you go
    to the web interface, you will see something similar to the following:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在前面的步骤中检查工具的参数。如果你进入Web界面，你会看到类似以下的内容：
- en: '![Figure 9.2 - Checking the results of our script via Galaxy’s web interface
    ](img/B17942_09_02.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图9.2 - 通过Galaxy的Web界面检查我们脚本的结果](img/B17942_09_02.jpg)'
- en: Figure 9.2 - Checking the results of our script via Galaxy’s web interface
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 - 通过Galaxy的Web界面检查我们脚本的结果
- en: Thus, we have accessed Galaxy using its REST API.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们通过其REST API访问了Galaxy。
- en: Deploying a variant analysis pipeline with Snakemake
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Snakemake部署变异分析管道
- en: 'Galaxy is mostly geared toward users who are less inclined to program. Knowing
    how to deal with it, even if you prefer a more programmer-friendly environment,
    is important because of its pervasiveness. It is reassuring that an API exists
    to interact with Galaxy. But if you want a more programmer-friendly pipeline,
    there are many alternatives available. In this chapter, we explore two widely
    used programmer-friendly pipelines: `snakemake` and Nextflow. In this recipe,
    we consider `snakemake`.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Galaxy 主要面向那些不太倾向于编程的用户。即使你更喜欢编程友好的环境，了解如何使用 Galaxy 仍然很重要，因为它的广泛应用。幸运的是，Galaxy
    提供了一个 API 可以进行交互。不过，如果你需要一个更适合编程的流程，也有很多替代方案。在本章中，我们将探讨两个广泛使用的编程友好型流程：`snakemake`
    和 Nextflow。在本配方中，我们考虑使用 `snakemake`。
- en: Snakemake is implemented in Python and shares many traits with it. That being
    said, its fundamental inspiration is a Makefile, the framework used by the venerable
    `make`-building system.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Snakemake 是用 Python 实现的，并且与 Python 共享许多特性。话虽如此，它的基本灵感来源于 Makefile，这是久负盛名的 `make`
    构建系统所使用的框架。
- en: Here, we will develop a mini variant analysis pipeline with `snakemake`. The
    objective here is not to get the scientific part right – we cover that in other
    chapters – but to see how to create pipelines with `snakemake`. Our mini pipeline
    will download HapMap data, subsample it at 1%, do a simple PCA, and draw it.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用 `snakemake` 开发一个迷你变异分析流程。这里的目标不是做出正确的科学部分—我们在其他章节中会讨论这个—而是展示如何使用 `snakemake`
    创建流程。我们的迷你流程将下载 HapMap 数据，对其进行 1% 的子采样，做一个简单的 PCA，并绘制图形。
- en: Getting ready
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'You will need Plink 2 installed alongside `snakemake`. To display execution
    strategies, you will also need Graphviz to draw the execution. We will define
    the following tasks:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要在安装了 `snakemake` 的同时安装 Plink 2。为了展示执行策略，你还需要 Graphviz 来绘制执行过程。我们将定义以下任务：
- en: Downloading data
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载数据
- en: Uncompressing it
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压它
- en: Sub-sampling it at 1%
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对其进行 1% 的子采样
- en: Computing the PCA on the 1% sub-sample
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 1% 子样本上计算 PCA
- en: Charting the PCA
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制 PCA 图
- en: 'Our pipeline recipe will have two parts: the actual coding of the pipeline
    in `snakemake` and a support script in Python.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的流程配方将包含两个部分：用 `snakemake` 编写的实际流程和一个 Python 支持脚本。
- en: The `snakemake` code for this can be found in `Chapter09/snakemake/Snakefile`,
    whereas the Python support script is in `Chapter09/snakemake/plot_pca.py`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这段 `snakemake` 代码可以在 `Chapter09/snakemake/Snakefile` 中找到，而 Python 支持脚本则在 `Chapter09/snakemake/plot_pca.py`
    中。
- en: How to do it…
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何执行……
- en: 'The first task is downloading the data:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个任务是下载数据：
- en: '[PRE19]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Snakemake’s language is Python-dependent, as you can see from the very first
    lines, which should be easy to understand from a Python perspective. The fundamental
    part is the rule. It has a set of input streams, which are rendered via `HTTP.remote`
    in our case, as we are dealing with remote files, followed by the output. We put
    two files in a `scratch` directory (the ones that are still uncompressed) and
    one in the `data` directory. Finally, our pipeline code is a simple shell script
    that moves the downloaded HTTP files to their final location. Note how the shell
    script refers to inputs and outputs.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Snakemake 的语言依赖于 Python，正如你从最前面的几行代码可以看到的那样，这些代码从 Python 的角度来看应该非常容易理解。核心部分是规则。它有一组输入流，在我们的案例中通过
    `HTTP.remote` 进行渲染，因为我们处理的是远程文件，接着是输出。我们将两个文件放在 `scratch` 目录（那些尚未解压的文件）中，另一个文件放在
    `data` 目录。最后，我们的流程代码是一个简单的 shell 脚本，它将下载的 HTTP 文件移到最终位置。注意 shell 脚本如何引用输入和输出。
- en: 'With this script, downloading the files is easy. Run the following on the command
    line:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这个脚本，下载文件变得非常简单。只需在命令行中运行以下命令：
- en: '[PRE20]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This tells `snakemake` that you want to materialize `data/relationships.txt`
    . We will be using a single core, `-c1` . As this is an output of the `plink_download`
    rule, the rule will then be run (unless the file is already available – in that
    case, `snakemake` will do nothing). Here is an abridged version of the output:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉 `snakemake` 你希望生成 `data/relationships.txt` 文件。我们将使用单核 `-c1`。由于这是 `plink_download`
    规则的输出，规则将会被执行（除非该文件已经存在—如果是这样，`snakemake` 就什么都不做）。以下是简化版的输出：
- en: '[PRE21]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Snakemake gives you some information about which jobs will be executed and starts
    running those.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Snakemake 会给你一些关于将要执行的任务的信息，并开始运行这些任务。
- en: 'Now that we have the data, let’s see the rule for uncompressing it:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了数据，接下来看看解压文件的规则：
- en: '[PRE22]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The most interesting feature here is the way that we can specify multiple files
    to download. Note how the `PLINKEXTS` list is converted into discrete `plinkext`
    elements in the code. You can execute by requesting an output from the rule.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最有趣的特点是我们可以指定多个文件进行下载。注意`PLINKEXTS`列表是如何在代码中转换成离散的`plinkext`元素的。你可以通过请求规则的输出执行它。
- en: 'Now, let’s subsample our data to 1%:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将数据下采样到1%：
- en: '[PRE23]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The new content is in the last two lines: we are not using `script`, but `run`.
    This tells `snakemake` that the execution is Python-based with a few extra functions
    available. Here we see the shell function, which executes a shell script. The
    string is a Python `f`-string – note the reference to the `snakemake` `input`
    and `output` variables in the string. You could put more complex Python code here
    – for example, you could iterate over the inputs.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 新的内容在最后两行：我们没有使用`script`，而是使用`run`。这告诉`snakemake`执行是基于Python的，并且有一些额外的功能可用。在这里，我们看到的是shell函数，它执行一个shell脚本。这个字符串是一个Python的`f`-字符串——注意字符串中对`snakemake`的`input`和`output`变量的引用。你可以在这里放入更复杂的Python代码——例如，你可以遍历输入数据。
- en: TIP
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Here, we are assuming that Plink is available, as we pre-installed it, but `snakemake`
    does provide some functionality to deal with dependencies. More specifically,
    `snakemake` rules can be annotated with a `YAML` file pointing to `conda` dependencies.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们假设Plink是可用的，因为我们已经预安装了它，但`snakemake`确实提供了一些功能来处理依赖关系。更具体地说，`snakemake`规则可以通过一个指向`conda`依赖的`YAML`文件进行注释。
- en: 'Now that we have our data sub-sampled, let’s compute the PCA. In this case,
    we will use Plink’s internal PCA framework to do the computation:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经对数据进行了下采样，让我们计算PCA。在这种情况下，我们将使用Plink的内部PCA框架来进行计算：
- en: '[PRE24]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As with most pipeline systems, `snakemake` constructs a `snakemake` to present
    you a DAG of what you will execute to generate your request. For example, to generate
    the PCA, use the following:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 和大多数管道系统一样，`snakemake`构建了一个`snakemake`来为你展示执行的DAG，以生成你的请求。例如，为了生成PCA，使用以下命令：
- en: '[PRE25]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This would generate the following figure:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下图像：
- en: '![Figure 9.3 - The DAG to compute the PCA ](img/B17942_09_03.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.3 - 计算PCA的DAG](img/B17942_09_03.jpg)'
- en: Figure 9.3 - The DAG to compute the PCA
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 - 计算PCA的DAG
- en: 'Finally, let’s generate the `plot` rule for the PCA:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们为PCA生成`plot`规则：
- en: '[PRE26]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `plot` rule introduces a new type of execution, `script`. In this case,
    an external Python script is called to process the rule.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`plot`规则引入了一种新的执行类型，`script`。在这种情况下，调用了一个外部的Python脚本来处理规则。'
- en: 'Our Python script to generate the chart is the following:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们用来生成图表的Python脚本如下：
- en: '[PRE27]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The Python script has access to the `snakemake` object. This object exposes
    the content of the rule: note how we make use of `input` to get the PCA data and
    `output` to generate the image.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Python脚本可以访问`snakemake`对象。这个对象暴露了规则的内容：注意我们如何使用`input`来获取PCA数据，使用`output`来生成图像。
- en: 'Finally, the code to produce a rough chart is as follows:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，生成粗略图表的代码如下：
- en: '![Figure 9.4 - A very rough PCA produced by the Snakemake pipeline ](img/B17942_09_04.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.4 - Snakemake管道生成的非常粗略的PCA](img/B17942_09_04.jpg)'
- en: Figure 9.4 - A very rough PCA produced by the Snakemake pipeline
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 - Snakemake管道生成的非常粗略的PCA
- en: There’s more
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多
- en: The preceding recipe was made to run on a simple configuration of `snakemake`.
    There are many more ways to construct rules in `snakemake`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的食谱是为了在简单配置的`snakemake`上运行制作的。`snakemake`中还有许多其他构建规则的方式。
- en: The most important issue that we didn’t discuss is the fact that `snakemake`
    can execute code in many different environments, from the local computer (as in
    our case), on-premises clusters, to the cloud. It would be unreasonable to ask
    for anything more than using a local computer to try `snakemake`, but don’t forget
    that `snakemake` can manage complex computing environments.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有讨论的最重要问题是，`snakemake`可以在多种不同环境中执行代码，从本地计算机（如我们的案例）、本地集群，到云端。要求除了使用本地计算机运行`snakemake`外更多的功能是不合理的，但不要忘了`snakemake`可以管理复杂的计算环境。
- en: Remember that `snakemake`, while implemented in Python, is conceptually based
    on `make`. It’s a subjective analysis to decide whether you like the (snake)make
    design. For an alternative design approach, check the next recipe, which uses
    Nextflow.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，虽然`snakemake`是用Python实现的，但其概念上基于`make`。是否喜欢这种（蛇形）设计是一个主观的分析。如果想了解一种替代的设计方法，查看下一个食谱，它使用Nextflow。
- en: Deploying a variant analysis pipeline with Nextflow
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Nextflow部署变异分析管道
- en: 'There are two main players in the pipeline framework space in bioinformatics:
    `snakemake` and Nextflow. They provide pipeline functionality whilst having different
    design approaches. Snakemake is based on Python, but its language and philosophy
    come from the `make` tool used to compile complex programs with dependencies.
    Nextflow is Java-based (more precisely, it’s implemented in Groovy – a language
    that works on top of the Java Virtual Machine) and has its own `snakemake` and
    choose the one that better suits your needs.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物信息学的管道框架领域，有两个主要的参与者：`snakemake`和Nextflow。它们提供管道功能，但设计方法不同。Snakemake基于Python，但它的语言和理念来源于用于编译有依赖关系的复杂程序的`make`工具。Nextflow是基于Java的（更准确地说，它是用Groovy实现的——一种运行在Java虚拟机上的语言），并且有自己的`snakemake`，可以选择适合你需求的那个。
- en: TIP
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: There are many perspectives on how to evaluate a pipeline system. Here, we present
    a perspective based on the language used to specify the pipeline. However, there
    are others that you should consider when choosing a pipeline system. For example,
    how well does it support your execution environment (such as an on-premises cluster
    or a cloud), does it support your tools (or allow easy development of extensions
    to deal with new tools), and does it provide good recovery and monitoring functionalities?
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 评估管道系统有许多视角。这里，我们呈现了一个基于用来指定管道的语言的视角。然而，选择管道系统时，你还应该考虑其他方面。例如，它是否能很好地支持你的执行环境（如本地集群或云环境），是否支持你的工具（或者是否允许轻松开发扩展以应对新工具），以及它是否提供良好的恢复和监控功能？
- en: Here, we will develop a pipeline with Nextflow that provides the same functionality
    as we implemented with `snakemake`, thus allowing for a fair comparison from the
    pipeline design point of view. The objective here is not to get the scientific
    part right – we cover that in other chapters – but to see how to create pipelines
    with `snakemake`. Our mini pipeline will download HapMap data, sub-sample it at
    1%, do a simple PCA, and draw it.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将开发一个Nextflow管道，提供与我们使用`snakemake`实现的相同功能，从而允许从管道设计角度进行公平比较。这里的目标不是搞清楚科学部分——我们将在其他章节中讨论这个——而是展示如何使用`snakemake`创建管道。我们的迷你管道将下载HapMap数据，进行1%的子抽样，做一个简单的PCA，并绘制出来。
- en: Getting ready
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 做好准备
- en: 'You will need Plink 2 installed along with Nextflow. Nextflow itself requires
    some software from the Java space: notably the Java Runtime Environment and Groovy.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要安装Plink 2以及Nextflow。Nextflow本身需要一些来自Java领域的软件：特别是Java运行时环境和Groovy。
- en: 'We will define the following tasks:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义以下任务：
- en: Downloading data
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载数据
- en: Uncompressing it
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压它
- en: Sub-sampling it at 1%
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对其进行1%的子抽样
- en: Computing the PCA on the 1% sub-sample
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对1%子抽样数据进行PCA计算
- en: Charting the PCA
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制PCA图
- en: The Nextflow code for this can be found in `Chapter09/nextflow/pipeline.nf`.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 相关的Nextflow代码可以在`Chapter09/nextflow/pipeline.nf`找到。
- en: How to do it…
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'The first task is downloading the data:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个任务是下载数据：
- en: '[PRE28]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Remember that the underlying language for the pipeline is not Python but Groovy,
    so the syntax will be a bit different, such as using braces for blocks or ignoring
    indentation.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，管道的基础语言不是Python，而是Groovy，因此语法会有些不同，比如使用大括号表示代码块或忽略缩进。
- en: We create a process (a pipeline building block in Nextflow) called `plink_download`,
    which downloads the Plink files. It only specifies outputs. The first output will
    be the `hapmap.map.gz` file and the second output will be `hapmap.ped.gz`. This
    process will have two output channels (another Nextflow concept, akin to a stream),
    which can be consumed by another process.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个名为`plink_download`的过程（Nextflow中的管道构建块），用于下载Plink文件。它只指定了输出。第一个输出将是`hapmap.map.gz`文件，第二个输出将是`hapmap.ped.gz`。该过程将有两个输出通道（Nextflow中的另一个概念，类似于流），可以被另一个过程消费。
- en: The code for the process is, by default, a bash script. It’s important to note
    how the script outputs files with names that are synchronized with the output
    section. Also, see how we refer to the variables defined in the pipeline (`download_root`,
    in our case).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程的代码默认是一个bash脚本。值得注意的是，脚本输出的文件名与输出部分是同步的。同时，也要注意我们是如何引用管道中定义的变量的（例如我们的例子中的`download_root`）。
- en: 'Let’s now define a process to consume the channels with the HapMap files and
    decompress them:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来定义一个过程，使用HapMap文件并解压它们：
- en: '[PRE29]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'There are three issues of note in this process: we now have a couple of inputs
    (remember that we have a couple of outputs from the previous process). Our script
    also now refers to input variables (`$mapgz` and `$pedgz`). Finally, we publish
    the output by using `publishDir`. Therefore, any files that are not published
    will only be stored temporarily.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中有三个需要注意的问题：我们现在有了一些输入（记住我们从上一个过程中得到了一些输出）。我们的脚本现在也引用了输入变量（`$mapgz`和`$pedgz`）。最后，我们通过使用`publishDir`发布输出。因此，任何未发布的文件将只会被暂时存储。
- en: 'Let’s specify a first version of the workflow that downloads and uncompresses
    the files:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们指定一个下载并解压文件的工作流的第一个版本：
- en: '[PRE30]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can execute the workflow by running the following on the shell:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过在命令行中运行以下命令来执行工作流：
- en: '[PRE31]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The `resume` flag at the end will make sure that the pipeline will continue
    from whatever step was already completed. The steps are, on local execution, stored
    in the `work` directory.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的`resume`标志将确保管道从已完成的步骤继续执行。步骤会在本地执行时存储在`work`目录中。
- en: 'If we remove the `work` directory, we don’t want to download the HapMap files
    if they were already published. As this is outside the `work` directory, hence
    not directly tracked, we need to change the workflow to track the data in the
    published directory:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们删除`work`目录，我们不希望下载HapMap文件，如果它们已经被发布。由于这些文件不在`work`目录中，因此不直接跟踪，我们需要修改工作流，以便在已发布的目录中跟踪数据：
- en: '[PRE32]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: There are alternative ways of doing this, but I wanted to introduce a bit of
    Groovy code, as you might sometimes have to write code in Groovy. There are ways
    to use Python code, as you will see soon.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他方法可以做到这一点，但我想介绍一些Groovy代码，因为你可能有时需要在Groovy中编写代码。正如你很快会看到的，也有方法可以使用Python代码。
- en: 'Now, we need to subsample the data:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要对数据进行亚采样：
- en: '[PRE33]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s now compute the PCA using Plink:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用Plink计算PCA：
- en: '[PRE34]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Finally, let’s plot the PCA:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们绘制PCA图：
- en: '[PRE35]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The new feature of this code is that we specify the bash script using the shebang
    (`#!`) operator, which allows us to call an external scripting language to process
    the data.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码的新特性是我们使用shebang（`#!`）操作符指定了bash脚本，这使我们能够调用外部脚本语言来处理数据。
- en: 'Here is our final workflow:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的最终工作流：
- en: '[PRE36]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We either download the data or use the already downloaded data.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要么下载数据，要么使用已经下载的数据。
- en: While there are other dialects for designing the complete workflow, I would
    like you to note how we use `subsample_1p` when the files are available; we can
    explicitly pass two channels to a process.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有其他方言用于设计完整的工作流，但我想让你注意我们如何在文件可用时使用`subsample_1p`；我们可以显式地将两个通道传递给一个过程。
- en: 'We can run the pipeline and request an HTML report on execution:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以运行管道并请求执行HTML报告：
- en: '[PRE37]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The report is quite exhaustive and will allow you to figure out the parts of
    the pipeline that are expensive from different perspectives, whether related to
    time, memory, CPU consumption, or I/O.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 报告非常详细，能够帮助你从不同角度了解管道中哪些部分是开销较大的，无论是与时间、内存、CPU消耗还是I/O相关。
- en: There’s more
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容
- en: This was a simple introductory example of Nextflow, which hopefully will allow
    you to get a flavor of the framework, particularly so that you can compare it
    with `snakemake`. Nextflow has many more functionalities and you are encouraged
    to check out its website.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的Nextflow入门示例，希望能让你对这个框架有所了解，尤其是让你能够与`snakemake`进行比较。Nextflow有更多的功能，建议你查看它的网站。
- en: As with `snakemake`, the most important issue that we didn’t discuss is the
    fact that Nextflow can execute code in many different environments, from the local
    computer, on-premises clusters, to the cloud. Check Nextflow’s documentation to
    see which computing environments are currently supported.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 与`snakemake`一样，我们没有讨论的最重要问题是Nextflow可以在许多不同的环境中执行代码，从本地计算机、现场集群到云。请查阅Nextflow的文档，了解当前支持哪些计算环境。
- en: As important as the underlying language is, Groovy with Nextflow and Python
    with `snakemake`, make sure to compare other factors. This includes not only where
    both pipelines can execute (locally, in a cluster, or in a cloud) but also the
    design of the framework, as they use quite different paradigms.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 无论底层语言多么重要，Groovy与Nextflow，Python与`snakemake`一样，都必须比较其他因素。这不仅包括两个管道可以在哪些地方执行（本地、集群或云），还包括框架的设计，因为它们使用的是截然不同的范式。
