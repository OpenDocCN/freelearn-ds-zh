- en: Predicting Fire Department Calls with Spark ML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark ML预测消防部门呼叫
- en: 'In this chapter, the following recipes will be covered:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将涵盖以下内容：
- en: Downloading the San Francisco fire department calls dataset
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载旧金山消防部门呼叫数据集
- en: Identifying the target variable of the logistic regression model
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别逻辑回归模型的目标变量
- en: Preparing feature variables for the logistic regression model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为逻辑回归模型准备特征变量
- en: Applying the logistic regression model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用逻辑回归模型
- en: Evaluating the accuracy of the logistic regression model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估逻辑回归模型的准确性
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Classification models are a popular way to predict a defined categorical outcome.
    We use outputs from classification models all the time. Anytime we go to see a
    movie in a theatre, we are interested to know whether the film is considered correct?
    One of the most popular classification models in the data science community is
    a logistic regression. The logistic regression model produces a response that
    is activated by a sigmoid function. The sigmoid function uses the inputs from
    the model and produces an output that is between 0 and 1\. That output is usually
    in a form of a probability score. Many deep learning models are also used for
    classification purposes. It is common to find logistic regression models performed
    in conjunction with deep learning models to help establish a baseline in which
    deep learning models are measured against. The sigmoid activation function is
    one of many activation functions that are also used in deep neural networks within
    deep learning to produce a probability output. We will utilize the built-in machine
    learning libraries within Spark to build a logistic regression model that will
    predict whether an incoming call to the San Francisco Fire department is actually
    related to a fire, rather than another incident.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型是预测定义的分类结果的一种流行方式。我们经常使用分类模型的输出。每当我们去电影院看电影时，我们都想知道这部电影是否被认为是正确的？数据科学社区中最流行的分类模型之一是逻辑回归。逻辑回归模型产生的响应由S形函数激活。S形函数使用模型的输入并产生一个在0和1之间的输出。该输出通常以概率分数的形式呈现。许多深度学习模型也用于分类目的。通常会发现逻辑回归模型与深度学习模型一起执行，以帮助建立深度学习模型的基线。S形激活函数是深度学习中使用的许多激活函数之一，用于产生概率输出。我们将利用Spark内置的机器学习库构建一个逻辑回归模型，该模型将预测旧金山消防部门的呼叫是否实际与火灾有关，而不是其他事件。
- en: Downloading the San Francisco fire department calls dataset
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载旧金山消防部门呼叫数据集
- en: 'The City of San Francisco does a great job of collecting fire department calls
    for services across their area. As it states on their website, each record includes
    the call number, incident number, address, unit identifier, call type, and disposition.
    The official website containing San Francisco fire department call data can be
    found at the following link:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 旧金山市在整个地区收集消防部门的服务呼叫记录做得非常好。正如他们的网站上所述，每条记录包括呼叫编号、事件编号、地址、单位标识符、呼叫类型和处理结果。包含旧金山消防部门呼叫数据的官方网站可以在以下链接找到：
- en: '[https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)'
- en: 'There is some general information regarding the dataset with regards to the
    number of columns and rows, seen in the following screenshot:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有关数据集的一些一般信息，包括列数和行数，如下截图所示：
- en: '![](img/00142.jpeg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00142.jpeg)'
- en: This current dataset, updated on 3/26/2018, has roughly 4.61 M rows and 34 columns.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这个当前数据集，更新于2018年3月26日，大约有461万行和34列。
- en: Getting ready
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The dataset is available in a `.csv` file and can be downloaded locally on to
    your machine, where it can then be imported into Spark.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集以`.csv`文件的形式可供下载，并可在本地机器上下载，然后导入Spark。
- en: How to do it...
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤如下：
- en: This section will walk through the steps to download and import the `.csv` file
    to our Jupyter notebook.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍下载和导入`.csv`文件到我们的Jupyter笔记本的步骤。
- en: 'Download the dataset from the website by selecting Export and then CSV, as
    seen in the following screenshot:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '通过选择导出然后CSV从网站下载数据集，如下截图所示： '
- en: '![](img/00143.jpeg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00143.jpeg)'
- en: If not already the case, name the downloaded dataset `Fire_Department_Calls_for_Service.csv`
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果还没有这样做，请将下载的数据集命名为`Fire_Department_Calls_for_Service.csv`
- en: 'Save the dataset to any local directory, although ideally it should be saved
    to the same folder that contains the Spark notebook that will be used in this
    chapter, as seen in the following screenshot:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集保存到任何本地目录，尽管理想情况下应该保存到包含本章中将使用的Spark笔记本的相同文件夹中，如下截图所示：
- en: '![](img/00144.jpeg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00144.jpeg)'
- en: 'Once the dataset has been saved to the same directory as the notebook, execute
    the following `pyspark` script to import the dataset into Spark and create a dataframe
    called `df`:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦数据集已保存到与笔记本相同的目录中，执行以下`pyspark`脚本将数据集导入Spark并创建一个名为`df`的数据框：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: How it works...
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理如下：
- en: The dataset is saved to the same directory that houses the Jupyter notebook
    for ease of import into the Spark session.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集保存在与Jupyter笔记本相同的目录中，以便轻松导入到Spark会话中。
- en: A local `pyspark` session is initialized by importing `SparkSession` from `pyspark.sql`.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过从`pyspark.sql`导入`SparkSession`来初始化本地`pyspark`会话。
- en: A dataframe, `df`, is created by reading in the CSV file with the options `header
    = 'true'` and `inferschema = 'true'`.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用选项`header='true'`和`inferschema='true'`读取CSV文件创建一个名为`df`的数据框。
- en: 'Finally, it is always ideal to run a script to show the data that has been
    imported into Spark through the dataframe to confirm that the data has made its
    way through. The outcome of the script, showing the first two rows of the dataset
    from the San Francisco fire department calls, can be seen in the following screenshot:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，始终最好运行一个脚本来显示已通过数据框导入Spark的数据，以确认数据已传输。可以在以下截图中看到该脚本的结果，显示了来自旧金山消防局呼叫的数据集的前两行：
- en: '![](img/00145.jpeg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00145.jpeg)'
- en: Please note that as we read the file into spark, we are using `.load()` to pull
    the `.csv` file into the Jupyter notebook. This is fine for our purposes as we
    are using a local cluster, but would not work if we were leveraging a cluster
    from Hadoop.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当我们将文件读入spark时，我们使用`.load()`将`.csv`文件拉入Jupyter笔记本。对于我们的目的来说，这是可以的，因为我们使用的是本地集群，但如果我们要利用Hadoop中的集群，这种方法就行不通了。
- en: There's more...
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The dataset is accompanied by a data dictionary that defines the headers for
    each of the 34 columns. This data dictionary can be accessed from the same website
    through the following link:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集附带有数据字典，定义了34列的标题。可以通过以下链接从同一网站访问此数据字典：
- en: '[https://data.sfgov.org/api/views/nuek-vuh3/files/ddb7f3a9-0160-4f07-bb1e-2af744909294?download=true&filename=FIR-0002_DataDictionary_fire-calls-for-service.xlsx](https://data.sfgov.org/api/views/nuek-vuh3/files/ddb7f3a9-0160-4f07-bb1e-2af744909294?download=true&filename=FIR-0002_DataDictionary_fire-calls-for-service.xlsx)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://data.sfgov.org/api/views/nuek-vuh3/files/ddb7f3a9-0160-4f07-bb1e-2af744909294?download=true&filename=FIR-0002_DataDictionary_fire-calls-for-service.xlsx](https://data.sfgov.org/api/views/nuek-vuh3/files/ddb7f3a9-0160-4f07-bb1e-2af744909294?download=true&filename=FIR-0002_DataDictionary_fire-calls-for-service.xlsx)'
- en: See also
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'The San Francisco government website allows for online visualization of the
    data, which can be used to do some quick data profiling. The visualization application
    can be accessed on the website by selecting the Visualize dropdown, as seen in
    the following screenshot:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 旧金山政府网站允许在线可视化数据，可用于进行一些快速数据概要分析。可以通过选择可视化下拉菜单在网站上访问可视化应用程序，如下截图所示：
- en: '![](img/00146.jpeg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00146.jpeg)'
- en: Identifying the target variable of the logistic regression model
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别逻辑回归模型的目标变量
- en: A logistic regression model operates as a classification algorithm aiming to
    predict a binary outcome. In this section, we will specify the best column within
    the dataset to predict whether an incoming call to the operator is related to
    fire or non-fire incidents.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型作为分类算法运行，旨在预测二进制结果。在本节中，我们将指定数据集中用于预测运营商呼入电话是否与火灾或非火灾事件相关的最佳列。
- en: Getting ready
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'We will visualize many of the data points in this section, which will require
    the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将可视化许多数据点，这将需要以下操作：
- en: Ensuring that `matplotlib` is installed by executing `pip install matplotlib`
    at the command line.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在命令行中执行`pip install matplotlib`来确保安装了`matplotlib`。
- en: Running `import matplotlib.pyplot as plt` as well as ensuring graphs are viewed
    within cells by running `%matplotlib inline`.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`import matplotlib.pyplot as plt`，并确保通过运行`%matplotlib inline`在单元格中查看图形。
- en: Additionally, there will be some manipulation of functions within `pyspark.sql`
    that requires `importing functions as F`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，将对`pyspark.sql`中的函数进行一些操作，需要`importing functions as F`。
- en: How to do it...
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: This section will walk through visualizing the data from the San Francisco Fire
    Department.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何可视化来自旧金山消防局的数据。
- en: 'Execute the following script to get a cursory identification of the unique
    values in the `Call Type Group` column:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本以对`Call Type Group`列中唯一值进行快速识别：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'There are five main categories:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有五个主要类别：
- en: '`Alarm`.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`警报`。'
- en: '`Potentially Life-threatening`.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`潜在危及生命`。'
- en: '`Non Life-threatening`.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`非危及生命`。'
- en: '`Fire`.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`火`。'
- en: '`null`.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`null`。'
- en: 'Unfortunately, one of those categories is `null` values. It would be useful
    to get a row count of each unique value to identify how many null values there
    are in the dataset. Execute the following script to generate a row count of each
    unique value for the column `Call Type Group`:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不幸的是，其中一个类别是`null`值。有必要获取每个唯一值的行计数，以确定数据集中有多少`null`值。执行以下脚本以生成`Call Type Group`列的每个唯一值的行计数：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Unfortunately, there are over 2.8 M rows of data that do not have a `Call Type
    Group` associated with them. That is over 60 percent of the available rows of
    4.6 M. Execute the following script to view the imbalance of null values in a
    bar chart:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不幸的是，有超过280万行数据没有与之关联的`呼叫类型组`。这超过了460万可用行的60％。执行以下脚本以查看条形图中空值的不平衡情况：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Another indicator may need to be chosen to determine a target variable. Instead,
    we can profile `Call Type` to identify calls associated with fire versus all other
    calls. Execute the following script to profile `Call Type`:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可能需要选择另一个指标来确定目标变量。相反，我们可以对`Call Type`进行概要分析，以识别与火灾相关的呼叫与所有其他呼叫。执行以下脚本以对`Call
    Type`进行概要分析：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'There do not appear to be any `null` values, as there were with `Call Type
    Group`. There are 32 unique categories for `Call Type`; therefore, it will be
    used as the target variable for fire incidents. Execute the following script to
    tag the columns containing `Fire` in`Call Type`:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与`Call Type Group`一样，似乎没有任何`null`值。`Call Type`有32个唯一类别；因此，它将被用作火灾事件的目标变量。执行以下脚本以标记包含`Fire`的`Call
    Type`列：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Execute the following script to retrieve the distinct counts of `Fire Indicator`:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本以检索`Fire Indicator`的不同计数：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Execute the following script to add the `Fire Indicator` column to the original
    dataframe, `df`:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本以将`Fire Indicator`列添加到原始数据框`df`中：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, add the `fireIndicator` column has to the dataframe, `df`, and confirm
    by executing the following script:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将`fireIndicator`列添加到数据框`df`中，并通过执行以下脚本进行确认：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works...
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'One of the key steps to building a successful logistic regression model is
    establishing a binary target variable that will be used as the prediction outcome.
    This section walks through the logic behind selecting our target variable:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 建立成功的逻辑回归模型的关键步骤之一是建立一个二元目标变量，该变量将用作预测结果。本节将介绍选择目标变量背后的逻辑：
- en: 'Data profiling of potential target columns is performed by identifying the
    unique column values of `Call Type Group`. We can view the unique values of the
    `Call Type Group` column, as seen in the following screenshot:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过识别`Call Type Group`的唯一列值来执行潜在目标列的数据概要分析。我们可以查看`Call Type Group`列的唯一值，如下截图所示：
- en: '![](img/00147.jpeg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00147.jpeg)'
- en: The goal is to identify whether there are any missing values within the `Call
    Type Group` column and what can be done with those missing values. Sometimes,
    the missing values in the columns can just be dropped, and other times they are
    manipulated to populate values.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目标是确定`Call Type Group`列中是否存在缺失值，以及如何处理这些缺失值。有时，可以直接删除列中的缺失值，而其他时候可以对其进行处理以填充值。
- en: 'The following screenshot shows how many null values are present:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下截图显示了存在多少空值：
- en: '![](img/00148.jpeg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00148.jpeg)'
- en: 'Additionally, we can also plot how many `null` values are present to get a
    better visual sense of the abundance of values, as seen in the following screenshot:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，我们还可以绘制存在多少`null`值，以更好地直观感受值的丰富程度，如下截图所示：
- en: '![](img/00149.jpeg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00149.jpeg)'
- en: Since there are over 2.8 M rows that are missing from `Call Type Group`, as
    seen in the `df.groupBy` script as well as the bar chart, it doesn't make sense
    to drop all of those values, as that is over 60 percent of the total row count
    from the dataset. Therefore, another column will need to be chosen as the target
    indicator.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于`Call Type Group`中有超过280万行缺失，如`df.groupBy`脚本和条形图所示，删除所有这些值是没有意义的，因为这超过了数据集的总行数的60%。因此，需要选择另一列作为目标指示器。
- en: 'While profiling the `Call Type` column, we find that there aren''t any null
    rows in the 32 unique possible values. This makes `Call Type` a better candidate
    for the target variable for the logistic regression model. The following is a
    screenshot of the `Call Type` column profiled:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在对`Call Type`列进行数据概要分析时，我们发现32个可能值中没有空行。这使得`Call Type`成为逻辑回归模型的更好目标变量候选项。以下是`Call
    Type`列的数据概要分析截图：
- en: '![](img/00150.jpeg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00150.jpeg)'
- en: 'Since logistic regression works best when there is a binary outcome, a new
    column is created using the `withColumn()` operator in the `df` dataframe to capture
    an indicator (0 or 1) as to whether a call is affiliated with a fire-related incident
    or a non-fire-related incident. The new column is called `fireIndicator` and can
    be seen in the following screenshot:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于逻辑回归在有二元结果时效果最佳，因此使用`withColumn()`操作符在`df`数据框中创建了一个新列，以捕获与火灾相关事件或非火灾相关事件相关的指示器（0或1）。新列名为`fireIndicator`，如下截图所示：
- en: '![](img/00151.jpeg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00151.jpeg)'
- en: 'We can identify how prevalent fire calls are compared to the rest of the calls
    by doing a `groupBy().count()`, as seen in the following screenshot:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过执行`groupBy().count()`来确定火警呼叫与其他呼叫的普遍程度，如下截图所示：
- en: '![](img/00152.jpeg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00152.jpeg)'
- en: 'It is best practice to confirm that the new column has been attached to the
    existing dataframe by executing the `printSchema()` script of the newly modified
    dataframe. The output of the new schema can be seen in the following screenshot:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最佳实践是通过执行新修改的数据框的`printSchema()`脚本来确认新列是否已附加到现有数据框。新模式的输出如下截图所示：
- en: '![](img/00153.jpeg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00153.jpeg)'
- en: There's more...
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'There were a couple of column manipulations done with the `pyspark.sql` module
    in this section. The `withColumn()` operator returns a new dataframe or modifies
    an existing dataframe by adding a new column or modifies an existing column of
    the same name. This is not to be confused with the `withColumnRenamed()` operator,
    which also returns a new dataframe, but by modifying the name of an existing column
    to a new column. Finally, we needed to perform some logical operations to convert
    values associated with `Fire` to 0 and without `Fire` to 1\. This required using
    the `pyspark.sql.functions` module and incorporating the `where` function as an
    equivalent to a case statement used in SQL. The function created a case statement
    equation using the following syntax:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，使用`pyspark.sql`模块进行了一些列操作。`withColumn()`操作符通过添加新列或修改同名现有列来返回新的数据框，或修改现有数据框。这与`withColumnRenamed()`操作符不同，后者也返回新的数据框，但是通过修改现有列的名称为新列。最后，我们需要执行一些逻辑操作，将与`Fire`相关的值转换为0，没有`Fire`的值转换为1。这需要使用`pyspark.sql.functions`模块，并将`where`函数作为SQL中case语句的等价物。该函数使用以下语法创建了一个case语句方程：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The outcome of the new dataset for both columns, `Call Type` and `fireIndicator`,
    appear as the following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 新数据集的结果，`Call Type`和`fireIndicator`两列如下所示：
- en: '![](img/00154.jpeg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00154.jpeg)'
- en: See also
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'In order to learn more about the `pyspark.sql` module available within Spark,
    visit the following website:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Spark中可用的`pyspark.sql`模块的信息，请访问以下网站：
- en: '[http://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html](http://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html](http://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html)'
- en: Preparing feature variables for the logistic regression model
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为逻辑回归模型准备特征变量
- en: In the previous section, we identified our target variable that will be used
    as our predictor for fire calls in our logistic regression model. This section
    will focus on identifying all of the features that will best help the model identify
    what the target should be. This is known as **feature selection**.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们确定了将用作逻辑回归模型预测结果的目标变量。本节将重点关注确定所有最有助于模型确定目标的特征。这被称为**特征选择**。
- en: Getting ready
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: This section will require importing `StringIndexer` from `pyspark.ml.feature`.
    In order to ensure proper feature selection, we will need to map string columns
    to columns of indices. This will help generate distinct numeric values for categorical
    variables that will provide ease of computation for the machine learning model
    to ingest the independent variables used to predict the target outcome.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将需要从`pyspark.ml.feature`中导入`StringIndexer`。为了确保正确的特征选择，我们需要将字符串列映射到索引列。这将有助于为分类变量生成不同的数值，从而为机器学习模型提供独立变量的计算便利，用于预测目标结果。
- en: How to do it...
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: This section will walk through the steps to prepare the feature variables for
    our model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将逐步介绍为我们的模型准备特征变量的步骤。
- en: 'Execute the following script to update the dataframe, `df`, by only selecting
    the fields that are independent of any fire indicators:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本来更新数据框`df`，只选择与任何火灾指示无关的字段：
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The next step is to identify any null values within the dataframe and remove
    them if they exist. Execute the following script to identify the row count with
    any null values:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是识别数据框中的任何空值并在存在时删除它们。执行以下脚本来识别具有任何空值的行数：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'There are 16,551 rows with missing values. Execute the following script to
    update the dataframe to remove all rows with null values:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有16,551行具有缺失值。执行以下脚本来更新数据框以删除所有具有空值的行：
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Execute the following script to retrieve the updated target count of `fireIndicator`:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本来检索`fireIndicator`的更新目标计数：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Import the `StringIndexer` class from `pyspark.ml.feature` to assign numeric
    values to each categorical variable for the features, as seen in the following
    script:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`pyspark.ml.feature`中导入`StringIndexer`类，为特征分配数值，如下脚本所示：
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create a Python list for all the feature variables that will be used in the
    model using the following script:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本为模型创建所有特征变量的Python列表：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Execute the following script to specify the output column format, `outputcol`,
    that will be `stringIndexed` from the list of features from the input column,
    `inputcol`:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本来指定输出列格式`outputcol`，它将从输入列`inputcol`的特征列表中进行`stringIndexed`：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Execute the following script to create a `model` that will be used to `fit`
    the input columns and produce the newly defined output columns to the existing
    dataframe, `df`:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本创建一个`model`，用于`fit`输入列并为现有数据框`df`生成新定义的输出列：
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Execute the following script to define a final selection of the features in
    the dataframe, `df`, that will be used for the model:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本来定义数据框`df`中将用于模型的特征的最终选择：
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: How it works...
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: This section will explain the logic behind the steps in preparing the feature
    variables for our model.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释为我们的模型准备特征变量的步骤背后的逻辑。
- en: 'Only the indicators in the dataframe that are truly independent of an indication
    of fire are selected to contribute to the logistic regression model that will
    predict the outcome. The reason this is performed is to remove any potential bias
    in the dataset that may already reveal the outcome of the prediction. This minimizes
    human interaction with the final outcome. The output of the updated dataframe
    can be seen in the following screenshot:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只选择数据框中真正与火灾指示无关的指标，以贡献于预测结果的逻辑回归模型。执行此操作的原因是为了消除数据集中可能已经显示预测结果的任何潜在偏见。这最小化了人为干预最终结果。更新后的数据框的输出可以在下面的截图中看到：
- en: '![](img/00155.jpeg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00155.jpeg)'
- en: Please note that the column `Neighborhooods - Analysis of Boundaries` is originally
    misspelled from the data we extract. We will continue to use the misspelling for
    the rest of the chapter for continuity purposes. However, the column name can
    be renamed using the `withColumnRenamed()` function in Spark.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，列`邻里-分析边界`在我们提取的数据中原本拼写错误。出于连续性目的，我们将继续使用拼写错误。但是，可以使用Spark中的`withColumnRenamed()`函数来重命名列名。
- en: 'The final selection of columns are chosen as the following:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终选择的列如下所示：
- en: '`fireIndicator`'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`火灾指示`'
- en: '`Zipcode of Incident`'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`事故邮政编码`'
- en: '`Battalion`'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`大队`'
- en: '`Station Area`'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`站点区域`'
- en: '`Box`'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`箱`'
- en: '`Number of Alarms`'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`警报数量`'
- en: '`Unit sequence in call dispatch`'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`呼叫调度中的单位序列`'
- en: '`Neighborhooods - Analysis Boundaries`'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`邻里-分析边界`'
- en: '`Fire Prevention District`'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`消防预防区`'
- en: '`Supervisor District`'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`监管区`'
- en: These columns are selected to avoid data leakage in our modeling. Data leakage
    is common in modeling and can lead to invalid predictive models because it can
    incorporate features that are directly a result of the outcome we are trying to
    predict. Ideally, we wish to incorporate features that are truly independent of
    the outcome. There are several columns that appeared to be leaky and, hence, are
    removed from our dataframe and model.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择这些列是为了避免我们建模中的数据泄漏。数据泄漏在建模中很常见，可能导致无效的预测模型，因为它可能包含直接由我们试图预测的结果产生的特征。理想情况下，我们希望包含真正与结果无关的特征。有几列似乎是有泄漏的，因此从我们的数据框和模型中删除了这些列。
- en: 'All rows with missing or null values are identified and removed in order to
    get the very best performance out of the model without overstating or understating
    key features. An inventory of the rows with missing values can be calculated and
    shown to be 16,551, as seen in the following script:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别并删除所有具有缺失或空值的行，以便在不夸大或低估关键特征的情况下获得模型的最佳性能。可以计算并显示具有缺失值的行的清单，如下脚本所示，数量为16,551：
- en: '![](img/00156.jpeg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00156.jpeg)'
- en: 'We can get a look at the frequency of calls that are fire-related versus those
    that are not, as seen in the following screenshot:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看一下与火灾相关的呼叫频率与非火灾相关的呼叫频率，如下截图所示：
- en: '![](img/00157.jpeg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00157.jpeg)'
- en: '`StringIndexer` is imported to help convert several of the categorical or string
    features into numerical values for ease of computation within the logistic regression
    model. The input of the features needs to be in a vector or array format, which
    is ideal for numeric values. A list of all the features that will be used in the
    model can be seen in the following screenshot:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`StringIndexer`以帮助将几个分类或字符串特征转换为数字值，以便在逻辑回归模型中进行计算。特征的输入需要以向量或数组格式，这对于数字值是理想的。可以在以下屏幕截图中看到将在模型中使用的所有特征的列表：
- en: '![](img/00158.jpeg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00158.jpeg)'
- en: 'An indexer is built for each of the categorical variables specifying the input
    (`inputCol`) and output (`outputCol`) columns that will be used in the model. Each
    column in the dataframe is adjusted or transformed to rebuild a new output with
    the updated indexing, ranging from 0 to the maximum value of the unique count
    of that specific column. The new column is appended with `_Index` at the end.
    While the updated column is created, the original column is still available in
    the dataframe, as seen in the following screenshot:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个分类变量构建了一个索引器，指定了模型中将使用的输入（`inputCol`）和输出（`outputCol`）列。数据框中的每一列都会被调整或转换，以重新构建一个具有更新索引的新输出，范围从0到该特定列的唯一计数的最大值。新列在末尾附加了`_Index`。在创建更新的列的同时，原始列仍然可在数据框中使用，如下屏幕截图所示：
- en: '![](img/00159.jpeg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00159.jpeg)'
- en: 'We can look at one of the newly created columns and compare it with the original
    to see how the strings have been converted to numeric categories. The following
    screenshot shows how `Neighborhooods - Analysis Boundaries` compares with `Neighborhooods -
    Analysis Boundaries_Index`:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以查看其中一个新创建的列，并将其与原始列进行比较，以查看字符串是如何转换为数字类别的。以下屏幕截图显示了`Neighborhooods - Analysis
    Boundaries`与`Neighborhooods - Analysis Boundaries_Index`的比较：
- en: '![](img/00160.jpeg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00160.jpeg)'
- en: The dataframe is then trimmed down to incorporate only the numerical values
    and remove the original categorical variables that were transformed. The non-numerical
    values no longer serve a purpose from a modeling perspective and are dropped from
    the dataframe.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，数据框被修剪以仅包含数字值，并删除了转换的原始分类变量。非数字值从建模的角度来看不再有意义，并且从数据框中删除。
- en: 'The new columns are printed out to confirm that each value type of the dataframe
    is either double precision or integer, as seen in the following screenshot:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出新列以确认数据框的每个值类型都是双精度或整数，如下屏幕截图所示：
- en: '![](img/00161.jpeg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00161.jpeg)'
- en: There's more...
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'A final look at the newly modified dataframe will reveal only numerical values,
    as seen in the following screenshot:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最终查看新修改的数据框将只显示数字值，如下屏幕截图所示：
- en: '![](img/00162.jpeg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00162.jpeg)'
- en: See also
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: In order to learn more about `StringIndexer`, visit the following website: [https://spark.apache.org/docs/2.2.0/ml-features.html#stringindexer](https://spark.apache.org/docs/2.2.0/ml-features.html#stringindexer).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`StringIndexer`的信息，请访问以下网站：[https://spark.apache.org/docs/2.2.0/ml-features.html#stringindexer](https://spark.apache.org/docs/2.2.0/ml-features.html#stringindexer)。
- en: Applying the logistic regression model
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用逻辑回归模型
- en: The stage is now set to apply the model to the dataframe.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经准备好将模型应用于数据框。
- en: Getting ready
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'This section will focus on applying a very common classification model called
    **logistic regression**, which will involve importing some of the following from
    Spark:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍一种非常常见的分类模型，称为**逻辑回归**，这将涉及从Spark中导入以下内容：
- en: '[PRE19]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: How to do it...
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: This section will walk through the steps of applying our model and evaluating
    the results.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍应用我们的模型和评估结果步骤。
- en: 'Execute the following script to lump all of the feature variables in the dataframe
    in a list called `features`:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，将数据框中的所有特征变量汇总到名为`features`的列表中：
- en: '[PRE20]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Execute the following to import `VectorAssembler` and configure the fields
    that will be assigned to the feature vector by assigning the `inputCols` and `outputCol`:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下操作以导入`VectorAssembler`并配置将被分配给特征向量的字段，通过分配`inputCols`和`outputCol`：
- en: '[PRE21]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Execute the following script to apply `VectorAssembler` to the dataframe with
    the `transform` function:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，将`VectorAssembler`应用于数据框，并使用`transform`函数：
- en: '[PRE22]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Modify the dataframe to remove all of the columns except for `fireIndicator`
    and `features`, as seen in the following script:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改数据框，删除除`fireIndicator`和`features`之外的所有列，如下脚本所示：
- en: '[PRE23]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Modify the dataframe to rename `fireIndicator` to `label`, as seen in the following
    script:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改数据框，将`fireIndicator`重命名为`label`，如下脚本所示：
- en: '[PRE24]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Split the entire dataframe, `df`, into training and test sets in a 75:25 ratio,
    with a random seed set as `12345`, as seen in the following script:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将整个数据框`df`分割为75:25的训练和测试集，随机种子设置为`12345`，如下脚本所示：
- en: '[PRE25]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Import the `LogisticRegression` library from `pyspark.ml.classification` and
    configure to incorporate the `label` and `features` from the dataframe, and then
    fit on the training dataset, `trainDF`, as seen in the following script:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`pyspark.ml.classification`中导入`LogisticRegression`库，并配置以将数据框中的`label`和`features`合并，然后在训练数据集`trainDF`上拟合，如下脚本所示：
- en: '[PRE26]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Transform the test dataframe, `testDF`, to apply the logistic regression model.
    The new dataframe with the scores from the prediction is called `df_predicted`,
    as seen in the following script:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换测试数据框`testDF`以应用逻辑回归模型。具有预测得分的新数据框称为`df_predicted`，如下脚本所示：
- en: '[PRE27]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: How it works...
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains the logic behind the steps in applying our model and evaluating
    the results.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释应用我们的模型和评估结果步骤背后的逻辑。
- en: Classification models work best when all of the features are combined in a single
    vector for training purposes. Therefore, we begin the vectorization process by
    collecting all of the features into a single list called `features`. Since our
    label is the first column of the dataframe, we exclude it and pull in every column
    after as a feature column or feature variable.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当所有特征被合并为单个向量进行训练时，分类模型的效果最佳。因此，我们通过将所有特征收集到一个名为`features`的列表中开始向量化过程。由于我们的标签是数据框的第一列，我们将其排除，并将其后的每一列作为特征列或特征变量引入。
- en: The vectorization process continues by converting all of the variables from
    the `features` list into a single vector output to a column called `features`.
    This process requires importing `VectorAssembler` from `pyspark.ml.feature`.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向量化过程继续，将`features`列表中的所有变量转换为名为`features`的单个向量输出到列中。此过程需要从`pyspark.ml.feature`导入`VectorAssembler`。
- en: 'Applying `VectorAssembler` transforms the dataframe by creating a newly added
    column called `features`, as seen in the following screenshot:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用`VectorAssembler`转换数据框，创建一个名为`features`的新添加列，如下截图所示：
- en: '![](img/00163.jpeg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00163.jpeg)'
- en: At this point, the only columns that are necessary for us to use in the model
    are the label column, `fireIndicator`, and the `features` column. All of the other
    columns can be dropped from the dataframe as they will no longer be needed for
    modeling purposes.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一点上，我们在模型中需要使用的唯一列是标签列`fireIndicator`和`features`列。数据框中的所有其他列都可以删除，因为它们在建模过程中将不再需要。
- en: 'Additionally, to help with the logistic regression model, we will change the
    column called `fireIndicator` to `label`. The output of the `df.show()` script
    can be seen in the following screenshot with the newly renamed columns:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，为了帮助逻辑回归模型，我们将名为`fireIndicator`的列更改为`label`。可以在以下截图中看到`df.show()`脚本的输出，其中包含新命名的列：
- en: '![](img/00164.jpeg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00164.jpeg)'
- en: 'In order to minimize overfitting the model, the dataframe will be split into
    a testing and training dataset to fit the model on the training dataset, `trainDF`,
    and test it on the testing dataset, `testDF`. A random seed of `12345` is set
    to keep the randomness consistent each time the cell is executed. We can identify
    the row counts for the data split, as seen in the following screenshot:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了最小化过拟合模型，数据框将被拆分为测试和训练数据集，以在训练数据集`trainDF`上拟合模型，并在测试数据集`testDF`上进行测试。设置随机种子为`12345`，以确保每次执行单元格时随机性保持一致。可以在以下截图中看到数据拆分的行数：
- en: '![](img/00165.jpeg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00165.jpeg)'
- en: A logistic regression model, `LogisticRegression`, is then imported from `pyspark.ml.classification`
    and configured to input the appropriate column names from the dataframe associated
    with the features and the label. Additionally, the logistic regression model is
    assigned to a variable called `logreg` that is then fit to train our data set,
    `trainDF`.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，从`pyspark.ml.classification`导入逻辑回归模型`LogisticRegression`，并配置以从与特征和标签相关的数据框中输入适当的列名。此外，逻辑回归模型分配给一个名为`logreg`的变量，然后拟合以训练我们的数据集`trainDF`。
- en: 'A new dataframe, `predicted_df`, is created based on the transformation of
    the test dataframe, `testDF`, once the logistic regression model is scored on
    it. The model creates three additional columns for `predicted_df`, based on the
    scoring. The three additional columns are `rawPrediction`, `probability`, and
    `prediction`, as seen in the following screenshot:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于测试数据框`testDF`的转换，创建一个名为`predicted_df`的新数据框，一旦逻辑回归模型对其进行评分。该模型为`predicted_df`创建了三个额外的列，基于评分。这三个额外的列是`rawPrediction`、`probability`和`prediction`，如下截图所示：
- en: '![](img/00166.jpeg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00166.jpeg)'
- en: 'Finally, the new columns in `df_predicted` can be profiled, as seen in the
    following screenshot:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，可以对`df_predicted`中的新列进行概要，如下截图所示：
- en: '![](img/00167.jpeg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00167.jpeg)'
- en: There's more...
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: One important thing to keep in mind because it may initially come off as being
    counter-intuitive is that our probability threshold is set at 50 percent in our
    dataframe. Any call with a probability of 0.500 and above is given a prediction
    of 0.0 and any call with a probability of less than 0.500 is given a prediction of
    1.0\. This was set during the pipeline development process and as long as we are
    aware of what the threshold is along with how the prediction is allocated, we
    are in good shape.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 需要牢记的一件重要事情是，因为它可能最初看起来有些违反直觉，我们的概率阈值在数据框中设置为50%。任何概率为0.500及以上的呼叫都会被预测为0.0，任何概率小于0.500的呼叫都会被预测为1.0。这是在管道开发过程中设置的，只要我们知道阈值是多少以及如何分配预测，我们就没问题。
- en: See also
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about `VectorAssembler`, visit the following website:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关`VectorAssembler`的更多信息，请访问以下网站：
- en: '[https://spark.apache.org/docs/latest/ml-features.html#vectorassembler](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/latest/ml-features.html#vectorassembler](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler)'
- en: Evaluating the accuracy of the logistic regression model
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估逻辑回归模型的准确性
- en: We are now ready to evaluate the performance of predicting whether a call was
    correctly classified as a fire incident.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好评估预测呼叫是否被正确分类为火灾事件的性能。
- en: Getting ready
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will perform the model analysis which will require importing the following:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将执行模型分析，需要导入以下内容：
- en: '`from sklearn import metrics`'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from sklearn import metrics`'
- en: How to do it...
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: This section walks through the steps to evaluate the model performance.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将逐步介绍评估模型性能的步骤。
- en: 'Create a confusion matrix using the `.crosstab()` function, as seen in the
    following script:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.crosstab()`函数创建混淆矩阵，如下脚本所示：
- en: '[PRE28]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Import `metrics` from `sklearn` to help measure accuracy using the following
    script:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn`导入`metrics`以帮助使用以下脚本衡量准确性：
- en: '[PRE29]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Create two variables for the `actual` and `predicted` columns from the dataframe
    that will be used to measure accuracy, using the following script:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了衡量准确性，从数据框中创建`actual`和`predicted`列的两个变量，使用以下脚本：
- en: '[PRE30]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Compute the accuracy prediction score using the following script:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本计算准确度预测分数：
- en: '[PRE31]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: How it works...
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains how the model performance is evaluated.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了如何评估模型性能。
- en: 'In order to compute the accuracy of our model, it is important to be able to
    identify how accurate our predictions were. Often, this is best visualized using
    a confusion matrix cross table that shows correct and incorrect prediction scores.
    We create a confusion matrix using the `crosstab()` function off the `df_predicted` dataframe
    that shows us we have 964,980 true negative predictions for labels that are 0
    and we have 48,034 true positive predictions for labels that are 1, as seen in
    the following screenshot:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了计算我们模型的准确度，重要的是能够确定我们的预测有多准确。通常，最好使用混淆矩阵交叉表来可视化，显示正确和错误的预测分数。我们使用`df_predicted`数据框的`crosstab()`函数创建一个混淆矩阵，它显示我们对标签为0的有964,980个真负预测，对标签为1的有48,034个真正预测，如下截图所示：
- en: '![](img/00168.jpeg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00168.jpeg)'
- en: We know from earlier in this section that there are a total of 1,145,589 rows
    from the `testDF` dataframe; therefore, we can calculate the accuracy of the model
    using the following formula: *(TP + TN) / Total*. The accuracy would then be 88.4
    percent.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从本节前面知道`testDF`数据框中共有1,145,589行；因此，我们可以使用以下公式计算模型的准确度：*(TP + TN) / 总数*。准确度为88.4%。
- en: It is important to note that not all false scores are created equal. For example,
    it is more detrimental to classify a call as not relating to fire and ultimately
    have it be related to fire than vice-versa from a fire safety perspective. This
    is referred to as a false negative. There is a metric that accounts for a **false
    negative** (**FN**), known as **recall**.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要注意的是，并非所有的假分数都是相等的。例如，将一个呼叫分类为与火灾无关，最终却与火灾有关，比相反的情况对火灾安全的影响更大。这被称为假阴性。有一个考虑**假阴性**（**FN**）的指标，称为**召回率**。
- en: While we can work out the accuracy manually, as seen in the last step, it is
    ideal to have the accuracy automatically calculated. This can be easily performed
    by importing `sklearn.metrics`, which is a module that is commonly used for scoring
    and model evaluation.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虽然我们可以手动计算准确度，如最后一步所示，但最好是自动计算准确度。这可以通过导入`sklearn.metrics`来轻松实现，这是一个常用于评分和模型评估的模块。
- en: '`sklearn.metrics` takes in two parameters, the actual results that we have
    for labels and the predicted values we derived from the logistic regression model.
    Therefore, two variables are created, `actual` and `predicted`, and an accuracy
    score is calculated using the `accuracy_score()` function, as seen in the following
    screenshot:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`sklearn.metrics`接受两个参数，我们拥有标签的实际结果和从逻辑回归模型中得出的预测值。因此，创建了两个变量`actual`和`predicted`，并使用`accuracy_score()`函数计算准确度分数，如下截图所示：'
- en: '![](img/00169.jpeg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00169.jpeg)'
- en: The accuracy score is the same as we calculated manually, 88.4 percent.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准确度分数与我们手动计算的相同，为88.4%。
- en: There's more...
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'We now know that our model was able to accurately predict whether a call coming
    in is related to fire or not at a rate of 88.4 percent. At first, this may sound
    like a strong prediction; however, it''s always important to compare this to a
    baseline score where every call was predicted as a non-fire call. The predicted
    dataframe, `df_predicted`, had the following breakdown of labels `1` and `0`,
    as seen in the following screenshot:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道我们的模型能够准确预测呼叫是否与火灾相关的比率为88.4%。起初，这可能听起来是一个强有力的预测；然而，将其与一个基准分数进行比较总是很重要，其中每个呼叫都被预测为非火灾呼叫。预测的数据框`df_predicted`中标签`1`和`0`的分布如下截图所示：
- en: '![](img/00170.jpeg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00170.jpeg)'
- en: 'We can run some statistics on that same dataframe to get the mean of label
    occurrences of value `1` using the `df_predicted.describe(''label'').show()` script.
    The output of that script can be seen in the following screenshot:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对同一数据框运行一些统计，使用`df_predicted.describe('label').show()`脚本得到值为`1`的标签出现的平均值。该脚本的输出如下截图所示：
- en: '![](img/00171.jpeg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00171.jpeg)'
- en: A base model has a prediction value of `1` at a rate of 14.94 percent, or in
    other words, it has a prediction rate of *100 - 14.94* percent, which is 85.06
    percent for a value of 0\. Therefore, since 85.06 percent is less than the model
    prediction rate of 88.4 percent, this model provides an improvement over a blind
    guess as to whether a call is fire-related or not.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型的预测值为`1`的比率为14.94%，换句话说，它对值为0的预测率为*100 - 14.94*%，即85.06%。因此，由于85.06%小于模型的预测率88.4%，这个模型相比于盲目猜测呼叫是否与火灾相关提供了改进。
- en: See also
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about accuracy vs. precision, visit the following website:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于准确度与精确度的信息，请访问以下网站：
- en: '[https://www.mathsisfun.com/accuracy-precision.html](https://www.mathsisfun.com/accuracy-precision.html)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.mathsisfun.com/accuracy-precision.html](https://www.mathsisfun.com/accuracy-precision.html)'
