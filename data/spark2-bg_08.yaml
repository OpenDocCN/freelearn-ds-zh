- en: Chapter 8. Spark Graph Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 Spark图处理
- en: A graph is a mathematical concept and a data structure in computer science.
    It has huge applications in many real-world use cases. It is used to model a pair-wise
    relationship between entities. An entity here is known as a vertex and two vertices
    are connected by an edge. A graph comprises a collection of vertices, and the
    edges connecting them.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 图是数学概念，也是计算机科学中的数据结构。它在许多现实世界的应用场景中有着广泛的应用。图用于建模实体之间的成对关系。这里的实体称为顶点，两个顶点通过一条边相连。图由一组顶点和连接它们的边组成。
- en: 'Conceptually, it is a deceptively simple abstraction, but when it comes to
    processing a huge number of vertices and edges, it is computationally intensive
    and consumes a lot of processing time and computing resources. Here is a representation
    of a graph with four vertices and three edges:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，这是一种看似简单的抽象，但当涉及到处理大量顶点和边时，它计算密集，消耗大量处理时间和计算资源。以下是一个具有四个顶点和三条边的图的表示：
- en: '![Spark Graph Processing](img/B05289_08_01_new.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![Spark图处理](img/B05289_08_01_new.jpg)'
- en: Figure 1
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 图1
- en: 'We will cover the following topics in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: Graphs and their uses
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图及其用途
- en: The GraphX library
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图计算库 GraphX
- en: The PageRank algorithm
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网页排名算法 PageRank
- en: The Connected component algorithm
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连通组件算法
- en: GraphFrames
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图框架 GraphFrames
- en: Graph Queries
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图查询
- en: Understanding graphs and their usage
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解图及其用途
- en: There are numerous application constructs that can be modeled as graphs. In
    a social networking application, the relationship between users can be modeled
    as a graph in which the users form the vertices of the graph and the relationships
    between users form the edges of the graph. In a multi-stage job scheduling application,
    the individual tasks form the vertices of the graph and the sequencing of the
    tasks forms the edges. In a road traffic modeling system, the towns form the vertices
    of the graph and the roads connecting the towns form the edges.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多应用程序结构可以被建模为图。在社交网络应用中，用户之间的关系可以被建模为一个图，其中用户构成图的顶点，用户之间的关系构成图的边。在多阶段作业调度应用中，各个任务构成图的顶点，任务的排序构成图的边。在道路交通建模系统中，城镇构成图的顶点，连接城镇的道路构成图的边。
- en: The edges of a given graph have a very important property, namely *the direction
    of the connection*. In many use cases, the direction of the connection doesn't
    matter. The case of connectivity between cities by roads is one such example.
    But if the use case is to produce driving directions within a city, the connectivity
    between traffic junctions has a direction. Take any two traffic junctions and
    there will be road connectivity, but it is also possible that it is a one-way
    road. So it all depends on the direction the traffic is flowing. If the road is
    open to traffic from traffic junction J1 to J2 but closed from J2 to J1, then
    the graph of driving directions will have a connectivity from J1 to J2 and not
    from J2 to J1\. In such cases, the edge connecting J1 and J2 has a direction.
    If the road between J2 and J3 is open in both directions, then the edge connecting
    J2 and J3 has no direction. A graph in which all the edges have a direction is
    called a **directed graph**.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 给定图的边有一个非常重要的属性，即*连接的方向*。在许多应用场景中，连接的方向并不重要。城市间道路连接的情况就是这样一个例子。但如果应用场景是在城市内提供驾驶方向，那么交通路口之间的连接就有方向。任意两个交通路口之间都有道路连接，但也可能是一条单行道。因此，这都取决于交通流向的方向。如果道路允许从交通路口J1到J2的交通，但不允许从J2到J1，那么驾驶方向的图将显示从J1到J2的连接，而不是从J2到J1。在这种情况下，连接J1和J2的边有方向。如果J2和J3之间的道路在两个方向都开放，那么连接J2和J3的边没有方向。所有边都有方向的图称为**有向图**。
- en: Tip
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: When representing a graph pictorially, it is mandatory to give the direction
    on the edges of the directed graph. If it is not a directed graph, the edge can
    be represented without any direction at all or with direction to both sides. This
    is up to the individual's choice. *Figure 1* is not a directed graph, but is represented
    with directions to both the vertices that the edge is connecting.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在图形表示中，对于有向图，必须给出边的方向。如果不是有向图，则可以不带任何方向地表示边，或者向两个方向表示边，这取决于个人选择。*图1*不是有向图，但表示时向连接的两个顶点都给出了方向。
- en: In *Figure 2*, the relationship between two users in a social networking application
    use case is represented as a graph. Users form the vertices and the relationships
    between the users form the edges. User A follows User B. At the same time, User
    A is the son of User B. In this graph, there are two parallel edges sharing the
    same source and destination vertices. A graph containing parallel edges is called
    a multigraph. The graph shown in *Figure 2* is also a directed graph. This is
    a good example of a **directed multigraph**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2*中，社交网络应用用例中两个用户之间的关系被表示为一个图。用户构成顶点，用户之间的关系构成边。用户A关注用户B。同时，用户A是用户B的儿子。在这个图中，有两条平行边共享相同的源和目标顶点。包含平行边的图称为多图。*图2*所示的图也是一个有向图。这是一个**有向多图**的好例子。'
- en: '![Understanding graphs and their usage](img/image_08_002.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![理解图及其用途](img/image_08_002.jpg)'
- en: Figure 2
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图2
- en: In real-world use cases, the vertices and edges of a graph represent real-world
    entities. These entities have properties. For example, in the social connectivity
    graph of users from a social networking application, the users form the vertices
    and users have many properties such as name, e-mail, phone number, and so on.
    Similarly, the relationships between the users form the edges of the graph and
    the edges connecting user vertices can have properties such as relationship. Any
    graph processing application library should be flexible enough to attach any kind
    of property to the vertices and edges of a graph.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界的用例中，图的顶点和边代表了现实世界的实体。这些实体具有属性。例如，在社交网络应用的用户社交连接图中，用户构成顶点，并拥有诸如姓名、电子邮件、电话号码等属性。同样，用户之间的关系构成图的边，连接用户顶点的边可以具有如关系等属性。任何图处理应用库都应足够灵活，以便为图的顶点和边附加任何类型的属性。
- en: The Spark GraphX library
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 火花图X库
- en: For graph processing, many libraries are available in the open source world.
    Giraph, Pregel, GraphLab, and Spark GraphX are some of them. Spark GraphX is one
    of the recent entrants into this space.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在开源世界中，有许多用于图处理的库，如Giraph、Pregel、GraphLab和Spark GraphX等。Spark GraphX是近期进入这一领域的新成员。
- en: What is so special about Spark GraphX? Spark GraphX is a graph processing library
    built on top of the Spark data processing framework. Compared to the other graph
    processing libraries, Spark GraphX has a real advantage. It can make use of all
    the data processing capabilities of Spark. However, in reality, the performance
    of graph processing algorithms is not the only aspect that needs consideration.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX有何特别之处？Spark GraphX是一个建立在Spark数据处理框架之上的图处理库。与其他图处理库相比，Spark GraphX具有真正的优势。它可以利用Spark的所有数据处理能力。然而，在现实中，图处理算法的性能并不是唯一需要考虑的方面。
- en: In many applications, the data that needs to be modeled as a graph does not
    exist in that form naturally. In many use cases, more than the graph processing,
    lots of processor time and other computing resources are expended to get the data
    in the right format so that the graph processing algorithms can be applied. This
    is the sweet spot where the combination of the Spark data processing framework
    and the Spark GraphX library deliver their value. The data processing jobs to
    make the data ready to be consumed by the Spark GraphX can be easily done using
    the plethora of tools available in the Spark toolkit. In summary, the Spark GraphX
    library, which is part of the Spark family, combines the power of the core data
    processing capabilities of Spark and a very easy-to-use graph processing library.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多应用中，需要建模为图的数据并不自然地以那种形式存在。在很多情况下，为了使图处理算法能够应用，需要花费大量的处理器时间和计算资源来将数据转换为正确的格式。这正是Spark数据处理框架与Spark
    GraphX库结合发挥价值的地方。使用Spark工具包中众多的工具，可以轻松完成使数据准备好供Spark GraphX消费的数据处理任务。总之，作为Spark家族一部分的Spark
    GraphX库，结合了Spark核心数据处理能力的强大功能和一个非常易于使用的图处理库。
- en: Revisit the bigger picture once again, as given in *Figure 3*, to set the context
    and see what is being discussed here before getting into the use cases. Unlike
    other chapters, in this chapter, the code samples will only be done in Scala because
    the Spark GraphX library only has a Scala API available at the moment.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 再次回顾*图3*所示的更大画面，以设定背景并了解正在讨论的内容，然后再深入到用例中。与其他章节不同，本章中的代码示例将仅使用Scala，因为Spark
    GraphX库目前仅提供Scala API。
- en: '![The Spark GraphX library](img/image_08_003.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![Spark GraphX 库](img/image_08_003.jpg)'
- en: Figure 3
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3*'
- en: GraphX overview
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GraphX 概览
- en: 'In any real-world use case, it is easy to understand the concept of a graph
    comprising vertices and edges. But when it comes to the implementation, this is
    not a data structure that is very well understood by even good designers and programmers.
    The reason is simple: unlike other ubiquitous data structures such as list, set,
    map, queue, and so on, graphs are not commonly used in most applications. Taking
    this into consideration, the concepts are introduced slowly and steadily, one
    step at a time, with simple and trivial examples, before taking up some real-world
    use cases.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何现实世界的用例中，理解由顶点和边组成的图的概念很容易。但当涉及到实现时，即使是优秀的设计师和程序员也不太了解这种数据结构。原因很简单：与其他无处不在的数据结构（如列表、集合、映射、队列等）不同，图在大多数应用程序中并不常用。考虑到这一点，概念被逐步引入，一步一个脚印，通过简单和微不足道的例子，然后才涉及一些现实世界的用例。
- en: The most important aspect of the Spark GraphX library is a data type, Graph,
    which extends the Spark **resilient distributed dataset** (**RDD**) and introduces
    a new graph abstraction. The graph abstraction in Spark GraphX is a directed multigraph
    with properties attached to all the vertices and edges. The properties for each
    of these vertices and edges can be user defined types that are supported by the
    Scala type system. These types are parameterized in the Graph type. A given graph
    may be required to have different data types for vertices or edges. This is possible
    by using a type system related by an inheritance hierarchy. In addition to all
    these basic ground rules, the library includes a collection of graph builders
    and algorithms.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX 库最重要的方面是一种数据类型，Graph，它扩展了 Spark **弹性分布式数据集**（**RDD**）并引入了一种新的图抽象。Spark
    GraphX 中的图抽象是有向多图，其所有顶点和边都附有属性。这些顶点和边的每个属性可以是 Scala 类型系统支持的用户定义类型。这些类型在 Graph
    类型中参数化。给定的图可能需要为顶点或边使用不同的数据类型。这是通过使用继承层次结构相关的类型系统实现的。除了所有这些基本规则外，该库还包括一组图构建器和算法。
- en: A vertex in a graph is identified by a unique 64-bit long identifier, `org.apache.spark.graphx.VertexId`.
    Instead of the VertexId type, a simple Scala type, Long, can also be used. In
    addition to that, vertices can take any type as a property. An edge in a graph
    should have a source vertex identifier, a destination vertex identifier, and any
    type as a property.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的一个顶点由一个唯一的 64 位长标识符 `org.apache.spark.graphx.VertexId` 标识。除了 VertexId 类型，简单的
    Scala 类型 Long 也可以使用。此外，顶点可以采用任何类型作为属性。图中的边应具有源顶点标识符、目标顶点标识符和任何类型的属性。
- en: '*Figure 4* shows a graph with a vertex property as a String type and an edge
    property as a String type. In addition to the properties, each vertex has a unique
    identifier and each edge has a source vertex number and destination vertex number.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4* 展示了一个图，其顶点属性为字符串类型，边属性也为字符串类型。除了属性外，每个顶点都有一个唯一标识符，每条边都有源顶点编号和目标顶点编号。'
- en: '![GraphX overview](img/image_08_004.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![GraphX 概览](img/image_08_004.jpg)'
- en: Figure 4
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4*'
- en: When processing a graph, there are methods to get the vertices and edges. But
    these independent objects of a graph in isolation may not be sufficient while
    doing processing.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理图时，有方法获取顶点和边。但这些孤立的图对象在处理时可能不足以满足需求。
- en: A vertex has its unique identifier and a property, as stated previously. An
    edge is uniquely identified by its source and destination vertices. To easily
    process each edge in graph processing applications, the triplet abstraction of
    the Spark GraphX library provides an easy way to access the properties of the
    source vertex, destination vertex, and the edge from a single object.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，一个顶点具有其唯一的标识符和属性。一条边由其源顶点和目标顶点唯一标识。为了便于在图处理应用中处理每条边，Spark GraphX 库的三元组抽象提供了一种简便的方法，通过单个对象访问源顶点、目标顶点和边的属性。
- en: 'The following Scala code snippet is used to create the graph shown in *Figure
    4* using the Spark GraphX library. After creating the graph, many methods are
    invoked on the graph that expose various properties of the graph. At the Scala
    REPL prompt, try the following statements:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 Scala 代码片段用于使用 Spark GraphX 库创建*图 4*中所示的图。创建图后，会调用图上的许多方法，这些方法展示了图的各种属性。在
    Scala REPL 提示符下，尝试以下语句：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Readers will be familiar with Spark programming using RDDs. The preceding code
    snippet elucidated the process of constructing the vertices and edges of a graph
    using RDDs. RDDs can be constructed using data persisted in various data stores.
    In real-world use cases, most of the time the data will come from external sources,
    such as NoSQL data stores, and there are ways to construct RDDs using such data.
    Once the RDDs are constructed, graphs can be constructed using that.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 读者将熟悉使用RDD进行Spark编程。上述代码片段阐明了使用RDD构建图的顶点和边的过程。RDD可以使用各种数据存储中持久化的数据构建。在现实世界的用例中，大多数情况下数据将来自外部源，如NoSQL数据存储，并且有方法使用此类数据构建RDD。一旦构建了RDD，就可以使用它们来构建图。
- en: 'The preceding code snippet also explained the various methods available with
    the graph to get all the required details of a given graph. The teaser use case
    covered here is a very small graph in terms of size. In real-world use cases,
    the number of vertices and edges of a graph can be in the millions. Since all
    these abstractions are implemented as RDDs, all the inherent goodness of immutability,
    partitioning, distribution, and parallel processing comes out of the box, hence
    making graph processing highly scalable. Finally, the following tables show how
    the vertices and edges are represented:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码片段还解释了图提供的各种方法，以获取给定图的所有必要详细信息。这里涉及的示例用例是一个规模非常小的图。在现实世界的用例中，图的顶点和边的数量可能达到数百万。由于所有这些抽象都作为RDD实现，因此固有的不可变性、分区、分布和并行处理的开箱即用特性使得图处理高度可扩展。最后，以下表格展示了顶点和边的表示方式：
- en: '**Vertex table**:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**顶点表**：'
- en: '| **VertexId** | **Vertex property** |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| **顶点ID** | **顶点属性** |'
- en: '| 1 | Thomas |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 1 | Thomas |'
- en: '| 2 | Krish |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Krish |'
- en: '| 3 | Mathew |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 3 | Mathew |'
- en: '**Edge table:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**边表**：'
- en: '| **Source VertexId** | **Destination VertexId** | **Edge property** |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| **源顶点ID** | **目标顶点ID** | **边属性** |'
- en: '| 1 | 2 | Follows |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | Follows |'
- en: '| 1 | 2 | Son |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | Son |'
- en: '| 2 | 3 | Follows |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3 | Follows |'
- en: '**Triplet table**:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**三元组表**：'
- en: '| **Source VertexId** | **Destination VertexId** | **Source vertex Property**
    | **Edge property** | **Destination vertex property** |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| **源顶点ID** | **目标顶点ID** | **源顶点属性** | **边属性** | **目标顶点属性** |'
- en: '| 1 | 2 | Thomas | Follows | Krish |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | Thomas | Follows | Krish |'
- en: '| 1 | 2 | Thomas | Son | Krish |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | Thomas | Son | Krish |'
- en: '| 2 | 3 | Krish | Follows | Mathew |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3 | Krish | Follows | Mathew |'
- en: Note
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It is important to note that these tables are only for explanation purposes.
    The real internal representation follows the rules and regulations of RDD representation.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这些表格仅用于解释目的。实际的内部表示遵循RDD表示的规则和规定。
- en: If anything is represented as an RDD, it is bound to get partitioned and distributed.
    But if the partitioning and distribution are done freely, without any control
    for the graph, then it is going to be suboptimal when it comes to graph processing
    performance. Because of that, the creators of the Spark GraphX library have thought
    through this problem well in advance and implemented a graph partitioning strategy
    in order to have an optimized representation of the graph as RDDs.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任何内容表示为RDD，它必然会被分区并分布。但如果分区分布不受图的控制，那么在图处理性能方面将是次优的。因此，Spark GraphX库的创建者提前充分考虑了这个问题，并实施了图分区策略，以便以RDD形式获得优化的图表示。
- en: Graph partitioning
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图分区
- en: It is important to understand a little bit about how the graph RDDs are partitioned
    and distributed across various partitions. This will be useful for advanced optimizations
    that determine the partition and distribution of the various RDDs that are the
    constituent parts of a graph.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 了解图RDD如何分区并在各个分区之间分布是很重要的。这对于确定图的各个组成部分RDD的分区和分布的高级优化非常有用。
- en: In general, there are three RDDs for a given graph. Apart from the vertex RDD
    and the edge RDD, one more RDD is used internally, and that is the routing RDD.
    To have optimal performance, all the vertices needed to form a given edge are
    kept in the same partition where the edge is stored. If a given vertex is participating
    in multiple edges and these edges are located in different partitions, then this
    particular vertex can be stored in multiple partitions.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，给定图有三个RDD。除了顶点RDD和边RDD之外，还有一个内部使用的路由RDD。为了获得最佳性能，构成给定边所需的所有顶点都保持在存储该边的同一分区中。如果某个顶点参与了多个边，并且这些边位于不同的分区中，那么该特定顶点可以存储在多个分区中。
- en: To keep track of the partitions where a given vertex is stored redundantly,
    a routing RDD is also maintained, containing the vertex details and the partitions
    in which each vertex is available.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟踪给定顶点冗余存储的分区，还维护了一个路由RDD，其中包含顶点详细信息以及每个顶点可用的分区。
- en: '*Figure 5* explains this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5*对此进行了解释：'
- en: '![Graph partitioning](img/image_08_005.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图分区](img/image_08_005.jpg)'
- en: Figure 5
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图5
- en: In *Figure 5*, assume that the edges are partitioned into partitions 1 and 2\.
    Also assume that the vertices are partitioned into partitions 1 and 2.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5*中，假设边被划分为分区1和2。同样假设顶点被划分为分区1和2。'
- en: In partition 1, all the vertices required for the edges are available locally.
    But in partition 2, only one vertex for the edge is available locally. So the
    missing vertex is also stored in partition 2 so that all the required vertices
    are available locally.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在分区1中，所有边所需的顶点都可在本地获取。但在分区2中，只有一个边的顶点可在本地获取。因此，缺失的顶点也存储在分区2中，以便所有所需的顶点都可在本地获取。
- en: To keep track of the replications, the vertex routing RDD maintains the partition
    numbers where a given vertex is available. In *Figure 5*, in the vertex routing
    RDD, callout symbols are used to show the partitions in which these vertices are
    replicated. In this way, while processing the edges or triplets, all the information
    related to the constituent vertices is available locally and performance will
    be highly optimal. Since the RDDs are immutable, the problems associated with
    information getting changed are removed, even if they are stored in multiple partitions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟踪复制情况，顶点路由RDD维护了给定顶点可用的分区编号。在*图5*中，在顶点路由RDD中，使用标注符号来显示这些顶点被复制的分区。这样，在处理边或三元组时，所有与组成顶点相关的信息都可在本地获取，性能将高度优化。由于RDD是不可变的，即使它们存储在多个分区中，与信息更改相关的问题也被消除。
- en: Graph processing
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图处理
- en: The constituent elements of a graph exposed to the users are the vertex RDD
    and the edge RDD. Just like any other data structure, a graph also undergoes lots
    of changes because of the change in the underlying data. To make the required
    graph operations to support various use cases, there are many algorithms available,
    using which the data hidden in the graph data structure can be processed to produce
    the desired business outcomes. Before getting into the algorithms to process a
    graph, it is good to understand some of the basics of graph processing using an
    air travel use case.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 向用户展示的图的组成元素是顶点RDD和边RDD。就像任何其他数据结构一样，由于底层数据的变化，图也会经历许多变化。为了使所需的图操作支持各种用例，有许多算法可用，使用这些算法可以处理图数据结构中隐藏的数据，以产生所需的业务成果。在深入了解处理图的算法之前，了解一些使用航空旅行用例的图处理基础知识是很有帮助的。
- en: 'Assume that a person is trying to find a cheap return air ticket from Manchester
    to Bangalore. In the travel preferences, this person has mentioned that he/she
    doesn''t care about the number of stops but the price should be the lowest. Assume
    that the air ticket reservation system has picked up the same stops for both the
    onward and the return journey and produced the following routes or journey legs
    with the cheapest price:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有人试图寻找从曼彻斯特到班加罗尔的廉价返程机票。在旅行偏好中，此人提到他/她不在乎中转次数，但价格应为最低。假设机票预订系统为往返旅程选择了相同的中转站，并生成了以下具有最低价格的路线或航段：
- en: Manchester → London → Colombo → Bangalore
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 曼彻斯特 → 伦敦 → 科伦坡 → 班加罗尔
- en: Bangalore → Colombo → London → Manchester
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 班加罗尔 → 科伦坡 → 伦敦 → 曼彻斯特
- en: 'This route plan is a perfect example of a graph. If the onward journey is considered
    as one graph and the return journey is considered as another graph, the return
    journey graph can be produced by reversing the onward journey graph. At the Scala
    REPL prompt, try the following statements:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 该路线规划是一个图的完美示例。如果将前行旅程视为一个图，将返程视为另一个图，那么返程图可以通过反转前行旅程图来生成。在Scala REPL提示符下，尝试以下语句：
- en: '[PRE1]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The source and destination of the onward journey legs are reversed in the return
    journey legs. When a graph is reversed, only the source and destination vertices
    of the edges are reversed and the identity of the vertices remains the same.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 前行旅程航段的起点和终点在返程航段中被反转。当图被反转时，只有边的起点和终点顶点被反转，顶点的身份保持不变。
- en: 'In other words, the vertex identifiers of each of the vertices remain the same.
    While processing a graph, it is important to know the names of the triplet attributes.
    They are useful for writing programs and processing the graph. As a continuation
    of the same Scala REPL session, try the following statements:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 换言之，每个顶点的标识符保持不变。在处理图时，了解三元组属性的名称很重要。它们对于编写程序和处理图很有用。在同一个 Scala REPL 会话中，尝试以下语句：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following table gives the list of attributes of a triplet that can be used
    to process a graph and extract the required data from the graph. The preceding
    code snippet and the following table may be cross-verified to fully understand:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 下表列出了可用于处理图并从图中提取所需数据的三元组属性。前面的代码片段和下表可以交叉验证，以便完全理解：
- en: '| **Triplet attribute** | **Description** |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| **三元组属性** | **描述** |'
- en: '| `srcId` | Source vertex identifier |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| `srcId` | 源顶点标识符 |'
- en: '| `dstId` | Destination vertex identifier |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| `dstId` | 目标顶点标识符 |'
- en: '| `attr` | Edge property |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `attr` | 边属性 |'
- en: '| `srcAttr` | Source vertex property |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `srcAttr` | 源顶点属性 |'
- en: '| `dstAttr` | Destination vertex property |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| `dstAttr` | 目标顶点属性 |'
- en: In a graph, vertices are RDDs and edges are RDDs, and just by virtue of that,
    transformations are possible.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，顶点是 RDD，边是 RDD，仅凭这一点，就可以进行转换。
- en: 'Now, to demonstrate graph transformations, the same use case is used, with
    a slight twist. Assume that a travel agent is getting special discount prices
    from the airline companies for selected routes. The travel agent decides to keep
    the discount and offer the market price to his/her customers, and for this purpose
    he/she adds 10% to the price given by the airline company. This travel agent has
    noticed that the airport names are being displayed inconsistently and wanted to
    make sure that there is consistent representation when displayed throughout the
    website and decides to change all the stop names to upper case. As a continuation
    of the same Scala REPL session, try the following statements:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了演示图转换，我们使用相同的用例，但稍作改动。假设一个旅行社从航空公司获得了某些路线的特别折扣价格。旅行社决定保留折扣，并向客户提供市场价格，为此，他们将航空公司给出的价格提高了10%。这个旅行社注意到机场名称显示不一致，并希望确保在整个网站上显示时有一致的表示，因此决定将所有停靠点名称改为大写。在同一个
    Scala REPL 会话中，尝试以下语句：
- en: '[PRE3]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In essence, these transformations are truly RDD transformations. If there is
    a conceptual understanding of how these different RDDs are cobbled together to
    form a graph, any programmer with RDD programming proficiency will be able to
    do graph processing very well. This is another testament to the power of the unified
    programming model of Spark.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，这些转换确实是 RDD 转换。如果有关于这些不同的 RDD 如何组合在一起形成图的概念理解，任何具有 RDD 编程熟练度的程序员都能很好地进行图处理。这是
    Spark 统一编程模型的另一个证明。
- en: The preceding use case did the map transformation on vertex and edge RDDs. Similarly,
    filter transformations are another useful type that is commonly used. Apart from
    these, all the transformations and actions can be used to process the vertex and
    edge RDDs.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的用例对顶点和边 RDD 进行了映射转换。类似地，过滤转换是另一种常用的有用类型。除了这些，所有转换和操作都可以用于处理顶点和边 RDD。
- en: Graph structure processing
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图结构处理
- en: 'In the previous section, one type of graph processing is done by individually
    processing the required vertices or edges. One disadvantage of this approach is
    that the processing is going through three different stages, as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，通过单独处理所需的顶点或边完成了一种图处理。这种方法的一个缺点是处理过程分为三个不同的阶段，如下：
- en: Extract vertices or edges from the graph
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从图中提取顶点或边
- en: Process the vertices or edges
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理顶点或边
- en: Re-create a new graph with the processed vertices and edges
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用处理过的顶点和边重新创建一个新图
- en: This is tedious and prone to user programming errors. To circumvent this problem,
    there are some structural operators available in the Spark GraphX library that
    let users process the graph as an individual unit that produces a new graph.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法繁琐且容易出错。为了解决这个问题，Spark GraphX 库提供了一些结构化操作符，允许用户将图作为一个单独的单元进行处理，从而生成一个新的图。
- en: One important structural operation has already been discussed in the previous
    section, which is the reversal of a graph producing a new graph with all the directions
    of the edges reversed. Another frequently used structural operation is the extraction
    of a subgraph from a given graph. The resultant subgraph can be the entire parent
    graph itself or a subset of the parent graph, depending on the operation that
    is done on the parent graph.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节已经讨论了一个重要的结构化操作，即图的反转，它生成一个所有边方向反转的新图。另一个常用的结构化操作是从给定图中提取子图。所得子图可以是整个父图，也可以是父图的子集，具体取决于对父图执行的操作。
- en: 'When creating a graph from data from external sources, there is a possibility
    that the edges may have invalid vertices. This is very much a possibility if the
    vertices and the edges are created from the data coming from two different sources
    or different applications. With these vertices and edges, if a graph is created,
    some of the edges will have invalid vertices, and processing will result in unexpected
    outcomes. The following is a use case where some of the edges containing invalid
    vertices and pruning are done to get rid of that using a structural operator.
    At the Scala REPL prompt, try the following statements:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当从外部数据源创建图时，边可能包含无效顶点。如果顶点和边来自两个不同的数据源或应用程序，这种情况非常可能发生。使用这些顶点和边创建的图，其中一些边将包含无效顶点，处理结果将出现意外。以下是一个用例，其中一些包含无效顶点的边通过结构化操作进行修剪以消除这种情况。在Scala
    REPL提示符下，尝试以下语句：
- en: '[PRE4]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In huge graphs, at times depending on the use case, there can be a whole lot
    of parallel edges. In some use cases, it is possible to combine the data of the
    parallel edges and maintain only one edge instead of maintaining lots of parallel
    edges. In the preceding use case, the final graph without any invalid edges, there
    are parallel edges, one with the property `Follows` and the other with `Son`,
    which have the same source and destination vertices.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型图中，根据具体用例，有时可能存在大量平行边。在某些用例中，可以将平行边的数据合并并仅保留一条边，而不是维护许多平行边。在前述用例中，最终没有无效边的图，存在平行边，一条具有属性`Follows`，另一条具有`Son`，它们具有相同的源和目标顶点。
- en: 'It is fine to combine these parallel edges into one single edge with the property
    concatenated from the parallel edges, which will reduce the number of edges without
    losing information. This is accomplished by the groupEdges structural operation
    of the graph. As a continuation of the same Scala REPL session, try the following
    statements:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些平行边合并为一条具有从平行边串联属性的单一边是可行的，这将减少边的数量而不丢失信息。这是通过图的groupEdges结构化操作实现的。在同一Scala
    REPL会话中，尝试以下语句：
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The preceding structural change in the graph reduced the number of edges by
    grouping the edges. When the edge property is numerical, and if it makes sense
    to consolidate by aggregating them, then also reduce the number of edges by removing
    the parallel edges, which can reduce the graph processing time considerably.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的图结构变化通过聚合边减少了边的数量。当边属性为数值型且通过聚合进行合并有意义时，也可以通过移除平行边来减少边的数量，这能显著减少图处理时间。
- en: Note
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: One important point to note in this code snippet is that the graph has been
    partitioned before the group-by operation on the edges.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 本代码片段中一个重要点是，在边上执行group-by操作之前，图已经进行了分区。
- en: By default, the edges and the constituent vertices of a given graph need not
    be co-located in the same partition. For the group-by operation to work, all the
    parallel edges have to be located on the same partition. The CanonicalRandomVertexCut
    partition strategy makes sure that colocation happens for all the edges between
    two vertices, irrespective of direction.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，给定图的边及其组成顶点无需位于同一分区。为了使group-by操作生效，所有平行边必须位于同一分区。CanonicalRandomVertexCut分区策略确保两个顶点之间的所有边，无论方向如何，都能实现共置。
- en: There are some more structural operators available in the Spark GraphX library
    and a consultation of the Spark documentation will give a good insight into them.
    They can be used depending on the use case.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark GraphX库中还有更多结构化操作符可供使用，查阅Spark文档可以深入了解这些操作符，它们可根据具体用例进行应用。
- en: Tennis tournament analysis
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网球锦标赛分析
- en: 'Since the basic graph processing fundamentals are in place, now it is time
    to take up a real-world use case that uses graphs. Here, a tennis tournament''s
    results are modeled using a graph. The Barclays ATP World Tour 2015 singles competition
    results are modeled using a graph. The vertices contain the player details and
    the edges contain the individual matches played. The edges are formed in such
    a way that the source vertex is the player who won the match and the destination
    vertex is the player who lost the match. The edge property contains the type of
    the match, the points the winner got in the match, and the head-to-head count
    of the players in the match. The points system used here is fictitious and is
    nothing but a weight earned by the winner in that particular match. The initial
    group matches carried the least weight, the semi-final matches carried more weight,
    and the final match carried the most weight. With this way of modeling the results,
    find out the following details by processing the graph:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 既然基本的图处理基础已经就位，现在是时候采用一个使用图的现实世界用例了。这里，我们使用图来模拟一场网球锦标赛的结果。使用图来模拟2015年巴克莱ATP世界巡回赛单打比赛的结果。顶点包含球员详情，边包含个人比赛记录。边的形成方式是，源顶点是赢得比赛的球员，目标顶点是输掉比赛的球员。边属性包含比赛类型、赢家在比赛中获得的分数以及球员之间的交锋次数。这里使用的积分系统是虚构的，仅仅是赢家在那场比赛中获得的权重。小组赛初赛权重最低，半决赛权重更高，决赛权重最高。通过这种方式模拟结果，处理图表以找出以下详细信息：
- en: List all the match details.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有比赛详情。
- en: List all the matches with player names, the match type, and the result.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有比赛，包括球员姓名、比赛类型和结果。
- en: List all the Group 1 winners with the points in the match.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有小组1的获胜者及其比赛中的积分。
- en: List all the Group 2 winners with the points in the match.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有小组2的获胜者及其比赛中的积分。
- en: List all the semi-final winners with the points in the match.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有半决赛获胜者及其比赛中的积分。
- en: List the final winner with the points in the match.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出决赛获胜者及其比赛中的积分。
- en: List the players with the total points they earned in the whole tournament.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出球员在整个锦标赛中获得的总积分。
- en: List the winner of the match by finding the highest number of points scored
    by the player.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过找出得分最高的球员来列出比赛获胜者。
- en: In the group-based matches, because of the round robin scheme of draws, it is
    possible that the same players can meet more than once. Find if there are any
    such players who have played each other more than once in this tournament.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在小组赛阶段，由于循环赛制，同一组球员可能会多次相遇。查找是否有任何球员在这场锦标赛中相互比赛超过一次。
- en: List the players who have won at least one match.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出至少赢得一场比赛的球员。
- en: List the players who have lost at least one match.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出至少输掉一场比赛的球员。
- en: List the players who have won at least one match and lost at least one match.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出至少赢得一场比赛且至少输掉一场比赛的球员。
- en: List the players who have no wins at all.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出完全没有获胜的球员。
- en: List the players who have no losses at all.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出完全没有输掉比赛的球员。
- en: 'Those who are not familiar with the game of tennis have no need to worry because
    the rules of the games are not discussed here and are not required to understand
    this use case. For all practical purposes, it is to be taken only as a game played
    between two people, where one wins and the other loses. At the Scala REPL prompt,
    try the following statements:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不熟悉网球比赛的人来说，无需担心，因为这里不讨论比赛规则，也不需要理解这个用例。实际上，我们只将其视为两人之间的比赛，其中一人获胜，另一人输掉。在Scala
    REPL提示符下，尝试以下语句：
- en: '[PRE6]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The graph containing the tennis tournament has been created, and from now on,
    all that is going to be done is the processing of this base graph and extracting
    information from it to fulfill the requirements of the use cases:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 包含网球锦标赛的图已经创建，从现在开始，所有要做的是处理这个基础图并从中提取信息以满足用例需求：
- en: '[PRE7]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It is worth noticing here that the usage of triplets in graphs comes in handy
    for extracting all the required data elements of a given tennis match, including
    who was playing, who won, and the match type, from a single object. The following
    implementations of analysis use cases involve filtering the tennis match records
    of the tournament. Here, only simple filtering logic is used, but in real-world
    use cases, any complex logic can be implemented in functions, and that can be
    passed as arguments to the filter transformations:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，在图形中使用三元组对于提取给定网球比赛的所有必需数据元素非常方便，包括谁在比赛、谁获胜以及比赛类型，这些都可以从一个对象中获取。以下分析用例的实现涉及筛选锦标赛的网球比赛记录。这里仅使用了简单的筛选逻辑，但在实际用例中，任何复杂的逻辑都可以在函数中实现，并作为参数传递给筛选转换：
- en: '[PRE8]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following implementations of analysis use cases involve grouping by key
    and doing summary calculations. It is not limited to just finding the sum of the
    tennis match record points, as shown in the following use case implementations;
    rather, user-defined functions can be used to do the calculations as well:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下分析用例的实现涉及按键分组并进行汇总计算。它不仅限于查找网球比赛记录点的总和，如以下用例实现所示；实际上，可以使用用户定义的函数进行计算：
- en: '[PRE9]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following implementations of analysis use cases involve finding unique
    records from the query. The Spark distinct transformation does that:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下分析用例的实现涉及从查询中查找唯一记录。Spark的distinct转换可以实现这一点：
- en: '[PRE10]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In this use case, not much effort has been made to make the results pretty because
    they are reduced to simple RDD-based structures that can be manipulated however
    required using the RDD programming techniques that were already covered in the
    initial chapters of the book.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个用例中，并没有花费太多精力来美化结果，因为它们被简化为简单的RDD结构，可以使用本书前几章已经介绍的RDD编程技术根据需要进行操作。
- en: The highly succinct and uniform programming model of Spark, in conjunction with
    the Spark GraphX library, helps developers build real-world use cases with very
    few lines of code. This also demonstrates that once the right graph structure
    is built with the relevant data, with the supported graph operations, lots of
    truth that is hidden in the underlying data can be brought to light.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的高度简洁和统一的编程模型，结合Spark GraphX库，帮助开发者用很少的代码构建实际用例。这也表明，一旦使用相关数据构建了正确的图形结构，并使用支持的图形操作，就可以揭示隐藏在底层数据中的许多真相。
- en: Applying the PageRank algorithm
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用PageRank算法
- en: A research paper, titled *The Anatomy of a Large-Scale Hypertextual Web Search
    Engine,* by Sergey Brin and Lawrence Page, revolutionized web searching, and Google
    based its search engine on this concept of PageRank and came to dominate other
    web search engines.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 由Sergey Brin和Lawrence Page撰写的研究论文，题为*The Anatomy of a Large-Scale Hypertextual
    Web Search Engine*，彻底改变了网络搜索，Google基于这一PageRank概念构建了其搜索引擎，并主导了其他网络搜索引擎。
- en: When searching the web using Google, pages that are ranked highly by its algorithm
    are displayed. In the context of graphs, instead of web pages, if vertices are
    ranked based on the same algorithm, lots of new inferences can be made. From the
    outside, it may sound like this PageRank algorithm is useful only for web searches.
    But it has immense potential to be applied to many other areas.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Google搜索网页时，其算法排名高的页面会被显示。在图形的上下文中，如果基于相同的算法对顶点进行排名，可以得出许多新的推断。从表面上看，这个PageRank算法似乎只对网络搜索有用。但它具有巨大的潜力，可以应用于许多其他领域。
- en: In graph parlance, if there is an edge, E, connecting two vertices, from V1
    to V2, according to the PageRank algorithm, V2 is more important than V1\. In
    a huge graph of vertices and edges, it is possible to calculate the PageRank of
    each and every vertex.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在图形术语中，如果存在一条边E，连接两个顶点，从V1到V2，根据PageRank算法，V2比V1更重要。在一个包含大量顶点和边的巨大图形中，可以计算出每个顶点的PageRank。
- en: The PageRank algorithm can be applied very well to the tennis tournament analysis
    use case covered in the preceding section. In the graph representation that is
    adopted here, each match is represented as an edge. The source vertex has the
    winner's details and the destination vertex has the loser's details. In the game
    of tennis, if this can be termed as some fictitious importance ranking, then in
    a given match the winner has higher importance ranking than the loser.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节中提到的网球锦标赛分析用例，PageRank算法可以很好地应用于此。在此采用的图表示中，每场比赛都表示为一个边。源顶点包含获胜者的详细信息，而目标顶点包含失败者的详细信息。在网球比赛中，如果可以将这称为某种虚构的重要性排名，那么在一场比赛中，获胜者的重要性排名高于失败者。
- en: 'If the graph in the previous use case is taken to demonstrate the PageRank
    algorithm, then that graph has to be reversed so that the winner of each match
    becomes the destination vertex of each and every edge. At the Scala REPL prompt,
    try the following statements:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在前述用例中采用的图来演示PageRank算法，那么该图必须反转，使得每场比赛的获胜者成为每个边的目标顶点。在Scala REPL提示符下，尝试以下语句：
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If the preceding code is scrutinized carefully, it can be seen that the highest
    ranked players have won the highest number of matches.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仔细审查上述代码，可以看出排名最高的玩家赢得了最多的比赛。
- en: Connected component algorithm
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连通分量算法
- en: In a graph, finding a subgraph consisting of connected vertices is a very common
    requirement with tremendous applications. In any graph, two vertices are that
    connected to each other by paths consisting of one or more edges, and are not
    connected to any other vertex in the same graph, are called a connected component.
    For example, in a graph, G, vertex V1 is connected to V2 by an edge and V2 is
    connected to V3 by another edge. In the same graph, G, vertex V4 is connected
    to V5 by another edge. In this case V1 and V3 are connected, V4 and V5 are connected
    and V1 and V5 are not connected. In graph G, there are two connected components.
    The Spark GraphX library has an implementation of the connected components algorithm.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，寻找由相连顶点组成的子图是一个非常常见的需求，具有广泛的应用。在任何图中，两个通过一条或多条边组成的路径相连的顶点，并且不与同一图中的任何其他顶点相连，被称为连通分量。例如，在图G中，顶点V1通过一条边与V2相连，V2通过另一条边与V3相连。在同一图G中，顶点V4通过另一条边与V5相连。在这种情况下，V1和V3相连，V4和V5相连，而V1和V5不相连。在图G中，有两个连通分量。Spark
    GraphX库实现了连通分量算法。
- en: In a social networking application, if the connections between the users are
    modeled as a graph, finding whether a given user is connected to another user
    is achieved by checking whether there is a connected component with these two
    vertices. In computer games, maze traversing from point A to point B can be done
    using a connected components algorithm by modeling the maze junctions as vertices
    and the paths connecting the junctions as edges in a graph.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在社交网络应用中，如果用户之间的连接被建模为图，那么检查给定用户是否与另一用户相连，可以通过检查这两个顶点是否存在连通分量来实现。在计算机游戏中，从点A到点B的迷宫穿越可以通过将迷宫交汇点建模为顶点，将连接交汇点的路径建模为图中的边，并使用连通分量算法来实现。
- en: 'In computer networks, checking whether packets can be sent from one IP address
    to another IP address is achieved by using a connected components algorithm. In
    logistics applications, such as a courier service, checking whether a packet can
    be sent from point A to point B is achieved by using a connected components algorithm.
    *Figure 6* shows a graph with three connected components:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机网络中，检查数据包是否可以从一个IP地址发送到另一个IP地址，是通过使用连通分量算法实现的。在物流应用中，例如快递服务，检查包裹是否可以从点A发送到点B，也是通过使用连通分量算法实现的。*图6*展示了一个具有三个连通分量的图：
- en: '![Connected component algorithm](img/image_08_006.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![连通分量算法](img/image_08_006.jpg)'
- en: Figure 6
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图6
- en: '*Figure 6* is the pictorial representation of a graph. In it, there are three
    *clusters* of vertices connected by edges. In other words, there are three connected
    components in this graph.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6*是图的图形表示。其中，有三个*簇*的顶点通过边相连。换句话说，该图中有三个连通分量。'
- en: 'The use case of users in a social networking application in which they follow
    each other is taken up here again for elucidation purposes. By extracting the
    connected components of the graph, it is possible to see whether any two users
    are connected or not. *Figure 7* shows the user graph:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这里再次以社交网络应用中用户相互关注的用例为例，以阐明其原理。通过提取图的连通分量，可以查看任意两个用户是否相连。*图 7* 展示了用户图：
- en: '![Connected component algorithm](img/image_08_007.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![连通分量算法](img/image_08_007.jpg)'
- en: Figure 7
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7
- en: 'In the graph depicted in *Figure 7*, it is clearly evident that there are two
    connected components. It is easy to say that Thomas and Mathew are connected and
    at the same time Thomas and Martin are not connected. If the connected component
    graph is extracted, it can be seen that Thomas and Martin will have the same connected
    component identifier, and at the same time, Thomas and Martin will have a different
    connected component identifiers. At the Scala REPL prompt, try the following statements:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 7* 所示的图中，很明显可以看出存在两个连通分量。可以轻松判断 Thomas 和 Mathew 相连，而 Thomas 和 Martin 不相连。如果提取连通分量图，可以看到
    Thomas 和 Martin 将具有相同的连通分量标识符，同时 Thomas 和 Martin 将具有不同的连通分量标识符。在 Scala REPL 提示符下，尝试以下语句：
- en: '[PRE12]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: There are some more graph processing algorithms available in the Spark GraphX
    library, and a detailed treatment of the complete set of algorithms deserves book
    on its own. The point here is that the Spark GraphX library provides very easy-to-use
    graph algorithms that fit very well into Spark's uniform programming model.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX 库中还有一些其他的图处理算法，对完整算法集的详细讨论足以写成一本书。关键在于，Spark GraphX 库提供了非常易于使用的图算法，这些算法很好地融入了
    Spark 的统一编程模型。
- en: Understanding GraphFrames
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 GraphFrames
- en: The Spark GraphX library is the graph processing library that has the least
    programming language support. Scala is the only programming language supported
    by the Spark GraphX library. GraphFrames is a new graph processing library available
    as an external Spark package developed by Databricks, University of California,
    Berkley, and Massachusetts Institute of Technology, built on top of Spark DataFrames.
    Since it is built on top of DataFrames, all the operations that can be done on
    DataFrames are potentially possible on GraphFrames, with support for programming
    languages such as Scala, Java, Python, and R with a uniform API. Since GraphFrames
    is built on top of DataFrames, the persistence of data, support for numerous data
    sources, and powerful graph queries in Spark SQL are additional benefits users
    get for free.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX 库是支持编程语言最少的图处理库。Scala 是 Spark GraphX 库唯一支持的编程语言。GraphFrames 是由
    Databricks、加州大学伯克利分校和麻省理工学院开发的新图处理库，作为外部 Spark 包提供，建立在 Spark DataFrames 之上。由于它是基于
    DataFrames 构建的，因此所有可以在 DataFrames 上执行的操作都可能适用于 GraphFrames，支持 Scala、Java、Python
    和 R 等编程语言，并具有统一的 API。由于 GraphFrames 基于 DataFrames，因此数据的持久性、对多种数据源的支持以及在 Spark
    SQL 中强大的图查询功能是用户免费获得的额外好处。
- en: Just like the Spark GraphX library, in GraphFrames the data is stored in vertices
    and edges. The vertices and edges use DataFrames as the data structure. The first
    use case covered in the beginning of this chapter is used again to elucidate GraphFrames-based
    graph processing.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Spark GraphX 库类似，在 GraphFrames 中，数据存储在顶点和边中。顶点和边使用 DataFrames 作为数据结构。本章开头介绍的第一个用例再次用于阐明基于
    GraphFrames 的图处理。
- en: Note
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**CAUTION**: GraphFrames is an external Spark package. It has some incompatibility
    with Spark 2.0\. Because of that, the following code snippets will not work with
    Spark 2.0\. They work with Spark 1.6\. Refer to their website to check Spark 2.0
    support.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：GraphFrames 是外部 Spark 包。它与 Spark 2.0 存在一些不兼容。因此，以下代码片段不适用于 Spark 2.0。它们适用于
    Spark 1.6。请访问他们的网站以检查 Spark 2.0 支持情况。'
- en: 'At the Scala REPL prompt of Spark 1.6, try the following statements. Since
    GraphFrames is an external Spark package, while bringing up the appropriate REPL,
    the library has to be imported and the following command is used in the terminal
    prompt to fire up the REPL and make sure that the library is loaded without any
    error messages:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Spark 1.6 的 Scala REPL 提示符下，尝试以下语句。由于 GraphFrames 是外部 Spark 包，在启动相应的 REPL
    时，需要导入库，并在终端提示符下使用以下命令启动 REPL，确保库加载无误：
- en: '[PRE13]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: When creating DataFrames for the GraphFrame, the only thing to keep in mind
    is that there are some mandatory columns for the vertices and the edges. In the
    DataFrame for vertices, the id column is mandatory. In the DataFrame for edges,
    the src and dst columns are mandatory. Apart from that, any number of arbitrary
    columns can be stored with both the vertices and the edges of a GraphFrame. In
    the Spark GraphX library, the vertex identifier must be a long integer, but the
    GraphFrame doesn't have any such limitations and any type is supported as the
    vertex identifier. Readers should already be familiar with DataFrames; any operation
    that can be done on a DataFrame can be done on the vertices and edges of a GraphFrame.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在为GraphFrame创建DataFrames时，唯一需要注意的是，对于顶点和边有一些强制性列。在顶点的DataFrame中，id列是强制性的。在边的DataFrame中，src和dst列是强制性的。除此之外，可以在GraphFrame的顶点和边上存储任意数量的任意列。在Spark
    GraphX库中，顶点标识符必须是长整型，但GraphFrame没有这样的限制，任何类型都可以作为顶点标识符。读者应该已经熟悉DataFrames；任何可以在DataFrame上执行的操作都可以在GraphFrame的顶点和边上执行。
- en: Tip
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: All the graph processing algorithms supported by Spark GraphX are supported
    by GraphFrames as well.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 所有Spark GraphX支持的图处理算法，GraphFrames也同样支持。
- en: The Python version of GraphFrames has fewer features. Since Python is not a
    supported programming language for the Spark GraphX library, GraphFrame to GraphX
    and GraphX to GraphFrame conversions are not supported in Python. Since readers
    are familiar with the creation of DataFrames in Spark using Python, the Python
    example is omitted here. Moreover, there are some pending defects in the GraphFrames
    API for Python and not all the features demonstrated previously using Scala function
    properly in Python at the time of writing.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: GraphFrames的Python版本功能较少。由于Python不是Spark GraphX库支持的编程语言，因此在Python中不支持GraphFrame与GraphX之间的转换。鉴于读者熟悉使用Python在Spark中创建DataFrames，此处省略了Python示例。此外，GraphFrames
    API的Python版本存在一些待解决的缺陷，并且在撰写本文时，并非所有之前在Scala中演示的功能都能在Python中正常工作。
- en: Understanding GraphFrames queries
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解GraphFrames查询
- en: The Spark GraphX library is the RDD-based graph processing library, but GraphFrames
    is a Spark DataFrame-based graph processing library that is available as an external
    package. Spark GraphX supports many graph processing algorithms, but GraphFrames
    supports not only graph processing algorithms, but also graph queries. The major
    difference between graph processing algorithms and graph queries is that graph
    processing algorithms are used to process the data hidden in a graph data structure,
    while graph queries are used to search for patterns in the data hidden in a graph
    data structure. In GraphFrame parlance, graph queries are also known as motif
    finding. This has tremendous applications in genetics and other biological sciences
    that deal with sequence motifs.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX库是基于RDD的图处理库，而GraphFrames是作为外部包提供的基于Spark DataFrame的图处理库。Spark GraphX支持多种图处理算法，但GraphFrames不仅支持图处理算法，还支持图查询。图处理算法与图查询之间的主要区别在于，图处理算法用于处理图数据结构中隐藏的数据，而图查询用于搜索图数据结构中隐藏的数据中的模式。在GraphFrame术语中，图查询也称为模式查找。这在涉及序列模式的遗传学和其他生物科学中具有巨大的应用价值。
- en: From a use case perspective, take the use case of users following each other
    in a social media application. Users have relationships between them. In the previous
    sections, these relationships were modeled as graphs. In real-world use cases,
    such graphs can become really huge, and if there is a need to find users with
    relationships between them in both directions, it can be expressed as a pattern
    in graph query, and such relationships can be found using easy programmatic constructs.
    The following demonstration models the relationship between the users in a GraphFrame,
    and a pattern search is done using that.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 从用例角度出发，以社交媒体应用中用户相互关注为例。用户之间存在关系。在前述章节中，这些关系被建模为图。在现实世界的用例中，此类图可能变得非常庞大，如果需要找到在两个方向上存在关系的用户，这可以通过图查询中的模式来表达，并使用简单的编程结构来找到这些关系。以下演示模型展示了用户间关系在GraphFrame中的表示，并利用该模型进行了模式搜索。
- en: 'At the Scala REPL prompt of Spark 1.6, try the following statements:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark 1.6的Scala REPL提示符下，尝试以下语句：
- en: '[PRE14]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note that the columns in the graph query result are formed with the elements
    given in the search pattern. There is no limit to the way the patterns can be
    formed.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，图查询结果中的列是由搜索模式中给出的元素构成的。形成模式的方式没有限制。
- en: Note
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note the data type of the graph query result. It is a DataFrame object. That
    brings a great flexibility in processing the query results using the familiar
    Spark SQL library.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 注意图查询结果的数据类型。它是一个DataFrame对象。这为使用熟悉的Spark SQL库处理查询结果带来了极大的灵活性。
- en: The biggest limitation of the Spark GraphX library is that its API is not currently
    supported with programming languages such as Python and R. Since GraphFrames is
    a DataFrame-based library, once it has matured, it will enable graph processing
    in all the programming languages supported by DataFrames. This Spark external
    package is definitely a potential candidate to be included as part of the Spark.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX库的最大限制是其API目前不支持Python和R等编程语言。由于GraphFrames是基于DataFrame的库，一旦成熟，它将使所有支持DataFrame的编程语言都能进行图处理。这个Spark外部包无疑是未来可能被纳入Spark的一部分的有力候选。
- en: References
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'For more information please visit the following links:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解更多信息，请访问以下链接：
- en: '[https://spark.apache.org/docs/1.5.2/graphx-programming-guide.html](https://spark.apache.org/docs/1.5.2/graphx-programming-guide.html)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/1.5.2/graphx-programming-guide.html](https://spark.apache.org/docs/1.5.2/graphx-programming-guide.html)'
- en: '[https://en.wikipedia.org/wiki/2015_ATP_World_Tour_Finals_%E2%80%93_Singles](https://en.wikipedia.org/wiki/2015_ATP_World_Tour_Finals_%E2%80%93_Singles)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://en.wikipedia.org/wiki/2015_ATP_World_Tour_Finals_%E2%80%93_Singles](https://en.wikipedia.org/wiki/2015_ATP_World_Tour_Finals_%E2%80%93_Singles)'
- en: '[http://www.protennislive.com/posting/2015/605/mds.pdf](http://www.protennislive.com/posting/2015/605/mds.pdf)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.protennislive.com/posting/2015/605/mds.pdf](http://www.protennislive.com/posting/2015/605/mds.pdf)'
- en: '[http://infolab.stanford.edu/~backrub/google.html](http://infolab.stanford.edu/~backrub/google.html)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://infolab.stanford.edu/~backrub/google.html](http://infolab.stanford.edu/~backrub/google.html)'
- en: '[http://graphframes.github.io/index.html](http://graphframes.github.io/index.html)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://graphframes.github.io/index.html](http://graphframes.github.io/index.html)'
- en: '[https://github.com/graphframes/graphframes](https://github.com/graphframes/graphframes)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/graphframes/graphframes](https://github.com/graphframes/graphframes)'
- en: '[https://spark-packages.org/package/graphframes/graphframes](https://spark-packages.org/package/graphframes/graphframes)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://spark-packages.org/package/graphframes/graphframes](https://spark-packages.org/package/graphframes/graphframes)'
- en: Summary
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: A Graph is a very useful data structure that has great application potential.
    Even though it is not very commonly used in most applications, there are some
    unique application use cases where using a Graph as a data structure is essential.
    A data structure is effectively used only when it is used in conjunction with
    well tested and highly optimized algorithms. Mathematicians and computer scientists
    have come up with many algorithms to process data that is part of a graph data
    structure. The Spark GraphX library has a large number of such algorithms implemented
    on top of the Spark core. This chapter provided a whirlwind tour of the Spark
    GraphX library and covered some of the basics through use cases at an introductory
    level.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图是一种非常有用的数据结构，具有广泛的应用潜力。尽管在大多数应用中不常使用，但在某些独特的应用场景中，使用图作为数据结构是必不可少的。只有当数据结构与经过充分测试和高度优化的算法结合使用时，才能有效地使用它。数学家和计算机科学家已经提出了许多处理图数据结构中数据的算法。Spark
    GraphX库在Spark核心之上实现了大量此类算法。本章通过入门级别的用例对Spark GraphX库进行了快速概览，并介绍了一些基础知识。
- en: The DataFrame-based graph abstraction named GraphFrames, which comes in an external
    Spark package available separately from Spark, has tremendous potential in graph
    processing as well as graph queries. A brief introduction to this external Spark
    package has been provided in order to do graph queries to find patterns in graphs.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 基于DataFrame的图抽象名为GraphFrames，它是Spark的一个外部包，可单独获取，在图处理和图查询方面具有巨大潜力。为了进行图查询以发现图中的模式，已提供了对该外部Spark包的简要介绍。
- en: Any book teaching a new technology has to conclude with an application covering
    its salient features. Spark is no different. So far in this book, Spark as a next
    generation data processing platform has been covered. Now it is the time to tie
    up all the loose ends and build an end-to-end application. The next chapter is
    going to cover the design and development of a data processing application using
    Spark and the family of libraries built on top of it.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 任何教授新技术的书籍都应以一个涵盖其显著特点的应用案例作为结尾。Spark也不例外。到目前为止，本书已经介绍了Spark作为下一代数据处理平台的特性。现在是时候收尾并构建一个端到端应用了。下一章将涵盖使用Spark及其上层构建的库家族设计和开发数据处理应用的内容。
