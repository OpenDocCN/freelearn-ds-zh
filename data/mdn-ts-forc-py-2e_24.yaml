- en: '20'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '20'
- en: Evaluating Forecasts—Validation Strategies
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估预测—验证策略
- en: Throughout the last few chapters, we have been looking at a few relevant, but
    seldom discussed, aspects of time series forecasting. While we learned about different
    forecasting metrics in the previous chapter, we now move on to the final piece
    of the puzzle—validation strategies. This is another integral part of evaluating
    forecasts.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几章中，我们一直在关注一些相关但很少讨论的时间序列预测方面。虽然我们在前一章中学习了不同的预测指标，但现在我们要进入拼图的最后一块——验证策略。这是评估预测的另一个重要部分。
- en: In this chapter, we try to answer the question *How do we choose the validation
    strategy to evaluate models from a time series forecasting perspective?* We will
    look at different strategies and their merits and demerits so that, by the end
    of the chapter, you can make an informed decision to set up the validation strategy
    for your time series problem.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们尝试回答问题：*如何选择验证策略来从时间序列预测的角度评估模型？* 我们将查看不同的策略及其优缺点，以便在本章结束时，您能够做出明智的决策，为您的时间序列问题设置验证策略。
- en: 'In this chapter, we will be covering these main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: Model validation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型验证
- en: Holdout strategies
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 留出法策略
- en: Cross-validation strategies
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉验证策略
- en: Choosing a validation strategy
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择验证策略
- en: Validation strategies for datasets with multiple time series
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多时间序列数据集的验证策略
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need to set up the Anaconda environment by following the instructions
    in the *Preface* of the book to get a working environment with all the packages
    and datasets required for the code in this book.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要通过按照本书*前言*中的说明设置Anaconda环境，才能获得一个具备本书中所需所有软件包和数据集的工作环境。
- en: The associated code for the chapter can be found at [https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-/tree/main/notebooks/Chapter20](https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-/tree/main/notebooks/Chapter20).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章相关代码可以在[https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-/tree/main/notebooks/Chapter20](https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-/tree/main/notebooks/Chapter20)找到。
- en: Model validation
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型验证
- en: In *Chapter 19*, *Evaluating Forecast Errors*—*A Survey of Forecast Metrics*,
    we learned about different forecast metrics that can be used to measure the quality
    of a forecast. One of the main uses for this is to measure how well our forecast
    is doing on test data (new and unseen data), but this comes after we train a model,
    tweak it, and tinker with it until we are happy with it. How do we know whether
    a model we are training or tweaking is good enough?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第19章*《*评估预测误差*—*预测指标概述*》中，我们学习了不同的预测指标，这些指标可以用来衡量预测的质量。其主要用途之一是衡量我们的预测在测试数据（新的、未见过的数据）上的表现，但这通常是在我们训练模型、调整模型、反复修改直到满意后进行的。那么我们如何知道一个正在训练或调整的模型是否足够好呢？
- en: Model validation is the process of evaluating a trained model using data to
    assess how good the model is. We use the metrics we learned about in *Chapter
    19*, *Evaluating Forecast Errors*—*A Survey of Forecast Metrics*, to calculate
    the goodness of the forecast. But there is one question we haven’t answered. Which
    part of the data do we use to evaluate? In a standard machine learning setup (classification
    or regression), we randomly sample a portion of the training data and call it
    validation data, and it is based on this data that all the modeling decisions
    are taken. The best practice in the field is to use cross-validation. **Cross-validation**
    is a resampling procedure where we sample different portions of the training dataset
    to train and test in multiple iterations. In addition to repeated evaluation,
    cross-validation also makes the most efficient use of the data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 模型验证是使用数据评估训练模型的一种过程，用来评估模型的好坏。我们使用在*第19章*《*评估预测误差*—*预测指标概述*》中学到的指标来计算预测的准确度。但有一个问题我们还没有解答：我们应该使用数据的哪一部分来进行评估？在标准的机器学习设置中（分类或回归），我们随机抽取一部分训练数据作为验证数据，所有的建模决策都是基于这些数据做出的。行业中的最佳实践是使用交叉验证。**交叉验证**是一种重采样程序，我们在多个迭代中从训练数据集中抽取不同部分的数据进行训练和测试。除了重复评估，交叉验证还能够最有效地利用数据。
- en: However, in the field of time series forecasting, such a consensus on best practice
    does not exist. This is mainly because of the temporal nature and the sheer variety
    of ways we can go about it. Different time series might have different lengths
    of history and we may choose different ways to model it, or there might be different
    horizons to forecast for, and so on. Because of the temporal dependence in the
    data, standard assumptions of i.i.d. don’t hold true; therefore, techniques such
    as cross-validation have their own complications. When randomly chosen, the validation
    and training datasets may not be independent, which will lead to an optimistic
    and misleading estimate of error.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在时间序列预测领域，并不存在这种最佳实践的共识。这主要是由于时间序列的时间性以及我们可以采取的多种方式的差异。不同的时间序列可能有不同的历史长度，我们可能选择不同的建模方式，或者可能有不同的预测时段，等等。由于数据中的时间依赖性，标准的独立同分布（i.i.d.）假设不再成立；因此，像交叉验证这样的技术就会面临其自身的复杂性。当数据集被随机选择时，验证集和训练集可能不独立，这将导致对误差的估计过于乐观并且具有误导性。
- en: 'There are two main paradigms of validation:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 验证的主要范式有两种：
- en: '**In-sample validation**: As the name suggests, the model is evaluated on the
    same or a subset of the same data that was used to train it.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样本内验证**：顾名思义，模型是在与训练数据相同或相同数据子集上进行评估的。'
- en: '**Out-of-sample validation**: Under this paradigm, the data we use to evaluate
    the model has no intersection with the data used to train the model.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样本外验证**：在这一范式下，我们用来评估模型的数据与用于训练模型的数据没有交集。'
- en: In-sample validation helps you understand how well your model fits the data
    you have. This was very popular in the era of statistics, where the models were
    meticulously designed and primarily used for inferencing and not predicting. In
    such cases, the in-sample error shows how well the specified model fits the data
    and how valid the inferences we make from that model are. But in a predictive
    paradigm, like most machine learning, the in-sample error is not the right measure
    of the *goodness* of a model. Complex models can easily fit the training data,
    memorize it, and not work well on new and unseen data. Therefore, out-of-sample
    validations are almost exclusively used in today’s predictive model evaluations.
    Since this book is solely concerned with forecasting, which is a predictive task,
    we will be sticking to out-of-sample evaluations only.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 样本内验证帮助你了解模型在已知数据上的拟合效果。这在统计学时代非常流行，当时的模型设计非常精细，主要用于推理而非预测。在这种情况下，样本内误差显示了指定模型如何拟合数据，以及我们从该模型中推导出的推论的有效性。但在预测范式中，像大多数机器学习一样，样本内误差并不是衡量模型*好坏*的正确标准。复杂的模型可以轻松地拟合训练数据，记住数据，却在新数据和未见过的数据上表现不佳。因此，样本外验证几乎是当今预测模型评估中唯一使用的验证方式。由于本书专注于预测任务，我们将仅使用样本外评估。
- en: 'As discussed earlier, deciding on a validation strategy for forecasting problems
    is not as trivial as standard machine learning. There are two major schools of
    thought here:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，为预测问题选择验证策略并不像标准机器学习那样简单。这里有两种主要的思想流派：
- en: Holdout-based strategies, which respect the temporal integrity of the problem
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于保留的策略，尊重问题的时间完整性
- en: Cross-validation-based strategies, which sample validation splits with no or
    a very loose sense of temporal ordering
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于交叉验证的策略，在这种策略中，验证划分没有或者只有非常宽松的时间顺序
- en: Let’s discuss the major ones in each category. What we have to keep in mind
    is that all the validation strategies that we discuss in the book are not exhaustive.
    They are merely a few popular ones. In the explanations that follow, the length
    of the validation period is *L*[v] and the length of the training period is *L*[t].
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论每个类别中的主要策略。我们必须记住的是，本书中讨论的所有验证策略并非详尽无遗，它们只是一些流行的策略。在接下来的解释中，验证期的长度是*L*[v]，训练期的长度是*L*[t]。
- en: Now, let’s look at the first school of thought.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看第一个思想流派。
- en: Holdout strategies
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保留策略
- en: 'There are three aspects of a holdout strategy, and they can be mixed and matched
    to create many variations of the strategy. For instance, we might have a sampling
    strategy with a fixed split, a rolling window for the training data, and a recalibration
    of the model for each iteration. The three aspects are as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 保留策略有三个方面，它们可以组合搭配，创造出许多不同的策略变体。例如，我们可以有一个固定划分的采样策略，一个滚动窗口的训练数据，以及每次迭代时重新校准模型。三个方面如下：
- en: '**Sampling strategy**: A sampling strategy is how we sample the validation
    split(s) from training data.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采样策略**：采样策略是指我们如何从训练数据中抽取验证集。'
- en: '**Window strategy**: A window strategy decides how we sample the window of
    training split(s) from training data.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**窗口策略**：窗口策略决定了我们如何从训练数据中抽取训练集的窗口。'
- en: '**Calibration strategy**: A calibration strategy decides whether a model should
    be recalibrated or not.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**校准策略**：校准策略决定了是否需要重新校准模型。'
- en: That said, designing a holdout validation strategy for a time series problem
    includes making decisions on these three aspects.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，为时间序列问题设计一个留出验证策略需要在这三个方面做出决策。
- en: Sampling strategies are ways to pick one or more origins in the training data.
    These **origins** are points in time that determine the starting point of the
    validation split and the ending point of the training split. The exact length
    of the validation split is governed by a parameter *L*[v], which is the horizon
    chosen for validation. The length of the training split depends on the window
    strategy.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 采样策略是从训练数据中选取一个或多个原点的方法。这些**原点**是确定验证集起点和训练集终点的时间点。验证集的确切长度由参数*L*[v]决定，这是为验证选择的时间范围。训练集的长度则取决于窗口策略。
- en: Window strategy
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 窗口策略
- en: 'There are two ways we can draw the windows of training split—expanding window
    and rolling window. *Figure 20.1* shows the difference between the two setups:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过两种方式来设置训练集窗口——扩展窗口和滚动窗口。*图20.1*展示了两种设置之间的区别：
- en: '![Figure 19.1 – Expanding (left) versus rolling (right) strategy ](img/B22389_01.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图19.1 – 扩展（左）与滚动（右）策略](img/B22389_01.png)'
- en: 'Figure 20.1: Expanding (left) versus rolling (right) window strategies'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.1：扩展（左）与滚动（右）窗口策略
- en: Under the expanding window strategy, the training split expands as the origin
    moves forward in time. In other words, under the expanding window strategy, we
    choose all the data that is available before the origin as the training split.
    This effectively increases the training length every time the origin moves forward
    in time.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在扩展窗口策略下，训练集会随着原点向前推进而扩展。换句话说，在扩展窗口策略下，我们选择所有在原点之前可用的数据作为训练集。每当原点向前推进时，训练长度就会有效增加。
- en: In the rolling window strategy, we keep the length of the training split constant
    (*L*[t]). Therefore, when we move the origin forward by three timesteps, the training
    split drops three timesteps from the start of the time series.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在滚动窗口策略中，我们保持训练集的长度不变（*L*[t]）。因此，当我们将原点向前推进三个时间步时，训练集会从时间序列的开始处删除三个时间步的数据。
- en: Although the expanding and rolling window concept may remind you of the window
    we use for feature engineering or use as the context in deep learning models,
    this window is not the same. The window we talk about in this chapter is the window
    of training data that we chose to train our model. For instance, the features
    of a machine learning model may only extend to the 5 days before, and we can have
    the training split using the last 5 years of data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管扩展窗口和滚动窗口的概念可能会让你联想到我们在特征工程或深度学习模型中使用的窗口，但这两者并不相同。本章中讨论的窗口是我们为训练模型所选择的训练数据窗口。例如，机器学习模型的特征可能仅延伸到前5天，我们可以使用过去5年的数据来划分训练集。
- en: 'There are merits and demerits to both of these window strategies. Let’s summarize
    them in a few key points:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种窗口策略各有优缺点。让我们通过几个关键点来总结它们：
- en: The expanding window is a good setup for a short time series, where the expanding
    window leads to more data being available for the models.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展窗口适用于短时间序列，其中扩展窗口可以为模型提供更多的数据。
- en: The rolling window removes the oldest data from training. If the time series
    is non-stationary and the behavior is bound to change as time passes, having a
    rolling window will be beneficial to keep the model up to date.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滚动窗口会从训练集中移除最旧的数据。如果时间序列是非平稳的，并且行为会随着时间的推移发生变化，那么使用滚动窗口有助于保持模型的最新状态。
- en: When we use the expanding window strategy for repeated evaluation, such as in
    cross-validation, the increase in time series length used for training can introduce
    some bias toward windows with a longer history. The rolling window strategy takes
    care of that bias by maintaining the same length of the series.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们在交叉验证等重复评估中使用扩展窗口策略时，训练中使用的时间序列长度的增加可能会引入一些偏差，尤其是对历史较长的窗口有偏好。滚动窗口策略通过保持时间序列的相同长度来解决这种偏差。
- en: Now, let’s look at another aspect of a validation strategy.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看验证策略的另一个方面。
- en: Calibration strategy
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校准策略
- en: The calibration strategy is only valid in cases where we do multiple evaluations
    with different origins. There are two ways we can do evaluations with different
    origins—recalibrate every origin or update every origin (terminology from Tashman,
    reference *1*).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 校准策略仅在我们使用不同原点进行多次评估的情况下有效。我们可以用两种方式进行不同原点的评估——重新校准每个原点，或者更新每个原点（Tashman术语，参考*1*）。
- en: Under the *recalibrate* strategy, the model is retrained with the new training
    split for every origin. This retrained model is used to evaluate the validation
    split. For the *update* strategy, we do not retrain the model but use the trained
    model to evaluate the new validation split.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在*重新校准*策略下，模型会在每个原点使用新的训练拆分进行重新训练。这个重新训练的模型将用于评估验证拆分。而对于*更新*策略，我们不会重新训练模型，而是使用已训练的模型来评估新的验证拆分。
- en: 'Let’s summarize a couple of key points to be considered for choosing a strategy
    here:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结几个选择策略时需要考虑的关键点：
- en: The golden standard is to recalibrate every new origin, but many times, this
    may not be feasible. In the econometrics/classical statistical models, the norm
    was to recalibrate every origin. That was feasible because those models are relatively
    less compute-intensive and the datasets at the time were also small. So, one could
    refit a model in a very short time. Nowadays, the datasets have grown in size,
    and so have the models. Retraining a deep learning model every time we move the
    origin may not be as easy.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黄金标准是重新校准每个新的原点，但很多时候这可能不可行。在计量经济学/经典统计模型中，标准是重新校准每个原点。这是可行的，因为这些模型相对计算负担较小，而当时的数据集也较小。因此，可以在非常短的时间内重新拟合模型。如今，数据集的规模和模型的规模都大幅增长。每次移动原点时重新训练深度学习模型可能没有那么容易。
- en: Therefore, if you are using modern, complex models with long training times,
    an update strategy might be better.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你使用的是现代的、复杂的模型，并且训练时间较长，那么更新策略可能会更好。
- en: For classical models that run fast, we can explore the recalibration strategy.
    However, if the time series you are forecasting is so dynamic that the behavior
    changes very frequently, then the recalibration strategy might be the way to go.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于运行速度较快的经典模型，我们可以探索重新校准策略。然而，如果你要预测的时间序列变化如此之快，行为频繁变化，那么重新校准策略可能更合适。
- en: Now, let’s get on to the third part of the validation strategy.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们进入验证策略的第三部分。
- en: Sampling strategy
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 采样策略
- en: In the holdout strategy, we sample a point (*origin*) on the time series, preferably
    toward the end, such that the portion of the time series after the origin is shorter
    than the portion of the time series before. From this origin, we can use either
    the *expanding* or *rolling window* strategy to generate training and validation
    splits. The model is trained on the training split and tested on the held-out
    validation split. This strategy is simply called the **holdout** strategy. The
    calibration strategy is fixed at *recalibrate* because we are only testing and
    evaluating the model once.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在保留策略中，我们会在时间序列中采样一个点（*原点*），最好选择接近时间序列末尾的位置，使得原点之后的时间序列部分比原点之前的部分短。从这个原点开始，我们可以使用*扩展窗口*或*滚动窗口*策略来生成训练和验证拆分。模型在训练拆分上进行训练，并在保留的验证拆分上进行测试。这个策略被简单地称为**保留**策略。校准策略固定为*重新校准*，因为我们只对模型进行一次测试和评估。
- en: The simple holdout strategy has one disadvantage—the forecast measure we have
    calculated on the held-out data may not be robust enough because of the single
    evaluation paradigm. We are relying on a single split of data to calculate the
    predictive performance of the model. For non-stationary series, this can be a
    problem because we might be selecting a model that captures the idiosyncrasies
    of the split that we have chosen.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的保留策略有一个缺点——我们在保留数据上计算的预测指标可能不足够稳健，因为它依赖于单一的评估范式。我们依赖于数据的单一拆分来计算模型的预测性能。对于非平稳时间序列，这可能成为一个问题，因为我们可能选择了一个只捕捉到我们所选拆分特性的模型。
- en: We can get over this problem by repeating the holdout evaluation multiple times.
    We can either hand-tailor the different origins using business domain knowledge,
    such as taking into account seasonality or some other factor, or we could sample
    the origin points randomly. If we repeat this *n* times, there will be *n* validation
    splits, and they may or may not overlap with each other. The performance metric
    from these repeated trials can be aggregated using a function such as the mean,
    maximum, and minimum. This is called the **repeated holdout** (**Rep-Holdout**)
    strategy.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过多次重复Holdout评估来克服这个问题。我们可以根据业务领域知识定制不同的起始点，例如考虑季节性或其他因素，或者我们可以随机抽样起始点。如果我们重复这个过程*n*次，就会有*n*个验证拆分，它们可能会重叠，也可能不会。来自这些重复试验的性能指标可以使用均值、最大值和最小值等函数进行聚合。这就是**重复Holdout**（**Rep-Holdout**）策略。
- en: '**A note on implementation:**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**关于实现的说明：**'
- en: The simple holdout strategy is very simple to implement because we decide the
    size of the validation split and keep that much from the end of the time series
    aside for the validation. The **Rep-Holdout** strategy involves sampling multiple
    windows randomly or using predefined windows as validation splits. We can make
    use of the `PredefinedSplit` class from scikit-learn to this effect.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的Holdout策略非常容易实现，因为我们决定验证拆分的大小，并将时间序列的末尾部分保留作为验证集。**Rep-Holdout**策略涉及随机抽样多个窗口或使用预定义的窗口作为验证拆分。我们可以使用scikit-learn中的`PredefinedSplit`类来实现这一点。
- en: '*Figure 20.2* shows the two holdout strategies using an expanding window approach:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20.2*展示了使用扩展窗口方法的两种Holdout策略：'
- en: '![Figure 19.2 – Holdout strategy (a) and Rep-Holdout strategy (b) ](img/B22389_02.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.2 – Holdout策略 (a) 和 Rep-Holdout策略 (b)](img/B22389_02.png)'
- en: 'Figure 20.2: Holdout strategy (a) and Rep-Holdout strategy (b)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 20.2：Holdout策略 (a) 和 Rep-Holdout策略 (b)
- en: 'The Rep-Holdout strategy has a few more variants. The vanilla *Rep-Holdout*
    strategy evaluates multiple validation datasets, is mostly hand-crafted, and can
    have overlapping validation datasets. A variation of the Rep-Holdout strategy
    that insists that multiple validation splits should have no overlap is a more
    popular option. We call this **Repeated Holdout (No Overlap) (Rep-Holdout-O)**.
    This has some properties from the cross-validation family and tries to use more
    data systematically. *Figure 20.3 (a)* shows this strategy:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Rep-Holdout策略有一些变种。基础的*Rep-Holdout*策略评估多个验证数据集，通常是手工构建的，且验证数据集可能会重叠。一种变种策略则要求多个验证拆分之间不应有重叠，这是一个更受欢迎的选择。我们称之为**重复Holdout（无重叠）（Rep-Holdout-O）**。它继承了交叉验证家族的一些特性，并试图更系统地利用更多数据。*图
    20.3 (a)*展示了这一策略：
- en: '![Figure 19.3 – Variations of Rep-Holdout strategy ](img/B22389_03.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.3 – Rep-Holdout策略的变种](img/B22389_03.png)'
- en: 'Figure 20.3: Variations of the Rep-Holdout strategy'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 20.3：Rep-Holdout策略的变种
- en: The *Rep-Holdout-O* strategy is easy to implement in scikit-learn using the
    `TimeSeriesSplit` class for single time series datasets.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*Rep-Holdout-O*策略在使用`TimeSeriesSplit`类对单一时间序列数据集进行操作时非常容易实现。'
- en: '**Notebook alert:**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**笔记本提醒：**'
- en: The associated notebook that shows how to implement different validation strategies
    can be found in the `Chapter20` folder under the name `01-Validation_Strategies.ipynb`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 相关的笔记本，展示了如何实现不同的验证策略，可以在`Chapter20`文件夹下找到，文件名为`01-Validation_Strategies.ipynb`。
- en: 'The `TimeSeriesSplit` class from `sklearn.model_selection` implements the Rep-Holdout
    validation strategy and even supports expanding or rolling window variants. The
    main parameter is `n_splits`. This determines how many splits you want from the
    data, and the validation split size is decided automatically according to this
    formula:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.model_selection`中的`TimeSeriesSplit`类实现了Rep-Holdout验证策略，甚至支持扩展或滚动窗口变种。主要参数是`n_splits`，它决定了你希望从数据中拆分多少个部分，验证拆分的大小则会根据以下公式自动决定：'
- en: '![](img/B22389_20_001.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_20_001.png)'
- en: In the default configuration, this implements an expanding window Rep-Holdout-O
    strategy. But there is a `max_train_size` parameter. If we set this parameter,
    then it will use a window of `max_train_size` in a rolling window manner.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在默认配置下，这实现了一个扩展窗口的Rep-Holdout-O策略。但是有一个`max_train_size`参数。如果我们设置这个参数，那么它将以滚动窗口的方式使用`max_train_size`大小的窗口。
- en: Yet another variant of the Rep-Holdout strategy introduces a gap of length *L*[g]
    between the train and validation splits. This is to increase the independence
    between the train and validation splits, hence getting a better error estimate
    through the procedure. We call this strategy **Repeated Holdout (No Overlap) with
    Gaps (Rep-Holdout-O(G))**. This strategy is depicted in *Figure 20.3 (b)*.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种Rep-Holdout策略的变体引入了长度为*L*[g]的间隔，将训练集和验证集之间进行分隔。这是为了增加训练集和验证集之间的独立性，从而通过该过程获得更好的误差估计。我们称这种策略为**带间隔的重复保留法（Rep-Holdout-O(G))**。该策略在*图20.3
    (b)*中进行了展示。
- en: We can implement this using the `TimeSeriesSplit` class as well. All we need
    to do is use a parameter called `gap`. By default, the gap is set to 0\. But if
    we change to a non-zero number, it inserts that much timestep gap between the
    end of the training and the beginning of validation.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用`TimeSeriesSplit`类来实现这一点。我们需要做的只是使用一个叫做`gap`的参数。默认情况下，gap设置为0。但是如果我们更改为非零值，它将在训练的结束和验证的开始之间插入相应的时间步长间隔。
- en: 'Before we move on to the next set of strategies, let’s summarize and discuss
    some key points about the holdout strategies:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续讲解下一组策略之前，让我们总结并讨论一下关于保留法策略的一些关键点：
- en: Holdout strategies respect the temporal integrity of the problem and have been
    the preferred way of evaluating forecasting models for a long time. However, they
    do have a weakness in the inefficient use of available data. For short time series,
    holdout or Rep-Holdout may not have enough training data to train a model.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保留法策略尊重问题的时间完整性，并且长期以来一直是评估预测模型的首选方法。然而，它们在有效利用可用数据方面存在不足。对于短时间序列，保留法或Rep-Holdout可能没有足够的训练数据来训练模型。
- en: A simple holdout depends on a single evaluation, and the error estimate is not
    robust. Even in a stationary series, this procedure does not guarantee a good
    estimate of the error. In non-stationary time series, such as a seasonal time
    series, this problem is exacerbated. But Rep-Holdout and its variants take care
    of that issue.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的保留法依赖于单次评估，且误差估计不够稳健。即便在平稳序列中，这种方法也无法保证获得准确的误差估计。而在非平稳时间序列中，例如季节性时间序列，这个问题更加严重。但Rep-Holdout及其变体能够解决这个问题。
- en: Now, let’s look at the other major school of thought.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来看看另一种主要的思路。
- en: Cross-validation strategies
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证策略
- en: 'Cross-validation is one of the most important tools when evaluating standard
    regression and classification methods. This is because of two reasons:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证是评估标准回归和分类方法时最重要的工具之一。其原因有两个：
- en: A simple holdout approach doesn’t use all the data available and, in cases where
    data is scarce, cross-validation makes the best use of the available data.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的保留法方法并未利用所有可用数据，在数据稀缺的情况下，交叉验证能够更好地利用现有的数据。
- en: Theoretically, the time series we have observed is one realization of a stochastic
    process, and so the acquired error measure of the data is also a stochastic variable.
    Therefore, it is essential to sample multiple error estimates to get an idea about
    the distribution of the stochastic variable. Intuitively, we can think of this
    as a “lack of reliability” on the error measure derived from a single slice of
    data.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从理论上讲，我们观察到的时间序列是一个随机过程的一个实现，因此从数据中获得的误差度量也是一个随机变量。因此，采样多个误差估计值来了解该随机变量的分布是非常必要的。从直观上讲，我们可以将其理解为“缺乏可靠性”，即单一数据切片获得的误差度量的不确定性。
- en: The most common strategy that is used in standard machine learning is called
    **k-fold cross-validation**. Under this strategy, we randomly shuffle and partition
    the training data into *k* equal parts. Now, the whole training of the model and
    calculating the error is repeated *k* times such that every *k* subset we have
    kept aside is used as a test set once, and only once. When we use a particular
    subset as testing data, we use all the other subsets as the training data. After
    we acquire *k* different estimates of the error measure, we aggregate it using
    a function such as an average. This mean will typically be more robust than a
    single error measure.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准机器学习中最常用的策略叫做**k折交叉验证**。在这种策略下，我们随机打乱并将训练数据分成*k*个相等的部分。现在，整个模型训练和误差计算的过程会重复*k*次，每次我们选择一个*k*子集作为测试集，且仅使用一次。当我们使用某个子集作为测试数据时，我们会将其他所有子集作为训练数据。获得*k*个不同的误差估计值后，我们会使用平均等函数对其进行聚合。这个均值通常比单一误差度量更稳健。
- en: 'However, there is one assumption that is central to the validity procedure:
    *i.i.d samples*. This is one assumption that is invalid in time series problems
    because, by definition, the different samples in time series are dependent on
    each other through autocorrelation.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一个假设对有效性过程至关重要：*独立同分布（i.i.d.）样本*。这个假设在时间序列问题中是无效的，因为根据定义，时间序列中不同的样本通过自相关性相互依赖。
- en: Some argue that when we use time delay embedding to convert time series to a
    regression problem, we can start to use k-fold cross-validation on time series
    problems. While there are obvious theoretical problems, *Bergmeir et al*. (Reference
    *2*) showed that, empirically, the k-fold cross-validation is not a bad option,
    but the caveat is that the time series needs to be stationary. We will talk about
    this in more detail in the next section, where we will discuss the merits and
    demerits of these strategies.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 有人认为，当我们使用时间延迟嵌入将时间序列转换为回归问题时，可以开始在时间序列问题上使用 k-fold 交叉验证。尽管在理论上存在明显的问题，*Bergmeir
    等人*（参考文献 *2*）表明，从经验上看，k-fold 交叉验证并不是一个坏的选择，但需要注意的是，时间序列必须是平稳的。我们将在下一节中详细讨论这个问题，在那里我们将讨论这些策略的优缺点。
- en: However, there have been modifications to the *k*-fold strategy, specifically
    aimed at sequential data.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，针对 *k*-折策略，特别是针对顺序数据，已经有了一些修改。
- en: '*Snijders et al.* (Reference 4) proposed a modification we call the **Blocked
    Cross-Validation** (**Bl-CV**) strategy. It is similar to the standard *k-fold*
    strategy, but we do not randomly shuffle the dataset before partitioning it into
    *k* subsets of length *L*[v]. So, this partitioning strategy results in *k* contiguous
    blocks of observations. Then, like a standard k-fold strategy, we train and test
    each of these *k* blocks and aggregate the error measure over these multiple evaluations,
    so the temporal integrity of the problem is satisfied partially.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*Snijders 等人*（参考文献 4）提出了一种修改方案，我们称之为 **阻塞交叉验证** (**Bl-CV**) 策略。它与标准的 *k-fold*
    策略类似，但我们在将数据集划分为 *k* 个长度为 *L*[v] 的子集之前不会随机打乱数据集。因此，这种划分策略会导致 *k* 个连续的观测块。然后，像标准的
    k-fold 策略一样，我们对这些 *k* 个块进行训练和测试，并将多个评估的误差度量进行聚合，从而部分地满足问题的时间完整性要求。'
- en: 'In other words, temporal integrity is maintained within each of the blocks,
    but not between the blocks. *Figure 20.4 (a)* shows this strategy:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，时间完整性在每个块内部得到保持，但块与块之间则不然。*图 20.4 (a)* 显示了这一策略：
- en: '![Figure 19.4 – Bl-CV strategies ](img/B22389_04.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.4 – Bl-CV 策略 ](img/B22389_04.png)'
- en: 'Figure 20.4: Bl-CV strategies'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 20.4：Bl-CV 策略
- en: To implement the **Bl-CV strategy**, we can use the same `Kfold` class from
    scikit-learn. As we saw earlier, the main parameter the cross-validation classes
    in scikit-learn takes in is `n_splits`. Here, `n_splits` also defines the number
    of equally sized folds it selects. There is another parameter, `shuffle`, which
    is set to `True` by default. If we make sure our data is sorted according to time
    and then use the `Kfold` class with `shuffle=False`, it will imitate the **Bl-CV**
    strategy. The associated notebook shows this usage. I urge you to check the notebook
    for a better understanding of how this is implemented.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现 **Bl-CV 策略**，我们可以使用 scikit-learn 中相同的 `Kfold` 类。如前所述，scikit-learn 中交叉验证类的主要参数是
    `n_splits`。在这里，`n_splits` 还定义了它选择的相等大小的折叠数。另一个参数是 `shuffle`，默认设置为 `True`。如果我们确保数据按照时间排序，然后使用
    `shuffle=False` 的 `Kfold` 类，它将模仿 **Bl-CV** 策略。相关的笔记本中展示了这种用法。我强烈建议你查看笔记本，深入理解它是如何实现的。
- en: In the previous section, we talked about introducing gaps between train and
    validation splits, to increase independence between them. Another variant of the
    Bl-CV is a version that uses these gaps. We call it **Blocked Cross-Validation
    with Gaps** (**Bl-CV(G)**). We can see this in action in *Figure 20.4 (b)*.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了在训练集和验证集之间引入间隙，以增加它们之间的独立性。Bl-CV 的另一个变体是使用这些间隙的版本。我们称之为 **带间隙的阻塞交叉验证**
    (**Bl-CV(G)**)。我们可以在 *图 20.4 (b)* 中看到这种方法的实际应用。
- en: Unfortunately, the `Kfold` implementation in scikit-learn does not support this
    variant, but it’s simple to extend the `Kfold` implementation to include gaps
    as well. The associated notebook has an implementation of this. It has an additional
    parameter, `gap`, that lets us set the gap between the train and validation splits.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，scikit-learn 中的 `Kfold` 实现不支持这种变体，但扩展 `Kfold` 实现以包含间隙是很简单的。相关的笔记本中有这种实现。它有一个额外的参数
    `gap`，让我们可以设置训练集和验证集之间的间隙。
- en: We saw many different strategies for validation; now let’s try and lay down
    a few points that will help you in deciding the right strategy for your problem.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到许多不同的验证策略；现在让我们尝试列出一些要点，帮助你决定适合你问题的正确策略。
- en: Choosing a validation strategy
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择验证策略
- en: 'Choosing the right validation strategy is one of the most important but overlooked
    tasks in the machine learning workflow. A good validation setup will go a long
    way in all the different steps in the modeling process, such as feature engineering,
    feature selection, model selection, and hyperparameter tuning. Although there
    are no hard and fast rules in setting up a validation strategy, there are a few
    guidelines we can follow. Some of them are from experience (both mine and others)
    and some of them are from empirical and theoretical studies that have been published
    as research papers:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的验证策略是机器学习工作流程中最重要但常被忽视的任务之一。一个好的验证设置将在建模过程的各个步骤中发挥重要作用，比如特征工程、特征选择、模型选择和超参数调优。虽然在设置验证策略时没有硬性规则，但我们可以遵循一些指导原则。其中一些来自经验（包括我自己的和他人的），而另一些则来自已发布的实证和理论研究论文：
- en: One guiding principle in the design is that we try to make the validation strategy
    replicate the real use of the model as much as possible. For instance, if the
    model is going to be used to predict the next 24 timesteps, we make the length
    of the validation split 24 timesteps. Of course, it’s not as simple as that because
    other practical constraints such as the availability of enough data, time, and
    computers have to be kept in mind while designing a validation strategy.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计的一个指导原则是，我们尽量让验证策略尽可能模拟模型的实际使用。例如，如果模型将用于预测接下来的24个时间步长，我们将验证集的长度设置为24个时间步长。当然，这并不是那么简单，因为设计验证策略时还需要考虑其他实际约束条件，如足够的数据、时间和计算资源。
- en: Rep-Holdout strategies that respect the temporal order of the time series problem
    are the preferred option, especially in cases where there is sufficient data available.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尊重时间序列问题时间顺序的Rep-Holdout策略是首选，尤其是在有足够数据的情况下。
- en: For purely autoregressive formulations of stationary time series, regular `Kfold`
    can also be used, and Bergmeir et al. (Reference 2) empirically show that they
    perform better than holdout strategies. But Bl-CV is a better alternative among
    cross-validated strategies. *Cerqueira et al.* (Reference 3) corroborated the
    findings in their empirical study for stationary time series.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于纯自回归形式的平稳时间序列，可以使用常规的`Kfold`，并且Bergmeir等人（参考文献2）通过实证研究表明，它们的表现优于保持策略。但是，Bl-CV在交叉验证策略中是一个更好的选择。*Cerqueira等人*（参考文献3）在他们的平稳时间序列实证研究中证实了这一发现。
- en: If the time series is non-stationary, then *Cerqueira et al.* showed empirically
    that the holdout strategies (especially Rep-Holdout strategies) are the best ones
    to choose.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果时间序列是非平稳的，*Cerqueira等人*通过实证研究表明，保持策略（特别是Rep-Holdout策略）是最优的选择。
- en: If the time series is short, using Bl-CV after making the time series stationary
    is a good strategy for autoregressive formulations, such as time delay embedding.
    However, for models that use some kind of memory of the history to forecast, such
    as exponential smoothing or deep learning models such as RNN, cross-validation
    strategies may not be safe to use.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果时间序列较短，在将时间序列平稳化后使用Bl-CV是自回归模型（如时间延迟嵌入）的一种好策略。然而，对于那些使用历史记忆来预测的模型，如指数平滑或深度学习模型（如RNN），交叉验证策略可能并不安全。
- en: If we have exogenous variables in addition to the autoregressive part, it may
    not be safe to use cross-validation strategies. It is best to stick to holdout-based
    strategies.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们除了自回归部分还具有外生变量，那么使用交叉验证策略可能并不安全。最好坚持基于保持的策略。
- en: For a strongly seasonal time series, it is beneficial to use validation periods
    that mimic the forecast horizon. For instance, if we are forecasting for October,
    November, and December, it is beneficial to check the performance of the model
    in October, November, and December of last year.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于强季节性的时间序列，使用模拟预测视野的验证期是有益的。例如，如果我们预测的是十月、十一月和十二月，那么检查去年十月、十一月和十二月的模型表现会很有帮助。
- en: Up until now, we have been talking about validation strategies for a single
    time series. But in the context of global models, we are at a point where we need
    to think about validation strategies for such cases as well.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在讨论单一时间序列的验证策略。但在全球模型的背景下，我们已经到了需要考虑这些情况的验证策略的阶段。
- en: Validation strategies for datasets with multiple time series
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 针对具有多个时间序列的数据集的验证策略
- en: All the strategies we have seen until now are perfectly valid for datasets with
    multiple time series, such as the London Smart Meters dataset we have been working
    with in this book. The insights we discussed in the last section are also valid.
    The implementation of such strategies can be slightly tricky because the scikit-learn
    classes we discussed work for a single time series. Those implementations assume
    that we have a single time series, sorted according to the temporal order. If
    there are multiple time series, the splits will be haphazard and messy.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 直到现在为止，我们所见过的所有策略对于具有多个时间序列的数据集都是完全有效的，例如我们在本书中使用的伦敦智能电表数据集。我们在上一节讨论的见解也是有效的。由于我们讨论的
    scikit-learn 类适用于单一时间序列，因此这些策略的实现可能稍显复杂。这些实现假设我们只有一个单独的时间序列，并且按时间顺序排序。如果有多个时间序列，划分将会杂乱无章。
- en: 'There are a couple of options we can adopt for datasets with multiple time
    series:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有多个时间序列的数据集，我们可以采用几种选择：
- en: We can loop over the different time series and use the methods we discussed
    to do the train-validation split, and then concatenate the resulting sets across
    all the time series. But that is not going to be so efficient.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以遍历不同的时间序列，使用我们讨论过的方法进行训练-验证划分，然后将结果集跨所有时间序列连接起来。但这样做并不高效。
- en: We can write some code and design the validation strategies to use datetime
    or a time index (such as the one we saw in PyTorch forecasting in *Chapter 15*,
    *Strategies for Global Deep Learning Forecasting Models*). I have provided a link
    to a brilliant notebook from *Konrad Banachewicz* in the *Further reading* section
    of this chapter, where he uses a custom `GroupSplit` class that uses the time
    index as the group. This is one way to use Rep-Holdout strategies on a dataset
    with multiple time series.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以编写一些代码并设计验证策略，以使用日期时间或时间索引（例如我们在*第15章*中看到的 PyTorch 预测中的时间索引，“*全球深度学习预测模型的策略*”）。我在本章的*进一步阅读*部分提供了一个来自*Konrad
    Banachewicz*的精彩笔记本链接，他使用了一个自定义的`GroupSplit`类，将时间索引用作分组。这是对具有多个时间序列的数据集使用 Rep-Holdout
    策略的一种方式。
- en: 'There are a few points that we need to keep in mind for datasets with multiple
    time series:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有多个时间序列的数据集，我们需要记住几个要点：
- en: Do not use different time windows for different time series. This is because
    different windows in time would have different errors, and that would skew the
    aggregate error metric we are tracking.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要为不同的时间序列使用不同的时间窗口。因为不同的时间窗口会产生不同的误差，这会扭曲我们跟踪的总体误差度量。
- en: If different time series have different lengths, align the length of the validation
    period across all the series. Training length can be different, but validation
    windows should be the same so that every time series equally contributes to the
    aggregate error metric.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果不同的时间序列具有不同的长度，请对所有序列的验证期长度进行对齐。训练长度可以不同，但验证窗口应该相同，以便每个时间序列对总误差度量的贡献相等。
- en: It is easy to get carried away by complicated validation schemes, but always
    keep the technical debt you incur by choosing a specific technique in mind.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很容易被复杂的验证方案所吸引，但始终要记住选择特定技术所带来的技术债务。
- en: With that, we have come to the end of a short but important chapter.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 到这里，我们已经结束了一个简短但重要的章节。
- en: Summary
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We have come to the end of our journey through the world of time series forecasting.
    In the last couple of chapters, we addressed a few mechanics of forecasting, such
    as how to do multi-step forecasting and how to evaluate forecasts. Different validation
    strategies for evaluating forecasts and forecasting models were the topics of
    the current chapter.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经结束了在时间序列预测领域的探索。在过去的几个章节中，我们讨论了预测的一些机制，比如如何进行多步预测以及如何评估预测。当前章节讨论的主题是评估预测和预测模型的不同验证策略。
- en: We started by enlightening you as to why model validation is an important task.
    Then, we looked at a few different validation strategies, such as the holdout
    strategies, and navigated the controversial use of cross-validation for time series.
    We spent some time summarizing and laying down a few guidelines to be used to
    select a validation strategy. To top it all off, we looked at how these validation
    strategies are applicable to datasets with multiple time series and talked about
    how to adapt them to such scenarios.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过阐明模型验证为何是一个重要任务来开始。接着，我们探讨了几种不同的验证策略，例如留出法，并讨论了时间序列中交叉验证的争议性使用。我们花了一些时间总结并提出了几个选择验证策略时的指导方针。最后，我们讨论了这些验证策略如何适用于包含多个时间序列的数据集，并谈到了如何将其应用到这类场景中。
- en: With that, we have come to the end of the book. Congratulations on making it
    all the way through, and I hope you have gained enough skills from the book to
    tackle the next time series problem that comes your way. I strongly urge you to
    start putting into practice the skills that you have gained from the book because,
    as Richard Feynman rightly put it, *“You do not know anything until you have practiced.”*
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们来到了本书的结尾。恭喜你顺利读完，希望你从本书中获得了足够的技能，以应对下一个出现的时间序列问题。我强烈建议你开始将本书中学到的技能付诸实践，因为正如理查德·费曼所说的那样，*“你不知道任何东西，直到你付诸实践。”*
- en: References
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'The following are the references used in this chapter:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是本章引用的参考文献：
- en: 'Tashman, Len. (2000). *Out-of-sample tests of forecasting accuracy: An analysis
    and review*. International Journal of Forecasting. 16\. 437–450\. 10.1016/S0169-2070(00)00065-0:
    [https://www.researchgate.net/publication/223319987_Out-of-sample_tests_of_forecasting_accuracy_An_analysis_and_review](https://www.researchgate.net/publication/223319987_Out-of-sample_tests_of_forecasting_accuracy_An_analysis_and_review).'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Tashman, Len. (2000). *样本外预测精度测试：分析与评述*. 《国际预测学杂志》16卷, 437–450，10.1016/S0169-2070(00)00065-0：[https://www.researchgate.net/publication/223319987_Out-of-sample_tests_of_forecasting_accuracy_An_analysis_and_review](https://www.researchgate.net/publication/223319987_Out-of-sample_tests_of_forecasting_accuracy_An_analysis_and_review)。
- en: 'Bergmeir, Christoph and Benítez, José M. (2012). *On the use of cross-validation
    for time series predictor evaluation*. In Information Sciences, Volume 191, 2012,
    Pages 192–213: [https://www.sciencedirect.com/science/article/abs/pii/S0020025511006773](https://www.sciencedirect.com/science/article/abs/pii/S0020025511006773).'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bergmeir, Christoph 和 Benítez, José M. (2012). *关于时间序列预测评估中交叉验证的使用*. 载于《信息科学》期刊，191卷，2012年，第192–213页：[https://www.sciencedirect.com/science/article/abs/pii/S0020025511006773](https://www.sciencedirect.com/science/article/abs/pii/S0020025511006773)。
- en: 'Cerqueira, V., Torgo, L., and Mozetič, I. (2020). *Evaluating time series forecasting
    models: an empirical study on performance estimation methods.* Mach Learn 109,
    1997–2028 (2020): [https://doi.org/10.1007/s10994-020-05910-7](https://doi.org/10.1007/s10994-020-05910-7).'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Cerqueira, V., Torgo, L., 和 Mozetič, I. (2020). *评估时间序列预测模型：关于性能估计方法的实证研究.*
    机器学习 109, 1997–2028 (2020): [https://doi.org/10.1007/s10994-020-05910-7](https://doi.org/10.1007/s10994-020-05910-7)。'
- en: 'Snijders, T.A.B. (1988). *On Cross-Validation for Predictor Evaluation in Time
    Series.* In: *Dijkstra, T.K.* (eds) *On Model Uncertainty and its Statistical
    Implications*. Lecture Notes in Economics and Mathematical Systems, vol 307\.
    Springer, Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-61564-1_4](https://doi.org/10.1007/978-3-642-61564-1_4).'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Snijders, T.A.B. (1988). *关于时间序列预测评估中的交叉验证.* 收录于：*Dijkstra, T.K.* (编辑) *关于模型不确定性及其统计学意义*.
    经济学与数学系统讲义，卷307。Springer出版社，柏林，海德堡。[https://doi.org/10.1007/978-3-642-61564-1_4](https://doi.org/10.1007/978-3-642-61564-1_4)。
- en: Further reading
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: '*TS-10: Validation methods for time series* by *Konrad Banachewicz*: [https://www.kaggle.com/code/konradb/ts-10-validation-methods-for-time-series](https://www.kaggle.com/code/konradb/ts-10-validation-methods-for-time-series
    )'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TS-10: 时间序列的验证方法* by *Konrad Banachewicz*: [https://www.kaggle.com/code/konradb/ts-10-validation-methods-for-time-series](https://www.kaggle.com/code/konradb/ts-10-validation-methods-for-time-series)'
- en: Join our community on Discord
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的社区，参加 Discord 讨论
- en: 'Join our community’s Discord space for discussions with authors and other readers:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/mts](https://packt.link/mts)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/mts](https://packt.link/mts)'
- en: '![](img/QR_Code15080603222089750.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code15080603222089750.png)'
- en: Leave a Review!
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 留下评论！
- en: Thank you for purchasing this book from Packt Publishing—we hope you enjoyed
    it! Your feedback is invaluable and helps us improve and grow. Please take a moment
    to leave an [Amazon review](https://packt.link/r/1835883192); it will only take
    a minute, but it makes a big difference for readers like you.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你购买 Packt 出版的这本书——希望你喜欢它！你的反馈对我们至关重要，帮助我们改进和成长。请花几分钟时间在 [Amazon 评价](https://packt.link/r/1835883192)上留下你的评论；这只需要一分钟，但对像你这样的读者来说却意义重大。
- en: Scan the QR code below to receive a free ebook of your choice.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描下方的二维码，免费领取你选择的电子书。
- en: '![A qr code with black squares Description automatically generated](img/review2.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![A qr code with black squares Description automatically generated](img/review2.jpg)'
- en: '[https://packt.link/NzOWQ](https://packt.link/NzOWQ)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/NzOWQ](https://packt.link/NzOWQ)'
- en: '![](img/New_Packt_Logo1.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/New_Packt_Logo1.png)'
- en: '[packt.com](https://www.packt.com)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[packt.com](https://www.packt.com)'
- en: Subscribe to our online digital library for full access to over 7,000 books
    and videos, as well as industry leading tools to help you plan your personal development
    and advance your career. For more information, please visit our website.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 订阅我们的在线数字图书馆，全面访问超过 7,000 本书籍和视频，以及行业领先的工具，帮助你规划个人发展并推动职业生涯。欲了解更多信息，请访问我们的网站。
- en: Why subscribe?
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要订阅？
- en: Spend less time learning and more time coding with practical eBooks and Videos
    from over 4,000 industry professionals
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过来自超过 4,000 位行业专家的实用电子书和视频，减少学习时间，增加编程时间
- en: Improve your learning with Skill Plans built especially for you
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用为你特别设计的技能计划提升你的学习效果
- en: Get a free eBook or video every month
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每月免费获取一本电子书或视频
- en: Fully searchable for easy access to vital information
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全可搜索，方便快速访问重要信息
- en: Copy and paste, print, and bookmark content
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复制、粘贴、打印和书签内容
- en: At [www.packt.com](https://www.packt.com), you can also read a collection of
    free technical articles, sign up for a range of free newsletters, and receive
    exclusive discounts and offers on Packt books and eBooks.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [www.packt.com](https://www.packt.com)，你还可以阅读免费的技术文章，注册各种免费的电子邮件通讯，获取 Packt
    书籍和电子书的独家折扣和优惠。
- en: Other Books You May Enjoy
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你可能喜欢的其他书籍
- en: 'If you enjoyed this book, you may be interested in these other books by Packt:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这本书，你可能会对 Packt 出版的以下其他书籍感兴趣：
- en: '[![](img/9781836205876.jpg)](https://www.packtpub.com/en-in/product/pandas-cookbook-9781836205869)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](img/9781836205876.jpg)](https://www.packtpub.com/en-in/product/pandas-cookbook-9781836205869)'
- en: '**Pandas Cookbook**'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pandas Cookbook**'
- en: William Ayd, Matthew Harrison
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 威廉·艾德、马修·哈里森
- en: 'ISBN: 9781836205876'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ISBN：9781836205876
- en: The pandas type system and how to best navigate it
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas 类型系统以及如何最好地导航它
- en: Import/export DataFrames to/from common data formats
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入/导出 DataFrame 到/从常见的数据格式
- en: Data exploration in pandas through dozens of practice problems
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过数十个实践问题进行 pandas 数据探索
- en: Grouping, aggregation, transformation, reshaping, and filtering data
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分组、聚合、转换、重塑和过滤数据
- en: Merge data from different sources through pandas SQL-like operations
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 pandas 类 SQL 操作合并来自不同来源的数据
- en: Leverage the robust pandas time series functionality in advanced analyses
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在高级分析中利用强大的 pandas 时间序列功能
- en: Scale pandas operations to get the most out of your system
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展 pandas 操作，充分利用你的系统性能
- en: The large ecosystem that pandas can coordinate with and supplement
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas 可以与之协同工作并补充的大型生态系统
- en: '[![](img/9781801074308.jpg)](https://www.packtpub.com/en-in/product/mastering-pytorch-9781801079969)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](img/9781801074308.jpg)](https://www.packtpub.com/en-in/product/mastering-pytorch-9781801079969)'
- en: '**Mastering PyTorch**'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mastering PyTorch**'
- en: Ashish Ranjan Jha
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 阿希什·兰贾·贾
- en: 'ISBN: 9781801074308'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ISBN：9781801074308
- en: Implement text, vision, and music generation models using PyTorch
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 PyTorch 实现文本、视觉和音乐生成模型
- en: Build a deep Q-network (DQN) model in PyTorch
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 PyTorch 中构建深度 Q 网络（DQN）模型
- en: Deploy PyTorch models on mobile devices (Android and iOS)
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在移动设备（安卓和 iOS）上部署 PyTorch 模型
- en: Become well versed in rapid prototyping using PyTorch with fastai
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 fastai 在 PyTorch 中熟练进行快速原型设计
- en: Perform neural architecture search effectively using AutoML
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AutoML 有效进行神经网络架构搜索
- en: Easily interpret machine learning models using Captum
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Captum 轻松解释机器学习模型
- en: Design ResNets, LSTMs, and graph neural networks (GNNs)
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计 ResNet、LSTM 和图神经网络（GNN）
- en: Create language and vision transformer models using Hugging Face
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Hugging Face 创建语言和视觉转换器模型
- en: Packt is searching for authors like you
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Packt 正在寻找像你这样的作者
- en: If you’re interested in becoming an author for Packt, please visit [authors.packtpub.com](https://authors.packtpub.com)
    and apply today. We have worked with thousands of developers and tech professionals,
    just like you, to help them share their insight with the global tech community.
    You can make a general application, apply for a specific hot topic that we are
    recruiting an author for, or submit your own idea.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣成为Packt的作者，请访问 [authors.packtpub.com](https://authors.packtpub.com) 并立即申请。我们已经与成千上万的开发者和技术专业人士合作，帮助他们将自己的见解与全球技术社区分享。你可以进行一般申请，申请我们正在招募作者的特定热门话题，或者提交你自己的想法。
