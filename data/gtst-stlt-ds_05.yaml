- en: '*Chapter 4*: Using Machine Learning with Streamlit'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第4章*：在 Streamlit 中使用机器学习'
- en: A very common situation data scientists find themselves in is at the end of
    the model creation process, not knowing exactly how to convince non-data scientists
    that their model is worthwhile. They might have performance metrics from their
    model or some static visualizations but have no easy way to allow others to interact
    with their model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家常常遇到的一个非常普遍的情况是在模型创建过程结束时，不知道如何说服非数据科学家相信他们的模型是有价值的。他们可能有模型的性能指标或一些静态的可视化效果，但没有简单的方法让其他人与他们的模型进行交互。
- en: Before Streamlit, there were a couple of other options, the most popular being
    creating a full-fledged app in Flask or Django or turning their model into an
    **Application Programming Interface** (**API**) and pointing developers toward
    it. These are great options but tend to be time-consuming and suboptimal for valuable
    use cases such as prototyping an app.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 Streamlit 之前，还有其他一些选择，其中最流行的是在 Flask 或 Django 中创建一个完整的应用程序，或者将模型转换为**应用程序编程接口**（**API**），并引导开发人员使用它。这些选项很棒，但往往耗时且不适合像应用程序原型制作这样的宝贵使用案例。
- en: The incentives on teams are a little misaligned here. A data scientist wants
    to create the best models for their teams, but if they need to take a day or two
    (or, if they have experience, a few hours) of work to turn their model into a
    Flask or Django app, it doesn't make much sense to build this out until they think
    they are nearly complete with the modeling process. The benefit of Streamlit is
    that it helps us turn this arduous process into a frictionless app creation experience.
    In this chapter, we'll go over how to create **Machine Learning** (**ML**) prototypes
    in Streamlit, how to add user interaction to your ML apps, and also how to understand
    the ML results.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 团队中的激励有点不一致。数据科学家希望为团队创建最好的模型，但如果他们需要花一两天时间（或者，如果有经验的话，几个小时）将他们的模型转化为 Flask
    或 Django 应用，那么直到他们认为建模过程接近完成时，才去构建这个应用就没有太大意义。Streamlit 的好处在于，它帮助我们将这个繁琐的过程转化为无摩擦的应用创建体验。在本章中，我们将介绍如何在
    Streamlit 中创建**机器学习**（**ML**）原型，如何为你的机器学习应用添加用户交互，以及如何理解机器学习的结果。
- en: 'Specifically, the following topics are covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涉及以下主题：
- en: The standard ML workflow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准的机器学习工作流
- en: Predicting penguin species
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测企鹅物种
- en: Utilizing a pre-trained ML model in Streamlit
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Streamlit 中使用预训练的机器学习模型
- en: Training models inside Streamlit apps
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Streamlit 应用中训练模型
- en: Understanding ML results
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解机器学习的结果
- en: The standard ML workflow
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准的机器学习（ML）工作流
- en: 'The first step to creating an app that uses ML is the ML model itself. There
    are dozens of popular workflows for creating your own ML models. It''s likely
    you might have your own already! There are two parts of this process to consider:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个使用机器学习的应用程序的第一步是机器学习模型本身。创建你自己的机器学习模型有许多流行的工作流，你很可能已经有自己的方法了！这个过程有两个部分需要考虑：
- en: The generation of the ML model
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型的生成
- en: The use of the ML model in production
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生产中使用机器学习模型
- en: If the plan is to train a model once and then use this model in our Streamlit
    app, the best method is to create this model outside of Streamlit (for example,
    in a Jupyter notebook or in a standard Python file) first, and then use this model
    within the app.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果计划是训练一次模型然后将此模型用于我们的 Streamlit 应用，那么最好的方法是先在 Streamlit 外部创建该模型（例如，在 Jupyter
    notebook 中或在标准的 Python 文件中），然后在应用中使用该模型。
- en: If the plan is to use the user input to train the model inside our app, then
    we can no longer create the model outside of Streamlit and instead will need to
    run the model training within the Streamlit app.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果计划是使用用户输入来训练我们应用程序中的模型，那么我们就不能再在 Streamlit 外部创建模型，而是需要在 Streamlit 应用程序内部运行模型训练。
- en: We will start by building our ML models outside of Streamlit and move on to
    training our models inside of Streamlit apps after.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先在 Streamlit 外部构建机器学习模型，然后再转向在 Streamlit 应用中训练模型。
- en: Predicting penguin species
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测企鹅物种
- en: 'The dataset that we will primarily use in this chapter is the same Palmer''s
    Penguins dataset that we used in [*Chapter 1*](B16864_01_Final_VK_ePub.xhtml#_idTextAnchor014),
    *An Introduction to Streamlit*. As is typical, we will create a new folder that
    will house our new Streamlit app and accompanying code. The following code creates
    this new folder within our `streamlit_apps` folder and copies the data from our
    `penguin_app` folder. If you haven''t downloaded the Palmer''s Penguins data yet,
    please follow the instructions in the *The Setup: Palmer''s Penguins* section
    in [*Chapter 2*](B16864_02_Final_VK_ePub.xhtml#_idTextAnchor024), *Uploading,
    Downloading, and Manipulating Data*:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们主要使用的数据集是与[ *第 1 章*](B16864_01_Final_VK_ePub.xhtml#_idTextAnchor014)，《Streamlit简介》中使用的相同的
    Palmer's Penguins 数据集。像往常一样，我们将创建一个新的文件夹，用于存放我们的 Streamlit 应用和相关代码。以下代码将在`streamlit_apps`文件夹内创建该新文件夹，并将数据从我们的`penguin_app`文件夹复制过来。如果你还没有下载
    Palmer's Penguins 数据，请按照[*第 2 章*](B16864_02_Final_VK_ePub.xhtml#_idTextAnchor024)，《上传、下载和处理数据》中的说明操作：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you may have noticed in the preceding code, there are two Python files here,
    one to create the ML model (`penguins_ml.py`) and the second to create the Streamlit
    app (`penguins_streamlit.py`). We will start with the `penguins_ml.py` file, and
    once we have a model we are happy with, we will move on to the `penguins_streamlit.py`
    file.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在前面的代码中可能注意到的那样，这里有两个 Python 文件，一个用于创建机器学习模型（`penguins_ml.py`），另一个用于创建 Streamlit
    应用（`penguins_streamlit.py`）。我们将从`penguins_ml.py`文件开始，一旦我们得到了满意的模型，就会转到`penguins_streamlit.py`文件。
- en: Note
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can also opt to create the model in a Jupyter notebook, which is less reproducible
    by design (as cells can be run out of order) but is still incredibly popular.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以选择在 Jupyter notebook 中创建模型，虽然这种方式设计上较不易复现（因为单元格可以乱序运行），但仍然是非常受欢迎的做法。
- en: 'Let''s get re-familiarized with the `penguins.csv` dataset. The following code
    will read the dataset and print out the first five rows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新熟悉一下`penguins.csv`数据集。以下代码将读取数据集并打印出前五行：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output of the preceding code, when we run our Python file `penguins_ml.py`
    in the terminal, will look something like the following screenshot:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在终端运行 Python 文件`penguins_ml.py`时，前面代码的输出将类似以下截图所示：
- en: '![Figure 4.1 – First five penguins'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.1 – 前五只企鹅'
- en: '](img/B16864_04_01.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16864_04_01.jpg)'
- en: Figure 4.1 – First five penguins
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 前五只企鹅
- en: For this app, we are going to attempt to create an app that will help researchers
    in the wild know what species of penguin they are looking at. It will predict
    the species of the penguin given some measurements of the bill, flippers, and
    body mass, and knowledge about the sex and location of the penguin.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个应用，我们将尝试创建一个帮助野外研究人员识别企鹅物种的应用。该应用将根据企鹅的喙、鳍和体重的测量值，以及关于企鹅性别和位置的信息来预测企鹅的物种。
- en: 'This next section is not an attempt to make the best ML model possible, but
    just to create something as a quick prototype for our Streamlit app that we can
    iterate off of. So in that light, we are going to drop our few rows with null
    values, and not use the `year` variable in our features as it does not fit with
    our use case. We will need to define our features and output variables, and do
    one-hot-encoding (or as pandas calls it, creating dummy variables for our text
    columns) on our features, and factorize our output variable (turn it from a string
    into a number). The following code should get our dataset in a better spot to
    run through a classification algorithm:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的这一部分并不是为了创建最好的机器学习模型，而只是为了快速为我们的 Streamlit 应用创建一个原型，方便我们在此基础上进行迭代。因此，从这个角度来看，我们将删除含有空值的几行，并且不使用`year`变量作为特征，因为它与我们的使用场景不匹配。我们需要定义特征和输出变量，对特征进行独热编码（或者像
    pandas 所说的，为我们的文本列创建虚拟变量），并对输出变量进行因子化（将其从字符串转换为数字）。以下代码应该能将我们的数据集整理得更适合进行分类算法的运行：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now when we run our Python file `penguins_ml.py` again, we see the output and
    feature variables separated, as shown in the following screenshot:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在当我们再次运行 Python 文件`penguins_ml.py`时，我们会看到输出变量和特征变量已经分开，如下图所示：
- en: '![Figure 4.2 – Output variables'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.2 – 输出变量'
- en: '](img/B16864_04_02.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16864_04_02.jpg)'
- en: Figure 4.2 – Output variables
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 输出变量
- en: Now, we want to create a classification model using a subset (in this case,
    80%) of our data, and get the accuracy of said model. The following code runs
    through those steps using a random forest model, but you can use other classification
    algorithms if you would like. Again, the point here is to get a quick prototype
    to show to the penguin researchers for feedback!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们希望使用我们数据的一个子集（在此情况下为 80%）来创建一个分类模型，并获取该模型的准确性。以下代码通过随机森林模型执行这些步骤，但如果你愿意，也可以使用其他分类算法。再次强调，这里的目的是为了快速制作一个原型，展示给企鹅研究人员，获取反馈！
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We now have a pretty good model for predicting the species of penguins! Our
    last step in the model generating process is to save the two parts of this model
    that we need the most – the model itself and the `uniques` variable, which maps
    the factorized output variable to the species name that we recognize. To the previous
    code, we will add a few lines that will save these objects as pickle files (files
    that turn a Python object into something we can save directly and import easily
    from another Python file such as our Streamlit app). More specifically, the `open()`
    function creates two pickle files, the `pickle.dump()` function writes our Python
    files to said files, and the `close()` function closes the files. The `wb` in
    the `open()` function stands for *write bytes*, which tells Python that we want
    to write, not read, to this file:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一个相当不错的模型来预测企鹅的物种！我们在模型生成过程中的最后一步是保存我们最需要的这两部分模型——模型本身和`uniques`变量，它将因子化的输出变量映射到我们可以识别的物种名称。对于之前的代码，我们将添加几行代码，用来将这些对象保存为
    pickle 文件（pickle 文件是将 Python 对象转化为可以直接保存并且从其他 Python 文件中轻松导入的格式，譬如我们的 Streamlit
    应用程序）。更具体来说，`open()`函数创建了两个 pickle 文件，`pickle.dump()`函数将我们的 Python 文件写入这些文件，`close()`函数用于关闭文件。`open()`函数中的`wb`表示*写入字节*，这告诉
    Python 我们要写入文件，而不是读取文件：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We now have two more files in our `penguin_ml` folder, a file called `random_forest_penguin.pickle`,
    which contains our model, and `output_penguin_.pickle`, which has the mapping
    between penguin species and the output of our model. This is it for the `penguins_ml.py`
    function! We can move on to our Streamlit app.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的`penguin_ml`文件夹中有了两个新的文件，一个是名为`random_forest_penguin.pickle`的文件，里面包含我们的模型，另一个是`output_penguin_.pickle`文件，它包含了企鹅物种和模型输出之间的映射关系。这就是`penguins_ml.py`函数的全部内容！我们可以继续进行
    Streamlit 应用程序的开发。
- en: Utilizing a pre-trained ML model in Streamlit
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Streamlit 中使用预训练的 ML 模型
- en: 'Now that we have our model, we want to load it (along with our mapping function
    as well) into Streamlit. In our file, `penguins_streamlit.py`, that we created
    before, we will again use the `pickle` library to load our files using the following
    code. We use the same functions as before, but instead of `wb`, we use the `rb`
    parameter, which stands for *read bytes*. To make sure these are the same Python
    objects that we used before, we will use the `st.write()` function that we are
    so familiar with already to check:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了我们的模型，我们希望将它（以及我们的映射函数）加载到 Streamlit 中。在我们之前创建的文件`penguins_streamlit.py`中，我们将再次使用`pickle`库，通过以下代码加载我们的文件。我们使用与之前相同的函数，但这次不是使用`wb`，而是使用`rb`参数，表示*读取字节*。为了确保这些是我们之前使用的相同的
    Python 对象，我们将使用我们非常熟悉的`st.write()`函数来进行检查：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As with our previous Streamlit apps, we run the following code in the terminal
    to run our app:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 和我们之前的 Streamlit 应用程序一样，我们在终端中运行以下代码来启动我们的应用程序：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We now have our random forest classifier, along with the penguin mapping! Our
    next step is to add Streamlit functions to get the user input. In our app, we
    used island, bill length, bill depth, flipper length, body mass, and sex to predict
    the penguin species, so we will need to get each of these from our user. For island
    and sex, we know which options were in our dataset already and want to avoid having
    to parse through user text, so we will use `selectbox`. For the other data, we
    just need to make sure that the user has input a positive number, so we will use
    the `st.number_input()` function and make the minimum value `0`. The following
    code takes these inputs in and prints them out on our Streamlit app:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了随机森林分类器，并且有了企鹅映射！我们的下一步是添加 Streamlit 函数以获取用户输入。在我们的应用程序中，我们使用了岛屿、喙长、喙深、鳍肢长、体重和性别来预测企鹅的物种，因此我们需要从用户那里获取这些信息。对于岛屿和性别，我们已经知道数据集中有哪些选项，并且希望避免解析用户的文本，因此我们将使用`selectbox`。对于其他数据，我们只需要确保用户输入的是一个正数，因此我们将使用`st.number_input()`函数，并将最小值设置为`0`。以下代码将这些输入值获取并在
    Streamlit 应用程序中显示出来：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding code should make the following app. Try it out and see if it
    works by changing the values and seeing if the output changes as well. Streamlit
    is designed so that, by default, each time a value is changed, the entire app
    reruns. The following screenshot shows the app live, with some values that I''ve
    changed. We can either change numeric values with the (**+** and **-**) buttons
    on the right-hand side, or we can just enter the values manually:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码应该生成如下应用。试试看，修改数值，看看输出是否会有所变化。Streamlit 的设计使得默认情况下，每次更改一个值，整个应用都会重新运行。下面的截图显示了正在运行的应用，展示了一些我更改过的数值。我们可以通过右侧的（**+**
    和 **-**）按钮来修改数值，或者直接手动输入数值：
- en: '![Figure 4.3 – Model inputs'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.3 – 模型输入'
- en: '](img/B16864_04_03.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16864_04_03.jpg)'
- en: Figure 4.3 – Model inputs
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 模型输入
- en: 'Now we have all our inputs, and we also have our model. The next step is to
    format the data into the same format as our preprocessed data, for example, our
    model does not have one variable called `sex` but instead has two variables called
    `sex_female` and `sex_male`. Once our data is in the right shape, we can call
    the `predict` function and map the prediction to our original species list to
    see how our model functions. The following code does exactly this, and also adds
    some basic titles and instructions to the app to make it more usable. This app
    is rather long, so I will break it up into multiple sections for readability,
    starting with adding instructions and a title to our app:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了所有的输入，并且也有了我们的模型。下一步是将数据格式化成与我们预处理数据相同的格式，例如，我们的模型没有一个叫做 `sex` 的变量，而是有两个叫做
    `sex_female` 和 `sex_male` 的变量。一旦我们的数据格式正确，我们就可以调用 `predict` 函数，并将预测结果映射到我们原始的物种列表上，看看模型是如何工作的。以下代码正是完成这个任务的，同时还为应用添加了一些基本的标题和说明，以便用户使用。这个应用比较长，所以我会将它分成多个部分来提高可读性，从为应用添加说明和标题开始：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We now have an app with our title and instructions for the user. The next step
    is to get the user inputs as we did before. We also need to put our `sex` and
    `island` variables into the correct format, as discussed before:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的应用已经有了标题和用户操作说明。下一步是像之前一样获取用户输入。我们还需要将 `sex` 和 `island` 变量转化为正确的格式，如前所述：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'All of our data is in the correct format! The last step here is using the `predict()`
    function on our model with our new data, which this final section takes care of:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据格式已经完全正确！最后一步是使用 `predict()` 函数在我们的模型上进行预测，并使用新数据，这一部分代码已经完成：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now our app should look like the following screenshot. I have added some example
    values to the inputs, but you should play around with changing the data to see
    if you can make the species change!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的应用应该像下面的截图一样。我在输入框中添加了一些示例值，但你应该尝试更改数据，看看是否能够改变物种预测！
- en: '![Figure 4.4 – Full Streamlit prediction'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.4 – 完整的 Streamlit 预测'
- en: '](img/B16864_04_04.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16864_04_04.jpg)'
- en: Figure 4.4 – Full Streamlit prediction
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – 完整的 Streamlit 预测
- en: We now have a full Streamlit app that utilizes our pre-trained ML model, takes
    user input, and outputs the prediction. Next, we will discuss how to train models
    directly within Streamlit apps!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个完整的 Streamlit 应用，它利用了我们预训练的机器学习模型，接收用户输入并输出预测结果。接下来，我们将讨论如何在 Streamlit
    应用中直接训练模型！
- en: Training models inside Streamlit apps
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Streamlit 应用中训练模型
- en: Often, we may want to have the user input change how our model is trained. We
    may want to accept data from the user or ask the user what features they would
    like to use, or even allow the user to pick the type of machine learning algorithm
    they would like to use. All of these options are feasible in Streamlit, and in
    this section, we will cover the basics around using user input to affect the training
    process. As we discussed in the section above, if a model is going to be trained
    only once, it is probably best to train the model outside of Streamlit and import
    the model into Streamlit. But what if, in our example, the penguin researchers
    have the data stored locally, or do not know how to retrain the model but have
    the data in the correct format already? In cases like these, we can add the `st.file_uploader()`
    option and include a method for these users to input their own data, and get a
    custom model deployed for them without having to write any code. The following
    code will add a user option to accept data and will use the preprocessing/training
    code that we originally had in `penguins_ml.py` to make a unique model for this
    user. It is important to note here that this will only work if the user has data
    in the exact same format and style that we used, which may be unlikely. One other
    potential add-on here is to show the user what format the data needs to be in
    for this app to correctly train a model as expected!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们常常希望让用户输入改变我们模型的训练方式。我们可能想接受用户的数据，或者询问用户他们希望使用哪些特征，甚至允许用户选择他们希望使用的机器学习算法类型。所有这些选项在Streamlit中都是可行的，在本节中，我们将介绍如何使用用户输入来影响训练过程的基础知识。正如我们在上节中所讨论的那样，如果一个模型只需要训练一次，那么最好是在Streamlit外部训练模型，并将模型导入Streamlit。但如果在我们的例子中，企鹅研究人员的数据已经存储在本地，或者他们不知道如何重新训练模型，但数据已处于正确的格式呢？在这种情况下，我们可以添加`st.file_uploader()`选项，并为这些用户提供一种输入自己数据的方法，从而无需编写任何代码就能为他们部署定制的模型。以下代码将添加一个用户选项以接受数据，并使用我们在`penguins_ml.py`中原本的预处理/训练代码为该用户制作一个独特的模型。这里需要注意的是，只有当用户的数据格式和风格与我们使用的完全相同时，这种方法才有效，这种情况可能比较少见。另一个可能的附加功能是向用户展示数据需要符合什么格式，以便此应用程序能够正确训练模型！
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This first section imports the libraries that we need, adds the title – as
    we have used before, and adds the `file_uploader()` function. What happens, however,
    when the user has yet to upload a file? We can set the default to load our random
    forest model if there is no penguin file, as shown in the next section of code:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 本节导入我们需要的库，添加标题——如我们之前所用，并添加`file_uploader()`函数。然而，当用户尚未上传文件时会发生什么呢？我们可以将默认值设置为加载我们的随机森林模型，如果没有企鹅文件，如下一节代码所示：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The next problem we need to solve is how to take in the user''s data, clean
    it, and train a model based on it. Luckily, we can reuse the model training code
    that we have already created and put it within our `else` statement in the next
    code block:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的问题是如何接收用户的数据，清洗它，并基于这些数据训练一个模型。幸运的是，我们可以重复使用已经创建的模型训练代码，并将其放入下一个代码块中的`else`语句中：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We have now created our model within the app and need to get the inputs from
    the user for our prediction. This time, however, we can make an improvement on
    what we have done before. As of now, each time a user changes an input in our
    app, the entire Streamlit app will rerun. We can use the `st.form()` and `st.submit_form_button()`
    functions to wrap the rest of our user inputs in and allow the user to change
    all of the inputs and submit the entire form at once instead of multiple times:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经在应用内创建了模型，需要从用户那里获取预测输入。不过，这一次，我们可以对之前的做法进行改进。到目前为止，每次用户更改应用中的输入时，整个Streamlit应用都会重新运行。我们可以使用`st.form()`和`st.submit_form_button()`函数将其余的用户输入包裹起来，让用户一次性提交整个表单，而不是每次都提交：
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now that we have the inputs with our new form, we need to create our prediction
    and write the prediction to the user, as shown in the next block:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了新表单的输入，我们需要创建我们的预测并将预测结果写给用户，如下一个代码块所示：
- en: '[PRE15]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And there we go! We now have a Streamlit app that allows the user to input
    their own data and trains a model based on their data and outputs the results,
    as shown in the next screenshot:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们现在有了一个Streamlit应用，允许用户输入自己的数据，并根据他们的数据训练模型并输出结果，如下图所示：
- en: '![Figure 4.5 – Penguin classifier predictions'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.5 – 企鹅分类器预测'
- en: '](img/B16864_04_05.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16864_04_05.jpg)'
- en: Figure 4.5 – Penguin classifier predictions
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – 企鹅分类器预测
- en: There are potential improvements here, such as through using caching functions
    (explored in [*Chapter 2*](B16864_02_Final_VK_ePub.xhtml#_idTextAnchor024), *Uploading,
    Downloading, and Manipulating Data*), as one example. Apps like these where users
    bring their own data are significantly harder to build, especially without a universal
    data format. It is more common as of this writing to see Streamlit apps that show
    off impressive ML models and use cases rather than apps that build them directly
    in-app (especially with more computationally expensive model training). As we
    mentioned before, Streamlit developers often will provide references to the required
    data format before asking for user input in the form of a dataset. However, this
    option of allowing users to bring their own data is available and practical, especially
    to allow for quick iterations on model building.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有潜在的改进方法，例如使用缓存功能（可以参考 [*第 2 章*](B16864_02_Final_VK_ePub.xhtml#_idTextAnchor024)，*上传、下载和操作数据*）。像这样允许用户上传数据的应用要构建起来更为困难，尤其是在没有统一数据格式的情况下。截至目前，看到展示出色的机器学习模型和使用案例的
    Streamlit 应用比直接在应用内构建模型的应用要更为常见（尤其是对于计算开销较大的模型训练）。正如我们之前提到的，Streamlit 开发者通常会在要求用户输入数据集之前提供必要的数据格式参考。然而，允许用户带入自己数据的选项仍然是可用且实用的，尤其是可以快速迭代模型构建。
- en: Understanding ML results
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习结果
- en: So far, our app might be useful, but often just showing a result is not good
    enough for a data app. We also should show some explanation as to why they got
    the result that they did! In order to do this, we can include in the output of
    the app that we have already made a section that helps users understand the model
    better.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的应用可能很有用，但仅仅展示结果对于一个数据应用来说并不够。我们还应该解释一下为什么会得到这样的结果！为了做到这一点，我们可以在应用输出中添加一个帮助用户更好理解模型的部分。
- en: 'To start, random forest models already have a built-in feature importance method
    derived from the set of individual decision trees that make up the random forest.
    We can edit our `penguins_ml.py` file to graph this importance, and then call
    that image from within our Streamlit app. We could also graph this directly from
    within our Streamlit app, but it is more efficient to make this graph once in
    `penguins_ml.py` instead of every time our Streamlit app reloads (which is every
    time a user changes a user input!). The following code edits our `penguins_ml.py`
    file and adds the feature importance graph, saving it to our folder. We also call
    the `tight_layout()` feature, which helps format our graph better and makes sure
    we avoid any labels getting cut off. This set of code is long, and the top half
    of the file remains unchanged, so only the section on library importing and data
    cleaning has been omitted:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，随机森林模型已经具备了一个内建的特征重要性方法，该方法来源于组成随机森林的单个决策树集合。我们可以编辑我们的 `penguins_ml.py` 文件来绘制这个特征重要性图，然后在我们的
    Streamlit 应用中调用该图像。我们也可以直接在 Streamlit 应用中绘制这个图形，但在 `penguins_ml.py` 中绘制一次会更高效，而不是每次我们的
    Streamlit 应用重新加载时（即每次用户更改输入时）都绘制一次。以下代码编辑了我们的 `penguins_ml.py` 文件并添加了特征重要性图，将其保存到我们的文件夹中。我们还调用了
    `tight_layout()` 功能，这有助于更好地格式化我们的图表，并确保避免任何标签被截断。由于这段代码较长，文件的前半部分保持不变，因此只省略了库导入和数据清洗部分：
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now when we rerun `pengiuns_ml.py`, we should see a file called `feature_importance.png`,
    which we can call from our Streamlit app. Let''s do that now! We can use the `st.image()`
    function to load an image from our `png` and print it to our penguin app. The
    following code adds our image to the Streamlit app and also improves our explanations
    around the prediction we made. Because of the length of this code block, we will
    just show the new code from the point where we start to predict using the user''s
    data:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们重新运行 `pengiuns_ml.py` 时，应该能看到一个名为 `feature_importance.png` 的文件，我们可以从我们的
    Streamlit 应用中调用这个文件。我们现在来做这个！我们可以使用 `st.image()` 函数加载我们 `png` 文件中的图像，并将其显示到我们的企鹅应用中。以下代码将我们的图像添加到
    Streamlit 应用中，并且改进了我们关于预测的解释。由于这个代码块的长度，我们只展示从开始使用用户数据进行预测的代码部分：
- en: '[PRE17]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, the bottom of your Streamlit app should look like the following screenshot
    (note: your string might be slightly different based on your inputs).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您的 Streamlit 应用的底部应该看起来像下图所示（注意：您的字符串可能会因输入的不同而略有不同）。
- en: '![Figure 4.6 – Feature importance screenshot'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.6 – 特征重要性截图'
- en: '](img/B16864_04_06.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16864_04_06.jpg)'
- en: Figure 4.6 – Feature importance screenshot
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 特征重要性截图
- en: 'As we can see, bill length, bill depth, and flipper length are the most important
    variables according to our random forest model. A final option for explaining
    how our model works is to plot the distributions of each of these variables by
    species, and also plot some vertical lines representing the user input. Ideally,
    the user can begin to understand the underlying data holistically, and therefore
    will understand the predictions that come from the model as well. To do this,
    we will need to actually import the data into our Streamlit app, which we have
    not done previously. The following code imports the penguin data we used to build
    the model, and plots three histograms (for *bill length*, *bill depth*, and *flipper
    length*) along with the user input as a vertical line, starting from the model
    explanation section:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，喙长、喙深和鳍肢长是根据我们的随机森林模型最重要的变量。解释我们模型工作原理的最终选项是按物种绘制这些变量的分布图，并绘制一些垂直线表示用户输入。理想情况下，用户可以开始全面理解基础数据，从而理解模型给出的预测结果。为此，我们需要将数据导入到Streamlit应用程序中，这是我们之前没有做过的。以下代码导入了我们用来构建模型的企鹅数据，并绘制了三张直方图（分别为*喙长*、*喙深*和*鳍肢长*），同时将用户输入作为垂直线显示，从模型解释部分开始：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now that we have set up our app for the histograms, we can use the `displot()`
    function in the Seaborn visualization library to create our three histograms for
    our most important variables:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为直方图设置好了应用程序，我们可以使用Seaborn可视化库中的`displot()`函数来为我们最重要的变量创建三个直方图：
- en: '[PRE19]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The preceding code should create the app shown in the following figure, which
    is our app in its final form. For viewing ease, we will just show the first histogram:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码应该会创建出下图所示的应用程序，这是我们最终形式的应用。为了方便查看，我们将仅展示第一个直方图：
- en: '![Figure 4.6 – Bill Length by Species'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.6 – 按物种分类的喙长'
- en: '](img/B16864_04_07.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16864_04_07.jpg)'
- en: Figure 4.6 – Bill Length by Species
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 按物种分类的喙长
- en: As always, the completed and final code can be found at [https://github.com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science](https://github.com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science).
    That completes this section. We have now created a fully formed Streamlit app
    that takes a pre-built model and user input and outputs both the result of the
    prediction and an explanation of the output as well.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，完整的最终代码可以在[https://github.com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science](https://github.com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science)找到。这部分内容到此结束。我们现在已经创建了一个完整的Streamlit应用程序，它能够接受预先构建的模型和用户输入，并输出预测结果和解释输出。
- en: Summary
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we learned some ML basics: how to take a pre-built ML model
    and use it within Streamlit, how to create our own models from within Streamlit,
    and also how to use user input to understand and iterate on ML models. Hopefully,
    at the end of this chapter, you feel comfortable with each of these. We will dive
    into the world of deploying Streamlit using Streamlit sharing next!'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了一些机器学习基础：如何在Streamlit中使用预构建的机器学习模型，如何在Streamlit中创建我们自己的模型，以及如何使用用户输入来理解和迭代机器学习模型。希望在本章结束时，你能对这些内容感到熟悉。接下来，我们将深入了解如何使用Streamlit
    Sharing部署Streamlit应用程序！
