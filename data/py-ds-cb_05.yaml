- en: Chapter 5. Data Mining – Needle in a Haystack
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章 数据挖掘——大海捞针
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将覆盖以下主题：
- en: Working with distance measures
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用距离度量
- en: Learning and using kernel methods
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习和使用核方法
- en: Clustering data using the k-means method
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 k-means 方法进行数据聚类
- en: Learning vector quantization
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习向量量化
- en: Finding outliers in univariate data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在单变量数据中寻找异常值
- en: Discovering outliers using the local outlier factor method
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用局部异常因子方法发现异常值
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In this chapter, we will focus mostly on unsupervised data mining algorithms.
    We will start with a recipe covering various distance measures. Understanding
    distance measures and various spaces is critical when building data science applications.
    Any dataset is usually a set of points that are objects belonging to a particular
    space. We can define space as a universal set of points from which the points
    in our dataset are drawn. The most often encountered space is Euclidean. In Euclidean
    space, the points are vectors real number. The length of the vector denotes the
    number of dimensions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将主要关注无监督数据挖掘算法。我们将从涵盖各种距离度量的食谱开始。理解距离度量和不同的空间在构建数据科学应用程序时至关重要。任何数据集通常都是一组属于特定空间的对象。我们可以将空间定义为从中抽取数据集中的点的点集。最常见的空间是欧几里得空间。在欧几里得空间中，点是实数向量。向量的长度表示维度的数量。
- en: We then have a recipe introducing kernel methods. Kernel methods are a very
    important topic in machine learning. They help us solve nonlinear data problems
    using linear methods. We will introduce the concept of the kernel trick.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍一个食谱，介绍核方法。核方法是机器学习中一个非常重要的主题。它们帮助我们通过线性方法解决非线性数据问题。我们将介绍核技巧的概念。
- en: We will follow it with some clustering algorithm recipes. Clustering is the
    process of partitioning a set of points into logical groups. For example, in a
    supermarket scenario, items are grouped into categories qualitatively. However,
    we will look at quantitative approaches. Specifically, we will focus our attention
    on the k-means algorithm and discuss its limitations and advantages.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍一些聚类算法的食谱。聚类是将一组点划分为逻辑组的过程。例如，在超市场景中，商品按类别进行定性分组。然而，我们将关注定量方法。具体来说，我们将把注意力集中在
    k-means 算法上，并讨论它的局限性和优点。
- en: Our next recipe is an unsupervised technique called learning vector quantization.
    It can be used both for clustering and classification tasks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一个食谱是一种无监督技术，称为学习向量量化。它既可以用于聚类任务，也可以用于分类任务。
- en: Finally, we will look at the outlier detection methods. Outliers are those observations
    in a dataset that differ significantly from the other observations in that dataset.
    It is very important to study these outliers as they might be indicative of unusual
    phenomena or errors in the underlying process that is generating the data. When
    machine learning models are fitted over data, it is important to understand how
    to handle outliers before passing the data to algorithms. We will concentrate
    on a few empirical outlier detection techniques in this chapter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将讨论异常值检测方法。异常值是数据集中与其他观测值有显著差异的观测值。研究这些异常值非常重要，因为它们可能是反映异常现象或数据生成过程中存在错误的信号。在机器学习模型应用于数据之前，了解如何处理异常值对于算法非常关键。本章将重点介绍几种经验性的异常值检测技术。
- en: We will rely heavily on the Python libraries, NumPy, SciPy, matplotlib, and
    scikit-learn for most of our recipes. We will also change our coding style from
    scripting to writing procedures and classes in this chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点依赖 Python 库，如 NumPy、SciPy、matplotlib 和 scikit-learn 来编写大部分食谱。我们还将从脚本编写转变为在本章中编写过程和类的风格。
- en: Working with distance measures
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用距离度量
- en: Distance and similarity measures are key to various data mining tasks. In this
    recipe, we will see some distance measures in action. Our next recipe will cover
    similarity measures. Let's define a distance measure before we look at the various
    distance metrics.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 距离和相似度度量是各种数据挖掘任务的关键。在本食谱中，我们将看到一些距离度量的应用。我们的下一个食谱将涉及相似度度量。在查看各种距离度量之前，让我们先定义一个距离度量。
- en: 'As data scientists, we are always presented with points or vectors of different
    dimensions. Mathematically, a set of points is defined as a space. A distance
    measure in this space is defined as a function d(x,y), which takes two points
    x and y as arguments in this space and gives a real number as the output. The
    distance function, that is, the real number output, should satisfy the following
    axioms:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，我们总是会遇到不同维度的点或向量。从数学角度来看，一组点被定义为一个空间。在这个空间中，距离度量被定义为一个函数d(x,y)，它以空间中的两个点x和y作为参数，并输出一个实数。这个距离函数，即实数输出，应该满足以下公理：
- en: The distance function output should be non-negative, d(x,y) >= 0
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 距离函数的输出应该是非负的，d(x,y) >= 0
- en: The output of the distance function should be zero only when x = y
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 距离函数的输出只有在x = y时才为零
- en: The distance should be symmetric, that is, d(x,y) = d(y,x)
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 距离应该是对称的，也就是说，d(x,y) = d(y,x)
- en: The distance should obey the triangle inequality, that is, d(x,y) <= d(x,z)
    + d(z,y)
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 距离应该遵循三角不等式，也就是说，d(x,y) <= d(x,z) + d(z,y)
- en: A careful look at the fourth axiom reveals that distance is the length of the
    shortest path between two points.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细查看第四个公理可以发现，距离是两点之间最短路径的长度。
- en: 'You can refer to the following link for more information on the axioms:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以参考以下链接获取有关公理的更多信息：
- en: '[http://en.wikipedia.org/wiki/Metric_%28mathematics%29](http://en.wikipedia.org/wiki/Metric_%28mathematics%29)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://en.wikipedia.org/wiki/Metric_%28mathematics%29](http://en.wikipedia.org/wiki/Metric_%28mathematics%29)'
- en: Getting ready
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备开始
- en: We will look at distance measures in Euclidean and non-Euclidean spaces. We
    will start with Euclidean distance and then define Lr–norm distance. Lr-norm is
    a family of distance measures of which Euclidean is a member. We will then follow
    it with the cosine distance. In non-Euclidean spaces, we will look at Jaccard's
    distance and Hamming distance.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究欧几里得空间和非欧几里得空间中的距离度量。我们将从欧几里得距离开始，然后定义Lr-norm距离。Lr-norm是一个距离度量家族，欧几里得距离是其中的一个成员。接着，我们会讨论余弦距离。在非欧几里得空间中，我们将研究Jaccard距离和汉明距离。
- en: How to do it…
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'Let''s start by defining the functions to calculate the various distance measures:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义函数开始，以计算不同的距离度量：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, let''s write a main routine in order to invoke these various distance
    measure functions:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编写一个主程序来调用这些不同的距离度量函数：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: How it works…
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Let's look at the main function. We created a sample dataset and two vectors
    of three dimensions and invoked the `euclidean_distance` function.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看主函数。我们创建了一个示例数据集和两个三维向量，并调用了`euclidean_distance`函数。
- en: 'This is the most common distance measure used is Euclidean distance. It belongs
    to a family of the Lr-Norm distance. A space is defined as a Euclidean space if
    the points in this space are vectors composed of real numbers. It''s also called
    the L2-norm distance. The formula for Euclidean distance is as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种最常用的距离度量，即欧几里得距离。它属于Lr-Norm距离的家族。如果空间中的点是由实数构成的向量，那么该空间被称为欧几里得空间。它也被称为L2范数距离。欧几里得距离的公式如下：
- en: '![How it works…](img/B04041_05_04.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/B04041_05_04.jpg)'
- en: As you can see, Euclidean distance is derived by finding the distance in each
    dimension (subtracting the corresponding dimensions), squaring the distance, and
    finally taking a square root.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，欧几里得距离是通过在每个维度上计算距离（减去对应的维度），将距离平方，最后取平方根来推导出来的。
- en: 'In our code, we leverage NumPy square root and power function in order to implement
    the preceding formula:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码中，我们利用了NumPy的平方根和幂函数来实现前述公式：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Euclidean distance is strictly positive. When x is equal to y, the distance
    is zero. This should become clear from how we invoked Euclidean distance:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得距离是严格正的。当x等于y时，距离为零。通过我们如何调用欧几里得距离，可以清楚地看到这一点：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you can see, we defined two NumPy arrays, `x` and `y`. We have kept them
    the same. Now, when we invoke the `euclidean_distance` function with these parameters,
    our output is zero.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们定义了两个NumPy数组，`x`和`y`。我们保持它们相同。现在，当我们用这些参数调用`euclidean_distance`函数时，输出是零。
- en: Let's now invoke the L2-norm function, `lrNorm_distance`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们调用L2范数函数，`lrNorm_distance`。
- en: 'The Lr-Norm distance metric is from a family of distance metrics of which Euclidean
    distance is a member. This should become clear as we see its formula:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Lr-Norm距离度量是距离度量家族中的一个成员，欧几里得距离属于该家族。我们可以通过它的公式来更清楚地理解这一点：
- en: '![How it works…](img/B04041_05_05.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/B04041_05_05.jpg)'
- en: 'You can see that we now have a parameter, `r`. Let''s substitute `r` with 2\.
    This will turn the preceding equation to a Euclidean equation. Hence, Euclidean
    is called the L2-norm distance:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，我们现在有了一个参数`r`。让我们将`r`替换为2，这样会将前面的方程转化为欧几里得方程。因此，欧几里得距离也称为L2范数距离：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In addition to two vectors, we will also pass a third parameter called `power`.
    This is the `r` defined in the formula. Invoking it with a power value set to
    two will yield the Euclidean distance. You can check it by running the following
    code:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 除了两个向量外，我们还将传入一个名为`power`的第三个参数。这就是公式中定义的`r`。将其调用并设置`power`值为2时，将得到欧几里得距离。你可以通过运行以下代码来验证：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This will yield zero as a result, which is similar to the Euclidean distance
    function.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得到零作为结果，这类似于欧几里得距离函数。
- en: Let's define two sample vectors, `x` and `y`, and invoke the `cosine_distance`
    function.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义两个示例向量，`x`和`y`，并调用`cosine_distance`函数。
- en: 'In the spaces where the points are considered as directions, the cosine distance
    yields a cosine of the angle between the given input vectors as a distance value.
    Both the Euclidean space also the spaces where the points are vectors of integers
    or Boolean values, are candidate spaces where the cosine distance function can
    be applied. The cosine of the angle between the input vectors is the ratio of
    a dot product of the input vectors to the product of an L2-norm of individual
    input vectors:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在将点视为方向的空间中，余弦距离表示给定输入向量之间角度的余弦值作为距离值。欧几里得空间以及点为整数或布尔值的空间，是余弦距离函数可以应用的候选空间。输入向量之间的角度余弦值是输入向量的点积与各自L2范数的乘积之比：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s look at the numerator where the dot product between the input vector
    is calculated:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下分子，其中计算了输入向量之间的点积：
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We will use the NumPy dot function to get the dot product value. The dot product
    for the two vectors, `x` and `y`, is defined as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用NumPy的点积函数来获取点积值。`x`和`y`这两个向量的点积定义如下：
- en: '![How it works…](img/B04041_05_06.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的…](img/B04041_05_06.jpg)'
- en: 'Now, let''s look at the denominator:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一下分母：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We again use the dot function to find the L2-norm of our input vectors:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次使用点积函数来计算输入向量的L2范数：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Thus, we can calculate the cosine of the angle between the two input vectors.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以计算两个输入向量之间角度的余弦值。
- en: We will move on to Jaccard's distance. Similar to the previous invocations,
    we will define the sample vectors and invoke the `jaccard_distance` function.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论Jaccard距离。与之前的调用类似，我们将定义示例向量并调用`jaccard_distance`函数。
- en: 'From vectors of real values, let''s move on to sets. Commonly called Jaccard''s
    coefficient, it is the ratio of the sizes of the intersection and the union of
    the given input vectors. One minus this value gives the Jaccard''s distance. As
    you can see, in the implementation, we first converted the input lists to sets.
    This will allows us to leverage the union and intersection operations provided
    by the Python set datatype:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从实数值的向量开始，让我们进入集合。通常称为Jaccard系数，它是给定输入向量交集与并集大小的比率。减去这个值等于Jaccard距离。如你所见，在实现中，我们首先将输入列表转换为集合。这样我们就可以利用Python集合数据类型提供的并集和交集操作：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, the distance is calculated as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，距离计算如下：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We must use the intersection and union functionalities that are available in
    the `set` datatype in order to calculate the distance.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须使用`set`数据类型中可用的交集和并集功能来计算距离。
- en: 'Our last distance metric is the Hamming distance. With two bit vectors, the
    Hamming distance calculates how many bits have differed in these two vectors:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最后一个距离度量是汉明距离。对于两个比特向量，汉明距离计算这两个向量中有多少个比特不同：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As you can see, we used the `zip` functionality to check each of the bits and
    maintain a counter on how many bits have differed. The Hamming distance is used
    with a categorical variable.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们使用了`zip`功能来检查每个比特，并维护一个计数器，统计有多少个比特不同。汉明距离用于分类变量。
- en: There's more...
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: Remember that by subtracting one from our distance values, we can arrive at
    a similarity value.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，通过从我们的距离值中减去1，我们可以得到一个相似度值。
- en: Yet another distance that we didn't go into in detail, but is used prevalently,
    is the Manhattan or city block distance. It's an L1-norm distance. By passing
    an r value as 1 to the Lr-norm distance function, we will get the Manhattan distance.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种我们没有详细探讨的距离，但它被广泛使用，那就是曼哈顿距离或城市块距离。这是一种L1范数距离。通过将r值设置为1传递给Lr范数距离函数，我们将得到曼哈顿距离。
- en: Depending on the underlying space in which the data is placed, an appropriate
    distance measure needs to be selected. When using these distances in algorithms,
    we need to be mindful about the underlying space. For example, in the k-means
    algorithm, at every step cluster center is calculated as an average of all the
    points that are close to each other. A nice property of Euclidean is that the
    average of the points exists and as a point in the same space. Note that our input
    for the Jaccard's distance was sets. An average of the sets does not make any
    sense.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据所处的底层空间，需要选择合适的距离度量。在算法中使用这些距离时，我们需要注意底层空间的情况。例如，在k均值算法中，每一步都会计算所有相互接近点的平均值作为簇中心。欧几里得空间的一个优点是点的平均值存在且也是该空间中的一个点。请注意，我们的Jaccard距离输入是集合，集合的平均值是没有意义的。
- en: While using the cosine distance, we need to check whether the underlying space
    is Euclidean or not. If the elements of the vectors are real numbers, then the
    space is Euclidean, if they are integers, then the space is non-Euclidean. The
    cosine distance is most commonly used in text mining. In text mining, the words
    are considered as the axes, and a document is a vector in this space. The cosine
    of the angle between two document vectors denotes how similar the two documents
    are.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用余弦距离时，我们需要检查底层空间是否为欧几里得空间。如果向量的元素是实数，则空间是欧几里得的；如果它们是整数，则空间是非欧几里得的。余弦距离在文本挖掘中最为常见。在文本挖掘中，单词被视为坐标轴，文档是这个空间中的一个向量。两个文档向量之间夹角的余弦值表示这两个文档的相似度。
- en: 'SciPy has an implementation of all these distance measures listed and much
    more at:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: SciPy实现了所有这些列出的距离度量及更多内容：
- en: '[http://docs.scipy.org/doc/scipy/reference/spatial.distance.html](http://docs.scipy.org/doc/scipy/reference/spatial.distance.html).'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://docs.scipy.org/doc/scipy/reference/spatial.distance.html](http://docs.scipy.org/doc/scipy/reference/spatial.distance.html)。'
- en: The above URL lists all the distance measures supported by SciPy.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的URL列出了SciPy支持的所有距离度量。
- en: 'Additionally, the scikit-learn `pairwise` submodule provides you with a method
    called `pairwise_distance`, which can be used to find out the distance matrix
    from input records. This can be found at:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，scikit-learn的`pairwise`子模块提供了一个叫做`pairwise_distance`的方法，可以用来计算输入记录之间的距离矩阵。你可以在以下位置找到：
- en: '[http://scikitlearn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html](http://scikitlearn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://scikitlearn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html](http://scikitlearn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html)。'
- en: We had mentioned that the Hamming distance is used with a categorical variable.
    A point worth mentioning here is the one-hot encoding that is used typically for
    categorical variables. After the one-hot encoding, the Hamming distance can be
    used as a similarity/distance measure between the input vectors.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们曾提到过汉明距离是用于分类变量的。这里需要提到的是，通常用于分类变量的一种编码方式是独热编码。在进行独热编码后，汉明距离可以作为输入向量之间的相似度/距离度量。
- en: See also
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: '*Reducing data dimension with Random Projections* recipe in [Chapter 4](ch04.xhtml
    "Chapter 4. Data Analysis – Deep Dive"), *Analyzing Data - Deep Dive*'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用随机投影减少数据维度*，见[第4章](ch04.xhtml "第4章 数据分析 - 深入探索")，*数据分析 - 深入探索*'
- en: Learning and using kernel methods
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习和使用核方法
- en: In this recipe, we will learn how to use kernel methods for data processing.
    Having the knowledge of kernels in your arsenal of methods will help you in dealing
    with nonlinear problems. This recipe is an introduction to kernel methods.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将学习如何使用核方法进行数据处理。掌握核方法可以帮助你解决非线性问题。本食谱是核方法的入门介绍。
- en: Typically, linear models—models that can separate the data using a straight
    line or hyper plane—are easy to interpret and understand. Nonlinearity in the
    data stops us from using linear models effectively. If the data can be transformed
    into a space where the relationship becomes linear, we can use linear models.
    However, mathematical computation in the transformed space can turn into a costly
    operation. This is where the kernel functions come to our rescue.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，线性模型——可以使用直线或超平面分离数据的模型——易于解释和理解。数据中的非线性使得我们无法有效使用线性模型。如果数据能够被转换到一个关系变为线性的空间中，我们就可以使用线性模型。然而，在变换后的空间中进行数学计算可能变成一个昂贵的操作。这就是核函数发挥作用的地方。
- en: Kernels are similarity functions. It takes two input parameters, and the similarity
    between the two inputs is the output of the kernel function. In this recipe, we
    will look at how kernel achieves this similarity. We will also discuss what is
    called a kernel trick.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 核函数是相似度函数。它接收两个输入参数，这两个输入之间的相似度就是核函数的输出。在这个示例中，我们将探讨核函数如何实现这种相似性。我们还将讨论所谓的“核技巧”。
- en: 'Formally defining a kernel K is a similarity function: K(x1,x2) > 0 denotes
    the similarity of x1 and x2.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正式定义一个核函数 K 是一个相似度函数：K(x1,x2) > 0 表示 x1 和 x2 之间的相似度。
- en: Getting ready
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'Let''s define it mathematically before looking at the various kernels:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看各种核函数之前，我们先来数学上定义一下：
- en: '![Getting ready](img/B04041_05_07.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/B04041_05_07.jpg)'
- en: 'Here, `xi` and, `xj` are the input vectors:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`xi` 和 `xj` 是输入向量：
- en: '![Getting ready](img/B04041_05_08.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/B04041_05_08.jpg)'
- en: 'The above mapping function is used to transform the input vectors into a new
    space. For example, if the input vector is in an n-dimensional space, the transformation
    function transforms it into a new space of dimension, m, where m >> n:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 上述映射函数用于将输入向量转化为一个新的空间。例如，如果输入向量位于一个 n 维空间中，变换函数将其转换为一个维度为 m 的新空间，其中 m >> n：
- en: '![Getting ready](img/B04041_05_09.jpg)![Getting ready](img/B04041_05_10.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/B04041_05_09.jpg)![准备就绪](img/B04041_05_10.jpg)'
- en: 'The above image denotes the dot product:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 上图表示的是点积：
- en: '![Getting ready](img/B04041_05_09.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/B04041_05_09.jpg)'
- en: The above image is the dot product, `xi` and `xj` are now transformed into a
    new space by the mapping function.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 上图是点积，`xi` 和 `xj` 现在通过映射函数被转换到一个新的空间中。
- en: In this recipe, we will see a simple kernel in action.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将看到一个简单的核函数在实际中的应用。
- en: 'Our mapping function will be as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的映射函数如下所示：
- en: '![Getting ready](img/B04041_05_20.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/B04041_05_20.jpg)'
- en: When the original data is supplied to this mapping function, it transforms the
    input into the new space.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当原始数据被输入到这个映射函数时，它将输入转化为新的空间。
- en: How to do it…
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'Let''s create two input vectors and define the mapping function as described
    in the previous section:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建两个输入向量，并按照前面章节中描述的方式定义映射函数：
- en: '[PRE13]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, let''s look at the main routine to invoke the kernel transformation. In
    the main function, we will define a kernel function and pass the input variable
    to the function, and print the output:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看主程序如何调用核变换。在主函数中，我们将定义一个核函数并将输入变量传递给它，然后打印输出：
- en: '![How to do it…](img/B04041_05_15.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![如何做](img/B04041_05_15.jpg)'
- en: '[PRE14]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: How it works…
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Let's follow this program from our main function. We created two input vectors,
    `x` and `y`. Both the vectors are of three dimensions.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从主函数开始跟踪这个程序。我们创建了两个输入向量，`x` 和 `y`。这两个向量都是三维的。
- en: We then defined a mapping function. The mapping function uses the input vector
    values and transforms the input vector into a new space with an increased dimension.
    In this case, the number of the dimension is increased to nine from three.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们定义了一个映射函数。这个映射函数利用输入向量的值，将输入向量转化为一个维度增加的新空间。在这个例子中，维度的数量从三维增加到九维。
- en: Let's now apply a mapping function on these vectors in order to increase their
    dimension to nine.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们对这些向量应用一个映射函数，将它们的维度增加到九维。
- en: 'If we print `tranf_x`, we will get the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打印 `tranf_x`，我们将得到如下结果：
- en: '[PRE15]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see, we transformed our input, x, from three dimensions to a nine-dimensional
    vector.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们将输入向量 x 从三维空间转化为一个九维向量。
- en: Now, let's take the dot product in the transformed space and print its output.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在变换后的空间中计算点积并打印输出。
- en: The output is 313600, a scalar value.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 输出为 313600，一个标量值。
- en: 'Let''s now recap: we first transformed our two input vectors into a higher
    dimensional space and then calculated the dot product in order to derive a scalar
    output.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们回顾一下：我们首先将两个输入向量转换到更高维的空间，然后计算点积以得到标量输出。
- en: What we did was a very costly operation of transforming our original three-dimensional
    vector to a nine-dimensional vector and then performing the dot product operation
    on it.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所做的是一个非常昂贵的操作，将原始的三维向量转换为九维向量，然后在其上执行点积操作。
- en: Instead, we can choose a kernel function, which can arrive at the same scalar
    output without explicitly transforming the original space into a new space.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可以选择一个内核函数，它能够在不显式地将原始空间转换为新空间的情况下得到相同的标量输出。
- en: 'Our new kernel is defined as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的新内核定义如下：
- en: '![How it works…](img/B04041_05_11.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/B04041_05_11.jpg)'
- en: With two inputs, `x` and `y`, this kernel computes the dot product of the vectors,
    and squares them.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于两个输入，`x` 和 `y`，该内核计算向量的点积，并对它们进行平方。
- en: After printing the output from the kernel, we get 313600.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在打印内核的输出后，我们得到了313600。
- en: We never did the transformation but still were able to get the same result as
    the dot product output in the transformed space. This is called the kernel trick.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从未进行过转换，但仍然能够得到与转换空间中点积输出相同的结果。这就是所谓的内核技巧。
- en: 'There was no magic in choosing this kernel. By expanding the kernel, we can
    arrive at our mapping function. Refer to the following reference for the expansion
    details:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 选择这个内核并没有什么魔力。通过扩展内核，我们可以得到我们的映射函数。有关扩展的详细信息，请参考以下文献：
- en: '[http://en.wikipedia.org/wiki/Polynomial_kernel](http://en.wikipedia.org/wiki/Polynomial_kernel).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://en.wikipedia.org/wiki/Polynomial_kernel](http://en.wikipedia.org/wiki/Polynomial_kernel)。'
- en: There's more...
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'There are several types of kernels. Based on our data characteristics and algorithm
    needs, we need to choose the right kernel. Some of them are as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种类型的内核。根据我们的数据特性和算法需求，我们需要选择合适的内核。以下是其中的一些：
- en: 'Linear kernel: This is the simplest kind of kernel function. For two given
    inputs, it returns the dot product of the input:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 线性内核：这是最简单的内核函数。对于两个给定的输入，它返回输入的点积：
- en: '![There''s more...](img/B04041_05_12.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![还有更多...](img/B04041_05_12.jpg)'
- en: 'Polynomial kernel: This is defined as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式内核：它的定义如下：
- en: '![There''s more...](img/B04041_05_13.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![还有更多...](img/B04041_05_13.jpg)'
- en: Here, `x` and `y` are the input vectors, `d` is the degree of the polynomial,
    and `c` is a constant. In our recipe, we used a polynomial kernel of degree 2.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`x` 和 `y` 是输入向量，`d` 是多项式的次数，`c` 是常数。在我们的配方中，我们使用了次数为2的多项式内核。
- en: 'The following is the scikit implementation of the linear and polynomial kernels:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是线性和多项式内核的scikit实现：
- en: '[http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.linear_kernel.html#sklearn.metrics.pairwise.linear_kernel](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.linear_kernel.html#sklearn.metrics.pairwise.linear_kernel)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.linear_kernel.html#sklearn.metrics.pairwise.linear_kernel](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.linear_kernel.html#sklearn.metrics.pairwise.linear_kernel)'
- en: '[http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.polynomial_kernel.html#sklearn.metrics.pairwise.polynomial_kernel](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.polynomial_kernel.html#sklearn.metrics.pairwise.polynomial_kernel).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.polynomial_kernel.html#sklearn.metrics.pairwise.polynomial_kernel](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.polynomial_kernel.html#sklearn.metrics.pairwise.polynomial_kernel)。'
- en: See also
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: '*Using Kernel PCA* recipe in [Chapter 4](ch04.xhtml "Chapter 4. Data Analysis
    – Deep Dive"), *Analyzing Data - Deep Dive*'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用内核PCA* 配方见[第4章](ch04.xhtml "第4章 数据分析 – 深入分析")，*数据分析 – 深入分析*'
- en: '*Reducing data dimension with Random Projections* recipe in [Chapter 4](ch04.xhtml
    "Chapter 4. Data Analysis – Deep Dive"), *Analyzing Data - Deep Dive*'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过随机投影减少数据维度* 配方见[第4章](ch04.xhtml "第4章 数据分析 – 深入分析")，*数据分析 – 深入分析*'
- en: Clustering data using the k-means method
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用k-means方法进行数据聚类
- en: In this recipe, we will look at the k-means algorithm. K-means is a center-seeking
    unsupervised algorithm. It is an iterative non-deterministic method. What we mean
    by iterative is that the algorithm steps are repeated till the convergence of
    a specified number of steps. Non-deterministic means that a different starting
    value may lead to a different final cluster assignment. The algorithm requires
    the number of clusters, `k`, as input. There is no good way to select the value
    of `k`, it has to be determined by running the algorithm multiple times.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论k-means算法。K-means是一种寻求中心的无监督算法。它是一种迭代的非确定性方法。所谓迭代是指算法步骤会重复，直到达到指定步数的收敛。非确定性意味着不同的起始值可能导致不同的最终聚类结果。该算法需要输入聚类的数量`k`。选择`k`值没有固定的方法，它必须通过多次运行算法来确定。
- en: For any clustering algorithm, the quality of its output is determined by inter-cluster
    cohesiveness and intra-cluster separation. Points in the same cluster should be
    close to each other; points in different clusters should be far away from each
    other.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何聚类算法，其输出的质量由聚类间的凝聚度和聚类内的分离度来决定。同一聚类中的点应彼此靠近；不同聚类中的点应相互远离。
- en: Getting ready
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Before we jump into how to write the k-means algorithm in Python, there are
    two key concepts that we need to cover that will help us understand better the
    quality of the output produced by our algorithm. First is a definition with respect
    to the quality of the clusters formed, and second is a metric that is used to
    find the quality of the clusters.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解如何用Python编写k-means算法之前，有两个关键概念需要讨论，它们将帮助我们更好地理解算法输出的质量。第一个是与聚类质量相关的定义，第二个是用于衡量聚类质量的度量标准。
- en: 'Every cluster detected by k-means can be evaluated using the following measures:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 每个由k-means检测到的聚类都可以通过以下度量进行评估：
- en: '**Cluster location**: This is the coordinates of the cluster center. K-means
    starts with some random points as the cluster center and iteratively finds a new
    center around which points that are similar are grouped.'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聚类位置**：这是聚类中心的坐标。K-means算法从一些随机点作为聚类中心开始，并通过迭代不断找到新的中心，使得相似的点被聚集到一起。'
- en: '**Cluster radius**: This is the average deviation of all the points from the
    cluster center.'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聚类半径**：这是所有点与聚类中心的平均偏差。'
- en: '**Mass of the cluster**: This is the number of points in a cluster.'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聚类质量**：这是聚类中点的数量。'
- en: '**Density of the cluster**: This is the ratio of mass of the cluster to its
    radius.'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聚类密度**：这是聚类质量与其半径的比值。'
- en: Now, we will measure the quality of our output clusters. As mentioned previously,
    this is an unsupervised problem and we don't have labels against which to check
    our output in order to get measures such as precision, recall, accuracy, F1-score,
    or other similar metrics. The metric that we will use for our k-means algorithm
    is called a silhouette coefficient. It takes values in the range of -1 to 1\.
    Negative values indicate that the cluster radius is greater than the distance
    between the clusters so that the clusters overlap. This suggests poor clustering.
    Large values, that is, values close to 1, indicate good clustering.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将衡量输出聚类的质量。如前所述，这是一个无监督问题，我们没有标签来验证输出，因此无法计算诸如精确度、召回率、准确度、F1分数或其他类似的度量指标。我们将为k-means算法使用的度量标准称为轮廓系数。它的取值范围是-1到1。负值表示聚类半径大于聚类之间的距离，从而导致聚类重叠，这表明聚类效果较差。较大的值，即接近1的值，表示聚类效果良好。
- en: A silhouette coefficient is defined for each point in the cluster. With a cluster,
    C, and a point, `i`, in this cluster, let `xi` be the average distance of this
    point from all the other points in the cluster.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 轮廓系数是为聚类中每个点定义的。对于一个聚类C和聚类中的一个点`i`，令`xi`为该点与聚类中所有其他点的平均距离。
- en: 'Now, calculate the average distance that the point `i` has from all the points
    in another cluster, D. Pick the smallest of these values and call it `yi`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，计算点`i`与另一个聚类D中所有点的平均距离，记为D。选择这些值中的最小值，称为`yi`：
- en: '![Getting ready](img/B04041_05_14.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/B04041_05_14.jpg)'
- en: For every cluster, the average of the silhouette coefficient of all the points
    can serve as a good measure of the cluster quality. An average of the silhouette
    coefficient of all the data points can serve as an overall quality metric for
    the clusters formed.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个簇，所有点的轮廓系数的平均值可以作为簇质量的良好度量。所有数据点的轮廓系数的平均值可以作为整体簇质量的度量。
- en: 'Let''s go ahead and generate some random data:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续生成一些随机数据：
- en: '[PRE16]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We sampled two sets of data from a normal distribution. The first set was picked
    up with a mean of `0.2` and standard deviation of `0.2`. For the second set, our
    mean value was `0.9` and standard deviation was `0.1`. Each dataset was a matrix
    of size 100 * 100—we have `100` instances and `100` dimensions. Finally, we merged
    both of them using the row stacking function from NumPy. Our final dataset was
    of size 200 * 100.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从正态分布中采样了两组数据。第一组数据的均值为`0.2`，标准差为`0.2`。第二组数据的均值为`0.9`，标准差为`0.1`。每个数据集的大小为100
    * 100——我们有`100`个实例和`100`个维度。最后，我们使用NumPy的行堆叠函数将它们合并。我们的最终数据集大小为200 * 100。
- en: 'Let''s do a scatter plot of the data:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制数据的散点图：
- en: '[PRE17]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The plot is as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图如下：
- en: '![Getting ready](img/B04041_05_01.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/B04041_05_01.jpg)'
- en: Though we plotted only the first and second dimension, you can still clearly
    see that we have two clusters. Let's now jump into writing our k-means clustering
    algorithm.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们只绘制了第一维和第二维，但你仍然可以清楚地看到我们有两个簇。现在，让我们开始编写我们的k-means聚类算法。
- en: How to do it…
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: Let's define a function that can perform the k-means clustering for the given
    data and a parameter, `k`. The function fits the clustering on the given data
    and returns an overall silhouette coefficient.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个函数，可以对给定的数据和参数`k`执行k-means聚类。该函数对给定数据进行聚类，并返回整体的轮廓系数。
- en: '[PRE18]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s invoke the preceding function for the different values of `k` and store
    the returned silhouette coefficient:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们调用上述函数，针对不同的`k`值，并存储返回的轮廓系数：
- en: '[PRE19]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Finally, let's plot the silhouette coefficient for the different values of `k`.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们绘制不同`k`值的轮廓系数。
- en: '[PRE20]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How it works…
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何运作...
- en: 'As mentioned previously, k-means is an iterative algorithm. Roughly, the steps
    of k-means are as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，k-means是一个迭代算法。大致来说，k-means的步骤如下：
- en: Initialize `k` random points from the dataset as initial center points.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据集中初始化`k`个随机点作为初始中心点。
- en: 'Do the following till the convergence of the specified number of times:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下步骤进行，直到指定次数的迭代收敛：
- en: Assign the points to the closest cluster center. Typically, Euclidean distance
    is used to find the distance between a point and the cluster center.
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将点分配给距离最近的簇中心。通常使用欧几里得距离来计算点与簇中心之间的距离。
- en: Recalculate the new cluster centers based on the assignment in this iteration.
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据本次迭代中的分配重新计算新的簇中心。
- en: Exit the loop if a cluster assignment of the points remains the same as the
    previous iteration. The algorithm has converged to an optimal solution.
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果点的簇分配与上一次迭代相同，则退出循环。算法已收敛到最优解。
- en: 'We will leverage the k-means implementation from the scikit-learn library.
    Our cluster function takes the k value and dataset as a parameter and runs the
    k-means algorithm:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用来自scikit-learn库的k-means实现。我们的聚类函数接受k值和数据集作为参数，并运行k-means算法：
- en: '[PRE21]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `no_clusters` is the parameter that we will pass to the function. Using
    the init parameter, we set the initial center points as random. When init is set
    to random, scikit-learn estimates the mean and variance from the data and then
    samples k centers from a Gaussian distribution.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`no_clusters`是我们将传递给函数的参数。使用init参数时，我们将初始中心点设置为随机值。当init设置为random时，scikit-learn会根据数据估算均值和方差，然后从高斯分布中采样k个中心。'
- en: 'Finally, we must call the fit method to run k-means on our dataset:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们必须调用fit方法，在我们的数据集上运行k-means算法：
- en: '[PRE22]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We get the labels, that is, the cluster assignment for each point and find out
    the silhouette coefficient for all the points in our cluster.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获取标签，即每个点的簇分配，并计算出簇中所有点的轮廓系数。
- en: 'In real-world scenarios, when we start with the k-means algorithm on a dataset,
    we don''t know the number of clusters present in the data; in other words, we
    don''t know the ideal value for k. However, in our example, we know that k=2 as
    we generated the data in such a manner that it fits in two clusters. Hence, we
    need to run k-means for the different values of k:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际场景中，当我们在数据集上启动k-means算法时，我们并不知道数据中存在的集群数量；换句话说，我们不知道k的理想值。然而，在我们的示例中，我们知道k=2，因为我们生成的数据已经适配了两个集群。因此，我们需要针对不同的k值运行k-means：
- en: '[PRE23]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'For each run, that is, each value of k, we store the silhouette coefficient.
    A plot of k versus the silhouette coefficient reveals the ideal k value for the
    dataset:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每次运行，也就是每个k值，我们都会存储轮廓系数。k与轮廓系数的图表可以揭示数据集的理想k值：
- en: '[PRE24]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![How it works…](img/B04041_05_02.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的…](img/B04041_05_02.jpg)'
- en: As expected, our silhouette coefficient is very high for k=2.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，k=2时，我们的轮廓系数非常高。
- en: There's more...
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: A couple of points to be noted about k-means. The k-means algorithm cannot be
    used for categorical data, k-medoids is used. Instead of averaging all the points
    in a cluster in order to find the cluster center, k-medoids selects a point that
    has the smallest average distance to all the other points in the cluster.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 关于k-means需要注意的几点：k-means算法不能用于类别数据，对于类别数据需要使用k-medoids。k-medoids不是通过平均所有点来寻找集群中心，而是选择一个点，使其与该集群中所有其他点的平均距离最小。
- en: Care needs to be taken while assigning the initial cluster. If the data is very
    dense with very widely separated clusters, and if the initial random centers are
    chosen in the same cluster, k-means may not perform very well.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在分配初始集群时需要小心。如果数据非常密集且集群之间距离非常远，且初始随机中心选择在同一个集群中，那么k-means可能表现不佳。
- en: 'Typically, k-means works if the data has star convex clusters. Refer to the
    following link for more information on star convex-shaped data points:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，k-means算法适用于具有星形凸集群的数据。有关星形凸数据点的更多信息，请参考以下链接：
- en: '[http://mathworld.wolfram.com/StarConvex.html](http://mathworld.wolfram.com/StarConvex.html)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://mathworld.wolfram.com/StarConvex.html](http://mathworld.wolfram.com/StarConvex.html)'
- en: The presence of nested or other complicated clusters will result in a junk output
    from k-means.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据中存在嵌套集群或其他复杂集群，k-means的结果可能会是无意义的输出。
- en: The presence of outliers in the data may yield poor results. A good practice
    is to do a thorough data exploration in order to identify the data characteristics
    before running k-means.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中异常值的存在可能导致较差的结果。一种好的做法是在运行k-means之前，进行彻底的数据探索，以便了解数据特征。
- en: 'An alternative method to initialize the centers during the beginning of the
    algorithm is the k-means++ method. So, instead of setting the init parameter to
    random, we can set it using k-means++. Refer to the following paper for k-means++:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一种在算法开始时初始化中心的替代方法是k-means++方法。因此，除了将init参数设置为随机值外，我们还可以使用k-means++来设置它。有关k-means++的更多信息，请参考以下论文：
- en: '*k-means++: the advantages of careful seeding*. *ACM-SIAM symposium* on *Discrete
    algorithms. 2007*'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '*k-means++：小心初始化的优势*。*ACM-SIAM 研讨会*关于*离散算法。2007年*'
- en: See also
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: '*Working with Distance Measures* recipe in [Chapter 5](ch05.xhtml "Chapter 5. Data
    Mining – Needle in a Haystack"), *Data Mining - Finding a needle in a haystack*'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第5章](ch05.xhtml "第5章 数据挖掘 - 在大海捞针")中的*距离度量工作法*配方，*数据挖掘 - 在大海捞针*
- en: Discovering outliers using the local outlier factor method
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用局部离群因子方法发现异常值
- en: The Local Outlier Factor (LOF) is an outlier detection algorithm that detects
    the outliers based on comparing the local density of the data instance with its
    neighbors. It does this in order to decide if the data instance belongs to a region
    of similar density. It can detect an outlier in a dataset, in such circumstances
    where the number of clusters are unknown and the clusters are of different density
    and sizes. It's inspired by the KNN (K-Nearest Neighbors) algorithm and is widely
    used.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 局部离群因子（LOF）是一种异常值检测算法，它通过比较数据实例与其邻居的局部密度来检测异常值。其目的是决定数据实例是否属于相似密度的区域。它可以在数据集群数量未知且集群具有不同密度和大小的情况下，检测出数据集中的异常值。它受KNN（K-最近邻）算法的启发，并被广泛使用。
- en: Getting ready
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In the previous recipe, we looked at univariate data. In this one, we will use
    multivariate data and try to find outliers. Let's use a very small dataset to
    understand the LOF algorithm for outlier detection.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个配方中，我们研究了单变量数据。在这个配方中，我们将使用多变量数据并尝试找出异常值。让我们使用一个非常小的数据集来理解LOF算法进行异常值检测。
- en: 'We will create a 5 X 2 matrix, and looking at the data, we know that the last
    tuple is an outlier. Let''s also plot it as a scatter plot:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个5 X 2的矩阵，查看数据后我们知道最后一个元组是异常值。我们也可以将其绘制为散点图：
- en: '[PRE25]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The plot looks as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图结果如下：
- en: '![Getting ready](img/B04041_05_19.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![准备中](img/B04041_05_19.jpg)'
- en: LOF works by calculating the local density of each point. Based on the distance
    of k-nearest neighbors of a point, the local density of the point is estimated.
    By comparing the local density of the point with the densities of its neighbors,
    outliers are detected. Outliers have a low density compared with their neighbors.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: LOF通过计算每个点的局部密度来工作。根据点的k近邻的距离，估算该点的局部密度。通过将点的局部密度与其邻居的密度进行比较，检测出异常值。与邻居相比，异常值的密度较低。
- en: 'We will need to go through some term definitions in order to understand LOF:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解LOF，我们需要了解一些术语定义：
- en: The k-distance of object P is the distance between the object P and its kth
    nearest neighbor. K is a parameter of the algorithm.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象P的k距离是对象P与其第k近邻之间的距离。K是算法的一个参数。
- en: The k-distance neighborhood of P is the list of all the objects, Q, whose distance
    from P is either less than or equal to the distance between P and its kth nearest
    object.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P的k距离邻域是所有距离P的距离小于或等于P与其第k近邻之间距离的对象Q的列表。
- en: 'The reachability distance from P to Q is defined as the maximum of the distance
    between P and its kth nearest neighbor, and the distance between P and Q. The
    following notation may help clarify this:'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从P到Q的可达距离定义为P与其第k近邻之间的距离与P到Q之间的距离中的最大值。以下符号可能有助于澄清这一点：
- en: '[PRE26]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The Local Reachability Density of P (LRD(P)) is the ratio of the k-distance
    neighborhood of P and the sum of the reachability distance of k and its neighborhood.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P的局部可达密度（LRD(P)）是P的k距离邻域与P及其邻居的可达距离之和的比值。
- en: The Local Outlier Factor of P (LOF(P)) is the average of the ratio of the local
    reachability of P and those of P's k-nearest neighbors.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P的局部异常因子（LOF(P)）是P的局部可达密度与P的k近邻局部可达密度的比值的平均值。
- en: How to do it…
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现……
- en: 'Let''s get the `pairwise` distance between the points:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算点之间的`pairwise`距离：
- en: '[PRE27]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s calculate the k-distance. We will use `heapq` and get the k-nearest
    neighbors:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算k距离。我们将使用`heapq`来获取k近邻：
- en: '[PRE28]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Calculate the k-distance neighborhood:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算k距离邻域：
- en: '[PRE29]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, calculate the reachability distance and LRD:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，计算可达距离和LRD：
- en: '[PRE30]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Calculate LOF:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算LOF：
- en: '[PRE31]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: How it works…
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: In step 1, we select our distance metric to be Manhattan and our k value as
    two. We are looking at the second nearest neighbor for our data point.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤1中，我们选择曼哈顿距离作为距离度量，k值为2。我们正在查看数据点的第二近邻。
- en: 'We must then proceed to calculate the pairwise distance between our tuples.
    The pairwise similarity is stored in the dist matrix. As you can see, the shape
    of dist is as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们必须计算我们的元组之间的成对距离。成对相似性存储在dist矩阵中。正如你所看到的，dist的形状如下：
- en: '[PRE32]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: It is a 5 X 5 matrix, where the rows and columns are individual tuples and the
    cell value indicates the distance between them.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 它是一个5 X 5的矩阵，其中行和列是各个元组，单元格的值表示它们之间的距离。
- en: 'In step 2, we then import `heapq`:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤2中，我们导入`heapq`：
- en: '[PRE33]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '`heapq` is a data structure that is also known as a priority queue. It is similar
    to a regular queue except that each element is associated with a priority, and
    an element with a high priority is served before an element with a low priority.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '`heapq`是一种数据结构，也称为优先队列。它类似于常规队列，区别在于每个元素都有一个优先级，优先级高的元素会先于优先级低的元素被处理。'
- en: 'Refer to the Wikipedia link for more information on priority queues:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考维基百科链接获取有关优先队列的更多信息：
- en: '[http://en.wikipedia.org/wiki/Priority_queue](http://en.wikipedia.org/wiki/Priority_queue).'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://en.wikipedia.org/wiki/Priority_queue](http://en.wikipedia.org/wiki/Priority_queue)。'
- en: The Python heapq documentation can be found at [https://docs.python.org/2/library/heapq.html](https://docs.python.org/2/library/heapq.html).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Python的heapq文档可以在[https://docs.python.org/2/library/heapq.html](https://docs.python.org/2/library/heapq.html)找到。
- en: '[PRE34]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Next, we define a dictionary where the key is the tuple ID and the value is
    the distance of the tuple to its kth nearest neighbor. In our case, it should
    be the second nearest neighbor.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个字典，其中键是元组ID，值是元组与其第k近邻的距离。在我们的情况下，应该是第二近邻。
- en: 'We then enter a for loop in order to find the kth nearest neighbor''s distance
    for each of the data points:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们进入一个for循环，以便为每个数据点找到第k近邻的距离：
- en: '[PRE35]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'From our distance matrix, we extract the ith row. As you can see, the ith row
    captures the distance between the object `i` and all the other objects. Remember
    that the cell value (`i`,`i`) holds the distance to itself. We need to ignore
    this in the next step. We must convert the array to a list for our convenience.
    Let''s try to understand this with an example. The distance matrix looks as follows:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的距离矩阵中，我们提取第i行。正如你所看到的，第i行捕获了对象`i`与所有其他对象之间的距离。记住，单元格值（`i`,`i`）表示与自身的距离。我们需要在下一步中忽略这一点。我们必须将数组转换为列表以方便操作。让我们通过一个例子来理解这一点。距离矩阵如下所示：
- en: '[PRE36]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Let's assume that we are in the first iteration of our for loop and hence, our
    `i` =`0`. (remember that the Python indexing starts with `0`).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们处于for循环的第一次迭代中，因此我们的`i`=`0`。（记住，Python的索引是从`0`开始的）。
- en: 'So, now our distances list will look as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在我们的距离列表将如下所示：
- en: '[PRE37]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: From this, we need the kth nearest neighbor, that is, the second nearest neighbor,
    as we have set K = `2` at the beginning of the program.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 从中，我们需要第k近邻，即第二近邻，因为我们在程序开始时将K设置为`2`。
- en: Looking at it, we can see that both index 1 and index 3 can be our the kth nearest
    neighbor as both have a value of `1`.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 从中我们可以看到，索引1和索引3都可以作为我们的第k近邻，因为它们的值都是`1`。
- en: 'Now, we use the `heapq.nsmallest` function. Remember that we had mentioned
    that `heapq` is a normal queue but with a priority associated with each element.
    The value of the element is the priority in this case. When we say that give me
    the n smallest, `heapq` will return the smallest elements:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用`heapq.nsmallest`函数。记住，我们之前提到过，`heapq`是一个普通队列，但每个元素都有一个优先级。在这种情况下，元素的值即为优先级。当我们说给我n个最小值时，`heapq`会返回最小的元素：
- en: '[PRE38]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let''s look at what the `heapq.nsmallest` function does:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下`heapq.nsmallest`函数的作用：
- en: '[PRE39]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: It returns the n smallest elements from the given dataset. In our case, we need
    the second nearest neighbor. Additionally, we need to avoid (`i`,`i`) as mentioned
    previously. So we must pass n = 3 to `heapq.nsmallest`. This ensures that it returns
    the three smallest elements. We then subset the list to exclude the first element
    (see [1:] after nsmallest function call) and finally retrieve the second nearest
    neighbor (see `[k-1]` after `[1:]`).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回给定数据集中的n个最小元素。在我们的例子中，我们需要第二近邻。此外，我们需要避免之前提到的（`i`,`i`）。因此，我们必须传递n=3给`heapq.nsmallest`。这确保它返回三个最小元素。然后，我们对列表进行子集操作，排除第一个元素（参见nsmallest函数调用后的[1:]），最终获取第二近邻（参见[1:]后的`[k-1]`）。
- en: 'We must also get the index of the second nearest neighbor of `i` and store
    it in our dictionary:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须获取`i`的第二近邻的索引，并将其存储在字典中：
- en: '[PRE40]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Let''s print our dictionary:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印出我们的字典：
- en: '[PRE41]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Our tuples have two elements: the distance, and the index of the elements in
    the distances array. So, for instance `0`, the second nearest neighbor is the
    element in index `1`.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的元组有两个元素：距离和在距离数组中元素的索引。例如，对于`0`，第二近邻是索引为`1`的元素。
- en: Having calculated the k-distance for all our data points, we then move on to
    find the k-distance neighborhood.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 计算完所有数据点的k距离后，我们接下来找出k距离邻域。
- en: 'In step 3, we find the k-distance neighborhood for each of our data points:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤3中，我们为每个数据点找到k距离邻域：
- en: '[PRE42]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Similar to our previous step, we import the heapq module and declare a dictionary
    that is going to hold our k-distance neighborhood details. Let''s recap what the
    k-distance neighborhood is:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一步类似，我们导入了heapq模块并声明了一个字典，用来保存我们的k距离邻域的详细信息。让我们回顾一下什么是k距离邻域：
- en: 'The k-distance neighborhood of P is the list of all the objects, Q, whose distance
    from P is either less than or equal to the distance between P and its kth nearest
    object:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: P的k距离邻域是所有与P的距离小于或等于P与其第k近邻之间距离的对象Q的列表：
- en: '[PRE43]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The first two lines should be familiar to you. We did this in our previous step.
    Look at the second line. Here, we invoked n smallest again with `n=3` in our case
    (K+1), but we selected all the elements in the output list except the first one.
    (Guess why? The answer is in the previous step.)
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 前两行应该对你很熟悉。我们在上一步已经做过了。看看第二行。在这里，我们再次调用了n smallest，`n=3`（即K+1），但我们选择了输出列表中的所有元素，除了第一个。（猜猜为什么？答案在前一步中）。
- en: Let's see it in action by printing the values. As usual, in the loop, we assume
    that we are seeing the first data point or tuple where i=0.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过打印值来查看其实际操作。像往常一样，在循环中，我们假设我们看到的是第一个数据点或元组，其中i=0。
- en: 'Our distances list is as follows:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的距离列表如下所示：
- en: '[PRE44]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Our `heapq.nsmallest` function returns the following:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`heapq.nsmallest`函数返回如下：
- en: '[PRE45]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'These are 1 to k-nearest neighbor''s distances. We need to find their indices,
    a simple list.index function will only return the first match, so we will write
    the `all_indices` function in order to retrieve all the indices:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是1到k个最近邻的距离。我们需要找到它们的索引，简单的list.index函数只会返回第一个匹配项，因此我们将编写`all_indices`函数来检索所有索引：
- en: '[PRE46]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'With a value and list, `all_indices` will return all the indices where the
    value occurs in the list. We must convert our k smallest to a set:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 通过值和列表，`all_indices`将返回值在列表中出现的所有索引。我们必须将k个最小值转换为集合：
- en: '[PRE47]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'So, [1.0,1.0] becomes a set ([1.0]). Now, using a for loop, we can find all
    the indices of the elements:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，[1.0,1.0]变成了一个集合([1.0])。现在，使用for循环，我们可以找到所有元素的索引：
- en: '[PRE48]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We get two indices for 1.0; they are 1 and 2:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为1.0得到两个索引；它们是1和2：
- en: '[PRE49]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The next for loop is to convert a list of the lists to a list. The `all_indices`
    function returns a list, and we then append this list to the `ksmallest_idx` list.
    Hence, we flatten it using the next for loop.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个for循环用于将列表中的列表转换为列表。`all_indices`函数返回一个列表，我们然后将此列表添加到`ksmallest_idx`列表中。因此，我们通过下一个for循环将其展开。
- en: 'Finally, we add the k smallest neighborhood to our dictionary:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将k个最小的邻域添加到我们的字典中：
- en: '[PRE50]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We then add tuples where the first item in the tuple is the distance and the
    second item is the index of the nearest neighbor. Let''s print the k-distance
    neighborhood dictionary:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们添加元组，其中元组中的第一个项是距离，第二个项是最近邻的索引。让我们打印k距离邻域字典：
- en: '[PRE51]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'In step 4, we calculate the LRD. The LRD is calculated using the reachability
    distance. Let''s recap both the definitions:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤4中，我们计算LRD。LRD是通过可达距离来计算的。让我们回顾一下这两个定义：
- en: 'The reachability distance from P to Q is defined as the maximum of the distance
    between P and its kth nearest neighbor, and the distance between P and Q. The
    following notation may help clarify this:'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从P到Q的可达距离被定义为P与其第k个最近邻之间的距离和P与Q之间的距离的最大值。以下符号可能有助于澄清这一点：
- en: '[PRE52]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The Local Reachability density of P (LRD(P)) is the ratio of the k-distance
    neighborhood of P and the sum of the reachability distance of k and its neighborhood:'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P的局部可达密度（LRD(P)）是P的k距离邻域与k及其邻域的可达距离之和的比率：
- en: '[PRE53]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We will first declare a dictionary in order to store the LRD:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先声明一个字典来存储LRD：
- en: '[PRE54]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: For every point, we will first find the k-distance neighborhood of that point.
    For example, for i = 0, the numerator would be len (`k_distance_neig[0]`), 2.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个点，我们将首先找到该点的k距离邻域。例如，对于i = 0，分子将是len(`k_distance_neig[0]`)，即2。
- en: Now, in the inner for loop, we calculate the denominator. We then calculate
    the reachability distance for each k-distance neighborhood point. The ratio is
    stored in the `local_reach_density` dictionary.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在内部的for循环中，我们计算分母。然后我们计算每个k距离邻域点的可达距离。该比率存储在`local_reach_density`字典中。
- en: 'Finally, in step 5, we calculate the LOF for each point:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在步骤5中，我们计算每个点的LOF：
- en: '[PRE55]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: For each data point, we calculate the LRD sum of its neighbor and the reachability
    distance sum with its neighbor, and multiply them to get the LOF.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个数据点，我们计算其邻居的LRD之和和与其邻居的可达距离之和，并将它们相乘以得到LOF。
- en: 'The point with a very high LOF is considered an outlier. Let''s print `lof_list`:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: LOF值非常高的点被视为异常点。让我们打印`lof_list`：
- en: '[PRE56]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: As you can see, the last point has a very high LOF compared with the others
    and hence, it's an outlier.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，最后一个点与其他点相比，LOF非常高，因此，它是一个异常点。
- en: There's more…
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'You can refer to the following paper in order to understand more about LOF:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解LOF，你可以参考以下论文：
- en: '*LOF: Identifying Density-Based Local Outliers*'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '*LOF：识别基于密度的局部异常点*'
- en: '*Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng, Jörg Sander*'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '*Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng, Jörg Sander*'
- en: '*Proc. ACM SIGMOD 2000 Int. Conf. On Management of Data, Dalles, TX, 2000*'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '*Proc. ACM SIGMOD 2000国际数据管理会议，德克萨斯州达拉斯，2000年*'
- en: Learning vector quantization
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习向量量化
- en: In this recipe, we will see a model-free method for clustering the data points
    called Learning Vector Quantization, LVQ for short. LVQ can be used in classification
    tasks. Not much of an inference can be made between the target variables and prediction
    variables using this technique. Unlike the other methods, it is tough to make
    out what relationships exist between the response variable, Y, and predictor,
    X. They serve very well as a black box approach in many real-world scenarios.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将看到一种无模型的方法来聚类数据点，称为学习向量量化，简称LVQ。LVQ可以用于分类任务。使用这种技术很难在目标变量和预测变量之间做出推理。与其他方法不同，很难弄清楚响应变量Y与预测变量X之间存在哪些关系。它们在许多现实世界的场景中作为黑箱方法非常有效。
- en: Getting ready
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: LVQ is an online learning algorithm where the data points are processed one
    at a time. It makes a very simple intuition. Assume that we have prototype vectors
    identified for the different classes present in our dataset. The training points
    will be attracted towards the prototypes of similar classes and will repel the
    other prototypes.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: LVQ是一种在线学习算法，其中数据点一次处理一个。它的直观理解非常简单。假设我们已经为数据集中不同的类别识别了原型向量。训练点会朝向相似类别的原型靠近，并会排斥其他类别的原型。
- en: 'The major steps in LVQ are as follows:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: LVQ的主要步骤如下：
- en: Select k initial prototype vectors for each class in the dataset. If it's a
    two-class problem and we decide to have two prototype vectors for each class,
    we will end up with four initial prototype vectors. The initial prototype vectors
    are selected randomly from the input dataset.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 为数据集中的每个类别选择k个初始原型向量。如果是二分类问题，我们决定为每个类别选择两个原型向量，那么我们将得到四个初始原型向量。初始原型向量是从输入数据集中随机选择的。
- en: We will start our iteration. Our iteration will end when our epsilon value has
    reached either zero or a predefined threshold. We will decide an epsilon value
    and decrement the epsilon value with every iteration.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开始迭代。我们的迭代将在epsilon值达到零或预定义阈值时结束。我们将决定一个epsilon值，并在每次迭代中递减epsilon值。
- en: 'In each iteration, we will sample an input point (with replacement) and find
    the closest prototype vector to this point. We will use Euclidean distance to
    find the closest point. We will update the prototype vector of the closest point,
    as follows:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次迭代中，我们将对一个输入点进行抽样（有放回抽样），并找到离该点最近的原型向量。我们将使用欧几里得距离来找到最近的点。我们将如下更新最近点的原型向量：
- en: If the class label of the prototype vector is the same as the input data point,
    we will increment the prototype vector with the difference between the prototype
    vector and data point.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 如果原型向量的类别标签与输入数据点相同，我们将通过原型向量与数据点之间的差值来增大原型向量。
- en: If the class label is different, we will decrement the prototype vector with
    the difference between the prototype vector and data point.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 如果类别标签不同，我们将通过原型向量与数据点之间的差值来减少原型向量。
- en: We will use the Iris dataset to demonstrate how LVQ works. As in some of our
    previous recipe, we will use the convenient data loading function from scikit-learn
    in order to load the Iris dataset. Iris is a well known classification dataset.
    However our purpose of using it here is to only demonstrate LVQ's capability.
    Datasets without class lablels can also be used or processed by LVQ. As we are
    going to use Euclidean distance, we will scale the data using minmax scaling.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Iris数据集来演示LVQ的工作原理。如同我们之前的一些示例，我们将使用scikit-learn的方便数据加载函数来加载Iris数据集。Iris是一个广为人知的分类数据集。然而我们在这里使用它的目的是仅仅为了演示LVQ的能力。没有类别标签的数据集也可以被LVQ使用或处理。由于我们将使用欧几里得距离，因此我们将使用minmax缩放来对数据进行缩放。
- en: '[PRE57]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: How to do it…
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'Let''s first declare the parameters for LVQ:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先声明LVQ的参数：
- en: '[PRE58]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Define a class to hold the prototype vectors:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个类来保存原型向量：
- en: '[PRE59]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'This is the function to find the closest prototype vector for a given vector:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个用于找到给定向量最接近的原型向量的函数：
- en: '[PRE60]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'A convenient function to find the class ID of the closest prototype vector
    is as follows:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个方便的函数，用来找到最接近的原型向量的类别ID如下：
- en: '[PRE61]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Choose the initial K * number of classes of prototype vectors:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择初始的K * 类别数的原型向量：
- en: '[PRE62]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Perform iteration to adjust the prototype vector in order to classify/cluster
    any new incoming points using the existing data points:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行迭代调整原型向量，以便使用现有的数据点对任何新的输入点进行分类/聚类：
- en: '[PRE63]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The following is a small test to verify the correctness of our method:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下是一个小的测试，用来验证我们方法的正确性：
- en: '[PRE64]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: How it works…
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In step 1, we initialize the parameters for the algorithm. We have chosen our
    R value as two, that is, we have two prototype vectors per class label. The Iris
    dataset is a three-class problem, so we have six prototype vectors in total. We
    must choose our epsilon value and epsilon decrement factor.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 1 步中，我们初始化了算法的参数。我们选择了 R 值为 2，也就是说，每个类别标签有两个原型向量。Iris 数据集是一个三类问题，所以我们一共有六个原型向量。我们必须选择我们的
    epsilon 值和 epsilon 减小因子。
- en: 'We then define a data structure to hold the details of our prototype vector
    in step 2\. Our class stores the following for each point in the dataset:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们在第 2 步中定义了一个数据结构，用来存储每个原型向量的详细信息。我们的类为数据集中每个点存储以下内容：
- en: '[PRE65]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The class id to which the prototype vector belongs is the vector itself and
    the epsilon value. It also has a function update that is used to change the prototype
    values:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 原型向量所属的类别 ID 就是向量本身和 epsilon 值。它还有一个 `update` 函数，用于更改原型值：
- en: '[PRE66]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'In step 3, we define the following function, which takes any given vector as
    the input and a list of all the prototype vectors. Out of all the prototype vectors,
    this function returns the closest prototype vector to the given vector:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 3 步中，我们定义了以下函数，该函数以任意给定的向量作为输入，并接受所有原型向量的列表。在所有原型向量中，函数返回与给定向量最接近的原型向量：
- en: '[PRE67]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: As you can see, it loops through all the prototype vectors to find the closest
    one. It uses Euclidean distance to measure the similarity.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，它会遍历所有的原型向量，找出最接近的一个。它使用欧几里得距离来衡量相似度。
- en: Step 4 is a small function that can return the class ID of the closest prototype
    vector to the given vector.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 第 4 步是一个小函数，可以返回与给定向量最接近的原型向量的类别 ID。
- en: 'Now that we have finished all the required preprocessing for the LVQ algorithm,
    we can move on to the actual algorithm in step 5\. For each class, we must select
    the initial prototype vectors. We then select R random points from each class.
    The outer loop goes through each class, and for each class, we select R random
    samples and create our prototype object, as follows:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了 LVQ 算法所需的所有预处理，可以进入第 5 步的实际算法。对于每个类别，我们必须选择初始的原型向量。然后，我们从每个类别中选择 R
    个随机点。外部循环遍历每个类别，对于每个类别，我们选择 R 个随机样本并创建我们的原型对象，具体如下：
- en: '[PRE68]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: In step 6, we increment or decrement the prototype vectors iteratively. We loop
    continuously till our epsilon value falls below a threshold of 0.01.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 6 步中，我们迭代地增加或减少原型向量。我们会持续循环，直到 epsilon 值降到 0.01 以下。
- en: 'We then randomly sample a point from our dataset, as follows:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们从数据集中随机采样一个点，具体如下：
- en: '[PRE69]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: The point and its corresponding class ID have been retrieved.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 点和它对应的类别 ID 已被提取。
- en: 'We can then find the closed prototype vector to this point, as follows:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以找到最接近这个点的原型向量，具体如下：
- en: '[PRE70]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'If the current point''s class ID matches the prototype''s class ID, we call
    the `update` method, with the increment set to `True`, or else we will call the
    `update` with the increment set to `False`:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 如果当前点的类别 ID 与原型的类别 ID 匹配，我们会调用 `update` 方法，增量设置为 `True`，否则我们将调用 `update` 方法，增量设置为
    `False`：
- en: '[PRE71]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Finally, we update the epsilon value for the closest prototype vector:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们更新最接近的原型向量的 epsilon 值：
- en: '[PRE72]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'We can print the prototype vectors in order to look at them manually:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以打印出原型向量，以便手动查看：
- en: '[PRE73]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'In step 7, we put our prototype vectors into action to do some predictions:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 7 步中，我们将原型向量投入实际应用，进行预测：
- en: '[PRE74]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: We can get the predicted class ID using the `find_class_id` function. We pass
    a point and all the learned prototype vectors to it to get the class ID.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `find_class_id` 函数获得预测的类别 ID。我们将一个点和所有已学习的原型向量传递给它，以获取类别 ID。
- en: 'Finally, we give our predicted output in order to generate a classification
    report:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们给出我们的预测输出，以生成分类报告：
- en: '[PRE75]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The classification report function is a convenient function provided by the
    scikit-learn library to view the classification accuracy scores:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 分类报告函数是由 scikit-learn 库提供的一个便捷函数，用于查看分类准确度评分：
- en: '![How it works…](img/B04041_05_03.jpg)'
  id: totrans-362
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的…](img/B04041_05_03.jpg)'
- en: You can see that we have done pretty well with our classification. Keep in mind
    that we did not keep a separate test set. Never measure the accuracy of your model
    based on the training data. Always use a test set that is unseen by the training
    routines. We did it only for illustration purposes.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们在分类方面做得相当不错。请记住，我们并没有保留单独的测试集。绝不要根据训练数据来衡量模型的准确性。始终使用训练过程中未见过的测试集。我们这么做仅仅是为了说明。
- en: There's more...
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Keep in mind that this technique does not involve any optimization criteria
    as in the other classification methods. Hence, it is very difficult to judge how
    good the prototype vectors have been generated.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这种技术不像其他分类方法那样涉及任何优化准则。因此，很难判断原型向量生成的效果如何。
- en: In our recipe, we initialized the prototype vectors as random values. You can
    use the k-means algorithm to initialize the prototype vectors.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的配方中，我们将原型向量初始化为随机值。你也可以使用 K-Means 算法来初始化原型向量。
- en: See also
  id: totrans-367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: '*Clustering of data using K-Means* recipe in [Chapter 5](ch05.xhtml "Chapter 5. Data
    Mining – Needle in a Haystack"), *Data Mining - Finding a needle in a haystack*'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 K-Means 聚类数据* 配方见 [第5章](ch05.xhtml "第5章 数据挖掘——大海捞针")， *数据挖掘——大海捞针*'
- en: Finding outliers in univariate data
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查找单变量数据中的异常值
- en: Outliers are data points that are far away from the other data points in your
    data. They have to be handled carefully in data science applications. Including
    them in some of your algorithms unknowingly may lead to wrong results or conclusions.
    It is very important to account for them properly and have the right algorithms
    in order to handle them.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值是与数据集中其他数据点相距较远的数据点。在数据科学应用中，它们必须小心处理。无意中将它们包含在某些算法中可能导致错误的结果或结论。正确处理异常值并使用合适的算法来应对它们是非常重要的。
- en: '|   | *"Outlier detection is an extremely important problem with a direct application
    in a wide variety of application domains, including fraud detection (Bolton, 2002),
    identifying computer network intrusions and bottlenecks (Lane, 1999), criminal
    activities in e-commerce and detecting suspicious activities (Chiu, 2003)."* |
      |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '|   | *“异常值检测是一个极其重要的问题，直接应用于许多领域，包括欺诈检测（Bolton, 2002）、识别计算机网络入侵和瓶颈（Lane, 1999）、电子商务中的犯罪活动和检测可疑活动（Chiu,
    2003）。”* |   |'
- en: '|   | --*- Jayakumar and Thomas, A New Procedure of Clustering Based on Multivariate
    Outlier Detection (Journal of Data Science 11(2013), 69-84)* |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '|   | --*- Jayakumar 和 Thomas, 基于多变量异常值检测的聚类新程序（《数据科学期刊》11(2013), 69-84）* |'
- en: We will look at the detection of outliers in univariate data in this recipe
    and then move on to look at outliers in multivariate and text data.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将查看如何检测单变量数据中的异常值，然后转向查看多变量数据和文本数据中的异常值。
- en: Getting ready
  id: totrans-374
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'In this recipe, we will look at the following three methods for outlier detection
    in univariate data:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将查看以下三种单变量数据异常值检测方法：
- en: Median absolute deviation
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中位数绝对偏差
- en: Mean plus or minus three standard deviation
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均值加减三个标准差
- en: 'Let''s see how we can leverage these methods to spot outliers in univariate
    data. Before we jump into the next section, let''s create a dataset with outliers
    so that we can evaluate our method empirically:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何利用这些方法来发现单变量数据中的异常值。在进入下一节之前，我们先创建一个包含异常值的数据集，以便我们可以通过经验评估我们的方法：
- en: '[PRE76]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'We will create 100 data points, and 10 percent of them will be outliers:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建 100 个数据点，其中 10% 会是异常值：
- en: '[PRE77]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'We will use the `randn` function in the `random` module of NumPy to generate
    our inliers. This will be a sample from a distribution with a mean of zero and
    a standard deviation of one. Let''s verify the mean and standard deviation of
    our sample:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 NumPy 的 `random` 模块中使用 `randn` 函数生成我们的正常值数据。这将是一个均值为零，标准差为一的分布样本。让我们验证一下我们样本的均值和标准差：
- en: '[PRE78]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'We will calculate the mean and standard deviation with the functions from NumPy
    and print the output. Let''s inspect the output:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 NumPy 中的函数来计算均值和标准差，并打印输出。让我们查看输出结果：
- en: '[PRE79]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: As you can see, the mean is close to zero and the standard deviation is close
    to one.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，均值接近零，标准差接近一。
- en: 'Now, let''s create the outliers. This will be 10 percent of the whole dataset,
    that is, 10 points, given that our sample size is 100\. As you can see, we sampled
    our outliers from a uniform distribution between -9 and 9\. Any points between
    this range will have an equal chance of being selected. We will concatenate our
    inlier and outlier data. It will be good to see the data with a scatter plot before
    we run our outlier detection program:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建异常值数据。这将是整个数据集的 10%，即 10 个点，假设我们的样本大小是 100。正如你所看到的，我们从 -9 到 9 之间的均匀分布中采样了异常值。这个范围内的任何点都有相等的被选择的机会。我们将合并正常值和异常值数据。在运行异常值检测程序之前，最好通过散点图查看数据：
- en: '[PRE80]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Let''s look at the graph that is generated:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下生成的图形：
- en: '![Getting ready](img/B04041_05_16.jpg)'
  id: totrans-390
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/B04041_05_16.jpg)'
- en: Our *y* axis is the actual values that we generated and our *x* axis is a running
    count. It will be a good exercise to mark the points that you feel are outliers.
    We can later compare our program output with your manual selections.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的*y*轴是我们生成的实际值，*x*轴是一个累积计数。您可以做一个练习，标记您认为是异常值的点。稍后我们可以将程序输出与您的手动选择进行比较。
- en: How to do it…
  id: totrans-392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Let''s start with the median absolute deviation. Then we will plot our values,
    with the outliers marked in red:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从中位数绝对偏差开始。然后我们将绘制我们的值，并将异常值标记为红色：
- en: '[PRE81]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Moving on to the mean plus or minus three standard deviation, we will plot
    our values, with the outliers colored in red:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续进行均值加减三倍标准差的操作，我们将绘制我们的值，并将异常值标记为红色：
- en: '[PRE82]'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: How it works…
  id: totrans-397
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'In step 1, we use the median absolute deviation to detect the outliers in the
    data:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，我们使用中位数绝对偏差来检测数据中的异常值：
- en: '[PRE83]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: We first calculate the median value of our dataset using the median function
    from NumPy. Next, we declare a variable with a value of 1.4826\. This is a constant
    to be multiplied with the absolute deviation from the median. Finally, we calculate
    the median of absolute deviations of each entry from the median value and multiply
    it with the constant, b.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用NumPy中的中位数函数计算数据集的中位数值。接着，我们声明一个值为1.4826的变量。这个常数将与偏离中位数的绝对偏差相乘。最后，我们计算每个数据点相对于中位数值的绝对偏差的中位数，并将其乘以常数b。
- en: 'Any point that is more than or less than three times the median absolute deviation
    is deemed as an outlier for our method:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 任何偏离中位数绝对偏差三倍以上的点都被视为我们方法中的异常值：
- en: '[PRE84]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'We then calculate the lower and upper limits of the median absolute deviation,
    as shown previously, and classify every point as either an outlier or inlier,
    as follows:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们计算了中位数绝对偏差的上下限，如前所示，并将每个点分类为异常值或正常值，具体如下：
- en: '[PRE85]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Finally, we have all our outlier points stored in a list by the name of outliers.
    We must also store the index of the outliers in a separate list called outlier_index.
    This is done for the ease of plotting, as you will see in the next step.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，所有异常值都存储在名为outliers的列表中。我们还必须将异常值的索引存储在一个名为outlier_index的单独列表中。这是为了方便绘图，您将在下一步中看到这一点。
- en: 'We then plot the original points and outliers. The plot looks as follows:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们绘制原始点和异常值。绘图结果如下所示：
- en: '![How it works…](img/B04041_05_17.jpg)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的…](img/B04041_05_17.jpg)'
- en: The points marked in red are classified as outliers by the algorithm.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 被红色标记的点被算法判定为异常值。
- en: 'In step 3, we code up the second algorithm, mean plus or minus three standard
    deviation:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三步中，我们编写第二个算法，即均值加减三倍标准差：
- en: '[PRE86]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'We then calculate the standard deviation and mean of our dataset. Here, you
    can see that we have set our `b = 3`. As the name of our algorithm suggests, we
    will need a standard deviation of three, and this b is used for the same:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着计算数据集的标准差和均值。在这里，您可以看到我们设置了`b = 3`。正如我们算法的名字所示，我们需要一个标准差为三，而这个b也正是用来实现这个目标的：
- en: '[PRE87]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: We can calculate the lower and upper limits as the mean minus three times the
    standard deviation. Using these values, we can then classify every point as either
    an outlier or inlier in the for loop. We then add all the outliers and their indices
    to the two lists, outliers and outlier_index, to plot.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计算出上下限，方法是将均值减去三倍标准差。使用这些值，我们可以在for循环中将每个点分类为异常值或正常值。然后我们将所有异常值及其索引添加到两个列表中，outliers
    和 outlier_index，以便绘图。
- en: 'Finally, we plot the outliers:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们绘制了异常值：
- en: '![How it works…](img/B04041_05_18.jpg)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的…](img/B04041_05_18.jpg)'
- en: There's more…
  id: totrans-416
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: As per the definition of outliers, outliers in a given dataset are those points
    that are far away from the other points in the data source. The estimates of the
    center of the dataset and the spread of the dataset can be used to detect the
    outliers. In the methods that we outlined in this recipe, we used the mean and
    median as the estimates for the center of the data and standard deviation, and
    the median absolute deviation as the estimates for the spread. Spread is also
    called scale.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 根据异常值的定义，给定数据集中的异常值是那些与其他数据点距离较远的点。数据集中心的估算值和数据集分布的估算值可以用来检测异常值。在我们在本食谱中概述的方法中，我们使用均值和中位数作为数据中心的估算值，使用标准差和中位数绝对偏差作为分布的估算值。分布也被称为尺度。
- en: Let's do a little bit of rationalization about why our methods work in the detection
    of the outliers. Let's start with the method of using standard deviation. For
    Gaussian data, we know that 68.27 percent of the data lies with in one standard
    deviation, 95.45 percent in two, and 99.73 percent lies in three. Thus, according
    to our rule that any point that is more than three standard deviations from the
    mean is classified as an outlier. However, this method is not robust. Let's look
    at a small example.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微理清一下我们的检测异常值方法为何有效。首先从使用标准差的方法开始。对于高斯数据，我们知道 68.27% 的数据位于一个标准差内，95.45%
    位于两个标准差内，99.73% 位于三个标准差内。因此，根据我们的规则，任何与均值的距离超过三个标准差的点都被归类为异常值。然而，这种方法并不稳健。我们来看一个小例子。
- en: Let's sample eight data points from a normal distribution, with the mean as
    zero and the standard deviation as one.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从正态分布中抽取八个数据点，均值为零，标准差为一。
- en: 'Let''s use the convenient function from `NumPy .random` to generate our numbers:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 `NumPy.random` 中的便捷函数来生成我们的数据：
- en: '[PRE88]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'This gives us the following numbers:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下数值：
- en: '[PRE89]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Let's add two outliers to it manually, for example, 45 and 69, to this list.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们手动添加两个异常值，例如 45 和 69，加入到这个列表中。
- en: 'Our dataset now looks as follows:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集现在看起来如下：
- en: '[PRE90]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: The mean of the preceding dataset is 11.211 and the standard deviation is `23.523`.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 前面数据集的均值是 11.211，标准差是 `23.523`。
- en: Let's look at the upper rule, mean + 3 * std. This is 11.211 + 3 * 23.523 =
    81.78.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下上限规则，均值 + 3 * 标准差。这是 11.211 + 3 * 23.523 = 81.78。
- en: Now, according to this upper bound rule, both the points, 45 and 69, are not
    outliers! Both the mean and the standard deviation are non-robust estimators of
    the center and scale of the dataset, as they are extremely sensitive to outliers.
    If we replace one of the points with an extreme point in a dataset with n observations,
    it will completely change the estimate of the mean and the standard deviation.
    This property of the estimators is called the finite sample breakdown point.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，根据这个上限规则，45 和 69 两个点都不是异常值！均值和标准差是数据集中心和尺度的非稳健估计量，因为它们对异常值非常敏感。如果我们用一个极端值替换数据集中任意一个点（样本量为
    n），这将完全改变均值和标准差的估计值。估计量的这一特性被称为有限样本断点。
- en: Note
  id: totrans-430
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The finite sample breakdown point is defined as the proportion of the observations
    in a sample that can be replaced before the estimator fails to describe the data
    accurately.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 有限样本断点被定义为，在样本中，能被替换的观察值比例，替换后估计器仍然能准确描述数据。
- en: Thus, for the mean and standard deviation, the finite sample breakdown point
    is 0 percent because in a large sample, replacing even a single point would change
    the estimators drastically.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于均值和标准差，有限样本断点是 0%，因为在大样本中，替换哪怕一个点也会显著改变估计值。
- en: In contrast, the median is a more robust estimate. The median is the middle
    observation in a finite set of observations that is sorted in an ascending order.
    For the median to change drastically, we have to replace half of the observations
    in the data that are far away from the median. This gives you a 50 percent finite
    sample breakdown point for the median.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，中位数是一个更稳健的估计值。中位数是有限观察集合中按升序排序后的中间值。为了使中位数发生显著变化，我们必须替换掉数据中远离中位数的一半观察值。这就给出了中位数的
    50% 有限样本断点。
- en: 'The median absolute deviation method is attributed to the following paper:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 中位绝对偏差法归因于以下论文：
- en: '*Leys, C., et al., Detecting outliers: Do not use standard deviation around
    the mean, use absolute deviation around the median, Journal of Experimental Social
    Psychology (2013)*, [http://dx.doi.org/10.1016/j.jesp.2013.03.013](http://dx.doi.org/10.1016/j.jesp.2013.03.013).'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '*Leys, C., 等，检测异常值：不要使用均值周围的标准差，使用中位数周围的绝对偏差，《实验社会心理学杂志》（2013）*, [http://dx.doi.org/10.1016/j.jesp.2013.03.013](http://dx.doi.org/10.1016/j.jesp.2013.03.013)。'
- en: See also
  id: totrans-436
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: '*Performing summary statistics and plots* recipe in [Chapter 1](ch01.xhtml
    "Chapter 1. Python for Data Science"), *Using Python for Data Science*'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第一章](ch01.xhtml "第一章. 数据科学中的 Python")中的 *执行汇总统计和绘图* 配方，*使用 Python 进行数据科学*'
