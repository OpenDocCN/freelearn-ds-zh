- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Overview of the Certification Guide and Exam
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 认证指南和考试的概述
- en: Preparing for any task initially involves comprehending the problem at hand
    thoroughly and, subsequently, devising a strategy to tackle the challenge. Creating
    a step-by-step methodology for addressing each aspect of the challenge is an effective
    approach within this planning phase. This method enables smaller tasks to be handled
    individually, aiding in a systematic progression through the challenges without
    the need to feel overwhelmed.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 准备任何任务最初涉及彻底理解手头的问题，然后制定一个应对挑战的策略。在这个规划阶段，为应对挑战的每个方面创建一个逐步的方法是有效的方法。这种方法使得可以单独处理较小的任务，有助于系统地通过挑战，而无需感到不知所措。
- en: 'This chapter intends to demonstrate this step-by-step approach to working through
    your Spark certification exam. In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在展示通过 Spark 认证考试逐步方法。在本章中，我们将涵盖以下主题：
- en: Overview of the certification exam
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 认证考试的概述
- en: Different types of questions to expect in the exam
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考试中可能遇到的不同类型的问题
- en: Overview of the rest of the chapters in this book
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书其余章节的概述
- en: We’ll start by providing an overview of the certification exam.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先概述一下认证考试。
- en: Overview of the certification exam
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 认证考试的概述
- en: The exam consists of **60 questions**. The time you’re given to attempt these
    questions is **120 minutes**. This gives you about **2 minutes** **per question**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 考试由 **60 个问题** 组成。你被给予的时间来尝试这些问题是 **120 分钟**。这给你大约 **每题 2 分钟**。
- en: To pass the exam, you need to have a **score of 70%**, which means that you
    need to **answer 42 questions correctly** out of 60 for you to pass.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过考试，你需要得到 **70% 的分数**，这意味着你需要在 60 个问题中正确回答 42 个才能通过。
- en: If you are well prepared, this time should be enough for you to answer the questions
    and also review them before the time finishes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你准备充分，这段时间应该足够你回答问题，并在时间结束前进行复习。
- en: Next, we will see how the questions are distributed throughout the exam.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看到这些问题如何在整个考试中分布。
- en: Distribution of questions
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题的分布
- en: 'Exam questions are distributed into the following broad categories. The following
    table provides a breakdown of questions based on different categories:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 考试问题被分为以下几个广泛的类别。以下表格根据不同类别提供了问题的细分：
- en: '| **Topic** | **Percentage** **of Exam** | **Number** **of Questions** |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| **主题** | **考试百分比** | **问题数量** |'
- en: '| Spark Architecture: Understanding of Concepts | 17% | 10 |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| Spark 架构：概念理解 | 17% | 10 |'
- en: '| Spark Architecture: Understanding of Applications | 11% | 7 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| Spark 架构：应用理解 | 11% | 7 |'
- en: '| Spark DataFrame API Applications | 72% | 43 |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| Spark DataFrame API 应用 | 72% | 43 |'
- en: 'Table 1.1: Exam breakdown'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.1：考试细分
- en: Looking at this distribution, you would want to focus on the Spark DataFrame
    API a lot more in your exam preparation since this section covers around 72% of
    the exam (about 43 questions). If you can answer these questions correctly, passing
    the exam will become easier.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察这个分布，你可能会想要在考试准备中更加关注 Spark DataFrame API，因为这个部分涵盖了大约 72% 的考试（大约 43 个问题）。如果你能正确回答这些问题，通过考试就会变得更容易。
- en: But this doesn’t mean that you shouldn’t focus on the Spark architecture areas.
    Spark architecture questions have varied difficulty, and they can sometimes be
    confusing. At the same time, they allow you to score easy points as architecture
    questions are generally straightforward.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不意味着你不应该关注 Spark 架构领域。Spark 架构问题难度各异，有时可能会令人困惑。同时，它们允许你轻松得分，因为架构问题通常很简单。
- en: Let’s look at some of the other resources available that can help you prepare
    for this exam.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些其他可用的资源，这些资源可以帮助你为这次考试做准备。
- en: Resources to prepare for the exam
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备考试的资源
- en: When you start planning to take the certification exam, the first thing you
    must do is master Spark concepts. This book will help you with these concepts.
    Once you’ve done this, it would be useful to do mock exams. There are two mock
    exams available in this book for you to take advantage of.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始计划参加认证考试时，你必须做的第一件事是掌握 Spark 概念。这本书将帮助你理解这些概念。一旦你完成了这些，进行模拟考试将很有用。这本书中提供了两个模拟考试供你利用。
- en: 'In addition, Databricks provides a practice exam, which is very useful for
    exam preparation. You can find it here: [https://files.training.databricks.com/assessments/practice-exams/PracticeExam-DCADAS3-Python.pdf](https://files.training.databricks.com/assessments/practice-exams/PracticeExam-DCADAS3-Python.pdf).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Databricks 提供了模拟考试，这对考试准备非常有用。您可以在以下位置找到它：[https://files.training.databricks.com/assessments/practice-exams/PracticeExam-DCADAS3-Python.pdf](https://files.training.databricks.com/assessments/practice-exams/PracticeExam-DCADAS3-Python.pdf).
- en: Resources available during the exam
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 考试期间可用的资源
- en: During the exam, you will be given access to the Spark documentation. This is
    done via **Webassessor** and its interface is a little different than the regular
    Spark documentation you’ll find on the internet. It would be good for you to familiarize
    yourself with this interface. You can find the interface at [https://www.webassessor.com/zz/DATABRICKS/Python_v2.html](https://www.webassessor.com/zz/DATABRICKS/Python_v2.html).
    I recommend going through it and trying to find different packages and functions
    of Spark via this documentation to make yourself comfortable navigating it during
    the exam.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在考试期间，您将能够访问 Spark 文档。这是通过 **Webassessor** 实现的，其界面与您在互联网上找到的常规 Spark 文档略有不同。熟悉这个界面会很好。您可以在
    [https://www.webassessor.com/zz/DATABRICKS/Python_v2.html](https://www.webassessor.com/zz/DATABRICKS/Python_v2.html)
    找到该界面。我建议您浏览它，并尝试通过此文档找到 Spark 的不同包和函数，以便在考试期间更舒适地导航。
- en: Next, we will look at how we can register for the exam.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看如何注册考试。
- en: Registering for your exam
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注册您的考试
- en: 'Databricks is the company that has prepared these exams and certifications.
    Here is the link to register for the exam: [https://www.databricks.com/learn/certification/apache-spark-developer-associate](https://www.databricks.com/learn/certification/apache-spark-developer-associate).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 是准备这些考试和认证的公司。您可以在此处注册考试：[https://www.databricks.com/learn/certification/apache-spark-developer-associate](https://www.databricks.com/learn/certification/apache-spark-developer-associate).
- en: Next, we will look at some of the prerequisites for the exam.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看考试的一些先决条件。
- en: Prerequisites for the exam
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 考试先决条件
- en: 'Some prerequisites are needed before you can take the exam so that you can
    be successful in passing the certification. Some of the major ones are as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在您参加考试之前，需要一些先决条件，以便您能够成功通过认证。以下是一些主要的先决条件：
- en: Grasp the fundamentals of Spark architecture, encompassing the principles of
    Adaptive Query Execution.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 掌握 Spark 架构的基本原理，包括自适应查询执行的原则。
- en: 'Utilize the Spark DataFrame API proficiently for various data manipulation
    tasks, such as the following:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熟练使用 Spark DataFrame API 进行各种数据操作任务，如下所示：
- en: Performing column operations, such as selection, renaming, and manipulation
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行列操作，例如选择、重命名和操作
- en: Executing row operations, including filtering, dropping, sorting, and aggregating
    data
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行行操作，包括过滤、删除、排序和聚合数据
- en: Conducting DataFrame-related tasks, such as joining, reading, writing, and implementing
    partitioning strategies
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行与 DataFrame 相关的任务，例如连接、读取、写入和实现分区策略
- en: Demonstrating proficiency in working with **user-defined functions** (**UDFs**)
    and Spark SQL functions
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展示使用 **用户定义函数**（**UDFs**）和 Spark SQL 函数的熟练程度
- en: While not explicitly tested, a functional understanding of either Python or
    Scala is expected. The examination is available in both programming languages.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然没有明确测试，但预期您对 Python 或 Scala 有功能性的理解。考试可用两种编程语言进行。
- en: Hopefully, by the end of this book, you will be able to fully grasp all these
    concepts and have done enough practice on your own to be prepared for the exam
    with full confidence.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 希望到这本书的结尾，您能够完全掌握所有这些概念，并且已经足够练习，以便对考试充满信心。
- en: Now, let’s discuss what to expect during the online proctored exam.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论一下在线监考考试期间可以期待什么。
- en: Online proctored exam
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线监考考试
- en: The Spark certification exam is an online proctored exam. What this means is
    that you will be taking the exam from the comfort of your home, but someone will
    be proctoring the exam online. I encourage you to understand the procedures and
    rules of the proctored exam in advance. This will save you a lot of trouble and
    anxiety at the time of the exam.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 认证考试是一个在线监考考试。这意味着您将在家中参加考试，但有人将在网上监考。我鼓励您提前了解监考考试的程序和规则。这将为您在考试时节省很多麻烦和焦虑。
- en: 'To give you an overview, throughout the exam session, the following procedures
    will be in place:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了给你一个概述，在整个考试过程中，以下程序将生效：
- en: Webcam monitoring will be conducted by a Webassessor proctor to ensure exam
    integrity
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Webassessor监考员将进行网络摄像头监控，以确保考试诚信。
- en: You will need to present a valid form of identification with a photo
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要出示带有照片的有效身份证明。
- en: You will need to conduct the exam alone
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要独自进行考试。
- en: Your desk needs to be decluttered and there should be no other electronic devices
    in the room except the laptop that you’ll need for the exam
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的桌子需要整理干净，并且除了你用于考试的笔记本电脑外，房间里不应有其他电子设备。
- en: There should not be any posters or charts on the walls of the room that may
    aid you in the exam
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 房间的墙上不应有任何可能帮助你考试的海报或图表。
- en: The proctor will be listening to you during the exam as well, so you’ll want
    to make sure that you’re sitting in a quiet and comfortable environment
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监考员在考试期间也会监听你，所以你想要确保你坐在一个安静舒适的环境中。
- en: It is recommended to **not** use your work laptop for this exam as it requires
    software to be installed and your antivirus and firewall to be disabled
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建议不要使用你的工作笔记本电脑参加这次考试，因为它需要安装软件，并且需要禁用你的防病毒软件和防火墙。
- en: 'The proctor’s responsibilities are as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 监考员的职责如下：
- en: Overseeing your exam session to maintain exam integrity
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督你的考试过程以保持考试诚信。
- en: Addressing any queries related to the exam delivery process
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决与考试交付过程相关的任何疑问。
- en: Offering technical assistance if needed
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如有必要，提供技术支持。
- en: It’s important to note that the proctor will not offer any form of assistance
    regarding the exam content
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要注意的是，监考员不会就考试内容提供任何形式的帮助。
- en: I recommend that you take sufficient time before the exam to set up the environment
    where you’ll be taking the exam. This will ensure a smooth online exam procedure
    where you can focus on the questions and not worry about anything else.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议你在考试前有足够的时间设置你将进行考试的环境。这将确保一个顺畅的在线考试流程，让你可以专注于问题，不必担心其他任何事情。
- en: Now, let’s talk about the different types of questions that may appear in the
    exam.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们谈谈考试中可能出现的不同类型的题目。
- en: Types of questions
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 题目类型。
- en: There are different categories of questions that you will find in the exam.
    They can be broadly divided into theoretical and code questions. We will look
    at both categories and their respective subcategories in this section.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 考试中你会遇到不同类别的题目。它们可以大致分为理论题和代码题。在本节中，我们将探讨这两个类别及其各自的子类别。
- en: Theoretical questions
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论题。
- en: Theoretical questions are the questions where you will be asked about the conceptual
    understanding of certain topics. Theoretical questions can be subdivided further
    into different categories. Let’s look at some of these categories, along with
    example questions taken from previous exams that fall into them.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 理论题是那些会要求你对某些主题的概念性理解的问题。理论题可以进一步细分为不同的类别。让我们看看这些类别，以及从之前的考试中选取的属于这些类别的示例问题。
- en: Explanation questions
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解释题。
- en: Explanation questions are ones where you need to define and explain something.
    It can also include how something works and what it does. Let’s look at an example.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 解释题是需要定义和解释某事的问题。它也可以包括某物是如何工作的以及它做什么。让我们看看一个例子。
- en: Which of the following describes a worker node?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下哪项描述了一个工作节点？
- en: Worker nodes are the nodes of a cluster that perform computations.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工作节点是集群中执行计算的节点。
- en: Worker nodes are synonymous with executors.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工作节点与执行器是同义词。
- en: Worker nodes always have a one-to-one relationship with executors.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工作节点总是与执行器保持一对一的关系。
- en: Worker nodes are the most granular level of execution in the Spark execution
    hierarchy.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工作节点是Spark执行层次结构中最细粒度的执行级别。
- en: Worker nodes are the coarsest level of execution in the Spark execution hierarchy.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工作节点是Spark执行层次结构中最粗粒度的执行级别。
- en: Connection questions
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连接题。
- en: Connections questions are such questions where you need to define how different
    things are related to each other or how they differ from each other. Let’s look
    at an example to demonstrate this.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 连接题是需要定义不同事物之间是如何相互关联的，或者它们是如何相互区别的问题。让我们通过一个例子来展示这一点。
- en: Which of the following describes the relationship between worker nodes and executors?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下哪项描述了工作节点与执行器之间的关系？
- en: An executor is a **Java Virtual Machine** (**JVM**) running on a worker node.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行器是在工作节点上运行的Java虚拟机（JVM）。
- en: A worker node is a JVM running on an executor.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工作节点是在执行器上运行的 JVM。
- en: There are always more worker nodes than executors.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总是存在比执行器更多的工作节点。
- en: There are always the same number of executors and worker nodes.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总是存在相同数量的执行器和工作节点。
- en: Executors and worker nodes are not related.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行器和工作节点之间没有关系。
- en: Scenario question
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景问题
- en: Scenario questions involve defining how things work in different if-else scenarios
    – for example, “If ______ occurs, then _____ happens.” Moreover, it also includes
    questions where a statement is incorrect about a scenario. Let’s look at an example
    to demonstrate this.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 场景问题涉及定义在不同 if-else 场景中事物是如何工作的——例如，“如果 ______ 发生，那么 _____ 就会发生。”此外，它还包括关于场景的陈述不正确的问题。让我们通过一个例子来展示这一点。
- en: If Spark is running in cluster mode, which of the following statements about
    nodes is incorrect?
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Spark 以集群模式运行，以下关于节点的说法中哪一个是错误的？
- en: There is a single worker node that contains the Spark driver and the executors.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有一个包含 Spark 驱动程序和执行器的工作节点。
- en: The Spark driver runs in its own non-worker node without any executors.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spark 驱动程序在其自己的非工作节点上运行，没有任何执行器。
- en: Each executor is a running JVM inside a worker node.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个执行器都是工作节点内部运行的 JVM。
- en: There is always more than one node.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总是存在多个节点。
- en: There might be more executors than total nodes or more total nodes than executors.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可能会有比总节点更多的执行器，或者比执行器更多的总节点。
- en: Categorization questions
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类问题
- en: Categorization questions are such questions where you need to describe categories
    that something belongs to. Let’s look at an example to demonstrate this.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 分类问题是这样的问题，你需要描述某个事物所属的类别。让我们通过一个例子来展示这一点。
- en: Which of the following statements accurately describes stages?
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 以下哪个说法准确地描述了阶段？
- en: Tasks within a stage can be simultaneously executed by multiple machines.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阶段内的任务可以由多台机器同时执行。
- en: Various stages within a job can run concurrently.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作业中的各个阶段可以并发运行。
- en: Stages comprise one or more jobs.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阶段包括一个或多个作业。
- en: Stages temporarily store transactions before committing them through actions.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阶段在提交之前暂时存储事务。
- en: Configuration questions
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置问题
- en: Configuration questions are such questions where you need to outline how things
    will behave based on different cluster configurations. Let’s look at an example
    to demonstrate this.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 配置问题是这样的问题，你需要根据不同的集群配置概述事物的行为。让我们通过一个例子来展示这一点。
- en: Which of the following statements accurately describes Spark’s cluster execution
    mode?
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以下哪个说法准确地描述了 Spark 的集群执行模式？
- en: Cluster mode runs executor processes on gateway nodes.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群模式在网关节点上运行执行器进程。
- en: Cluster mode involves the driver being hosted on a gateway machine.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群模式涉及驱动程序托管在网关机器上。
- en: In cluster mode, the Spark driver and the cluster manager are not co-located.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在集群模式下，Spark 驱动程序和集群管理器不在同一位置。
- en: The driver in cluster mode is located on a worker node.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群模式下的驱动程序位于工作节点上。
- en: Next, we’ll look at the code-based questions and their subcategories.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨基于代码的问题及其子类别。
- en: Code-based questions
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于代码的问题
- en: The next category is code-based questions. A large number of Spark API-based
    questions lie in this category. Code-based questions are the questions where you
    will be given a code snippet, and you will be asked questions about it. Code-based
    questions can be subdivided further into different categories. Let’s look at some
    of these categories, along with example questions taken from previous exams that
    fall into these different subcategories.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个类别是基于代码的问题。大量基于 Spark API 的问题属于这个类别。基于代码的问题是你会得到一个代码片段，然后你会被问及关于它的问题。基于代码的问题可以进一步细分为不同的类别。让我们看看这些类别，以及从之前的考试中选取的属于这些不同子类别的示例问题。
- en: Function identification questions
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 函数识别问题
- en: Function identification questions are such questions where you need to define
    which function does something. It is important to know the different functions
    that are available in Spark for data manipulation, along with their syntax. Let’s
    look at an example to demonstrate this.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 函数识别问题是这样的问题，你需要定义某个事物是由哪个函数执行的。了解 Spark 中用于数据操作的不同函数及其语法非常重要。让我们通过一个例子来展示这一点。
- en: Which of the following code blocks returns a copy of the `df` DataFrame, where
    the `column` salary has been renamed `employeeSalary`?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下哪个代码块返回了 `df` DataFrame 的副本，其中 `column` 的 `salary` 已重命名为 `employeeSalary`？
- en: '`df.withColumn(["salary", "employeeSalary"])`'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`df.withColumn(["salary", "employeeSalary"])`'
- en: '`df.withColumnRenamed("salary").alias("employeeSalary ")`'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`df.withColumnRenamed("salary").alias("employeeSalary ")`'
- en: '`df.withColumnRenamed("salary", "` `employeeSalary ")`'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`df.withColumnRenamed("salary", "` `employeeSalary ")`'
- en: '`df.withColumn("salary", "` `employeeSalary ")`'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`df.withColumn("salary", "` `employeeSalary ")`'
- en: Fill-in-the-blank questions
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 填空题
- en: Fill-in-the-blank questions are such questions where you need to complete the
    code block by filling in the blanks. Let’s look at an example to demonstrate this.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 填空题是这样的问题，您需要通过填写空白来完成代码块。让我们通过一个示例来演示这一点。
- en: The following code block should return a DataFrame with the `employeeId`, `salary`,
    `bonus`, and `department` columns from the `transactionsDf` DataFrame. Choose
    the answer that correctly fills the blanks to accomplish this.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块应返回一个DataFrame，其中包含`transactionsDf` DataFrame中的`employeeId`、`salary`、`bonus`和`department`列。请选择正确填充空白的答案来完成此操作。
- en: '[PRE0]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`drop`'
  id: totrans-116
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`drop`'
- en: '`"employeeId", "salary", "``bonus", "department"`'
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`"employeeId", "salary", "``bonus", "department"`'
- en: '`filter`'
  id: totrans-118
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`filter`'
- en: '`"employeeId, salary,` `bonus, department"`'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`"employeeId, salary,` `bonus, department"`'
- en: '`select`'
  id: totrans-120
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`select`'
- en: '`["employeeId", "salary", "``bonus", "department"]`'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`["employeeId", "salary", "``bonus", "department"]`'
- en: '`select`'
  id: totrans-122
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`select`'
- en: '`col(["employeeId", "salary", "``bonus", "department"])`'
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`col(["employeeId", "salary", "``bonus", "department"])`'
- en: Order-lines-of-code questions
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码行顺序问题
- en: Order-lines-of-code questions are such questions where you need to place the
    lines of code in a certain order so that you can execute an operation correctly.
    Let’s look at an example to demonstrate this.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 代码行顺序问题是这样的问题，您需要将代码行按特定顺序排列，以便正确执行操作。让我们通过一个示例来演示这一点。
- en: Which of the following code blocks creates a DataFrame that shows the mean of
    the `salary` column of the `salaryDf` DataFrame based on the `department` and
    `state` columns, where `age` is greater than 35?
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 以下哪个代码块创建了一个DataFrame，该DataFrame显示了基于`department`和`state`列的`salary`列的平均值，其中`age`大于35？
- en: '`salaryDf.filter(col("age") >` `35)`'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`salaryDf.filter(col("age") >` `35)`'
- en: '`.``filter(col("employeeID")`'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`.``filter(col("employeeID")`'
- en: '`.``filter(col("employeeID").isNotNull())`'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`.``filter(col("employeeID").isNotNull())`'
- en: '`.``groupBy("department")`'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`.``groupBy("department")`'
- en: '`.``groupBy("department", "state")`'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`.``groupBy("department", "state")`'
- en: '`.``agg(avg("salary").alias("mean_salary"))`'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`.``agg(avg("salary").alias("mean_salary"))`'
- en: '`.``agg(average("salary").alias("mean_salary"))`'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`.``agg(average("salary").alias("mean_salary"))`'
- en: i, ii, v, vi
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: i, ii, v, vi
- en: i, iii, v, vi
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: i, iii, v, vi
- en: i, iii, vi, vii
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: i, iii, vi, vii
- en: i, ii, iv, vi
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: i, ii, iv, vi
- en: Summary
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter provided an overview of the certification exam. At this point,
    you know what to expect in the exam and how to best prepare for it. To do so,
    we covered different types of questions that you will encounter.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了认证考试的概述。到目前为止，您已经知道考试中可以期待什么，以及如何最好地准备它。为此，我们介绍了您将遇到的不同类型的问题。
- en: Going forward, each chapter of this book will equip you with practical knowledge
    and hands-on examples so that you can harness the power of Apache Spark for various
    data processing and analytics tasks.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 今后，本书的每一章都将为您提供实用的知识和动手实践示例，以便您能够利用Apache Spark进行各种数据处理和分析任务。
- en: 'Part 2: Introducing Spark'
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分：介绍Spark
- en: This part will offer you a comprehensive understanding of Spark’s capabilities
    and operational principles. It will cover what Spark is, why it’s important, and
    some of the applications Spark is most useful in. It will tell you about the different
    types of users who can benefit from Spark. It will also cover the basics of Spark
    architecture and how applications are navigated through in Spark. It will detail
    narrow and wide Spark transformations and discuss lazy evaluations in Spark. It’s
    important to have this understanding because Spark works differently than other
    traditional frameworks.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分将为您提供对Spark功能和操作原理的全面了解。它将涵盖Spark是什么，为什么它很重要，以及Spark最有用的应用领域。它将介绍可以从Spark中受益的不同类型的用户。它还将涵盖Spark的基本架构以及如何在Spark中导航应用程序。它将详细说明窄和宽Spark转换，并讨论Spark中的懒加载评估。这种理解很重要，因为Spark的工作方式与其他传统框架不同。
- en: 'This part has the following chapters:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 2*](B19176_02.xhtml#_idTextAnchor030)*, Understanding Apache Spark
    and Its Applications*'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第二章*](B19176_02.xhtml#_idTextAnchor030)*，理解Apache Spark及其应用*'
- en: '[*Chapter 3*](B19176_03.xhtml#_idTextAnchor053)*, Spark Architecture and Transformations*'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第三章*](B19176_03.xhtml#_idTextAnchor053)*，Spark架构和转换*'
