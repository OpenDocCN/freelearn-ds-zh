- en: '*Chapter 6*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第六章*'
- en: Exploratory Data Analysis
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，您将能够：
- en: Implement the concept of reproducibility with Jupyter notebooks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Jupyter笔记本实现可重复性概念
- en: Perform data gathering in a reproducible way
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以可重复的方式进行数据收集
- en: Implement suitable code practices and standards to keep analysis reproducible
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施适当的代码实践和标准，以保持分析的可重复性
- en: Avoid the duplication of work by using IPython scripts
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用IPython脚本避免工作重复
- en: In this chapter, we will learn what problem definition is and how to use the
    KPI analysis techniques to enable coherent and well rounded analysis from the
    data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将学习什么是问题定义，以及如何使用KPI分析技术来实现数据的连贯和全面分析。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: One of the most important stages, and the initial step of a data science project,
    is understanding and defining a business problem. However, this cannot be a mere
    reiteration of the existing problem as a statement or a written report. To investigate
    a business problem in detail and define its purview, we can either use the existing
    business metrics to explain the patterns related to it or quantify and analyze
    the historical data and generate new metrics. Such identified metrics are the
    **Key Performance Indicators** (**KPIs**) that measure the problem at hand and
    convey to business stakeholders the impact of a problem.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学项目中最重要的阶段之一，也是最初的一步，是理解和定义商业问题。然而，这不能仅仅是对现有问题的简单重复陈述或书面报告。为了详细调查商业问题并定义其范围，我们可以使用现有的商业指标来解释与之相关的模式，或者量化并分析历史数据并生成新指标。这些识别出的指标就是**关键绩效指标**（**KPIs**），用于衡量当前的问题，并向业务利益相关者传达问题的影响。
- en: This chapter is all about understanding and defining a business problem, identifying
    key metrics related to it, and using these identified and generated KPIs through
    pandas and similar libraries for descriptive analytics. The chapter also covers
    how to plan a data science project through a structured approach and methodology,
    concluding with how to represent a problem using graphical and visualization techniques.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点是理解和定义商业问题，识别与之相关的关键指标，并通过pandas及类似库使用这些已识别和生成的KPI进行描述性分析。本章还涵盖了如何通过结构化的方法和方法论规划数据科学项目，并最终展示如何使用图形和可视化技术呈现问题。
- en: Defining a Business Problem
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义商业问题
- en: A business problem in data science is a *long-term* or *short-term* challenge
    faced by a business entity that can prevent business goals being achieved and
    act as a constraint for growth and sustainability that can otherwise be prevented
    through an efficient data-driven decision system. Some typical data science business
    problems are predicting the demand for consumer products in the coming week, optimizing
    logistic operations for **third-party logistics** (**3PL**), and identifying fraudulent
    transactions in insurance claims.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学中的商业问题是企业在*长期*或*短期*内面临的挑战，这些问题可能会阻碍商业目标的实现，成为增长和可持续性的制约因素，而这些问题本可以通过高效的数据驱动决策系统来避免。一些典型的数据科学商业问题包括预测下周消费品需求、优化**第三方物流**（**3PL**）的物流操作、以及识别保险索赔中的欺诈交易。
- en: Data science and machine learning are not magical technologies that can solve
    these business problems by just ingesting data into pre-built algorithms. They
    are complex in terms of the approach and design needed to create end-to-end analytics
    projects.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学和机器学习并不是可以通过将数据输入到预构建算法中来解决这些商业问题的神奇技术。它们在方法和设计方面复杂，需要创建端到端的分析项目。
- en: When a business needs such solutions, you may end up in a situation that forms
    a requirement gap if a clear understanding of the final objective is not set in
    place. A strong foundation to this starts with defining the business problem quantitatively
    and then carrying out scoping and solutions in line with the requirements.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当企业需要此类解决方案时，如果没有明确理解最终目标，可能会陷入形成需求差距的境地。构建这一强大基础的第一步是定量定义商业问题，然后根据需求进行范围界定和解决方案实施。
- en: 'The following are a few examples of common data science use cases that will
    provide an intuitive idea about common business problems faced by the industry
    today that are solved through data science and analytics:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些常见数据科学应用场景的例子，它们能直观地展示当前行业面临的典型商业问题，这些问题通过数据科学和分析得以解决：
- en: Inaccurate demand/revenue/sales forecasts
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不准确的需求/收入/销售预测
- en: Poor customer conversion, churn, and retention
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低效的客户转化、流失和保持
- en: Fraud and pricing in the lending industry and insurance
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 借贷行业和保险中的欺诈和定价
- en: Ineffective customer and vendor/distributor scoring
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无效的客户和供应商/分销商评分
- en: Ineffective recommendation systems for cross-sell/up-sell
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无效的交叉销售/追加销售推荐系统
- en: Unpredictable machine failures and maintenance
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可预测的机器故障和维护
- en: Customer sentiment/emotion analysis through text data
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过文本数据进行客户情感/情绪分析
- en: Non-automation of repetitive tasks that require unstructured data analytics
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未自动化的重复任务，这些任务需要非结构化数据分析
- en: As we all know, in the last few years, industries have been changing tremendously,
    driven by the technology and innovation landscape. With the pace of evolving technology,
    successful businesses adapt to it, which leads to highly evolving and complex
    business challenges and problems. Understanding new business problems in such
    a dynamic environment is not a straightforward process. Though, case-by-case,
    business problems may change, as well as the approaches to them. However, the
    approach can be generalized to a large extent.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所知，近年来，行业在技术和创新的推动下发生了巨大的变化。随着技术不断发展，成功的企业能够适应这些变化，从而产生高度发展和复杂的商业挑战和问题。在如此动态的环境中理解新的业务问题并不是一个简单的过程。尽管每个案例的业务问题和应对方法可能会变化，但这种方法在很大程度上是可以概括的。
- en: 'The following pointers are a broad step-by-step approach for defining and concluding
    a business problem, and in the following section, a detailed description of each
    step is provided:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下要点是定义和解决业务问题的广泛步骤，接下来的部分将详细描述每个步骤：
- en: Problem identification
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题识别
- en: Requirement gathering
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需求收集
- en: Data pipeline and workflow
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据管道和工作流
- en: Identifying measurable metrics
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定可衡量的指标
- en: Documentation and presentation
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文档和展示
- en: Note
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The target variable, or the study variable, which is used as the attribute/variable/column
    in the dataset for studying the business problem, is also known as the **dependent
    variable** (**DV**), and all other attributes that are considered for the analysis
    are called **independent variables** (**IVs**).
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标变量，或研究变量，在数据集中用作分析业务问题的属性/变量/列，也被称为**因变量**（**DV**），所有其他被考虑用于分析的属性被称为**自变量**（**IVs**）。
- en: Problem Identification
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 问题识别
- en: Let's start with an example where an **Asset Management Company** (**AMC**)
    that has a strong hold on customer acquisition in their mutual funds domain, that
    is, targeting the right customers and onboarding them, is looking for higher customer
    retention to improve the average customer revenue and wallet share of their premium
    customers through data science-based solutions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个例子开始：一家在其共同基金领域拥有强大客户获取能力的**资产管理公司**（**AMC**），即能够针对正确的客户并将其引入，正在寻求通过基于数据科学的解决方案提高客户保持率，以改善其高端客户的平均客户收入和钱包份额。
- en: Here, the business problem is how to increase the revenue from the existing
    customers and increase their wallet share.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，业务问题是如何从现有客户那里增加收入并提高他们的钱包份额。
- en: The problem statement is "*How do we improve the average customer revenue and
    increase the wallet share of premium customers through customer retention analytics?*"
    Summarizing the problem as stated will be the first step to defining a business
    problem.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 问题陈述是“*我们如何通过客户保持分析提高平均客户收入并增加高端客户的钱包份额？*” 总结问题的陈述将是定义业务问题的第一步。
- en: Requirement Gathering
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 需求收集
- en: Once the problem is identified, have a point-by-point discourse with your client,
    which can include a **subject matter expert** (**SME**) or someone who is well-versed
    in the problem.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦问题被识别，与你的客户进行逐条讨论，客户可以是**主题专家**（**SME**）或在该问题领域有深厚知识的人。
- en: Endeavor to comprehend the issue from their perspective and make inquiries about
    the issue from various points of view, understand the requirements, and conclude
    how you can define the problem from the existing historical data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 力求从客户的角度理解问题，并从不同的角度询问问题，理解需求，并总结如何从现有的历史数据中定义问题。
- en: Now and again, you will find that clients themselves can't comprehend the issue
    well. In such cases, you should work with your client to work out a definition
    of the issue that is satisfactory to both of you.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，你会发现客户自己并不能很好地理解问题。在这种情况下，你应该与客户合作，制定出一个双方都能接受的问题定义。
- en: Data Pipeline and Workflow
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据管道和工作流
- en: After you have comprehended the issue in detail, the subsequent stage is to
    characterize and agree on quantifiable metrics for measuring the problem, that
    is, agreeing with the clients about the metrics to use for further analysis. In
    the long run, this will spare you a ton of issues.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在你详细理解了问题后，接下来的阶段是定义并商定用于衡量问题的可量化指标，即与客户达成一致，确定用于进一步分析的指标。长期来看，这将为你节省很多麻烦。
- en: These metrics can be identified with the existing system for tracking the performance
    of the business, or new metrics can be derived from historical data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标可以与现有的业务绩效追踪系统相关，或者可以从历史数据中导出新的指标。
- en: When you study the metrics for tracking the problem, the data for identifying
    and quantifying the problem may come from multiple data sources, databases, legacy
    systems, real-time data, and so on. The data scientist involved with this has
    to closely work with the client's data management teams to extract and gather
    the required data and push it into analytical tools for further analysis. For
    this, there needs to be a strong pipeline for acquiring data. The acquired data
    is further analyzed to identify its important attributes and how they change over
    time in order to generate the KPIs. This is a crucial stage in client engagement
    and working in tandem with their teams goes a long way toward making the work
    easier.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当你研究跟踪问题的指标时，识别和量化问题的数据可能来自多个数据源、数据库、遗留系统、实时数据等。参与此工作的数据科学家需要与客户的数据管理团队密切合作，提取并收集所需数据，并将其推送到分析工具中进行进一步分析。因此，必须有一个强大的数据获取管道。获取的数据进一步分析，以识别其重要属性及其随时间变化的情况，从而生成KPI。这是客户参与的关键阶段，与他们团队的密切合作有助于使工作更加顺利。
- en: Identifying Measurable Metrics
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定可衡量的指标
- en: Once the required data is gathered through data pipelines, we can develop descriptive
    models to analyze historical data and generate insights into the business problem.
    **Descriptive models/analytics** is all about knowing *what has happened in the
    past* through time trend analysis and the density distribution of data analysis,
    among other things. For this, several attributes from the historical data need
    to be studied in order to gain insights into which of the data attributes are
    related to the current problem.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦通过数据管道收集了所需的数据，我们就可以开发描述性模型来分析历史数据，并生成业务问题的洞察。**描述性模型/分析**主要是通过时间趋势分析、数据分布密度分析等方法，了解*过去发生了什么*。为此，必须研究历史数据中的多个属性，以洞察哪些数据属性与当前问题相关。
- en: An example, as explained in the previous case, is an AMC that is looking for
    solutions to their specific business problem with customer retention. We'll look
    into identifying how we can generate KPIs to understand the problem with retention.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述案例中所解释的例子，某资产管理公司（AMC）正在寻找解决客户留存问题的方案。我们将研究如何生成KPI，以便理解留存问题。
- en: For this, historical data is mined to analyze the customer transaction patterns
    of previous investments and derive KPIs from them. A data scientist has to develop
    these KPIs based on their relevance and efficiency in explaining the variability
    of the problem, or in this case, the retention of customers.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，需要挖掘历史数据，分析以前投资的客户交易模式，并从中导出KPI。数据科学家必须根据KPI在解释问题变动性方面的相关性和效率来开发这些KPI，或者在此案例中，即客户留存。
- en: Documentation and Presentation
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文档编制与展示
- en: The final step is documenting the identified KPIs, their significant trends,
    and how they can impact the business in the long run. In the previous case of
    customer retention, all these metrics—**length of relationship**, **average transaction
    frequency**, **churn rate**—can act as KPIs and be used to explain the problem
    quantitatively.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的步骤是记录已识别的关键绩效指标（KPI）、它们的重要趋势，以及它们如何在长期内影响业务。在前述的客户留存案例中，所有这些指标——**关系长度**、**平均交易频率**、**流失率**——都可以作为KPI，并用于定量解释问题。
- en: If we observe the trend in the churn rate, and let's say in this example, it
    has an increasing trend in the last few months, and if we graphically represent
    this, the client can easily understand the importance of having predictive churn
    analytics in place to identify the customer before they churn, and targeting stronger
    retention.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们观察到流失率的趋势，并假设在过去几个月中呈上升趋势，如果我们用图表表示这一点，客户就可以轻松理解，建立预测流失分析来识别即将流失的客户，以及采取更强有力的留存措施的重要性。
- en: The potential of having a retention system in place needs to be presented to
    the client for which the documentation and graphical representation of the KPIs
    need to be carried out. In the previous case, the identified KPIs, along with
    their change in pattern, need to be documented and presented to the client.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 需要向客户展示是否有可能建立一个客户留存系统，为此需要完成KPIs的文档化和图形表示。在前面的案例中，已识别的KPIs及其变化模式需要进行文档化并呈现给客户。
- en: Translating a Business Problem into Measurable Metrics and Exploratory Data
    Analysis (EDA)
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将业务问题转化为可衡量的指标和探索性数据分析（EDA）
- en: If a specific business problem comes to us, we need to identify the KPIs that
    define that business problem and study the data related to it. Beyond generating
    KPIs related to the problem, looking into the trends and quantifying the problem
    through **Exploratory Data Analysis** (**EDA**) methods will be the next step.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有一个具体的业务问题出现，我们需要确定定义该业务问题的关键绩效指标（KPIs），并研究与之相关的数据。在生成与问题相关的KPIs之后，下一步将是通过**探索性数据分析**（**EDA**）方法，分析趋势并量化问题。
- en: 'The approach to explore KPIs is as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 探索KPIs的方法如下：
- en: Data gathering
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据收集
- en: Analysis of data generation
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据生成分析
- en: KPI visualization
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KPI可视化
- en: Feature importance
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征重要性
- en: Data Gathering
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集
- en: 'The data that is required for analyzing the problem is part of defining the
    business problem. However, the selection of attributes from the data will change
    according to the business problem. Consider the following examples:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 分析问题所需的数据是定义业务问题的一部分。然而，从数据中选择的特征会根据业务问题的不同而有所变化。以下是几个例子：
- en: If it is a recommendation engine or churn analysis of customers, we need to
    look into historical purchases and **Know Your Customer** (**KYC**) data, among
    other data.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是推荐引擎或客户流失分析，我们需要查看历史购买和**了解你的客户**（**KYC**）数据等其他数据。
- en: If it is related to forecasting demand, we need to look into daily sales data.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果与需求预测相关，我们需要查看每日销售数据。
- en: It needs to be concluded that the required data can change from problem to problem.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 需要得出结论，所需的数据会根据问题的不同而变化。
- en: Analysis of Data Generation
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据生成分析
- en: From the available data sources, the next step is to identify the metrics related
    to the defined problem. Apart from the preprocessing of data (refer to *Chapter
    1*, *The Python Data Science Stack*, for details on data manipulation), at times,
    we need to manipulate the data to generate such metrics, or they can be directly
    available in the given data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从可用的数据源中，下一步是识别与已定义问题相关的度量指标。除了数据预处理（有关数据处理的详细信息，请参阅*第1章*，*Python数据科学栈*），有时我们需要对数据进行处理，以生成这些度量指标，或者它们可以直接从给定数据中获得。
- en: For example, let's say we are looking at supervised analysis, such as a **predictive
    maintenance problem** (a problem where predictive analytics is used to predict
    the condition of in-service equipment or machinery before it fails), where sensor-
    or computer-generated log data is used. Although log data is unstructured, we
    can identify which of the log files explain the failures of machinery and which
    do not. Unstructured data is without columns or rows. For example, it can be in
    XML or a similar format. Computer-generated log data is an example. Such data
    needs to be converted into columns and rows or make them structured, or label
    them, that is, provide column names for the data by converting the data into rows
    and columns.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们正在进行监督分析，如**预测性维护问题**（使用预测分析来预测在设备或机器故障之前的服务状态问题），其中使用的是传感器或计算机生成的日志数据。尽管日志数据是非结构化的，我们仍然可以识别哪些日志文件解释了机器故障，哪些没有。非结构化数据没有列或行。例如，它可能是XML格式或类似格式。计算机生成的日志数据就是一个例子。这样的数据需要转换为列和行，或使其结构化，或者对其进行标签化，即通过将数据转换为行和列来为数据提供列名。
- en: Another example is identifying the churn of customers and predicting future
    customers who may churn in the coming periods, where we have transactional data
    on purchases with the features related to each purchase. Here, we need to manipulate
    the data and transform the current data in order to identify which customers have
    churned and which have not from all the purchase-related data.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是识别客户流失并预测未来可能流失的客户，我们拥有与每次购买相关的交易数据及其特征。在这种情况下，我们需要处理数据并转化当前数据，以识别哪些客户已流失，哪些客户没有，从所有与购买相关的数据中进行筛选。
- en: To explain this better, in the raw data, there may be many rows of purchases
    for each customer, with the date of purchase, the units purchased, the price,
    and so on. All the purchases related to a customer need to be identified as a
    single row whether the customer has churned (churned means customers who discontinue
    using a product or service, also known as customer attrition) or not and with
    all the related information.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地解释这一点，在原始数据中，可能会有每个客户的多个购买记录，包括购买日期、购买数量、价格等。所有与某个客户相关的购买记录需要合并为一行，不论该客户是否已经流失（流失指的是停止使用产品或服务的客户，也称为客户流失），并且包含所有相关信息。
- en: 'Here, we will be generating a KPI: **Churned** or **Not Churned** attributes
    for a customer, and similarly for all customers. The identified variable that
    defines the business problem is the target variable. A target variable is also
    known as the **response variable** or **dependent variable**. In *Exercise XX*,
    *Generate the Feature Importance for the Target Variable and Carry Out EDA*, in
    this chapter, it''s captured and defined through the **churn** attribute.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将为客户生成一个 KPI：**流失**或**未流失**属性，其他所有客户也同样如此。定义业务问题的目标变量是已识别的变量。目标变量也称为**响应变量**或**因变量**。在本章的*练习
    XX*中，通过**流失**属性进行捕捉和定义。
- en: KPI Visualization
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: KPI 可视化
- en: To understand the trends and patterns in the KPIs, we need to represent them
    through interactive visualization techniques. We can use different methods, such
    as boxplot, time-trend graphs, density plots, scatter plots, pie charts, and heatmaps.
    We will learn more on this in *Exercise XX*, *Generate the Feature Importance
    for the Target Variable and Carry Out EDA*, in this chapter.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解 KPI 的趋势和模式，我们需要通过交互式可视化技术来表示它们。我们可以使用不同的方法，如箱线图、时间趋势图、密度图、散点图、饼图和热图。在本章的*练习
    XX*中，我们将进一步学习如何*生成目标变量的特征重要性并进行 EDA*。
- en: Feature Importance
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征重要性
- en: Once the target variable is identified, the other attributes in the data and
    their importance to it in explaining the variability of the target variable need
    to be studied. For this, we use association, variance, and correlation methods
    to establish relations with the target variable of other variables (**explanatory**
    or **independent** variables).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了目标变量，就需要研究数据中其他属性及其在解释目标变量的变异性方面的重要性。为此，我们使用关联、方差和相关方法来建立其他变量与目标变量之间的关系（**解释性**或**独立**变量）。
- en: There are multiple feature-importance methods and algorithms that can be used
    depending on the type of variables in the study, such as Pearson Correlation,
    Chi-Square tests, and algorithms based on Gini variable importance, decision trees,
    and Boruta, among others.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 根据研究中变量的类型，可以使用多种特征重要性方法和算法，如皮尔逊相关、卡方检验、基于基尼变量重要性、决策树和 Boruta 等算法。
- en: Note
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The **target variable** or the **study variable**, which is used as the attribute/variable/column
    in the dataset for studying the business problem is also known as the **dependent
    variable** (**DV**), and all other attributes that are considered for the analysis
    are called **independent variables** (**IVs**).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标变量**或**研究变量**，即用于作为数据集中研究业务问题的属性/变量/列，也被称为**因变量**（**DV**），而所有其他被考虑用于分析的属性则称为**自变量**（**IVs**）。'
- en: In the following exercise, we will cover data gathering and analysis-data **(data
    that is generated by merging or combining multiple data sources to get one dataset
    for the analysis)** generation with KPI visualization, and then in the subsequent
    exercise, we will cover what feature importance is.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的练习中，我们将涵盖数据收集和分析——数据**（通过合并或结合多个数据源生成的分析数据集）**的生成与 KPI 可视化，随后我们将介绍特征重要性是什么。
- en: 'Exercise 43: Identify the Target Variable and Related KPIs from the Given Data
    for the Business Problem'
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 43：从给定数据中识别目标变量及与业务问题相关的 KPI
- en: 'Let''s take the example of a **subscription problem** in the banking sector.
    We will use data that is from direct marketing campaigns by a Portuguese banking
    institution, where a customer either opens a term deposit (ref: [https://www.canstar.com.au/term-deposits/what-is-a-term-deposit/](https://www.canstar.com.au/term-deposits/what-is-a-term-deposit/))
    or not after the campaign. The subscription problem is characterized or defined
    contrastingly by every organization. For the most part, the customers who will
    subscribe to a service (here, it is a term deposit) have higher conversion potential
    (that is, from lead to customer conversion) to a service or product. Thus, in
    this problem, subscription metrics, that is, the outcome of historical data, is
    considered as the target variable or KPI.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以银行领域中的**订阅问题**为例。我们将使用来自葡萄牙某银行机构的直接营销活动的数据，其中客户在活动后要么开设定期存款（参考：[https://www.canstar.com.au/term-deposits/what-is-a-term-deposit/](https://www.canstar.com.au/term-deposits/what-is-a-term-deposit/)），要么不开设。每个组织对订阅问题的定义都不同。在大多数情况下，愿意订阅某项服务（在这里是定期存款）的客户具有更高的转化潜力（即，从潜在客户到实际客户的转化）。因此，在这个问题中，订阅指标，也就是历史数据的结果，被视为目标变量或KPI。
- en: 'We will use descriptive analytics to explore trends in the data. We will start
    by identifying and defining the target variable (here, subscribed or not subscribed)
    and the related KPIs:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用描述性分析来探索数据趋势。我们将首先识别并定义目标变量（此处为订阅与未订阅）及相关的KPI：
- en: 'Download the bank.csv data from the following online resources:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下在线资源下载bank.csv数据：
- en: '[https://archive.ics.uci.edu/ml/datasets/Bank+Marketing](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://archive.ics.uci.edu/ml/datasets/Bank+Marketing](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)'
- en: '[https://archive.ics.uci.edu/ml/machine-learning-databases/00222/](https://archive.ics.uci.edu/ml/machine-learning-databases/00222/)'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://archive.ics.uci.edu/ml/machine-learning-databases/00222/](https://archive.ics.uci.edu/ml/machine-learning-databases/00222/)'
- en: Create a folder for the exercise (`packt_exercises`) and save the downloaded
    data there.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为练习创建一个文件夹（`packt_exercises`），并将下载的数据保存在其中。
- en: 'Start Jupyter notebook and import all the required libraries as illustrated.
    Now set the working directory using the `os.chdir()` function:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 Jupyter notebook 并按示例导入所有所需的库。然后，使用`os.chdir()`函数设置工作目录：
- en: '[PRE0]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Use the following code to read the CSV and explore the dataset:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码读取CSV并探索数据集：
- en: '[PRE1]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After executing the previous command, you will get output similar to the following:![](img/C12913_06_01.jpg)
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行前述命令后，你将看到类似以下的输出：![](img/C12913_06_01.jpg)
- en: 'Figure 6.1: Bank DataFrame'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.1: 银行数据框'
- en: When studying the target variable (subscribed or not subscribed—`y`), it is
    important to look at the distribution of it. The type of target variable in this
    dataset is categorical, or of multiple classes. In this case, it's binary (Yes/No).
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在研究目标变量（订阅与未订阅——`y`）时，重要的是要查看其分布情况。此数据集中的目标变量类型是分类的，或者说是多类的。在这种情况下，它是二元的（是/否）。
- en: When the distribution is skewed to one class, the problem is known as an *imbalance
    in the variable*. We can study the proportion of the target variable using a bar
    plot. This gives us an idea about how many of each class there is (in this case,
    how many each of no and yes). The proportion of no is way higher than yes, which
    explains the imbalance in the data.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当分布偏向某一类别时，问题被称为*变量不平衡*。我们可以通过条形图研究目标变量的比例。这可以让我们了解每个类别的数量（在此案例中，了解“no”和“yes”各自的数量）。其中，no的比例远高于yes，这就解释了数据中的不平衡。
- en: 'Let''s execute the following commands to plot a bar plot for the given data:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们执行以下命令，以绘制给定数据的条形图：
- en: '[PRE2]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output is as follows:'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 6.2: Bar plot](img/Image38462.jpg)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.2: 条形图](img/Image38462.jpg)'
- en: 'Figure 6.2: Bar plot'
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.2: 条形图'
- en: 'Now, we will take each variable and look at their distribution trends. The
    following histogram, which is provided as an example, is of the ''`age''` column
    (attribute) in the dataset. Histograms/density plots are a great way to explore
    numerical/float variables, similar to bar plots. They can be used for categorical
    data variables. Here, we will show two numerical variables, `age` and `balance`,
    as examples using a histogram, and two categorical variables, `education` and
    `month`, using bar plots:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将查看每个变量并观察它们的分布趋势。下面的直方图是数据集中'`age'`列（属性）的示例。直方图/密度图是探索数值型/浮动变量的好方法，类似于条形图。它们也可以用于分类数据变量。在这里，我们将使用直方图展示两个数值型变量（`age`
    和 `balance`）的示例，并用条形图展示两个分类变量（`education` 和 `month`）：
- en: '[PRE3]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The histogram is as follows:'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 直方图如下所示：
- en: '![Figure 6.3: Histogram for age](img/C12913_06_03.jpg)'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.3：年龄的直方图](img/C12913_06_03.jpg)'
- en: 'Figure 6.3: Histogram for age'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.3：年龄的直方图
- en: 'To plot the histogram for the `balance` attribute in the dataset, use the following
    command:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要绘制数据集中`balance`属性的直方图，请使用以下命令：
- en: '[PRE4]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The histogram for balance is as follows:'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平衡的直方图如下所示：
- en: '![Figure 6.4: Histogram for balance](img/C12913_06_04.jpg)'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.4：平衡的直方图](img/C12913_06_04.jpg)'
- en: 'Figure 6.4: Histogram for balance'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.4：平衡的直方图
- en: 'Now, using the following code, plot a bar plot for the `education` attribute
    in the dataset:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下代码，绘制数据集中`education`属性的条形图：
- en: '[PRE5]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The bar plot for the `education` attribute is as follows:'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`education`属性的条形图如下所示：'
- en: '![Figure 6.5: Bar plot for education](img/C12913_06_05.jpg)'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.5：教育的条形图](img/C12913_06_05.jpg)'
- en: 'Figure 6.5: Bar plot for education'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.5：教育的条形图
- en: 'Use the following command to plot a bar plot for the `month` attribute of the
    dataset:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令绘制数据集的`month`属性的条形图：
- en: '[PRE6]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The plotted graph is as follows:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 绘制的图形如下所示：
- en: '![Figure 6.6: Bar plot for month](img/C12913_06_06.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.6：月度的条形图](img/C12913_06_06.jpg)'
- en: 'Figure 6.6: Bar plot for month'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.6：月度的条形图
- en: 'The next task is to generate a distribution for each class of the target variable
    to compare the distributions. Plot a histogram of the `age` attribute for the
    target variable (`yes`/`no`):'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个任务是为目标变量的每个类别生成分布并比较分布。绘制目标变量的`age`属性的直方图（`yes`/`no`）：
- en: '[PRE7]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The bar plot of the `month` attribute target variable is as follows:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标变量的`month`属性条形图如下所示：
- en: '![Figure 6.7: Bar plot of the month attribute for the target variable](img/C12913_06_07.jpg)'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.7：目标变量的月份属性条形图](img/C12913_06_07.jpg)'
- en: 'Figure 6.7: Bar plot of the month attribute for the target variable'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.7：目标变量的月份属性条形图
- en: 'Now, using the following command, plot a bar plot for the target variable grouped
    by month:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令，绘制按月分组的目标变量的条形图：
- en: '[PRE8]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The plotted graph is as follows:'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 绘制的图形如下所示：
- en: '![Figure 6.8: Histogram grouped by month](img/C12913_06_08.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.8：按月分组的直方图](img/C12913_06_08.jpg)'
- en: 'Figure 6.8: Histogram grouped by month'
  id: totrans-129
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.8：按月分组的直方图
- en: In this exercise, we looked into establishing KPIs and the target variable—**data
    gathering** and **analysis-data (data that is generated by merging or combining
    multiple data sources to get one dataset for analysis) generation**. The KPIs
    and target variable have been determined—**KPI visualization**. Now, in the next
    exercise, we will identify which of the variables are important in terms of explaining
    the variance of the target variable—**feature importance**.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们研究了建立KPI和目标变量—**数据收集**和**分析数据（通过合并或结合多个数据源生成的数据集，用于分析）生成**。KPI和目标变量已经确定—**KPI可视化**。现在，在下一个练习中，我们将识别哪些变量在解释目标变量的方差方面是重要的—**特征重要性**。
- en: 'Exercise 44: Generate the Feature Importance of the Target Variable and Carry
    Out EDA'
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 44：生成目标变量的特征重要性并进行EDA
- en: In the previous exercise, we looked into the trends of the attributes, identifying
    their distribution, and how we can use various plots and visualization methods
    to carry these out. Prior to tackling a modeling problem, whether it is a predictive
    or a classification problem (for example, from the previous marketing campaign
    data, how to predict future customers that will have the highest probability of
    converting), we have to pre-process the data and select the important features
    that will impact the subscription campaign output models. To do this, we have
    to see the association of the attributes to the outcome (the target variable),
    that is, how much variability of the target variable is explained by each variable.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的练习中，我们研究了属性的趋势，识别它们的分布，以及如何使用各种图表和可视化方法来进行这些分析。在处理建模问题之前，无论是预测问题还是分类问题（例如，从先前的营销活动数据中，如何预测未来最有可能转化的客户），我们必须对数据进行预处理，并选择那些对订阅活动输出模型有影响的重要特征。为此，我们需要查看属性与结果（目标变量）之间的关联，即每个变量解释目标变量的变异性程度。
- en: Associations between variables can be drawn using multiple methods; however,
    we have to consider the data type when choosing a method/algorithm. For example,
    if we are studying numerical variables (integers that are ordered, floats, and
    so on), we can use correlation analysis; if we are studying categorical variables
    with multiple classes, we can use Chi-Square methods. However, there are many
    algorithms that can handle both together and provide measurable outcomes to compare
    the importance of variables.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 变量之间的关联可以通过多种方法绘制；然而，在选择方法/算法时，我们必须考虑数据类型。例如，如果我们研究的是数值型变量（有序的整数、浮动数值等），我们可以使用相关分析；如果我们研究的是具有多个类别的分类变量，则可以使用卡方方法。然而，也有许多算法可以同时处理这两者，并提供可衡量的结果来比较变量的重要性。
- en: 'In this exercise, we will look at how various methods can be used to identify
    the importance of features:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将研究如何使用各种方法来识别特征的重要性：
- en: 'Download the `bank.csv` file and read the data using the following command:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载`bank.csv`文件，并使用以下命令读取数据：
- en: '[PRE9]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Develop a correlation matrix using the following command to identify the correlation
    between the variables:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令开发相关矩阵，以识别变量之间的相关性：
- en: '[PRE10]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The plotted correlation matrix heatmap is as follows:'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 绘制的相关矩阵热图如下：
- en: '![Figure 6.9: Correlation matrix](img/C12913_06_09.jpg)'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.9：相关矩阵](img/C12913_06_09.jpg)'
- en: 'Figure 6.9: Correlation matrix'
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.9：相关矩阵
- en: Note
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '`-1` to `+1`, where a value close to `0` signifies no relation, -1 signifies
    a relation where one variable reduces as the other increases (inverse), and +1
    signifies that as one variable increases the other also increases (direct).'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`-1` 到 `+1`，其中接近 `0` 的值表示无关系，-1 表示一种变量增加时，另一变量减少（反向关系），+1 表示一种变量增加时，另一变量也增加（正向关系）。'
- en: High correlation among independent variables (which are all variables except
    the target variable) can lead to multicollinearity among the variables, which
    can affect the predictive model accuracy.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 独立变量之间的高相关性（即所有除目标变量之外的变量）可能会导致变量之间的多重共线性，这可能影响预测模型的准确性。
- en: Note
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'Make sure to install boruta if not installed already using the following command:'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果尚未安装 Boruta，请使用以下命令确保安装：
- en: '`pip install boruta --upgrade`'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`pip install boruta --upgrade`'
- en: 'Build a feature importance output based on Boruta (a wrapper algorithm around
    a random forest):'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于 Boruta（一个随机森林包装算法）构建特征重要性输出：
- en: '[PRE11]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 6.10: Fit Boruta algorithm](img/C12913_06_10.jpg)'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.10：拟合 Boruta 算法](img/C12913_06_10.jpg)'
- en: 'Figure 6.10: Fit Boruta algorithm'
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.10：拟合 Boruta 算法
- en: 'Check the rank of features as follows:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式检查特征的排名：
- en: '[PRE12]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output is as follows:'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 6.11: Boruta output](img/C12913_06_11.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.11：Boruta 输出](img/C12913_06_11.jpg)'
- en: 'Figure 6.11: Boruta output'
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.11：Boruta 输出
- en: Structured Approach to the Data Science Project Life Cycle
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学项目生命周期的结构化方法
- en: Embarking on data science projects needs a robust methodology in planning the
    project, taking into consideration the potential scaling, maintenance, and team
    structure. We have learned how to define a business problem and quantify it with
    measurable parameters, so the next stage is a project plan that includes the development
    of the solution, to the deployment of a consumable business application.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 开始数据科学项目时，需要有一个稳健的方法来规划项目，考虑到潜在的扩展性、维护性和团队结构。我们已经学习了如何定义一个业务问题并通过可量化的参数加以量化，接下来的阶段是项目计划，涵盖了解决方案的开发到部署一个可用的商业应用程序。
- en: This topic puts together some of the best industry practices structurally with
    examples for data science project life cycle management. This approach is an idealized
    sequence of stages; however, in real applications, the order can change according
    to the type of solution that is required.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 本主题结合了业界一些最佳实践，以结构化方式提供数据科学项目生命周期管理的示例。这种方法是一个理想化的阶段顺序；然而，在实际应用中，顺序可以根据所需解决方案的类型而变化。
- en: Typically, a data science project for a single model deployment takes around
    three months, but this can increase to six months, or even up to a year. Defining
    a process from data to deployment is the key to reducing the time to deployment.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，一个数据科学项目单个模型的部署需要大约三个月的时间，但这可能增加到六个月，甚至长达一年。定义从数据到部署的过程是缩短部署时间的关键。
- en: Data Science Project Life Cycle Phases
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据科学项目生命周期阶段
- en: 'The stages of a data science project life cycle are as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学项目生命周期的各个阶段如下：
- en: Understanding and defining the business problem
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理解和定义业务问题
- en: Data access and discovery
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据访问与发现
- en: Data engineering and pre-processing
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据工程与预处理
- en: Modeling development and evaluation
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 建模开发与评估
- en: 'Phase 1: Understanding and Defining the Business Problem'
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阶段 1：理解并定义业务问题
- en: Every data science project starts with learning the business domain and framing
    the business problem. In most organizations, the application of advanced analytics
    and data science techniques is a fledgling discipline, and most of the data scientists
    involved will have a limited understanding of the business domains.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据科学项目都始于了解业务领域和框定业务问题。在大多数组织中，高级分析和数据科学技术的应用还是一个新兴学科，参与其中的大多数数据科学家对业务领域的理解有限。
- en: To understand the business problem and the domain, the key stakeholders and
    **subject matter experts** (**SMEs**) need to be identified. Then, the SMEs and
    the data scientists interact with each other to develop the initial hypothesis
    and identify the data sources required for the solution's development. This is
    the first phase of understanding a data science project.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解业务问题和领域，需要识别关键利益相关者和**主题专家**（**SMEs**）。然后，主题专家和数据科学家相互合作，提出初步假设，并确定开发解决方案所需的数据源。这是理解数据科学项目的第一阶段。
- en: Once we have a well-structured business problem and the required data is identified,
    along with the data sources, the next phase of data discovery can be initiated.
    The first phase is crucial in building a strong base for scoping and the solution
    approach.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了结构清晰的业务问题，并确定了所需的数据和数据源，就可以开始数据发现的下一阶段。第一阶段对建立强大的基础来确定范围和解决方案方法至关重要。
- en: 'Phase 2: Data Access and Discovery'
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阶段 2：数据访问与发现
- en: This phase includes identifying the data sources and building data pipelines
    and data workflows in order to acquire the data. The nature of the solution and
    the dependent data can vary from one problem to another in terms of the structure,
    velocity, and volume.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段包括识别数据源，并构建数据管道和数据工作流以获取数据。解决方案的性质和依赖的数据在结构、速度和体积方面可能因问题而异。
- en: At this stage, it's important to identify how to acquire the data from the data
    sources. This can be through direct connectors (libraries available on Python)
    using database access credentials, having APIs that provide access to the data,
    directly crawling data from web sources, or can even be data dumps provided in
    CSVs for initial prototype developments. Once a strong data pipeline and workflow
    for acquiring data is established, the data scientists can start exploring the
    data to prepare the analysis-data **(data that is generated by merging or combining
    multiple data sources to get one dataset for analysis).**
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，重要的是要确定如何从数据源获取数据。获取数据的方式可以通过直接连接器（使用Python中的数据库访问库）、使用提供数据访问的API、直接从网络来源抓取数据，或者甚至是初步原型开发所提供的CSV格式的数据转储。一旦建立了强大的数据管道和数据获取工作流，数据科学家就可以开始探索数据，准备分析数据**（通过合并或组合多个数据源以生成一个分析用的数据集）。**
- en: 'Phase 3: Data Engineering and Pre-processing'
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阶段 3：数据工程与预处理
- en: The pre-processing of data means transforming raw data into a form that's consumable
    by a machine learning algorithm. It is essentially the manipulation of data into
    a structure that's suitable for further analysis or getting the data into a form
    that can be input data for modeling purposes. Often, the data required for analysis
    can reside in several tables, databases, or even external data sources.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理是指将原始数据转化为机器学习算法可以使用的形式。实际上，这是将数据处理成适合进一步分析的结构，或者将数据转化为可以输入到建模过程中的形式。通常，所需的分析数据可能存储在多个表格、数据库，甚至是外部数据源中。
- en: A data scientist needs to identify the required attributes from these data sources
    and merge the available data tables to get what is required for the analytics
    model. This is a tedious and time-consuming phase on which data scientists spend
    a considerable part of the development cycle.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家需要从这些数据源中识别出所需的属性，并将现有的数据表合并，以获取分析模型所需的数据。这是一个繁琐且耗时的阶段，数据科学家通常会在开发周期中花费大量时间。
- en: The pre-processing of data includes activities such as outlier treatment, missing
    value imputation, scaling features, mapping the data to a Gaussian (or normal)
    distribution, encoding categorical data, and discretization, among others.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理包括处理异常值、缺失值填充、特征缩放、将数据映射到高斯（或正态）分布、编码类别数据、离散化等活动。
- en: To develop robust machine learning models, it's important that data is pre-processed
    efficiently.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开发强大的机器学习模型，数据必须高效地进行预处理。
- en: Note
  id: totrans-180
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Python has a few libraries that are used for data pre-processing. scikit-learn
    has many efficient built-in methods for pre-processing data. The scikit-learn
    documentation can be found at [https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Python有一些库用于数据预处理。scikit-learn有许多高效的内置方法用于数据预处理。scikit-learn的文档可以在[https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)找到。
- en: Let's go through the following activity to understand how to carry out data
    engineering and pre-processing using one of the pre-processing techniques, such
    as Gaussian normalization.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下活动，了解如何使用其中一种预处理技术（例如高斯归一化）来进行数据工程和预处理。
- en: 'Activity 13: Carry Out Mapping to Gaussian Distribution of Numeric Features
    from the Given Data'
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动13：对给定数据的数值特征进行高斯分布映射
- en: Various pre-processing techniques need to be carried out to prepare the data
    before pushing it into an algorithm.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据输入算法之前，需要进行各种预处理技术来准备数据。
- en: Note
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'Explore this website to find various methods for pre-processing: [https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html).'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 访问此网站，了解各种预处理方法：[https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)。
- en: 'In this exercise, we will carry out data normalization, which is important
    for parametric models such as linear regression, logistic regression, and many
    others:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将进行数据归一化，这对线性回归、逻辑回归等许多参数化模型非常重要：
- en: Use the `bank.csv` file and import all the required packages and libraries into
    the Jupyter notebook.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`bank.csv`文件，并将所有所需的包和库导入到Jupyter笔记本中。
- en: Now, determine the numeric data from the DataFrame. Categorize the data according
    to its type, such as categorical, numeric (float or integer), date, and so on.
    Let's carry out normalization on numeric data.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，确定DataFrame中的数值数据。根据数据类型（如类别、数值（浮动或整数）、日期等）对数据进行分类。让我们对数值数据进行归一化处理。
- en: Carry out a normality test and identify the features that have a non-normal
    distribution.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行正态性检验，识别出具有非正态分布的特征。
- en: Plot the probability density of the features to visually analyze the distribution
    of the features.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制特征的概率密度图，以直观分析特征的分布。
- en: Prepare the power transformation model and carry out transformations on the
    identified features to convert them to normal distribution based on the `box-cox`
    or `yeo-johnson` method.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备功率转换模型，并根据`box-cox`或`yeo-johnson`方法对识别出的特征进行转换，将它们转换为正态分布。
- en: Apply the transformations on new data (evaluation data) with the same generated
    parameters for the features that were identified in the training data.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对新数据（评估数据）应用相同的生成参数进行转换，应用到训练数据中识别出的特征。
- en: Note
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Multiple variables' density plots are shown in the previous plot after the transformations
    are carried out. The distribution of the features in the plots is closer to a
    Gaussian distribution.
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在转换完成后，前面的图中显示了多个变量的密度图。图中的特征分布更接近高斯分布。
- en: The solution for this activity can be found on page 236.
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第236页找到。
- en: Once the transformations are carried out, we analyze the normality of the features
    again to see the effect. You can see that after the transformations, some of the
    features can have the null hypothesis not rejected (that is, the distribution
    is still not Gaussian) with almost all features higher `p` values (refer to point
    2 of this activity). Once the transformed data is generated, we bind it back to
    the numeric data.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦转换完成，我们再次分析特征的正态性，以查看其效果。你会发现，经过转换后，一些特征的原假设未被拒绝（即分布仍然不是高斯分布），并且几乎所有特征的`p`值都较高（参考本活动的第2点）。一旦生成了转换后的数据，我们将其与数值数据绑定。
- en: 'Phase 4: Model Development'
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第4阶段：模型开发
- en: Once we have a cleaned and pre-processed data, it can be ingested into a machine
    learning algorithm for exploratory or predictive analysis, or for other applications.
    Although the approach to a problem may be designed, whether it's a classification,
    association, or a regression problem, for example, the specific algorithm that
    needs to considered for the data has to be identified. For example, if it's a
    classification problem, it could be a decision tree, a support vector machine,
    or a neural network with many layers.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们获得了清理和预处理过的数据，就可以将其输入到机器学习算法中进行探索性分析或预测分析，或用于其他应用。尽管问题的处理方法可以设计出来，比如分类、关联或回归问题，但需要为数据确定的特定算法也必须被识别出来。例如，如果是分类问题，它可能是决策树、支持向量机，或者是一个具有多层的神经网络。
- en: For modeling purposes, the data needs to be separated into testing and training
    data. The model is developed on the training data and its performance (accuracy/error)
    is evaluated on the testing data. With the algorithms selected, the related parameters
    with respect to it need to be tuned by the data scientist to develop a robust
    model.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在建模过程中，数据需要分为测试数据和训练数据。模型在训练数据上进行开发，并在测试数据上评估其性能（准确性/误差）。在选择算法后，需要通过数据科学家调整与之相关的参数，以开发一个稳健的模型。
- en: Summary
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned how to define a business problem from a data science
    perspective through a well-defined, structured approach. We started by understanding
    how to approach a business problem, how to gather the requirements from stakeholders
    and business experts, and how to define the business problem by developing an
    initial hypothesis.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何通过一个明确结构化的方法，从数据科学的角度定义业务问题。我们首先理解了如何处理业务问题，如何从利益相关者和业务专家处收集需求，以及如何通过开发初步假设来定义业务问题。
- en: Once the business problem was defined with data pipelines and workflows, we
    looked into understanding how to start the analysis on the gathered data in order
    to generate the KPIs and carry out descriptive analytics to identify the key trends
    and patterns in the historical data through various visualization techniques.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦业务问题通过数据管道和工作流定义完成，我们就开始了解如何对收集到的数据进行分析，以生成 KPI 并进行描述性分析，通过各种可视化技术识别历史数据中的关键趋势和模式。
- en: We also learned how a data science project life cycle is structured, from defining
    the business problem to various pre-processing techniques and model development.
    In the next chapter, we will be learning how to implement the concept of high
    reproducibility on a Jupyter notebook, and its importance in development.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还了解了数据科学项目生命周期的结构，从定义业务问题到各种预处理技术和模型开发。在下一章中，我们将学习如何在 Jupyter notebook 上实现高可复现性的概念，以及它在开发中的重要性。
