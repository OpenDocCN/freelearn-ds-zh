- en: 1\. Data Exploration and Cleaning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 数据探索与清理
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, you will take your first steps with Python and Jupyter notebooks,
    some of the most common tools data scientists use. You'll then take the first
    look at the dataset for the case study project that will form the core of this
    book. You will begin to develop an intuition for quality assurance checks that
    data needs to be put through before model building. By the end of the chapter,
    you will be able to use pandas, the top package for wrangling tabular data in
    Python, to do exploratory data analysis, quality assurance, and data cleaning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将迈出使用 Python 和 Jupyter 笔记本的第一步，这些是数据科学家常用的工具。接下来，你将首次查看本书核心案例研究项目的数据集。你将开始培养对数据在建模前需要进行的质量保证检查的直觉。到本章结束时，你将能够使用
    pandas，这是 Python 中处理表格数据的顶级包，进行探索性数据分析、质量保证和数据清理。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Most businesses possess a wealth of data on their operations and customers.
    Reporting on this data in the form of descriptive charts, graphs, and tables is
    a good way to understand the current state of the business. However, in order
    to provide quantitative guidance on future business strategies and operations,
    it is necessary to go a step further. This is where the practices of machine learning
    and predictive modeling are needed. In this book, we will show how to go from
    descriptive analyses to concrete guidance for future operations, using predictive
    models.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数企业拥有大量关于其运营和客户的数据。通过描述性图表、图形和表格来报告这些数据，是了解企业当前状况的好方法。然而，为了为未来的商业战略和运营提供量化指导，还需要进一步深入。这正是机器学习和预测建模技术派上用场的地方。本书将展示如何通过预测模型，从描述性分析转变为为未来运营提供具体指导的方法。
- en: 'To accomplish this goal, we''ll introduce some of the most widely used machine
    learning tools via Python and many of its packages. You will also get a sense
    of the practical skills necessary to execute successful projects: inquisitiveness
    when examining data and communication with the client. Time spent looking in detail
    at a dataset and critically examining whether it accurately meets its intended
    purpose is time well spent. You will learn several techniques for assessing data
    quality here.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这个目标，我们将通过 Python 和许多它的包，介绍一些最广泛使用的机器学习工具。你还将获得执行成功项目所需的实用技能：在检查数据时保持好奇心，以及与客户的沟通。花时间仔细查看数据集，并批判性地检查它是否准确地满足预期目的，是值得的。你将在这里学习评估数据质量的几种技术。
- en: In this chapter, after getting familiar with the basic tools for data exploration,
    we will discuss a few typical working scenarios for how you may receive data.
    Then, we will begin a thorough exploration of the case study dataset and help
    you learn how you can uncover possible issues, so that when you are ready for
    modeling, you may proceed with confidence.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，熟悉了基本的数据探索工具之后，我们将讨论几种典型的工作场景，说明你可能如何接收数据。然后，我们将开始对案例研究数据集进行全面的探索，帮助你学习如何发现潜在问题，以便当你准备进行建模时，能够有信心地进行操作。
- en: Python and the Anaconda Package Management System
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 和 Anaconda 包管理系统
- en: In this book, we will use the Python programming language. Python is a top language
    for data science and is one of the fastest-growing programming languages. A commonly
    cited reason for Python's popularity is that it is easy to learn. If you have
    Python experience, that's great; however, if you have experience with other languages,
    such as C, Matlab, or R, you shouldn't have much trouble using Python. You should
    be familiar with the general constructs of computer programming to get the most
    out of this book. Examples of such constructs are `for` loops and `if` statements
    that guide the **control flow** of a program. No matter what language you have
    used, you are likely familiar with these constructs, which you will also find
    in Python.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中，我们将使用 Python 编程语言。Python 是数据科学的顶级语言，也是增长最快的编程语言之一。Python 受欢迎的一个常见原因是它易于学习。如果你有
    Python 经验，那就太好了；不过，如果你有其他语言的经验，比如 C、Matlab 或 R，你应该也不会遇到太多困难。你应该熟悉计算机编程的一般结构，以便最大限度地利用本书。此类结构的示例包括`for`循环和`if`语句，它们指导程序的**控制流**。不论你曾使用什么语言，你很可能都对这些结构有所了解，而它们也同样出现在
    Python 中。
- en: A key feature of Python that is different from some other languages is that
    it is zero-indexed; in other words, the first element of an ordered collection
    has an index of `0`. Python also supports negative indexing, where the index `-1`
    refers to the last element of an ordered collection and negative indices count
    backward from the end. The slice operator, `:`, can be used to select multiple
    elements of an ordered collection from within a range, starting from the beginning,
    or going to the end of the collection.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Python的一个关键特点是它与其他一些语言不同，它是零索引的；换句话说，一个有序集合的第一个元素的索引是`0`。Python还支持负索引，其中索引`-1`表示有序集合中的最后一个元素，负索引从集合的末尾开始倒数。切片操作符`:`可以用来从有序集合中选择一个范围内的多个元素，既可以从开始位置选择，也可以选择到集合的末尾。
- en: Indexing and the Slice Operator
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 索引和切片操作符
- en: 'Here, we demonstrate how indexing and the slice operator work. To have something
    to index, we will create a `range()` Python function. The `range()` function technically
    creates an `list()` function, although you need not be concerned with that detail
    here. The following screenshot shows a list of the first five positive integers
    being printed on the console, as well as a few indexing operations, and changing
    the first item of the list to a new value of a different data type:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们展示了索引和切片操作符是如何工作的。为了进行索引操作，我们将创建一个`range()` Python函数。`range()`函数在技术上创建了一个`list()`函数，尽管你不需要关心这个细节。以下截图显示了打印在控制台上的前五个正整数的列表，以及一些索引操作，并将列表的第一个项更改为不同数据类型的新值：
- en: '![Figure 1.1: List creation and indexing'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.1：列表创建和索引](img/B16925_01_02.jpg)'
- en: '](img/B16925_01_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_01.jpg)'
- en: 'Figure 1.1: List creation and indexing'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1：列表创建和索引
- en: 'A few things to notice about *Figure 1.1*: the endpoint of an interval is open
    for both slice indexing and the `range()` function, while the starting point is
    closed. In other words, notice how when we specify the start and end of `range()`,
    endpoint 6 is not included in the result but starting point 1 is. Similarly, when
    indexing the list with the slice `[:3]`, this includes all elements of the list
    with indices up to, but not including, 3.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 关于*图1.1*需要注意几点：对于切片索引和`range()`函数，区间的端点是开放的，而起始点是闭合的。换句话说，注意当我们指定`range()`的起始和结束时，端点6不包括在结果中，但起始点1被包括在内。同样，当用切片`[:3]`索引列表时，它包括所有索引小于3的元素，但不包括索引为3的元素。
- en: 'We''ve referred to ordered collections, but Python also includes unordered
    collections. An important one of these is called a `{}` and with the **key:value**
    pairs separated by commas. The following screenshot is an example of how we can
    create a dictionary with counts of fruit – examine the number of apples, then
    add a new type of fruit and its count:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过有序集合，但Python也包括无序集合。其中一个重要的集合类型叫做`{}`，它包含**键:值**对，通过逗号分隔。以下截图展示了如何创建一个包含水果数量的字典——首先查看苹果的数量，然后添加一种新的水果类型及其数量：
- en: '![Figure 1.2: An example dictionary'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.2：一个字典示例](img/B16925_01_02.jpg)'
- en: '](img/B16925_01_02.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_02.jpg)'
- en: 'Figure 1.2: An example dictionary'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2：一个字典示例
- en: There are many other distinctive features of Python and we just want to give
    you a flavor here, without getting into too much detail. In fact, you will probably
    use packages such as `pandas`) and `numpy`) for most of your data handling in
    Python. NumPy provides fast numerical computation on arrays and matrices, while
    pandas provides a wealth of data wrangling and exploration capabilities on tables
    of data called **DataFrames**. However, it's good to be familiar with some of
    the basics of Python—the language that sits at the foundation of all of this.
    For example, indexing works the same in NumPy and pandas as it does in Python.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Python还有许多其他独特的特点，我们这里只是给你一个大致的概念，不会涉及太多细节。实际上，你可能会使用像`pandas`和`numpy`这样的包来处理大多数Python中的数据。NumPy提供了对数组和矩阵的快速数值计算，而pandas则提供了丰富的数据处理和探索功能，特别是对被称为**DataFrames**的数据表的操作。然而，熟悉一些Python的基础知识是很有帮助的，因为它是所有这些内容的基础。例如，索引在NumPy和pandas中的工作方式与在Python中相同。
- en: One of the strengths of Python is that it is open source and has an active community
    of developers creating amazing tools. We will use several of these tools in this
    book. A potential pitfall of having open source packages from different contributors
    is the dependencies between various packages. For example, if you want to install
    pandas, it may rely on a certain version of NumPy, which you may or may not have
    installed. Package management systems make life easier in this respect. When you
    install a new package through the package management system, it will ensure that
    all the dependencies are met. If they aren't, you will be prompted to upgrade
    or install new packages as necessary.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的一个优势是它是开源的，并且拥有一个活跃的开发者社区，创造了许多令人惊叹的工具。我们将在本书中使用其中的几个工具。使用不同贡献者提供的开源包的一个潜在陷阱是各个包之间的依赖关系。例如，如果您想安装
    pandas，它可能依赖于某个版本的 NumPy，而您可能已经安装了该版本，也可能没有。包管理系统在这方面让生活变得更加轻松。当您通过包管理系统安装新包时，它会确保所有依赖关系都已满足。如果没有，它会提示您升级或根据需要安装新包。
- en: For this book, we will use the **Anaconda** package management system, which
    you should already have installed. While we will only use Python here, it is also
    possible to run R with Anaconda.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本书，我们将使用**Anaconda**包管理系统，您应该已经安装了它。虽然我们这里只使用 Python，但也可以在 Anaconda 中运行 R。
- en: 'Note: Environments'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注释：环境
- en: It is recommended to create a new Python 3.x environment for this book. Environments
    are like separate installations of Python, where the set of packages you have
    installed can be different, as well as the version of Python. Environments are
    useful for developing projects that need to be deployed in different versions
    of Python, possibly with different dependencies. For general information on this,
    see [https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html).
    See the *Preface* for specific instructions on setting up an Anaconda environment
    for this book before you begin the upcoming exercises.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐为本书创建一个新的 Python 3.x 环境。环境就像是 Python 的独立安装版本，其中已安装的包集可能不同，Python 的版本也可能不同。环境对于开发需要在不同版本的
    Python 中部署的项目非常有用，这些项目可能依赖于不同的包版本。有关这方面的一般信息，请参阅 [https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)。请在开始接下来的练习之前，查看*前言*中关于为本书设置
    Anaconda 环境的具体说明。
- en: 'Exercise 1.01: Examining Anaconda and Getting Familiar with Python'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.01：检查 Anaconda 并熟悉 Python
- en: 'In this exercise, you will examine the packages in your Anaconda installation
    and practice with some basic Python control flow and data structures, including
    a `for` loop, `dict`, and `list`. This will confirm that you have completed the
    installation steps in the preface and show you how Python syntax and data structures
    may be a little different from other programming languages you may be familiar
    with. Perform the following steps to complete the exercise:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，您将检查 Anaconda 安装中的包，并练习一些基本的 Python 控制流和数据结构，包括`for` 循环、`dict` 和 `list`。这将确认您已经完成了前言中的安装步骤，并展示
    Python 语法和数据结构可能与您熟悉的其他编程语言有所不同。执行以下步骤以完成练习：
- en: Note
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 注释
- en: 'Before executing the exercises and the activity in this chapter, please make
    sure you have followed the instructions regarding setting up your Python environment
    as mentioned in the *Preface*. The code file for this exercise can be found here:
    [https://packt.link/N0RPT](https://packt.link/N0RPT).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行本章的练习和活动之前，请确保您已按照*前言*中提到的设置 Python 环境的说明进行操作。本练习的代码文件可以在此找到：[https://packt.link/N0RPT](https://packt.link/N0RPT)。
- en: 'Open up Terminal, if you''re using macOS or Linux, or a Command Prompt window
    in Windows. If you''re using an environment, activate it using `conda activate
    <name_of_your_environment>`. Then type `conda` `list` at the command line. You
    should observe an output similar to the following:![Figure 1.3: Selection of packages
    from conda list'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端（如果您使用的是 macOS 或 Linux）或在 Windows 中打开命令提示符窗口。如果您使用的是环境，请使用`conda activate
    <name_of_your_environment>`激活它。然后在命令行中键入`conda` `list`。您应该看到类似以下内容的输出：![图 1.3：从
    conda list 中选择包
- en: '](img/B16925_01_03.jpg)'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_03.jpg)'
- en: 'Figure 1.3: Selection of packages from conda list'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.3：从 conda list 中选择包
- en: You can see all the packages installed in your environment, including the packages
    we will directly interact with, as well as their dependencies which are needed
    for them to function. Managing dependencies among packages is one of the main
    advantages of a package management system.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以看到环境中安装的所有包，包括我们将直接交互的包，以及它们的依赖项，这些依赖项是它们正常运行所必需的。包管理系统的一个主要优势是能够管理包之间的依赖关系。
- en: Note
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注释
- en: 'For more information about Anaconda and command-line interaction, check out
    this "cheat sheet": [https://docs.conda.io/projects/conda/en/latest/_downloads/843d9e0198f2a193a3484886fa28163c/conda-cheatsheet.pdf](https://docs.conda.io/projects/conda/en/latest/_downloads/843d9e0198f2a193a3484886fa28163c/conda-cheatsheet.pdf).'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有关 Anaconda 和命令行交互的更多信息，请查看此“备忘单”：[https://docs.conda.io/projects/conda/en/latest/_downloads/843d9e0198f2a193a3484886fa28163c/conda-cheatsheet.pdf](https://docs.conda.io/projects/conda/en/latest/_downloads/843d9e0198f2a193a3484886fa28163c/conda-cheatsheet.pdf)。
- en: 'Type `python` in Terminal to open a command-line Python interpreter. You should
    obtain an output similar to the following:![Figure 1.4: Command-line Python'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中输入`python`，打开命令行 Python 解释器。你应该会得到类似以下的输出：![图 1.4：命令行 Python
- en: '](img/B16925_01_04.jpg)'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_04.jpg)'
- en: 'Figure 1.4: Command-line Python'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.4：命令行 Python
- en: You should see some information about your version of Python, as well as the
    Python Command Prompt (`>>>`). When you type after this prompt, you are writing
    Python code.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该看到一些关于 Python 版本的信息，以及 Python 命令提示符（`>>>`）。当你在此提示符后输入时，你正在编写 Python 代码。
- en: Note
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注释
- en: Although we will be using the Jupyter notebook in this book, one of the aims
    of this exercise is to go through the basic steps of writing and running Python
    programs on the Command Prompt.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尽管本书中我们将使用 Jupyter notebook，但本练习的目标之一是通过在命令提示符下编写和运行 Python 程序的基本步骤。
- en: 'Write a `for` loop at the Command Prompt to print values from 0 to 4 using
    the following code (note that the three dots at the beginning of the second and
    third lines appear automatically if you are writing code in the command-line Python
    interpreter; if you''re instead writing in a Jupyter notebook, these won''t appear):'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在命令提示符下编写`for`循环，使用以下代码打印从 0 到 4 的值（请注意，在命令行 Python 解释器中编写代码时，第二行和第三行开头的三个点会自动出现；如果你在
    Jupyter notebook 中编写代码，这些点将不会出现）：
- en: '[PRE0]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once you hit *Enter* when you see `...` on the prompt, you should obtain this output:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当你在看到`...`提示符时按下*Enter*，你应该得到以下输出：
- en: '![Figure 1.5: Output of a for loop at the command line'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.5：命令行中 for 循环的输出'
- en: '](img/B16925_01_05.jpg)'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_05.jpg)'
- en: 'Figure 1.5: Output of a for loop at the command line'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.5：命令行中 for 循环的输出
- en: Notice that in Python, the opening of the `for` loop is followed by a colon,
    and `for` loop prints the values returned by the `range()` iterator, having repeatedly
    accessed them using the `counter` variable with the `in` keyword.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，在 Python 中，`for`循环的开始后面紧跟一个冒号，`for`循环打印由`range()`迭代器返回的值，这些值通过使用`counter`变量与`in`关键字反复访问。
- en: Note
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注释
- en: 'For many more details on Python code conventions, refer to the following: [https://www.python.org/dev/peps/pep-0008/](https://www.python.org/dev/peps/pep-0008/).'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有关更多关于 Python 代码规范的详细信息，请参考以下链接：[https://www.python.org/dev/peps/pep-0008/](https://www.python.org/dev/peps/pep-0008/)。
- en: Now, we will return to our dictionary example. The first step here is to create
    the dictionary.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们将回到字典的示例。这里的第一步是创建字典。
- en: 'Create a dictionary of fruits (`apples`, `oranges`, and `bananas`) using the
    following code:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建一个水果字典（`apples`、`oranges` 和 `bananas`）：
- en: '[PRE1]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Convert the dictionary to a list using the `list()` function, as shown in the
    following snippet:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`list()`函数将字典转换为列表，如下所示的代码片段：
- en: '[PRE2]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once you run the preceding code, you should obtain the following output:'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦运行前面的代码，你应该会得到以下输出：
- en: '[PRE3]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice that when this is done and we examine the contents, only the keys of
    the dictionary have been captured in the list. If we wanted the values, we would
    have had to specify that with the `.values()` method of the list. Also, notice
    that the list of dictionary keys happens to be in the same order that we wrote
    them when creating the dictionary. This is not guaranteed, however, as dictionaries
    are unordered collection types.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，当这完成后，我们检查内容时，列表中仅捕获了字典的键。如果我们想要获取值，必须使用`.values()`方法指定。此外，请注意，字典键的列表恰好与我们创建字典时书写的顺序相同。然而，这并不保证，因为字典是无序集合类型。
- en: 'One convenient thing you can do with lists is to append other lists to them
    with the `+` operator. As an example, in the next step, we will combine the existing
    list of fruit with a list that contains just one more type of fruit, overwriting
    the variable containing the original list, like this: `list(example_dict.values());`
    the interested readers can confirm this for themselves.'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用列表时，你可以通过`+`运算符将其他列表添加到现有列表中。作为示例，在下一步中，我们将现有的水果列表与只包含一种水果的新列表合并，并覆盖包含原始列表的变量，像这样：`list(example_dict.values());`
    有兴趣的读者可以自行验证这一点。
- en: 'Use the `+` operator to combine the existing list of fruits with a new list
    containing only one fruit (`pears`):'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`+`运算符将现有的水果列表与只包含一个水果（`pears`）的新列表合并：
- en: '[PRE4]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Your output will be as follows:'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出将如下所示：
- en: '[PRE5]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`sorted()` function that can be used for this; it will return a sorted version
    of the input. In our case, this means the list of fruit types will be sorted alphabetically.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`sorted()`函数可以用于此；它将返回输入的排序版本。在我们的例子中，这意味着水果种类列表将按字母顺序排序。'
- en: 'Sort the list of fruits in alphabetical order using the `sorted()` function,
    as shown in the following snippet:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`sorted()`函数按字母顺序排序水果列表，如下所示：
- en: '[PRE6]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once you run the preceding code, you should see the following output:'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦运行前面的代码，你应该会看到以下输出：
- en: '[PRE7]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: That's enough Python for now. We will show you how to execute the code for this
    book, so your Python knowledge should improve along the way. While you have the
    Python interpreter open, you may wish to run the code examples shown in *Figures
    1.1* and *1.2*. When you're done with the interpreter, you can type `quit()` to
    exit.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经足够的Python知识了。我们将展示如何执行本书中的代码，所以在过程中你的Python知识应该会有所提升。在你打开Python解释器时，你可能希望运行*图1.1*和*1.2*中展示的代码示例。当你使用完解释器后，可以输入`quit()`退出。
- en: Note
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'As you learn more and inevitably want to try new things, consult the official
    Python documentation: [https://docs.python.org/3/](https://docs.python.org/3/).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你学习的深入，并且不可避免地想尝试新事物，请参考官方的Python文档：[https://docs.python.org/3/](https://docs.python.org/3/)。
- en: Different Types of Data Science Problems
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学问题的不同类型
- en: 'Much of your time as a data scientist is likely to be spent wrangling data:
    figuring out how to get it, getting it, examining it, making sure it''s correct
    and complete, and joining it with other types of data. pandas is a widely used
    tool for data analysis in Python, and it can facilitate the data exploration process
    for you, as we will see in this chapter. However, one of the key goals of this
    book is to start you on your journey to becoming a machine learning data scientist,
    for which you will need to master the art and science of **predictive modeling**.
    This means using a mathematical model, or idealized mathematical formulation,
    to learn relationships within the data, in the hope of making accurate and useful
    predictions when new data comes in.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，你的大部分时间可能都会花在数据清理上：弄清楚如何获取数据、获取数据、检查数据、确保数据的正确性和完整性，并将数据与其他类型的数据结合。pandas是Python中广泛使用的数据分析工具，它能帮助你加速数据探索过程，正如我们在本章中所看到的。然而，本书的一个关键目标是帮助你踏上成为机器学习数据科学家的旅程，而这需要你掌握**预测建模**的艺术和科学。这意味着使用数学模型或理想化的数学公式来学习数据中的关系，希望当新的数据到来时，能够做出准确且有用的预测。
- en: For predictive modeling use cases, data is typically organized in a tabular
    structure, with **features** and a **response variable**. For example, if you
    want to predict the price of a house based on some characteristics about it, such
    as **area** and **number of bedrooms**, these attributes would be considered the
    features and the **price of the house** would be the response variable. The response
    variable is sometimes called the **target variable** or **dependent variable**,
    while the features may also be called the **independent variables**.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于预测建模的使用场景，数据通常以表格结构组织，包含**特征**和**响应变量**。例如，如果你想根据一些关于房子的特征来预测房价，如**面积**和**卧室数量**，这些特征将被视为特征，而**房价**则是响应变量。响应变量有时也称为**目标变量**或**因变量**，而特征有时也称为**自变量**。
- en: 'If you have a dataset of 1,000 houses including the values of these features
    and the prices of the houses, you can say you have 1,000 **samples** of **labeled**
    data, where the labels are the known values of the response variable: the prices
    of different houses. Most commonly, the tabular data structure is organized so
    that different rows are different samples, while features and the response occupy
    different columns, along with other metadata such as sample IDs, as shown in *Figure
    1.6*:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个包含1,000个房屋的数据集，其中包括这些特征的值和房屋的价格，那么你可以说你拥有1,000个**样本**的**标注**数据，其中标签是响应变量的已知值：不同房屋的价格。通常，表格数据结构被组织成不同的行表示不同的样本，而特征和响应占据不同的列，并且还有其他元数据，如样本ID，如*图1.6*所示：
- en: '![Figure 1.6: Labeled data (the house prices are the known target variable)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.6：标注数据（房价是已知的目标变量）'
- en: '](img/B16925_01_06.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_06.jpg)'
- en: 'Figure 1.6: Labeled data (the house prices are the known target variable)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6：标注数据（房价是已知的目标变量）
- en: '**Regression Problem**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归问题**'
- en: Once you have trained a model to learn the relationship between the features
    and response using your labeled data, you can then use it to make predictions
    for houses where you don't know the price, based on the information contained
    in the features. The goal of predictive modeling in this case is to be able to
    make a prediction that is close to the true value of the house. Since we are predicting
    a numerical value on a continuous scale, this is called a **regression problem**.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你训练了一个模型，通过使用标注数据学习特征与响应之间的关系，你就可以利用它对那些你不知道价格的房屋进行预测，基于特征中包含的信息。在这种情况下，预测建模的目标是能够做出接近房屋真实价值的预测。由于我们预测的是一个连续尺度上的数值，这被称为**回归问题**。
- en: '**Classification Problem**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类问题**'
- en: 'On the other hand, if we were trying to make a qualitative prediction about
    the house, to answer a **yes** or **no** question such as "will this house go
    on sale within the next 5 years?" or "will the owner default on the mortgage?",
    we would be solving what is known as a **classification problem**. Here, we would
    hope to answer the yes or no question correctly. The following figure is a schematic
    illustrating how model training works, and what the outcomes of regression or
    classification models might be:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们试图对房屋做出定性预测，回答像“这栋房屋在未来5年内会出售吗？”或“房主会违约吗？”这样的**是**或**否**问题，那么我们将解决一个称为**分类问题**的问题。在这里，我们希望能够正确地回答是或否的问题。下图是一个示意图，展示了模型训练的工作原理，以及回归或分类模型的可能结果：
- en: '![Figure 1.7: Schematic of model training and prediction for regression and
    classification'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.7：回归和分类的模型训练与预测示意图'
- en: '](img/B16925_01_07.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_07.jpg)'
- en: 'Figure 1.7: Schematic of model training and prediction for regression and classification'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7：回归和分类的模型训练与预测示意图
- en: Classification and regression tasks are called **supervised learning**, which
    is a class of problems that relies on labeled data. These problems can be thought
    of as needing "supervision" by the known values of the target variable. By contrast,
    there is also **unsupervised learning**, which relates to more open-ended questions
    of trying to find some sort of structure in a dataset that does not necessarily
    have labels. Taking a broader view, any kind of applied math problem, including
    fields as varied as **optimization**, **statistical inference**, and **time series
    modeling**, may potentially be considered an appropriate responsibility for a
    data scientist.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 分类和回归任务被称为**监督学习**，这是一类依赖于标注数据的问题。可以将这些问题视为需要目标变量的已知值进行“监督”。相对而言，还有**无监督学习**，它涉及到更开放性的问题，试图在一个没有标签的数据集中找到某种结构。从更广泛的角度来看，任何应用数学问题，包括像**优化**、**统计推断**和**时间序列建模**这样的领域，都可能被视为数据科学家的适当职责。
- en: Loading the Case Study Data with Jupyter and pandas
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Jupyter和pandas加载案例研究数据
- en: Now it's time to take a first look at the data we will use in our case study.
    We won't do anything in this section other than ensure that we can load the data
    into a **Jupyter notebook** correctly. Examining the data, and understanding the
    problem you will solve with it, will come later.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候首次查看我们在案例研究中将使用的数据了。我们在本节中不会做任何其他事情，只是确保我们能正确地将数据加载到**Jupyter notebook**中。数据的检查和对你将要解决的问题的理解将在之后进行。
- en: The data file is an Excel spreadsheet called `default_of_credit_card_clients__courseware_version_1_21_19.xls`.
    We recommend you first open the spreadsheet in Excel or the spreadsheet program
    of your choice. Note the number of rows and columns. Look at some example values.
    This will help you know whether or not you have loaded it correctly in the Jupyter
    notebook.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 数据文件是一个名为`default_of_credit_card_clients__courseware_version_1_21_19.xls`的Excel电子表格。我们建议你先在Excel或你选择的电子表格程序中打开该电子表格。注意行数和列数。查看一些示例值。这将帮助你了解是否已经正确加载该文件到Jupyter笔记本中。
- en: Note
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The dataset can be obtained from the following link: [https://packt.link/wensZ](https://packt.link/wensZ).
    This is a modified version of the original dataset, which has been sourced from
    the UCI Machine Learning Repository [[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)].
    Irvine, CA: University of California, School of Information and Computer Science.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以从以下链接获取：[https://packt.link/wensZ](https://packt.link/wensZ)。这是原始数据集的修改版本，原数据集来自UCI机器学习库[[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)]。加利福尼亚州尔湾：加利福尼亚大学信息与计算机科学学院。
- en: '**What is a Jupyter notebook?**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么是Jupyter笔记本？**'
- en: 'Jupyter notebooks are interactive coding environments that allow for inline
    text and graphics. They are great tools for data scientists to communicate and
    preserve their results, since both the methods (code) and the message (text and
    graphics) are integrated. You can think of the environment as a kind of web page
    where you can write and execute code. Jupyter notebooks can, in fact, be rendered
    as web pages, as is done on GitHub. Here is an example notebook: [https://packt.link/pREet](https://packt.link/pREet).
    Look it over and get a sense of what you can do. An excerpt from this notebook
    is displayed here, showing code, graphics, and prose, which is known as **Markdown**
    in this context:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter笔记本是互动式编码环境，允许插入文本和图形。它们是数据科学家用于交流和保存结果的绝佳工具，因为方法（代码）和信息（文本和图形）是集成在一起的。你可以将这个环境看作一个可以编写和执行代码的网页。实际上，Jupyter笔记本可以呈现为网页，就像在GitHub上那样。这里有一个示例笔记本：[https://packt.link/pREet](https://packt.link/pREet)。查看它，了解你可以做什么。以下是该笔记本的摘录，展示了代码、图形和散文，这在这种情况下被称为**Markdown**：
- en: '![Figure 1.8: Example of a Jupyter notebook showing code, graphics, and Markdown
    text'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.8：展示代码、图形和Markdown文本的Jupyter笔记本示例'
- en: '](img/B16925_01_08.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_08.jpg)'
- en: 'Figure 1.8: Example of a Jupyter notebook showing code, graphics, and Markdown
    text'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8：展示代码、图形和Markdown文本的Jupyter笔记本示例
- en: One of the first things to learn about Jupyter notebooks is how to navigate
    around and make edits. There are two modes available to you. If you select a cell
    and press *Enter*, you are in **edit mode** and you can edit the text in that
    cell. If you press *Esc*, you are in **command mode** and you can navigate around
    the notebook.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 学习Jupyter笔记本的首要任务之一是如何浏览和进行编辑。你可以选择两种模式。如果你选择一个单元格并按下*Enter*，你会进入**编辑模式**，在该模式下你可以编辑该单元格中的文本。如果你按下*Esc*，则进入**命令模式**，可以在笔记本中进行导航。
- en: Note
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you''re reading the print version of this book, you can download and browse
    the color versions of some of the images in this chapter by visiting the following
    link: [https://packt.link/T5EIH](https://packt.link/T5EIH).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在阅读本书的印刷版，可以通过访问以下链接下载并浏览本章中某些图像的彩色版本：[https://packt.link/T5EIH](https://packt.link/T5EIH)。
- en: When you are in command mode, there are many useful hotkeys you can use. The
    *Up* and *Down* arrows will help you select different cells and scroll through
    the notebook. If you press *y* on a selected cell in command mode, it changes
    it to a **code cell**, in which the text is interpreted as code. Pressing *m*
    changes it to a **Markdown cell**, where you can write formatted text. *Shift*
    + *Enter* evaluates the cell, rendering the Markdown or executing the code, as
    the case may be. You'll get some practice with a Jupyter notebook in the next
    exercise.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当你处于命令模式时，有许多有用的快捷键可以使用。*上*箭头和*下*箭头可以帮助你选择不同的单元格并滚动浏览笔记本。如果在命令模式下按下*y*键，选中的单元格会变为**代码单元格**，其中的文本会被解释为代码。按下*m*键会将其变为**Markdown单元格**，在其中你可以编写格式化文本。按下*Shift*
    + *Enter*会执行该单元格，呈现Markdown或执行代码，具体取决于情况。在接下来的练习中，你将通过Jupyter笔记本进行一些实践。
- en: Our first task in our first Jupyter notebook will be to load the case study
    data. To do this, we will use a tool called **pandas**. It is probably not a stretch
    to say that pandas is the pre-eminent data-wrangling tool in Python.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们第一个 Jupyter notebook 中的第一个任务是加载案例研究数据。为此，我们将使用一个名为 **pandas** 的工具。毫不夸张地说，pandas
    可能是 Python 中最优秀的数据处理工具。
- en: A DataFrame is a foundational class in pandas. We'll talk more about what a
    class is later, but you can think of it as a template for a data structure, where
    a data structure is something like the lists or dictionaries we discussed earlier.
    However, a DataFrame is much richer in functionality than either of these. A DataFrame
    is similar to spreadsheets in many ways. There are rows, which are labeled by
    a row index, and columns, which are usually given column header-like labels that
    can be thought of as a column index. `Index` is, in fact, a data type in pandas
    used to store indices for a DataFrame, and columns have their own data type called
    `Series`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 是 pandas 中的一个基础类。我们稍后会讨论类是什么，但你可以将其看作数据结构的模板，其中数据结构类似于我们之前讨论的列表或字典。然而，DataFrame
    的功能比这两者都要强大得多。DataFrame 在许多方面类似于电子表格。它有行，这些行通过行索引进行标记；它还有列，通常会有类似列头的标签，可以被看作列索引。`Index`
    实际上是 pandas 中用来存储 DataFrame 索引的数据类型，而列则有自己的数据类型，称为 `Series`。
- en: 'You can do a lot of the same things with a DataFrame that you can do with Excel
    sheets, such as creating pivot tables and filtering rows. pandas also includes
    SQL-like functionality. You can join different DataFrames together, for example.
    Another advantage of DataFrames is that once your data is contained in one of
    them, you have the capabilities of a wealth of pandas functionality at your fingertips,
    for data analysis. The following figure is an example of a pandas DataFrame:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DataFrame，你可以做很多与 Excel 表格相同的操作，比如创建数据透视表和筛选行。pandas 还包含类似 SQL 的功能。例如，你可以将不同的
    DataFrame 合并在一起。DataFrame 的另一个优点是，一旦你的数据被包含在其中，你就可以随时使用 pandas 提供的强大功能进行数据分析。下图是一个
    pandas DataFrame 的示例：
- en: '![Figure 1.9: Example of a pandas DataFrame with an integer row index at the
    left and a column index of strings'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.9：带有整数行索引在左侧、字符串列索引的 pandas DataFrame 示例'
- en: '](img/B16925_01_09.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_09.jpg)'
- en: 'Figure 1.9: Example of a pandas DataFrame with an integer row index at the
    left and a column index of strings'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9：带有整数行索引在左侧、字符串列索引的 pandas DataFrame 示例
- en: The example in *Figure 1.9* is in fact the data for the case study. As the first
    step with Jupyter and pandas, we will now see how to create a Jupyter notebook
    and load data with pandas. There are several convenient functions you can use
    in pandas to explore your data, including `.head()` to see the first few rows
    of the DataFrame, `.info()` to see all columns with datatypes, `.columns` to return
    a list of column names as strings, and others we will learn about in the following
    exercises.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.9* 中的示例实际上就是案例研究的数据。作为使用 Jupyter 和 pandas 的第一步，我们现在将展示如何创建一个 Jupyter notebook
    并使用 pandas 加载数据。在 pandas 中，你可以使用几个方便的函数来探索数据，包括 `.head()` 查看 DataFrame 的前几行，`.info()`
    查看所有列的数据类型，`.columns` 返回列名的字符串列表，等等，我们将在接下来的练习中学习这些函数。'
- en: 'Exercise 1.02: Loading the Case Study Data in a Jupyter Notebook'
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.02：在 Jupyter Notebook 中加载案例研究数据
- en: 'Now that you''ve learned about Jupyter notebooks, the environment in which
    we''ll write code, and pandas, the data wrangling package, let''s create our first
    Jupyter notebook. We''ll use pandas within this notebook to load the case study
    data and briefly examine it. Perform the following steps to complete the exercise:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了 Jupyter notebooks——我们将编写代码的环境，和 pandas——数据处理包，让我们来创建第一个 Jupyter notebook。在这个
    notebook 中，我们将使用 pandas 加载案例研究数据，并对其进行简单的检查。请按照以下步骤完成练习：
- en: Note
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The Jupyter notebook for this exercise can be found at [https://packt.link/GHPSn](https://packt.link/GHPSn).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的 Jupyter notebook 可以在 [https://packt.link/GHPSn](https://packt.link/GHPSn)
    找到。
- en: Open a Terminal (macOS or Linux) or a Command Prompt window (Windows) and type
    `jupyter notebook` (first activating your Anaconda environment if you're using
    one).
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端（macOS 或 Linux）或命令提示符窗口（Windows），然后输入 `jupyter notebook`（如果你使用的是 Anaconda
    环境，请先激活环境）。
- en: You will be presented with the Jupyter interface in your web browser. If the
    browser does not open automatically, copy and paste the URL from the Terminal
    into your browser. In this interface, you can navigate around your directories
    starting from the directory you were in when you launched the notebook server.
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您将在浏览器中看到 Jupyter 界面。如果浏览器没有自动打开，您可以将终端中的 URL 复制并粘贴到浏览器中。在此界面中，您可以从启动笔记本服务器时所在的目录开始浏览您的文件夹。
- en: 'Navigate to a convenient location where you will store the materials for this
    book, and create a new Python 3 notebook from the **New** menu, as shown here:![Figure
    1.10: Jupyter home screen'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到您将存储本书材料的方便位置，然后从 **New** 菜单创建一个新的 Python 3 笔记本，如下所示：![图 1.10：Jupyter 首页
- en: '](img/B16925_01_10.jpg)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_10.jpg)'
- en: 'Figure 1.10: Jupyter home screen'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.10：Jupyter 首页
- en: Make your very first cell a Markdown cell by typing *m* while in command mode
    (press *Esc* to enter command mode), then type a number sign, `#`, at the beginning
    of the first line, followed by a space, for a heading. Add a title for your notebook
    here. On the next few lines, place a description.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在命令模式下（按 *Esc* 进入命令模式）通过输入 *m* 来将您的第一个单元格设置为 Markdown 单元格，然后在第一行的开头输入一个井号 `#`，后面加一个空格，以设置标题。为您的笔记本添加标题。接下来的几行，输入描述。
- en: 'Here is a screenshot of an example, including other kinds of Markdown such
    as bold, italics, and the way to write code-style text in a Markdown cell:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是一个示例的截图，展示了其他类型的 Markdown 语法，如粗体、斜体，以及如何在 Markdown 单元格中书写代码风格的文本：
- en: '![Figure 1.11: Unrendered Markdown cell'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.11：未渲染的 Markdown 单元格'
- en: '](img/B16925_01_11.jpg)'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_11.jpg)'
- en: 'Figure 1.11: Unrendered Markdown cell'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.11：未渲染的 Markdown 单元格
- en: Note that it is good practice to add a title and brief description for your
    notebook, to identify its purpose to readers.
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，良好的实践是为您的笔记本添加标题和简短的描述，以便读者了解其目的。
- en: Press *Shift* + *Enter* to render the Markdown cell.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按 *Shift* + *Enter* 来渲染 Markdown 单元格。
- en: This should also create a new cell, which will be a code cell. You can change
    it to a Markdown cell by pressing *m*, and back to a code cell by pressing *y*.
    You will know it's a code cell because of the `In [ ]:` next to it.
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这也应该会创建一个新的单元格，它将是一个代码单元格。您可以通过按 *m* 将其更改为 Markdown 单元格，通过按 *y* 恢复为代码单元格。您可以通过旁边的
    `In [ ]:` 来判断它是代码单元格。
- en: 'Type `import` `pandas` `as` `pd` in the new cell, as shown in the following screenshot:![Figure
    1.12: Rendered Markdown cell and code cell'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新单元格中输入 `import` `pandas` `as` `pd`，如下所示的截图所示：![图 1.12：渲染后的 Markdown 单元格和代码单元格
- en: '](img/B16925_01_12.jpg)'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_12.jpg)'
- en: 'Figure 1.12: Rendered Markdown cell and code cell'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.12：渲染后的 Markdown 单元格和代码单元格
- en: After you execute this cell, the `pandas` module will be loaded into your computing
    environment. It's common to import modules with `as` to create a short alias such
    as `pd`. Now, we are going to use pandas to load the data file. It's in Microsoft
    Excel format, so we can use `pd.read_excel`.
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 执行此单元格后，`pandas` 模块将被加载到您的计算环境中。通常，我们会使用 `as` 来导入模块，并为其创建一个简短的别名，比如 `pd`。现在，我们将使用
    pandas 加载数据文件。该文件是 Microsoft Excel 格式，因此我们可以使用 `pd.read_excel`。
- en: Note
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: 'For more information on all the possible options for `pd.read_excel`, refer
    to the following documentation: [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html).'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 若要了解 `pd.read_excel` 的所有可能选项，请参考以下文档：[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)。
- en: 'Import the dataset, which is in the Excel format, as a DataFrame using the
    `pd.read_excel()` method, as shown in the following snippet:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pd.read_excel()` 方法将数据集（Excel 格式）作为 DataFrame 导入，如下所示的代码片段：
- en: '[PRE8]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that you need to point the Excel reader to wherever the file is located.
    If it's in the same directory as your notebook, you could just enter the filename.
    The `pd.read_excel` method will load the Excel file into a `DataFrame`, which
    we've called `df`. By default, the first sheet of the spreadsheet is loaded, which
    in this case is the only sheet. The power of pandas is now available to us.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，您需要指定 Excel 文件所在的位置。如果文件与您的笔记本在同一目录下，您可以只输入文件名。`pd.read_excel` 方法会将 Excel
    文件加载到一个 `DataFrame` 中，我们将其命名为 `df`。默认情况下，电子表格的第一张表单会被加载，而在此情况下，只有这一张表单。现在我们可以使用
    pandas 的强大功能了。
- en: Let's do some quick checks in the next few steps. First, does the number of
    rows and columns match what we know from looking at the file in Excel?
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们在接下来的几个步骤中进行一些快速检查。首先，行数和列数是否与我们在 Excel 中查看文件时看到的一致？
- en: 'Use the `.shape` method to review the number of rows and columns, as shown
    in the following snippet:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.shape` 方法查看行列的数量，如以下代码片段所示：
- en: '[PRE9]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once you run the cell, you will obtain the following output:'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦运行该单元格，你将得到以下输出：
- en: '[PRE10]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This should match your observations from the spreadsheet. If it doesn't, you
    would then need to look into the various options of `pd.read_excel` to see if
    you needed to adjust something.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这应该与你在电子表格中的观察一致。如果不一致，你就需要查看 `pd.read_excel` 的各种选项，看看是否需要调整什么。
- en: With this exercise, we have successfully loaded our dataset into the Jupyter
    notebook. You may also wish to try the `.info()` and `.head()` methods on the
    DataFrame, which will tell you information about all the columns, and show you
    the first few rows of the `DataFrame`, respectively. Now you're up and running
    with your data in pandas.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个练习，我们成功地将数据集加载到 Jupyter 笔记本中。你还可以尝试对 DataFrame 使用 `.info()` 和 `.head()`
    方法，分别查看所有列的信息，并显示 DataFrame 的前几行。现在你已经能够开始使用 pandas 处理数据了。
- en: 'As a final note, while this may already be clear, observe that if you define
    a variable in one code cell, it is available to you in other code cells within
    the notebook. This is because the code cells within a notebook are said to share
    **scope** as long as the notebook is running, as shown in the following screenshot:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，虽然这可能已经很清楚了，但请注意，如果你在一个代码单元中定义了一个变量，它在笔记本中的其他代码单元也可以使用。这是因为，只要笔记本在运行，笔记本中的代码单元被认为共享**作用域**，如下面的截图所示：
- en: '![Figure 1.13: Variable in scope between cells'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.13：单元格之间的变量作用域'
- en: '](img/B16925_01_13.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_13.jpg)'
- en: 'Figure 1.13: Variable in scope between cells'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13：单元格之间的变量作用域
- en: 'Every time you launch a Jupyter notebook, while the code and markdown cells
    are saved from your previous work, the environment starts fresh and you will need
    to reload all modules and data to start working with them again. You can also
    shut down or restart the notebook manually using the **Kernel** menu of the notebook.
    More details on Jupyter notebooks can be found in the documentation here: [https://jupyter-notebook.readthedocs.io/en/stable/](https://jupyter-notebook.readthedocs.io/en/stable/).'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 每次启动 Jupyter 笔记本时，尽管代码和 Markdown 单元格会保存你之前的工作，但环境会重新初始化，你需要重新加载所有模块和数据才能继续工作。你也可以使用笔记本中的**内核**菜单手动关闭或重启笔记本。关于
    Jupyter 笔记本的更多细节可以在这里找到：[https://jupyter-notebook.readthedocs.io/en/stable/](https://jupyter-notebook.readthedocs.io/en/stable/)。
- en: note
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: 'In this book, each new exercise and activity will be done in a new Jupyter
    notebook. However, some exercise notebooks also contain additional Python code
    and outputs presented in the sections preceding the exercises. There are also
    reference notebooks that contain the entirety of each chapter. For example, the
    notebook for *Chapter 1*, *Data Exploration and Cleaning*, can be found here:
    [https://packt.link/zwofX](https://packt.link/zwofX).'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，每个新的练习和活动都会在一个新的 Jupyter 笔记本中完成。然而，一些练习笔记本也包含在练习前的部分中展示的额外 Python 代码和输出。还有一些参考笔记本包含了每个章节的全部内容。例如，*第一章*《数据探索与清洗》的笔记本可以在这里找到：[https://packt.link/zwofX](https://packt.link/zwofX)。
- en: Getting Familiar with Data and Performing Data Cleaning
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 熟悉数据并进行数据清洗
- en: 'Now let''s take a first look at this data. In your work as a data scientist,
    there are several possible scenarios in which you may receive such a dataset.
    These include the following:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们初步查看一下这些数据。在你的数据科学家工作中，你可能会遇到几种收到这样的数据集的情况。包括以下几种：
- en: You created the SQL query that generated the data.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你创建了生成数据的 SQL 查询。
- en: A colleague wrote a SQL query for you, with your input.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一位同事根据你的意见为你写了一个 SQL 查询。
- en: A colleague who knows about the data gave it to you, but without your input.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一位了解数据的同事把它交给了你，但没有征求你的意见。
- en: You are given a dataset about which little is known.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你得到一个对数据了解不多的数据集。
- en: In cases 1 and 2, your input was involved in generating/extracting the data.
    In these scenarios, you probably understood the business problem and then either
    found the data you needed with the help of a data engineer or did your own research
    and designed the SQL query that generated the data. Often, especially as you gain
    more experience in your data science role, the first step will be to meet with
    the business partner to understand and refine the mathematical definition of the
    business problem. Then, you would play a key role in defining what is in the dataset.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1和第2种情况下，你的输入参与了数据的生成/提取。在这些场景中，你可能理解了商业问题，然后在数据工程师的帮助下找到所需的数据，或者自己做研究并设计了生成数据的SQL查询。通常，尤其是随着你在数据科学角色上经验的积累，第一步会是与商业合作伙伴会面，理解并完善商业问题的数学定义。然后，你将在定义数据集内容中发挥关键作用。
- en: Even if you have a relatively high level of familiarity with the data, doing
    data exploration and looking at **summary statistics** of different variables
    is still an important first step. This step will help you select good features,
    or give you ideas about how you can engineer new features. However, in the third
    and fourth cases, where your input was not involved or you have little knowledge
    about the data, data exploration is even more important.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你对数据有相对较高的熟悉度，进行数据探索并查看不同变量的**汇总统计**仍然是一个重要的第一步。这个步骤将帮助你选择好的特征，或者给你一些如何构建新特征的思路。然而，在第三和第四种情况中，如果你的输入没有涉及或者你对数据了解较少，数据探索就显得更加重要。
- en: Another important initial step in the data science process is examining the
    **data dictionary**. A data dictionary is a document that explains what the data
    owner thinks should be in the data, such as definitions of the column labels.
    It is the data scientist's job to go through the data carefully to make sure that
    these definitions match the reality of what is in the data. In cases 1 and 2,
    you will probably need to create the data dictionary yourself, which should be
    considered essential project documentation. In cases 3 and 4, you should seek
    out the dictionary if at all possible.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学过程中的另一个重要初步步骤是检查**数据字典**。数据字典是一个文档，解释了数据拥有者认为数据中应该包含的内容，比如列标签的定义。数据科学家的职责是仔细审查数据，确保这些定义与数据实际内容一致。在第1和第2种情况下，你可能需要自己创建数据字典，这应该视为重要的项目文档。在第3和第4种情况下，你应该尽可能寻找数据字典。
- en: The case study data we'll use in this book is similar to case 3 here.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中我们将使用的案例研究数据类似于此处的第3种情况。
- en: The Business Problem
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 商业问题
- en: Our client is a credit card company. They have brought us a dataset that includes
    some demographics and recent financial data, over the past 6 months, for a sample
    of 30,000 of their account holders. This data is at the credit account level;
    in other words, there is one row for each account (you should always clarify what
    the definition of a row is, in a dataset). Rows are labeled by whether, in the
    next month after the 6-month historical data period, an account owner has defaulted,
    or in other words, failed to make the minimum payment.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的客户是一家信用卡公司。他们为我们提供了一个数据集，包含过去6个月内约30,000名账户持有人的一些人口统计信息和近期财务数据。该数据集是在信用账户级别的；换句话说，每一行代表一个账户（你应始终明确数据集中的每一行的定义）。每一行会标注账户所有者是否在6个月历史数据期之后的下一个月违约，或者换句话说，未能按时支付最低款项。
- en: '**Goal**'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标**'
- en: Your goal is to develop a predictive model for whether an account will default
    next month, given demographics and historical data. Later in the book, we'll discuss
    the practical application of the model.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你的目标是根据人口统计信息和历史数据，开发一个预测模型，预测账户下个月是否会违约。在本书后续部分，我们将讨论该模型的实际应用。
- en: 'The data is already prepared, and a data dictionary is available. The dataset
    supplied with the book, `default_of_credit_card_clients__courseware_version_1_21_19.xls`,
    is a modified version of this dataset in the UCI Machine Learning Repository:
    [https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients).
    Have a look at that web page, which includes the data dictionary.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 数据已经准备好，并且提供了数据字典。本书附带的数据集`default_of_credit_card_clients__courseware_version_1_21_19.xls`是UCI机器学习库中该数据集的修改版：[https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)。请查看该网页，其中包含数据字典。
- en: Data Exploration Steps
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据探索步骤
- en: 'Now that we''ve understood the business problem and have an idea of what is
    supposed to be in the data, we can compare these impressions to what we actually
    see in the data. Your job in data exploration is to not only look through the
    data both directly and using numerical and graphical summaries but also to think
    critically about whether the data make sense and match what you have been told
    about it. These are helpful steps in data exploration:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了业务问题，并对数据中应该包含的内容有了大致了解，我们可以将这些印象与实际数据进行对比。你在数据探索中的任务，不仅是通过直接查看数据以及使用数值和图形摘要来了解数据，还要批判性地思考这些数据是否合理，并与所提供的信息相匹配。这些都是数据探索中的有用步骤：
- en: How many columns are there in the data?
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据中有多少列？
- en: These may be features, responses, or metadata.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些可能是特征、响应或元数据。
- en: How many rows (samples) are there?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据中有多少行（样本）？
- en: What kind of features are there? Which are **categorical** and which are **numerical**?
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有哪些特征？哪些是**类别型**的，哪些是**数值型**的？
- en: Categorical features have values in discrete classes such as "Yes," "No," or "Maybe."
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类别特征的值属于离散的类别，例如“是”、“否”或“也许”。
- en: Numerical features are typically on a continuous numerical scale, such as dollar amounts.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数值特征通常是连续的数值尺度，比如美元金额。
- en: What does the data look like in these features?
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些特征中的数据看起来如何？
- en: To see this, you can examine the range of values in numeric features, or the
    frequency of different classes in categorical features, for example.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了查看这一点，你可以检查数值特征的值范围，或类别特征中不同类别的频率，例如。
- en: Is there any missing data?
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有没有缺失的数据？
- en: We have already answered questions 1 and 2 in the previous section; there are
    30,000 rows and 25 columns. As we start to explore the rest of these questions
    in the following exercise, pandas will be our go-to tool. We begin by verifying
    basic data integrity in the next exercise.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节已经回答了问题1和2；数据中有30,000行和25列。当我们在接下来的练习中开始探索其余问题时，pandas将是我们的首选工具。我们从验证基本数据完整性开始，进入下一个练习。
- en: Note
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Note that compared to the website's description of the data dictionary, `X6`-`X11`
    are called `PAY_1`-`PAY_6` in our data. Similarly, `X12`-`X17` are `BILL_AMT1`-`BILL_AMT6`,
    and `X18`-`X23` are `PAY_AMT1`-`PAY_AMT6`.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，与网站描述的数据字典相比，我们数据中的`X6`-`X11`被称为`PAY_1`-`PAY_6`。类似地，`X12`-`X17`对应的是`BILL_AMT1`-`BILL_AMT6`，而`X18`-`X23`则是`PAY_AMT1`-`PAY_AMT6`。
- en: 'Exercise 1.03: Verifying Basic Data Integrity'
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.03：验证基本数据完整性
- en: In this exercise, we will perform a basic check on whether our dataset contains
    what we expect and verify whether there is the correct number of samples.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将进行基本的检查，验证我们的数据集是否包含我们所期望的内容，并检查样本数量是否正确。
- en: The data is supposed to have observations for 30,000 credit accounts. While
    there are 30,000 rows, we should also check whether there are 30,000 unique account
    IDs. It's possible that, if the SQL query used to generate the data was run on
    an unfamiliar schema, values that are supposed to be unique are in fact not unique.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 数据应该包含30,000个信用账户的观察数据。虽然有30,000行数据，但我们还应该检查是否有30,000个唯一账户ID。如果生成数据的SQL查询是在一个不熟悉的架构下运行的，那么本应唯一的值可能实际上并不唯一。
- en: 'To examine this, we can check if the number of unique account IDs is the same
    as the number of rows. Perform the following steps to complete the exercise:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查这一点，我们可以检查唯一账户ID的数量是否与行数相同。按照以下步骤完成练习：
- en: Note
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Jupyter notebook for this exercise can be found here: [https://packt.link/EapDM](https://packt.link/EapDM).'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习的Jupyter笔记本可以在这里找到：[https://packt.link/EapDM](https://packt.link/EapDM)。
- en: 'Import pandas, load the data, and examine the column names by running the following
    command in a cell, using *Shift* + *Enter*:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入pandas，加载数据，并运行以下命令检查列名，使用*Shift* + *Enter*：
- en: '[PRE11]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The `.columns` method of the DataFrame is employed to examine all the column
    names. You will obtain the following output once you run the cell:'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DataFrame的`.columns`方法用于检查所有列名。运行单元格后，你将得到以下输出：
- en: '![Figure 1.14: Columns of the dataset'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.14：数据集的列'
- en: '](img/B16925_01_14.jpg)'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_14.jpg)'
- en: 'Figure 1.14: Columns of the dataset'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.14：数据集的列
- en: 'As can be observed, all column names are listed in the output. The account
    ID column is referenced as `ID`. The remaining columns appear to be our features,
    with the last column being the response variable. Let''s quickly review the dataset
    information that was given to us by the client:'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如可以观察到，所有列名都列出了。账户 ID 列被标记为 `ID`。其余列似乎是我们的特征，最后一列是响应变量。让我们快速回顾一下客户提供的数据集信息：
- en: '`LIMIT_BAL`: Amount of credit provided (in New Taiwanese (NT) dollar) including
    individual consumer credit and the family (supplementary) credit.'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`LIMIT_BAL`: 提供的信用额度（以新台币为单位），包括个人消费信用和家庭（附加）信用。'
- en: '`SEX`: Gender (1 = male; 2 = female).'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`SEX`: 性别 (1 = 男性；2 = 女性)。'
- en: Note
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: We will not be using the gender data to decide credit-worthiness owing to ethical
    considerations.
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 出于伦理考虑，我们不会使用性别数据来决定信用评级。
- en: '`EDUCATION`: Education (1 = graduate school; 2 = university; 3 = high school;
    4 = others).'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`EDUCATION`: 教育水平 (1 = 研究生; 2 = 大学; 3 = 高中; 4 = 其他)。'
- en: '`MARRIAGE`: Marital status (1 = married; 2 = single; 3 = others).'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`MARRIAGE`: 婚姻状况 (1 = 已婚；2 = 单身；3 = 其他)。'
- en: '`AGE`: Age (year).'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`AGE`: 年龄（岁）。'
- en: '`PAY_1`–`PAY_6`: A record of past payments. Past monthly payments, recorded
    from April to September, are stored in these columns.'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`PAY_1`–`PAY_6`: 过去付款记录。记录从 4 月到 9 月的每月付款，这些数据存储在这些列中。'
- en: '`PAY_1` represents the repayment status in September; `PAY_2` is the repayment
    status in August; and so on up to `PAY_6`, which represents the repayment status
    in April.'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`PAY_1` 代表 9 月的还款状态；`PAY_2` 是 8 月的还款状态；依此类推，直到 `PAY_6`，代表 4 月的还款状态。'
- en: 'The measurement scale for the repayment status is as follows: -1 = pay duly;
    1 = payment delay for 1 month; 2 = payment delay for 2 months; and so on up to
    8 = payment delay for 8 months; 9 = payment delay for 9 months and above.'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 还款状态的测量尺度如下：-1 = 按时支付；1 = 延迟支付 1 个月；2 = 延迟支付 2 个月；依此类推，直到 8 = 延迟支付 8 个月；9 =
    延迟支付 9 个月及以上。
- en: '`BILL_AMT1`–`BILL_AMT6`: Bill statement amount (in NT dollar).'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`BILL_AMT1`–`BILL_AMT6`: 账单金额（新台币）。'
- en: '`BILL_AMT1` represents the bill statement amount in September; `BILL_AMT2`
    represents the bill statement amount in August; and so on up to `BILL_AMT6`, which
    represents the bill statement amount in April.'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`BILL_AMT1` 代表 9 月的账单金额；`BILL_AMT2` 代表 8 月的账单金额；依此类推，直到 `BILL_AMT6`，代表 4 月的账单金额。'
- en: '`PAY_AMT1`–`PAY_AMT6`: Amount of previous payment (NT dollar). `PAY_AMT1` represents
    the amount paid in September; `PAY_AMT2` represents the amount paid in August;
    and so on up to `PAY_AMT6`, which represents the amount paid in April.'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`PAY_AMT1`–`PAY_AMT6`: 之前的付款金额（新台币）。`PAY_AMT1` 代表 9 月的支付金额；`PAY_AMT2` 代表 8
    月的支付金额；依此类推，直到 `PAY_AMT6`，代表 4 月的支付金额。'
- en: Let's now use the `.head()` method in the next step to observe the first few
    rows of data. By default, this will return the first 5 rows.
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们在下一步中使用 `.head()` 方法查看数据的前几行。默认情况下，这将返回前 5 行数据。
- en: 'Run the following command in the subsequent cell:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在随后的单元格中运行以下命令：
- en: '[PRE12]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is a portion of the output you should see:'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是你应该看到的输出的一部分：
- en: '![Figure 1.15: .head() of a DataFrame'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.15：DataFrame 的 .head() 方法'
- en: '](img/B16925_01_15.jpg)'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_15.jpg)'
- en: 'Figure 1.15: .head() of a DataFrame'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.15：DataFrame 的 .head() 方法
- en: The ID column seems like it contains unique identifiers. Now, to verify whether
    they are in fact unique throughout the whole dataset, we can count the number
    of unique values using the `.nunique()` method on the Series (aka column) `ID`.
    We first select the column using square brackets.
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ID 列似乎包含唯一标识符。现在，为了验证它们是否确实在整个数据集中是唯一的，我们可以使用 `.nunique()` 方法计算 `ID` 列（即 Series）的唯一值数量。我们首先使用方括号选择该列。
- en: 'Select the column (`ID`) and count unique values using the following command:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择列（`ID`）并使用以下命令计算唯一值：
- en: '[PRE13]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here''s the output:'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE14]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As can be seen from the preceding output, the number of unique entries is `29,687`.
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从前面的输出可以看出，唯一条目的数量是 `29,687`。
- en: 'Run the following command to obtain the number of rows in the dataset:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令以获取数据集中的行数：
- en: '[PRE15]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As can be observed in the following output, the total number of rows in the
    dataset is `30,000`:'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如下输出所示，数据集的总行数为 `30,000`：
- en: '[PRE16]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We see here that the number of unique IDs is less than the number of rows. This
    implies that the ID is not a unique identifier for the rows of the data. So we
    know that there is some duplication of IDs. But how much? Is one ID duplicated
    many times? How many IDs are duplicated?
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们看到这里的唯一ID数少于行数。这意味着ID不是数据行的唯一标识符。所以我们知道ID有重复。那么重复的程度如何？某个ID是否重复多次？有多少个ID是重复的？
- en: We can use the `.value_counts()` method on the ID Series to start to answer
    these questions. This is similar to a `id_counts` variable.
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以在ID Series上使用`.value_counts()`方法来开始回答这些问题。这类似于一个`id_counts`变量。
- en: 'Store the value counts in the variable defined as `id_counts` and then display
    the stored values using the `.head()` method, as shown:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将值计数存储在定义为`id_counts`的变量中，然后使用`.head()`方法显示存储的值，如下所示：
- en: '[PRE17]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You will obtain the following output:'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将获得以下输出：
- en: '![Figure 1.16: Getting value counts of the account IDs'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.16：获取账户ID的值计数'
- en: '](img/B16925_01_16.jpg)'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_16.jpg)'
- en: 'Figure 1.16: Getting value counts of the account IDs'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.16：获取账户ID的值计数
- en: Note that `.head()` returns the first five rows by default. You can specify
    the number of items to be displayed by passing the required number in the parentheses,
    `()`.
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，`.head()`默认返回前五行。你可以通过在括号`()`中传入所需的数字来指定显示的条目数。
- en: 'Display the number of duplicated entries by running another value count:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行另一个值计数来显示重复条目的数量：
- en: '[PRE18]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You will obtain the following output:'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将获得以下输出：
- en: '![Figure 1.17: Getting value counts of the account IDs'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.17：获取账户ID的值计数'
- en: '](img/B16925_01_17.jpg)'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_17.jpg)'
- en: 'Figure 1.17: Getting value counts of the account IDs'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.17：获取账户ID的值计数
- en: Here, we can see that most IDs occur exactly once, as expected. However, 313
    IDs occur twice. So, no ID occurs more than twice. With this information, we are
    ready to begin taking a closer look at this data quality issue and go about fixing
    it. We will create Boolean masks to do this.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到大多数ID都恰好出现一次，正如预期的那样。然而，313个ID出现了两次。所以，没有任何ID出现超过两次。有了这些信息，我们可以开始仔细查看这个数据质量问题，并着手修复它。我们将创建布尔掩码来实现这一点。
- en: Boolean Masks
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 布尔掩码
- en: 'To help clean the case study data, we introduce the concept of a `==`, to find
    all locations of an array that contain a certain value. Other comparisons, such
    as "greater than" (`>`), "less than" (`<`), "greater than or equal to" (`>=`),
    and "less than or equal to" (`<=`), can be used similarly. The output of such
    a comparison is an array or Series of `True/False` values, also known as `True`
    if the condition is met, and is `False` otherwise. To illustrate how this works,
    we will use `np`. We''ll also import the default random number generator from
    the random module within NumPy:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助清理案例研究数据，我们引入了`==`的概念，用来查找数组中包含某个特定值的位置。其他比较方式，如“大于” (`>`)、 “小于” (`<`)、
    “大于或等于” (`>=`)、 “小于或等于” (`<=`)，也可以类似使用。此类比较的输出是一个`True/False`值的数组或Series，如果条件成立，则为`True`，否则为`False`。为了说明其工作原理，我们将使用`np`。我们还将从NumPy中的random模块导入默认的随机数生成器：
- en: '[PRE19]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now we use what''s called a `12345`:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用所谓的`12345`：
- en: '[PRE20]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next, we generate 100 random integers, using the `integers` method of `rg`,
    with the appropriate arguments. We generate integers from between 1 and 4\. Note
    the `high` argument specifies an open endpoint by default, that is, the upper
    limit of the range is not included:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`rg`的`integers`方法生成100个随机整数，传入合适的参数。我们生成的整数范围为1到4之间。请注意，`high`参数默认指定的是开区间，即范围的上限不包含在内：
- en: '[PRE21]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s look at the first five elements of this array, with `random_integers[:5]`.
    The output should appear as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下该数组的前五个元素，使用`random_integers[:5]`。输出应该如下所示：
- en: '[PRE22]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Suppose we wanted to know the locations of all elements of `random_integers`
    equal to 3\. We could create a Boolean mask to do this:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想知道`random_integers`中所有等于3的元素的位置。我们可以创建一个布尔掩码来实现：
- en: '[PRE23]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: From examining the first 5 elements, we know the first element is equal to 3,
    but none of the rest are. So in our Boolean mask, we expect `True` in the first
    position and `False` in the next 4 positions. Is this the case?
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查前五个元素，我们知道第一个元素等于3，但其余的都不等于。所以在我们的布尔掩码中，我们期望第一个位置为`True`，接下来的四个位置为`False`。这是对的吗？
- en: '[PRE24]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The preceding code should give this output:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码应当给出以下输出：
- en: '[PRE25]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This is what we expected. This shows the creation of a Boolean mask. But what
    else can we do with them? Suppose we wanted to know how many elements were equal
    to 3\. To know this, you can take the sum of a Boolean mask, which interprets
    `True` as 1 and `False` as 0:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们所期待的。这显示了布尔掩码的创建。但我们还可以用它们做什么呢？假设我们想知道有多少个元素等于 3。为了知道这一点，你可以对布尔掩码进行求和，它将
    `True` 解释为 1，将 `False` 解释为 0：
- en: '[PRE26]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This should give us the following output:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们以下输出：
- en: '[PRE27]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This makes sense, as with a random, equally likely choice of 4 possible values,
    we would expect each value to appear about 25% of the time. In addition to seeing
    how many values in the array meet the Boolean condition, we can also use the Boolean
    mask to select the elements of the array that meet that condition. Boolean masks
    can be used directly to index arrays, as shown here:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这很有道理，因为在一个随机、每个值等可能的 4 个值中，我们会预期每个值大约有 25% 的概率出现。除了看到数组中有多少个值符合布尔条件外，我们还可以使用布尔掩码选择数组中符合该条件的元素。布尔掩码可以直接用于索引数组，正如下面所示：
- en: '[PRE28]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This outputs the elements of `random_integers` meeting the Boolean condition
    we specified. In this case, the 31 elements equal to 3:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出符合我们指定的布尔条件的 `random_integers` 数组元素。在这个例子中，31 个等于 3 的元素：
- en: '![Figure 1.18: Using the Boolean mask to index an array'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.18：使用布尔掩码索引数组'
- en: '](img/B16925_01_18.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_18.jpg)'
- en: 'Figure 1.18: Using the Boolean mask to index an array'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.18：使用布尔掩码索引数组
- en: Now you know the basics of Boolean arrays, which are useful in many situations.
    In particular, you can use the `.loc` method of DataFrames to index the rows by
    a Boolean mask, and the columns by label, to get values of various columns meeting
    a condition in a potentially different column. Let's continue exploring the case
    study data with these skills.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经掌握了布尔数组的基础知识，它在许多情况下都非常有用。特别是，你可以使用 DataFrame 的 `.loc` 方法，通过布尔掩码对行进行索引，通过标签对列进行索引，从而获取满足条件的不同列中的值。让我们继续用这些技能探索案例研究数据。
- en: Note
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The Jupyter notebook containing the code and the corresponding outputs presented
    in the preceding section can be found at [https://packt.link/pT9gT](https://packt.link/pT9gT).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 包含前一节中展示的代码和相应输出的 Jupyter notebook 可以在此找到：[https://packt.link/pT9gT](https://packt.link/pT9gT)。
- en: 'Exercise 1.04: Continuing Verification of Data Integrity'
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.04：继续验证数据完整性
- en: 'In this exercise, with our knowledge of Boolean arrays, we will examine some
    of the duplicate IDs we discovered. In *Exercise 03*, *Verifying Basic Data Integrity*,
    we learned that no ID appears more than twice. We can use this learning to locate
    the duplicate IDs and examine them. Then we take action to remove rows of dubious
    quality from the dataset. Perform the following steps to complete the exercise:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，利用我们对布尔数组的了解，我们将检查一些我们发现的重复 ID。在 *练习 03*，*验证基本数据完整性* 中，我们学到没有 ID 出现超过两次。我们可以利用这一点来定位重复的
    ID 并进行检查。然后我们采取措施从数据集中删除质量可疑的行。按照以下步骤完成本次练习：
- en: Note
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Jupyter notebook for this exercise can be found here: [https://packt.link/snAP0](https://packt.link/snAP0).'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 本次练习的 Jupyter notebook 可以在这里找到：[https://packt.link/snAP0](https://packt.link/snAP0)。
- en: 'Continuing where we left off in *Exercise 1.03*, *Verifying Basic Data Integrity*,
    we need to get the locations of the `id_counts` Series, where the count is `2`,
    to locate the duplicates. First, we load the data and get the value counts of
    IDs to bring us to where we left off in *Exercise 03*, *Verifying Basic Data Integrity*,
    then we create a Boolean mask locating the duplicated IDs with a variable called
    `dupe_mask` and display the first five elements. Use the following commands:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续我们在 *练习 1.03*，*验证基本数据完整性* 中的内容，我们需要获取 `id_counts` Series 中计数为 `2` 的位置，以定位重复项。首先，我们加载数据并获取
    ID 的值计数，以便回到 *练习 03*，*验证基本数据完整性* 中的位置，然后我们创建一个布尔掩码，定位重复的 ID，变量名为 `dupe_mask`，并显示前五个元素。使用以下命令：
- en: '[PRE29]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You will obtain the following output (note the ordering of IDs may be different
    in your output, as `value_counts` sorts on frequency, not the index of IDs):'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将得到以下输出（请注意，ID 的排序在你的输出中可能不同，因为 `value_counts` 是按频率排序的，而不是 ID 的索引）：
- en: '![Figure 1.19: A Boolean mask to locate duplicate IDs'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.19：使用布尔掩码定位重复的 ID'
- en: '](img/B16925_01_19.jpg)'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_19.jpg)'
- en: 'Figure 1.19: A Boolean mask to locate duplicate IDs'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.19：使用布尔掩码定位重复的 ID
- en: Note that in the preceding output, we are displaying only the first five entries
    using `dupe_mask` to illustrate the contents of this array. You can edit the integer
    indices in the square brackets (`[]`) to change the number of entries displayed.
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，在上面的输出中，我们仅使用 `dupe_mask` 显示前五个条目，以说明此数组的内容。你可以编辑方括号 (`[]`) 中的整数索引来更改显示的条目数。
- en: Our next step is to use this logical mask to select the IDs that are duplicated.
    The IDs themselves are contained as the index of the `id_count` Series. We can
    access the index in order to use our logical mask for selection purposes.
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下一步是使用此逻辑掩码选择重复的 ID。这些 ID 本身包含在 `id_count` 系列的索引中。我们可以访问该索引，以便使用逻辑掩码进行选择。
- en: 'Access the index of `id_count` and display the first five rows as context using
    the following command:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令访问 `id_count` 的索引，并显示前五行作为上下文：
- en: '[PRE30]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'With this, you will obtain the following output:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这样，你将获得以下输出：
- en: '![Figure 1.20: Duplicated IDs'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.20：重复的 ID'
- en: '](img/B16925_01_20.jpg)'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_20.jpg)'
- en: 'Figure 1.20: Duplicated IDs'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.20：重复的 ID
- en: 'Select and store the duplicated IDs in a new variable called `dupe_ids` using
    the following command:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令选择并将重复的 ID 存储到名为 `dupe_ids` 的新变量中：
- en: '[PRE31]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Convert `dupe_ids` to a list and then obtain the length of the list using the
    following commands:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `dupe_ids` 转换为列表，然后使用以下命令获取该列表的长度：
- en: '[PRE32]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You should obtain the following output:'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该获得以下输出：
- en: '[PRE33]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We changed the `dupe_ids` variable to a `list`, as we will need it in this form
    for future steps. The list has a length of `313`, as can be seen in the preceding
    output, which matches our knowledge of the number of duplicate IDs from the value count.
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将 `dupe_ids` 变量更改为 `list` 类型，因为在未来的步骤中我们将需要它以这种形式。该列表的长度为 `313`，如前面的输出所示，这与我们通过值计数了解到的重复
    ID 数量一致。
- en: 'We verify the data in `dupe_ids` by displaying the first five entries using
    the following command:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过使用以下命令显示前五个条目来验证 `dupe_ids` 中的数据：
- en: '[PRE34]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We obtain the following output:'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们获得了以下输出：
- en: '![Figure 1.21: Making a list of duplicate IDs'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.21：制作重复 ID 列表'
- en: '](img/B16925_01_21.jpg)'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_21.jpg)'
- en: 'Figure 1.21: Making a list of duplicate IDs'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.21：制作重复 ID 列表
- en: We can observe from the preceding output that the list contains the required
    entries of duplicate IDs. We're now in a position to examine the data for the
    IDs in our list of duplicates. In particular, we'd like to look at the values
    of the features, to see what, if anything, might be different between these duplicate
    entries. We will use the `.isin` and `.loc` methods of the DataFrame `df` for
    this purpose.
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以从前面的输出中观察到，列表包含所需的重复 ID 条目。现在我们可以检查这些重复 ID 的数据，特别是我们想查看这些特征的值，看看是否有任何区别。我们将使用
    DataFrame `df` 的 `.isin` 和 `.loc` 方法来实现这一目的。
- en: Using the first three IDs on our list of dupes, `dupe_ids[0:3]`, we will plan
    to first find the rows containing these IDs. If we pass this list of IDs to the
    `.isin` method of the ID Series, this will create another logical mask we can
    use on the larger DataFrame to display the rows that have these IDs. The `.isin`
    method is nested in a `.loc` statement indexing the DataFrame in order to select
    the location of all rows containing `True` in the Boolean mask. The second argument
    of the `.loc` indexing statement is `:`, which implies that all columns will be
    selected. By performing the following steps, we are essentially filtering the
    DataFrame in order to view all the columns for the first three duplicate IDs.
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用我们重复列表中的前三个 ID，`dupe_ids[0:3]`，我们将首先查找包含这些 ID 的行。如果我们将这个 ID 列表传递给 ID 系列的 `.isin`
    方法，它将创建另一个逻辑掩码，我们可以用来在较大的 DataFrame 中显示包含这些 ID 的行。`.isin` 方法嵌套在 `.loc` 语句中，后者用于索引
    DataFrame，以选择所有包含 `True` 的行的位置。`.loc` 索引语句的第二个参数是 `:`, 这意味着选择所有列。通过执行以下步骤，我们实际上是在过滤
    DataFrame，以查看前三个重复 ID 的所有列。
- en: 'Run the following command in your notebook to execute the plan we formulated
    in the previous step:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的笔记本中运行以下命令，以执行我们在上一步中制定的计划：
- en: '[PRE35]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![Figure 1.22: Examining the data for duplicate IDs'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.22：检查重复 ID 的数据'
- en: '](img/B16925_01_22.jpg)'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_22.jpg)'
- en: 'Figure 1.22: Examining the data for duplicate IDs'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.22：检查重复 ID 的数据
- en: What we observe here is that each duplicate ID appears to have one row with
    what seems like valid data, and one row that's entirely zeros. Take a moment and
    think to yourself what you would do with this knowledge.
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在这里观察到，每个重复的 ID 似乎都有一行看起来像有效数据的行，以及一行完全为零的行。花一点时间想一想，你会如何利用这些信息。
- en: After some reflection, it should be clear that you ought to delete the rows
    with all zeros. Perhaps these arose through a faulty join condition in the SQL
    query that generated the data? Regardless, a row of all zeros is definitely invalid
    data as it makes no sense for someone to have an age of 0, a credit limit of 0,
    and so on.
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 经过一番反思，应该很明显，你应该删除所有值为零的行。也许这些行是由于 SQL 查询中的错误连接条件生成的数据？无论如何，一行全为零的数据肯定是无效的，因为一个人的年龄为零，信用额度为零等，显然没有意义。
- en: One approach to deal with this issue would be to find rows that have all zeros,
    except for the first column, which has the IDs. These would be invalid data in
    any case, and it may be that if we get rid of all of these, we would also solve
    our problem of duplicate IDs. We can find the entries of the DataFrame that are
    equal to zero by creating a Boolean matrix that is the same size as the whole
    DataFrame, based on the "is equal to zero" condition.
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解决这个问题的一种方法是找到所有列为零的行，除了第一列（包含 ID）。这些行无论如何都是无效数据，可能如果我们删除这些行，就能解决重复 ID 的问题。我们可以通过创建一个与整个
    DataFrame 大小相同的布尔矩阵，基于“是否等于零”这一条件，来找到 DataFrame 中等于零的条目。
- en: 'Create a Boolean matrix of the same size as the entire DataFrame using `==`,
    as shown:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`==`创建一个与整个 DataFrame 大小相同的布尔矩阵，如下所示：
- en: '[PRE36]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: In the next steps, we'll use `df_zero_mask`, which is another DataFrame containing
    Boolean values. The goal will be to create a Boolean Series, `feature_zero_mask`,
    that identifies every row where all the elements starting from the second column
    (the features and response, but not the IDs) are 0\. To do so, we first need to
    index `df_zero_mask` using the integer indexing (`.iloc`) method. In this method,
    we pass (`:`) to examine all rows and (`1:`) to examine all columns starting with
    the second one (index `1`). Finally, we will apply the `all()` method along the
    column axis (`axis=1`), which will return `True` if and only if every column in
    that row is `True`. This is a lot to think about, but it's pretty simple to code,
    as will be observed in the following step. The goal is to get one Series, that
    is the same length as the DataFrame, telling us which rows have all zeros besides
    the ID.
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将使用`df_zero_mask`，它是另一个包含布尔值的 DataFrame。目标是创建一个布尔系列`feature_zero_mask`，标识出每一行，其中从第二列开始的所有元素（特征和响应，而不是
    ID）都为 0。为此，我们首先需要使用整数索引（`.iloc`）方法对`df_zero_mask`进行索引。在此方法中，我们传递（`:`）来检查所有行，并传递（`1:`）来检查从第二列开始的所有列（索引
    `1`）。最后，我们将在列轴（`axis=1`）上应用`all()`方法，只有当该行的每一列都是`True`时，它才会返回`True`。这个过程需要思考，但编写代码其实很简单，正如接下来的步骤所示。目标是得到一个与
    DataFrame 长度相同的系列，告诉我们哪些行除了 ID 外，所有值都是零。
- en: 'Create the Boolean Series `feature_zero_mask`, as shown in the following code:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建布尔系列`feature_zero_mask`，如以下代码所示：
- en: '[PRE37]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Calculate the sum of the Boolean Series using the following command:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令计算布尔系列的总和：
- en: '[PRE38]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'You should obtain the following output:'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该获得以下输出：
- en: '[PRE39]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The preceding output tells us that 315 rows have zeros for every column but
    the first one. This is greater than the number of duplicate IDs (313), so if we
    delete all the "zero rows," we may get rid of the duplicate ID problem.
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上面的输出告诉我们，315 行除了第一列外每列都是零。这比重复 ID 的数量（313）还多，因此如果我们删除所有“零行”，可能就能解决重复 ID 的问题。
- en: 'Clean the DataFrame by eliminating the rows with all zeros, except for the
    ID, using the following code:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码清理 DataFrame，删除所有除了 ID 之外的值全为零的行：
- en: '[PRE40]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: While performing the cleaning operation in the preceding step, we return a new
    DataFrame called `df_clean_1`. Notice that here we've used the `.copy()` method
    after the `.loc` indexing operation to create a copy of this output, as opposed
    to a view on the original DataFrame. You can think of this as creating a new DataFrame,
    as opposed to referencing the original one. Within the `.loc` method, we used
    the logical not operator, `~`, to select all the rows that don't have zeros for
    all the features and the response variable, and `:` to select all columns. This
    is the valid data we wish to keep. After doing this, we now want to know if the
    number of remaining rows is equal to the number of unique IDs.
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的清理操作中，我们返回了一个新的 DataFrame，名为 `df_clean_1`。请注意，在这里我们在 `.loc` 索引操作后使用了 `.copy()`
    方法来创建该输出的副本，而不是对原始 DataFrame 的视图。你可以把它当作创建一个新的 DataFrame，而不是引用原始的 DataFrame。在
    `.loc` 方法中，我们使用了逻辑非运算符 `~` 来选择所有没有零值的特征和响应变量的行，使用 `:` 来选择所有列。这是我们希望保留的有效数据。做完这个后，我们现在希望知道剩余的行数是否等于唯一
    ID 的数量。
- en: 'Verify the number of rows and columns in `df_clean_1` by running the following
    code:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码，验证 `df_clean_1` 的行数和列数：
- en: '[PRE41]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'You will obtain the following output:'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将得到以下输出：
- en: '[PRE42]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Obtain the number of unique IDs by running the following code:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码获取唯一 ID 的数量：
- en: '[PRE43]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Here''s the output:'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE44]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'From the preceding output, we can see that we have successfully eliminated
    duplicates, as the number of unique IDs is equal to the number of rows. Now take
    a breath and pat yourself on the back. That was a whirlwind introduction to quite
    a few pandas techniques for indexing and characterizing data. Now that we''ve
    filtered out the duplicate IDs, we''re in a position to start looking at the actual
    data itself: the features, and eventually, the response variable.'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从之前的输出中，我们可以看到我们成功地消除了重复项，因为唯一 ID 的数量等于行数。现在，深呼吸一下，拍拍自己背。这是对一些用于索引和表征数据的 pandas
    技巧的快速介绍。现在，我们已经筛选出了重复的 ID，接下来可以开始查看实际的数据：特征，最终是响应变量。
- en: 'After completing this exercise, save your progress as follows, to a CSV (comma-separated
    value) file. Notice we don''t include the index of the DataFrame when saving,
    as this is not necessary and can create extra columns when we load it later:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这个练习后，按以下步骤将进度保存为 CSV（逗号分隔值）文件。请注意，在保存时我们不包括 DataFrame 的索引，因为这不是必需的，而且当我们稍后加载时可能会创建额外的列：
- en: '[PRE45]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Exercise 1.05: Exploring and Cleaning the Data'
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.05：探索和清理数据
- en: 'Thus far, we have identified a data quality issue related to the metadata:
    we had been told that every sample from our dataset corresponded to a unique account
    ID, but found that this was not the case. We were able to use logical indexing
    and pandas to correct this issue. This was a fundamental data quality issue, having
    to do simply with what samples were present, based on the metadata. Aside from
    this, we are not really interested in the metadata column of account IDs: these
    will not help us develop a predictive model for credit default.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经识别出一个与元数据相关的数据质量问题：我们曾被告知数据集中的每个样本都对应一个唯一的账户 ID，但发现事实并非如此。我们能够利用逻辑索引和
    pandas 来纠正这个问题。这是一个基本的数据质量问题，仅涉及基于元数据的样本存在情况。除此之外，我们对账户 ID 的元数据列并不感兴趣：这些列不会帮助我们开发信用违约的预测模型。
- en: 'Now, we are ready to start examining the values of the features and response
    variable, the data we will use to develop our predictive model. Perform the following
    steps to complete this exercise:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备开始检查特征和响应变量的值，这些数据将用于开发我们的预测模型。按照以下步骤完成这个练习：
- en: Note
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Jupyter notebook for this exercise can be found here: [https://packt.link/q0huQ](https://packt.link/q0huQ).'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习的 Jupyter notebook 可以在这里找到：[https://packt.link/q0huQ](https://packt.link/q0huQ)。
- en: 'Load the results of the previous exercise and obtain the data type of the columns
    in the data by using the `.info()` method as shown:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载上一个练习的结果，并通过使用 `.info()` 方法获取数据中各列的数据类型，如下所示：
- en: '[PRE46]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'You should see the following output:'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该看到以下输出：
- en: '![Figure 1.23: Getting column metadata'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.23：获取列元数据'
- en: '](img/B16925_01_23.jpg)'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_23.jpg)'
- en: 'Figure 1.23: Getting column metadata'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.23：获取列元数据
- en: We can see in *Figure 1.23* that there are 25 columns. Each row has 29,685 `int64`
    next to them, indicating they are an `ID` and `PAY_1`. We are already familiar
    with `ID`; this contains strings, which are account IDs. What about `PAY_1`? According
    to the data dictionary, we'd expect this to contain integers, like all the other
    features. Let's take a closer look at this column.
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以从*图 1.23*中看到，数据中有25列。每行旁边都有 29,685 个 `int64`，这表示它们是 `ID` 和 `PAY_1`。我们已经熟悉了
    `ID`；它包含的是字符串，即账户ID。那么 `PAY_1` 呢？根据数据字典，我们可以预期它包含的是整数，就像其他所有特征一样。我们来仔细看看这一列。
- en: 'Use the `.head(n)` pandas method to view the top `n` rows of the `PAY_1` Series:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.head(n)` pandas 方法查看 `PAY_1` 列的前 `n` 行：
- en: '[PRE47]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'You should obtain the following output:'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 1.24: Examine a few columns'' contents'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.24：检查几列的内容'
- en: '](img/B16925_01_24.jpg)'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_24.jpg)'
- en: 'Figure 1.24: Examine a few columns'' contents'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.24：检查几列的内容
- en: 'The integers on the left of the output are the DataFrame index, which is simply
    consecutive integers starting with 0\. The data from the `PAY_1` column is shown
    on the right. This is supposed to be the payment status of the most recent month''s
    bill, using the values –1, 1, 2, 3, and so on. However, we can see that there
    are values of 0 here, which are not documented in the data dictionary. According
    to the data dictionary, *"The measurement scale for the repayment status is: -1
    = pay duly; 1 = payment delay for one month; 2 = payment delay for two months;
    . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and
    above"* ([https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)).
    Let''s take a closer look, using the value counts of this column.'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果左侧的整数是 DataFrame 索引，简单来说就是从 0 开始的连续整数。右侧显示的是 `PAY_1` 列的数据。它本应是最近一个月账单的还款状态，使用的值有
    -1、1、2、3 等等。然而，我们可以看到这里存在值 0，这在数据字典中没有说明。根据数据字典，*“还款状态的测量尺度为：-1 = 按时还款；1 = 逾期一个月；2
    = 逾期两个月；...；8 = 逾期八个月；9 = 逾期九个月及以上”* ([https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients))。我们来仔细看一下，使用该列的值计数。
- en: 'Obtain the value counts for the `PAY_1` column by using the `.value_counts()`
    method:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.value_counts()` 方法获取 `PAY_1` 列的值计数：
- en: '[PRE48]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'You should see the following output:'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该看到以下输出：
- en: '![Figure 1.25: Value counts of the PAY_1 column'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.25：`PAY_1` 列的值计数'
- en: '](img/B16925_01_25.jpg)'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_25.jpg)'
- en: 'Figure 1.25: Value counts of the PAY_1 column'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.25：`PAY_1` 列的值计数
- en: 'The preceding output reveals the presence of two undocumented values: 0 and
    –2, as well as the reason this column was imported by pandas as an `object` data
    type, instead of `int64` as we would expect for integer data: there is a `''Not
    available''` string present in this column, symbolizing missing data. Later on
    in the book, we''ll come back to this when we consider how to deal with missing
    data. For now, we''ll remove rows of the dataset in which this feature has a missing
    value.'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述输出揭示了两个未记录的值：0 和 -2，并且解释了为什么 pandas 将该列导入为 `object` 数据类型，而不是我们预期的 `int64`（整数数据类型）：因为该列中存在
    `'Not available'` 字符串，表示缺失数据。在本书后续的章节中，我们会回到这一点，讨论如何处理缺失数据。目前，我们将删除数据集中包含缺失值的行。
- en: 'Use a logical mask with the `!=` operator (which means "does not equal" in
    Python) to find all the rows that don''t have missing data for the `PAY_1` feature:'
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `!=` 操作符（在 Python 中表示“不等于”）创建一个逻辑掩码，查找所有 `PAY_1` 特征没有缺失数据的行：
- en: '[PRE49]'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'By running the preceding code, you will obtain the following output:'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过运行上面的代码，你将得到以下输出：
- en: '![Figure 1.26: Creating a Boolean mask'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.26：创建布尔掩码'
- en: '](img/B16925_01_26.jpg)'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_26.jpg)'
- en: 'Figure 1.26: Creating a Boolean mask'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.26：创建布尔掩码
- en: 'Check how many rows have no missing data by calculating the sum of the mask:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过计算掩码的和来检查有多少行没有缺失数据：
- en: '[PRE50]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'You will obtain the following output:'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将获得以下输出：
- en: '[PRE51]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: We see that 26,664 rows do not have the value `'Not available'` in the `PAY_1`
    column. We saw from the value count that 3,021 rows do have this value. Does this
    make sense? From *Figure 1.23* we know there are 29,685 entries (rows) in the
    dataset, and 29,685 – 3,021 = 26,664, so this checks out.
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们看到有 26,664 行 `PAY_1` 列没有 `'Not available'` 这个值。从值计数中我们可以看到，有 3,021 行有这个值。这样合理吗？从*图
    1.23*中我们知道数据集中有 29,685 条记录（行），29,685 – 3,021 = 26,664，因此这一结果是正确的。
- en: 'Clean the data by eliminating the rows with the missing values of `PAY_1` as shown:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理数据，删除缺失值的`PAY_1`行，如下所示：
- en: '[PRE52]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Obtain the shape of the cleaned data using the following command:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令获取清理后数据的形状：
- en: '[PRE53]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'You will obtain the following output:'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将得到以下输出：
- en: '[PRE54]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'After removing these rows, we check that the resulting DataFrame has the expected
    shape. You can also check for yourself whether the value counts indicate the desired
    values have been removed like this: `df_clean_2[''PAY_1''].value_counts()`.'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 删除这些行后，我们检查结果 DataFrame 是否具有预期的形状。你还可以自己检查值计数是否表明所需的值已被删除，方法是：`df_clean_2['PAY_1'].value_counts()`。
- en: Lastly, so this column's data type can be consistent with the others, we will
    cast it from the generic `object` type to `int64` like all the other features,
    using the `.astype` method. Then we select a couple of columns, including `PAY_1`,
    to examine the data types and make sure it worked.
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，为了使这一列的数据类型与其他列一致，我们将其从通用的`object`类型转换为`int64`类型，像所有其他特征一样，使用`.astype`方法。然后我们选择几列，包括`PAY_1`，检查数据类型，并确保转换成功。
- en: 'Run the following command to convert the data type for `PAY_1` from `object`
    to `int64` and show the column metadata for `PAY_1` and `PAY_2` by using a list
    to select multiple columns:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令，将`PAY_1`的数据类型从`object`转换为`int64`，并使用列表选择多个列，显示`PAY_1`和`PAY_2`的列元数据：
- en: '[PRE55]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'This is the output you will obtain:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你将得到的输出：
- en: '![Figure 1.27: Check the data type of the cleaned column'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.27：检查已清理列的数据类型'
- en: '](img/B16925_01_27.jpg)'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_27.jpg)'
- en: 'Figure 1.27: Check the data type of the cleaned column'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.27：检查已清理列的数据类型
- en: 'Congratulations, you have completed your second data cleaning operation! However,
    if you recall, during this process we also noticed the undocumented values of
    –2 and 0 in `PAY_1`. Now, let''s imagine we got back in touch with our business
    partner and learned the following information:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你，完成了第二次数据清理操作！但是，如果你还记得，在此过程中我们也注意到`PAY_1`中存在未记录的值-2和0。现在，假设我们再次与商业伙伴取得联系，并了解了以下信息：
- en: -2 means the account started that month with a zero balance and never used any
    credit.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -2表示账户在该月初余额为零，并且从未使用过信用。
- en: -1 means the account had a balance that was paid in full.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -1表示账户的余额已全部还清。
- en: 0 means that at least the minimum payment was made, but the entire balance wasn't
    paid (that is, a positive balance was carried to the next month).
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示至少支付了最低还款额，但并未偿还全部余额（即，存在正余额并转入下个月）。
- en: We thank our business partner since this answers our questions, for now. Maintaining
    a good line of communication and working relationship with the business partner
    is important, as you can see here, and may determine the success or failure of
    a project.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢我们的商业伙伴，因为这回答了我们目前的问题。保持良好的沟通和合作关系非常重要，正如你所看到的，这可能决定一个项目的成败。
- en: 'In your notebook, save your progress from this exercise like this:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的笔记本中，像这样保存这次练习的进度：
- en: '[PRE56]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Data Quality Assurance and Exploration
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据质量保证与探索
- en: So far, we remedied two data quality issues just by asking basic questions or
    by looking at the `.info()` summary. Let's now take a look at the first few columns
    of data. Before we get to the historical bill payments, we have the credit limits
    of the `LIMIT_BAL` accounts, and the `SEX`, `EDUCATION`, `MARRIAGE`, and `AGE`
    demographic features. Our business partner has reached out to us, to let us know
    that gender should not be used to predict credit-worthiness, as this is **unethical**
    by their standards. So we keep this in mind for future reference. Now we'll explore
    the rest of these columns, making any corrections that are necessary.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们通过提出一些基本问题或查看`.info()`摘要，已经解决了两个数据质量问题。接下来我们来看看前几列的数据。在查看历史账单支付记录之前，我们首先有`LIMIT_BAL`账户的信用额度，还有`SEX`、`EDUCATION`、`MARRIAGE`和`AGE`这些人口统计特征。我们的商业伙伴已经联系了我们，告诉我们性别不应被用来预测信用状况，因为按照他们的标准，这是**不道德**的。因此我们会在今后的工作中考虑这一点。现在我们将继续检查其余列，并进行必要的更正。
- en: In order to further explore the data, we will use **histograms**. Histograms
    are a good way to visualize data that is on a continuous scale, such as currency
    amounts and ages. A histogram groups similar values into bins and shows the number
    of data points in these bins as a bar graph.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步探索数据，我们将使用**直方图**。直方图是一种很好的方法，可以可视化那些连续值的数据，如货币金额和年龄。直方图将相似的值分组到不同的箱子中，并以条形图的方式显示这些箱子中的数据点数量。
- en: To plot histograms, we will start to get familiar with the graphical capabilities
    of pandas. pandas relies on another library called `matplotlib`. Using these tools,
    we'll also learn how to get quick statistical summaries of data in pandas.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 为了绘制直方图，我们将开始熟悉pandas的图形功能。pandas依赖于另一个名为`matplotlib`的库。使用这些工具，我们还将学习如何快速获取pandas中数据的统计摘要。
- en: 'Exercise 1.06: Exploring the Credit Limit and Demographic Features'
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习1.06：探索信用额度和人口统计特征
- en: 'In this exercise, we''ll start our exploration of data with the credit limit
    and age features. We will visualize them and get summary statistics to check that
    the data contained in these features is sensible. Then we will look at the education
    and marriage categorical features to see if the values there make sense, correcting
    them as necessary. `LIMIT_BAL` and `AGE` are numerical features, meaning they
    are measured on a continuous scale. Consequently, we''ll use histograms to visualize
    them. Perform the following steps to complete the exercise:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将开始探索数据中的信用额度和年龄特征。我们将可视化它们并获取统计摘要，以检查这些特征中的数据是否合理。然后，我们将查看教育和婚姻等分类特征，看看这些值是否合理，必要时进行修正。`LIMIT_BAL`和`AGE`是数值型特征，意味着它们是在一个连续的尺度上进行测量的。因此，我们将使用直方图来可视化它们。按照以下步骤完成练习：
- en: Note
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Jupyter notebook for this exercise found here: [https://packt.link/PRdtP](https://packt.link/PRdtP).'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的Jupyter笔记本可以在这里找到：[https://packt.link/PRdtP](https://packt.link/PRdtP)。
- en: 'In addition to pandas, import `matplotlib` and set up some plotting options
    with this code snippet. Note the use of comments in Python with `#`. Anything
    appearing after a `#` on a line will be ignored by the Python interpreter:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了pandas，还需要导入`matplotlib`并使用以下代码片段设置一些绘图选项。注意Python中的注释用法，注释以`#`开头。任何出现在`#`后面的内容都会被Python解释器忽略：
- en: '[PRE57]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: This imports `matplotlib` and uses `.rcParams` to set the resolution (`dpi`
    = dots per inch) for a nice crisp image; you may not want to worry about this
    last part unless you are preparing things for presentation, as it could make the
    images quite large in your notebook.
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码导入了`matplotlib`并使用`.rcParams`设置了分辨率（`dpi` = 每英寸点数），以便得到清晰的图像；除非你准备展示这些内容，否则不需要担心最后这部分，因为它可能会使图片在笔记本中变得非常大。
- en: 'Load our progress from the previous exercise using the following code:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码加载我们上一个练习的进度：
- en: '[PRE58]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Run `df_clean_2[[''LIMIT_BAL'', ''AGE'']].hist()` and you should see the following
    histograms:![Figure 1.28: Histograms of the credit limit and age data'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`df_clean_2[['LIMIT_BAL', 'AGE']].hist()`，你应该能看到以下直方图：![图1.28：信用额度和年龄数据的直方图
- en: '](img/B16925_01_28.jpg)'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_28.jpg)'
- en: 'Figure 1.28: Histograms of the credit limit and age data'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.28：信用额度和年龄数据的直方图
- en: This is a nice visual snapshot of these features. We can get a quick, approximate
    look at all of the data in this way. In order to see statistics such as the mean
    and median (that is, the 50th percentile), there is another helpful pandas function.
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是这些特征的一个不错的视觉快照。我们可以通过这种方式快速大致地查看所有数据。为了查看均值和中位数（即第50百分位数）等统计信息，还有另一个有用的pandas函数。
- en: 'Generate a tabular report of summary statistics using the following command:'
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令生成汇总统计的表格报告：
- en: '[PRE59]'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'You should see the following output:'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该看到以下输出：
- en: '![Figure 1.29: Statistical summaries of credit limit and age data'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.29：信用额度和年龄数据的统计摘要'
- en: '](img/B16925_01_29.jpg)'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_29.jpg)'
- en: 'Figure 1.29: Statistical summaries of credit limit and age data'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.29：信用额度和年龄数据的统计摘要
- en: Based on the histograms and the convenient statistics computed by `.describe()`,
    which include a count of non-nulls, the mean and standard deviation, minimum,
    maximum, and quartiles, we can make a few judgments.
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于直方图和通过`.describe()`计算的便捷统计数据，其中包括非空值的计数、均值和标准差、最小值、最大值以及四分位数，我们可以做出一些判断。
- en: '`LIMIT_BAL`, the credit limit, seems to make sense. The credit limits have
    a minimum of 10,000\. This dataset is from Taiwan; the exact unit of currency
    (NT dollar) may not be familiar, but intuitively, a credit limit should be above
    zero. You are encouraged to look up the conversion to your local currency and
    consider these credit limits. For example, 1 US dollar is about 30 NT dollars.'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`LIMIT_BAL`（信用额度）看起来是合理的。信用额度的最小值为10,000。该数据集来自台湾，具体的货币单位（新台币）可能不太熟悉，但直观上，信用额度应该大于零。我们建议你查找与本地货币的兑换汇率并考虑这些信用额度。例如，1美元大约等于30新台币。'
- en: The `AGE` feature also looks reasonably distributed, with no one under the age
    of 21 having a credit account.
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`AGE`特征看起来也分布得比较合理，且21岁以下的人群没有信用账户。'
- en: For the categorical features, a look at the value counts is useful, since there
    are relatively few unique values.
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于分类特征，查看值计数是有用的，因为唯一值相对较少。
- en: 'Obtain the value counts for the `EDUCATION` feature using the following code:'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码获取`EDUCATION`特征的值计数：
- en: '[PRE60]'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'You should see this output:'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该看到以下输出：
- en: '![Figure 1.30: Value counts of the EDUCATION feature'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.30：EDUCATION特征的值计数'
- en: '](img/B16925_01_30.jpg)'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_30.jpg)'
- en: 'Figure 1.30: Value counts of the EDUCATION feature'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.30：EDUCATION特征的值计数
- en: Here, we see undocumented education levels 0, 5, and 6, as the data dictionary
    describes only `Education (1 = graduate school; 2 = university; 3 = high school;
    4 = others)`. Our business partner tells us they don't know about the others.
    Since they are not very prevalent, we will lump them in with the `others` category,
    which seems appropriate.
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们看到未记录的教育水平0、5和6，因为数据字典只描述了`教育（1 = 研究生；2 = 大学；3 = 高中；4 = 其他）`。我们的业务合作伙伴告诉我们他们不知道其他教育水平。由于它们不太常见，我们将它们归类为`其他`类别，这似乎是合适的。
- en: 'Run this code to combine the undocumented levels of the `EDUCATION` feature
    into the level for `others` and then examine the results:'
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码将`EDUCATION`特征中未记录的级别合并到`其他`级别中，然后检查结果：
- en: '[PRE61]'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The pandas `.replace` method makes doing the replacements described in the
    preceding step pretty quick. Once you run the code, you should see this output:'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pandas的`.replace`方法使得执行上述替换操作非常快速。运行代码后，你应该会看到以下输出：
- en: '![Figure 1.31: Cleaning the EDUCATION feature'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.31：清理EDUCATION特征'
- en: '](img/B16925_01_31.jpg)'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_31.jpg)'
- en: 'Figure 1.31: Cleaning the EDUCATION feature'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.31：清理EDUCATION特征
- en: Note that here we make this change `inplace=True`). This means that, instead
    of returning a new DataFrame, this operation will make the change on the existing
    DataFrame.
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，这里我们使用了`inplace=True`参数。这意味着，操作将直接修改现有的DataFrame，而不是返回一个新的DataFrame。
- en: 'Obtain the value counts for the `MARRIAGE` feature using the following code:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码获取`MARRIAGE`特征的值计数：
- en: '[PRE62]'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'You should obtain the following output:'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该获得以下输出：
- en: '![Figure 1.32: Value counts of the raw MARRIAGE feature'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.32：原始MARRIAGE特征的值计数'
- en: '](img/B16925_01_32.jpg)'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_32.jpg)'
- en: 'Figure 1.32: Value counts of the raw MARRIAGE feature'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.32：原始MARRIAGE特征的值计数
- en: 'The issue here is similar to that encountered for the `EDUCATION` feature;
    there is a value, 0, which is not documented in the data dictionary: `1 = married;
    2 = single; 3 = others`. So we''ll lump it in with `others`.'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里的问题与`EDUCATION`特征遇到的问题类似；有一个值0，在数据字典中没有记录：`1 = 已婚；2 = 单身；3 = 其他`。因此，我们将其归类为`其他`。
- en: 'Change the values of 0 in the `MARRIAGE` feature to 3 and examine the result
    with this code:'
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码将`MARRIAGE`特征中的0值改为3，并检查结果：
- en: '[PRE63]'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The output should be as follows:'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '![Figure 1.33: Value counts of the cleaned MARRIAGE feature'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.33：清理后的MARRIAGE特征的值计数'
- en: '](img/B16925_01_33.jpg)'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_33.jpg)'
- en: 'Figure 1.33: Value counts of the cleaned MARRIAGE feature'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.33：清理后的MARRIAGE特征的值计数
- en: We've now accomplished a lot of exploration and cleaning of the data. We will
    do some more advanced visualization and exploration of the financial history features
    that come after this in the DataFrame, later. First, we'll consider the meaning
    of the `EDUCATION` feature, a categorical feature in our dataset.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经完成了大量数据的探索和清理。接下来，我们将在DataFrame中对其后的财务历史特征进行更高级的可视化和探索。首先，我们将考虑`EDUCATION`特征的含义，这是数据集中的一个分类特征。
- en: 'Save your progress from this exercise as follows:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下方式保存此练习的进度：
- en: '[PRE64]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Deep Dive: Categorical Features'
  id: totrans-443
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度分析：分类特征
- en: Machine learning algorithms only work with numbers. If your data contains text
    features, for example, these would require transformation to numbers in some way.
    We learned above that the data for our case study is, in fact, entirely numerical.
    However, it's worth thinking about how it got to be that way. In particular, consider
    the `EDUCATION` feature.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法只处理数字。如果你的数据包含文本特征，例如，这些特征需要以某种方式转化为数字。我们上面了解到，我们的案例研究的数据实际上完全是数字化的。然而，值得思考的是它是如何变成这样的。特别是，考虑一下`EDUCATION`特征。
- en: This is an example of what is called a `graduate school`, `university`, `high
    school`, and `others`. These are called the **levels** of the categorical feature;
    here, there are four levels. It is only through a mapping, which has already been
    chosen for us, that this data exists as the numbers 1, 2, 3, and 4 in our dataset.
    This particular assignment of categories to numbers creates what is known as an
    **ordinal feature**, since the levels are mapped to numbers in order. As a data
    scientist, at a minimum, you need to be aware of such mappings, if you are not
    choosing them yourself.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个例子，说明什么是`研究生院`、`大学`、`高中`和`其他`。这些被称为**分类特征的等级**；这里有四个等级。正是通过已经为我们选择的映射，数据才在我们的数据集中以1、2、3和4的数字形式存在。这个将类别映射到数字的特定分配创建了所谓的**有序特征**，因为这些等级按顺序映射到数字。作为数据科学家，至少你需要意识到这样的映射，除非你自己选择这些映射。
- en: '**What are the implications of this mapping?**'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: '**这种映射有什么影响？**'
- en: It makes some sense that the education levels are ranked, with 1 corresponding
    to the highest level of education in our dataset, 2 to the next highest, 3 to
    the next, and 4 presumably including the lowest levels. However, when you use
    this encoding as a numerical feature in a machine learning model, it will be treated
    just like any other numerical feature. For some models, this effect may not be
    desired.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 教育水平按等级排列是有一定道理的，1对应我们数据集中最高的教育水平，2对应次高水平，3对应再高水平，4可能包括最低水平。然而，当你将这种编码作为机器学习模型中的数值特征时，它会像处理任何其他数值特征一样被对待。对于某些模型，这种效果可能并不希望出现。
- en: '**What if a model seeks to find a straight-line relationship between the features
    and response?**'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果一个模型试图找到特征与响应之间的直线关系，会怎样呢？**'
- en: This may seem like an arbitrary question, although later in the book you will
    learn the importance of distinguishing between linear and non-linear models. In
    this section, we will briefly introduce the concept that some models do look for
    linear relationships between features and the response variable. Whether or not
    this would work well in the case of the education feature depends on the actual
    relationship between different levels of education and the outcome we are trying
    to predict.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题可能看起来有些随意，尽管在书的后面你会了解区分线性模型和非线性模型的重要性。在本节中，我们将简要介绍一些模型确实会寻找特征与响应变量之间的线性关系。是否能够在教育特征的情况下起作用，取决于不同教育水平与我们试图预测的结果之间的实际关系。
- en: 'Here, we examine two hypothetical cases of synthetic data with ordinal categorical
    variables, each with 10 levels. The levels measure the self-reported satisfaction
    of customers visiting a website. The average number of minutes spent on the website
    for customers reporting each level is plotted on the y-axis. We''ve also plotted
    the line of best fit in each case to illustrate how a linear model would deal
    with this data, as shown in the following figure:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们考察了两个假设的合成数据案例，每个案例都包含10个等级的有序分类变量。这些等级衡量的是访问网站的客户自我报告的满意度。每个等级的客户在网站上停留的平均分钟数绘制在y轴上。我们还在每种情况下绘制了最佳拟合线，以说明线性模型如何处理这些数据，如下图所示：
- en: '![Figure 1.34: Ordinal features may or may not work well in a linear model'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.34：有序特征在线性模型中可能有效，也可能无效'
- en: '](img/B16925_01_34.jpg)'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_34.jpg)'
- en: 'Figure 1.34: Ordinal features may or may not work well in a linear model'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.34：有序特征在线性模型中可能有效，也可能无效
- en: 'We can see that if an algorithm assumes a linear (straight-line) relationship
    between the features and response variable, this may or may not work well depending
    on the true relationship. Notice that in this synthetic example, we are modeling
    a regression problem: the response variable takes on a continuous range of numbers.
    While our case study involves a classification problem, some classification algorithms
    such as **logistic regression** also assume a linear effect of the features. We
    will discuss this in greater detail later when we get into modeling the data for
    our case study.'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，如果一个算法假设特征与响应变量之间存在线性（直线）关系，这可能根据真实关系的不同效果好坏不一。注意，在这个合成示例中，我们正在建模一个回归问题：响应变量采用连续的数字范围。虽然我们的案例研究涉及分类问题，但一些分类算法，如**逻辑回归**，也假设特征的线性效应。我们将在稍后更详细地讨论这个问题，当我们进入为案例研究建模的数据时。
- en: Roughly speaking, for a binary classification problem, meaning the response
    variable only has two outcomes, which we'll assume are coded as 0 and 1, you can
    look at the different levels of a categorical feature in terms of the average
    values of the response variable within each level. These average values represent
    the "rates" of the positive class (that is, the samples where the response variable
    = 1) for each level. This can give you an idea of whether an ordinal encoding
    will work well with a linear model. Assuming you've imported the same packages
    in your Jupyter notebook as in the previous sections, you can quickly look at
    this using a `groupby`/`agg`regate procedure and a bar plot in pandas.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 大致而言，对于二分类问题，即响应变量只有两个结果，我们假设其编码为0和1，您可以通过每个类别特征在每个水平内响应变量的平均值来查看类别特征的不同水平。这些平均值表示每个水平的正类“比率”（即响应变量=1的样本）。这可以让您了解顺序编码是否适合与线性模型配合使用。假设您在Jupyter笔记本中导入了与前面章节相同的包，您可以通过`groupby`/`agg`聚合过程以及pandas中的条形图快速查看这一点。
- en: 'This will group the data by the values in the `EDUCATION` feature and then
    within each group aggregate the data together using the average of the `default
    payment next month` response variable:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 这将根据`EDUCATION`特征中的值对数据进行分组，然后在每个组内通过`default payment next month`响应变量的平均值进行聚合：
- en: '[PRE65]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Once you run the code, you should obtain the following output:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码后，您应该会得到以下输出：
- en: '![Figure 1.35: Default rate within education levels'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.35：不同教育水平的违约率'
- en: '](img/B16925_01_35.jpg)'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_35.jpg)'
- en: 'Figure 1.35: Default rate within education levels'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.35：不同教育水平的违约率
- en: Similar to *Example 2* in *Figure 1.34*, it looks like a straight-line fit would
    probably not be the best description of the data here. In case a feature has a
    non-linear effect like this, it may be better to use a more complex algorithm
    such as a **decision tree** or **random forest**. Or, if a simpler and more interpretable
    linear model such as logistic regression is desired, we could avoid an ordinal
    encoding and use a different way of encoding categorical variables. A popular
    way of doing this is called **one-hot encoding** (**OHE**).
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 与*图1.34中的示例2*类似，这里的数据似乎不太适合用直线拟合来描述。如果某个特征具有类似的非线性效应，可能更适合使用更复杂的算法，例如**决策树**或**随机森林**。或者，如果需要更简单且更具可解释性的线性模型（如逻辑回归），我们可以避免使用顺序编码，而采用不同的类别变量编码方式。一种常见的方式叫做**独热编码**（**OHE**）。
- en: OHE is a way to transform a categorical feature, which may consist of text labels
    in the raw data, into a numerical feature that can be used in mathematical models.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: OHE是一种将类别特征（可能由原始数据中的文本标签组成）转换为数值特征的方法，以便在数学模型中使用。
- en: Let's learn about this in an exercise. And if you are wondering why a logistic
    regression is more interpretable and a random forest is more complex, we will
    be learning about these concepts in detail in later chapters.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个练习中学习这个。如果你在想为什么逻辑回归更具可解释性，而随机森林更复杂，我们将在后续章节详细学习这些概念。
- en: 'Exercise 1.07: Implementing OHE for a Categorical Feature'
  id: totrans-465
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习1.07：为类别特征实现OHE
- en: 'In this exercise, we will "reverse engineer" the `EDUCATION` feature in the
    dataset to obtain the text labels that represent the different education levels,
    then show how to use pandas to create an OHE. As a preliminary step, please set
    up the environment and load in the progress from previous exercises:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将“逆向工程”数据集中的`EDUCATION`特征，以获取表示不同教育水平的文本标签，然后展示如何使用pandas创建OHE。作为初步步骤，请设置环境并加载之前练习的进度：
- en: '[PRE66]'
  id: totrans-467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'First, let''s consider our `EDUCATION` feature before it was encoded as an
    ordinal. From the data dictionary, we know that 1 = graduate school, 2 = university,
    3 = high school, 4 = others. We would like to recreate a column that has these
    strings, instead of numbers. Perform the following steps to complete the exercise:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们考虑`EDUCATION`特征在编码为顺序之前的样子。从数据字典中我们知道，1 = 研究生，2 = 大学，3 = 高中，4 = 其他。我们希望重新创建一个包含这些字符串的列，而不是数字。执行以下步骤完成练习：
- en: Note
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Jupyter notebook for this exercise found here: [https://packt.link/akAYJ](https://packt.link/akAYJ).'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 本次练习的Jupyter笔记本可以在这里找到：[https://packt.link/akAYJ](https://packt.link/akAYJ)。
- en: 'Create an empty column for the categorical labels called `EDUCATION_CAT`. Using
    the following command, every row will contain the string `''none''`:'
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为类别标签创建一个空列，命名为`EDUCATION_CAT`。使用以下命令，每一行将包含字符串`'none'`：
- en: '[PRE67]'
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Examine the first few rows of the DataFrame for the `EDUCATION` and `EDUCATION_CAT`
    columns:'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `EDUCATION` 和 `EDUCATION_CAT` 列的 DataFrame 的前几行：
- en: '[PRE68]'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The output should appear as follows:'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 1.36: Selecting columns and viewing the first 10 rows'
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.36：选择列并查看前 10 行'
- en: '](img/B16925_01_36.jpg)'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_36.jpg)'
- en: 'Figure 1.36: Selecting columns and viewing the first 10 rows'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.36：选择列并查看前 10 行
- en: We need to populate this new column with the appropriate strings. pandas provides
    a convenient functionality for mapping all values of a Series onto new values.
    This function is in fact called `.map` and relies on a dictionary to establish
    the correspondence between the old values and the new values. Our goal here is
    to map the numbers in `EDUCATION` onto the strings they represent. For example,
    where the `EDUCATION` column equals the number 1, we'll assign the `'graduate
    school'` string to the `EDUCATION_CAT` column, and so on for the other education
    levels.
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要用适当的字符串填充这个新列。pandas 提供了一个方便的功能，可以将一个 Series 的所有值映射到新的值。这个函数实际上叫 `.map`，并依赖于一个字典来建立旧值和新值之间的对应关系。我们的目标是将
    `EDUCATION` 中的数字映射到它们所代表的字符串。例如，当 `EDUCATION` 列的值为 1 时，我们将把 `'研究生'` 字符串赋值给 `EDUCATION_CAT`
    列，其他教育水平也是如此。
- en: 'Create a dictionary that describes the mapping for education categories using
    the following code:'
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建描述教育类别映射的字典：
- en: '[PRE69]'
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Apply the mapping to the original `EDUCATION` column using `.map` and assign
    the result to the new `EDUCATION_CAT` column:'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.map` 将映射应用到原始的 `EDUCATION` 列，并将结果赋值给新的 `EDUCATION_CAT` 列：
- en: '[PRE70]'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'After running those lines, you should see the following output:'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行这些代码后，你应该看到以下输出：
- en: '![Figure 1.37: Examining the string values corresponding to the ordinal'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.37：检查对应于序数编码的字符串值'
- en: encoding of EDUCATION
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: EDUCATION 的编码
- en: '](img/B16925_01_37.jpg)'
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_37.jpg)'
- en: 'Figure 1.37: Examining the string values corresponding to the ordinal encoding
    of EDUCATION'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.37：检查对应于 EDUCATION 的序数编码的字符串值
- en: Excellent! Note that we could have skipped *Step 1*, where we assigned the new
    column with `'none'`, and gone straight to *Steps 3* and *4* to create the new
    column. However, sometimes it's useful to create a new column initialized with
    a single value, so it's worth knowing how to do that.
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 很好！请注意，我们本可以跳过*步骤 1*，直接通过*步骤 3*和*4*创建新列，而不需要先将新列赋值为 `'none'`。然而，有时候创建一个初始化为单一值的新列是有用的，因此了解如何做到这一点是值得的。
- en: Now we are ready to one-hot encode. We can do this by passing a Series of a
    `DataFrame` to the pandas `get_dummies()` function. The function got this name
    because one-hot encoded columns are also referred to as **dummy variables**. The
    result will be a new DataFrame, with as many columns as there are levels of the
    categorical variable.
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们准备进行一热编码。我们可以通过将一个 `DataFrame` 的 Series 传递给 pandas 的 `get_dummies()` 函数来实现。该函数得名于一热编码列也被称为**虚拟变量**。结果将是一个新的
    DataFrame，包含与类别变量的级别数相等的列。
- en: 'Run this code to create a one-hot encoded DataFrame of the `EDUCATION_CAT`
    column. Examine the first 10 rows:'
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码以创建 `EDUCATION_CAT` 列的一热编码 DataFrame。查看前 10 行：
- en: '[PRE71]'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'This should produce the following output:'
  id: totrans-493
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这应该产生以下输出：
- en: '![Figure 1.38: DataFrame of one-hot encoding'
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.38：一热编码的 DataFrame'
- en: '](img/B16925_01_38.jpg)'
  id: totrans-495
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_38.jpg)'
- en: 'Figure 1.38: DataFrame of one-hot encoding'
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.38：一热编码的 DataFrame
- en: 'You can now see why this is called "one-hot encoding": across all these columns,
    any particular row will have a 1 in exactly 1 column, and 0s in the rest. For
    a given row, the column with the 1 should match up to the level of the original
    categorical variable. To check this, we need to concatenate this new DataFrame
    with the original one and examine the results side by side. We will use the pandas
    `concat` function, to which we pass the list of DataFrames we wish to concatenate,
    and the `axis=1` keyword saying to concatenate them horizontally; that is, along
    the column axis. This basically means we are combining these two DataFrames "side
    by side," which we know we can do because we just created this new DataFrame from
    the original one: we know it will have the same number of rows, which will be
    in the same order as the original DataFrame.'
  id: totrans-497
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你现在可以理解为什么这叫做“独热编码”：在所有这些列中，任何一行都会在恰好一列中为 1，其余列为 0。对于给定的一行，含有 1 的列应该与原始分类变量的水平相匹配。为了验证这一点，我们需要将这个新的
    DataFrame 与原始 DataFrame 进行合并，并并排查看结果。我们将使用 pandas 的 `concat` 函数，传入我们希望合并的 DataFrame
    列表，并使用 `axis=1` 参数表示水平合并；也就是说，沿着列轴合并。这基本上意味着我们将这两个 DataFrame “并排”组合在一起，我们知道我们可以这样做，因为我们刚刚从原始
    DataFrame 创建了这个新 DataFrame：我们知道它将有相同数量的行，且行的顺序与原始 DataFrame 一致。
- en: 'Concatenate the one-hot encoded DataFrame to the original DataFrame as follows:'
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如下所示，将独热编码后的 DataFrame 合并到原始 DataFrame 中：
- en: '[PRE72]'
  id: totrans-499
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'You should see this output:'
  id: totrans-500
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会看到以下输出：
- en: '![Figure 1.39: Checking the one-hot encoded columns'
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.39：检查独热编码列'
- en: '](img/B16925_01_39.jpg)'
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16925_01_39.jpg)'
- en: 'Figure 1.39: Checking the one-hot encoded columns'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.39：检查独热编码列
- en: 'Alright, looks like this has worked as intended. OHE is another way to encode
    categorical features that avoids the implied numerical structure of an ordinal
    encoding. However, notice what has happened here: we have taken a single column,
    `EDUCATION`, and exploded it out into as many columns as there were levels in
    the feature. In this case, since there are only four levels, this is not such
    a big deal. However, if your categorical variable had a very large number of levels,
    you may want to consider an alternate strategy, such as grouping some levels together
    into single categories.'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，看起来这个方法如预期一样有效。OHE 是另一种编码分类特征的方法，它避免了顺序编码中隐含的数值结构。然而，请注意这里发生了什么：我们将单一列 `EDUCATION`
    拓展成了与特征水平数量相同的多列。在这种情况下，由于只有四个水平，因此问题不大。但如果你的分类变量有非常多的水平，你可能需要考虑使用其他策略，比如将某些水平合并为一个类别。
- en: This is a good time to save the DataFrame we've created here, which encapsulates
    our efforts at cleaning the data and adding an OHE column.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候保存我们创建的 DataFrame 了，它包含了我们清洗数据并添加 OHE 列的成果。
- en: 'Write the latest DataFrame to a file like this: `df_with_ohe.to_csv(''../../Data/Chapter_1_cleaned_data.csv'',
    index=False)`.'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 将最新的 DataFrame 写入文件，如下所示：`df_with_ohe.to_csv('../../Data/Chapter_1_cleaned_data.csv',
    index=False)`。
- en: Exploring the Financial History Features in the Dataset
  id: totrans-507
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据集中的财务历史特征
- en: 'We are ready to explore the rest of the features in the case study dataset.
    First set up the environment and load data from the previous exercise. This can
    be done using the following snippet:'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好探索案例研究数据集中的其余特征。首先设置环境并加载上一个练习中的数据。可以使用以下代码片段来实现：
- en: '[PRE73]'
  id: totrans-509
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Note
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The path to your CSV file may be different depending on where you saved it.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 CSV 文件的路径可能会有所不同，具体取决于你保存的路径。
- en: 'The remaining features to be examined are the financial history features. They
    fall naturally into three groups: the status of the monthly payments for the last
    6 months, and the billed and paid amounts for the same period. First, let''s look
    at the payment statuses. It is convenient to break these out as a list so we can
    study them together. You can do this using the following code:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 需要检查的其余特征是财务历史特征。它们自然分为三组：过去 6 个月的月度付款状态，以及同一时期的账单和已付款金额。首先，让我们来看一下付款状态。将这些特征拆分成一个列表，以便我们可以一起研究它们，比较方便。你可以使用以下代码来实现：
- en: '[PRE74]'
  id: totrans-513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'We can use the `.describe` method on these six Series to examine summary statistics:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `.describe` 方法对这六个 Series 进行汇总统计分析：
- en: '[PRE75]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'This should produce the following output:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 1.40: Summary statistics of payment status features'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.40：付款状态特征的摘要统计'
- en: '](img/B16925_01_40.jpg)'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_40.jpg)'
- en: 'Figure 1.40: Summary statistics of payment status features'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.40：付款状态特征的摘要统计
- en: 'Here, we observe that the range of values is the same for all of these features:
    -2, -1, 0, ... 8\. It appears that the value of 9, described in the data dictionary
    as *payment delay for nine months and above*, is never observed.'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们观察到所有这些特征的值范围都是相同的：-2，-1，0，... 8。看起来，数据字典中描述的值为9，即*九个月及以上的付款延迟*，从未出现过。
- en: 'We have already clarified the meaning of all of these levels, some of which
    were not in the original data dictionary. Now let''s look again at the `value_counts()`
    of `PAY_1`, now sorted by the values we are counting, which are the `index` of
    this Series:'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经澄清了所有这些级别的含义，其中一些并不在原始数据字典中。现在让我们再次查看`PAY_1`的`value_counts()`，现在按我们正在计数的值进行排序，这些值是该Series的`index`：
- en: '[PRE76]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'This should produce the following output:'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该产生以下输出：
- en: '![Figure 1.41: Value counts of the payment status for the previous month'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.41：上个月付款状态的值计数'
- en: '](img/B16925_01_41.jpg)'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_41.jpg)'
- en: 'Figure 1.41: Value counts of the payment status for the previous month'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.41：上个月付款状态的值计数
- en: 'Compared to the positive integer values, most of the values are either -2,
    -1, or 0, which correspond to an account that was in good standing last month:
    not used, paid in full, or made at least the minimum payment.'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 与正整数值相比，大多数值要么是-2，-1，要么是0，这对应于上个月处于良好状态的帐户：未使用，全额支付，或至少支付了最低还款额。
- en: 'Notice that, because of the definition of the other values of this variable
    (1 = payment delay for 1 month; 2 = payment delay for 2 months, and so on), this
    feature is sort of a hybrid of categorical and numerical features. Why should
    no credit usage correspond to a value of -2, while a value of 2 means a 2-month
    late payment, and so forth? We should acknowledge that the numerical coding of
    payment statuses -2, -1, and 0 constitute a decision made by the creator of the
    dataset on how to encode certain categorical features, which were then lumped
    in with a feature that is truly numerical: the number of months of payment delay
    (values of 1 and larger). Later on, we will consider the potential effects of
    this way of doing things on the predictive capability of this feature.'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于此变量的其他值的定义（1 = 一个月的付款延迟；2 = 两个月的付款延迟，依此类推），此特征在分类和数值特征之间有点混合。为什么没有信用使用对应于-2的值，而值为2表示2个月的延迟付款，依此类推？我们应该意识到，付款状态的数值编码-2，-1和0构成了数据集创建者对如何对某些分类特征进行编码的决定，然后将其与一个真正数值的特征混合在一起：付款延迟的月数（值为1及以上）。稍后，我们将考虑这种做法对该特征的预测能力的潜在影响。
- en: 'For now, we will continue to explore the data. This dataset is small enough,
    with 18 of these financial features and a handful of others, that we can afford
    to individually examine every feature. If the dataset had thousands of features,
    we would likely forgo this and instead explore `df[pay_feats[0]].hist()`, to produce
    this:'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将继续探索数据。这个数据集足够小，有18个这些财务特征和少数其他特征，我们可以负担得起逐个检查每个特征。如果数据集有数千个特征，我们可能会放弃这一点，而是探索`df[pay_feats[0]].hist()`，以产生这个：
- en: '![Figure 1.42: Histogram of PAY_1 using default arguments'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.42：使用默认参数绘制的PAY_1直方图'
- en: '](img/B16925_01_42.jpg)'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_42.jpg)'
- en: 'Figure 1.42: Histogram of PAY_1 using default arguments'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.42：使用默认参数绘制的PAY_1直方图
- en: Now we're going to take an in-depth look at how this graphic is produced and
    consider whether it is as informative as it should be. A key point about the graphical
    functionality of pandas is that `.hist()` method is `**kwds`, which the documentation
    indicates are `matplotlib` keyword arguments.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将深入研究如何生成这个图形，并考虑它是否如此信息丰富。关于pandas的图形功能的一个关键点是`.hist()`方法是`**kwds`，文档指出这些是`matplotlib`关键字参数。
- en: Note
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'For more information, refer to the following: [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html).'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多信息，请参考以下链接：[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html)。
- en: Looking at the `matplotlib` documentation for `matplotlib.pyplot.hist` shows
    additional arguments you can use with the pandas `.hist()` method, such as the
    type of histogram to plot (see [https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html)
    for more details). In general, to get more details about plotting functionality,
    it's important to be aware of `matplotlib`, and in some scenarios, you will want
    to use `matplotlib` directly, instead of pandas, to have more control over the
    appearance of plots.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 查阅`matplotlib`文档中的`matplotlib.pyplot.hist`可以看到更多可以与pandas的`.hist()`方法一起使用的附加参数，比如绘制的直方图类型（更多详情请参见[https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html)）。通常，为了获得更详细的绘图功能，了解`matplotlib`是非常重要的，在某些场景下，你可能希望直接使用`matplotlib`而不是pandas，以便更好地控制图形外观。
- en: You should be aware that pandas uses `matplotlib`, which in turn uses NumPy.
    When plotting histograms with `matplotlib`, the numerical calculation for the
    values that make up the histogram is actually carried out by the NumPy `.histogram`
    function. This is a key example of code reuse, or "not reinventing the wheel."
    If a standard functionality, such as plotting a histogram, already has a good
    implementation in Python, there is no reason to create it anew. And if the mathematical
    operation to create the histogram data for the plot is already implemented, this
    should be leveraged as well. This shows the interconnectedness of the Python ecosystem.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该意识到，pandas使用了`matplotlib`，而`matplotlib`又使用了NumPy。在使用`matplotlib`绘制直方图时，实际上生成直方图数值的计算是由NumPy的`.histogram`函数来执行的。这是代码复用的一个关键示例，或称“不要重复造轮子”。如果像绘制直方图这样的标准功能已经在Python中有了很好的实现，那么就没有理由重新创建它。而且，如果绘制直方图所需的数学计算已经实现，我们也应该利用它。这展示了Python生态系统的相互关联性。
- en: We'll now address a couple of key issues that arise when calculating and plotting histograms.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将讨论计算和绘制直方图时出现的几个关键问题。
- en: '**Number of bins**'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: '**箱体数量**'
- en: Histograms work by grouping together values into what are called `PAY_1` feature,
    there are 11 unique values. In cases like this, it's better to manually set the
    number of histogram bins to the number of unique values.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图通过将值分组到所谓的`PAY_1`特征中，那里有11个唯一的值。在这种情况下，最好手动将直方图的箱体数设置为唯一值的数量。
- en: In our current example, since there are very few values in the higher bins of
    `PAY_1`, the plot may not look much different. But in general, this is important
    to keep in mind when plotting histograms.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前的示例中，由于`PAY_1`的高箱体值非常少，图表可能看起来没有太大变化。但通常来说，绘制直方图时要牢记这一点。
- en: '**Bin edges**'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: '**箱体边缘**'
- en: The locations of the edges of the bins determine how the values get grouped
    in the histogram. Instead of indicating the number of bins to the plotting function,
    you could alternatively supply a list or array of numbers for the `bins` keyword
    argument. This input would be interpreted as the bin edge locations on the x-axis.
    The way values are grouped into bins in `matplotlib`, using the edge locations,
    is important to understand. All bins, except the last one, group together values
    as low as the left edge, and up to **but not including** values as high as the
    right edge. In other words, the left edge is closed but the right edge is open
    for these bins. However, the last bin includes both edges; it has a closed left
    and right edge. This is of more practical importance when you are binning a relatively
    small number of unique values that may land on the bin edges.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 箱体边缘的位置决定了值在直方图中的分组方式。你可以选择不向绘图函数指定箱体数量，而是为`bins`关键字参数提供一个数字列表或数组。该输入将被解释为x轴上的箱体边缘位置。理解`matplotlib`如何使用这些边缘位置将值分组到箱体中是很重要的。除了最后一个箱体外，所有箱体都会将值从左边缘开始，包括左边缘，但不包括右边缘，换句话说，左边缘是闭合的，右边缘是开放的。然而，最后一个箱体则包括了两个边缘，它的左右边缘都是闭合的。当你将相对较少的唯一值分配到箱体边缘时，这一点特别重要。
- en: 'For control over plot appearance, it''s usually better to specify the bin edge
    locations. We''ll create an array of 12 numbers, which will result in 11 bins,
    each one centered around 1 of the unique values of `PAY_1`:'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地控制图形外观，通常最好指定箱体的边缘位置。我们将创建一个包含12个数字的数组，这将生成11个箱体，每个箱体都围绕`PAY_1`的一个唯一值进行中心对齐：
- en: '[PRE77]'
  id: totrans-545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The output shows the bin edge locations:'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了箱体的边缘位置：
- en: '[PRE78]'
  id: totrans-547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'As a final point of style, it is important to always *label your plots* so
    that they are interpretable. We haven''t yet done this manually, because in some
    cases, pandas does it automatically, and in other cases, we simply left the plots
    unlabeled. From now on, we will follow best practice and label all plots. We use
    the `xlabel` and `ylabel` functions in `matplotlib` to add axis labels to this
    plot. The code is as follows:'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个风格点是，始终*标注你的图表*，使其具有可解释性。我们还没有手动标注，因为在某些情况下，pandas 会自动完成，其他情况下我们只是让图表保持无标签。从现在开始，我们将遵循最佳实践并标注所有图表。我们使用
    `matplotlib` 中的 `xlabel` 和 `ylabel` 函数为此图表添加轴标签。代码如下：
- en: '[PRE79]'
  id: totrans-549
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The output should look like this:'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '![Figure 1.43: A better histogram of PAY_1'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.43：改进后的 PAY_1 直方图'
- en: '](img/B16925_01_43.jpg)'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_43.jpg)'
- en: 'Figure 1.43: A better histogram of PAY_1'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.43：改进后的 PAY_1 直方图
- en: '*Figure 1.43* represents an improved histogram, since the bars are centered
    over the actual values in the data, and there is 1 bar per unique value. While
    it''s tempting, and often sufficient, to just call plotting functions with the
    default arguments, one of your jobs as a data scientist is to create *accurate
    and representative data visualizations*. To do that, sometimes you need to dig
    into the details of plotting code, as we''ve done here.'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.43* 展示了改进后的直方图，因为条形图已对齐实际数据值，每个唯一值对应一个条形图。虽然仅使用默认参数调用绘图函数很有吸引力，并且通常足够，但作为数据科学家的职责之一是创建*准确且具有代表性的数据可视化图表*。为此，有时你需要深入了解绘图代码的细节，就像我们在这里做的那样。'
- en: '**What have we learned from this data visualization?**'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们从这次数据可视化中学到了什么？**'
- en: Since we already looked at the value counts, this confirms for us that most
    accounts are in good standing (values -2, -1, and 0). For those that aren't, it's
    more common for the "months late" to be a smaller number. This makes sense; likely,
    most people are paying off their balances before too long. Otherwise, their account
    may be closed or sold to a collection agency. Examining the distribution of your
    features and making sure it seems reasonable is a good thing to confirm with your
    client, as the quality of this data underlies the predictive modeling you seek
    to do.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经查看了值的计数，这进一步确认了大多数账户处于良好状态（值为 -2、-1 和 0）。对于那些没有处于良好状态的账户，"延迟月份" 较小的情况更为常见。这是有道理的；很可能大多数人会在不久后支付完余额。否则，他们的账户可能会被关闭或转交给收款公司。检查特征的分布并确保其合理性是与客户确认的好方法，因为数据的质量直接影响到你所进行的预测建模。
- en: 'Now that we''ve established some good plotting style for histograms, let''s
    use pandas to plot multiple histograms together, and visualize the payment status
    features for each of the last 6 months. We can pass our list of column names `pay_feats`
    to access multiple columns to plot with the `.hist()` method, specifying the bin
    edges we''ve already determined, and indicating we''d like a 2 by 3 grid of plots.
    First, we set the font size small enough to fit between these **subplots**. Here
    is the code for this:'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经为直方图建立了一些良好的绘图风格，让我们使用 pandas 一起绘制多个直方图，并可视化最近 6 个月的还款状态特征。我们可以将包含列名的列表
    `pay_feats` 传递给 `.hist()` 方法，指定我们已确定的箱子边界，并表示我们希望绘制 2 行 3 列的子图。首先，我们将字体大小设置得足够小，以适应这些**子图**之间的间距。以下是相关代码：
- en: '[PRE80]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'The plot titles have been created automatically for us based on the column
    names. The y-axes are understood to be counts. The resulting visualizations are
    as follows:'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图标题已经根据列名自动生成。y 轴表示计数。生成的可视化结果如下：
- en: '![Figure 1.44: Grid of histogram subplots'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.44：直方图子图的网格'
- en: '](img/B16925_01_44.jpg)'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_44.jpg)'
- en: 'Figure 1.44: Grid of histogram subplots'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.44：直方图子图的网格
- en: We've already seen the first of these, and it makes sense. What about the rest
    of them? Remember the definitions of the positive integer values of these features,
    and what each feature means. For example, `PAY_2` is the repayment status in August,
    `PAY_3` is the repayment status in July, and the others go further back in time.
    A value of 1 means a payment delay for 1 month, while a value of 2 means a payment
    delay for 2 months, and so forth.
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看过了第一个图表，这很有意义。那么其余的呢？请记住这些特征的正整数值定义及其含义。例如，`PAY_2` 是 8 月的还款状态，`PAY_3` 是
    7 月的还款状态，其他则追溯得更久。值为 1 表示延迟支付 1 个月，值为 2 表示延迟支付 2 个月，依此类推。
- en: 'Did you notice that something doesn''t seem right? Consider the values between
    July (`PAY_3`) and August (`PAY_2`). In July, there are very few accounts that
    had a 1-month payment delay; this bar is not really visible in the histogram.
    However, in August, there are suddenly thousands of accounts with a 2-month payment
    delay. This does not make sense: the number of accounts with a 2-month delay in
    a given month should be less than or equal to the number of accounts with a 1-month
    delay in the previous month.'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 你有没有注意到似乎有什么不对劲？看看7月（`PAY_3`）和8月（`PAY_2`）之间的值。7月，支付延迟1个月的账户非常少；在直方图中几乎看不见这一条。然而，到了8月，突然出现了数千个支付延迟2个月的账户。这不合逻辑：在一个月内，2个月延迟的账户数量应该小于或等于前一个月支付延迟1个月的账户数量。
- en: 'Let''s take a closer look at accounts with a 2-month delay in August and see
    what the payment status was in July. We can do this with the following code, using
    a Boolean mask and `.loc`, as shown in the following snippet:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看8月有2个月延迟的账户，查看它们在7月的支付状态。我们可以使用以下代码，通过布尔掩码和`.loc`来实现，代码示例如下：
- en: '[PRE81]'
  id: totrans-566
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'The output of this should appear as follows:'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果应该如下所示：
- en: '![Figure 1.45: Payment status in July (PAY_3) of accounts with a 2-month payment'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.45：8月有2个月支付延迟的账户在7月的支付状态（PAY_3）'
- en: delay in August (PAY_2)
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟支付状态（PAY_2）]
- en: '](img/B16925_01_45.jpg)'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_45.jpg)'
- en: 'Figure 1.45: Payment status in July (PAY_3) of accounts with a 2-month payment
    delay in August (PAY_2)'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.45：8月有2个月支付延迟的账户在7月的支付状态（PAY_3）（PAY_2）
- en: From *Figure 1.45*, it's clear that accounts with a 2-month delay in August
    have nonsensical values for the July payment status. The only way to progress
    to a 2-month delay should be from a 1-month delay the previous month, yet none
    of these accounts indicate that.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图1.45*可以看出，8月有2个月延迟的账户在7月的支付状态值是无意义的。实现2个月延迟的唯一途径应该是从前一个月的1个月延迟开始，但这些账户都没有显示这一点。
- en: When you see something like this in the data, you need to either check the logic
    in the query used to create the dataset or contact the person who gave you the
    dataset. After double-checking these results, for example using `.value_counts()`
    to view the numbers directly, we contact our client to inquire about this issue.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在数据中看到类似的情况时，你需要检查用来创建数据集的查询逻辑，或者联系提供数据集的人。在仔细检查这些结果之后，比如使用`.value_counts()`直接查看数字，我们联系了客户以询问这个问题。
- en: The client lets us know that they had been having problems with pulling the
    most recent month of data, leading to faulty reporting for accounts that had a
    1-month delay in payment. In September, they had mostly fixed these problems (although
    not entirely; that is why there were missing values in the `PAY_1` feature, as
    we found). So, in our dataset, the value of 1 is underreported in all months except
    for September (the `PAY_1` feature). In theory, the client could create a query
    to look back into their database and determine the correct values for `PAY_2`,
    `PAY_3`, and so on up to `PAY_6`. However, for practical reasons, they won't be
    able to complete this retrospective analysis in time for us to receive it and
    include it in our project.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 客户告诉我们，他们在获取最新月份数据时遇到了问题，这导致了支付延迟1个月的账户报告错误。在9月，他们大部分修复了这些问题（尽管没有完全修复，这也是我们发现`PAY_1`特征中存在缺失值的原因）。因此，在我们的数据集中，除了9月（`PAY_1`特征）之外，所有月份中的1的值都被低估了。从理论上讲，客户可以创建查询来回溯他们的数据库，并确定`PAY_2`、`PAY_3`等的正确值。然而，出于实际原因，他们无法在我们需要的时候完成这一回溯分析并将结果纳入我们的项目中。
- en: 'Because of this, only the most recent month of our payment status data is correct.
    This means that, of all the payment status features, only `PAY_1` is representative
    of future data, those that will be used to make predictions with the model we
    develop. This is a key point: *a predictive model relies on getting the same kind
    of data to make predictions as it was built with*. This means we can use `PAY_1`
    as a feature in our model, but not `PAY_2` or the other payment status features
    from previous months.'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的支付状态数据中只有最新月份是正确的。这意味着，在所有支付状态特征中，只有`PAY_1`能够代表未来数据，即将用于我们开发的模型进行预测的数据。这是一个关键点：*预测模型依赖于获取与其构建时相同类型的数据来进行预测*。这意味着我们可以将`PAY_1`作为模型中的特征，但不能使用`PAY_2`或来自前几个月的其他支付状态特征。
- en: This episode shows the importance of a thorough examination of data quality.
    Only by carefully combing through the data did we discover this issue. It would
    have been nice if the client had told us up front that they had been having reporting
    issues over the last few months, when our dataset was collected, and that the
    reporting procedure was not **consistent** during that time period. However, ultimately
    it is our responsibility to build a credible model, so we need to be sure we believe
    the data is correct, by making this kind of detailed exploration. We explain to
    the client that we can't use the older features since they are not representative
    of the future data the model will be **scored** on (that is, to make predictions
    on future months), and ask them to let us know of any further data issues they
    are aware of. There are none at this time.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节展示了对数据质量进行彻底检查的重要性。只有通过仔细地梳理数据，我们才发现了这个问题。如果客户能提前告知我们，在数据集收集的那段时间里，他们在报告过程中遇到过问题，并且报告过程在那段时间内并不**一致**，那就好了。然而，最终建立一个可信的模型是我们的责任，因此我们需要通过这种详细的探索，确保我们相信数据是正确的。我们向客户解释，由于旧的特征不代表模型将在其上进行**评分**的未来数据（即预测未来几个月的数据），因此无法使用这些旧特征，并要求他们告知我们他们所知的任何进一步的数据问题。目前没有。
- en: 'Activity 1.01: Exploring the Remaining Financial Features in the Dataset'
  id: totrans-577
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 1.01：探索数据集中的剩余财务特征
- en: 'In this activity, you will examine the remaining financial features in a similar
    way to how we examined `PAY_1`, `PAY_2`, `PAY_3`, and so on. In order to better
    visualize some of this data, we''ll use a mathematical function that should be
    familiar: the logarithm. You''ll use pandas'' `apply` method, which serves to
    apply any function to an entire column or DataFrame in the process. Once you complete
    the activity, you should have the following set of histograms of logarithmic transformations
    of non-zero payments:'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，您将以类似于我们检查 `PAY_1`、`PAY_2`、`PAY_3` 等特征的方式检查剩余的财务特征。为了更好地可视化这些数据，我们将使用一个大家应该熟悉的数学函数：对数。您将使用
    pandas 的 `apply` 方法，这个方法可以将任何函数应用到整个列或 DataFrame。在完成活动后，您应该得到以下一组非零支付对数变换的直方图：
- en: '![Figure 1.46: Expected set of histograms'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.46：预期的直方图集](img/B16925_01_46.jpg)'
- en: '](img/B16925_01_46.jpg)'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16925_01_46.jpg)'
- en: 'Figure 1.46: Expected set of histograms'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.46：预期的直方图集
- en: 'Perform the following steps to complete the activity:'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成活动：
- en: 'Before beginning, set up your environment and load in the cleaned dataset as follows:'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，设置您的环境并按以下方式加载清理过的数据集：
- en: '[PRE82]'
  id: totrans-584
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Create lists of feature names for the remaining financial features.
  id: totrans-585
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建剩余财务特征的特征名称列表。
- en: Use `.describe()` to examine statistical summaries of the bill amount features.
    Reflect on what you see. Does it make sense?
  id: totrans-586
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.describe()` 检查账单金额特征的统计摘要。反思一下你看到的内容。这合理吗？
- en: Visualize the bill amount features using a 2 by 3 grid of histogram plots.
  id: totrans-587
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 2x3 网格的直方图绘制账单金额特征。
- en: 'Hint: You can use 20 bins for this visualization.'
  id: totrans-588
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示：您可以为此可视化使用 20 个区间。
- en: Obtain the `.describe()` summary of the payment amount features. Does it make
    sense?
  id: totrans-589
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取支付金额特征的 `.describe()` 摘要。这合理吗？
- en: Plot a histogram of the bill payment features similar to the bill amount features,
    but also apply some rotation to the x-axis labels with the `xrot` keyword argument
    so that they don't overlap. In any plotting function, you can include the `xrot=<angle>`
    keyword argument to rotate x-axis labels by a given angle in degrees. Consider
    the results.
  id: totrans-590
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制类似于账单金额特征的账单支付特征的直方图，但也使用 `xrot` 关键字参数对 x 轴标签进行旋转，以避免重叠。在任何绘图函数中，您都可以使用 `xrot=<角度>`
    关键字参数，将 x 轴标签按给定角度（以度为单位）旋转。考虑一下结果。
- en: Use a Boolean mask to see how much of the payment amount data is exactly equal
    to 0\. Does this make sense given the histogram in the previous step?
  id: totrans-591
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用布尔掩码查看有多少支付金额数据正好等于 0。考虑一下在前一步的直方图中，这是否合理？
- en: Ignoring the payments of 0 using the mask you created in the previous step,
    use pandas' `.apply()` and NumPy's `np.log10()` to plot histograms of logarithmic
    transformations of the non-zero payments. Consider the results.
  id: totrans-592
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您在前一步创建的掩码忽略 0 的支付，使用 pandas 的 `.apply()` 和 NumPy 的 `np.log10()` 对非零支付的对数变换进行直方图绘制。考虑一下结果。
- en: 'Hint: You can use `.apply()` to apply any function, including `log10`, to all
    the elements of a DataFrame or a column using the following syntax: `.apply(<function_name>)`.'
  id: totrans-593
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示：您可以使用 `.apply()` 将任何函数，包括 `log10`，应用到 DataFrame 或列的所有元素，语法如下：`.apply(<函数名称>)`。
- en: Note
  id: totrans-594
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Jupyter notebook containing the Python code and corresponding outputs for
    this activity can be found here: [https://packt.link/FQQOB](https://packt.link/FQQOB).
    Detailed step-wise solution to this activity can be found via [this link](B16925_Solution_ePub.xhtml#_idTextAnchor149).'
  id: totrans-595
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含本次活动的Python代码及对应输出的Jupyter notebook可以在这里找到：[https://packt.link/FQQOB](https://packt.link/FQQOB)。本次活动的详细逐步解决方案可以通过[此链接](B16925_Solution_ePub.xhtml#_idTextAnchor149)找到。
- en: Summary
  id: totrans-596
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this introductory chapter, we made extensive use of pandas to load and explore
    the case study data. We learned how to check for basic consistency and correctness
    by using a combination of statistical summaries and visualizations. We answered
    such questions as "Are the unique account IDs truly unique?", "Is there any missing
    data that has been given a fill value?", and "Do the values of the features make
    sense given their definition?"
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的介绍部分，我们广泛使用了pandas来加载和探索案例研究数据。我们学习了如何通过结合统计摘要和可视化来检查基本的一致性和正确性。我们回答了诸如“唯一的账户ID真的唯一吗？”，“是否有缺失数据已被填充？”以及“特征的值是否符合其定义？”等问题。
- en: You may notice that we spent nearly all of this chapter identifying and correcting
    issues with our dataset. This is often the most time-consuming stage of a data
    science project. While it is not necessarily the most exciting part of the job,
    it gives you the raw materials necessary to build exciting models and insights.
    These will be the subjects of most of the rest of this book.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到，我们几乎将本章的所有时间都花在了识别和修正数据集的问题上。这通常是数据科学项目中最耗时的阶段。虽然这未必是最激动人心的部分，但它为你提供了构建激动人心的模型和洞察所需的原材料。这些将成为本书其余部分的大部分内容。
- en: Mastery of software tools and mathematical concepts is what allows you to execute
    data science projects, at a technical level. However, managing your relationships
    with clients, who are relying on your services to generate insights from their
    data, is just as important to successful projects. You must make as much use as
    you can of your business partner's understanding of the data. They are likely
    going to be more familiar with it than you, unless you are already a subject matter
    expert in the area. However, even in that case, your first step should be a thorough
    and critical review of the data you are using.
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 软件工具和数学概念的掌握使你能够在技术层面执行数据科学项目。然而，管理与客户的关系同样重要，因为客户依赖你的服务从数据中提取洞察。你必须尽可能多地利用业务伙伴对数据的理解。除非你已经是该领域的专家，否则他们对数据可能比你更熟悉。然而，即便如此，你的第一步应该是对所使用的数据进行彻底且批判性的审查。
- en: 'In our data exploration, we discovered an issue that could have undermined
    our project: the data we had received was not internally consistent. Most of the
    months of the payment status features were plagued by a data reporting issue,
    included nonsensical values, and were not representative of the most recent month
    of data, or the data that would be available to the model going forward. We only
    uncovered this issue by taking a careful look at all of the features. While this
    is not always possible, especially when there are very many features, you should
    always take the time to spot-check as many features as you can. If you can''t
    examine every feature, it''s useful to check a few of every category of feature,
    when the features fall into categories, such as financial or demographic features.'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的数据探索过程中，我们发现了一个可能会破坏我们项目的问题：我们收到的数据在内部并不一致。大多数支付状态特征的月份存在数据报告问题，包括不合逻辑的值，而且这些数据并不是最新一个月的数据，也不是未来模型可能使用的数据。我们只有通过仔细查看所有特征才发现了这个问题。虽然这并非总是可能的，特别是当特征非常多时，但你应该始终抽时间检查尽可能多的特征。如果无法检查每个特征，那么在特征有类别时，比如财务或人口统计特征，检查每类中的几个特征会很有用。
- en: When discussing data issues like this with your client, make sure you are respectful
    and professional. The client may simply have forgotten about the issue when presenting
    you with the data. Or, they may have known about it but assumed it wouldn't affect
    your analysis for some reason. In any case, you are doing them an essential service
    by bringing it to their attention and explaining why it would be a problem to
    use flawed data to build a model. Be as specific as you can, presenting the kinds
    of graphs and tables you used to discover the issue.
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 在与客户讨论此类数据问题时，请确保保持尊重和专业。客户在向你提供数据时，可能只是忘记了这个问题。或者，他们可能知道这个问题，但出于某种原因认为它不会影响你的分析。无论如何，你通过提醒客户并解释为何使用有缺陷的数据建立模型会成为问题，实际上是在为他们提供一项重要的服务。尽量具体说明，展示你用来发现问题的图表和表格类型。
- en: In the next chapter, we will examine the response variable for our case study
    problem, which completes the initial data exploration. Then we will start to get
    some hands-on experience with machine learning models and learn how we can decide
    whether a model is useful or not. These skills will be important when we start
    building models using the case study data.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将检查我们的案例研究问题中的响应变量，这将完成初步的数据探索。然后我们将开始接触机器学习模型，学习如何判断一个模型是否有用。当我们开始使用案例研究数据建立模型时，这些技能将变得非常重要。
