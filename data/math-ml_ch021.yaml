- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Optimization
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 优化
- en: If someone gave you a function defined by some tractable formula, how would
    you find its minima and maxima? Take a moment and conjure up some ideas before
    moving on.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有人给你一个由某个易处理的公式定义的函数，你将如何找到它的极小值和极大值？在继续之前，花点时间想想一些方法。
- en: The first idea that comes to mind for most people is to evaluate the function
    for all possible values and simply find the optimum. This method immediately breaks
    down due to multiple reasons. We can only perform finite evaluations, so this
    would be impossible. Even if we cleverly define a discrete search grid and evaluate
    only there, this method takes an unreasonable amount of time.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数人首先想到的方式是对所有可能的值评估函数，简单地找到最优解。但这种方法由于多种原因立即失败。我们只能进行有限的评估，因此这是不可能的。即使我们巧妙地定义一个离散的搜索网格并只在其上进行评估，这种方法也需要耗费不合理的时间。
- en: Another idea is to use some kind of inequality to provide an ad hoc upper or
    lower bound, then see if this bound can be attained. Sadly, this is nearly impossible
    for more complicated functions, like losses for neural networks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是使用某种不等式来提供一个特定的上界或下界，然后查看这个界限是否能达到。遗憾的是，对于更复杂的函数，如神经网络的损失函数，这几乎是不可能的。
- en: However, derivatives provide an extremely useful way to optimize functions.
    In this chapter, we will study the relationship between derivatives and optimal
    points, and algorithms on how to find them. Let’s go!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，导数提供了一种极其有用的方式来优化函数。在本章中，我们将研究导数与最优点之间的关系，以及如何找到它们的算法。让我们开始吧！
- en: 13.1 Minima, maxima, and derivatives
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.1 极小值、极大值和导数
- en: Intuitively, the notion of minima and maxima is simple. Take a look at Figure [13.1](#)
    below.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，极小值和极大值的概念很简单。看看下面的图[13.1](#)。
- en: '![PIC](img/file1245.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file1245.png)'
- en: 'Figure 13.1: Local and global optima'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1：局部和全局极值
- en: Peaks of hills are the maxima, and the bottoms of valleys are the minima. Minima
    and maxima are collectively called extremal or optimal points. As our example
    demonstrates, we have to distinguish between local and global optima. The graph
    has two valleys, and although both have a bottom, one of them is lower than the
    other.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 山峰的顶部是极大值，山谷的底部是极小值。极小值和极大值统称为极值点或最优点。正如我们的例子所示，我们必须区分局部最优解和全局最优解。图形中有两个山谷，虽然它们都有底部，但其中一个底部比另一个低。
- en: The really interesting part is finding these, as we’ll see next. Let’s consider
    our example above to demonstrate how derivatives are connected to local minima
    and maxima.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 真正有趣的部分是找到这些点，正如我们接下来将看到的那样。让我们考虑上面的例子来演示导数是如何与局部极小值和极大值相连接的。
- en: If we use our geometric intuition, we see that the tangents are horizontal at
    the peaks of the hills and the bottoms of the valleys. Intuitively, if the tangent
    line is not horizontal, then there’s an elevation or decline in the graph. This
    is illustrated by Figure [13.2](#).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运用几何直觉，我们会发现切线在山峰和山谷的底部是水平的。直观地说，如果切线不是水平的，那么图形上就有一个上升或下降。这在图[13.2](#)中得到了说明。
- en: '![PIC](img/file1246.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file1246.png)'
- en: 'Figure 13.2: Tangents at local and global optima'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2：局部和全局极值点的切线
- en: In terms of derivatives, since they describe the slope of the tangent, it means
    that the derivative should be 0 there.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从导数的角度来看，由于它们描述了切线的斜率，这意味着在该点导数应该为0。
- en: If we think about the function as the description of a motion along the real
    line, derivatives say that the motion stops there and changes direction. It slows
    down first, stops, then immediately starts in the opposite direction. For instance,
    in the local maxima case, the function increases up until that point, where it
    starts decreasing.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们把函数看作是沿着实数轴的运动描述，导数表明运动在该点停止并改变方向。它首先减速，停下来，然后立即开始向相反方向运动。例如，在局部最大值的情况下，函数在那个点之前增加，然后开始减少。
- en: '![PIC](img/file1247.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file1247.png)'
- en: 'Figure 13.3: The flow of the function'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3：函数的流动
- en: Again, we can describe this monotonicity behavior in terms of derivatives. Notice
    that when the function increases, the derivative is positive (the object in motion
    has a positive speed). On the other hand, decreasing parts have a negative derivative.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们可以通过导数来描述这种单调性行为。注意，当函数增加时，导数是正的（物体在运动时速度是正的）。另一方面，减小部分的导数是负的。
- en: '![PIC](img/file1248.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file1248.png)'
- en: 'Figure 13.4: The sign of the derivatives'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4：导数的符号
- en: We can go ahead and put these intuitions into a mathematical form. First, we’ll
    start with the definitions’ monotonicity, and their relation to the derivative.
    Then, we’ll connect all the dots and see how this comes together to characterize
    the optima.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些直觉转化为数学形式。首先，我们从定义的单调性开始，以及它们与导数的关系。然后，我们将所有点连接起来，看看这如何结合起来描述最优解。
- en: Definition 56\. (Locally increasing and decreasing functions)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 56\. （局部增大和减小函数）
- en: 'Let f : ℝ →ℝ be an arbitrary function and let a ∈ℝ. We say that'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : ℝ → ℝ 为一个任意函数，且 a ∈ ℝ。我们说'
- en: (a) f is locally increasing at a if there is a neighborhood (a −δ,a + δ) such
    that
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 如果 f 在 a 处局部增大，则在邻域 (a −δ, a + δ) 中存在这样一种情况：
- en: '![ (| ||| ≥ f(x), if x ∈ (a− δ,a), { f(a)|| ≤ f(x), if x ∈ (a,a+ δ), ||( ](img/file1249.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![ (| ||| ≥ f(x)，如果 x ∈ (a − δ, a)， { f(a)|| ≤ f(x)，如果 x ∈ (a, a + δ)， ||(
    ](img/file1249.png)'
- en: (b) and f is strictly locally increasing at a if there is a neighborhood (a
    −δ,a + δ) such that
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 并且如果在邻域 (a −δ, a + δ) 中存在这样的情况：
- en: '![ (| ||| > f(x), if x ∈ (a− δ,a), { f(a)|| < f(x), if x ∈ (a,a+ δ). ||( ](img/file1250.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![ (| ||| > f(x)，如果 x ∈ (a − δ, a)， { f(a)|| < f(x)，如果 x ∈ (a, a + δ)。 ||(
    ](img/file1250.png)'
- en: The locally decreasing and strictly locally decreasing properties are defined
    similarly, with the inequalities reversed.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 局部减小和严格局部减小的性质定义类似，只是不等式方向相反。
- en: For differentiable functions, the behavior of the derivative describes their
    local behavior in terms of monotonicity.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于可微函数，导数的行为描述了它们在单调性方面的局部行为。
- en: Theorem 84\.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 84\.
- en: 'Let f : ℝ →ℝ be an arbitrary function that is differentiable at some a ∈ℝ.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : ℝ → ℝ 为一个在某个 a ∈ ℝ 处可微的任意函数。'
- en: (a) If f^′(a) ≥ 0, then f is locally increasing at a.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 如果 f^′(a) ≥ 0，那么 f 在 a 处局部增大。
- en: (b) If f^′(a)/span>0, then f is strictly locally increasing at a.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 如果 f^′(a)/span>0，那么 f 在 a 处严格地局部增大。
- en: (c) If f^′(a) ≤ 0, then f is locally decreasing at a.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 如果 f^′(a) ≤ 0，那么 f 在 a 处局部减小。
- en: (d) If f^′(a)/span>0, then f is strictly locally decreasing at a.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 如果 f^′(a)/span>0，那么 f 在 a 处严格地局部减小。
- en: Proof. We will only show (a), since the rest of the proofs go the same way.
    Due to how limits are defined (Definition [51](ch019.xhtml#x1-190002r51)),
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。我们只证明 (a)，因为其余的证明是一样的。由于极限的定义方式（定义 [51](ch019.xhtml#x1-190002r51)），
- en: '![ f(x)-−-f(a) ′ lxi→ma x − a = f (a) ≥ 0 ](img/file1251.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![ f(x)-−-f(a) ′ lxi→ma x − a = f (a) ≥ 0 ](img/file1251.png)'
- en: means that once x gets close enough to a, that is, x is from a small neighborhood
    (a −δ,a + δ),
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着一旦 x 足够接近 a，即 x 来自于小邻域 (a −δ, a + δ)，
- en: '![f(x)−-f-(a)-≥ 0, x ∈ (a− δ,a + δ) x− a ](img/file1252.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![f(x)−-f-(a)-≥ 0，x ∈ (a− δ,a + δ) x− a ](img/file1252.png)'
- en: holds. If x >a, then because the differential quotient is nonnegative, f(x)
    ≥f(a) must hold. Similarly, for x <a, the nonnegativity of the differential quotient
    implies that f(x) ≤f(a).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 成立。如果 x >a，那么因为差商非负，必须有 f(x) ≥ f(a)。同样地，对于 x <a，差商的非负性意味着 f(x) ≤ f(a)。
- en: The proofs for (b), (c), and (d) are almost identical, with the obvious changes
    in the inequalities.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: (b)、(c) 和 (d) 的证明几乎完全相同，唯一的变化是在不等式中的显著改变。
- en: The propositions related to not strict monotonicity are true the other way around
    as well.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 与非严格单调性相关的命题也以相反的方式成立。
- en: Theorem 85\.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 85\.
- en: 'Let f : ℝ →ℝ be an arbitrary function that is differentiable at some a ∈ℝ.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : ℝ → ℝ 为一个在某个 a ∈ ℝ 处可微的任意函数。'
- en: (a) If f is locally increasing at a, then f^′(a) ≥ 0.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 如果 f 在 a 处局部增大，那么 f^′(a) ≥ 0。
- en: (b) If f is locally decreasing at a, then f^′(a) ≤ 0.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 如果 f 在 a 处局部减小，那么 f^′(a) ≤ 0。
- en: 'Proof. Similar to before, we will only show the proof of (a), since (b) can
    be done in the same way. If f is locally increasing at a, then the differential
    quotient is positive:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。与之前类似，我们只证明 (a)，因为 (b) 可以用相同的方式完成。如果 f 在 a 处局部增大，那么差商是正的：
- en: '![f(x)− f(a) -----------≥ 0\. x− a ](img/file1253.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![f(x)− f(a) -----------≥ 0\. x− a ](img/file1253.png)'
- en: Using the transfer principle of limits (Theorem [73](ch019.xhtml#x1-191005r73)),
    we obtain
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用极限的传递原理（定理 [73](ch019.xhtml#x1-191005r73)），我们得到
- en: '![ ′ f(x)-−-f(a) f (a ) = lxi→ma x − a ≥ 0, ](img/file1254.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![ ′ f(x)-−-f(a) f (a ) = lxi→ma x − a ≥ 0， ](img/file1254.png)'
- en: which is what we had to prove.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们需要证明的内容。
- en: After all this setup, we are ready to study local optima. What can the derivative
    tell us about them? Let’s see!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些准备工作完成后，我们准备研究局部最优解。导数能告诉我们什么关于它们的信息呢？让我们看看！
- en: 13.1.1 Local minima and maxima
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.1 局部最小值和最大值
- en: As we have seen in the introduction, the tangent at the extremal points is horizontal.
    Now it is time to put this introduction into a mathematically correct form.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在引言中看到的，极值点的切线是水平的。现在是时候将这个引言转化为一个数学上正确的形式了。
- en: Definition 57\. (Local minima and maxima)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 57.（局部最小值和最大值）
- en: 'Let f : ℝ →ℝ be an arbitrary function and let a ∈ℝ.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : ℝ →ℝ 是任意函数，且 a ∈ℝ。'
- en: (a) a is a local minimum, if there is a neighborhood (a −δ,a + δ) such that
    for every x ∈ (a −δ,a + δ), f(a) ≤f(x) holds.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 如果存在一个邻域 (a−δ,a+δ)，使得对于每一个 x ∈ (a−δ,a+δ)，都有 f(a) ≤ f(x)，则 a 是局部最小值。
- en: (b) a is a strict local minimum, if there is a neighborhood (a−δ,a+δ) such that
    for every x ∈ (a −δ,a + δ), f(a)/span>f(x) holds.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 如果存在一个邻域 (a−δ,a+δ)，使得对于每一个 x ∈ (a−δ,a+δ)，都有 f(a) < f(x)，则 a 是严格局部最小值。
- en: (c) a is a local maximum, if there is a neighborhood (a −δ,a + δ) such that
    for every x ∈ (a −δ,a + δ), f(x) ≤f(a) holds.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 如果存在一个邻域 (a−δ,a+δ)，使得对于每一个 x ∈ (a−δ,a+δ)，都有 f(x) ≤ f(a)，则 a 是局部最大值。
- en: (d) a is a strict local maximum, if there is a neighborhood (a−δ,a+δ) such that
    for every x ∈ (a −δ,a + δ), f(x)/span>f(a) holds.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 如果存在一个邻域 (a−δ,a+δ)，使得对于每一个 x ∈ (a−δ,a+δ)，都有 f(x) > f(a)，则 a 是严格局部最大值。
- en: Extremal points have their global versions as well. The sad truth is, even though
    we always want global optima, we only have the tools to find local ones.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 极值点也有其全局版本。遗憾的是，尽管我们总是追求全局最优解，但我们只有工具能够找到局部最优解。
- en: Definition 58\. (Global minima and maxima)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 58.（全局最小值和最大值）
- en: 'Let f : ℝ →ℝ be an arbitrary function and let a ∈ℝ.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : ℝ →ℝ 是任意函数，且 a ∈ℝ。'
- en: (a) a is a global minimum if f(a) ≤f(x) holds for every x ∈ℝ.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 如果对所有 x ∈ ℝ，f(a) ≤ f(x) 都成立，则 a 是全局最小值。
- en: (b) a is a global maximum if f(x) ≤f(a) holds for every x ∈ℝ.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 如果对所有 x ∈ ℝ，f(x) ≤ f(a) 都成立，则 a 是全局最大值。
- en: Note that a global optimum is also a local optimum, but not the other way around.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，全局最优解也是局部最优解，但反之则不成立。
- en: Theorem 86\.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 86\。
- en: 'Let f : ℝ →ℝ be an arbitrary function that is differentiable at some a ∈ℝ.
    If f has a local minima or maxima at a, then f^′(a) = 0.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : ℝ →ℝ 是在某点 a ∈ℝ 可微的任意函数。如果 f 在 a 处有局部最小值或最大值，则 f^′(a) = 0。'
- en: Proof. According to Theorem [84](ch021.xhtml#x1-212014r84), if f^′(a)≠0, then
    it is either strictly increasing or decreasing locally. Since this contradicts
    our assumption that a is a local optimum, the theorem is proven.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 证明：根据定理[84](ch021.xhtml#x1-212014r84)，如果 f^′(a)≠0，则该点在局部范围内要么严格递增，要么严格递减。由于这与我们假设
    a 是局部最优解相矛盾，因此该定理得证。
- en: (In case you are interested, this was the principle of contraposition (Theorem [150](ch036.xhtml#x1-371003r150))
    in action. From the negation of the conclusion, we have shown the negation of
    the premises.)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: （如果你感兴趣，这就是逆命题原理（定理[150](ch036.xhtml#x1-371003r150)）的实际应用。通过否定结论，我们证明了前提的否定。）
- en: It is very important to emphasize that the theorem is not true the other way
    around. For instance, the function f(x) = x³ is strictly increasing everywhere,
    yet f^′(0) = 0.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 强调这一点非常重要，即定理并非反过来也成立。例如，函数 f(x) = x³ 在任何地方都是严格递增的，但 f^′(0) = 0。
- en: In general, we call this behavior inflection. So, f(x) = x³ is said to have
    an inflection point at 0\. Inflection means a change in behavior, which reflects
    the switch in its derivative from decreasing to increasing in this case. (The
    multidimensional analogue of inflection is called a “saddle,” as we shall see
    later.)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们称这种行为为拐点。因此，f(x) = x³ 被认为在 0 处具有拐点。拐点意味着行为的变化，在这种情况下，反映了其导数从递减变为递增的转换。（多维的拐点类比被称为“鞍点”，我们稍后会讨论。）
- en: So, we are not at our end goal yet, as the other half of the promised characterization
    is missing.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们的最终目标还没有实现，因为所承诺的另一半刻画还没有完成。
- en: The derivative is zero at the local extremal points, but can we come up with
    a criterion that implies the existence of minima or maxima?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在局部极值点处导数为零，但我们能否提出一个准则，暗示最小值或最大值的存在？
- en: '![PIC](img/file1255.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1255.png)'
- en: 'Figure 13.5: Graph of f(x) = x³ as a counterexample to show that f^′(0) = 0
    doesn’t imply local optimum'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5：f(x) = x³ 的图像，作为反例展示 f^′(0) = 0 并不意味着局部最优解
- en: With the utilization of second derivatives, this is possible.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 利用二阶导数，这是可能的。
- en: 13.1.2 Characterization of optima with higher order derivatives
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.2 利用高阶导数刻画极值
- en: Let’s take a second look at our example, considering the local behavior of f^′
    this time, not just its sign. In Figure [13.6](#), the derivative is plotted along
    with our function.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一遍我们的例子，这次考虑 f^′ 的局部行为，而不仅仅是其符号。在图 [13.6](#) 中，导数与我们的函数一起绘制。
- en: '![PIC](img/file1456.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1456.png)'
- en: 'Figure 13.6: The function and its derivative'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6：函数及其导数
- en: 'The pattern seems simple: an increasing derivative implies a local minimum,
    a decreasing one means a local maximum. This aligns with our intuition about derivative
    as speed: local maximum means that the object is going in a positive direction,
    then stops and starts reversing.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模式看起来很简单：导数增大意味着局部最小值，导数减小意味着局部最大值。这与我们对于导数作为速度的直觉相符合：局部最大值意味着物体在正方向上运动，然后停下并开始反转。
- en: We can make this mathematically precise with the following theorem.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下定理将这一点数学化。
- en: Theorem 87\. (The second derivative test)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 87. （第二导数法则）
- en: 'Let f : ℝ →ℝ be an arbitrary function that is twice differentiable at some
    a ∈ℝ.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '设f : ℝ →ℝ是一个在某个a ∈ℝ处二次可微的任意函数。'
- en: (a) If f^′(a) = 0 and f^(′′)(a)/span>0, then a is a local minimum.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 如果f^′(a) = 0且f^(′′)(a)/span>0，那么a是局部最小值。
- en: (b) If f^′(a) = 0 and f^(′′)(a)/span>0, then a is a local maximum.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 如果f^′(a) = 0且f^(′′)(a)/span>0，那么a是局部最大值。
- en: Proof. Once again, we will only prove (a), since the proof of (b) is almost
    identical.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。再一次，我们只证明(a)，因为(b)的证明几乎是相同的。
- en: First, as we saw when discussing the relation between derivatives and monotonicity
    (Theorem [84](ch021.xhtml#x1-212014r84)), f^(′′)(a) 0 implies that f^′ is strictly
    locally increasing at a. Since f^′(a) = 0, this means that
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，正如我们在讨论导数与单调性之间的关系时所看到的（定理 [84](ch021.xhtml#x1-212014r84)），f^(′′)(a) 0意味着f^′在a处严格局部递增。由于f^′(a)
    = 0，这意味着
- en: '![ ( ′ |{ ≤ 0 if x ∈ (a− δ,a] f (x)| ( ≥ 0 if x ∈ [a,a + δ) ](img/file1257.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![ ( ′ |{ ≤ 0 如果x ∈ (a− δ,a] f (x)| ( ≥ 0 如果x ∈ [a,a + δ) ](img/file1257.png)'
- en: for some δ >0\. Because of Theorem [84](ch021.xhtml#x1-212014r84), f is locally
    decreasing in (a −δ,a] and locally increasing in [a,a + δ). This can only happen
    if a is a local minimum.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个δ > 0。根据定理 [84](ch021.xhtml#x1-212014r84)，f在(a −δ,a]内局部递减，在[a,a + δ)内局部递增。只有当a是局部最小值时，这种情况才可能发生。
- en: In summary, the method of finding the extrema of a function f is the following.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，找到函数f的极值的方法如下。
- en: Solve f^′(x) = 0\. Its solutions {x[1],…,x[n]} — called critical points — are
    the candidates that can be extremal points. (But not necessarily all of them are.)
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解f^′(x) = 0。它的解{x[1],…,x[n]} —— 被称为临界点 —— 是可能的极值点候选点。（但不一定所有解都是极值点。）
- en: Check the sign of f^(′′)(x[i]) for all solutions x[i]. If f^(′′)(x[i])/span>0,
    it is a local minimum. If f^(′′)(x[i])/span>0, it is a local maximum.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查所有解x[i]的f^(′′)(x[i])的符号。如果f^(′′)(x[i])/span>0，则为局部最小值。如果f^(′′)(x[i])/span>0，则为局部最大值。
- en: If f^(′′)(x[i]) = 0, we still can’t draw any conclusions. The functions x⁴,
    −x², and x³ show that critical points with zero second derivatives can be local
    minima, maxima, or neither.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果f^(′′)(x[i]) = 0，我们仍然无法得出任何结论。函数x⁴，−x²和x³表明，具有零二阶导数的临界点可以是局部最小值、最大值或两者都不是。
- en: Even though we have a “recipe,” this is still far from enough for practical
    purposes. Not counting that our functions of interest are multivariable, calculating
    the derivative and solving f^′(x) = 0 is not tractable. For loss functions of
    neural networks, we don’t even bother writing out a formula because, for a composition
    of hundreds of functions, it can be unreasonably complex.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们有了一个“公式”，这对于实际应用来说仍然远远不够。更不用说我们关心的函数是多变量的，计算导数并解f^′(x) = 0并不可行。对于神经网络的损失函数，我们甚至懒得写出公式，因为对于数百个函数的组合，公式可能会变得异常复杂。
- en: 13.1.3 Mean value theorems
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.3 均值定理
- en: In some cases, we can extract a lot of information about the derivatives without
    explicitly calculating them. These results are extremely useful in cases where
    we don’t have an explicit formula for the function or the formula might be too
    huge. (Like in the case of neural networks.) In the following, we’ll get to meet
    the famous mean value theorems, connecting the function’s behavior at the endpoints
    and inside an interval.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，我们可以不显式计算导数就提取出很多关于导数的信息。这些结果在我们没有函数的显式公式或公式可能非常庞大的情况下（例如在神经网络的情况下）极为有用。接下来，我们将介绍著名的均值定理，连接函数在区间端点和区间内的行为。
- en: First, we start with a special case that states that the function attains the
    same value at the end of some interval [a,b], then its derivative is zero somewhere
    inside the interval.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从一个特殊的情况开始，假设函数在某个区间[a,b]的末端取得相同的值，那么它的导数在该区间内某处为零。
- en: Theorem 88\. (Rolle’s mean value theorem)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 88. （罗尔均值定理）
- en: 'Let f : ℝ →ℝ be a differentiable function and suppose that f(a) = f(b) for
    some a≠b. Then there exists a ξ ∈ (a,b) such that f^′(ξ) = 0.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '设f : ℝ →ℝ是一个可微函数，且假设对于某个a≠b，f(a) = f(b)。则存在一个ξ ∈ (a,b)，使得f^′(ξ) = 0。'
- en: Proof. If you are a visual person, take a look at Figure [13.7](#). This is
    what we need to show.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。如果你是一个喜欢可视化的人，可以看一下图 [13.7](#)。这就是我们需要证明的内容。
- en: '![PIC](img/file1258.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1258.png)'
- en: 'Figure 13.7: Rolle’s theorem'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7：罗尔定理
- en: To be mathematically precise, there are two cases. First, if f is constant on
    [a,b], then its derivative is zero on the entire interval.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了数学上的精确性，存在两种情况。首先，如果 f 在 [a,b] 上是常数，那么它在整个区间上的导数为零。
- en: If f is not constant, then it attains some value c inside (a,b) that is not
    equal to f(a) = f(b). For simplicity, suppose that c >f(a). (The argument that
    follows goes through in the c <f(a) case with some obvious changes.) Since f is
    continuous, it attains its maximum there at a point ξ ∈ [a,b]. (See Theorem [76](ch019.xhtml#x1-193003r76).)
    According to what we have just seen regarding the relation of local maxima and
    the derivative (Theorem [86](ch021.xhtml#x1-213005r86)), f^′(ξ) = 0, which is
    what we had to show.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 f 不是常数，那么它在 (a,b) 内达到某个不等于 f(a) = f(b) 的值 c。为了简化，假设 c > f(a)。（如果是 c < f(a)
    的情况，接下来的论证也能成立，只需做一些显而易见的调整。）由于 f 是连续的，它在 [a,b] 上会在某个点 ξ ∈ [a,b] 处达到最大值。（见定理 [76](ch019.xhtml#x1-193003r76)）。根据我们刚刚看到的关于局部极值与导数关系的内容（定理
    [86](ch021.xhtml#x1-213005r86)），有 f^′(ξ) = 0，这就是我们要证明的内容。
- en: Rolle’s theorem is an important stepping stone towards Lagrange’s mean value
    theorem, which we will show in the following.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 罗尔定理是通向拉格朗日均值定理的重要跳板，接下来我们将证明这一点。
- en: Theorem 89\. (Lagrange’s mean value theorem)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 89\.（拉格朗日均值定理）
- en: 'Let f : ℝ → ℝ be a differentiable function and [a,b] an interval for some a≠b.
    Then there exists a ξ ∈ (a,b) such that'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : ℝ → ℝ 为可微函数，且 [a,b] 为某个 a≠b 的区间。那么存在 ξ ∈ (a,b)，使得'
- en: '![ ′ f(b)− f(a) f (ξ) = --b-−-a---- ](img/file1259.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![ ′ f(b)− f(a) f (ξ) = --b-−-a---- ](img/file1259.png)'
- en: holds.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 成立。
- en: Proof. Again, let’s start with a visualization to get a grip on the theorem.
    Figure [13.8](#) shows what we need to show.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。让我们再次从一个可视化开始，以便更好地理解该定理。图 [13.8](#) 展示了我们需要证明的内容。
- en: '![PIC](img/file1260.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1260.png)'
- en: 'Figure 13.8: Lagrange’s mean value theorem'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.8：拉格朗日均值定理
- en: Recall that ![f(b)−f(a)- b−a](img/file1261.png) is the slope of the line going
    through (a,f(a)) and (b,f(b)). This line is described by the function
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，![f(b)−f(a)- b−a](img/file1261.png) 是通过 (a,f(a)) 和 (b,f(b)) 两点的直线的斜率。该直线由以下函数描述：
- en: '![f(b)− f(a) -----------(x− a) + f(a), b− a ](img/file1262.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![f(b)− f(a) -----------(x− a) + f(a), b− a ](img/file1262.png)'
- en: as given by the point-slope equation of a line. Using this, we introduce the
    function
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如通过直线的点斜式方程给出。利用这一点，我们引入函数
- en: '![ f(b)− f (a) g(x) := f (x)− (-----------(x − a) + f(a)). b− a ](img/file1263.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![ f(b)− f (a) g(x) := f (x)− (-----------(x − a) + f(a)). b− a ](img/file1263.png)'
- en: We can apply Rolle’s theorem to g(x), since g(a) = g(b) = 0\. Thus, for some
    ξ ∈ (a,b), we have
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将罗尔定理应用于 g(x)，因为 g(a) = g(b) = 0。因此，对于某个 ξ ∈ (a,b)，我们有
- en: '![g′(ξ) = 0 = f ′(ξ)− f(b)−-f(a), b − a ](img/file1264.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![g′(ξ) = 0 = f ′(ξ)− f(b)−-f(a), b − a ](img/file1264.png)'
- en: implying f^′(ξ) = ![f(b)b−−fa(a)-](img/file1265.png), which is what we had to
    show.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着 f^′(ξ) = ![f(b)b−−fa(a)-](img/file1265.png)，这是我们需要证明的内容。
- en: 'Why are mean value theorems so important? In mathematics, they serve as a cornerstone
    in several results. To give you one example, think about integration. (Perhaps
    you are familiar with this concept already. Don’t worry if not, we are going to
    study it in detail later.) Integration is essentially the inverse of differentiation:
    if F^′(x) = f(x), then'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么均值定理如此重要？在数学中，它们在多个结果中起着基石的作用。举个例子，想一想积分。（或许你已经熟悉这个概念了。如果不熟悉也没关系，我们稍后会详细学习它。）积分本质上是微分的逆过程：如果
    F^′(x) = f(x)，那么
- en: '![∫ b a f (x )dx = F (b)− F (a), ](img/file1266.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![∫ b a f (x )dx = F (b)− F (a), ](img/file1266.png)'
- en: which will be a simple consequence of Lagrange’s mean value theorem.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是拉格朗日均值定理的一个简单推论。
- en: 13.2 The basics of gradient descent
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.2 梯度下降的基础
- en: 'We need to solve two computational problems to train neural networks:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要解决两个计算问题来训练神经网络：
- en: computing the derivative of the loss L(w),
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算损失 L(w) 的导数，
- en: and finding its minima using the derivative.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并且通过导数找到它的最小值。
- en: 'Finding the minima by solving ![ddw--](img/file1267.png)L(w) = 0 is not going
    to work in practice. There are several problems. First, as we have seen, not all
    solutions are minimal points: there are maximal and inflection points as well.
    Second, solving this equation is not feasible except in the simplest cases, like
    for linear regression with the mean squared error. Training a neural network is
    not a simple case.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 通过求解![ddw--](img/file1267.png)L(w) = 0来寻找最小值在实际中行不通。存在几个问题。首先，正如我们所看到的，并不是所有的解都是最小点：还有最大点和拐点。其次，除非在最简单的情况下，比如线性回归和均方误差，否则解这个方程是不可行的。训练神经网络不是简单的案例。
- en: 'Fortunately for us, machine learning practitioners, there is a solution: gradient
    descent! The famous gradient descent provides a way to tackle the complexity of
    finding the exact solution, enabling us to do machine learning on a large scale.
    Let’s see how it’s done!'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，对于我们这些机器学习从业者来说，有一个解决方案：梯度下降！著名的梯度下降提供了一种方法来应对寻找精确解的复杂性，使我们能够大规模地进行机器学习。让我们看看它是如何实现的！
- en: 13.2.1 Derivatives, revisited
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.1 再访导数
- en: When we first explored the concept of the derivative in Chapter [12](ch020.xhtml#differentiation),
    we saw its many faces. We have learned that the derivative can be thought of as
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们第一次在第[12](ch020.xhtml#differentiation)章探讨导数的概念时，我们看到了它的多种形式。我们已经学到，导数可以被看作
- en: speed (when the function describes a time-distance graph of a moving object),
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 速度（当函数描述一个移动物体的时间-距离图时），
- en: the slope of the tangent line of a function,
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数切线的斜率，
- en: and the best linear approximator at a given point.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在给定的点上的最佳线性近似器。
- en: 'To understand how gradient descent works, we’ll see yet another interpretation:
    derivatives as vectors. For any differentiable function f(x), the derivative f^′(x)
    can be thought of as a one-dimensional vector. If f^′(x) is positive, it points
    to the right. If it is negative, it points to the left. We can visualize this
    by drawing a horizontal vector to every point of f(x)-s graph, where the length
    represents jf^′(x)j and the direction represents the sign. This is illustrated
    by Figure [13.9](#).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解梯度下降是如何工作的，我们将看到另一个解释：导数作为向量。对于任何可微分函数f(x)，导数f^′(x)可以被看作一个一维向量。如果f^′(x)是正的，它指向右侧。如果是负的，它指向左侧。我们可以通过为f(x)图形上的每个点画一条水平向量来可视化这一点，其中向量的长度代表|f^′(x)|，方向代表符号。图[13.9](#)展示了这一过程。
- en: '![PIC](img/file1268.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1268.png)'
- en: 'Figure 13.9: The derivative as a vector'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.9：导数作为一个向量
- en: Do you recall how monotonicity is characterized by the sign of the derivative?
    (As Theorem [84](ch021.xhtml#x1-212014r84) states.) Negative derivative means
    a decreasing function, and positive means an increasing function. In other words,
    this implies that the derivative, as a vector, points towards the direction of
    the increase.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否还记得单调性是如何通过导数的符号来描述的？（正如定理[84](ch021.xhtml#x1-212014r84)所述。）负导数意味着函数递减，正导数意味着函数递增。换句话说，这意味着导数作为一个向量指向增大的方向。
- en: Imagine yourself as a hiker on the x-y plane, where y signifies the height.
    How would you climb a mountain ahead of you? By taking a step towards the direction
    of increase; that is, following the derivative. If you are not there yet, you
    can still take another (perhaps smaller) step in the right direction, over and
    over again until you arrive. If you are right at the top, the derivative is zero,
    so you won’t move anywhere.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你自己是x-y平面上的一个徒步旅行者，y表示高度。你如何攀登面前的山？通过朝着增高的方向迈出一步；也就是说，跟随导数。如果你还没有到达山顶，你仍然可以在正确的方向上再迈出一步（也许更小），反复如此，直到到达顶峰。如果你已经在山顶，导数就是零，你就不会再移动。
- en: This process is illustrated by Figure [13.10](#).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程如图[13.10](#)所示。
- en: '![PIC](img/file1269.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1269.png)'
- en: 'Figure 13.10: Climbing a mountain, one step at a time'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.10：一步一步爬山
- en: What you have seen here is gradient ascent in action. Now that we understand
    the main idea, we are ready to tackle the mathematical details.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到的正是梯度上升的过程。现在我们已经理解了主要思想，准备处理数学细节。
- en: 13.2.2 The gradient descent algorithm
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.2 梯度下降算法
- en: 'Let f : ℝ →ℝ be a differentiable function which we want to maximize, that is,
    find'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '设f : ℝ →ℝ是我们想要最大化的可微函数，也就是说，找到'
- en: '![xmax = argmaxx ∈ℝf(x). ](img/file1270.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![xmax = argmaxx ∈ℝf(x). ](img/file1270.png)'
- en: Based on our intuition, the process is quite simple. First, we conjure up an
    arbitrary starting point x[0], then define the sequence
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们的直觉，过程相当简单。首先，我们设定一个任意的起始点x[0]，然后定义序列
- en: x[n+1] := x[n] + h f′(x[n]), (13.1)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: x[n+1] := x[n] + h f′(x[n]), (13.1)
- en: where h ∈ (0,∞) is a parameter of our gradient descent algorithm, called the
    learning rate.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 其中h ∈ (0,∞)是我们梯度下降算法的一个参数，称为学习率。
- en: In English, the formula x[n] + hf^′(x[n]) describes taking a small step from
    x[n] towards the direction of the increase, with step size hf^′(x[n]). (Recall
    that the sign of the derivative shows the direction of the increase.)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在英语中，公式x[n] + hf^′(x[n])描述了从x[n]出发，朝着增大方向迈出一步，步长为hf^′(x[n])。（回想一下，导数的符号表示增大的方向。）
- en: If things go our way, the sequence x[n] converges to a local maximum of f. However,
    things do not always go our way. We’ll discuss this when talking about the issues
    of gradient descent.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，序列x[n]会收敛到f的局部最大值。然而，事情并不总是按照我们的计划进行。我们将在讨论梯度下降的问题时谈到这一点。
- en: 'But what about finding minima? In machine learning, we are trying to minimize
    loss functions. There is a simple trick: the minima of f(x) is the maxima of −f(x).
    So, since ( −f)^′ = −f^′, the definition of the approximating sequence x[n] changes
    to'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如何找到最小值呢？在机器学习中，我们试图最小化损失函数。有一个简单的技巧：f(x)的最小值就是−f(x)的最大值。因此，既然( −f)^′ = −f^′，逼近序列x[n]的定义就变为
- en: '![x := x − hf′(x ). n+1 n n ](img/file1273.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![x := x − hf′(x ). n+1 n n ](img/file1273.png)'
- en: This is gradient descent in a nutshell.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是梯度下降的核心概念。
- en: 13.2.3 Implementing gradient descent
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.3 实现梯度下降
- en: At this point, we have all the knowledge to implement the gradient descent algorithm.
    We’ll use the previously introduced Function base class; here it is again so you
    don’t have to look up the class definition.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，我们已经具备了实现梯度下降算法的所有知识。我们将使用之前介绍的Function基类；在这里再次给出它，以免你需要查找类定义。
- en: '[PRE0]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As usual, I encourage you to try implementing your version of gradient descent
    before looking at mine. Coding is one of the most effective ways to learn, even
    in the age of AI – especially in the age of AI.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我鼓励你在查看我的实现之前，先尝试实现你自己的梯度下降版本。编程是学习最有效的方式之一，即使在人工智能的时代——特别是在人工智能的时代。
- en: '[PRE1]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Let’s test the gradient descent out on a simple example, say f(x) = x²! If all
    goes according to plan, the algorithm should find the minimum x = 0 in no time.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个简单的例子上测试梯度下降，假设f(x) = x²！如果一切顺利，算法应该会在短时间内找到最小值x = 0。
- en: '[PRE2]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The result is as expected: our gradient_descent function successfully finds
    the minimum.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如预期：我们的gradient_descent函数成功找到了最小值。
- en: To visualize what happens, we can plot the process in its entirety. As we’ll
    reuse the same plot, here’s a general function that does this job.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化发生的过程，我们可以绘制整个过程。由于我们将重复使用相同的图表，这里有一个通用函数来完成这个工作。
- en: '[PRE4]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![PIC](img/file1274.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1274.png)'
- en: 'Figure 13.11: Finding the minima of f(x) = x² by gradient descent'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.11：通过梯度下降找到f(x) = x²的最小值
- en: So, is it all happiness and sunshine? No, but that’s fine. Let’s see what can
    go wrong, and how we can fix it.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，一切都是快乐和阳光吗？不是，但这没关系。让我们看看可能出现的问题，以及如何解决它们。
- en: 13.2.4 Drawbacks and caveats
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.4 缺点与警告
- en: Even though the idea behind gradient descent is sound, there are several issues.
    During our journey in machine learning, we’ll see most of these issues fixed by
    variants of the algorithm, but it is worth looking at the potential problems of
    the base version at this point.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管梯度下降背后的思想是合理的，但它仍然存在一些问题。在我们的机器学习旅程中，我们会看到大多数这些问题通过算法的变种得到解决，但在此时了解基础版本可能出现的问题也是值得的。
- en: First, the base gradient descent can get infinitely stuck at a local minima.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，基础的梯度下降算法可能会在局部最小值处陷入无限循环。
- en: To illustrate this, let’s take a look at the f(x) = cos(x) + ![1 2](img/file1275.png)x
    function, which has no global minima, only local ones.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，让我们看看f(x) = cos(x) + ![1 2](img/file1275.png)x函数，它没有全局最小值，只有局部最小值。
- en: '[PRE5]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![PIC](img/file1276.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1276.png)'
- en: 'Figure 13.12: Running the gradient descent on f(x) = sin(x) + 1/2x'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.12：运行梯度下降于f(x) = sin(x) + 1/2x
- en: Note that if the initial point x[0] is selected poorly, the algorithm is much
    less effective. In other words, sensitivity to the initial conditions is another
    weakness. It might not seem that much of an issue in the simple one-variable case
    that we have just seen. However, it is a significant headache in the million-dimensional
    parameter spaces that we encounter when training neural networks.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果初始点x[0]选择不当，算法的效果会大打折扣。换句话说，对初始条件的敏感性是另一个弱点。在我们刚刚看到的简单一维案例中，这个问题可能不那么明显。然而，在训练神经网络时，我们会遇到百万维的参数空间，这时它就是一个巨大的难题。
- en: 'The starting point is not the only parameter of the algorithm; it depends on
    the learning rate h as well. There are several potential mistakes here: a too
    large learning rate results in the algorithm bouncing all around the space, never
    finding an optimum. On the other hand, a too small one results in an extremely
    slow convergence.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 起始点并不是算法的唯一参数；它还依赖于学习率h。这里有几个潜在的错误：过大的学习率会导致算法在空间中四处弹跳，永远找不到最优解。另一方面，过小的学习率会导致收敛速度极慢。
- en: In the case of f(x) = x², starting the gradient descent from x[0] = 1.0 with
    a learning rate of h = 1.05, the algorithm diverges, with x[n] oscillating at
    a larger and larger amplitude.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在f(x) = x²的情况下，从x[0] = 1.0开始梯度下降，学习率为h = 1.05，算法发散，x[n]在越来越大的幅度下振荡。
- en: '[PRE6]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![PIC](img/file1278.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1278.png)'
- en: 'Figure 13.13: Gradient descent, as it overshoots the optimum because of the
    large learning rate'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.13：梯度下降，由于学习率过大导致错过最优解
- en: Can you come up with some solution ideas to these problems? No need to work
    anything out, just take a few minutes to brainstorm and make a mental note about
    what comes to mind. In the later chapters, we’ll see several proposed solutions
    for all of these problems, but putting some time into this is a very useful exercise.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 你能想到一些解决这些问题的方案吗？无需进行详细的计算，只需花几分钟进行头脑风暴，记下你想到的内容。在后续章节中，我们会看到这些问题的几种解决方案，但花些时间思考这些问题是一个非常有益的练习。
- en: 'However, if you have an eye for detail, you might ask: does gradient descent
    always converge to a local optimum? Why does it work so well in practice? Let’s
    take a look.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你注重细节，可能会问：梯度下降总是会收敛到局部最优解吗？为什么它在实践中如此有效？让我们来看看。
- en: 13.3 Why does gradient descent work?
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.3 为什么梯度下降有效？
- en: Young man, in mathematics you don’t understand things. You just get used to
    them. — John von Neumann
  id: totrans-187
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 年轻人，在数学中你并不理解事物。你只是习惯它们。——约翰·冯·诺依曼
- en: In the practice of machine learning, we use gradient descent so much that we
    get used to it. We hardly ever question why it works.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的实践中，我们如此频繁地使用梯度下降，以至于我们已经习惯了它。我们几乎从不质疑它为何有效。
- en: 'What’s usually told is the mountain-climbing analogue: to find the peak (or
    the bottom) of a bumpy terrain, one has to look at the direction of the steepest
    ascent (or descent), and take a step in that direction. This direction is desribed
    by the gradient, and the iterative process of finding local extrema by following
    the gradient is called gradient ascent/descent. (Ascent for finding peaks, descent
    for finding valleys.)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的解释是爬山类比：为了找到一个崎岖地形的山顶（或山谷），需要观察最陡上升（或下降）方向，并朝该方向迈出一步。这个方向由梯度描述，而通过跟随梯度迭代寻找局部极值的过程称为梯度上升/下降。（上升用于寻找山顶，下降用于寻找山谷。）
- en: However, this is not a mathematically precise explanation. There are several
    questions left unanswered, and based on our mountain-climbing intuition, it’s
    not even clear if the algorithm works.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不是一个数学上精确的解释。仍然存在一些未解答的问题，并且根据我们的爬山直觉，甚至不清楚该算法是否有效。
- en: Without a precise understanding of gradient descent, we are practically flying
    blind. In this section, our goal is to look behind gradient descent and reveal
    the magic behind it.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有对梯度下降的精确理解，我们实际上是在盲目地操作。在本节中，我们的目标是深入探讨梯度下降背后的原理，揭示其中的奥秘。
- en: 'Understanding the “whys” of gradient descent starts with one of the most beautiful
    areas of mathematics: differential equations.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 理解梯度下降的“为什么”从数学中最美丽的领域之一——微分方程开始。
- en: 13.3.1 Differential equations 101
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.1 微分方程入门
- en: What is a differential equation? Equations play an essential role in mathematics;
    this is common wisdom, but there is a deep truth behind it. Quite often, equations
    arise from modeling systems such as interactions in a biochemical network, economic
    processes, and thousands more. For instance, modelling the metabolic processes
    in organisms yields linear equations of the form
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是微分方程？方程在数学中扮演着至关重要的角色；这是一条常识，但其背后有着深刻的真理。方程常常来源于对系统的建模，例如生化网络中的相互作用、经济过程等成千上万的应用。例如，建模有机体中的代谢过程会得到如下形式的线性方程：
- en: '![Ax = b, A ∈ ℝn×n, x,b ∈ ℝn ](img/file1279.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![Ax = b, A ∈ ℝn×n, x,b ∈ ℝn ](img/file1279.png)'
- en: where the vectors x and b represent the concentration of molecules (where x
    is the unknown), and the matrix A represents the interactions between them. Linear
    equations are easy to solve, and we understand quite a lot about them.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 其中向量 x 和 b 表示分子浓度（其中 x 为未知量），矩阵 A 表示它们之间的相互作用。线性方程容易求解，我们对它们了解颇多。
- en: However, the equations we have seen so far are unfit to model dynamical systems,
    as they lack a time component. To describe, for example, the trajectory of a space
    station orbiting around Earth, we have to describe our models in terms of functions
    and their derivatives.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们迄今为止看到的方程并不适合用来描述动力学系统，因为它们缺少时间组件。例如，要描述绕地球轨道运行的空间站的轨迹，我们必须用函数及其导数来描述我们的模型。
- en: For instance, the trajectory of a swinging pendulum can be described by the
    equation
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，摆动的钟摆的轨迹可以通过方程描述：
- en: x″(t) + (g/L) sin x(t) = 0, (13.2)
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: x″(t) + (g/L) sin x(t) = 0, (13.2)
- en: where
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: x(t) describes the angle of the pendulum from the vertical,
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x(t) 描述钟摆相对于竖直方向的角度，
- en: L is the length of the (massless) rod that our object of mass m hangs on,
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L 是（无质量）杆的长度，物体的质量为 m，物体悬挂在其上，
- en: and g is the gravitational acceleration constant ≈ 9.81m∕s².
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其中 g 是重力加速度常数 ≈ 9.81 m/s²。
- en: According to the original interpretation of differentiation, if x(t) describes
    the movement of the pendulum at time t, then x^′(t) and x^(′′)(t) describe the
    velocity and the acceleration of it, where the differentiation is taken with respect
    to the time t.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 根据微分的原始解释，如果 x(t) 描述了钟摆在时刻 t 的运动，那么 x^′(t) 和 x^(′′)(t) 分别描述了它的速度和加速度，其中微分是相对于时间
    t 进行的。
- en: (In fact, the differential equation ([13.2](ch021.xhtml#differential-equations-))
    is a direct consequence of Newton’s second law of motion.)
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: （实际上，微分方程（[13.2](ch021.xhtml#differential-equations-)）是牛顿第二定律的直接结果。）
- en: '![PIC](img/file1281.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1281.png)'
- en: 'Figure 13.14: A swinging pendulum'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.14：摆动的钟摆
- en: 'Equations involving functions and their derivatives, such as ([13.2](ch021.xhtml#differential-equations-)),
    are called ordinary differential equations, or ODEs for short. Without any overexaggeration,
    their study has been the main motivating force of mathematics since the 17th century.
    Trust me when I say this: differential equations are one of the most beautiful
    objects in mathematics. As we are about to see, the gradient descent algorithm
    is, in fact, an approximate solution of differential equations.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 包含函数及其导数的方程，如（[13.2](ch021.xhtml#differential-equations-)），被称为常微分方程，简称 ODE。从17世纪起，它们的研究几乎可以说是推动数学发展的主要动力。相信我，当我说微分方程是数学中最美丽的对象之一时，你会明白的。正如我们将看到的，梯度下降算法实际上是微分方程的一个近似解。
- en: The first part of this section will serve as a quickstart to differential equations.
    I am mostly going to follow the fantastic Nonlinear Dynamics and Chaos book by
    Steven Strogatz. If you ever feel the desire to dig deep into dynamical systems,
    I wholeheartedly recommend this book to you. (This is one of my favorite math
    books ever – it reads like a novel. The quality and clarity of its exposition
    serves as a continuous inspiration for my writing.)
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的第一部分将作为微分方程的快速入门。我将主要跟随 Steven Strogatz 的《非线性动力学与混沌》这本精彩的书。如果你有兴趣深入研究动力学系统，我全心全意推荐这本书给你。（这是我最喜欢的数学书籍之一——它读起来像小说一样。书中阐述的质量和清晰度始终是我写作的持续灵感来源。）
- en: 13.3.2 The (slightly more) general form of ODEs
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.2 常微分方程的（稍微更一般的）形式
- en: Let’s dive straight into the deep waters and start with an example to get a
    grip on differential equations. Quite possibly, the simplest example is the equation
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接跳入深水，先从一个例子开始，以掌握微分方程。很可能，最简单的例子是方程
- en: '![ ′ x(t) = x (t), ](img/file1282.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![ ′ x(t) = x (t), ](img/file1282.png)'
- en: 'where the differentiation is taken with respect to the time variable t. If,
    for example, x(t) is the size of a bacterial colony, the equation x^′(t) = x(t)
    describes its population dynamics if the growth is unlimited. Think about x^′(t)
    as the rate at which the population grows: if there are no limitations in space
    and nutrients, every bacterial cell can freely replicate whenever possible. Thus,
    since every cell can freely divide, the speed of growth matches the colony’s size.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，微分是相对于时间变量 t 进行的。例如，如果 x(t) 是细菌群落的大小，那么方程 x^′(t) = x(t) 描述的是其种群动态，假设增长是无限的。可以将
    x^′(t) 理解为种群增长的速度：如果空间和养分没有限制，每个细菌细胞都可以随时自由繁殖。因此，由于每个细胞都可以自由分裂，增长的速度与群落的大小成正比。
- en: 'In plain English, the solutions of the equation x^′(t) = x(t) are functions
    whose derivatives are themselves. After a bit of thinking, we can come up with
    a family of solutions: x(t) = ce^t, where c ∈ℝ is an arbitrary constant. (Recall
    that e^t is an elementary function, and we have seen that its derivative is itself
    in Theorem [82](ch020.xhtml#x1-203003r82).)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 用通俗的语言来说，方程 x^′(t) = x(t) 的解是其导数等于自身的函数。稍加思考，我们可以得到一个解的族：x(t) = ce^t，其中 c ∈ℝ
    是一个任意常数。（回想一下，e^t 是一个初等函数，我们在定理 [82](ch020.xhtml#x1-203003r82) 中已经看到它的导数是它自己。）
- en: If you are a visual person, some of the solutions are plotted on Figure [13.15](#).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一个视觉型的人，可以在图 [13.15](#) 上看到一些解的图像。
- en: 'There are two key takeaways here: differential equations describe dynamical
    processes that change in time, and they can have multiple solutions. Each solution
    is determined by two factors: the equation x^′(t) = x(t), and an initial condition
    x(0) = x^∗. If we specify x(0) = x^∗, then the value of c is given by'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个关键要点：微分方程描述了随时间变化的动态过程，而且它们可能有多个解。每个解由两个因素决定：方程 x^′(t) = x(t)，和初始条件 x(0)
    = x^∗。如果我们指定 x(0) = x^∗，那么常数 c 的值为
- en: '![x(0) = ce0 = c = x∗. ](img/file1283.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![x(0) = ce0 = c = x∗. ](img/file1283.png)'
- en: Thus, ODEs have a bundle of solutions, each one determined by the initial condition.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，常微分方程有一组解，每一个解由初始条件确定。
- en: So, it’s time to discuss differential equations in more general terms!
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在是时候更一般性地讨论微分方程了！
- en: '![PIC](img/file1284.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1284.png)'
- en: 'Figure 13.15: Some solutions of the exponential growth equation'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.15：指数增长方程的一些解
- en: Definition 59\. (Ordinary differential equations in one dimension)
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 59. （一维常微分方程）
- en: 'Let f : ℝ →ℝ be a differentiable function. The equation'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : ℝ →ℝ 是一个可微函数。方程'
- en: x′(t) = f(x(t)) (13.3)
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: x′(t) = f(x(t)) （13.3）
- en: is called a first-order homogeneous ordinary differential equation.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 称为一阶齐次常微分方程。
- en: When it is clear, the dependence on t is often omitted, so we only write x^′
    = f(x). (Some resources denote the time derivative by ẋ, a notation that can be
    originated from Newton. We will not use this, though it is good to know.)
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 当情况明确时，t 的依赖性通常会被省略，所以我们只写 x^′ = f(x)。 （一些资源用 ẋ 表示时间导数，这种符号可能源自牛顿。我们不会使用这个符号，尽管了解它是有益的。）
- en: The term “first-order homogeneous ordinary differential equation” doesn’t exactly
    roll off the tongue, and it is overloaded with heavy terminology. So, let’s unpack
    what is going on here.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: “一阶齐次常微分方程”这个术语不容易说出口，而且它充满了繁重的术语。所以，让我们解开其中的含义。
- en: 'The differential equation part is clear: it is a functional equation that involves
    derivatives. Since the time t is the only variable, the differential equation
    is ordinary. (As opposed to differential equations involving multivariable functions
    and partial derivatives, but more on those later.) As only the first derivative
    is present, the equation becomes first-order. Second-order would involve second
    derivatives, and so on. Finally, since the right-hand side f(x) doesn’t explicitly
    depend on the time variable t, the equation is homogeneous in time. Homogeneity
    means that the rules governing our dynamical system don’t change over time.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 微分方程部分很明确：它是一个涉及导数的函数方程。由于时间 t 是唯一的变量，因此该微分方程是常微分方程。（与涉及多变量函数和偏导数的微分方程相对，后者将在以后讲解。）由于只涉及一阶导数，方程成为一阶微分方程。二阶方程则涉及二阶导数，以此类推。最后，由于右侧的
    f(x) 不显式依赖于时间变量 t，因此该方程在时间上是齐次的。齐次性意味着支配我们动态系统的规则不会随着时间变化。
- en: Don’t let the f(x(t)) part scare you! For instance, in our example x^′(t) =
    x(t), the role of f is cast to the identity function f(x) = x. In general, f(x)
    establishes a relation between the quantity x(t) (which can be position, density,
    etc) and its derivative, that is, its rate of change.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 不要让 f(x(t)) 部分吓到你！例如，在我们的例子 x^′(t) = x(t) 中，f 的角色被映射为恒等函数 f(x) = x。一般来说，f(x)
    建立了量 x(t)（可以是位置、密度等）及其导数（即变化率）之间的关系。
- en: As we have seen, we think in terms of differential equations and initial conditions
    that pinpoint solutions among a bundle of functions. Let’s put this into a proper
    mathematical definition!
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们通过微分方程和初始条件来思考，这些条件确定了解在一组函数中的位置。让我们将这一点写成正式的数学定义！
- en: Definition 60\. (Initial value problems)
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 60. （初值问题）
- en: Let x^′ = f(x) be a first-order homogeneous ordinary differential equation and
    let x[0] ∈ℝ be an arbitrary value. The system
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 设 x^′ = f(x) 是一阶齐次常微分方程，且 x[0] ∈ℝ 为任意值。系统
- en: '![( |{ ′ x = f (x ) |( x(t0) = x0 ](img/file1285.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![( |{ ′ x = f (x ) |( x(t0) = x0 ](img/file1285.png)'
- en: is called an initial value problem. If a function x(t) satisfies both conditions,
    it is said to be a solution to the initial value problem.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 被称为初值问题。如果函数x(t)满足这两个条件，则称其为初值问题的解。
- en: Most often, we select t[0] to be 0\. After all, we have the freedom to select
    the origin of the time as we want.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的是，我们选择t[0]为0。毕竟，我们可以自由选择时间的原点。
- en: 'Unfortunately, things are not as simple as they seem. In general, differential
    equations and initial value problems are tough to solve. Except for a few simple
    ones, we cannot find exact solutions. (And when I say we, I include every person
    on the planet.) In these cases, there are two things that we can do: either we
    construct approximate solutions via numeric methods or turn to qualitative methods
    that study the behavior of the solutions without actually finding them.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，事情并不像看起来那么简单。通常，微分方程和初值问题是很难求解的。除了少数简单的例子，我们无法找到精确的解。（当我说“我们”时，我指的是地球上的每一个人。）在这种情况下，我们可以做两件事：要么通过数值方法构造近似解，要么转向定性方法，研究解的行为，而不需要实际找到它们。
- en: We’ll talk about both, but let’s turn to the qualitative methods first. As we’ll
    see, looking from a geometric perspective gives us a deep insight into how differential
    equations work.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论这两者，但首先让我们转向定性方法。如我们所见，从几何的角度来看，可以深刻理解微分方程是如何运作的。
- en: 13.3.3 A geometric interpretation of differential equations
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.3 微分方程的几何解释
- en: When finding analytic solutions is not feasible, we look for a qualitative understanding
    of the solutions, focusing on the local and long-term behavior instead of formulas.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 当无法找到解析解时，我们会寻求对解的定性理解，关注局部和长期行为，而不是公式。
- en: Imagine that, given a differential equation
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 假设给定一个微分方程
- en: '![x′(t) = f(x(t)), ](img/file1286.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![x′(t) = f(x(t)), ](img/file1286.png)'
- en: you are interested in a particular solution that assumes the value x^∗ at time
    t[0].
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 你对一个特定的解感兴趣，它在时间t[0]时假设值为x^∗。
- en: For instance, you could be studying the dynamics of a bacterial colony and want
    to provide a predictive model to fit your latest measurement x(t[0]) = x^∗. In
    the short term, where will your solutions go?
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你正在研究细菌群体的动态，并希望提供一个预测模型，以适应你最新的测量值x(t[0]) = x^∗。在短期内，你的解会走向哪里？
- en: We can immediately notice that if x(t[0]) = x^∗ and f(x) = 0, then the constant
    function x(t) = x is a solution! These are called equilibrium solutions, and they
    are extremely important. So, let’s make a formal definition!
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以立即注意到，如果x(t[0]) = x^∗且f(x) = 0，则常数函数x(t) = x是一个解！这些被称为平衡解，而且它们非常重要。所以，让我们给出一个正式定义！
- en: Definition 61\. (Equilibrium solutions)
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 定义61（平衡解）
- en: Let
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 设
- en: x′(t) = f(x(t)) (13.4)
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: x′(t) = f(x(t)) (13.4)
- en: be a first-order homogeneous ODE, and let x^∗∈ℝ be an arbitrary point. If f(x^∗)
    = 0, then x^∗ is called an equilibrium point of the equation x^′ = f(x).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 设为一阶齐次常微分方程，并让x^∗∈ℝ为任意点。如果f(x^∗) = 0，则称x^∗为方程x^′ = f(x)的平衡点。
- en: For equilibrium points, the constant function x(t) = x^∗ is a solution of ([13.4](ch021.xhtml#x1-224002r61)).
    This is called an equilibrium solution.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 对于平衡点，常数函数x(t) = x^∗是方程([13.4](ch021.xhtml#x1-224002r61))的解。这被称为平衡解。
- en: 'Think about our recurring example, the simplest ODE x^′(t) = x(t). As mentioned,
    we can interpret this equation as a model of unrestricted population growth under
    ideal conditions. In that case, f(x) = x, and this is zero only for x = 0\. Therefore,
    the constant x(t) = 0 function is a solution. This makes perfect sense: if a population
    has zero individuals, no change is going to happen in its size. In other words,
    the system is in equilibrium.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 思考我们反复出现的例子，最简单的常微分方程x^′(t) = x(t)。如前所述，我们可以将这个方程解释为在理想条件下无限制的种群增长模型。在这种情况下，f(x)
    = x，而只有当x = 0时，这个方程的解才为零。因此，常数解x(t) = 0是一个解。这是完全合乎逻辑的：如果一个种群的个体数量为零，那么它的大小就不会发生变化。换句话说，系统处于平衡状态。
- en: 'This is like a pendulum that stopped moving and reached its resting point at
    the bottom. However, pendulums have two equilibria: one at the top and one at
    the bottom. (Let’s suppose that the mass is held by a massless rod. Otherwise,
    it would collapse.) At the bottom, you can push the hanging mass all you want
    and it’ll return to rest. However, at the top, any small push would disrupt the
    equilibrium state, to which it would never return.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这就像一个停止运动并到达底部静止点的摆。然而，摆有两个平衡态：一个在顶部，一个在底部。（假设质量由一根无质量的杆支撑，否则它会坍塌。）在底部，你可以尽情推摆的质量，它会返回静止状态。然而，在顶部，任何轻微的推力都会打破平衡状态，摆将永远无法恢复到平衡。
- en: 'To shed light on this phenomenon, let’s look at another example: the famous
    logistic equation'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 为了阐明这一现象，让我们来看另一个例子：著名的逻辑方程
- en: x′(t) = x(t)(1 − x(t)). (13.5)
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: x′(t) = x(t)(1 − x(t))。 (13.5)
- en: From a population dynamics perspective, if our favorite equation x^′(t) = x(t)
    describes the unrestricted growth of a bacterial colony, the logistic equation
    models the population growth under a resource constraint. If we assume that 1
    is the total capacity of our population, the growth becomes more difficult as
    the size approaches this limit. Thus, the population’s rate of change x^′(t) can
    be modelled as x(t)(1 −x(t)), where the term 1 −x(t) slows down the process as
    the colony nears the sustain capacity.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 从种群动态的角度来看，如果我们最喜欢的方程x^′(t) = x(t)描述了细菌群落的无限制增长，那么逻辑方程则模拟了在资源限制下的种群增长。如果我们假设1是我们种群的总容量，那么当种群接近这一限制时，增长会变得越来越困难。因此，种群的变化率x^′(t)可以通过x(t)(1
    −x(t))来建模，其中1 −x(t)这一项会随着群体接近承载能力而减缓增长过程。
- en: We can write the logistic equation in the general form ([13.3](ch021.xhtml#x1-223003r59))
    by casting the role f(x) = x(1 −x). Do you recall Theorem [84](ch021.xhtml#x1-212014r84)
    about the relation of derivatives and monotonicity? Translated to the differential
    equation x^′ = f(x), this reveals the flow of our solutions! To be specific,
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将f(x) = x(1 −x)代入通用形式([13.3](ch021.xhtml#x1-223003r59))来写出逻辑方程。你还记得关于导数与单调性关系的定理[84](ch021.xhtml#x1-212014r84)吗？将其转化为微分方程x^′
    = f(x)，这揭示了我们解的流动！具体来说，
- en: '![ (| |||{ increasing if f (x) >0, x(t) is || decreasing if f (x) <0, ||( constant
    if f (x) = 0\. ](img/file1287.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![ (| |||{ 当f(x) > 0时x(t)递增， || 当f(x) < 0时x(t)递减， || 当f(x) = 0时x(t)恒定。 ](img/file1287.png)'
- en: We can visualize this in the so-called phase portrait.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在所谓的相位图中可视化这个过程。
- en: '![PIC](img/file1288.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1288.png)'
- en: 'Figure 13.16: The flow of solutions for x^′ = x(1 −x), visualized on the phase
    portrait. (The arrows represent the direction where the solutions for given initial
    values are headed.)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.16：x^′ = x(1 −x)的解的流动，在相位图上可视化。（箭头表示给定初值的解的方向。）
- en: 'Thus, the monotonicity describes long-term behavior:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，单调性描述了长期行为：
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(19).png)(13.6)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f 是线性}](img/equation_(19).png)(13.6)'
- en: With a little bit of calculation (whose details are not essential for us), we
    can obtain that we can write the solutions as noindent
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一些计算（其细节对我们来说并不重要），我们可以得到我们可以将解写为noindent。
- en: '![x(t) = ---1----, 1 + ce−t ](img/file1290.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![x(t) = ---1----, 1 + ce−t ](img/file1290.png)'
- en: where c ∈ℝ is an arbitrary constant. For c = 1, this is the famous sigmoid function.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 其中c ∈ℝ是一个任意常数。对于c = 1，这是著名的S型函数。
- en: You can check by hand that these are indeed solutions. We can even plot them,
    as shown in Figure [13.17](#) below.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以手动检查这些确实是解。我们甚至可以绘制它们，如下图[13.17](#)所示。
- en: '![PIC](img/file1291.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1291.png)'
- en: 'Figure 13.17: Solutions of the logistic differential equation x^′ = x(1 −x)'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.17：逻辑微分方程x^′ = x(1 −x)的解
- en: As we can see in Figure [13.17](#), the monotonicity of the solutions are as
    we predicted in ([13.6](#)).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[13.17](#)所示，解的单调性正如我们在([13.6](#))中预测的那样。
- en: 'We can characterize the equilibria based on the long-term behavior of nearby
    solutions. (In the case of our logistic equation, the equilibria are 0 and 1.)
    This can be connected to the local behavior of f: if it decreases around the equilibrium
    x^∗, it attracts the nearby solutions. On the other hand, if f increases around
    x^∗, then the nearby solutions are repelled.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据附近解的长期行为来表征平衡态。（在我们的逻辑方程中，平衡态是0和1。）这可以与函数f的局部行为相联系：如果它在平衡点x^∗周围减小，它就会吸引附近的解。另一方面，如果f在x^∗周围增大，则附近的解会被排斥。
- en: This gives rise to the concept of stable and unstable equilibria.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了稳定和平衡不稳定点的概念。
- en: Definition 62\. (Stable and unstable equilibria)
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 定义62.（稳定和平衡不稳定点）
- en: Let x^′ = f(x) be a first-order homogeneous ordinary differential equation,
    and suppose that f is differentiable. Moreover, let x^∗ be an equilibrium of the
    equation.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 令 x^′ = f(x) 为一阶齐次常微分方程，并假设 f 是可微的。此外，设 x^∗ 为该方程的平衡点。
- en: x^∗ is called a stable equilibrium if there is a neighborhood (x^∗−𝜀,x^∗ + 𝜀)
    around x^∗ such that for all x[0] ∈ (x^∗−𝜀,x^∗ + 𝜀), the solution of the initial
    value problem
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: x^∗ 被称为稳定的平衡点，如果存在一个邻域 (x^∗−𝜖, x^∗ + 𝜖)，对于所有的 x[0] ∈ (x^∗−𝜖, x^∗ + 𝜖)，初值问题的解
- en: '![( |{ x′ = f(x) |( x(0) = x0 ](img/file1292.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![( |{ x′ = f(x) |( x(0) = x0 ](img/file1292.png)'
- en: converges towards x^∗. (That is, lim[t→∞]x(t) = x^∗ holds.)
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 收敛到 x^∗。（也就是说，lim[t→∞]x(t) = x^∗ 成立。）
- en: If x^∗ is not stable, it is called unstable.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 x^∗ 不是稳定的，那么它被称为不稳定。
- en: 'In the case of the logistic ODE x^′ = x(1 −x), x^∗ = 1 is a stable and x^∗
    = 0 is an unstable equilibrium. This makes sense given its population dynamics
    interpretation: the equilibrium x^∗ = 1 means that the population is at maximum
    capacity. If the size is slightly above or below the capacity 1, some specimens
    die due to starvation, or the colony reaches its constraints. On the other hand,
    no matter how small the population is, it won’t ever go extinct in this ideal
    model.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在逻辑斯蒂常微分方程 x^′ = x(1 −x) 的情况下，x^∗ = 1 是稳定平衡点，而 x^∗ = 0 是不稳定平衡点。这是符合其种群动态解释的：平衡点
    x^∗ = 1 意味着种群处于最大容量。如果种群数量略高或略低于容量 1，部分个体会因饥饿而死亡，或者种群达到其约束。另一方面，无论种群有多小，在这个理想模型中，它永远不会灭绝。
- en: Recall how the derivatives characterize the monotonicity of differentiable functions
    by Theorem [84](ch021.xhtml#x1-212014r84)? With this, we have a simple tool that
    can help us decide whether a given equilibrium is stable or not.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下微分定理[84](ch021.xhtml#x1-212014r84)如何表征可微函数的单调性？有了这个，我们就有了一个简单的工具，帮助我们判断一个给定的平衡点是否稳定。
- en: Theorem 90\.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 90\.
- en: Let x^′ = f(x) be a first-order homogeneous ordinary differential equation,
    and suppose that f is differentiable. Moreover, let x^∗ be an equilibrium point
    of the equation.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 令 x^′ = f(x) 为一阶齐次常微分方程，并假设 f 是可微的。此外，设 x^∗ 为该方程的平衡点。
- en: If f^′(x)/span>0, then x is a stable equilibrium.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 f^′(x)/span>0，则 x 是一个稳定的平衡点。
- en: 'The concept of stable equilibrium is fundamental, even in the most general
    cases. At this point, it’s time to take a few steps backward and remind ourselves
    why we are here: to understand gradient descent. If stable equilibria remind you
    of a local minimum which a gradient descent process converges towards, it is not
    an accident. We are ready to see what’s behind the scenes.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定平衡的概念是基本的，即使在最一般的情况下也是如此。此时，是时候退后一步，提醒我们自己为什么在这里：为了理解梯度下降。如果稳定平衡让你想起梯度下降过程所收敛到的局部最小值，那并非偶然。我们已经准备好了解幕后隐藏的内容。
- en: 13.3.4 A continuous version of gradient ascent
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.4 梯度上升的连续版本
- en: 'Now, let’s talk about maximizing a function F : ℝ →ℝ. Suppose that F is twice
    differentiable, and we denote its derivative by F^′ = f. Luckily, the local maxima
    of F can be found with the help of its second derivative (Theorem [87](ch021.xhtml#x1-214004r87))
    by looking for x^∗ where f(x) = 0 and f^′(x)/span>0\.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，让我们讨论最大化一个函数 F : ℝ → ℝ。假设 F 是二阶可微的，并且我们将它的导数记作 F^′ = f。幸运的是，可以通过查看 f(x)
    = 0 和 f^′(x)/span>0 来找到 F 的局部最大值（定理[87](ch021.xhtml#x1-214004r87)）。'
- en: Does this look familiar? If f(x) = 0 indeed holds, then x(t) = x is an equilibrium
    solution; and since f^′(x^∗)/span>0, it attracts the nearby solutions as well.
    This means that if x[0] is drawn from the basin of attraction and x(t) is the
    solution of the initial value problem
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来熟悉吗？如果 f(x) = 0 确实成立，那么 x(t) = x 是一个平衡解；且由于 f^′(x^∗)/span>0，它也会吸引附近的解。这意味着，如果
    x[0] 来自吸引盆地，并且 x(t) 是初值问题的解
- en: '![L(U,V ) = {f : U → V | f is linear}](img/file1293.png)(13.7)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f 是线性映射}](img/file1293.png)(13.7)'
- en: then lim[t→∞]x(t) = x^∗. In other words, the solution converges towards x^∗,
    a local maxima of F! This is gradient ascent in a continuous version.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，lim[t→∞]x(t) = x^∗。换句话说，解收敛到 x^∗，这是 F 的局部最大值！这是连续版本的梯度上升。
- en: We are happy, but there is an issue. We’ve talked about how hard solving differential
    equations are. For a general F, we have no prospects to actually find the solutions.
    Fortunately, we can approximate them.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很高兴，但有一个问题。我们已经讨论过解微分方程有多困难。对于一般的 F，我们没有办法实际找到解。幸运的是，我们可以对它们进行近似。
- en: 13.3.5 Gradient ascent as a discretized differential equation
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.5 梯度上升作为离散化的微分方程
- en: When studying differentiation in practice, we have seen that derivatives can
    be approximated numerically by the forward difference
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际研究微分时，我们看到导数可以通过前向差分进行数值近似。
- en: '![x ′(t) ≈ x(t+-h)−-x-(t), h ](img/file1294.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![x ′(t) ≈ x(t+-h)−-x-(t), h ](img/file1294.png)'
- en: where h/span>0 is a small step size. If x(t) is indeed the solution for the
    initial value problem ([13.7](ch021.xhtml#a-continuous-version-of-gradient-ascent)),
    we are in luck! Using forward differences, we can take a small step from 0 and
    approximate x(h) by substituting the forward difference into the differential
    equation. To be precise, we have
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 其中h/span>0是一个小步长。如果x(t)确实是初值问题的解([13.7](ch021.xhtml#a-continuous-version-of-gradient-ascent))，那么我们很幸运！使用前向差分，我们可以从0出发，采用小步长近似x(h)，将前向差分代入微分方程。准确地说，我们有
- en: '![x(h)−-x-(0)- h ≈ f (x (0)), ](img/file1295.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![x(h)−-x-(0)- h ≈ f (x (0)), ](img/file1295.png)'
- en: from which
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 从中
- en: '![x(h) ≈ x (0) + hf(x(0)) ](img/file1296.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![x(h) ≈ x (0) + hf(x(0)) ](img/file1296.png)'
- en: follows. By defining x[0] and x[1] by
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 可得。通过定义x[0]和x[1]为
- en: '![x0 := x(0), x := x + hf(x ), 1 0 0 ](img/file1297.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![x0 := x(0), x := x + hf(x ), 1 0 0 ](img/file1297.png)'
- en: we have x[1] ≈x(h). If this looks like the first step of the gradient ascent
    ([13.1](ch021.xhtml#the-gradient-descent-algorithm)) to you, you are on the right
    track. Using the forward difference once again, this time from the point x(h),
    we obtain
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有x[1] ≈ x(h)。如果这看起来像是梯度上升的第一步([13.1](ch021.xhtml#the-gradient-descent-algorithm))，那么你走在正确的道路上。再次使用前向差分，这次从点x(h)开始，我们得到
- en: '![x(2h) ≈ x(h)+ hf (x(h)) ≈ x1 + hf (x1), ](img/file1298.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![x(2h) ≈ x(h)+ hf (x(h)) ≈ x1 + hf (x1), ](img/file1298.png)'
- en: 'thus by defining x[2] := x[1] + hf(x[1]), we have x[2] ≈x(2h). Notice that
    in x[2], two kinds of approximation errors are accumulated: first the forward
    difference, then the approximation error of the previous step.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过定义x[2] := x[1] + hf(x[1])，我们得到x[2] ≈ x(2h)。注意，在x[2]中，积累了两种类型的近似误差：首先是前向差分，然后是上一步的近似误差。
- en: This motivates us to define the recursive sequence
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这激励我们定义递归序列
- en: '![L(U,V ) = {f : U → V | f is linear}](img/file1299.png)(13.8)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f is linear}](img/file1299.png)(13.8)'
- en: which approximates x(nh) with x[n], as this is implied by the very definition.
    This recursive sequence is the gradient ascent itself, and the small step h is
    the learning rate!
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 它通过x[n]近似x(nh)，正如其定义所暗示的那样。这个递归序列就是梯度上升本身，而小步长h就是学习率！
- en: Check ([13.1](ch021.xhtml#the-gradient-descent-algorithm)) if you don’t believe
    me. ([13.8](ch021.xhtml#gradient-ascent-as-a-discretized-differential-equation))
    is called the Euler method.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 查看([13.1](ch021.xhtml#the-gradient-descent-algorithm))，如果你不相信我。[13.8](ch021.xhtml#gradient-ascent-as-a-discretized-differential-equation)被称为欧拉方法。
- en: Without going into the details, if h is small enough and f “behaves properly,”
    the Euler method will converge to the equilibrium solution x^∗. (Whatever proper
    behavior might mean.)
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 不深入细节，如果h足够小并且f“表现得当”，欧拉方法将收敛到平衡解x^∗。（“表现得当”是什么意思呢？）
- en: 'We only have one more step: to turn everything into gradient descent instead
    of ascent. This is extremely simple, as gradient descent is just applying gradient
    ascent to −f. Think about it: minimizing a function f is the same as maximizing
    its negative −f. And with that, we are done! The famous gradient descent is a
    consequence of dynamical systems converging towards their stable equilibria, and
    this is beautiful.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要再做一步：将一切变成梯度下降而不是上升。这非常简单，因为梯度下降就是对−f应用梯度上升。想想看：最小化一个函数f就等同于最大化它的负值−f。这样，我们就完成了！著名的梯度下降是动态系统向其稳定平衡收敛的结果，这非常美妙。
- en: 13.3.6 Gradient ascent in action
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.6 梯度上升的实际应用
- en: 'To see gradient ascent (that is, the Euler method) in action, we should go
    back to our good old example: the logistic equation ([13.5](#)). So, suppose that
    we want to find the local maxima of the function'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看到梯度上升（即欧拉方法）在实际中的应用，我们应该回到我们熟悉的例子：逻辑斯蒂方程([13.5](#))。所以，假设我们想找到该函数的局部最大值。
- en: '![ 1 1 F (x) = -x2 − -x3, 2 3 ](img/file1300.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 1 F (x) = -x2 − -x3, 2 3 ](img/file1300.png)'
- en: plotted in Figure [13.18](#).
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[13.18](#)所示。
- en: '![PIC](img/file1301.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1301.png)'
- en: 'Figure 13.18: The graph of F(x) = ![12](img/file1302.png)x² −![13](img/file1303.png)x³'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.18：F(x) = ![12](img/file1302.png)x² −![13](img/file1303.png)x³的图形
- en: First, we can use what we learned and find the maxima using the derivative f(x)
    = F^′(x) = x(1 −x), concluding that there is a local maximum at x^∗ = 1\. (Don’t
    just take my word for it, check out Theorem [87](ch021.xhtml#x1-214004r87) and
    work it out!)
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以运用学到的知识，利用导数 f(x) = F^′(x) = x(1 −x) 来找最大值，得出在 x^∗ = 1 处有一个局部最大值。（不要只听我说，查阅定理 [87](ch021.xhtml#x1-214004r87)，自己推导一下！）
- en: Since f(x) = F^′(x) = 0 and f^′(x)/span>0, the point x is a stable equilibrium
    of the logistic equation
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 f(x) = F^′(x) = 0 且 f^′(x)/span>0，点 x 是逻辑方程的稳定平衡点
- en: '![x′ = x(1 − x). ](img/file1304.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![x′ = x(1 − x). ](img/file1304.png)'
- en: Thus, if the initial value x(0) = x[0] is sufficiently close to x^∗ = 1, the
    solution x(t) of the initial value problem
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果初始值 x(0) = x[0] 足够接近 x^∗ = 1，初值问题的解 x(t) 将是
- en: '![( ||| x′ = x(1− x), |{ x(0) = x0, |||| ( ](img/file1305.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![( ||| x′ = x(1− x), |{ x(0) = x0, |||| ( ](img/file1305.png)'
- en: then lim[t→∞]x(t) = x^∗. (In fact, we can select any initial value x[0] from
    the infinite interval (0,∞), and the convergence will hold). Upon discretization
    via the Euler method, we obtain the recursive sequence
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 lim[t→∞]x(t) = x^∗。（实际上，我们可以从无限区间 (0,∞) 中选择任何初始值 x[0]，并且收敛性将成立）。通过欧拉方法的离散化，我们得到递归序列
- en: '![ x0 = x (0), xn+1 = xn + hxn (1− xn). ](img/file1306.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![ x0 = x (0), xn+1 = xn + hxn (1− xn). ](img/file1306.png)'
- en: This process is visualized by Figure [13.19](#).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程由图 [13.19](#) 可视化。
- en: '![PIC](img/file1307.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1307.png)'
- en: 'Figure 13.19: Solving x^′ = x(1 −x) via the Euler method. (For visualization
    purposes, the initial value was set at t[0] = −5.)'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.19：通过欧拉方法求解 x^′ = x(1 −x)。 （为了可视化，初始值设为 t[0] = −5。）
- en: We can even take the discrete solution provided by the Euler method, and plot
    it on the x −F(x) plane.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以取欧拉方法提供的离散解，并将其绘制在 x −F(x) 平面上。
- en: '![PIC](img/file1308.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1308.png)'
- en: 'Figure 13.20: Mapping the Euler method on the x, F(x) plane'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.20：将欧拉方法映射到 x, F(x) 平面
- en: If you check Figure [13.20](#) out, you can see that this is the gradient ascent
    for F! If you consider that F^′ = f and consider that the solution given by the
    Euler method is
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看图 [13.20](#)，你会看到这是 F 的梯度上升！如果你考虑 F^′ = f 并且考虑欧拉方法给出的解是
- en: '![L(U,V ) = {f : U → V | f is linear}](img/file1309.png)(13.9)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f 是线性的}](img/file1309.png)(13.9)'
- en: you can notice that ([13.9](ch021.xhtml)) is exactly how we defined gradient
    ascent.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到（[13.9](ch021.xhtml)）正是我们定义梯度上升的方法。
- en: 13.4 Summary
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.4 小结
- en: Finally, we’ve done it. Until this chapter, we haven’t been that close to machine
    learning, but now, we are right at the heart of it. Gradient descent is the number
    one algorithm to train neural networks. Yes, even state-of-the-art ones.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们做到了。直到这一章之前，我们还没有接触到机器学习，但现在，我们已经进入了它的核心。梯度下降是训练神经网络的第一算法。是的，即使是最先进的神经网络。
- en: 'It all starts with calculus. To reach the heights of gradient descent, we studied
    the relations between monotonicity, local extrema, and the derivative. The pattern
    is simple: if f^′(a)/span>0, then f is increasing, but if f^′(a)/span>0, then
    f is decreasing around a. Speaking in terms of physics, if the speed is positive,
    the object is moving away, but if the speed is negative, the object is coming
    closer.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都始于微积分。为了达到梯度下降的高度，我们研究了单调性、局部极值和导数之间的关系。这个模式很简单：如果 f^′(a)/span>0，那么 f 是递增的；但如果
    f^′(a)/span>0，那么 f 在 a 周围是递减的。从物理角度讲，如果速度为正，物体在远离；但如果速度为负，物体在靠近。
- en: 'Based on this observation, we can deduce necessary and sufficient conditions
    to find local minima and maxima: if f^′(a) = 0'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这一观察，我们可以推导出找到局部极值和极大值的必要和充分条件：如果 f^′(a) = 0
- en: and if f^(′′)(a)/span>0, then a is a local minimum,
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 f^(′′)(a)/span>0，那么 a 是局部最小值，
- en: but if f^′(a) = 0 and f^(′′)(a)/span>0, then a is a local maximum.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 但如果 f^′(a) = 0 且 f^(′′)(a)/span>0，那么 a 是局部最大值。
- en: So, finding the local extrema should be as simple as solving f^′(a) = 0, right?
    In theory, no, because the case f^(′′)(a) = 0 is undetermined. In practice, still
    no, because even finding f^′ is hard for complex f-s, let alone solving f^′(x)
    = 0.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，找到局部极值应该和解 f^′(a) = 0 一样简单，对吧？理论上，不是，因为当 f^(′′)(a) = 0 时，结果是未定的。实践中，仍然不行，因为即使是复杂的
    f，也很难找到 f^′，更不用说解 f^′(x) = 0 了。
- en: 'However, there’s a way. We can take an iterative approach with gradient descent:
    if the learning rate h and starting point x[0] are selected appropriately, the
    recursive sequence defined by'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还是有办法的。我们可以采用带有梯度下降的迭代方法：如果学习率 h 和起始点 x[0] 选择得当，那么由以下递归序列定义的
- en: '![xn+1 = xn − hf′(xn ) ](img/file1310.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![xn+1 = xn − hf′(xn ) ](img/file1310.png)'
- en: converges to a local minimum.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 收敛到局部最小值。
- en: As always, when one problem is solved, a dozen others are created. For example,
    the gradient descent can fail to converge or get stuck in the local minimum instead
    of finding the global one. But that’s the least of our problems. The real issue
    is that we have to optimize functions of multiple variables in practice, often
    in the range of billions of parameters.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，当一个问题得到解决时，往往会产生十个其他问题。例如，梯度下降可能无法收敛，或者会陷入局部最小值而不是找到全局最小值。但这只是我们面临的最小问题。真正的问题是，我们在实践中必须优化多个变量的函数，通常参数的范围可以达到数十亿。
- en: Before we move on to the study of multivariable calculus, there’s one more topic
    to go. I’ve hinted at integration, the mysterious “inverse differentiation” a
    couple of times. It’s time to see what it is and why it is indispensable to study
    advanced mathematics.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续学习多变量微积分之前，还有一个话题需要讲解。我曾多次提到过积分，即神秘的“逆向微分”。现在是时候看看它是什么，以及为什么它对于学习高级数学至关重要。
- en: 13.5 Problems
  id: totrans-341
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.5 问题
- en: Problem 1\. Find the local minima and maxima of f(x) = sinx.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 1. 找出 f(x) = sinx 的局部最小值和最大值。
- en: Problem 2\. Use the second derivative test to find the local minima and maxima
    of f(x) = 2x³ + 5x² + 4x + 6.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 2. 使用二阶导数法则找出 f(x) = 2x³ + 5x² + 4x + 6 的局部最小值和最大值。
- en: 'Problem 3\. Let f : ℝ →ℝ be a differentiable function. The recursive sequence
    defined by'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '问题 3. 设 f : ℝ →ℝ 为可微函数。由以下递推式定义的序列'
- en: '![δn+1 = αδn − hf′(xn), xn+1 = xn + δn, ](img/file1311.png)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![δn+1 = αδn − hf′(xn), xn+1 = xn + δn, ](img/file1311.png)'
- en: where δ[0] = 0 and x[0] is arbitrary, is called gradient descent with momentum.
    Implement it!
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 δ[0] = 0，x[0] 为任意值，称为带动量的梯度下降法。实现它！
- en: Join our community on Discord
  id: totrans-347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: Read this book alongside other users, Machine Learning experts, and the author
    himself. Ask questions, provide solutions to other readers, chat with the author
    via Ask Me Anything sessions, and much more. Scan the QR code or visit the link
    to join the community. [https://packt.link/math](https://packt.link/math)
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 和其他用户、机器学习专家以及作者本人一起阅读本书。提出问题，为其他读者提供解决方案，通过“问我任何问题”环节与作者交流，等等。扫描二维码或访问链接加入社区。[https://packt.link/math](https://packt.link/math)
- en: '![PIC](img/file1.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1.png)'
