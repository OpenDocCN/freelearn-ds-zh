- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Tabular Data Augmentation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 表格数据增强
- en: Tabular augmentation supplements tabular data with additional information to
    make it more useful for predictive analytics. Database, spreadsheet, and table
    data are examples of tabular data. It involves transforming otherwise insufficient
    datasets into robust inputs for ML. Tabular augmentation can help turn unstructured
    data into structured data and can also assist in combining multiple data sources
    into a single dataset. It is an essential step in data pre-processing for increasing
    AI predictive accuracy.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 表格增强通过向表格数据添加额外信息，使其在预测分析中更具实用性。数据库、电子表格和表格数据是表格数据的例子。它涉及将不足的数据集转化为强大的机器学习输入。表格增强可以帮助将非结构化数据转化为结构化数据，还可以协助将多个数据源合并为一个数据集。它是数据预处理中的一个关键步骤，有助于提高
    AI 预测的准确性。
- en: The idea of tabular augmentation is to include additional information to a given
    dataset that can then be used to generate valuable insights. These datasets can
    come from various sources, such as customer feedback, social media posts, and
    IoT device logs. Tabular augmentation can add new information columns to the dataset
    by enriching the existing columns with more informative tags. It increases the
    completeness of the dataset and provides more accurate insights.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 表格增强的想法是向给定的数据集中添加额外的信息，从而生成有价值的洞察。这些数据集可以来自各种来源，例如客户反馈、社交媒体帖子和物联网设备日志。表格增强可以通过用更多有意义的标签来丰富现有列，从而向数据集中添加新的信息列。它增加了数据集的完整性，并提供了更准确的洞察。
- en: Tabular augmentation is an important method to consider when pre-processing
    and generating insights from data. It provides a way to work with incomplete and
    unstructured datasets by organizing and enriching them for improved accuracy and
    speed. By implementing tabular augmentation, you can better unlock the value of
    real-world datasets and make better-informed decisions.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 表格增强是在数据预处理和生成洞察时需要考虑的重要方法。它通过组织和丰富数据，以提高准确性和速度，为处理不完整和非结构化的数据集提供了一种方法。通过实施表格增强，你可以更好地挖掘现实世界数据集的价值，并做出更明智的决策。
- en: Tabular augmentation is a young field for data scientists. It is contrary to
    using analytics for reporting, summarizing, or forecasting. In analytics, altering
    or adding data to skew the results to a preconceived desired outcome is unethical.
    In data augmentation, the purpose is to derive new data from an existing dataset.
    The two goals might be incongruent, but they are not. DL is an entirely different
    technique from traditional analytics. One is based on a neural network algorithm,
    while the other is based on statistical analysis and data relationships.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 表格增强是数据科学家们的一个年轻领域。它与使用分析进行报告、总结或预测是相反的。在分析中，改变或添加数据以扭曲结果以达到预设的期望结果是不道德的。而在数据增强中，目的是从现有数据集中衍生出新的数据。这两个目标可能不一致，但它们并不矛盾。深度学习（DL）是与传统分析完全不同的技术。一个是基于神经网络算法，另一个则基于统计分析和数据关系。
- en: The salient point is that even though you might introduce synthetic data into
    the datasets, it is an acceptable practice. The *Synthesizing Tabular Data using
    Generative Adversarial Networks* paper, by Lei Xu and Kalyan Veeramachaneni, published
    in the *arXiv Forum* in November 2018, supports this proposition.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的一点是，即使你可能会向数据集中引入合成数据，这也是一种可接受的做法。Lei Xu 和 Kalyan Veeramachaneni 在 2018 年
    11 月发布的《使用生成对抗网络合成表格数据》论文，在 *arXiv 论坛* 上支持这一观点。
- en: This chapter focuses on describing concepts. It has a few practical coding examples
    using the Python Notebook. One main reason for this is that there are only a few
    tabular augmentation open source libraries available. You will spend most of the
    coding time plotting various graphs to inspire further insight from the datasets.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章专注于描述概念。它有一些使用 Python Notebook 的实际编码示例。主要原因之一是，目前只有少数几种开放源代码的表格增强库可用。你将花费大部分时间绘制各种图表，以从数据集中激发更多的洞察。
- en: 'Before continuing, let’s take a sneak peek at a real-world tabular dataset.
    Later, Pluto will explain in detail how to write Python code for the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们先窥探一下一个真实的表格数据集。接下来，Pluto 会详细解释如何编写 Python 代码来处理以下内容：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output is as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.1 – Bank Account Fraud Dataset Suite (NeurIPS 2022)](img/B17990_09_01.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.1 – 银行账户欺诈数据集套件（NeurIPS 2022）](img/B17990_09_01.jpg)'
- en: Figure 9.1 – Bank Account Fraud Dataset Suite (NeurIPS 2022)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – 银行账户欺诈数据集套件（NeurIPS 2022）
- en: One challenge in augmenting tabular data is that no fixed methods work universally,
    such as flipping images, injecting misspelled words, or time-stretching audio
    files. You will learn that the dataset dictates which augmentation techniques
    are **safe** or in a **safe range**. It is essential to thoroughly review the
    tabular dataset before augmenting it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 增强表格数据的一个挑战是没有固定的方法可以普遍适用，例如翻转图像、注入拼写错误的单词或时间拉伸音频文件。你将了解到，数据集决定了哪些增强技术是**安全的**或处于**安全范围内**。在增强数据集之前，彻底审查表格数据集是非常重要的。
- en: Fun fact
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味事实
- en: '**Deep neural networks** (**DNNs**) excel at predicting future stock values
    and tabular data, based on the scholarly paper *Deep learning networks for stock
    market analysis and prediction: Methodology, data representations, and case studies*,
    by Eunsuk Chong, Chulwoo Han, and Frank C. Park. It was published by Elsevier,
    *Expert Systems with Applications*, Volume 83, on 15 October 2017.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度神经网络**（**DNNs**）在预测未来股市价值和表格数据方面表现出色，基于学术论文*Deep learning networks for
    stock market analysis and prediction: Methodology, data representations, and case
    studies*，由Eunsuk Chong, Chulwoo Han和Frank C. Park撰写。该论文由Elsevier出版，刊登于*Expert
    Systems with Applications*，第83卷，于2017年10月15日发布。'
- en: 'Tabular augmentation is an approach to augmenting a tabular dataset with synthetic
    data. It involves adding new columns to a tabular dataset with features from the
    derived calculation. You will spend the majority of the time in Python code visualizing
    the real-world tabular dataset with exotics plots. In this chapter, we will cover
    the following topics:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 表格增强是一种通过合成数据增强表格数据集的方法。它包括通过衍生计算中的特征向表格数据集添加新列。你将花费大部分时间在Python代码中可视化现实世界的表格数据集，并用奇异的图表进行展示。在本章中，我们将涵盖以下主题：
- en: Tabular augmentation libraries
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表格增强库
- en: Augmentation categories
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增强类别
- en: Real-world tabular datasets
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现实世界的表格数据集
- en: Exploring and visualizing tabular data
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索和可视化表格数据
- en: Transformation augmentation
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换增强
- en: Extraction augmentation
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取增强
- en: Let’s start with augmentation libraries.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从增强库开始。
- en: Tabular augmentation libraries
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 表格增强库
- en: 'Tabular augmentations are not established as image, text, or audio augmentations.
    Typically, data scientists develop tabular augmentation techniques specific to
    a project. There are a few open source projects on the GitHub website. Still,
    DL and generative AI will continue to advance in forecasting for time series and
    tabular data predictions, and so will tabular augmentations. The following open
    source libraries can be found on the GitHub website:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 表格数据增强不像图像、文本或音频增强那样被广泛建立。通常，数据科学家会根据项目开发特定的表格增强技术。GitHub网站上有一些开源项目，但深度学习和生成式AI将继续推进时间序列和表格数据预测的预测能力，表格数据增强也将随之发展。以下开源库可以在GitHub网站上找到：
- en: '**DeltaPy** is a tabular augmentation for generating and synthesizing data
    focusing on financial applications such as time series stock forecasting. It fundamentally
    applies to a broad range of datasets. The GitHub website link is [https://github.com/firmai/deltapy.](https://github.com/firmai/deltapy.)
    The published scholarly paper is called *DeltaPy: A Framework for Tabular Data
    Augmentation in Python*, by Derek Snow, The Alan Turing Institute, in 2020.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DeltaPy**是一个针对生成和合成数据的表格增强工具，专注于金融应用，如时间序列股市预测。它基本上适用于广泛的数据集。GitHub网站链接是[https://github.com/firmai/deltapy](https://github.com/firmai/deltapy)。已发布的学术论文名为*DeltaPy:
    A Framework for Tabular Data Augmentation in Python*，由Derek Snow, Alan Turing
    Institute于2020年发表。'
- en: The **Synthetic Data Vault** (**SDV**) is for augmenting tabular data by generating
    synthetic data from a single table, multi-table, and time series data. In 2020,
    Kalyan Veeramachaneni, Neha Patki, and Saman Amarsinghe developed a commercial
    version named *Datacebo*. The GitHub link is [https://github.com/sdv-dev/SDV](https://github.com/sdv-dev/SDV).
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Synthetic Data Vault**（**SDV**）用于通过从单个表、多个表和时间序列数据生成合成数据来增强表格数据。2020年，Kalyan
    Veeramachaneni、Neha Patki和Saman Amarsinghe开发了一个名为*Datacebo*的商业版本。GitHub链接是[https://github.com/sdv-dev/SDV](https://github.com/sdv-dev/SDV)。'
- en: The tabular **Generative Adversarial Network** (**GAN**) uses the successfully
    generating realistic image algorithm and applies it to tabular augmentation. The
    scholarly paper is *Tabular GANs for uneven distribution*, by Insaf Ashrapov,
    published by *Cornell University*, *Arxiv*, in 2020\. The GitHub website link
    is [https://github.com/Diyago/GAN-for-tabular-data](https://github.com/Diyago/GAN-for-tabular-data).
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表格**生成对抗网络**（**GAN**）采用成功生成真实图像的算法，并将其应用于表格增强。相关的学术论文是*Tabular GANs for uneven
    distribution*，由 Insaf Ashrapov 撰写，2020年由*康奈尔大学*出版，发布于*Arxiv*。GitHub 网站链接是[https://github.com/Diyago/GAN-for-tabular-data](https://github.com/Diyago/GAN-for-tabular-data)。
- en: Pluto has chosen the **DeltaPy** library to use as the engine under the hood
    for his tabular augmenting wrapper functions, but first, let’s look at the augmentation
    categories.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 选择了**DeltaPy**库作为其表格增强包装函数背后的引擎，但首先，我们来看一下增强类别。
- en: Augmentation categories
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增强类别
- en: 'It is advantageous to group tabular augmentation into categories. The following
    concepts are new and particular to the DeltaPy library. The augmentation functions
    are grouped into the following categories:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 将表格增强分组为不同的类别是有优势的。以下概念是 DeltaPy 库的新特性。增强函数被分为以下几个类别：
- en: '**Transforming** techniques can be applied for cross-section and time series
    data. Transforming techniques in tabular augmentation are used to modify existing
    rows or columns to create new, synthetic data representative of the original data.
    These methods can include the following:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变换**技术可以应用于横截面数据和时间序列数据。表格增强中的变换技术用于修改现有的行或列，以创建新的、合成的数据，这些数据代表了原始数据。这些方法可以包括以下内容：'
- en: '**Scaling**: Increasing or decreasing a column value to expand the diversity
    of values in a dataset'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缩放**：增加或减少列值，以扩展数据集中值的多样性'
- en: '**Binning**: Combining two or more columns into a single bucket to create new
    features'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分箱**：将两列或多列合并为一个单一的桶，以创建新特征'
- en: '**Categorical encoding**: Using a numerical representation of categorical data'
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类别编码**：使用数值表示分类数据'
- en: '**Smoothing**: Compensating for unusually high or low values in a dataset'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平滑**：补偿数据集中的异常高值或低值'
- en: '**Outlier detection and removal**: Detecting and removing points farther from
    the norm'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值检测与移除**：检测并移除偏离正常值的数据点'
- en: '**Correlation-based augmentation**: Adding new features based on correlations
    between existing features'
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于相关性的增强**：根据现有特征之间的相关性添加新特征'
- en: The **interacting** function is a cross-sectional or time series tabular augmentation
    that includes normalizing, discretizing, and autoregression models. In tabular
    augmentation, these functions are used to specify interactions between two or
    more variables and help generate new features that represent combinations of the
    original variables. This type of augmentation is beneficial when modeling the
    relationships between multiple input features and the target variable, as it allows
    the model to consider interactions between the different components.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交互**功能是一个横截面或时间序列的表格增强，包括归一化、离散化和自回归模型。在表格增强中，这些功能用于指定两个或更多变量之间的交互，并帮助生成表示原始变量组合的新特征。当建模多个输入特征和目标变量之间的关系时，这种类型的增强非常有益，因为它允许模型考虑不同组件之间的交互。'
- en: The **mapping** method, which uses **eigendecomposition** in tabular augmentation,
    is a method of unsupervised learning that uses data decomposition to transform
    data into lower-dimensional space using eigenvectors and eigenvalues. This type
    of feature transformation is useful for clustering, outlier detection, and dimensionality
    reduction. By projecting the data onto the eigenvectors, the data can be represented
    in a reduced space while still preserving the structure of the data.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**映射**方法使用**特征分解**进行表格增强，是一种无监督学习方法，利用数据分解通过特征向量和特征值将数据转化为低维空间。这种特征转换对于聚类、异常值检测和降维非常有用。通过将数据投影到特征向量上，数据可以在降低维度的同时，保持数据的结构。'
- en: The **extraction** method is a tabular augmentation technique that utilizes
    **Natural Language Processing** (**NLP**) to generate additional information from
    textual references in tabular datasets. It uses the **TSflesh** library, a collection
    of rules and heuristics, to extract additional data from text, such as names,
    dates, and locations. This approach is beneficial in augmenting structured datasets,
    where the output of **sentence split**, **tokenization**, and **part-of-speech
    tagging** is used to create features that can be used for further processing.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提取**方法是一种表格数据增强技术，利用**自然语言处理**（**NLP**）从表格数据集中的文本引用中生成附加信息。它使用**TSflesh**库——一组规则和启发式方法——从文本中提取附加数据，如姓名、日期和地点。这种方法有助于增强结构化数据集，其中**句子分割**、**分词**和**词性标注**的输出可以用来创建特征，供进一步处理使用。'
- en: '**Time series synthesis** (**TSS**) is a method for tabular data augmentation
    where rows of data across multiple sources or temporal points in time are synthesized
    together. You can use it to increase a dataset’s size and create a more consistent
    set of features.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间序列合成**（**TSS**）是一种表格数据增强方法，其中将来自多个来源或不同时间点的数据行进行合成。你可以使用它来增加数据集的大小，并创建一个更一致的特征集。'
- en: '**Cross-sectional synthesis** (**CSS**) is a method for tabular data augmentation
    where columns of data from multiple sources are combined. You can use it to increase
    a dataset’s features and create a more complete and holistic data view.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**横截面合成**（**CSS**）是一种表格数据增强方法，其中将来自多个来源的数据列进行合并。你可以使用它来增加数据集的特征，并创建更完整、更全面的数据视图。'
- en: The **combining** technique uses the mix-and-match process from the existing
    methods.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组合**技术采用现有方法中的混合搭配过程。'
- en: There are functions associated with each category in the DeltaPy library. However,
    Pluto has to construct a neural network model, such as a **convolutional neural
    network** (**CNN**) or **reoccurring neural network** (**RNN**), to gauge the
    effectiveness of these methods. It is a complex process, and Pluto will not implement
    a CNN in this chapter. Nevertheless, Pluto will demonstrate the mechanics of using
    the DeltaPy library on the Python Notebook. He will not explain how they work.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在DeltaPy库中，每个类别都有相关的函数。然而，Pluto必须构建一个神经网络模型，比如**卷积神经网络**（**CNN**）或**递归神经网络**（**RNN**），以评估这些方法的有效性。这是一个复杂的过程，而Pluto在本章中不会实现CNN。不过，Pluto会展示如何在Python
    Notebook中使用DeltaPy库的机制，但他不会解释这些方法是如何工作的。
- en: Now, it is time to download the real-world datasets from the *Kaggle* website.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是从*Kaggle*网站下载真实世界数据集的时候了。
- en: Real-world tabular datasets
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 真实世界的表格数据集
- en: There are thousands of real-world tabular datasets on the *Kaggle* website.
    Pluto has chosen two tabular datasets for this process.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*Kaggle*网站上有成千上万的真实世界表格数据集。Pluto选择了两个表格数据集来进行这一过程。'
- en: The *Bank Account Fraud Dataset Suite (NeurIPS 2022)* contains six synthetic
    bank account fraud tabular datasets. Each dataset contains 1 million records.
    They are based on real-world data for fraud detection. Each dataset focuses on
    a different type of bias. Sergio Jesus, Jose Pombal, and Pedro Saleiro published
    the dataset in 2022 under the **Attribution-NonCommercial-ShareAlike 4.0 International
    (CC BY-NC-SA 4.0)** license. The *Kaggle* link is [https://www.kaggle.com/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022](https://www.kaggle.com/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*银行账户欺诈数据集套件（NeurIPS 2022）*包含六个合成的银行账户欺诈表格数据集。每个数据集包含100万个记录。它们基于真实世界的欺诈检测数据，每个数据集侧重于不同类型的偏差。Sergio
    Jesus、Jose Pombal和Pedro Saleiro在2022年以**署名-非商业性使用-相同方式共享4.0国际（CC BY-NC-SA 4.0）**许可证发布了该数据集。*Kaggle*链接为[https://www.kaggle.com/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022](https://www.kaggle.com/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022)。'
- en: The *World Series Baseball Television Ratings* is a dataset for audiences watching
    the baseball World Series on television from 1969 to 2022\. Matt OP published
    the dataset in 2022 under the **CC0 1.0 Universal (CC0 1.0) Public Domain Dedication**
    license. The *Kaggle* link is [https://www.kaggle.com/datasets/mattop/world-series-baseball-television-ratings](https://www.kaggle.com/datasets/mattop/world-series-baseball-television-ratings).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*世界大联盟棒球电视收视率*是一个数据集，记录了1969到2022年间收看棒球世界大联盟赛的电视观众数据。Matt OP在2022年以**CC0 1.0通用（CC0
    1.0）公共领域献身**许可证发布了该数据集。*Kaggle*链接为[https://www.kaggle.com/datasets/mattop/world-series-baseball-television-ratings](https://www.kaggle.com/datasets/mattop/world-series-baseball-television-ratings)。'
- en: The steps for instantiating Pluto and downloading real-world datasets from the
    *Kaggle* website are the same. It starts with loading the `data_augmentation_with_python_chapter_9.ipynb`
    file into Google Colab or your chosen Jupyter Notebook or JupyterLab environment.
    From this point onward, the code snippets are from the Python Notebook, which
    contains the complete functions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化 Pluto 并从 *Kaggle* 网站下载真实世界数据集的步骤是相同的。首先，加载 `data_augmentation_with_python_chapter_9.ipynb`
    文件到 Google Colab 或你选择的 Jupyter Notebook 或 JupyterLab 环境。从这一点开始，代码片段来自于 Python
    Notebook，包含了完整的功能。
- en: 'You will be using the code from [*Chapter 2*](B17990_02.xhtml#_idTextAnchor038)
    because you will need the wrapper functions for downloading the *Kaggle* dataset,
    not the wrapper functions for image, text, and audio augmentations. You should
    review *Chapters 2* and *3* if the steps are unfamiliar:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用来自 [*第 2 章*](B17990_02.xhtml#_idTextAnchor038) 的代码，因为你需要用于下载 *Kaggle* 数据集的包装函数，而不是用于图像、文本和音频增强的包装函数。如果步骤不熟悉，应该复习
    *第 2 章* 和 *第 3 章*：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Fun challenge
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味挑战
- en: At the end of [*Chapter 8*](B17990_08.xhtml#_idTextAnchor167), Pluto challenged
    you to refactor the Pluto code for speed and compactness. The goal is to upload
    Pluto to [Pypi.org](https://Pypi.org). This challenge extends that concept and
    asks you to combine the setup code into one uber wrapper function, such as `pluto.just_do_it()`.
    Pluto does not use uber methods because this book aims to make the concepts and
    functions easier to learn and demystify the process.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 8 章*](B17990_08.xhtml#_idTextAnchor167) 结束时，Pluto 挑战你对 Pluto 代码进行重构以提高速度和紧凑性。目标是将
    Pluto 上传到 [Pypi.org](https://Pypi.org)。这个挑战扩展了这一概念，要求你将设置代码合并成一个超级包装函数，例如 `pluto.just_do_it()`。Pluto
    不使用超级方法，因为本书的目的是让概念和函数更容易学习，并揭开过程的神秘面纱。
- en: 'The output for gathering Pluto’s system information is as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 收集 Pluto 系统信息的输出如下：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Fun challenge
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味挑战
- en: Pluto challenges you to search for, download, and import two additional tabular
    datasets from the *Kaggle* website or your project into pandas.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 挑战你从 *Kaggle* 网站或你的项目中搜索、下载并导入两个额外的表格数据集到 pandas。
- en: With that, you have selected a tabular augmentation library, cloned the GitHub
    repository, instantiated Pluto, and downloaded the two real-world tabular datasets
    from the *Kaggle* website. Now, it is time for Pluto to explore and visualize
    the data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，你已经选择了一个表格数据增强库，克隆了 GitHub 仓库，实例化了 Pluto，并从 *Kaggle* 网站下载了两个真实世界的表格数据集。现在，是时候让
    Pluto 探索和可视化数据了。
- en: Exploring and visualizing tabular data
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索和可视化表格数据
- en: Tabular augmentation is more challenging than image, text, and audio augmentation.
    The primary reason is that you need to build a CNN or RNN model to see the effect
    of the synthetic data.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 表格数据增强比图像、文本和音频增强更具挑战性。主要原因是你需要构建一个 CNN 或 RNN 模型，以查看合成数据的效果。
- en: Pluto will spend more time explaining his journey to investigate the real-world
    Bank Fraud and World Series datasets than implementing the tabular augmentation
    functions using the DeltaPy library. Once you understand the data visualization
    process, you can apply it to other tabular datasets.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 将花更多时间解释他调查真实世界银行欺诈和世界大赛数据集的历程，而不是使用 DeltaPy 库实现表格增强函数。一旦你理解了数据可视化过程，你可以将其应用于其他表格数据集。
- en: Fun fact
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味事实
- en: Typically, Pluto starts a chapter by writing code in the Python Notebook for
    that chapter. It consists of around 150 to 250 combined code and text cells. They
    are unorganized collections of research notes and try-and-error Python code cells.
    Once Pluto proves that the concepts and techniques are working correctly through
    coding, he starts writing the chapter. As part of the writing progress, he cleans
    and refactors the Python Notebook with wrapper functions and deletes the dead-end
    code. The clean version of the Python Notebook contains 20% to 30% of the original
    code and text cells.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，Pluto 通过在该章节的 Python Notebook 中编写代码来开始一个章节。它包含大约 150 到 250 个代码和文本单元格。它们是未经组织的研究笔记和尝试错误的
    Python 代码单元格。一旦 Pluto 通过编码证明概念和技术正确无误，他便开始编写该章节。作为写作过程的一部分，他会清理并重构 Python Notebook，添加包装函数并删除无用的代码。Python
    Notebook 的干净版本包含原始代码和文本单元格的 20% 到 30%。
- en: 'In particular, while exploring tabular data, we will cover the following topics:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是在探索表格数据时，我们将涵盖以下主题：
- en: Data structure
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据结构
- en: First graph view
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个图表视图
- en: Checksum
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 校验和
- en: Specialized plots
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专门的图表
- en: Exploring the World Series baseball dataset
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索世界大赛棒球数据集
- en: Let’s start with data structures.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从数据结构开始。
- en: Data structure
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据结构
- en: 'Pluto starts by inspecting the data structure using pandas’ built-in function.
    He uses the following command:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto通过使用pandas的内置函数检查数据结构。他使用以下命令：
- en: '[PRE3]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The result is as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '[PRE4]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The Bank Fraud dataset consists of 32 columns, 1 million records or rows, no
    null values, and five columns that are not numeric. Pluto wants to find out which
    columns are **continuous** or **categorical**. He does this by calculating the
    unique value in each column. He uses the following pandas function:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 银行欺诈数据集由32列、100万条记录或行、没有空值，以及五列非数值型数据组成。Pluto想要找出哪些列是**连续的**或**分类的**。他通过计算每列的唯一值来实现这一点。他使用以下pandas函数：
- en: '[PRE5]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The partial output is as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 部分输出如下：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The Python Notebook contains the complete result. There are 7 continuous columns
    and 25 categorical columns. Generally, continuous columns have many unique values,
    as in total records, while categorical columns have unique values between two
    and a few hundred.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Python Notebook包含了完整的结果。共有7个连续列和25个分类列。通常，连续列有很多独特的值，如总记录数，而分类列的唯一值通常介于2到几百之间。
- en: 'Before using plots to display the data, Pluto will view sample data from the
    Bank Fraud dataset with the following command:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用图表展示数据之前，Pluto将使用以下命令查看银行欺诈数据集的样本数据：
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.2 – Sample Bank Fraud data](img/B17990_09_02.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图9.2 – 示例银行欺诈数据](img/B17990_09_02.jpg)'
- en: Figure 9.2 – Sample Bank Fraud data
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 – 示例银行欺诈数据
- en: After repeatedly running the command and variation, Pluto finds no surprises
    in the data. It is clean. The Python Notebook contains additional inspecting functions,
    such as the pandas `describe()` method.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在反复运行命令和变体后，Pluto发现数据中没有什么意外。数据是干净的。Python Notebook还包含额外的检查函数，如pandas的`describe()`方法。
- en: Fun fact
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味事实
- en: For a tabular dataset, you will write custom code for inspecting, visualizing,
    and augmenting the data. In other words, there will be more reusable concepts
    and processes than reusable code being carried over to the next project.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于表格数据集，你将编写自定义代码来检查、可视化和扩展数据。换句话说，更多的可重用概念和过程将被带到下一个项目，而不是可重用的代码。
- en: The Bank Fraud dataset has 32 million elements, which is the typical size of
    data that data scientists work with. However, your Python Notebook would crash
    if you tried to plot 32 million points using pandas and Matplotlib with the default
    settings. Pluto created a simple graph, `pluto.df_bank_data.plot()`, and his Google
    Colab Pro-version Python Notebook crashed. It required additional RAM.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 银行欺诈数据集包含3200万个元素，这也是数据科学家处理的典型数据量。然而，如果你尝试使用默认设置通过pandas和Matplotlib绘制3200万个点，Python
    Notebook会崩溃。Pluto创建了一个简单的图表`pluto.df_bank_data.plot()`，但他的Google Colab Pro版本Python
    Notebook崩溃了，原因是需要更多的内存。
- en: First graph view
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一个图形视图
- en: The various plots are not directly aiding in the tabular augmentation process.
    The primary goal is for you to envision a sizeable tabular dataset. Reading millions
    of data points is less effective than seeing them plotted on a graph. You may
    skip the sections about plotting and go directly to the tabular augmentation techniques
    using the DeltaPy library.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 各种图表并没有直接帮助表格扩展过程。主要目标是帮助你想象一个大型表格数据集。阅读数百万个数据点比将它们绘制在图表上更不有效。你可以跳过关于绘图的部分，直接进入使用DeltaPy库的表格扩展技术。
- en: 'For a large dataset, the solution is to select graphs with calculated or summarizing
    values. Hence, there will be fewer points to plot. For example, the **histogram**
    graph is a viable choice because it groups the frequency of ranges. Pluto uses
    a wrapper function to draw the histogram plot:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大型数据集，解决方案是选择计算或汇总值的图表。因此，将绘制更少的点。例如，**直方图**图表是一个可行的选择，因为它将频率范围分组。Pluto使用一个包装函数来绘制直方图：
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The key code line for the wrapper function is as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 包装函数的关键代码行如下：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.3 – Bank Fraud histogram plot](img/B17990_09_03.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图9.3 – 银行欺诈直方图](img/B17990_09_03.jpg)'
- en: Figure 9.3 – Bank Fraud histogram plot
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 – 银行欺诈直方图
- en: '*Figure 9**.3* does not yield any beneficial insights. Thus, Pluto proceeds
    to summarize the data with a **checksum** concept.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9.3*没有提供任何有益的见解。因此，Pluto继续通过**校验和**概念来总结数据。'
- en: Checksum
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校验和
- en: Pluto spends weeks playing with different types of graphs and graphing packages
    such as **Matplotlib**, **Seaborn**, **Joypi**, and **PyWaffle**. He has fun,
    but most do not enhance the visualization of the Bank Fraud and World Series datasets.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 花了几周的时间与不同类型的图表和绘图库进行尝试，如**Matplotlib**、**Seaborn**、**Joypi** 和 **PyWaffle**。他玩得很开心，但大多数并没有提升银行欺诈和世界系列数据集的可视化效果。
- en: 'At this point, Pluto will get back to more plotting. In tabular data, displaying
    the string, non-numeric data is challenging. A clean solution is transforming
    the categorical string data into an integer token index. Pluto writes the `_fetch_token_index()`
    helper function to index value from a list. The key code snippet is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，Pluto 将继续进行更多的绘图操作。在表格数据中，显示字符串类型的非数字数据具有挑战性。一种简洁的解决方案是将分类字符串数据转换为整数令牌索引。Pluto
    编写了 `_fetch_token_index()` 辅助函数，用于从列表中索引值。关键代码片段如下：
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `add_token_index()` wrapped function uses the helper function and the pandas
    `apply()` function. The essential code snippet is as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`add_token_index()` 包装函数使用了辅助函数和 pandas 的 `apply()` 函数。核心代码片段如下：'
- en: '[PRE11]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To put it all together, Pluto uses the following command to copy and create
    the tokenized columns for the Data Fraud dataset:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 综合起来，Pluto 使用以下命令来复制并创建数据欺诈数据集的令牌化列：
- en: '[PRE12]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Pluto double-checked the tokenization by viewing sample values using the following
    commands:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 通过查看以下命令中的示例值，双重检查了令牌化过程：
- en: '[PRE13]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.4 – Bank Fraud sample tokenized data](img/B17990_09_04.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.4 – 银行欺诈样本令牌化数据](img/B17990_09_04.jpg)'
- en: Figure 9.4 – Bank Fraud sample tokenized data
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 – 银行欺诈样本令牌化数据
- en: Pluto double-checked the other columns, and they are correct. You can view the
    code and the results by reading the Python Notebook.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 对其他列进行了双重检查，确保它们是正确的。你可以通过阅读 Python Notebook 查看代码和结果。
- en: 'For data analysis, it is practical to have a `_fetch_checksum()` helper function
    uses the pandas `apply()` method with `lambda`. The code snippet is as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据分析来说，具有一个使用 pandas `apply()` 方法和 `lambda` 的 `_fetch_checksum()` 辅助函数是很实用的。代码片段如下：
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Pluto calculates the checksum for the Bank Fraud dataset using the following
    command:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 使用以下命令计算银行欺诈数据集的校验和：
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: It took 27 seconds to compute the checksum for 32 million data points. Now,
    let’s explore a few specialized plots with the **checksum** concept.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 计算3200万个数据点的校验和花费了27秒。现在，让我们探索一些与**校验和**概念相关的专业绘图。
- en: Specialized plots
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 专业绘图
- en: Pluto wants to remind you that the following graphs and exercises do not directly
    pertain to tabular augmentation. The goal is to sharpen your skills in understanding
    and visualizing sizeable real-world datasets – for example, the Bank Fraud dataset
    consists of 1 million records in preparation for data augmentation. You can skip
    the plotting exercises and jump directly to the tabular augmentation lessons if
    you wish.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 想提醒你，以下图表和练习与表格增强并不直接相关。目标是提高你在理解和可视化大型真实世界数据集方面的技能——例如，银行欺诈数据集包含100万条记录，旨在为数据增强做准备。如果你愿意，可以跳过绘图练习，直接进入表格增强的课程。
- en: 'Pluto creates `self.df_bank_half_data` with a limited number of columns for
    ease of display. He uses `heatmap()` function to draw the **correlogram** plot.
    The command is as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 创建了一个包含有限列的 `self.df_bank_half_data`，以便于展示。他使用 `heatmap()` 函数绘制了**相关图**。命令如下：
- en: '[PRE16]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output is as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.5 – Bank Fraud half correlogram](img/B17990_09_05.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.5 – 银行欺诈半相关图](img/B17990_09_05.jpg)'
- en: Figure 9.5 – Bank Fraud half correlogram
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 – 银行欺诈半相关图
- en: '*Figure 9**.5* shows a high relationship between `credit_risk_score` and `proposed_credit_limit`
    with 61%. `fraud_bool` has a low correlation with all other parameters.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9.5* 显示了 `credit_risk_score` 与 `proposed_credit_limit` 之间的高相关性，达到了61%。`fraud_bool`
    与其他所有参数的相关性较低。'
- en: When Pluto draws the correlogram plot with the entire dataset, it exposes a
    high correlation between the **checksum** and **velocity_6h**, **velocity_24h**,
    and **velocity_4w**. The code and the output can be found in the Python Notebook.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Pluto 使用整个数据集绘制相关图时，揭示了**校验和**与**velocity_6h**、**velocity_24h**和**velocity_4w**之间的高相关性。代码和输出结果可以在
    Python Notebook 中找到。
- en: 'The `draw_tabular_heatmap()` wrapper function looks like a heatmap. The command
    is as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`draw_tabular_heatmap()` 包装函数看起来像是热图。命令如下：'
- en: '[PRE17]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.6 – Bank Fraud checksum and month heatmap](img/B17990_09_06.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.6 – 银行欺诈校验和与月份热图](img/B17990_09_06.jpg)'
- en: Figure 9.6 – Bank Fraud checksum and month heatmap
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.6 – 银行欺诈 校验和与月份热力图
- en: '*Figure 9**.6* shows a pattern, but the relationship between the **checksum**
    and **month** is unclear.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9.6* 显示了一个模式，但 **校验和** 与 **月份** 之间的关系并不明确。'
- en: Fun fact
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味小知识
- en: Pluto is not an expert in reading Bank Fraud data, and it is natural for you
    not to be an expert in every domain. Pluto consults friends in banking and consumer
    protection agencies for background research. Here are a few charts that he uses
    in his work.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 并不是银行欺诈数据的专家，而你也不可能在每个领域都是专家。Pluto 向银行和消费者保护机构的朋友咨询，进行背景研究。以下是他在工作中使用的一些图表。
- en: 'The fraud data, `fraud_bool == 1`, is 1% of the total. Thus, Pluto might want
    to augment more fraud data. He creates a pandas DataFrame using the following
    commands:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 欺诈数据 `fraud_bool == 1` 占总数据的 1%。因此，Pluto 可能希望增强更多欺诈数据。他使用以下命令创建了一个 pandas DataFrame：
- en: '[PRE18]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The following two graphs suggested by Pluto’s banking expert friends are fun
    to create but may not benefit the Bank Fraud augmentation. The complete code is
    in the Python Notebook. Nevertheless, they are thought-provoking concepts over
    the standard line or bar charts:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 的银行专家朋友建议的以下两个图形非常有趣，但可能对银行欺诈数据增强没有益处。完整代码在 Python Notebook 中。尽管如此，它们仍然是超越标准线性或条形图的发人深省的概念：
- en: '![Figure 9.7 – Bank Fraud Seaborn heatmap with mask](img/B17990_09_07.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.7 – 银行欺诈 Seaborn 带掩码的热力图](img/B17990_09_07.jpg)'
- en: Figure 9.7 – Bank Fraud Seaborn heatmap with mask
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.7 – 银行欺诈 Seaborn 带掩码的热力图
- en: The next graph is the Swarmplot.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图形是群集图（Swarmplot）。
- en: '![Figure 9.8 – Bank Fraud Seaborn swarm plot](img/B17990_09_08.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.8 – 银行欺诈 Seaborn 群集图](img/B17990_09_08.jpg)'
- en: Figure 9.8 – Bank Fraud Seaborn swarm plot
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.8 – 银行欺诈 Seaborn 群集图
- en: Fun challenge
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味挑战
- en: 'Can you make use of the `tripcolor()` 3D graph, shown in *Figure 9**.9*, using
    the Bank Fraud dataset? The `tripcolor()` code is in the Python Notebook:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 你能否利用 `tripcolor()` 3D 图，展示在 *图 9.9* 中的内容，使用银行欺诈数据集？`tripcolor()` 的代码在 Python
    Notebook 中：
- en: '![Figure 9.9 – Fun challenge – a tripcolor plot of random values](img/B17990_09_09.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.9 – 趣味挑战 – 随机值的 tripcolor 图](img/B17990_09_09.jpg)'
- en: Figure 9.9 – Fun challenge – a tripcolor plot of random values
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.9 – 趣味挑战 – 随机值的 tripcolor 图
- en: Exploring the World Series data
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 World Series 数据
- en: In this section, Pluto will spend much time plotting various graphs to understand
    and visualize the World Series data. He is not performing tabular augmentation.
    Even though comprehending the data is essential before deciding which augmentation
    functions are applicable, you can skip this exercise and directly go to the tabular
    augmentation wrapper functions.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，Pluto 将花费大量时间绘制各种图形，以便理解和可视化 World Series 数据。他并没有执行表格数据增强。尽管理解数据在决定应用哪些增强功能之前至关重要，但你可以跳过这一练习，直接进入表格数据增强的封装函数。
- en: Fun fact
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味小知识
- en: Anecdotally, Pluto, an imaginary Sybirian Huskey, loves to rush ahead and start
    writing augmenting code without taking the time to sniff out the content of the
    datasets. Consequently, his AI model diverged 9 out of 10 times, resulting in
    high levels of false negatives and false positives. Thus, spending 40% to 70%
    of the time studying the datasets seems non-productive, but it is not. It is an
    acceptable fact when working with real-world datasets.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 据说，Pluto，一只虚构的西伯利亚哈士奇，喜欢冲到前面，开始编写增强代码，而不花时间嗅探数据集的内容。因此，他的 AI 模型有 9 次中的 10 次会出现偏差，导致高水平的假阴性和假阳性。因此，花费
    40% 到 70% 的时间研究数据集似乎效率不高，但事实并非如此。这在处理实际数据集时是一个可以接受的现实。
- en: 'Pluto follows a similar process for the World Series dataset. He runs the first
    `info()` method, followed by `nunique(), describe()`, and then `sample()`. The
    World Series dataset consists of 14 columns and 54 rows, representing 756 data
    points. There are 11 numeric columns and three label categories. Other factors
    are eight `pluto.df_world_data.info()` command is as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 对 World Series 数据集执行类似的处理。他首先运行 `info()` 方法，然后是 `nunique(), describe()`，接着运行
    `sample()`。World Series 数据集包含 14 列和 54 行，代表 756 个数据点。数据集中有 11 列数字型数据和 3 列标签类别。其他因素包括以下的
    `pluto.df_world_data.info()` 命令：
- en: '[PRE19]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Other results can be found in the Python Notebook. The histogram plot is the
    practical first data visualization technique for the World Series dataset. The
    command is as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 其他结果可以在 Python Notebook 中找到。直方图绘图是 World Series 数据集的首要数据可视化技术。命令如下：
- en: '[PRE20]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.10 – World Series histogram](img/B17990_09_10.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.10 – World Series 直方图](img/B17990_09_10.jpg)'
- en: Figure 9.10 – World Series histogram
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.10 – World Series 直方图
- en: 'The histogram plot shown in *Figure 9**.10* does not highlight the comparison
    between the audience in the seven games. Pluto uses the `joyplot()` method from
    the **joypy** library to display the relationship between the viewing audience
    and the TV networks. The command is as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9.10*中的直方图没有突出显示七场比赛观众之间的比较。Pluto使用来自**joypy**库的`joyplot()`方法显示观众与电视网络之间的关系。命令如下：'
- en: '[PRE21]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.11 – World Series audience and TV networks](img/B17990_09_11.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图9.11 – 世界大赛观众与电视网络](img/B17990_09_11.jpg)'
- en: Figure 9.11 – World Series audience and TV networks
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.11 – 世界大赛观众与电视网络
- en: '*Figure 9**.11* is a beautiful and insightful visualization plot. NBC television
    network has the highest number of game viewers for game #7 but also has the lowest
    number for game #5\. Fox TV has the least number of viewers, and ABC TV has the
    highest total viewers but only a little more than NBC TV. Game #3 has the lowest
    number of viewers, while game #7 has the highest.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9.11*是一个美丽且富有洞察力的可视化图。NBC电视网络在第七场比赛中拥有最多的观众，但在第五场比赛中拥有最少的观众。Fox电视台的观众最少，而ABC电视台的总观众数最多，仅略高于NBC电视台。第三场比赛的观众最少，而第七场比赛的观众最多。'
- en: 'Pluto prepares the World Series dataset for augmenting by converting the label
    categories into integer token indexes and calculates the checksum. The commands
    are as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto通过将标签类别转换为整数令牌索引并计算校验和，为世界大赛数据集的增强做准备。命令如下：
- en: '[PRE22]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The code for double-checking and printing the results for the tokenization
    and checksum can be found in the Python Notebook. Pluto made a quick correlogram
    plot with the following command:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 用于双重检查并打印分词和校验和结果的代码可以在Python Notebook中找到。Pluto使用以下命令快速绘制了相关图：
- en: '[PRE23]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The result is as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 9.12 – World Series correlogram plot](img/B17990_09_12.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图9.12 – 世界大赛相关图](img/B17990_09_12.jpg)'
- en: Figure 9.12 – World Series correlogram plot
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.12 – 世界大赛相关图
- en: '*Figure 9**.12* exposes many intriguing relationships between the data. For
    example, there is a 100% correlation between **losing_team_wins** and **total_game_played**,
    and strong relationships between **average_audience, game_1_audience**, **game_2_audience**,
    **game_3_audience**, and **game_4_audience**.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9.12*揭示了数据之间许多有趣的关系。例如，**losing_team_wins**和**total_game_played**之间有100%的相关性，**average_audience、game_1_audience**、**game_2_audience**、**game_3_audience**和**game_4_audience**之间也存在强烈的关系。'
- en: 'Pluto uses the `joyplot()` method to compare the checksum with the average
    viewers grouped by the TV networks. The command is as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto使用`joyplot()`方法将校验和与按电视网络分组的平均观众进行比较。命令如下：
- en: '[PRE24]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.13 – World Series checksum, average audience grouped by TV networks](img/B17990_09_13.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图9.13 – 世界大赛校验和，按电视网络分组的平均观众](img/B17990_09_13.jpg)'
- en: Figure 9.13 – World Series checksum, average audience grouped by TV networks
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.13 – 世界大赛校验和，按电视网络分组的平均观众
- en: In *Figure 9**.13*, Pluto uses the `mean()` function to calculate the checksum
    values. Thus, the comparison to the average viewers yields a similar shape. Compared
    to *Figure 9**.11*, the relationship between average audience size and each game’s
    total is not immediately apparent because CBS TV has the highest average but seems
    to have lower per-game viewers.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图9.13*中，Pluto使用`mean()`函数计算校验和值。因此，与平均观众数的比较呈现出相似的形状。与*图9.11*相比，平均观众人数与每场比赛的总观众人数之间的关系并不显而易见，因为CBS电视台的平均观众数最高，但似乎每场比赛的观众较少。
- en: At this stage, Pluto wonders if plotting more graphs would help him understand
    the dataset better. There is a good chance that you are thinking the same thoughts.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，Pluto在想，绘制更多图表是否有助于他更好地理解数据集。你很可能也在想同样的问题。
- en: The justification for exploring additional charts is twofold. The real-world
    tabular data is diverse. Thus, knowing various graphs makes you better prepared
    to tackle your next project. Second, no criteria or algorithm lets you know you
    have learned about the datasets sufficiently. Therefore, if you know the data,
    skip to the tabular augmentation functions section or follow along with Pluto
    as he learns new graphs.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 探索更多图表的理由有两点。首先，现实世界中的表格数据非常多样化。因此，了解各种图表能让你更好地为下一个项目做好准备。其次，没有任何标准或算法可以告诉你，数据集是否已经学得足够深入。因此，如果你已经了解数据，可以跳过数据增强函数部分，或者像Pluto一样继续学习新的图表。
- en: 'Pluto uses the `draw_tabular_waffle()` uses the `Waffle` class from the **pywaffle**
    library. The command for displaying the World Series winning teams is as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 使用 `draw_tabular_waffle()` 方法调用 **pywaffle** 库中的 `Waffle` 类。显示世界大赛冠军队的命令如下：
- en: '[PRE25]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output is as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.14 – World Series winning team](img/B17990_09_14.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.14 – 世界大赛冠军队](img/B17990_09_14.jpg)'
- en: Figure 9.14 – World Series winning team
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.14 – 世界大赛冠军队
- en: 'Pluto does the same for displaying the losing teams. The command is as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 对显示失败队伍做了相同的处理。命令如下：
- en: '[PRE26]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output is as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.15 – World Series losing team](img/B17990_09_15.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.15 – 世界大赛失败队](img/B17990_09_15.jpg)'
- en: Figure 9.15 – World Series losing team
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.15 – 世界大赛失败队
- en: '*Figures 9.14* and *9.15* are beautifully colored waffle graphs. There is no
    dominant or underdog team. Pluto does the same for TV networks. The command is
    as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9.14* 和 *9.15* 是色彩鲜艳的华夫图。没有明显的强队或弱队。Pluto 对电视网络做了相同的处理。命令如下：'
- en: '[PRE27]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.16 – World Series TV networks](img/B17990_09_16.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.16 – 世界大赛电视网络](img/B17990_09_16.jpg)'
- en: Figure 9.16 – World Series TV networks
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.16 – 世界大赛电视网络
- en: '*Figure 9**.16* yields a surprising hidden fact in the data: Fox TV aired the
    most games, but from *Figures 9.11* and *9.12*, it does not seem like the network
    with the most viewers.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9.16* 显示了数据中一个令人惊讶的隐藏事实：Fox TV 播出了最多的比赛，但从 *图 9.11* 和 *图 9.12* 中来看，它似乎不是观众最多的电视网络。'
- en: Fun challenge
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味挑战
- en: 'Here is a thought experiment: can you visualize a **four-dimensional** (**4D**)
    graph? Hint: a 2D chart displays two measurements, such as the number of TV audiences
    per game, or one vector with an implied time series as the X-axis, such as the
    bank member’s income with the X-axis indicated as day or month. A 3D graph typically
    reveals the snow depth level on a mountain. Time could be the fourth dimension.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个思想实验：你能想象一个 **四维**（**4D**）图表吗？提示：一个二维图显示两个度量标准，例如每场比赛的电视观众人数，或者一个带有时间序列隐含的X轴的向量，例如银行成员的收入，X轴表示日期或月份。三维图通常显示山上的积雪深度。时间可以作为第四维。
- en: Pluto has explored and explained the real-world Bank Fraud and World Series
    datasets. He uses pandas functions to display statistical information and provides
    numerous graphs to visualize them. Understanding and visualizing the data is the
    first and most essential step before augmenting tabular data.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 探索并解释了现实世界中的银行欺诈和世界大赛数据集。他使用 pandas 函数来展示统计信息，并提供了许多图表来进行可视化。在对表格数据进行增强之前，理解和可视化数据是第一步，也是最重要的一步。
- en: Fun fact
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味事实
- en: 'Data augmentation is a secret for DL and generative AI to achieve unprecedented
    accuracy and success. Many scholarly papers reinforced data augmentation’s significance,
    such as *Enhancing Performance of Deep Learning Models with Different Data Augmentation
    Techniques: A Survey*, by Cherry Khosla and Baljit Singh Saini, published by *IEEE
    2020 Intelligent Engineering and Management (ICIEM),* *International Conference*.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '数据增强是深度学习（DL）和生成式人工智能（AI）实现前所未有的准确性和成功的秘密。许多学术论文加强了数据增强的重要性，例如Cherry Khosla和Baljit
    Singh Saini撰写的*Enhancing Performance of Deep Learning Models with Different Data
    Augmentation Techniques: A Survey*，该论文发表于*IEEE 2020 Intelligent Engineering and
    Management (ICIEM)*，*国际会议*。'
- en: Transforming augmentation
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据增强的转变
- en: 'Before digging into the tabular augmentation methods, Pluto will reiterate
    that he will not build a neural network model to test if the augmentation benefits
    the particular dataset. In addition, the pattern for writing the wrapper functions
    follows the previous practice: using the chosen library to do the critical augmentation
    step.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨表格数据增强方法之前，Pluto 重申他不会建立神经网络模型来验证增强对特定数据集的效果。此外，编写包装函数的模式遵循以前的做法：使用选定的库来执行关键的增强步骤。
- en: As the Python Notebook notes, the DeltaPy library’s dependency is the **fbprofet**
    and **pystan** libraries. The three libraries are in beta and may be unstable.
    Pluto has repeatedly tested the Python code. Once the libraries have been loaded,
    the code works flawlessly.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 正如 Python Notebook 中所述，DeltaPy 库的依赖是 **fbprophet** 和 **pystan** 库。这三个库都处于测试版，可能不稳定。Pluto
    已反复测试过 Python 代码。一旦这些库加载完成，代码就能完美运行。
- en: Tabular transformation is a collection of techniques that take one variable
    and generate a new dataset based on the transformation method. It applies to both
    cross-section and time series data. The DeltaPy library defines 14 functions for
    transformation.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 表格变换是一种技术集合，它通过变换方法基于一个变量生成新的数据集。它适用于横截面数据和时间序列数据。DeltaPy库定义了14个变换函数。
- en: These transformation techniques include the **operations** functions used in
    present information, the **smoothing** method used with past data, and the **select
    filters** procedure used with lagging and leading values.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变换技术包括用于当前信息的**操作**函数、用于历史数据的**平滑**方法，以及用于滞后和领先值的**选择过滤器**过程。
- en: In image augmentation, Pluto can run the functions and see what changes in the
    photo. Here, the effects are apparent, such as **cropped**, **enlarged**, or **altered**
    hue values. Tabular augmentation requires knowledge of DL and time series data.
    In other words, the output effects are not obvious; therefore, selecting augmentation
    functions for a particular dataset can be intimidating. Pluto will demonstrate
    how to write Python code for tabular augmentation, but he will not thoroughly
    explain when to use them.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像增强中，Pluto可以运行这些函数并查看照片中发生了什么变化。这里的效果非常明显，例如**裁剪**、**放大**或**改变**色调值。表格增强需要对深度学习和时间序列数据有一定的了解。换句话说，输出效果不那么明显，因此选择适合特定数据集的增强函数可能会令人望而却步。Pluto将演示如何为表格增强编写Python代码，但他不会详细解释何时使用这些函数。
- en: Time series forecasting is a mature and highly researched branch of AI. It could
    take several college courses to understand a time series and how to forecast or
    predict future outcomes. A compact definition of a time series is a data sequence
    that depends on time. Typical time series data is the market stock value. For
    example, Pluto uses the Microsoft stock data for the previous 10 years to predict
    the closing price of tomorrow, next week, or next month. Weather forecasting is
    another widespread use of time series algorithms.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列预测是人工智能中一个成熟且高度研究的分支。理解时间序列及其如何预测或预示未来结果可能需要数门大学课程。时间序列的简洁定义是一个依赖于时间的数据序列。典型的时间序列数据是市场股票价值。例如，Pluto使用过去10年的微软股票数据来预测明天、下周或下个月的收盘价。天气预报是时间序列算法的另一个广泛应用。
- en: The two key concepts in time series data are **lag time** and **windows**. The
    lag time is from the observer to a set point, while the window is the range of
    elements segmented. There are dozens of other key concepts in time series algorithms,
    from the earliest **long short-term memory** (**LSTM**) neural network to **ARIMA**,
    **SARIMA**, **HWES**, **ResNet**, **InceptionTime**, **MiniRocket**, and many
    others.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据中的两个关键概念是**滞后时间**和**窗口**。滞后时间是从观察者到某一特定点的时间，而窗口是分段的元素范围。时间序列算法中还有几十个其他关键概念，从最早的**长短期记忆**（**LSTM**）神经网络到**ARIMA**、**SARIMA**、**HWES**、**ResNet**、**InceptionTime**、**MiniRocket**等。
- en: Most tabular data can be converted into time series data. The **World Series**
    data is a time series based on the year. The **Bank Fraud** data does not directly
    have a time vector. However, by adding time data, Pluto can predict at which hour
    of the day, be it early morning or late night, when most online bank fraud occurs,
    or he can forecast when most bank fraud happens seasonally, such as around Christmas
    or college Spring Break.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数表格数据可以转换为时间序列数据。**世界系列**数据是基于年份的时间序列数据。**银行诈骗**数据没有直接的时间向量。然而，通过添加时间数据，Pluto可以预测一天中的哪个时段——无论是清晨还是深夜——大多数在线银行诈骗发生的时刻，或者他可以预测季节性银行诈骗的发生时间，例如圣诞节或大学春假期间。
- en: 'There are 14 transformation methods, and in particular, Pluto will cover the
    following three functions:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 共有14种变换方法，特别地，Pluto将介绍以下三种函数：
- en: Robust scaler
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鲁棒缩放器
- en: Standard scaler
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准缩放器
- en: Capping
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上限限制
- en: Let’s start with the robust scaler.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从鲁棒缩放器开始。
- en: Robust scaler
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 鲁棒缩放器
- en: The **K-means** and **principal component analysis** (**PCA**) time series algorithms
    use Euclidean distance. Thus, scaling applies to the World Series dataset. When
    you’re unsure of the data distribution, the robust scaler, also known as **normalization**,
    is a viable technique. The algorithm forecasts future outcomes.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**K-means**和**主成分分析**（**PCA**）时间序列算法使用欧几里得距离。因此，缩放适用于世界系列数据集。当你不确定数据分布时，鲁棒缩放器，也称为**归一化**，是一种可行的技术。该算法用于预测未来结果。'
- en: 'Pluto’s `augment_tabular_robust_scaler()` wrapped function uses the DeltaPy
    library function and the joy and waffle plots. The essential code snippet is as
    follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 的 `augment_tabular_robust_scaler()` 封装函数使用了 DeltaPy 库函数和喜悦图与华夫图。核心代码片段如下：
- en: '[PRE28]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The full function code can be found in the Python Notebook. The command for
    the World Series data is as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的函数代码可以在 Python 笔记本中找到。世界大赛数据的命令如下：
- en: '[PRE29]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output is as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.17 – World Series and robust scaler joy plot](img/B17990_09_17.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.17 – 世界大赛和稳健缩放器喜悦图](img/B17990_09_17.jpg)'
- en: Figure 9.17 – World Series and robust scaler joy plot
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.17 – 世界大赛和稳健缩放器喜悦图
- en: '*Figure 9**.17* confirmed that Pluto successfully implemented the robust scaler
    augmenting technique. Whether it is practical in forecasting is another question
    entirely. It depends on the goal of the prediction and the base DL model or algorithm
    used.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9**.17* 确认了 Pluto 成功实现了稳健缩放器增强技术。它在预测中的实际效果则是另一个问题，这取决于预测目标和所使用的基础深度学习模型或算法。'
- en: The **standard scaler** is similar to the robust scaler.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '**标准缩放器**与稳健缩放器类似。'
- en: Standard scaler
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标准缩放器
- en: 'DL models that rely on Gaussian distributions or linear and logistic regressions
    will benefit from the standardization scaler augmentation method. Pluto’s `augment_tabular_standard_scaler()`
    wrapper function uses the DeltaPy library function and the joy and waffle plots.
    The essential code snippet is as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖于高斯分布或线性回归和逻辑回归的深度学习模型将从标准化缩放器增强方法中受益。Pluto 的 `augment_tabular_standard_scaler()`
    封装函数使用了 DeltaPy 库函数和喜悦图与华夫图。核心代码片段如下：
- en: '[PRE30]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The full function code can be found in the Python Notebook. The command is
    as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的函数代码可以在 Python 笔记本中找到。命令如下：
- en: '[PRE31]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The output is as follows:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.18 – World Series and standard scaler joy plot](img/B17990_09_18.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.18 – 世界大赛和标准缩放器喜悦图](img/B17990_09_18.jpg)'
- en: Figure 9.18 – World Series and standard scaler joy plot
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.18 – 世界大赛和标准缩放器喜悦图
- en: '*Figure 9**.18* demonstrated that Pluto did the augmentation correctly. He
    did not build and train a DL model using the augmented data to confirm that it
    increased the forecast accuracy. Many tabular augmentation methods require defining
    the goal for the DL project to verify if the augmentation is beneficial. For example,
    Pluto could build a DL model for predicting the audience size for the next World
    Series.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9**.18* 演示了 Pluto 正确进行了数据增强。他并未使用增强后的数据构建并训练深度学习模型，以确认它是否提高了预测准确性。许多表格数据增强方法需要定义深度学习项目的目标，以验证增强是否有效。例如，Pluto
    可以构建一个深度学习模型来预测下一次世界大赛的观众人数。'
- en: The next tabular transformation technique we’ll look at is **capping**.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要查看的下一个表格数据转换技术是 **封顶**。
- en: Capping
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 封顶
- en: The capping technique limits the distribution value, such as average, maximum,
    minimum, or arbitrary values. In particular, it restricts the values using statistical
    analysis and replaces the outliers with specific percentile values.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 封顶技术限制了分布值，例如平均值、最大值、最小值或任意值。特别地，它通过统计分析来限制数值，并用特定的百分位数值替换异常值。
- en: 'Pluto’s `augment_tabular_capping()` wrapper function uses the DeltaPy library
    function and correlogram plots. The essential code snippet is as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 的 `augment_tabular_capping()` 封装函数使用了 DeltaPy 库函数和相关图。核心代码片段如下：
- en: '[PRE32]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The command for the Bank Fraud data is as follows:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 银行欺诈数据的命令如下：
- en: '[PRE33]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output is as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.19 – Bank Fraud capping correlogram plot, half data](img/B17990_09_19.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.19 – 银行欺诈封顶相关图，半数据](img/B17990_09_19.jpg)'
- en: Figure 9.19 – Bank Fraud capping correlogram plot, half data
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.19 – 银行欺诈封顶相关图，半数据
- en: '*Figure 9**.19* indicates that Pluto implemented the capping technique correctly.
    Compared to *Figure 9**.4*, the original data, the values are similar, as expected.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9**.19* 表示 Pluto 正确实施了封顶技术。与 *图 9**.4*（原始数据）相比，数值相似，符合预期。'
- en: 'The Python implementation of tabular transformation wrapper functions becomes
    repetitive. Thus, Pluto will provide a brief explanation of the other nine methods
    in the DeltaPy library. They are as follows:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 表格数据转换封装函数的 Python 实现变得重复。因此，Pluto 会简要介绍 DeltaPy 库中的其他九种方法。它们如下：
- en: '**Operations** is a technique for using power, log, or square root functions
    to replace elements in the dataset'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操作**是一种使用幂函数、对数函数或平方根函数替换数据集元素的技术。'
- en: '**Smoothing** is a technique that uses the triple exponential smoothing or
    Holt-Winters exponential smoothing function'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平滑**是一种使用三重指数平滑或Holt-Winters指数平滑函数的技术。'
- en: '**Decomposing** is a technique that uses the naive decomposition function for
    seasonal vectors in time series data'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分解**是一种使用朴素分解函数处理时间序列数据中的季节性向量的技术。'
- en: '**Filtering** is a technique that uses the Baxter-King bandpass filter to smooth
    time series data'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过滤**是一种使用Baxter-King带通滤波器对时间序列数据进行平滑的技术。'
- en: '**Spectral analysis** is a technique that uses the periodogram function to
    estimate the spectral density'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**谱分析**是一种使用周期图函数估计谱密度的技术。'
- en: '**Waveforms** is a technique that uses the continuous harmonic wave radar function
    to augment waveform data'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**波形**是一种使用连续谐波波形雷达函数来增强波形数据的技术。'
- en: '**Rolling** is a technique that uses mean or standard deviation to calculate
    the rolling average over a fixed window size in time series data'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**滚动**是一种使用均值或标准差计算固定窗口大小下的滚动平均值的技术，适用于时间序列数据。'
- en: '**Lagging** is a technique that calculates the lagged values in time series
    data'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**滞后**是一种计算时间序列数据中滞后值的技术。'
- en: '**Forecast model** is a technique that uses the prophet algorithm to forecast
    seasonal trends, such as weekly or yearly, in time series data'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测模型**是一种使用Prophet算法来预测时间序列数据中季节性趋势（如每周或每年）的技术。'
- en: Fun challenge
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的挑战
- en: Pluto challenges you to implement three wrapper functions in the Python Notebook
    from the nine tabular transformation techniques mentioned.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto挑战你在Python Notebook中实现九种表格转换技术中的三个包装函数。
- en: Now that we’ve reviewed various tabular transformation techniques, let’s look
    at **interaction** techniques.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经回顾了各种表格转换技术，让我们来看看**交互**技术。
- en: Interaction augmentation
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交互增强
- en: Interaction techniques are used in ML and statistical modeling to capture the
    relationships between two or more features in a dataset for augmentation. The
    goal is to create new augmentation data that captures the interaction between
    existing components, which can help improve model performance and provide additional
    insights into the data. You can apply these techniques to cross-sectional or time-specific
    data, including normalizing, discretizing, and autoregression models.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 交互技术在机器学习和统计建模中用于捕捉数据集中两个或更多特征之间的关系，以进行增强。其目标是创建新的增强数据，捕捉现有组件之间的交互关系，这有助于提高模型的性能，并为数据提供更多的见解。你可以将这些技术应用于横截面数据或特定时间数据，包括归一化、离散化和自回归模型。
- en: Pluto has selected two out of seven methods for a hands-on Python programming
    demonstration. As with the transformation augmentation methods, the coding is
    repetitive. Thus, Pluto will provide fun challenges for the other five interaction
    augmentation techniques.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto从七种方法中选择了两种进行Python编程演示。与转换增强方法一样，编码是重复性的。因此，Pluto将为其他五种交互增强技术提供有趣的挑战。
- en: Pluto will start with the **regression** method, then the **operator** method.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto将从**回归**方法开始，然后是**操作符**方法。
- en: Regression augmentation
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归增强
- en: The regression method uses the **lowess smoother** function to smooth the curve
    of the data by locally weighting the observations near a given point. It is a
    useful tabular augmentation technique for exploring relationships in scatterplots
    where the relationship between the dependent and independent variables needs to
    be well-described by a linear function. This method can suffer from forward-looking
    bias. Thus, Pluto recommends caution in using it for predictive modeling.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 回归方法使用**lowess平滑器**函数，通过局部加权给定点附近的观测值来平滑数据曲线。这是一种有用的表格增强技术，适用于探索散点图中因变量和自变量之间的关系，这种关系需要通过线性函数来很好地描述。该方法可能会受到前瞻性偏差的影响。因此，Pluto建议在用于预测建模时要谨慎使用。
- en: 'Pluto’s `augment_tabular_regression()` wrapper function uses the DeltaPy library
    function, a joy plot, and a correlogram graph. The essential code snippet is as
    follows:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto的`augment_tabular_regression()`包装函数使用DeltaPy库函数、愉悦图和自相关图。核心代码片段如下：
- en: '[PRE34]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The command for the World Series data is as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 世界系列数据的命令如下：
- en: '[PRE35]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The output is as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.20 – World Series regression augmentation, joy plot](img/B17990_09_20.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.20 – 世界系列回归增强，愉悦图](img/B17990_09_20.jpg)'
- en: Figure 9.20 – World Series regression augmentation, joy plot
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.20 – 世界系列回归增强，愉悦图
- en: '*Figures 9.20* confirm that Pluto implemented the regression tabular augmentation
    correctly. The DeltaPy library does the actual calculation. Thus, if Pluto made
    a mistake, the result would be an error, or the dataset would contain random numbers
    and not display correctly. Pluto can only claim the effectiveness of the regression
    technique to the World Series data. The next tabular augmentation technique we’ll
    look at is the operator augmenting method.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9.20*确认Pluto正确地实现了回归表格增强。DeltaPy库执行实际计算。因此，如果Pluto出错，结果将是一个错误，或者数据集将包含随机数并无法正确显示。Pluto只能声明回归技术对世界系列数据的有效性。接下来我们将讨论的表格增强技术是运算符增强方法。'
- en: Operator augmentation
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运算符增强
- en: The operator method is a simple multiplication or division function between
    two variables in tabular data.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 运算符方法是一个简单的乘法或除法函数，作用于表格数据中的两个变量。
- en: 'Pluto’s `augment_tabular_operator()` wrapper function uses the DeltaPy library
    function and a correlogram graph. The essential code snippet is as follows:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto的`augment_tabular_operator()`包装函数使用DeltaPy库函数和相关图。其核心代码片段如下：
- en: '[PRE36]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Pluto runs the command for the Bank Fraud data, as follows:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto运行了用于银行欺诈数据的命令，结果如下：
- en: '[PRE37]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output is as follows:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.21 – Bank Fraud operator augmentation, correlogram plot](img/B17990_09_21.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![图9.21 – 银行欺诈运算符增强，相关图](img/B17990_09_21.jpg)'
- en: Figure 9.21 – Bank Fraud operator augmentation, correlogram plot
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.21 – 银行欺诈运算符增强，相关图
- en: '*Figure 9**.21* shows a strong relationship between three new vectors: `credit_risk_score_X_proposed_credit_limit`
    (multiply), `proposed_credit_limit/credit_risk_score` (divide), and `proposed_credit_limit_X_credit_risk_score`
    (multiply). Pluto implements the operator function correctly but still determines
    the benefit of the DL prediction accuracy.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9.21*显示了三个新向量之间的强关系：`credit_risk_score_X_proposed_credit_limit`（乘法）、`proposed_credit_limit/credit_risk_score`（除法）和`proposed_credit_limit_X_credit_risk_score`（乘法）。Pluto正确地实现了运算符功能，但仍需确定深度学习预测准确度的收益。'
- en: 'The other five interaction tabular augmentation techniques are as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 其他五种交互表格增强技术如下：
- en: '**Discretizing** is a method that uses **decision trees**, **equal width binding**,
    **equal frequency binding**, and **K-means clustering** to augment the tabular
    data. The discretization method depends on the AI model and the tabular data properties.
    Pluto recommends trying multiple approaches and evaluating their performance.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离散化**是一种使用**决策树**、**等宽分箱**、**等频分箱**和**K均值聚类**来增强表格数据的方法。离散化方法取决于AI模型和表格数据的特性。Pluto建议尝试多种方法并评估其性能。'
- en: The **quantile normalizing** method makes the distributions of the datasets
    comparable by transforming them so that they have the same cumulative distribution
    value.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分位数归一化**方法通过转换数据集，使它们具有相同的累计分布值，从而使数据集的分布具有可比性。'
- en: The **haversine distance** calculates the shortest distance between two angular
    points, such as the Earth’s surface. Tabular augmentation also uses the **Euclidean**,
    **Mahalanobis**, and **Minkowski** distance algorithms.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**哈弗辛距离**计算两个角度点之间的最短距离，例如地球表面的距离。表格增强还使用**欧几里得**、**马哈拉诺比斯**和**闵可夫斯基**距离算法。'
- en: The **technical** indicator is one of the **specialty** methods in tabular augmentation.
    It uses technical analysis to help predict future price movements of securities
    or financial instruments. They are based on mathematical calculations of price,
    volume, and open interest.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术**指标是表格增强中的**专业**方法之一。它利用技术分析来帮助预测证券或金融工具的未来价格走势。这些指标基于价格、交易量和未平仓合约的数学计算。'
- en: The **genetic** method, or **genetic** tabular augmentation, is a type of ML
    technique that uses evolutionary algorithms to optimize the AI model. The concept
    is to create a population of candidate solutions, or **chromosomes**, for a problem,
    then evolve that population over time by applying genetic operations such as crossover,
    mutation, and selection. The goal is to find the best solution to the problem
    through natural selection.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遗传**方法，或**遗传**表格增强，是一种使用进化算法来优化AI模型的机器学习技术。其概念是为一个问题创建一群候选解，即**染色体**，然后通过应用交叉、变异和选择等遗传操作，随着时间的推移进化这些解的群体。目标是通过自然选择找到问题的最佳解决方案。'
- en: Fun challenge
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味挑战
- en: Pluto challenges you to implement two more interaction augmentations in the
    Python Notebook.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto挑战你在Python Notebook中实现更多的交互增强。
- en: The next tabular augmentation class is **mapping** augmentation. Pluto will
    describe the mapping functions but not implement them in the Python Notebook.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个表格增强类别是**映射**增强。Pluto 会描述映射函数，但不会在 Python Notebook 中实现它们。
- en: Mapping augmentation
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 映射增强
- en: The mapping method uses ML and data analysis to summarize and reduce the dimensionality
    of data for augmentation. It can be done via unsupervised or supervised learning.
    Some examples of mapping methods include **eigendecomposition** and PCA. PCA is
    a statistical procedure that transforms a set of correlated variables into uncorrelated
    variables called principal components.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 映射方法使用机器学习（ML）和数据分析来总结和减少数据的维度，以进行增强。可以通过无监督学习或监督学习来完成。一些映射方法的例子包括**特征分解**和
    PCA。PCA 是一种统计程序，它将一组相关变量转换为称为主成分的无关变量。
- en: 'In the DeltaPy library, there are seven mapping methods for tabular augmentation.
    Pluto has done a few implementations in the Python Notebook, but he will not explain
    the coding here. The Python wrapper function is repetitive and can easily be applied
    to any mapping method. The functions are as follows:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DeltaPy 库中，有七种映射方法用于表格增强。Pluto 在 Python Notebook 中做了一些实现，但他不会在这里解释代码。Python
    包装函数是重复的，可以很容易地应用于任何映射方法。函数如下：
- en: '**Eigendecomposition** (**ED**) is a form of **PCA** for tabular augmentation.
    In ED, the **eigenvectors** are the covariance matrix of the data, and the corresponding
    **eigenvalues** represent the amount of variance by each component. ED includes
    **linear discriminant analysis** (**LDA**), **singular value decomposition** (**SVD**),
    and **Markov chains**.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征分解**（**ED**）是用于表格增强的**PCA**的一种形式。在特征分解中，**特征向量**是数据的协方差矩阵，而相应的**特征值**表示每个组件的方差量。特征分解包括**线性判别分析**（**LDA**）、**奇异值分解**（**SVD**）和**马尔可夫链**。'
- en: '**Cross-decomposition** methods, including **canonical correlation analysis**
    (**CCA**), are used to uncover linear relationships between two pieces of multivariate
    tabular data. Various applications, such as dimensionality reduction, feature
    extraction, and feature selection, use the cross-decomposition method. The goal
    is to find a linear combination between tabular data variables.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交叉分解**方法，包括**典型相关分析**（**CCA**），用于揭示两块多变量表格数据之间的线性关系。各种应用，如降维、特征提取和特征选择，都使用交叉分解方法。目标是找到表格数据变量之间的线性组合。'
- en: '**Kernel approximation** methods are used in ML algorithms such as SVMs to
    transform the tabular data into a higher dimensional space where a linear boundary
    can be found to separate the classes. The **additive Chi2 kernel** is a specific
    **kernel approximation** method that measures the independence between two sets
    of variables.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**核近似**方法用于支持向量机（SVM）等机器学习算法，将表格数据转换到一个更高维的空间，在该空间中可以找到一个线性边界来分离不同的类别。**加性
    Chi2 核**是一种特定的**核近似**方法，用于衡量两个变量集之间的独立性。'
- en: '**Autoencoders** are used in various domains, such as image compression, anomaly
    detection, and for generating new data for tabular augmentation. We use autoencoders
    in the pre-training step for supervised learning tasks to improve the subsequent
    models’ performance.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自编码器**在多个领域中都有应用，例如图像压缩、异常检测，以及为表格增强生成新数据。我们在监督学习任务的预训练步骤中使用自编码器，以提高后续模型的性能。'
- en: '**Manifold learning** is a class of techniques for non-linear dimensionality
    reduction, aiming to preserve the tabular data’s underlying non-linear structure.
    **Locally linear embedding** (**LLE**) is one method in which the idea is to approximate
    the local linear relationships between data points in the high-dimensional space.
    The goal is to find a lower-dimensional representation of high-dimensional data
    that still captures the essential patterns and relationships in the tabular data.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流形学习**是一类用于非线性降维的技术，旨在保持表格数据的基本非线性结构。**局部线性嵌入**（**LLE**）是一种方法，其思想是近似高维空间中数据点之间的局部线性关系。目标是找到一个低维的高维数据表示，同时仍然捕捉到表格数据中的基本模式和关系。'
- en: '**Clustering** is a popular unsupervised ML technique for grouping similar
    tabular data points into clusters. Clustering methods help in identifying patterns
    and structure in tabular data.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**是一种流行的无监督机器学习技术，用于将相似的表格数据点分组到聚类中。聚类方法有助于识别表格数据中的模式和结构。'
- en: '**Neighbouring** is the nearest neighbor method for supervised ML algorithms
    for classification and regression problems. It also is used in tabular augmentation.
    You can extend the nearest neighbor method to a more sophisticated version called
    **k-nearest neighbor** (**k-NN**) classification.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**邻近**是用于分类和回归问题的监督式机器学习算法的最近邻方法，也用于表格增强。你还可以将最近邻方法扩展为更复杂的版本，称为**k-最近邻**（**k-NN**）分类。'
- en: The next classification of tabular augmentation we’ll look at is **extraction**
    augmentation.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们要看的表格增强分类是**提取**增强。
- en: Extraction augmentation
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取增强
- en: The extraction method is a process in time series analysis where multiple constructed
    elements are used as input, and a singular value is extracted from each time series
    to create new augmented data. This method uses a package called **TSfresh** and
    includes default and custom features. The output of extraction methods differs
    from the output of transformation and interaction methods, as the latter outputs
    entirely new time series data. You can use this method when specific values need
    to be pulled from time series data.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 提取方法是时间序列分析中的一种过程，其中多个构建的元素作为输入，每个时间序列从中提取一个单一的值，进而创建新的增强数据。此方法使用名为**TSfresh**的包，包含默认和自定义特征。提取方法的输出与转换和交互方法的输出不同，后者输出的是完全新的时间序列数据。当需要从时间序列数据中提取特定值时，可以使用此方法。
- en: The DeltaPy library contains 34 extraction methods. Writing the wrapper functions
    for extraction is similar to the wrapper transformation functions. The difficulty
    is how to discern the forecasting’s effectiveness from tabular augmentation. Furthermore,
    these methods are components and not complete functions for tabular augmentation.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: DeltaPy 库包含 34 种提取方法。编写提取的包装函数与包装转换函数相似。难点在于如何区分预测的有效性与表格增强之间的差异。此外，这些方法是组件，而不是完整的表格增强函数。
- en: 'Pluto will not explain each function, but here is a list of the extraction
    functions in the DeltaPy library: `Amplitude`, `Averages`, `Autocorrelation`,
    `Count`, `Crossings`, `Density`, `Differencing`, `Derivative`, `Distance`, `Distribution`,
    `Energy`, `Entropy`, `Exponent`, `Fixed Points`, `Fluctuation`, `Fractals`, `Information`,
    `Linearity`, `Location`, `Model` `Coefficients`, `Non-linearity`, `Occurrence`,
    `Peaks`, `Percentile`, `Probability`, `Quantile`, `Range`, `Shape`, `Size`, `Spectral`
    `Analysis`, `Stochasticity`, `Streaks`, `Structural`, `and` `Volatility`.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 不会解释每个函数，但以下是 DeltaPy 库中提取函数的列表：`Amplitude`、`Averages`、`Autocorrelation`、`Count`、`Crossings`、`Density`、`Differencing`、`Derivative`、`Distance`、`Distribution`、`Energy`、`Entropy`、`Exponent`、`Fixed
    Points`、`Fluctuation`、`Fractals`、`Information`、`Linearity`、`Location`、`Model`
    `Coefficients`、`Non-linearity`、`Occurrence`、`Peaks`、`Percentile`、`Probability`、`Quantile`、`Range`、`Shape`、`Size`、`Spectral`
    `Analysis`、`Stochasticity`、`Streaks`、`Structural` 和 `Volatility`。
- en: The extraction method is the last tabular augmentation category. Thus, it is
    time for a summary.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 提取方法是最后一个表格增强类别。因此，现在是时候做一个总结了。
- en: Summary
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Tabular augmentation is a technique that can improve the accuracy of ML models
    by increasing the amount of data used. It adds columns or rows to a dataset generated
    by existing features or data from other sources. It increases the available input
    data, allowing the model to make more accurate predictions. Tabular augmentation
    adds new information not currently included in the dataset, increasing the model’s
    utility. Tabular augmentation is beneficial when used with other ML techniques,
    such as DL, to improve the accuracy and performance of predictive models.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 表格增强是一种通过增加使用的数据量来提高机器学习模型准确性的技术。它通过现有特征或来自其他来源的数据，向数据集添加列或行。它增加了可用的输入数据，使得模型能够做出更准确的预测。表格增强增加了当前数据集中未包含的新信息，增强了模型的实用性。当与其他机器学习技术（如深度学习）结合使用时，表格增强有助于提高预测模型的准确性和性能。
- en: Pluto downloaded the real-world Bank Fraud and World Series datasets from the
    *Kaggle* website. He wrote most of the code in the Python Notebook for visualizing
    large datasets using various graphs, such as histograms, heatmaps, correlograms,
    and waffle and joy plots. He did this because understanding the datasets is essential
    before augmenting them. However, he didn’t write a CNN or RNN model to verify
    the augmentation methods because building a CNN model is a complex process worthy
    of a separate book.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto从*Kaggle*网站下载了真实世界的银行欺诈和世界系列数据集。他在Python Notebook中编写了大部分代码，用于通过各种图表（如直方图、热图、相关图、华夫图和快乐图）可视化大型数据集。他之所以这样做，是因为在进行数据增强之前，理解数据集至关重要。然而，他并没有编写CNN或RNN模型来验证增强方法，因为构建CNN模型是一个复杂的过程，值得写成一本独立的书籍。
- en: The DeltaPy open source library contains dozens of methods for tabular augmentation,
    but it is a beta version and can be unstable to load. Still, Pluto demonstrated
    a few tabular augmentation techniques, such as the robust scaler, standard scaler,
    capping, regression, and operator methods.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: DeltaPy开源库包含了数十种表格数据增强方法，但它是一个测试版，加载时可能不稳定。不过，Pluto演示了一些表格数据增强技术，比如鲁棒缩放器、标准缩放器、截断、回归和操作符方法。
- en: Throughout this chapter, there were *fun facts* and *fun challenges*. Pluto
    hopes you will take advantage of these and expand your experience beyond this
    book’s scope.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，有*有趣的事实*和*有趣的挑战*。Pluto希望你能够利用这些内容，将你的经验扩展到本书的范围之外。
- en: This is the last chapter of the book. You and Pluto have covered augmentation
    techniques for image, text, audio, and tabular data. As AI and generative AI continue
    to expand and integrate into the fabric of our life, data will play an essential
    role. Data augmentation methods are the best practical option to extend your datasets
    without the high cost of gathering and purchasing additional data. Furthermore,
    generative AI transforms how we work and play, such as OpenAI's GPT3, GPT4, Google
    Bard, and Stability.ai's Stable Diffusion. What you discussed about AI in boardrooms
    or classrooms last month will be outdated, but the data augmentation concepts
    and techniques remain the same.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本书的最后一章。你和Pluto已经涵盖了图像、文本、音频和表格数据的增强技术。随着人工智能和生成式人工智能继续扩展并融入我们的生活，数据将扮演着至关重要的角色。数据增强方法是扩展数据集的最佳实用选择，而不需要高成本地收集或购买额外的数据。此外，生成式人工智能正在改变我们的工作和娱乐方式，例如OpenAI的GPT3、GPT4、Google
    Bard和Stability.ai的Stable Diffusion。你上个月在会议室或课堂上讨论的关于人工智能的内容可能会过时，但数据增强的概念和技术依然不变。
- en: You and Pluto have learned to code the augmentation techniques using wrapper
    functions and download real-world datasets from the Kaggle website. As new, better,
    and faster augmentation libraries are available, you can add to your collection
    or switch the libraries under the hood. What you implement may change slightly,
    but what you have learned about data augmentation will remain true.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 你和Pluto已经学会了使用包装函数编码数据增强技术，并从Kaggle网站下载真实世界的数据集。随着新的、更好、更快的增强库的出现，你可以将它们添加到你的工具集，或者更换背后的库。你实现的内容可能会略有变化，但你对数据增强的理解将保持不变。
- en: I hope you enjoyed reading the book and hacking the Python Notebook as much
    as I enjoyed writing it. Thank you.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你和我一样，享受了阅读本书和操作Python Notebook的过程。谢谢你。
