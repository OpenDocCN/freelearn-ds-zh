- en: I/Os of Different Data Formats with pandas
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同数据格式的 I/O 操作与 pandas
- en: 'A data scientist has to work on data that comes from a variety of sources and
    hence in a variety of formats. The most common are the ubiquitous spreadsheets,
    Excel sheets, and `CSV` and text files. But there are many others, such as `URL`, `API`, `JSON`, `XML`, `HDF`, `Feather` and
    so on, depending on where it is being accessed. In this chapter, we will cover
    the following topics among others:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家需要处理来自各种来源的数据，因此数据格式也各异。最常见的格式是无处不在的电子表格、Excel 表格、`CSV` 和文本文件。但也有许多其他格式，如
    `URL`、`API`、`JSON`、`XML`、`HDF`、`Feather` 等，具体取决于数据访问的方式。本章我们将涉及以下几个主题：
- en: Data sources and pandas methods
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据源和 pandas 方法
- en: CSV and TXT
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CSV 和 TXT
- en: URL and S3
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: URL 和 S3
- en: JSON
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JSON
- en: Reading HDF formats
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取 HDF 格式
- en: Let's get started!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧！
- en: Data sources and pandas methods
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据源和 pandas 方法
- en: 'The data sources for a data science project can be clubbed into the following
    categories:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学项目的数据源可以分为以下几类：
- en: '**Databases**: Most of the CRM, ERP, and other business operations tools store
    data in a database. Depending on the volume, velocity, and variety, it can be
    a traditional or NoSQL database. To connect to most of the popular databases,
    we need `JDBC/ODBC` drivers from Python. Fortunately, there are such drivers available
    for all the popular databases. Working with data in such databases involves making
    a connection through Python to these databases, querying the data through Python,
    and then manipulating it using pandas. We will look at an example of how to do
    this later in this chapter.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库**：大多数 CRM、ERP 及其他业务操作工具都将数据存储在数据库中。根据数据的体积、速度和种类，可能是传统的数据库或 NoSQL 数据库。为了连接到大多数流行的数据库，我们需要
    Python 的 `JDBC/ODBC` 驱动程序。幸运的是，所有流行数据库的驱动程序都有提供。使用这些数据库中的数据需要通过 Python 连接到数据库，通过
    Python 查询数据，然后使用 pandas 进行数据操作。我们将在本章后面查看如何实现这一过程的示例。'
- en: '**Web services**: Many of the business operations tools, especially **Software
    as a Services** (**SaaS**) tools, make their data accessible through **Application
    Programming Interfaces** (**APIs**) instead of a database. This reduces the infrastructure
    cost of hosting a database permanently. Instead, data is made available as a service,
    as and when required. An `API` call can be made through Python, which returns
    packets of data in formats such as `JSON` or `XML`. This data is parsed and then
    manipulated using pandas for further usage.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Web 服务**：许多业务操作工具，尤其是 **软件即服务**（**SaaS**）工具，通过 **应用程序编程接口**（**API**）而非数据库提供其数据访问。这减少了永久托管数据库的基础设施成本。相反，数据作为服务按需提供。可以通过
    Python 发起 `API` 调用，返回格式为 `JSON` 或 `XML` 的数据包。然后解析这些数据并使用 pandas 进行进一步处理。'
- en: '**Data files**: A lot of data for prototyping data science models comes as
    data files. One example of data being stored as a physical file is the data from
    IoT sensors – more often than not, the data from these sensors is stored in a
    flat file, a `.txt` file, or a `.csv` file. Another source for a data file is
    the sample data that''s been extracted from a database and stored in such files.
    The output of many data science and machine learning algorithms are also stored
    in such files, such as CSV, Excel, and `.txt` files. Another example is that the
    trained weight matrices of a deep learning neural network model can be stored
    as an HDF file.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据文件**：许多用于原型数据科学模型的数据以数据文件的形式存在。一个例子是来自物联网传感器的数据——这些传感器的数据通常存储在平面文件中，如 `.txt`
    文件或 `.csv` 文件。另一个数据文件来源是从数据库中提取并存储在这些文件中的示例数据。许多数据科学和机器学习算法的输出也存储在此类文件中，如 CSV、Excel
    和 `.txt` 文件。另一个例子是深度学习神经网络模型的训练权重矩阵，可以存储为 HDF 文件。'
- en: '**Web and document scraping**: Two other sources of data are the tables and
    text present on web pages. This data is gleaned from these pages using Python
    packages such as BeautifulSoup and Scrapy and are put into a data file or database
    to be used further. The tables and data that are present in another non-data format
    file, such as PDF or Docs, are also a major source of data. This is then extracted
    using Python packages such as Tesseract and Tabula-py.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网页和文档抓取**：另一个数据来源是网页上存在的表格和文本。通过使用如 BeautifulSoup 和 Scrapy 等 Python 包，从这些页面中提取数据，并将其放入数据文件或数据库中以供进一步使用。存在于其他非数据格式文件中的表格和数据，如
    PDF 或 Docs，也是一个重要的数据来源。这些数据通过如 Tesseract 和 Tabula-py 等 Python 包进行提取。'
- en: In this chapter, we will look at how to read and write data to and from these
    formats/sources using pandas and ancillary libraries. We will also discuss a little
    bit about these formats, their utilities, and various operations that can be performed
    on them.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究如何使用pandas和附属库读取和写入这些格式/源的数据。我们还将讨论这些格式的简要介绍，它们的用途以及可以对它们执行的各种操作。
- en: 'The following is a summary of the read and write methods in Python for some
    of the data formats we are going to discuss in this chapter:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是Python中用于读取和写入某些数据格式的方法总结，这些格式将在本章中讨论：
- en: '![](img/8abf637c-9d15-45c5-b8e7-fdef295dd9d5.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8abf637c-9d15-45c5-b8e7-fdef295dd9d5.png)'
- en: Reader and writer methods in pandas for different types of data file formats
    and their sources
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: pandas中用于不同数据文件格式的读取和写入方法及其来源
- en: The section headers mean that we are dealing with I/O operations of that file
    type in that section.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些部分标题意味着我们正在处理该文件类型的I/O操作。
- en: CSV and TXT
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CSV和TXT
- en: CSV stands for comma-separated values, which means that the comma is the default
    delimiter for these files. However, they accept other delimiters as well.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: CSV代表逗号分隔值，意味着逗号是这些文件的默认分隔符。然而，它们也接受其他分隔符。
- en: CSVs are made of columns and rows and the cell value is arranged in a tabular
    format. They can come with or without column names and row indices. The primary
    reasons for a CSV file's existence include manually gathered data, data that's
    been extracted and downloaded from a database, a direct download from a tool or
    website, web scraping, and the result of running a data science algorithm.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: CSV由列和行组成，单元格值以表格形式排列。它们可以带有或不带有列名和行索引。CSV文件存在的主要原因包括手动收集的数据、从数据库中提取并下载的数据、从工具或网站直接下载的数据、网页抓取的数据以及运行数据科学算法的结果。
- en: Reading CSV and TXT files
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取CSV和TXT文件
- en: '`read_csv` is the go-to method for reading CSV files in `pandas`. It can also
    be used to read `txt` files. The syntax of using `read_csv` is shown in the following
    code:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_csv`是pandas中读取CSV文件的首选方法。它也可以用来读取`txt`文件。使用`read_csv`的语法如下：'
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The parameters of the `read_csv` method are as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_csv`方法的参数如下：'
- en: '`filepath`: A string or filename with or without a filepath.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filepath`: 字符串或带有或不带有文件路径的文件名。'
- en: '`dtype`: Can be passed as a dictionary containing name and type as a key-value
    pair. Specifies the data type of the column name. Generally, pandas guesses the
    type of columns based on the first few rows.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype`: 可以作为字典传递，字典包含名称和类型的键值对。指定列名的数据类型。通常，pandas会根据前几行来猜测列的类型。'
- en: '`header`: True/False. This specifies whether the first row in the data is a
    header or not.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`header`: True/False。指定数据的第一行是否为标题。'
- en: '`names`: List. Specifies column names for all the columns of a dataset.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`names`: 列表。指定数据集所有列的列名。'
- en: '`skiprows`: List. Skip certain rows of data by specifying row indices.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skiprows`: 列表。通过指定行索引跳过某些数据行。'
- en: '`index_col`: Series/List. Specifies the column that can work as a row number/identifier.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`index_col`: Series/列表。指定可以作为行号/标识符的列。'
- en: '`skip_blank_lines`: True/False. Specifies whether to skip blank lines or not.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_blank_lines`: True/False。指定是否跳过空行。'
- en: '`na_filter`: True/False. Specifies whether to filter NA values or not.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`na_filter`: True/False。指定是否过滤NA值。'
- en: '`usecols`: List. Returns the subset of data with columns in the passed list.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`usecols`: 列表。返回传递列表中的列的数据子集。'
- en: The `read_csv` method returns a DataFrame. The following are some examples of
    reading files using the `read_csv` method.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_csv`方法返回一个DataFrame。以下是使用`read_csv`方法读取文件的一些示例。'
- en: Reading a CSV file
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取CSV文件
- en: 'We can read a CSV file by using the following code:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码读取CSV文件：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Specifying column names for a dataset
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为数据集指定列名
- en: 'The following code will specify the column names for a dataset:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将指定数据集的列名：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that the column names are read from a file and then converted into a list
    to be passed to the names parameter in `read_csv`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，列名是从文件中读取的，然后转换成列表，并传递给`read_csv`中的names参数。
- en: Reading from a string of data
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据字符串中读取
- en: 'Here''s how we can use `read_csv` to create a DataFrame from a list of strings:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们如何使用`read_csv`从字符串列表创建一个DataFrame：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Skipping certain rows
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跳过某些行
- en: 'We can also skip certain rows. Let''s say that we only want the rows whose
    indices are multiples of 3:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以跳过某些行。假设我们只想要索引是3的倍数的行：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We get the following output:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/7e5b5fa6-3e3b-4995-a8db-66caaf0727eb.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7e5b5fa6-3e3b-4995-a8db-66caaf0727eb.png)'
- en: Demonstration of using the skiprows parameter in read_csv. The right-hand panel
    shows the data that's been filtered through skiprows (keeping only rows with row
    numbers that are multiples of 3)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 演示如何在`read_csv`中使用`skiprows`参数。右侧面板显示了通过`skiprows`筛选的数据（仅保留行号是3的倍数的行）
- en: The left-hand side diagram shows the resultant DataFrame without skipping any
    row, while the right-hand side shows the same DataFrame after filtering the rows
    whose indices are not multiples of 3\. Note that this method considers the real
    index (3rd and 6th from the top, starting from 1) and not the Python index (starting
    from 0) for filtering the rows based on their index.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧图示显示了结果 DataFrame，没有跳过任何行，而右侧图示显示了过滤掉行索引不是3的倍数的同一 DataFrame。注意，这种方法是根据实际索引（从1开始的第3行和第6行）来过滤行，而不是根据
    Python 索引（从0开始）。
- en: Row index
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行索引
- en: 'If a file has one more column of data than the number of column names, the
    first column will be used as the DataFrame''s row names:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果文件的列数比列名的数量多一列数据，第一列将作为 DataFrame 的行名：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We get the following output:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/8e787128-6e43-4df6-a46d-728f1e129fb9.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8e787128-6e43-4df6-a46d-728f1e129fb9.png)'
- en: The column with values but no corresponding column name is used as a row index.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 具有值但没有对应列名的列被用作行索引。
- en: Reading a text file
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读文本文件
- en: '`read_csv` can help read text files as well. Often, data is stored in `.txt`
    files with different kinds of delimiters. The `sep` parameter can be used to specify
    the delimiter of a particular file, as shown in the following code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_csv`也可以帮助读取文本文件。通常，数据存储在具有不同分隔符的`.txt`文件中。`sep`参数可用于指定特定文件的分隔符，如以下代码所示：'
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The preceding file has `Tab` as a delimiter, which is specified using the `sep`
    parameter.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 上述文件的分隔符为`Tab`，通过`sep`参数指定。
- en: Subsetting while reading
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读时的子集化
- en: 'Only a selected list of columns can be subsetted and loaded using the `usecols`
    parameter while reading:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在读取时，可以使用`usecols`参数仅选择部分列进行子集化和加载：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Numeric lists, as well as explicit lists with column names, can be used. Numeric
    indexing follows Python indexing, that is, starting from 0.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 数字列表以及带有列名的显式列表都可以使用。数字索引遵循 Python 索引规则，即从0开始。
- en: Reading thousand format numbers as numbers
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将千位格式的数字作为数字读取
- en: 'If a dataset contains a numeric column that has thousand numbers formatted
    by a comma or any other delimiter, the default data type for such a column is
    a string or object. The problem is that it is actually a numeric field and it
    needs to be read as a numeric field to be used further:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集中包含一个数字列，该列的千位数字以逗号或其他分隔符格式化，那么该列的默认数据类型将是字符串或对象。问题是它实际上是一个数字字段，需要作为数字字段进行读取，以便进一步使用：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We get the following output:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/a1ae239f-3e96-45a6-85a3-47f6f43ba54d.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1ae239f-3e96-45a6-85a3-47f6f43ba54d.png)'
- en: Data with a level column with thousand format numbers
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 带有千位格式数字的列数据
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To overcome this problem, the `thousands` parameter can be used while reading:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这个问题，可以在读取时使用`thousands`参数：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Indexing and multi-indexing
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 索引和多重索引
- en: '`index_col` can be used to specify one column to provide row indices. A list
    of columns can be passed as indices, which leads to multi-indexing. Let''s look
    at an example:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`index_col`可用于指定某一列作为行索引。可以传递列的列表作为索引，这将导致多重索引。我们来看一个例子：'
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Take a look at the following screenshot:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 请看下面的截图：
- en: '![](img/c22b0911-c5a3-40af-9b87-92c6b3161b6d.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c22b0911-c5a3-40af-9b87-92c6b3161b6d.png)'
- en: Single index (left) and multi-index (right) on the same data
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 单一索引（左）和多重索引（右）在同一数据上的应用
- en: 'This kind of multi-indexing makes it easy to subset based on either an index
    or both:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这种多重索引使得基于某一索引或两个索引进行子集化变得容易：
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We get the following output:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/4752a1fa-6e39-4f44-80b3-529f1880ba9e.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4752a1fa-6e39-4f44-80b3-529f1880ba9e.png)'
- en: Subsetting multi-indexed data using one index (left) and both indices (right)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单一索引（左）和两个索引（右）对子集化多重索引数据
- en: Reading large files in chunks
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分块读取大文件
- en: Reading a large file in memory at once may consume the entire RAM of the computer
    and may cause it to throw an error. In such cases, it becomes pertinent to divide
    the data into chunks. These chunks can then be read sequentially and processed.
    This is achieved by using the `chunksize` parameter in `read_csv`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一次性将大文件读取到内存中可能会占用整个计算机的内存，并可能导致错误。在这种情况下，按块划分数据变得尤为重要。这些数据块可以按顺序读取并处理。通过使用`chunksize`参数，在`read_csv`中实现了这一点。
- en: 'The resulting chunks can be iterated over using a for loop. In the following
    code, we are printing the shape of the chunks:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的块可以通过 `for` 循环进行迭代。在以下代码中，我们正在打印块的形状：
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'These chunks can then be concatenated to each other using the `concat` method:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，这些块可以使用 `concat` 方法连接在一起：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Handling delimiter characters in column data
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理列数据中的分隔符字符
- en: Sometimes, a column separate character is present as part of the data in one
    of the columns. This leads to incorrectly parsing data as this would split the
    column that was supposed to be read as one into two. To avoid such a situation,
    a quote character should be used around the data in the specified columns. This
    quote character forces `read_csv` to ignore the delimiter for the data that's
    present inside the quote character and not break it into two pieces.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，列分隔符字符作为数据的一部分出现在某一列中。这会导致数据解析错误，因为它会将本应作为一个读取的列分割成两个。为了避免这种情况，应该在指定的列数据周围使用引号字符。这个引号字符强制
    `read_csv` 忽略数据中引号字符内的分隔符，并且不将其分成两部分。
- en: 'The quote characters can be specified using the `quotechar` argument of `read_csv`.
    For example, consider the following dataset. Here, white space is used as a delimiter
    and double quotes have been used as a grouping element:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过 `read_csv` 的 `quotechar` 参数指定引号字符。例如，考虑以下数据集。在这里，使用空格作为分隔符，并使用双引号作为分组元素：
- en: '![](img/c343c737-1b11-46a8-9dd4-f8dbb4d2f424.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c343c737-1b11-46a8-9dd4-f8dbb4d2f424.png)'
- en: Usage of quotechar keyword 1—input dataset
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `quotechar` 关键字 1——输入数据集
- en: 'To parse this, we would use the following code:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要解析此数据，我们可以使用以下代码：
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We would get the following output:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到以下输出：
- en: '![](img/5e92e0f9-5111-4605-bc3a-9110692a106d.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5e92e0f9-5111-4605-bc3a-9110692a106d.png)'
- en: Usage of quotechar keyword 2—output dataset
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `quotechar` 关键字 2——输出数据集
- en: Writing to a CSV
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 写入 CSV
- en: A DataFrame is an in-memory object. Often, DataFrames need to be saved as physical
    files for later use. In such cases, the DataFrames can be written as a `CSV` or `TXT` file.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 是内存中的对象。通常，DataFrame 需要保存为物理文件以便后续使用。在这种情况下，DataFrame 可以写入为 `CSV`
    或 `TXT` 文件。
- en: 'Let''s create a synthesized DataFrame using random numbers:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用随机数创建一个合成的 DataFrame：
- en: '[PRE16]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This can be written to a `.csv` or `.txt` file using the `to_csv` method, as
    shown in the following code:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过 `to_csv` 方法写入 `.csv` 或 `.txt` 文件，如以下代码所示：
- en: '[PRE17]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: These files would be written to the current working directory.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这些文件将被写入当前工作目录。
- en: 'A delimiter of choice can be provided while writing to a file:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 写入文件时可以提供自定义的分隔符：
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'There are many other useful options available, such as the following:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他有用的选项，如下所示：
- en: '`index`: True/False. Indicates whether we should have row indices or not.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`index`: True/False。指示是否需要行索引。'
- en: '`index_label`: String/Column name. Column to be used as a row index.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`index_label`: 字符串/列名。用作行索引的列。'
- en: '`header`: True/False. Specifies whether to write the column names.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`header`: True/False。指定是否写入列名。'
- en: '`na_rep`: String. A string representation for missing values.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`na_rep`: 字符串。缺失值的字符串表示。'
- en: Excel
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Excel
- en: Excel files are similar to `CSV` files but are different in the sense that they
    can have multiple sheets, formatted data and tables, charts, and formulas. In
    many cases, reading data from Excel files is required.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Excel 文件与 `CSV` 文件相似，但不同之处在于它们可以包含多个工作表、格式化的数据和表格、图表以及公式。在许多情况下，需要从 Excel 文件中读取数据。
- en: '`xlrd` is the package of choice while working with Excel sheets. Some of the
    major functionalities of the `xlrd` package are summarized in the following table:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`xlrd` 是处理 Excel 工作表时首选的包。`xlrd` 包的一些主要功能总结在下表中：'
- en: '| **Code snippet** | **Goal achieved** |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| **代码片段** | **目标达成** |'
- en: '| `import xlrd` | Importing the xlrd library |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `import xlrd` | 导入 xlrd 库 |'
- en: '| `book=xlrd.open_workbook(''SRS Career.xlsx'')` | Reading the Excel workbook
    |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `book=xlrd.open_workbook(''SRS Career.xlsx'')` | 读取 Excel 工作簿 |'
- en: '| `n=book.nsheets` | Finding the number of sheets in a workbook |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `n=book.nsheets` | 查找工作簿中的工作表数量 |'
- en: '| `book.sheet_names()` | Finding the names of sheets in a workbook |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| `book.sheet_names()` | 查找工作簿中工作表的名称 |'
- en: '| `last_sheet=book.sheet_by_index(n-1)` | Reading the sheets by sheet index
    |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| `last_sheet=book.sheet_by_index(n-1)` | 通过工作表索引读取工作表 |'
- en: '| `last_sheet.row_values(0)` | Getting the first row of a sheet |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| `last_sheet.row_values(0)` | 获取工作表的第一行 |'
- en: '| `last_sheet.cell(0,0)` | Getting the first cell of the sheet |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `last_sheet.cell(0,0)` | 获取工作表的第一个单元格 |'
- en: '| `last_sheet.row_slice(rowx=0,start_colx=1,end_colx=5)` | Getting the 1^(st)
    to the 5^(th) columns of the first row |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `last_sheet.row_slice(rowx=0,start_colx=1,end_colx=5)` | 获取第一行的第 1 列到第 5
    列 |'
- en: URL and S3
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: URL 和 S3
- en: 'Sometimes, the data is directly available as a URL. In such cases, `read_csv`
    can be directly used to read from these URLs:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，数据可以直接通过 URL 获取。在这种情况下，可以直接使用 `read_csv` 从这些 URL 中读取数据：
- en: '[PRE19]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Alternatively, to work with URLs in order to get data, we can use a couple
    of Python packages that we haven''t used so far, such as `.csv` and `.urllib`.
    It would suffice to know that `.csv` provides a range of methods for handling `.csv`
    files and that `urllib` is used to navigate to and access information from the
    URL. Here is how we can do this:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，为了通过 URL 获取数据，我们可以使用一些尚未使用的 Python 包，如 `.csv` 和 `.urllib`。只需知道 `.csv` 提供了一系列处理
    `.csv` 文件的方法，而 `urllib` 用于访问和获取 URL 中的信息即可。以下是实现方法：
- en: '[PRE20]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '`AWS S3` is a popular file-sharing and storage repository on the web. Many
    enterprises store their business operations data as files on S3, which needs to
    be read and processed directly or be moved to a database. Python allows us to
    directly read files from S3, as shown in the following code.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`AWS S3` 是一个流行的文件共享和存储库，许多企业将其业务运营数据以文件形式存储在 S3 上，这些数据需要直接读取和处理，或者被移入数据库。Python
    允许我们直接从 S3 读取文件，如下所示的代码所示：'
- en: 'Python 3.4 and above use the `s3fs` package in addition to pandas to read files
    directly from S3\. An AWS config file needs to be placed in the current working
    directory. The bucket name, as well as the path and filename, need to be passed
    for reading:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3.4 及以上版本在使用 pandas 之外，还需要使用 `s3fs` 包来直接从 S3 读取文件。AWS 配置文件需要放置在当前工作目录中。需要传入存储桶名称以及路径和文件名来进行读取：
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'A DataFrame can be written to a CSV file and saved directly in S3 as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将 DataFrame 写入 CSV 文件并直接保存在 S3 中，如下所示：
- en: '[PRE22]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: HTML
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTML
- en: 'HTML is the popular file format for creating and wrapping web elements and
    pages. Sometimes, tabular data is stored in a file. In such cases, the `read_html`
    method is directly used to read such data. This function parses table elements
    from HTML files and reads the tables as DataFrames:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: HTML 是一种流行的文件格式，用于创建和包装网页元素和页面。有时，表格数据会存储在文件中。在这种情况下，可以直接使用 `read_html` 方法读取这些数据。此功能解析
    HTML 文件中的表格元素，并将表格读取为 DataFrame：
- en: '[PRE23]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can find all of the table elements containing a particular match word by
    using the following code:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下代码查找包含特定匹配词的所有表格元素：
- en: '[PRE24]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'A DataFrame can be converted into an HTML table element so that it can be placed
    into an HTML file like so:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将 DataFrame 转换为 HTML 表格元素，以便将其嵌入 HTML 文件中，如下所示：
- en: '[PRE25]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We get the following output:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到如下输出：
- en: '![](img/99e747e1-7272-4977-8aad-2b2550d77cb7.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99e747e1-7272-4977-8aad-2b2550d77cb7.png)'
- en: HTML table element created from a DataFrame
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 从 DataFrame 创建的 HTML 表格元素
- en: 'A selected list of columns can be filtered and converted into HTML like so:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 可以选择性地筛选和转换某些列为 HTML，如下所示：
- en: '[PRE26]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Writing to an HTML file
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 写入 HTML 文件
- en: 'The HTML file can be saved as a physical file like so:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: HTML 文件可以保存为一个物理文件，如下所示：
- en: '[PRE27]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Take a look at the following screenshot:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下截图：
- en: '![](img/6f0d904f-7480-42a1-a071-7acbf2a42ad1.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f0d904f-7480-42a1-a071-7acbf2a42ad1.png)'
- en: Subsetting multi-indexed data using one index (left) and both indices (right)
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个索引（左）和两个索引（右）对子集化多重索引数据
- en: 'The row and column names are bold by default. This can be changed with the
    following code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，行和列的名称是粗体的。可以通过以下代码进行更改：
- en: '[PRE28]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: JSON
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JSON
- en: '`JSON` is a popular dictionary-like, key-value pair-based data structure that''s
    suitable for exposing data as APIs from SaaS tools. `address`, `postalCode`, `state`,
    `streetAddress`, `age`, `firstName`, `lastName`, and `phoneNumber` are keys whose
    values are shown to the right of them. `JSON` files can be nested (the values
    of a key are JSON) as well. Here, `address` has nested values:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`JSON` 是一种流行的字典型、基于键值对的数据结构，适用于从 SaaS 工具暴露数据为 API。`address`、`postalCode`、`state`、`streetAddress`、`age`、`firstName`、`lastName`
    和 `phoneNumber` 是键，它们的值显示在它们的右侧。`JSON` 文件也可以是嵌套的（键的值本身也是 JSON）。在这里，`address` 有嵌套值：'
- en: '![](img/b14ed272-db57-4fba-9a57-9c9cea728544.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b14ed272-db57-4fba-9a57-9c9cea728544.png)'
- en: Example of JSON data (dictionary; key-value pairs)
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 数据示例（字典；键值对）
- en: 'DataFrames can be converted into JSON using `to_json`:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 可以使用 `to_json` 转换为 JSON 格式：
- en: '[PRE29]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Take a look at the following screenshot:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下截图：
- en: '![](img/502b72f1-18c4-4307-ab86-8fd00f5b27d8.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/502b72f1-18c4-4307-ab86-8fd00f5b27d8.png)'
- en: Converting a DataFrame into JSON format
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrame 转换为 JSON 格式
- en: While converting the DataFrame into a JSON file, the orientation can be set.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在将 DataFrame 转换为 JSON 文件时，可以设置方向。
- en: 'If we want to keep the column name as the primary index and the row indices
    as the secondary index, then we can choose the orientation to be `columns`:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想保持列名作为主要索引，行索引作为次要索引，那么我们可以选择将方向设置为 `columns`：
- en: '[PRE30]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We receive the following output:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/016ceada-6767-443e-8442-efbebb525bb9.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/016ceada-6767-443e-8442-efbebb525bb9.png)'
- en: Converting a DataFrame into JSON with the column orientation
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个 DataFrame 转换为具有列方向的 JSON
- en: 'If we want to keep the row indices as the primary index and the column names
    as the secondary index, then we can choose the orientation to be `index`:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想保持行索引作为主要索引，列名作为次要索引，那么我们可以选择将方向设置为 `index`：
- en: '[PRE31]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We receive the following output:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/9f1817dc-3dee-4536-8d37-613c445ee872.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9f1817dc-3dee-4536-8d37-613c445ee872.png)'
- en: Converting a DataFrame into JSON with the index orientation
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个 DataFrame 转换为具有索引方向的 JSON
- en: 'Another option is to convert a DataFrame into an array of JSONs. This is useful
    while passing data to a visualization library, like so:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是将一个 DataFrame 转换为一个 JSON 数组。这在将数据传递给可视化库时非常有用，如下所示：
- en: '[PRE32]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We receive the following output:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/3f25c39c-f779-4804-8e0e-e03ee72f54ea.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f25c39c-f779-4804-8e0e-e03ee72f54ea.png)'
- en: Converting a DataFrame into JSON with the records orientation
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个 DataFrame 转换为具有记录方向的 JSON
- en: 'We can also contain the bare-bones values as a list of values, without any
    row or column index:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将纯值作为值的列表包含，而不需要任何行或列索引：
- en: '[PRE33]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We receive the following output:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/b3ea3f67-3fe1-4968-bfd3-302fcc8198d0.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b3ea3f67-3fe1-4968-bfd3-302fcc8198d0.png)'
- en: Converting a DataFrame into JSON with the values orientation
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个 DataFrame 转换为具有值方向的 JSON
- en: 'Finally, we can also orient the converted JSON in order to separate the row
    indices, column names, and data values:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还可以调整转换后的 JSON，以便分离行索引、列名和数据值：
- en: '[PRE34]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We receive the following output:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/69ac8ae1-0481-40fa-a39f-dcbc19b84268.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/69ac8ae1-0481-40fa-a39f-dcbc19b84268.png)'
- en: Converting a DataFrame into JSON with the split orientation
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个 DataFrame 转换为具有拆分方向的 JSON
- en: Writing a JSON to a file
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 JSON 写入文件
- en: 'JSON can be written to physical files like so:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 可以像这样写入物理文件：
- en: '[PRE35]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Reading a JSON
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取 JSON
- en: '`json_loads` is used to read a physical file containing JSONs:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`json_loads` 用于读取包含 JSON 的物理文件：'
- en: '[PRE36]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We get the following output:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/04b51282-c183-492b-a784-6eeeec586db7.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/04b51282-c183-492b-a784-6eeeec586db7.png)'
- en: First record in a list of JSONs
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 列表中的第一个记录
- en: 'The files can be read one JSON at a time using the `open` and `readline` methods:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 文件可以通过 `open` 和 `readline` 方法一次读取一个 JSON：
- en: '[PRE37]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, `records` contains a list of JSONs from which all the values of a particular
    key can be pulled out. For example, here, we are  pulling out all the `latlong`
    (`''ll''` column) wherever it has a non-zero value:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`records` 包含一个 JSON 列表，我们可以从中提取出某个特定键的所有值。例如，在这里，我们提取出所有具有非零值的 `latlong`（`'ll'`
    列）：
- en: '[PRE38]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Writing JSON to a DataFrame
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 JSON 写入 DataFrame
- en: 'A list of JSON objects can be converted into a DataFrame (much like a dictionary
    can). The records element we created previously is a list of JSONs (we can check
    this by using `records[0:3]` or `type(records)`):'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 JSON 对象列表可以转换为一个 DataFrame（就像字典一样）。我们之前创建的 `records` 元素是一个 JSON 列表（我们可以通过使用
    `records[0:3]` 或 `type(records)` 来检查）：
- en: '[PRE39]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: In the last line, we are trying to find the count of different time zones contained
    in the `'tz'` column.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一行，我们尝试查找 `'tz'` 列中包含的不同时区的数量。
- en: Subsetting a JSON
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对 JSON 进行子集筛选
- en: 'Let''s have a look at a new JSON file:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看一个新的 JSON 文件：
- en: '[PRE40]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We get the following output:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/2d6b3b39-b011-49be-a8ed-edfd9191c8e3.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2d6b3b39-b011-49be-a8ed-edfd9191c8e3.png)'
- en: Loading a JSON file with several degrees of nesting
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 加载一个具有多个嵌套层级的 JSON 文件
- en: This is a JSON with several degrees of nesting. The `hits` key contains a JSON
    as a value whose key value is `hits`. The value of this JSON is a list containing
    another JSON.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个具有多个嵌套层级的 JSON。`hits` 键包含一个值为 JSON 的键值对，其中该 JSON 的键值为 `hits`，该 JSON 的值是一个包含另一个
    JSON 的列表。
- en: 'Let''s say that we want to find out the score value from this JSON:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想从这个 JSON 中找出分数值：
- en: '[PRE41]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Similarly, the image URL can be found as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，图像 URL 可以如下找到：
- en: '[PRE42]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Looping over JSON keys
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遍历 JSON 键
- en: 'JSON data can be looped on its keys and values:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 可以遍历 JSON 数据的键和值：
- en: '[PRE43]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We receive the following output:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/5f5e5349-afc0-410e-845e-10fe1314ea0e.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f5e5349-afc0-410e-845e-10fe1314ea0e.png)'
- en: Printing keys of the loaded JSON by looping over the keys and values
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遍历键和值来打印加载的 JSON 的键
- en: We can print both the keys and values together as well.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将键和值一起打印出来。
- en: '[PRE44]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We receive the following output:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接收到以下输出：
- en: '![](img/bb4bd0e2-2b88-4120-a6e4-1bc8d5ef1f16.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bb4bd0e2-2b88-4120-a6e4-1bc8d5ef1f16.png)'
- en: Printing keys and values of the loaded JSON by looping over the keys and values
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遍历键和值来打印加载的 JSON 的键和值
- en: Now, we will look at how to use reading and writing operations with exotic file
    formats.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将学习如何使用读写操作处理不同的文件格式。
- en: Reading HDF formats
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取 HDF 格式
- en: The **Hierarchical Data Format** (**HDF**) is efficient in handling large and
    complex data models. The versatility and flexibility of HDF in data storage make
    it a sought after format for storing scientific data. In fact, HDF was selected
    as the standard data and information system by NASA, for use in the Earth Observing
    System. HDF5 is the current technological suite used by the HDF file format and
    replaced the older HDF4.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '**层次数据格式**（**HDF**）在处理大规模和复杂数据模型时非常高效。HDF 在数据存储中的多功能性和灵活性使其成为存储科学数据的热门格式。事实上，HDF
    被 NASA 选为地球观测系统中的标准数据与信息系统。HDF5 是当前由 HDF 文件格式使用的技术套件，并取代了较旧的 HDF4。'
- en: 'The following are some unique features of HDF5:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 HDF5 的一些独特功能：
- en: HDF5 has no set limits regarding file size and the objects in the file.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HDF5 对文件大小和文件中的对象没有设定限制。
- en: HDF5 can group and link objects in the file, thereby facilitating as a supportive
    mechanism for complex relationships and dependencies in data.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HDF5 可以对文件中的对象进行分组和链接，从而为数据中的复杂关系和依赖提供支持机制。
- en: HDF5 also supports metadata.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HDF5 还支持元数据。
- en: While accommodating a variety of predefined and user-defined data types, HDF5
    also has the ability to store and share data type descriptions in HDF files.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HDF5 在支持多种预定义和用户定义的数据类型的同时，还能够在 HDF 文件中存储和共享数据类型描述。
- en: For efficiency in the data transfer process, HDF5 incorporates Standard (Posix),
    Parallel, and Network I/O file drivers. Additional file drivers can also be developed
    and integrated with HDF5 for any custom data transfer and storage requirements.
    HDF5 makes data storage more optimized through techniques such as compression,
    extensibility, and chunking. Being able to perform data transformations, make
    changes to data types, and select subsets of data during data transfer makes the
    reading and writing processes efficient.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高数据传输过程的效率，HDF5 集成了标准（Posix）、并行和网络 I/O 文件驱动程序。还可以开发并将其他文件驱动程序与 HDF5 集成，以满足任何自定义的数据传输和存储需求。HDF5
    通过压缩、可扩展性和分块等技术优化了数据存储。能够在数据传输过程中执行数据转换、修改数据类型以及选择数据子集，使得读写过程更加高效。
- en: 'Now, let''s read an HDF file using pandas:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 pandas 读取一个 HDF 文件：
- en: '[PRE45]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We receive the following output:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接收到以下输出：
- en: '![](img/d925a312-cffd-4dd2-8e60-44d2d1fad99c.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d925a312-cffd-4dd2-8e60-44d2d1fad99c.png)'
- en: Output of read_hdf
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: read_hdf 的输出
- en: 'A subset of the data could be extracted during the reading process using the
    index argument:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在读取过程中，可以通过索引参数提取数据的一个子集：
- en: '[PRE46]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We receive the following output:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接收到以下输出：
- en: '![](img/743debf2-53b8-4f10-b761-dada60221e07.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](img/743debf2-53b8-4f10-b761-dada60221e07.png)'
- en: Output of read_hdf with indexing
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 带索引的 read_hdf 输出
- en: Reading feather files
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取 Feather 文件
- en: The feather format is a binary file format for storing data that makes use of
    Apache Arrow, an in-memory columnar data structure. It was developed by Wes Mckinney
    and Hadley Wickham, chief scientists at RStudio as an initiative for a data sharing
    infrastructure across Python and R. The columnar serialization of data in feather
    files makes way for efficient read and write operations, making it far faster
    than CSV and JSON files where storage is record-wise.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: Feather 格式是一种二进制文件格式，用于存储数据，采用 Apache Arrow 作为内存中的列式数据结构。它由 RStudio 的首席科学家 Wes
    Mckinney 和 Hadley Wickham 开发，旨在为 Python 和 R 之间的数据共享基础设施提供支持。Feather 文件中数据的列式序列化使得读写操作更加高效，比存储按记录方式排列的
    CSV 和 JSON 文件要快得多。
- en: 'Feather files have the following features:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: Feather 文件具有以下特点：
- en: Fast I/O operations.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速的输入/输出操作。
- en: Feather files can be read and written in languages other than R or Python, such
    as Julia and Scala.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feather 文件可以在除 R 或 Python 之外的其他语言中进行读写，例如 Julia 和 Scala。
- en: They have compatibility with all pandas datatypes, such as Datetime and Categorical.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们与所有 pandas 数据类型兼容，例如 Datetime 和 Categorical。
- en: 'Feather currently supports the following datatypes:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Feather 当前支持以下数据类型：
- en: All numeric datatypes
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有数值数据类型
- en: Logical
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑数据
- en: Timestamps
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间戳
- en: Categorical
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类数据
- en: UTF-8 encoded strings
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UTF-8 编码的字符串
- en: Binary
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二进制
- en: 'Since feather is merely a simplistic version of Arrow, it has several caveats
    associated with it. The following are some limitations of using a feather file:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 feather 只是 Arrow 的简化版，它有一些相关的限制。以下是使用 feather 文件的一些限制：
- en: Not recommended for long-term data storage as their stability between versions
    cannot be guaranteed.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不推荐用于长期数据存储，因为它们在版本之间的稳定性无法保证。
- en: Any index or multi-index, other than the default indexing scheme, is not supported
    in Feather format.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feather 格式不支持任何非默认索引或多重索引。
- en: Python data types such as Period are not supported.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 数据类型如 Period 不被支持。
- en: Duplicates in column names are not supported.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不支持列名重复。
- en: 'Reading a feather file in pandas is done like so:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 中读取 feather 文件的方法如下：
- en: '[PRE47]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'This results in the following output:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/b96d3b4f-a50f-4a52-91c6-a4165aaf499b.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b96d3b4f-a50f-4a52-91c6-a4165aaf499b.png)'
- en: Output of read_feather
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: read_feather 输出
- en: Reading parquet files
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取 parquet 文件
- en: Apache Parquet is another file format that makes use of columnar compression
    for efficient read and write operations. It was designed to be compatible with
    big data ecosystems such as Hadoop and can handle nested data structures and sparsely
    populated columns. Though the parquet and feather formats share a similar base,
    parquet has a better compression routine than feather. The compressed file is
    smaller in parquet than it is in feather. Columns with similar data types use
    the same encoding for compression. The use of different encoding schemes for the
    compression of parquet makes it efficient. Just like feather, parquet is a binary
    file format that can work well with all pandas data types and is supported across
    several languages. Parquet can be used for the long-term storage of data.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Parquet 是另一种文件格式，利用列式压缩进行高效的读写操作。它设计上与 Hadoop 等大数据生态系统兼容，并能处理嵌套数据结构和稀疏列。虽然
    parquet 和 feather 格式有相似的基础，但 parquet 的压缩方法比 feather 更优。压缩后的文件在 parquet 中比在 feather
    中小。具有相似数据类型的列使用相同的编码进行压缩。不同编码方案的使用使得 parquet 的压缩效率更高。像 feather 一样，parquet 是一种二进制文件格式，可以与所有
    pandas 数据类型良好配合，并在多个语言中得到支持。Parquet 可以用于长期数据存储。
- en: 'The following are some limitations of the parquet file format:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 parquet 文件格式的一些限制：
- en: While parquet can accept multi-level indices, it requires that the index level
    name is in string format.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然 parquet 可以接受多级索引，但它要求索引级别名称必须是字符串格式。
- en: Python data types such as Period are not supported.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 数据类型如 Period 不被支持。
- en: Duplicates in column names are not supported.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不支持列名重复。
- en: When Categorical objects are serialized in a parquet file, they are deserialized
    as an object datatype.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当分类对象序列化到 parquet 文件时，它们会作为对象数据类型进行反序列化。
- en: Serialization or deserialization of parquet files t in pandas can take place
    in either of the `pyarrow` and `fastparquet` engines. These two engines have different
    dependencies. Pyarrow does not support Timedelta.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 中的 parquet 文件的序列化或反序列化可以通过 `pyarrow` 和 `fastparquet` 引擎完成。这两个引擎有不同的依赖关系。Pyarrow
    不支持 Timedelta。
- en: 'Let''s read a parquet file using the `pyarrow` engine:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 `pyarrow` 引擎读取一个 parquet 文件：
- en: '[PRE48]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This results in the following output:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/1a4f82f0-be20-408d-805a-3cb1e7160638.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1a4f82f0-be20-408d-805a-3cb1e7160638.png)'
- en: Output of read_parquet
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: read_parquet 输出
- en: 'Parquet allows us to select columns when reading a file, which saves time:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: Parquet 允许我们在读取文件时选择列，这可以节省时间：
- en: '[PRE49]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The same works for the `fastparquet` engine as well:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '`fastparquet` 引擎也适用相同的方法：'
- en: '[PRE50]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Reading a SQL file
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取 SQL 文件
- en: Interacting with a SQL database through pandas requires the sqlalchemy dependency
    to be installed.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 pandas 与 SQL 数据库交互需要安装 sqlalchemy 依赖。
- en: 'First, let''s define the engine from which connection parameters can be obtained:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义获取连接参数的引擎：
- en: '[PRE51]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Now, let''s read the `data_sql` table from the SQL database:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从 SQL 数据库中读取 `data_sql` 表：
- en: '[PRE52]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'This results in the following output:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/e991f948-810a-4d79-9894-cd22d844b593.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e991f948-810a-4d79-9894-cd22d844b593.png)'
- en: Output of read_sql_table
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: read_sql_table 输出
- en: 'The `read_sql_table()` function reads an entire table for the given table name.
    A specific column can be set as the index when reading:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_sql_table()` 函数用于读取给定表名的整个表。读取时，可以将特定的列设置为索引：'
- en: '[PRE53]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'This results in the following output:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/357a68c7-d791-454a-8dfe-fdff32a5188c.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![](img/357a68c7-d791-454a-8dfe-fdff32a5188c.png)'
- en: Output of read_sql_table with indexing
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 使用索引的 read_sql_table 输出
- en: 'The columns argument lets us choose specific columns when reading data by passing
    the column names as a list. Any date columns can be parsed into a specific format
    during the read process, as shown in the following code:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '`columns` 参数允许我们在读取数据时选择特定的列，通过传递列名列表来实现。任何日期列都可以在读取过程中解析为特定格式，如下代码所示：'
- en: '[PRE54]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The `schema` argument in this function helps specify the schema from which the
    table is to be extracted.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数中的 `schema` 参数有助于指定要从中提取表格的模式。
- en: 'Instead of reading the entire table, it is also possible to use a SQL query
    to get data in the necessary format. We can do this with the `read_sql_query()`
    function:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 除了读取整个表格外，还可以使用 SQL 查询以所需格式获取数据。我们可以通过 `read_sql_query()` 函数来实现：
- en: '[PRE55]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'This results in the following output:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '![](img/5276913a-81d8-4b1e-a138-bf3e32b90d67.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5276913a-81d8-4b1e-a138-bf3e32b90d67.png)'
- en: Output of read_sql_query
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_sql_query` 的输出'
- en: 'To run the `INSERT` and `CREATE` queries, which do not return any output, the
    `sql.execute()` function can be used. This requires an `sql` file of `pandas.io`
    to be imported:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行 `INSERT` 和 `CREATE` 查询，这些查询不会返回任何输出，可以使用 `sql.execute()` 函数。这需要导入一个 `pandas.io`
    的 `sql` 文件：
- en: '[PRE56]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'With a `sqlite` database, the connection to the engine has to be defined as
    follows so that it can be used in the `read_sql_table()` or `read_sql_query()`
    functions. The `sqlite` module must be imported prior to this:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `sqlite` 数据库时，必须按照如下方式定义与引擎的连接，以便可以在 `read_sql_table()` 或 `read_sql_query()`
    函数中使用。必须先导入 `sqlite` 模块：
- en: '[PRE57]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Reading a SAS/Stata file
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取 SAS/Stata 文件
- en: Pandas can read two file formats from SAS – SAS xports (`.XPT`) and SAS data
    files (`.sas7bdat`).
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 可以读取来自 SAS 的两种文件格式——SAS xports（`.XPT`）和 SAS 数据文件（`.sas7bdat`）。
- en: 'The `read_sas()` function helps read SAS files. Here, a SAS data file has been
    read and displayed as a pandas dataframe:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_sas()` 函数帮助读取 SAS 文件。这里已读取一个 SAS 数据文件，并作为 pandas 数据框显示：'
- en: '[PRE58]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'This results in the following output:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '![](img/83cb9f2b-0d6c-428a-bde7-f4e3ebaa063e.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![](img/83cb9f2b-0d6c-428a-bde7-f4e3ebaa063e.png)'
- en: Output of read_sas
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_sas` 的输出'
- en: 'The `chunksize` and `iterator` arguments help in reading the SAS file in groups
    of the same size. If the SAS data file that was used earlier is read with a chunksize
    of 10, then the 51 records will be divided into six groups, as shown in the following
    code:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '`chunksize` 和 `iterator` 参数有助于按相同大小的组读取 SAS 文件。如果之前使用的 SAS 数据文件以 chunksize
    10 进行读取，则 51 条记录将被分为六组，如下代码所示：'
- en: '[PRE59]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Take a look at the following output:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下输出：
- en: '![](img/b71ebc09-1929-443e-bdf7-1a75cf72d09c.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b71ebc09-1929-443e-bdf7-1a75cf72d09c.png)'
- en: Output of read_sas with chunksize
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 chunksize 的 `read_sas` 输出
- en: However, these SAS files cannot be written using pandas.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些 SAS 文件无法使用 pandas 写入。
- en: 'Pandas also provides support for reading and writing files that have been generated
    from Stata. Stata only supports limited datatypes: `int8`, `int16`, `int32`, `float32`,
    `float64`, and strings with a length less than 244\. When writing a Stata data
    file through pandas, type conversion is applied wherever applicable.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 还支持读取和写入从 Stata 生成的文件。Stata 只支持有限的数据类型：`int8`、`int16`、`int32`、`float32`、`float64`，以及长度小于
    244 的字符串。在通过 pandas 写入 Stata 数据文件时，会在适当的地方应用类型转换。
- en: 'Let''s read a Stata datafile using pandas:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 pandas 读取一个 Stata 数据文件：
- en: '[PRE60]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Take a look at the following output:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下输出：
- en: '![](img/a760ba3a-248a-4b8d-9d52-6bb2a95e589c.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a760ba3a-248a-4b8d-9d52-6bb2a95e589c.png)'
- en: Output of read_stata
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_stata` 的输出'
- en: 'The `read_stata()` function also has `chunksize` and `iterator` arguments to
    read data in smaller groups. The following arguments are the available `stata`
    reader functions:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_stata()` 函数还具有 `chunksize` 和 `iterator` 参数，用于按较小的组读取数据。以下是可用的 `stata`
    读取函数参数：'
- en: '`convert_categoricals`: Converts a suitable column into a categorical data
    type'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convert_categoricals`：将合适的列转换为分类数据类型'
- en: '`index_col`: Identifies the column to be defined as an index'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`index_col`：指定要定义为索引的列'
- en: '`convert_missing`: Specifies whether to represent missing values as NaN or
    with a Stata missing value object'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convert_missing`：指定是否将缺失值表示为 NaN 或 Stata 的缺失值对象'
- en: '`columns`: Columns to select from the dataset'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`columns`：要从数据集中选择的列'
- en: Reading from Google BigQuery
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 Google BigQuery 读取数据
- en: BigQuery is an extremely powerful data warehousing solution provided by Google.
    Pandas can directly connect to BigQuery and bring your data to a Python environment
    for further analysis.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery 是 Google 提供的一个极其强大的数据仓储解决方案。Pandas 可以直接连接到 BigQuery，并将数据带入 Python 环境进行进一步分析。
- en: 'The following is an example of reading a dataset from BigQuery:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从 BigQuery 读取数据集的示例：
- en: '[PRE61]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Take a look at the following output:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下输出：
- en: '![](img/7131995c-654c-4c9f-a9a1-74c5225ac87a.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7131995c-654c-4c9f-a9a1-74c5225ac87a.png)'
- en: Output of read_gbq
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: read_gbq 的输出
- en: 'The `read_gbq()` function accepts the query and the Google Cloud project-id
    (which serves as a key) so that it can access the database and bring out the data.
    The dialect argument takes care of the SQL syntax to be used: BigQuery''s legacy
    SQL dialect or the standard SQL dialect. In addition, there are arguments that
    allow the index column to be set (`index_col`), columns to be reordered (`col_order`),
    and reauthentication to be enabled (`reauth`).'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_gbq()` 函数接受查询和 Google Cloud 项目 ID（作为密钥）以便访问数据库并提取数据。dialect 参数处理 SQL
    语法的使用：BigQuery 的旧版 SQL 方言或标准 SQL 方言。此外，还有允许设置索引列（`index_col`）、重新排序列（`col_order`）以及启用重新认证（`reauth`）的参数。'
- en: Reading from a clipboard
  id: totrans-350
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从剪贴板读取数据
- en: This is a rather interesting feature in pandas. Any tabular data that has been
    copied onto the clipboard can be read as a DataFrame in pandas.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 pandas 中一个非常有趣的功能。任何已经复制到剪贴板的表格数据都可以作为 DataFrame 在 pandas 中读取。
- en: 'Let''s copy the following tabular data with the usual *ctrl + C* keyboard command:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用常规的 *ctrl + C* 键盘命令复制以下表格数据：
- en: '|  | **Gender** | **Entry_Date** | **Flag** |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '|  | **性别** | **入职日期** | **标记** |'
- en: '| **A** | M | 2012-01-19 | True |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| **A** | M | 2012-01-19 | True |'
- en: '| **B** | F | 2012-12-30 | False |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| **B** | F | 2012-12-30 | False |'
- en: '| **C** | M | 2012-05-05 | False |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| **C** | M | 2012-05-05 | False |'
- en: 'Calling the `read_clipboard()` function makes this data available as a pandas
    DataFrame:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `read_clipboard()` 函数会将剪贴板中的数据转换为 pandas DataFrame：
- en: '[PRE62]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Take a look at the following output:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下输出：
- en: '![](img/9479c71d-b380-484b-9e00-c217d19a956f.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9479c71d-b380-484b-9e00-c217d19a956f.png)'
- en: Output of read_clipboard
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: read_clipboard 的输出
- en: 'This function also recognizes the **Flag** column as a bool data type by default
    and assigns the unnamed column to be the index:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数默认也会将 **Flag** 列识别为布尔类型，并将未命名的列作为索引：
- en: '![](img/8ab745a9-7b80-4af3-bd88-83f89e40fe90.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8ab745a9-7b80-4af3-bd88-83f89e40fe90.png)'
- en: Data types after reading the clipboard
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 从剪贴板读取后的数据类型
- en: Managing sparse data
  id: totrans-365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理稀疏数据
- en: Sparse data refers to data structures such as arrays, series, DataFrames, and
    panels in which there is a very high proportion of missing data or NaNs.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏数据指的是像数组、系列、DataFrame 和面板等数据结构，其中有很大一部分数据缺失或为 NaN。
- en: 'Let''s create a sparse DataFrame:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来创建一个稀疏的 DataFrame：
- en: '[PRE63]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'This DataFrame has NaNs in 95% of the records. The memory usage of this data
    can be estimated with the following code:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 该 DataFrame 中 95% 的记录包含 NaN。可以通过以下代码估算该数据的内存使用情况：
- en: '[PRE64]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Take a look at the following output:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下输出：
- en: '![](img/395b1fb1-ccac-4920-9d60-8879499c651a.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![](img/395b1fb1-ccac-4920-9d60-8879499c651a.png)'
- en: Memory usage of a DataFrame with 95% NaNs
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 含有 95% NaN 的 DataFrame 的内存使用情况
- en: 'As we can see, each element consumes 8 bytes of data, irrespective of whether
    it is actual data or a NaN. Pandas offers a memory-efficient solution for handling
    sparse data, as depicted in the following code:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，每个元素消耗 8 字节的内存，无论它是实际数据还是 NaN。Pandas 提供了一种内存高效的解决方案来处理稀疏数据，如下代码所示：
- en: '[PRE65]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Take a look at the following output:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下输出：
- en: '![](img/006a584e-c19f-4aa2-b459-408b6d75f790.png)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![](img/006a584e-c19f-4aa2-b459-408b6d75f790.png)'
- en: Memory usage of sparse data
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏数据的内存使用情况
- en: 'Now, the memory usage has come down, with memory not being allotted to NaNs.
    This can also be implemented by defining a `fill_value` instead of NaN:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，内存使用量已经减少，NaN 不再分配内存。这也可以通过定义一个 `fill_value` 来代替 NaN 实现：
- en: '[PRE66]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Take a look at the following output:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下输出：
- en: '![](img/e92501ca-3ad0-4c92-9cdb-c15e3cfb8a0c.png)'
  id: totrans-382
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e92501ca-3ad0-4c92-9cdb-c15e3cfb8a0c.png)'
- en: Memory usage of sparse data after filling in the values
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 填充数据后的稀疏数据内存使用情况
- en: 'The sparse data can also be converted back into the original dense form, as
    shown in the following code:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏数据也可以转换回原始的密集形式，如下代码所示：
- en: '[PRE67]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: This way of handling sparse data can be applied in a similar way to series,
    panels, and arrays.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 这种处理稀疏数据的方式也可以类似地应用于系列、面板和数组。
- en: Writing JSON objects to a file
  id: totrans-387
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 JSON 对象写入文件
- en: 'The `to_json()` function allows any DataFrame object to be converted into a
    JSON string or written to a JSON file if the file path is specified:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '`to_json()` 函数允许将任何 DataFrame 对象转换为 JSON 字符串，或者如果指定文件路径，则写入 JSON 文件：'
- en: '[PRE68]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Take a look at the following output:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下输出：
- en: '![](img/3093bb79-a18a-40aa-9758-d5a8d340405b.png)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3093bb79-a18a-40aa-9758-d5a8d340405b.png)'
- en: JSON output
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 输出
- en: 'The orientation of the data in the JSON can be altered. The `to_json()` function
    has an orient argument which can be set for the following modes: columns, index,
    record, value, and split. Columns is the default setting for orientation:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 数据的方向可以被更改。`to_json()` 函数具有一个 orient 参数，可以设置为以下模式：columns、index、record、value
    和 split。默认的方向设置是列（columns）：
- en: '[PRE69]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Take a look at the following output:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下输出：
- en: '![](img/a98a5f64-dc5b-44bd-8e85-be398a6fc207.png)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a98a5f64-dc5b-44bd-8e85-be398a6fc207.png)'
- en: JSON output – column orientation
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 输出 – 列方向
- en: 'Orienting along the index acts like a transpose of the former case with a reversal
    of row and column indices in the JSON dictionary:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 沿索引方向的设置就像是前一个情况的转置，JSON 字典中的行和列索引被反转：
- en: '[PRE70]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Take a look at the following output:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下输出：
- en: '![](img/b257e514-0a3d-4c8e-b9cb-4e236929305f.png)'
  id: totrans-401
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b257e514-0a3d-4c8e-b9cb-4e236929305f.png)'
- en: JSON output – index orientation
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 输出 – 索引方向
- en: 'Setting orient as records creates a JSON structure where each record or row
    from the original DataFrame retains its structural form:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 将 orient 设置为记录（records）会创建一个 JSON 结构，其中原 DataFrame 中的每个记录或行保留其结构形式：
- en: '[PRE71]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Take a look at the following output:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下输出：
- en: '![](img/2238dc0e-150a-451d-866b-651b27862cb4.png)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2238dc0e-150a-451d-866b-651b27862cb4.png)'
- en: JSON output – records orientation
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 输出 – 记录方向
- en: 'When the orient option is set to values, both row indices and column indices
    vanish from the picture:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 当 orient 选项设置为值（values）时，行索引和列索引都会从图像中消失：
- en: '[PRE72]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Take a look at the following output:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下输出：
- en: '![](img/a0d7aa85-911e-4556-94e7-6db105f4765f.png)'
  id: totrans-411
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a0d7aa85-911e-4556-94e7-6db105f4765f.png)'
- en: JSON output – values orientation
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 输出 – 值方向
- en: 'The split orientation defines a JSON made up of entities such as column, index,
    and data:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 拆分方向定义了一个由实体如列、索引和数据组成的 JSON：
- en: '[PRE73]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Take a look at the following output:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下输出：
- en: '![](img/c909c169-02bf-4ebc-a2e7-40fb9626bad0.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c909c169-02bf-4ebc-a2e7-40fb9626bad0.png)'
- en: JSON output—split orientation
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 输出 – 拆分方向
- en: 'Setting orient to table brings out aspects such as schema and field:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 将 orient 设置为表格会展示出如架构和字段等方面：
- en: '[PRE74]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Take a look at the following output:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下输出：
- en: '![](img/4214d637-f8be-4ec1-9a61-40762c7b7e15.png)'
  id: totrans-421
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4214d637-f8be-4ec1-9a61-40762c7b7e15.png)'
- en: JSON output—table orientation
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 输出 – 表格方向
- en: The `date_format` argument of `to_json()` allows timestamps in the DataFrame
    to be converted into either `epoch` format or `iso` format.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '`to_json()` 的 `date_format` 参数允许将 DataFrame 中的时间戳转换为 `epoch` 格式或 `iso` 格式。'
- en: An unsupported datatype such as `complex` can be handled by specifying the type
    conversion to be followed through the `default_handler` argument.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像 `complex` 这样的不支持的数据类型，可以通过 `default_handler` 参数指定要执行的类型转换来处理。
- en: Serialization/deserialization
  id: totrans-425
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列化/反序列化
- en: Serialization is the process of translating [data structures](https://en.wikipedia.org/wiki/Data_structure)
    or [object](https://en.wikipedia.org/wiki/Object_(computer_science)) state into
    a format that can be stored (for example, in a [file](https://en.wikipedia.org/wiki/Computer_file)
    or memory [buffer](https://en.wikipedia.org/wiki/Data_buffer)) or transmitted
    (for example, across a [network](https://en.wikipedia.org/wiki/Computer_network)
    connection link) and reconstructed later (possibly in a different computer environment).[[1]](https://en.wikipedia.org/wiki/Serialization#cite_note-1)
    When the resulting series of bits is reread according to the serialization format,
    it can be used to create a semantically identical clone of the original object.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 序列化是将 [数据结构](https://en.wikipedia.org/wiki/Data_structure) 或 [对象](https://en.wikipedia.org/wiki/Object_(computer_science))
    的状态转换为一种可以存储（例如，在 [文件](https://en.wikipedia.org/wiki/Computer_file) 或内存 [缓冲区](https://en.wikipedia.org/wiki/Data_buffer)
    中）或通过 [网络](https://en.wikipedia.org/wiki/Computer_network) 连接传输的格式，并在之后重新构建（可能在不同的计算环境中）。[[1]](https://en.wikipedia.org/wiki/Serialization#cite_note-1)
    当根据序列化格式重新读取该位序列时，它可以用来创建一个语义上与原始对象完全相同的克隆。
- en: Data structures such as JSON, arrays, DataFrames, and Series sometimes need
    to be stored as physical files or transmitted over a network. These serializations
    can be understood as a dump of data where data can be stored in any format (text,
    CSV, and so on) or structure but all the important data points can be recreated
    by loading/deserializing them.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 数据结构如 JSON、数组、DataFrame 和 Series 有时需要作为物理文件存储或通过网络传输。这些序列化可以理解为数据的转储，数据可以以任何格式（文本、CSV
    等）或结构存储，但所有重要的数据点可以通过加载/反序列化恢复。
- en: Some examples of this are storing the parameters of the trained model object
    of a statistical model. This serialized file containing trained parameters can
    be loaded and the testing data can be passed through it for prediction. This is
    a popular method that's used to put statistical models to use.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 这些的例子包括存储统计模型的训练模型对象的参数。这个包含训练参数的序列化文件可以被加载，并且测试数据可以通过它进行预测。这是将统计模型投入使用的一种流行方法。
- en: Other uses of serialized data formats include transferring data through wires,
    storing objects in databases or HDDs, to make remote procedure calls, and to detect
    changes in time-varying data.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 序列化数据格式的其他用途包括通过网络传输数据、在数据库或硬盘中存储对象、进行远程过程调用，以及检测时间变化数据的变化。
- en: 'Let''s create a sample DataFrame to understand the serialization of various
    file formats supported by Pandas:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个示例DataFrame，来理解Pandas支持的各种文件格式的序列化：
- en: '[PRE75]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Take a look at the following output:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下输出：
- en: '![](img/20da6e5b-781d-4b37-9945-e38614c41d24.png)'
  id: totrans-433
  prefs: []
  type: TYPE_IMG
  zh: '![](img/20da6e5b-781d-4b37-9945-e38614c41d24.png)'
- en: DataFrame for serialization
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 用于序列化的DataFrame
- en: Writing to exotic file types
  id: totrans-435
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 写入特殊文件类型
- en: There are various formats that a data structure or object can be stored in.
    Let's go over a few of them.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 存储数据结构或对象的格式有多种。让我们来看看其中一些格式。
- en: to_pickle()
  id: totrans-437
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: to_pickle()
- en: When a Python object is pickled, it gets saved to disk. Pickling serializes
    the object first, before writing it. It involves converting objects such as lists,
    Dicts, DataFrames, and trained machine learning models into a character stream.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个Python对象被pickle时，它会被保存到磁盘。Pickling首先序列化对象，然后写入磁盘。它包括将列表、字典、DataFrame和训练的机器学习模型等对象转换为字符流。
- en: 'Let''s convert the DataFrame we defined earlier into pickle format:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将之前定义的DataFrame转换成pickle格式：
- en: '[PRE76]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'It is also possible to compress pickle files before they are written. Compression
    schemes such as `gzip`, `bz2`, and `xz` are supported:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以在写入之前压缩pickle文件。支持`gzip`、`bz2`和`xz`等压缩方案：
- en: '[PRE77]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'By default, the compression type is inferred from the extension that''s provided:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，压缩类型是根据提供的扩展名推断的：
- en: '[PRE78]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: The `read_pickle()` function will deserialize the `pickle` file. Zip compression
    is only supported for reading a single file and not for writing.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_pickle()`函数将反序列化`pickle`文件。压缩仅支持读取单个文件，不支持写入。'
- en: to_parquet()
  id: totrans-446
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: to_parquet()
- en: 'As we discussed in the *Reading parquet files* section, two engines can be
    used for deserialization as well:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*读取parquet文件*部分中讨论的那样，也可以使用两种引擎进行反序列化：
- en: '[PRE79]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: to_hdf()
  id: totrans-449
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: to_hdf()
- en: 'An HDF file is like a dictionary and it can store multiple objects. The `to_hdf()`
    function converts a Pandas object into an HDF file:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: HDF文件像字典一样，可以存储多个对象。`to_hdf()`函数将Pandas对象转换为HDF文件：
- en: '[PRE80]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: When all the columns of a row are NaNs, they are not automatically dropped.
    This can be done by setting the `dropna` argument to `True` when writing to HDF.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 当一行的所有列都是NaN时，它们不会自动删除。可以通过将`dropna`参数设置为`True`来在写入HDF时删除这些行。
- en: to_sql()
  id: totrans-453
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: to_sql()
- en: 'With support from the `sqlalchemy` package, data can be transferred to databases
    through pandas:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`sqlalchemy`包的支持，数据可以通过pandas传输到数据库：
- en: '[PRE81]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Data can also be pushed iteratively in batches by using the `chunksize` argument.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以通过使用`chunksize`参数迭代地批量推送数据。
- en: 'The data type of any column can also be changed when pushing to the database,
    as shown in the following code:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据推送到数据库时，任何列的数据类型也可以更改，如以下代码所示：
- en: '[PRE82]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: The `Timedelta` datatype, which is not supported across databases, is converted
    into its equivalent integral value in nanoseconds before being stored in the database.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '`Timedelta`数据类型（在数据库中不支持）会在存储到数据库之前，转换为等效的纳秒整数值。'
- en: to_feather()
  id: totrans-460
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: to_feather()
- en: 'Serializing a pandas object into feather format just requires the `to_feather()`
    function to be called:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 将pandas对象序列化为feather格式只需要调用`to_feather()`函数：
- en: '[PRE83]'
  id: totrans-462
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: to_html()
  id: totrans-463
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: to_html()
- en: 'The `to_html()` function converts a DataFrame into a raw HTML format:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '`to_html()`函数将DataFrame转换为原始HTML格式：'
- en: '[PRE84]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'This results in the following output:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/91c4cda7-34b2-4cd7-bb92-f9548df02cf8.png)'
  id: totrans-467
  prefs: []
  type: TYPE_IMG
  zh: '![](img/91c4cda7-34b2-4cd7-bb92-f9548df02cf8.png)'
- en: DataFrame in HTML format
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: HTML格式的DataFrame
- en: A horde of options in the `to_html()` function allow the raw HTML to be enriched.
    Being able to select columns and control escape sequences is possible through
    the use of the `columns` and `escape` arguments.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: '`to_html()`函数中有一大堆选项，可以丰富原始的HTML。通过使用`columns`和`escape`参数，可以选择列并控制转义序列。'
- en: to_msgpack()
  id: totrans-470
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: to_msgpack()
- en: Msgpack offers fast and efficient binary serialization.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: Msgpack提供快速高效的二进制序列化。
- en: 'A single object can be directly converted into `msgpack` format like so:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 单个对象可以像这样直接转换为`msgpack`格式：
- en: '[PRE85]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'If we have multiple objects, they can be serialized into a single `msgpack`
    file like so:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有多个对象，它们可以像这样序列化为一个`msgpack`文件：
- en: '[PRE86]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: to_latex()
  id: totrans-476
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: to_latex()
- en: 'The `to_latex()` function takes a DataFrame and converts it into an aesthetic
    tabular structure that''s compatible with `latex` documents:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: '`to_latex()`函数将DataFrame转换为兼容`latex`文档的美观表格结构：'
- en: '[PRE87]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Take a look at the following output:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下输出：
- en: '![](img/f3f596fb-88e6-4ca5-99d7-6ef2497ef3a2.png)'
  id: totrans-480
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f596fb-88e6-4ca5-99d7-6ef2497ef3a2.png)'
- en: DataFrame in latex format
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: LaTeX格式的DataFrame
- en: to_stata()
  id: totrans-482
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: to_stata()
- en: 'Pandas can help with creating `stata` data files with the `.dta` extension,
    as shown in the following code:'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas可以帮助创建带有`.dta`扩展名的`stata`数据文件，如下代码所示：
- en: '[PRE88]'
  id: totrans-484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: to_clipboard()
  id: totrans-485
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: to_clipboard()
- en: 'The `to_clipboard()` function transfers a DataFrame from a Python environment
    to the clipboard. From the clipboard, the object can be pasted elsewhere through
    the use of the *ctrl* + *V* keyboard command:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '`to_clipboard()`函数将DataFrame从Python环境转移到剪贴板。然后可以通过*ctrl* + *V*键盘命令将对象粘贴到其他地方：'
- en: '[PRE89]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'This DataFrame can also be sent to the clipboard in a format that''s more compatible
    with CSV like so:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 这个DataFrame也可以以更兼容CSV的格式复制到剪贴板，如下所示：
- en: '[PRE90]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: GeoPandas
  id: totrans-490
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GeoPandas
- en: GeoPandas is a Python package written on top of pandas that's used to work with
    geospatial data. It is designed to work with existing tools, such as desktop GIS,
    geospatial databases, web maps, and Python data tools.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: GeoPandas是一个基于pandas的Python包，用于处理地理空间数据。它旨在与现有工具兼容，如桌面GIS、地理空间数据库、网页地图和Python数据工具。
- en: GeoPandas allows you to easily perform operations in Python that would otherwise
    require a spatial database such as PostGIS.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: GeoPandas允许你轻松地在Python中执行本来需要空间数据库（如PostGIS）才能完成的操作。
- en: What is geospatial data?
  id: totrans-493
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是地理空间数据？
- en: Spatial data, geospatial data, GIS data, and geodata are the names for numeric
    data that identifies the geographical location of a physical object such as a
    building, street, town, city, country, and so on according to a geographic coordinate
    system**.** Apart from the geographical location, geospatial data often also stores
    socioeconomic data, transaction data, and so on for each location.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 空间数据、地理空间数据、GIS数据和地理数据是指通过地理坐标系统标识物理对象（如建筑物、街道、城镇、城市、国家等）的地理位置的数值数据**。** 除了地理位置，地理空间数据通常还存储每个位置的社会经济数据、交易数据等。
- en: Installation and dependencies
  id: totrans-495
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装与依赖
- en: 'GeoPandas can be installed through pip or Anaconda, or directly through GitHub.
    The most common ways are through `pip` and Anaconda through a Terminal window:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过pip或Anaconda，或直接通过GitHub安装GeoPandas。最常见的安装方法是通过`pip`和Anaconda在终端窗口中进行：
- en: '[PRE91]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'GeoPandas depends on the following Python libraries:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: GeoPandas依赖于以下Python库：
- en: '`pandas`'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas`'
- en: '`numpy`'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy`'
- en: '`shapely`'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shapely`'
- en: '`fiona`'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fiona`'
- en: '`pyproj`'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pyproj`'
- en: '`six`'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`six`'
- en: '`rtree`'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rtree`'
- en: Working with GeoPandas
  id: totrans-506
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GeoPandas
- en: We can use the GeoPandas library to read many GIS file formats (relying on the
    `fiona` library, which is an interface to GDAL/OGR) using the `geopandas.read_file`
    function.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用GeoPandas库通过`geopandas.read_file`函数读取许多GIS文件格式（依赖于`fiona`库，这是GDAL/OGR的接口）。
- en: Data can be read through shapefiles as well. In this section, we will look at
    an example of working with GeoPandas. We will explain how to read a shapefile
    that contains geospatial data, performing aggregations on it, sorting it, and
    finally plotting the required Geo DataFrame.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 数据也可以通过shapefiles读取。在本节中，我们将通过一个示例演示如何使用GeoPandas。我们将解释如何读取包含地理空间数据的shapefile，对其进行聚合、排序，最后绘制所需的Geo
    DataFrame。
- en: 'Use the following code to call in the required prerequisites libraries:'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码调用所需的先决库：
- en: '[PRE92]'
  id: totrans-510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Use the following code to read a shapefile that has geospatial information
    data:'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码读取包含地理空间信息数据的shapefile：
- en: '[PRE93]'
  id: totrans-512
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Use the following code to access the first five rows of the dataset, just like
    we do with pandas:'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码访问数据集的前五行，就像我们使用pandas一样：
- en: '[PRE94]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'The preceding code snippets result in the following output:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段将产生以下输出：
- en: '![](img/9ce0578f-c959-4a75-bd6b-e3c778dcbd1f.png)'
  id: totrans-516
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ce0578f-c959-4a75-bd6b-e3c778dcbd1f.png)'
- en: A geospatial shape file read as a DataFrame
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 作为DataFrame读取的地理空间shapefile
- en: 'Let''s plot a quick basic visualization of the data:'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速绘制数据的基本可视化：
- en: '[PRE95]'
  id: totrans-519
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'This results in the following output:'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/5db74b7f-59a8-46b4-bed9-66be5731c66d.png)'
  id: totrans-521
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5db74b7f-59a8-46b4-bed9-66be5731c66d.png)'
- en: The countries in the shapefile plotted on a map
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 在地图上绘制的形状文件中的国家
- en: 'To check the data type of our geospatial data, we can use the following code:'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查我们地理空间数据的类型，可以使用以下代码：
- en: '[PRE96]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'This results in the following output:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/b7a1f2d4-33c6-46b5-b852-2b0e93eb46b6.png)'
  id: totrans-526
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7a1f2d4-33c6-46b5-b852-2b0e93eb46b6.png)'
- en: Asserting that the data type of the countries shapefile is a GeoDataFrame after
    conversion
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 在转换后，断言国家形状文件的数据类型是 GeoDataFrame
- en: Here, we can see that the DataFrame is a GeoDataFrame. Now, let's discuss what
    a GeoDataFrame is.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到该 DataFrame 是一个 GeoDataFrame。现在，让我们讨论一下 GeoDataFrame 是什么。
- en: GeoDataFrames
  id: totrans-529
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GeoDataFrames
- en: 'A GeoDataFrame contains a geospatial dataset. It is just like a pandas DataFrame
    but with some additional functionality for working with geospatial data. This
    additional functionality is as follows:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: GeoDataFrame 包含一个地理空间数据集。它就像一个 pandas DataFrame，但具有一些额外的功能，用于处理地理空间数据。这些附加功能如下：
- en: A `.geometry` attribute that always returns the column that includes geometry
    information (returning a GeoSeries). The column name itself does not necessarily
    need to be `.geometry`, but it will always be accessible as the `.geometry` attribute.
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.geometry` 属性始终返回包含几何信息的列（返回一个 GeoSeries）。列名本身不一定需要是 `.geometry`，但它将始终可以作为
    `.geometry` 属性访问。'
- en: It has some extra methods for working with spatial data (area, distance, buffer,
    intersection, and so on), all of which we will look at in later chapters.
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它有一些额外的方法来处理空间数据（如面积、距离、缓冲区、交集等），这些方法我们将在后面的章节中逐一探讨。
- en: GeoDataFrame is still a DataFrame, so we have all the functionalities that we
    have available for DataFrames. We can perform aggregation, sorting, filtering,
    and so on in GeoDataFrames as well.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: GeoDataFrame 仍然是一个 DataFrame，因此我们可以在 GeoDataFrame 中执行 DataFrame 中所有可用的功能，比如聚合、排序、过滤等。
- en: 'Use the following code to perform a simple aggregation with GeoPandas:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码执行 GeoPandas 的简单聚合：
- en: '[PRE97]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '`POP_EST` is a column in the `countries` GeoDataFrame and is of the numeric
    type. This results in the following output:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: '`POP_EST` 是 `countries` GeoDataFrame 中的一列，数据类型为数字。 这将产生以下输出：'
- en: '![](img/c9bc4306-c07b-4ef9-af33-5110ae805ff2.png)'
  id: totrans-537
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9bc4306-c07b-4ef9-af33-5110ae805ff2.png)'
- en: Aggregating a numeric column in a GeoDataFrame shows that it works exactly the
    same way as a normal DataFrame
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 对 GeoDataFrame 中的数字列进行聚合，证明它的工作方式与普通 DataFrame 完全相同
- en: 'Alternatively, we can use boolean filtering to select a subset of the DataFrame
    based on a condition:'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用布尔过滤来基于条件选择 DataFrame 的子集：
- en: '[PRE98]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Now, we will try to plot the filtered GeoDataFrame by using the `plot()` function:'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将尝试使用 `plot()` 函数绘制过滤后的 GeoDataFrame：
- en: '[PRE99]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'This results in the following output:'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/1812f806-00e9-48b4-83f9-553a54086457.png)'
  id: totrans-544
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1812f806-00e9-48b4-83f9-553a54086457.png)'
- en: Subsetting one continent and plotting it for better visibility
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 对一个大洲进行子集化并绘制以提高可视化效果
- en: GeoPandas also helps in converting an ordinary DataFrame into a GeoDataFrame,
    provided that you have `Latitude` and `Longitude` coordinates. Let's take a look
    at this.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: GeoPandas 还可以帮助将普通 DataFrame 转换为 GeoDataFrame，前提是你拥有 `Latitude` 和 `Longitude`
    坐标。让我们来看一下这个例子。
- en: 'Let''s assume that we have a simple DataFrame, like this:'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个简单的 DataFrame，像这样：
- en: '[PRE100]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'The preceding code results in the following output:'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码将产生以下输出：
- en: '![](img/33331910-d469-4863-9e25-20be419b7a83.png)'
  id: totrans-550
  prefs: []
  type: TYPE_IMG
  zh: '![](img/33331910-d469-4863-9e25-20be419b7a83.png)'
- en: Creating a normal DataFrame of country capitals with latitude and longitude
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个包含国家首都及其经纬度的普通 DataFrame
- en: 'Let''s append a new column called `''Coordinates''` which concatenates the
    latitude and longitude columns:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们添加一个新列，命名为 `'Coordinates'`，它将经纬度列连接起来：
- en: '[PRE101]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'This results in the following output:'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/d86862f8-a170-4390-97fd-193d8b46b2bb.png)'
  id: totrans-555
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d86862f8-a170-4390-97fd-193d8b46b2bb.png)'
- en: A normal DataFrame with latitude and longitude zipped in one column
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 一个将纬度和经度合并在一列中的普通 DataFrame
- en: 'Using the `Point` function from the shapely package, we can correctly identify
    these as positional coordinates or point tuple parameters, which are the vertebra
    of a GeoDataFrame:'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 shapely 包中的 `Point` 函数，我们可以正确地将这些标识为位置坐标或点元组参数，它们是 GeoDataFrame 的骨架。
- en: '[PRE102]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'This results in the following output:'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/86e05119-7fff-4636-80a6-b3214ef99f72.png)'
  id: totrans-560
  prefs: []
  type: TYPE_IMG
  zh: '![](img/86e05119-7fff-4636-80a6-b3214ef99f72.png)'
- en: Converting the zipped latitude and longitude into a point so that it is usable
    by geopandas for converting it into a GeoDataFrame
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 将压缩的经度和纬度转换为点，以便GeoPandas可以使用它将其转换为GeoDataFrame
- en: 'Now that everything is in place, let''s convert this to a GeoDataFrame:'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 一切准备就绪后，让我们将其转换为GeoDataFrame：
- en: '[PRE103]'
  id: totrans-563
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'Let''s print the type as `gdf` to see its GeodataFrame type:'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印出`gdf`类型，看看它的GeoDataFrame类型：
- en: '[PRE104]'
  id: totrans-565
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'This results in the following output:'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/ecdd1986-6e59-4459-9087-39a7fe552661.png)'
  id: totrans-567
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ecdd1986-6e59-4459-9087-39a7fe552661.png)'
- en: Asserting that the type of the newly created DataFrame is a GeoDataFrame
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 确认新创建的DataFrame的类型是GeoDataFrame
- en: This has given us a basic idea about GeoPandas and how it works. Its wings are
    so widespread that you can glide across the various features of it and get benefits
    from it.
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了关于GeoPandas的基本概念，以及它是如何工作的。它的应用范围广泛，你可以跨越其各种功能并从中获益。
- en: Open source APIs – Quandl
  id: totrans-570
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开源API – Quandl
- en: Python can be used to fetch data from open source and commercial APIs. We can
    use it to fetch data in several formats. Some of them output data in JSON format,
    some in XML, and some in tabular formats such as CSV and DataFrames. Once converted
    into DataFrames, this data is generally processed in pandas.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: Python可以用来从开源和商业API获取数据。我们可以用它获取多种格式的数据。有些数据以JSON格式输出，有些以XML格式输出，还有一些以表格格式，如CSV和DataFrame输出。数据转换为DataFrame后，通常会在pandas中进行处理。
- en: In this section, we will look at an example of fetching data from the Quandl
    API, which is an open source API that contains data on a variety of topics such
    as financial, economic, and alternative data. You can have a look at this famous
    data repository here: [https://www.quandl.com/](https://www.quandl.com/).
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示一个从Quandl API获取数据的示例，Quandl是一个开源API，包含各种主题的数据，如金融、经济和替代数据。你可以在这里查看这个著名的数据仓库：[https://www.quandl.com/](https://www.quandl.com/)。
- en: An `api` key is an application programming interface that acts as a mediator
    between a developer or any other user who wishes to access the data within the
    website using a computer code. An `api` key is a piece of code that identifies
    the user and their associated account.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: '`api`密钥是一种应用程序接口，充当开发者或任何希望通过计算机代码访问网站数据的用户之间的中介。`api`密钥是一段代码，用于识别用户及其关联的账户。'
- en: To get started with this example, you will need to sign up for a Quandl account,
    which is free. Post signup, the API key can be found under the Account setting
    options, which will be available under the dropdown of the profile image.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始这个示例，你需要注册一个免费的Quandl账号。注册后，你可以在账户设置选项中找到API密钥，该选项会显示在个人资料图片的下拉菜单中。
- en: Python has made it easier to work with the Quandl API by providing us with a
    package that can be used to interact with the latest version of the Quandl data
    repository. This package is compatible with Python version 2.7 and above.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: Python通过提供一个可以与最新版本的Quandl数据仓库交互的包，使得使用Quandl API变得更加容易。这个包兼容Python 2.7及以上版本。
- en: 'First things first, you need to install the Quandl package through `pip` or
    `conda` using the following command:'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要通过`pip`或`conda`安装Quandl包，使用以下命令：
- en: '[PRE105]'
  id: totrans-577
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'You can fetch any dataset you wish to use. Here, I am using the Brazilian Real
    Futures, July 2022 dataset for illustration purposes. You will need to find the
    data code for the dataset you want to download. This can be obtained from the
    Quandl website and is shown in the following screenshot:'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以获取任何你希望使用的数据集。在这里，我使用的是2022年7月的巴西雷亚尔期货数据集作为示例。你需要找到你想要下载的数据集的代码。这个代码可以从Quandl网站获取，如下图所示：
- en: '![](img/6b21ddba-b76c-4576-b7e6-109183f6a825.png)'
  id: totrans-579
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6b21ddba-b76c-4576-b7e6-109183f6a825.png)'
- en: Finding the data code for a dataset on the Quandl website
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 在Quandl网站上查找数据集的数据代码
- en: 'Now, let''s look at how we can use the Quandl API to fetch the data we want:'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下如何使用Quandl API来获取我们想要的数据：
- en: '[PRE106]'
  id: totrans-582
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'This results in the following output:'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/3b2db996-2bea-4c2c-9b41-18c247cd38f2.png)'
  id: totrans-584
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3b2db996-2bea-4c2c-9b41-18c247cd38f2.png)'
- en: Brazilian Real Futures data fetched via the Quandl API
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Quandl API获取的巴西雷亚尔期货数据
- en: 'The API can also be used to fetch a subset of data and not all of it at once.
    For example, here, we have filtered the data for a given date range:'
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: API还可以用来获取数据的子集，而不是一次性获取所有数据。例如，在这里，我们筛选了某个日期范围内的数据：
- en: '[PRE107]'
  id: totrans-587
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'This results in the following output:'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/4377abc8-7f48-40fc-bd88-b142a4cb1b36.png)'
  id: totrans-589
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4377abc8-7f48-40fc-bd88-b142a4cb1b36.png)'
- en: Brazilian Real Futures data fetched via the Quandl API with a date range filter
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Quandl API获取的巴西雷亚尔期货数据，带有日期范围过滤
- en: Once the data has been read, pandas can be used to perform all the transformations
    on the data, which will be helpful for further analysis.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据被读取，pandas可以用来对数据进行所有转换，这将对进一步的分析非常有帮助。
- en: Datasets can also be downloaded by providing the URLs of the dataset. This can
    be checked by downloading a file that will list the available datasets. Let's
    try downloading a file from the URL through Python's `urllib` package rather than
    following the `Quandl` package method.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集也可以通过提供数据集的网址来下载。通过下载一个文件列出可用的数据集，您可以检查这一点。让我们尝试通过Python的`urllib`包来下载一个文件，而不是按照`Quandl`包的方法。
- en: 'To get the URL that can be used in this method, follow these steps:'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取可以在此方法中使用的网址，请按照以下步骤操作：
- en: 'Click on the dataset header/link (marked in the red box):'
  id: totrans-594
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击数据集的标题/链接（标记在红色框中）：
- en: '![](img/27f37797-063f-4bb8-bdd5-858dc4fb0b66.png)'
  id: totrans-595
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27f37797-063f-4bb8-bdd5-858dc4fb0b66.png)'
- en: Data topic link to get more details about the topic
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 数据主题链接以获取更多关于该主题的详细信息
- en: 'Clicking on the link will take you to the next page, where you would see these
    options. Select API under the Usage option, as shown in the following screenshot:'
  id: totrans-597
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击链接将带您到下一个页面，您将在该页面看到这些选项。在“用法”选项下选择API，如下图所示：
- en: '![](img/3805a13b-b080-48cf-b9c3-48710a3fbe5f.png)'
  id: totrans-598
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3805a13b-b080-48cf-b9c3-48710a3fbe5f.png)'
- en: Data topic documentation
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 数据主题文档
- en: 'After this selection, you should scroll down a bit to find the following URLs,
    which can be used in the code to fetch the data:'
  id: totrans-600
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此选择之后，您应该稍微向下滚动一下，找到以下网址，可以在代码中使用它们来获取数据：
- en: '![](img/bd0bf04a-881e-4eb0-af08-610d5189a8f4.png)'
  id: totrans-601
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd0bf04a-881e-4eb0-af08-610d5189a8f4.png)'
- en: API links for Quandl data that were obtained from the Data topic documentation
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据主题文档中获取的Quandl数据的API链接
- en: 'Since one topic may contain multiple datasets, the topic is downloaded as a
    `.zip` file containing all the datasets. It provides a metadata table, as well
    as the details (including the dataset key) of each dataset:'
  id: totrans-603
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于一个主题可能包含多个数据集，主题会作为`.zip`文件下载，文件中包含所有数据集。它提供了一个元数据表，并且列出了每个数据集的详细信息（包括数据集键）：
- en: '[PRE108]'
  id: totrans-604
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'This results in the following output:'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下输出：
- en: '![](img/507b5a15-cb3c-4309-99b6-531fd6a82d48.png)'
  id: totrans-606
  prefs: []
  type: TYPE_IMG
  zh: '![](img/507b5a15-cb3c-4309-99b6-531fd6a82d48.png)'
- en: Output of the metadata table of the downloaded data topic
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 下载的数据主题的元数据表输出
- en: read_sql_query
  id: totrans-608
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: read_sql_query
- en: 'Python supports a lot of database operations using libraries such as `psycopg2`
    and `sqlalchemy`. Both of them are quite comprehensive and useful when working
    with databases from a Python interface. However, they have their own paraphernalia,
    which sometimes gets too much information for simple querying tasks. Fortunately,
    there is a hidden gem in pandas called `read_sql_query` method. It does the following:'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: Python支持很多数据库操作，使用如`psycopg2`和`sqlalchemy`等库。它们在从Python接口操作数据库时非常全面和有用。然而，它们有自己的繁琐内容，有时会对简单的查询任务产生过多的信息。幸运的是，pandas中有一个隐藏的宝石，那就是`read_sql_query`方法。它的功能如下：
- en: Runs simple queries involving select, where, and so on.
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行包含select、where等的简单查询。
- en: Runs all the queries that return a table or its subset in a tabular form.
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行所有返回表格或其子集的查询，并以表格形式展示。
- en: Can't use the INSERT, UPDATE, and DELETE statements.
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无法使用INSERT、UPDATE和DELETE语句。
- en: The output is a DataFrame and hence all the pandas methods can be used for further
    data processing.
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出是一个数据框，因此可以使用所有pandas方法进行进一步的数据处理。
- en: Let's look at how we can make use of this method. To illustrate this, we will
    insert a dataset as a table into a database. To do this, you will need to install
    a PostgreSQL or SQL database to your local directory. If you already have a database
    set up, you can ignore the table creation process and jump to the queries process.
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何利用这个方法。为了说明这一点，我们将把一个数据集作为表格插入到数据库中。为此，您需要在本地目录中安装PostgreSQL或SQL数据库。如果您已经设置好了数据库，可以跳过表格创建过程，直接跳到查询过程。
- en: 'Let''s download the World Happiness 2019 dataset from Kaggle, push it to a
    `db`, and perform various DB and pandas operations on it:'
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从Kaggle下载2019年世界幸福感数据集，将其推送到`db`，并对其进行各种DB和pandas操作：
- en: '[PRE109]'
  id: totrans-616
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'The following data shows us the World Happiness report as a DataFrame:'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 以下数据展示了世界幸福报告作为一个数据框：
- en: '![](img/b3bac349-5720-4957-9446-3d44cee6a066.png)'
  id: totrans-618
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b3bac349-5720-4957-9446-3d44cee6a066.png)'
- en: World Happiness report as a DataFrame
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 世界幸福报告作为一个数据框
- en: 'Since we are going to directly create a table from the DataFame that we generated
    previously, it is necessary to change the column name to postgresql since it does
    not support column names with spaces:'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将直接从之前生成的DataFrame创建一个表，因此需要将列名更改为postgresql，因为它不支持带空格的列名：
- en: '[PRE110]'
  id: totrans-621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'In order to use the `read_sql_query` method, we need to make a connection with
    the database using either `psycopg2` or `sqlalchemy`. Once the connection has
    been established, `read_sql_query` can be used in its full form:'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用`read_sql_query`方法，我们需要通过`psycopg2`或`sqlalchemy`与数据库建立连接。连接建立后，就可以完整地使用`read_sql_query`方法：
- en: '[PRE111]'
  id: totrans-623
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'This results in the following output:'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![](img/97849629-087f-4e41-a3f4-2c00306967da.png)'
  id: totrans-625
  prefs: []
  type: TYPE_IMG
  zh: '![](img/97849629-087f-4e41-a3f4-2c00306967da.png)'
- en: World Happiness report data as a DataFrame queried from the table in the PostgreSQL
    DB
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 从PostgreSQL数据库中的表查询出的世界幸福报告数据作为DataFrame
- en: Take a look at the following code. This helps in running a SQL query.
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下下面的代码。它有助于运行SQL查询。
- en: '[PRE112]'
  id: totrans-628
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'This results in the following output:'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![](img/ce2363d9-2dc4-43f9-9fc5-31592f4d4844.png)'
  id: totrans-630
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce2363d9-2dc4-43f9-9fc5-31592f4d4844.png)'
- en: World Happiness report data with filters as a DataFrame queried from the table
    in the PostgreSQL DB
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: 使用从PostgreSQL数据库中的表查询出的带过滤器的世界幸福报告数据作为DataFrame
- en: '[PRE113]'
  id: totrans-632
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: The `pd.read_sql_query()` method returns the table as a DataFrame rather than
    requiring the programmer to intervene and convert the data into the necessary
    format.
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.read_sql_query()`方法将结果返回为DataFrame，而无需程序员介入并将数据转换为所需格式。'
- en: Pandas plotting
  id: totrans-634
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pandas绘图
- en: A picture is worth a thousand words. This is why graphs are commonly used to
    visually illustrate relationships in data. The purpose of a graph is to present
    data that is too numerous or complicated to be described adequately in terms of
    text and in less space. With Python's **plotting function**, it takes far less
    than a few words of code to create a production-quality graphic.
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 一图胜千言。这就是为什么图表通常用于直观地展示数据之间的关系。图表的目的是呈现那些过于庞大或复杂，以至于无法通过文本充分描述的数据，并且能在更小的空间内展示。使用Python的**绘图函数**，只需要几行代码就可以创建出生产质量的图形。
- en: 'We will begin by installing the necessary packages:'
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开始安装所需的包：
- en: '[PRE114]'
  id: totrans-637
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'We are using the `mtcars` data here to explain the plots:'
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用`mtcars`数据来解释这些图表：
- en: '[PRE115]'
  id: totrans-639
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'This results in the following output:'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![](img/2d0b263d-0e95-49e8-9a1b-f32841cfce3b.png)'
  id: totrans-641
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2d0b263d-0e95-49e8-9a1b-f32841cfce3b.png)'
- en: mtcars DataFrame
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: mtcars DataFrame
- en: Let's discuss the various plots in `pandas.plotting` in detail.
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细讨论`pandas.plotting`中的各种绘图。
- en: Andrews curves
  id: totrans-644
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Andrews曲线
- en: Andrews curve is a method that's used to visualize multidimensional data. It
    does this by mapping each observation onto a function. Here, each color that's
    used represents a class and we can easily note that the lines that represent samples
    from the same class have similar curves. This curve is very useful in analyzing
    time series and signal data.
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: Andrews曲线是一种用于可视化多维数据的方法。它通过将每个观察值映射到一个函数来实现。在这里，每种使用的颜色代表一个类别，我们可以很容易地看到，代表同一类别的样本线具有相似的曲线。这种曲线在分析时间序列和信号数据时非常有用。
- en: Basically, each data point is sent through a Fourier transform according to
    the Fourier function. Each line in the following chart represents a separate data
    point. It can be plotted using the snippet below.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，每个数据点都根据傅里叶函数进行傅里叶变换。以下图表中的每条线代表一个单独的数据点。可以使用下面的代码片段绘制它。
- en: '[PRE116]'
  id: totrans-647
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: 'The following is the graph:'
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是图表：
- en: '![](img/c372bbe4-daf0-4f94-946e-9706f991bbf0.png)'
  id: totrans-649
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c372bbe4-daf0-4f94-946e-9706f991bbf0.png)'
- en: Andrews curve plot
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: Andrews曲线图
- en: Parallel plot
  id: totrans-651
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行图
- en: Parallel plots are best used when we need to compare many variables for each
    point and to understand the relationship between them, for example, if you need
    to compare an array of variables with the same attributes but differing values
    (for example, comparing motorcycle specs across different models).
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 并行绘图最适合在需要比较每个点的多个变量并理解它们之间关系时使用，例如，当你需要比较一组具有相同属性但不同数值的变量时（例如，比较不同型号的摩托车规格）。
- en: 'Each connected line represents one data point. The vertical lines represent
    the columns or variables whose values have been plotted for each data point. The
    inflection point (marked in red) represents the values of those variables for
    those points. A parallel chart can be plotted very easily using pandas, as shown
    in the following code:'
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: 每条连接线代表一个数据点。垂直线表示已为每个数据点绘制的列或变量的值。拐点（用红色标记）表示这些变量在这些点上的值。可以通过以下代码非常轻松地绘制并行图：
- en: '[PRE117]'
  id: totrans-654
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'This results in the following output:'
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成以下输出：
- en: '![](img/d63564e2-d01a-4300-8c17-66bc6ddb8dd5.png)'
  id: totrans-656
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d63564e2-d01a-4300-8c17-66bc6ddb8dd5.png)'
- en: Parallel plot
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: 并行图
- en: Radviz plots
  id: totrans-658
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Radviz 图
- en: Radviz plots allow for the exploration of multi-task classification problems.
    It displays data of three or more variables in a two-dimensional projection. This
    plot is like a circle with data points inside it. The variables are present around
    the perimeter of the circle.
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: Radviz 图允许探索多任务分类问题。它以二维投影展示三个或更多变量的数据。这个图像类似于一个圆形，数据点位于圆形内部。变量则位于圆圈的周边。
- en: 'The position of each point is determined by the values of all the variable
    values that make it. An imaginary circle is created and the variables are placed
    on this circle. The points are placed within the perimeter of the circle. The
    exact position of the point is determined by the position where the force that''s
    exerted on it by each variable sums to zero. The force that''s applied by each
    variable can be thought of as a spring force and is governed by Hook''s law (F
    = kx):'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 每个点的位置由所有构成它的变量值决定。创建一个虚拟圆圈，并将变量放置在这个圆圈上。点位于圆圈的边缘内。点的确切位置由各个变量施加的力的总和为零的位置决定。每个变量施加的力可以看作是弹簧力，并遵循胡克定律（F
    = kx）：
- en: '![](img/29eadd53-789c-4924-b7c2-96032063ac2c.png)'
  id: totrans-661
  prefs: []
  type: TYPE_IMG
  zh: '![](img/29eadd53-789c-4924-b7c2-96032063ac2c.png)'
- en: Radviz plot explanation
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: Radviz 图解释
- en: The plot above can be obtained by running the snippet below.
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 上图可以通过运行下面的代码片段来获得。
- en: '[PRE118]'
  id: totrans-664
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'This results in the following output:'
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成以下输出：
- en: '![](img/0d7e97fb-4d6c-44ee-a265-6e41c7fd895c.png)'
  id: totrans-666
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0d7e97fb-4d6c-44ee-a265-6e41c7fd895c.png)'
- en: Radviz plot
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: Radviz 图
- en: Scatter matrix plot
  id: totrans-668
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 散点矩阵图
- en: 'A scatter matrix plot consists of several plots of variables, all of which
    are present in a matrix format. Basically, a 2 x 2 matrix of variables is created
    where each cell represents a combination of two variables. Then, a scatter plot
    is generated for each combination. It can be used to determine the correlation
    between variables. It is used in a lot of dimension reduction cases:'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 散点矩阵图由多个变量的图表组成，所有这些图表都以矩阵格式呈现。基本上，会创建一个 2 x 2 的变量矩阵，其中每个单元格表示两个变量的组合。然后，为每个组合生成一个散点图。它可以用来确定变量之间的相关性，广泛应用于维度缩减的情况：
- en: '[PRE119]'
  id: totrans-670
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'This results in the following output:'
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成以下输出：
- en: '![](img/e32e1878-bc5c-4c40-a6f0-19eeb6f9c660.png)'
  id: totrans-672
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e32e1878-bc5c-4c40-a6f0-19eeb6f9c660.png)'
- en: Scatter matrix plot
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 散点矩阵图
- en: Lag plot
  id: totrans-674
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 延迟图
- en: A lag plot is a special type of scatter plot with variables (X, X-lagged, and
    so on).
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟图是一种特殊类型的散点图，包含变量（X、X-滞后等）。
- en: 'X -lagged is the variable that''s derived from X with a time lag. The graph
    is plotted among two variables and the plot is used to determine the randomness,
    model suitability, outliers, and serial correlation in the data – especially time
    series data:'
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: X-滞后是由X衍生出的带时间滞后的变量。该图绘制了两个变量之间的关系，用于确定数据的随机性、模型适应性、异常值和序列相关性——特别是时间序列数据：
- en: '[PRE120]'
  id: totrans-677
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'This results in the following output:'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成以下输出：
- en: '![](img/68f06f9e-8f57-4809-b3a3-1bd8cf53baf8.png)'
  id: totrans-679
  prefs: []
  type: TYPE_IMG
  zh: '![](img/68f06f9e-8f57-4809-b3a3-1bd8cf53baf8.png)'
- en: Lag plot
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟图
- en: Bootstrap plot
  id: totrans-681
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自助法图
- en: A bootstrap plot is used to determine the uncertainty of statistics such as
    mean, median, midrange, and so on. It relies on the random sampling method with
    replacement. Calculating a statistic by randomly sampling from the same data multiple
    times and then averaging the individual result from each sample is called bootstrapping.
    A bootstrapping plot basically plots all the resultant values that were obtained
    from each random sample. It calculates the mean, median, and mode for all the
    samples and plots them as bar and line charts.
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 自助法图用于确定统计量的统计不确定性，例如均值、中位数、最小-最大值等。它依赖于带有替换的随机抽样方法。通过从同一数据中随机抽取多次样本并计算每次抽样的结果平均值，这一过程称为自助抽样。自助法图基本上绘制了从每个随机样本中得到的所有结果值。它计算所有样本的均值、中位数和众数，并将它们绘制为条形图和折线图。
- en: 'A random sample is selected from the data and the process is repeated a specified
    number of times to obtain the required metrics. The resulting plot that''s obtained
    is a bootstrap plot:'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据中选择一个随机样本，重复该过程若干次，以获得所需的指标。最终得到的图表就是一个自助法图：
- en: '[PRE121]'
  id: totrans-684
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'This results in the following output:'
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/fdd433ce-4e14-47e1-ad5a-40d2c899fec3.png)'
  id: totrans-686
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fdd433ce-4e14-47e1-ad5a-40d2c899fec3.png)'
- en: Lag plot
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟图
- en: pandas-datareader
  id: totrans-688
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: pandas-datareader
- en: We can use pandas to not only read data from local CSV or text files but also
    from various popular remote data sources such as Yahoo Finance, World Bank, and
    so on. Without any support from pandas, this would have been tedious and we would
    have to resort to web scraping. This simple and powerful functionality is provided
    through the `pandas-datareader`.
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用pandas不仅从本地CSV或文本文件中读取数据，还可以从各种流行的远程数据源中读取数据，如Yahoo Finance、世界银行等。如果没有pandas的支持，这将变得十分繁琐，我们可能不得不依赖网页抓取。通过`pandas-datareader`，这个简单且强大的功能得到了提供。
- en: It provides us with a direct way of connecting through various data sources
    from the comfort of the pandas ecosystem without having to delve into the complexity
    of HTML/JavaScript code where data is enmeshed. These data sources can be accessed
    by providing the source name and data code. Only a subset of the data can be obtained.
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: 它为我们提供了一种通过pandas生态系统直接连接到各种数据源的方式，无需深入HTML/JavaScript代码的复杂性，在这些代码中数据被嵌套。只需提供数据源名称和数据代码即可访问这些数据源，且仅能获取数据的一个子集。
- en: 'Let''s delve deeper and see how we can use it:'
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解，看看如何使用它：
- en: 'Install `pandas-datareader` through `pip` using the following command:'
  id: totrans-692
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下命令使用`pip`安装`pandas-datareader`：
- en: '[PRE122]'
  id: totrans-693
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: You can also install it through `conda` using the following  set of commands
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以通过以下命令集通过`conda`进行安装：
- en: 'First, we have to add `conda-forge` to our channel:'
  id: totrans-695
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要将`conda-forge`添加到我们的频道：
- en: '[PRE123]'
  id: totrans-696
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: 'After enabling `pandas-datareader`, it can be installed with the following
    code:'
  id: totrans-697
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用`pandas-datareader`后，可以使用以下代码进行安装：
- en: '[PRE124]'
  id: totrans-698
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: Now, let's get hands-on with some of the remote data sources and perform various
    functions provided by the pandas library to get an idea of how it works.
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们动手使用一些远程数据源，并通过pandas库提供的各种功能，了解它是如何工作的。
- en: Yahoo Finance
  id: totrans-700
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Yahoo Finance
- en: If you are interested in knowing about the trends of the business world and
    have a thirst to get updates about [stocks](https://money.howstuffworks.com/personal-finance/financial-planning/stocks.htm) and [bonds](https://money.howstuffworks.com/personal-finance/budgeting/bonds.htm),
    or if you are the one who has invested in them, then you may crave an update that
    occurs every minute. Google Finance is a financial website that was developed
    by Google that's made this straightforward by providing the required information
    and also letting us customize our needs according to our interests.
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对了解商业世界的趋势感兴趣，并渴望获取关于[股票](https://money.howstuffworks.com/personal-finance/financial-planning/stocks.htm)和[债券](https://money.howstuffworks.com/personal-finance/budgeting/bonds.htm)的最新动态，或者您是其中的投资者，您可能会渴望每分钟更新一次。Google
    Finance是由Google开发的一个金融网站，它通过提供所需的信息并允许我们根据兴趣自定义需求，使这一过程变得更加简便。
- en: Google's API became less reliable during 2017 and has become highly deprecated
    because of the unavailability of a stable replacement due to large breaks in the
    API.
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: 由于API中存在较大的中断，Google的API在2017年以后变得不那么可靠，并且由于没有稳定的替代品，已经变得高度弃用。
- en: An alternative to it is **Yahoo** Finance, which is similar to Google Finance,
    and is popular among users for its robust data and consistency.
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: 其替代方案是**Yahoo** Finance，它与Google Finance类似，并且因其强大的数据和一致性而在用户中颇受欢迎。
- en: Now let's use `pandas-datareader` to get information related to stocks, mutual
    funds, and anything related to finance using the Google Finance API.
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用`pandas-datareader`通过Google Finance API获取与股票、共同基金以及任何与金融相关的信息。
- en: '[PRE125]'
  id: totrans-705
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: 'The preceding code results in the following output:'
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将产生以下输出：
- en: '![](img/8c88926d-7f47-4230-b091-596d14be8e2e.png)'
  id: totrans-707
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8c88926d-7f47-4230-b091-596d14be8e2e.png)'
- en: Date filtered stock data for Apple, Google, Facebook, and Twitter
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: 苹果、谷歌、Facebook和Twitter的日期过滤股票数据
- en: '[PRE126]'
  id: totrans-709
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: 'This results in the following output:'
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/0845aa70-e0bd-489d-9f36-6bfc68a14f7c.png)'
  id: totrans-711
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0845aa70-e0bd-489d-9f36-6bfc68a14f7c.png)'
- en: Summary statistics of the stock data
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: 股票数据的汇总统计
- en: 'Take a look at the following code:'
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下代码：
- en: '[PRE127]'
  id: totrans-714
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'This results in the following output:'
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/f1b34b5d-8aca-4956-9ebb-42e4a4861bb4.png)'
  id: totrans-716
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f1b34b5d-8aca-4956-9ebb-42e4a4861bb4.png)'
- en: 'Take a look at the following code:'
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下代码：
- en: '[PRE128]'
  id: totrans-718
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: 'This results in the following output:'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得到以下输出：
- en: '![](img/d74262cf-8abb-48c4-8a9b-f2c91efecc78.png)'
  id: totrans-720
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d74262cf-8abb-48c4-8a9b-f2c91efecc78.png)'
- en: The preceding code will return a DataFrame that gives you full details about
    the stock prices for each and every day between the two dates for `Apple[AAPL]`,
    `Google[GOOGL]`, `FB[FB]`, and `Twitter[TWTR]`.
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将返回一个 DataFrame，提供`Apple[AAPL]`、`Google[GOOGL]`、`FB[FB]` 和 `Twitter[TWTR]`
    在这两个日期之间的每一天的股票价格详细信息。
- en: 'It is important to get to know your data before performing any kind of analysis.
    Please take the following things into account:'
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行任何分析之前，了解你的数据非常重要。请考虑以下几点：
- en: High is the highest price that the stock was traded for on that particular date.
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: High 是该特定日期股票的最高交易价格。
- en: Low is the lowest price that the stock was traded for on that particular date.
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Low 是该特定日期股票的最低交易价格。
- en: Open is the price that the stock was when the date started.
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Open 是该日期开始时股票的价格。
- en: Close is the price that the stock was when the market closed for that date.
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Close 是该日期市场收盘时的股票价格。
- en: Volume is the number of physical shares that were traded for that particular
    stock.
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Volume 是该特定股票的交易量，即交易的实际股票数量。
- en: Adj Close is the price that the stock was after the market closed.
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adj Close 是市场关闭后股票的价格。
- en: World Bank
  id: totrans-729
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 世界银行
- en: The World Bank is an organization that provides financial advice and helps various
    nations in terms of their economical state. It also provides a variety of data,
    including time series, geospatial, financial data, and so on, all of which will
    be helpful for analysis.
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: 世界银行是一个提供财务咨询并在经济状况方面帮助各国的组织。它还提供各种数据，包括时间序列、地理空间数据、财务数据等，这些都对分析非常有帮助。
- en: Before we start fetching data from the World Bank website, we must sign up to
    it. This allows us to get the indicator code for the dataset that we want to download.
    Signing up for the World Bank is free and doesn't take much time.
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始从世界银行网站获取数据之前，我们必须先注册。这允许我们获得我们想要下载的数据集的指标代码。注册世界银行是免费的，且不会占用太多时间。
- en: 'For the purpose of this example, I have used the World Development Indicators
    dataset. You can choose any dataset of your choice and start working on it:'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: 出于本示例的目的，我使用了世界发展指标数据集。你可以选择任何你喜欢的数据集并开始使用：
- en: '[PRE129]'
  id: totrans-733
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'To get the indicator code, select the Databank tab and choose Metadata Glossary
    from the list that''s displayed on the left-hand pane. You can find the indicator
    below each dataset, on the left-hand side of the panel (marked in red in the attached
    screenshot):'
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取指标代码，请选择 Databank 标签页，并从左侧面板中显示的列表中选择 Metadata Glossary。你可以在每个数据集下方的左侧面板找到该指标（在附图中用红色标出）：
- en: '![](img/cbf5065e-9268-4764-aff2-898397b13765.png)'
  id: totrans-735
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cbf5065e-9268-4764-aff2-898397b13765.png)'
- en: Indicator code for the dataset, which is required for fetching data
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的指标代码，用于获取数据
- en: '[PRE130]'
  id: totrans-737
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'The DataFrame is returned in a multi-index row format:'
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的 DataFrame 采用多重索引行格式：
- en: '[PRE131]'
  id: totrans-739
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'This results in the following output:'
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得到以下输出：
- en: '![](img/d8bb985a-5374-4ce0-a358-e528b1090bd5.png)'
  id: totrans-741
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d8bb985a-5374-4ce0-a358-e528b1090bd5.png)'
- en: Multi-indexed DataFrame output of the World Bank indicator data
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 世界银行指标数据的多重索引 DataFrame 输出
- en: 'Now, let''s display the data for one particular country, like so:'
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来展示一个特定国家的数据，如下所示：
- en: '[PRE132]'
  id: totrans-744
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: 'This results in the following output:'
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得到以下输出：
- en: '![](img/35220b81-cb9a-4a59-a420-71a2dcadc30c.png)'
  id: totrans-746
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35220b81-cb9a-4a59-a420-71a2dcadc30c.png)'
- en: Multi-indexed DataFrame output of the World Bank indicator data for one country.
    It becomes single indexed.
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: 世界银行指标数据的多重索引 DataFrame 输出，针对一个国家。它变为单重索引。
- en: 'We can also return the price inflation data related to only one particular
    year for a particular country, like so:'
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以仅返回一个特定年份的价格通货膨胀数据，如下所示：
- en: '[PRE133]'
  id: totrans-749
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: 'This results in the following output:'
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得到以下输出：
- en: '![](img/40efc2f1-f406-4a72-aa41-2ec6a597c839.png)'
  id: totrans-751
  prefs: []
  type: TYPE_IMG
  zh: '![](img/40efc2f1-f406-4a72-aa41-2ec6a597c839.png)'
- en: Data subsetted by both indices
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: 按两个索引子集化的数据
- en: Summary
  id: totrans-753
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'After reading this chapter, the following points have been observed:'
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完本章后，观察到以下几点：
- en: '`pandas` provides powerful methods so that we can read from and write to a
    variety of data structures and a variety of sources.'
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas` 提供了强大的方法，让我们可以从各种数据结构和多个数据源读取和写入数据。'
- en: The `read_csv` method in pandas can be used for reading CSV files, TXT files,
    and tables. This method has a multitude of arguments in order to specify delimiters,
    which rows to skip while reading, reading a file in smaller chunks, and so on.
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas 中的 `read_csv` 方法可以用来读取 CSV 文件、TXT 文件和表格。此方法有许多参数，用于指定分隔符、跳过的行、分块读取文件等。
- en: pandas can be used to read data directly from URLs or S3.
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas 可以用来直接从 URL 或 S3 中读取数据。
- en: DataFrames can be converted into JSON and vice versa. JSON can be stored in
    text files that can be read.
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrame 可以转换为 JSON，反之亦然。JSON 可以存储在文本文件中，并且可以读取。
- en: JSONs have dictionary-like structures that can be nested an infinite number
    of times. This nested data can be subsetted just like a dictionary with keys.
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JSON 具有类似字典的结构，可以无限次嵌套。这些嵌套数据可以像字典一样通过键进行子集提取。
- en: Pandas provide methods so that we can read data from the HD5, HTML, SAS, SQL,
    parquet, feather, and Google BigQuery data formats.
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas 提供了方法，允许我们从 HD5、HTML、SAS、SQL、parquet、feather 和 Google BigQuery 等数据格式中读取数据。
- en: Serialization helps in dumping data structures or objects to physical files,
    storing them in a database, or transmitting them through a message.
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列化有助于将数据结构或对象转储到物理文件中、存储到数据库，或通过消息进行传输。
- en: In the next chapter, we will learn how to access and select data from panda
    data structures. We will also look in detail at basic indexing and label-, integer-,
    and mixed indexing.
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何访问和选择 pandas 数据结构中的数据。我们还将详细讨论基本索引、标签索引、整数索引和混合索引。
