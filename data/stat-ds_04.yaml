- en: Data Mining and the Database Developer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据挖掘与数据库开发者
- en: This chapter introduces the data developer to mining (not to be confused with
    querying) data, providing an understanding of exactly what data mining is and
    why it is an integral part of data science.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向数据开发者介绍数据挖掘（与查询不同），并帮助理解什么是数据挖掘以及它为何是数据科学的核心组成部分。
- en: 'We''ll provide working examples to help the reader feel comfortable using R
    for the most common statistical data mining methods: dimensional reduction, frequent
    patterns, and sequences.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将提供工作示例，帮助读者熟悉使用R进行最常见的统计数据挖掘方法：维度约简、频繁模式和序列挖掘。
- en: 'In this chapter, we''ve broken things into the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将内容分为以下主题：
- en: Definition and purpose of data mining
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据挖掘的定义与目的
- en: Preparing the developer for data mining rather than data querying
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为数据挖掘而非数据查询准备开发者
- en: Using R for dimensional reduction, frequent patterns, and sequence mining
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用R进行维度约简、频繁模式和序列挖掘
- en: Data mining
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据挖掘
- en: It is always prudent to start explaining things with a high-level definition.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在解释事物时，从高层次的定义开始是明智的。
- en: Data mining can be explained simply as assembling information concerning a particular
    topic or belief in an understandable (and further useable) format. Keep in mind
    though that the information assembled is not the data itself (as with data querying)
    but information from the data (more on this later in this chapter).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘可以简单地解释为将有关特定主题或信念的信息整理成一种可理解（且可进一步使用）的格式。然而，需要记住的是，整理的信息并非数据本身（如数据查询），而是来自数据的信息（本章后面会详细讨论）。
- en: Data mining should also not be confused with analytics, information extraction,
    or data analysis. Also, it can be manual or by hand, a semi-automatic, or automatic
    process. When working with new data, it will typically be a manual process that
    the data scientist will perform. Later, when working with newer versions of the
    same data (source), it may become automated to some level or degree.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘也不应与分析、信息提取或数据分析混淆。此外，它可以是手动的、半自动的或自动化的过程。在处理新数据时，通常是由数据科学家手动进行的过程。后来，在处理相同数据（来源）的新版本时，可能会在某种程度上实现自动化。
- en: 'Data mining is the probing carried out by a data scientist to find previously
    unknown information within the data, such as:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘是数据科学家进行的一种探测，目的是在数据中发现以前未知的信息，例如：
- en: Patterns, such as groups of data records, known as **clusters**
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式，如一组数据记录，被称为**簇**
- en: Unusual records, known as **anomalies**
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不寻常的记录，被称为**异常值**
- en: Dependencies in the form of association rules or sequential patterns
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依赖关系，如关联规则或序列模式
- en: This new information (or insights) can be thought of as a kind of data summary
    and can be used in further analysis or, for example, in machine learning and predictive
    analytics. For example, with data mining, a data scientist might identify various
    groups that can then be used to obtain more accurate prediction results by a decision
    support system.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些新信息（或洞察）可以看作是一种数据总结，并可用于进一步分析，或例如在机器学习和预测分析中使用。例如，通过数据挖掘，数据科学家可能会识别出不同的组群，这些组群可以在决策支持系统中用于获得更准确的预测结果。
- en: Data developers can liken the insights derived from data mining to descriptive
    or structural metadata, which is understood within the industry as data that defines
    data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据开发者可以将从数据挖掘中得到的洞察类比为描述性或结构性元数据，这在行业中被理解为定义数据的数据。
- en: Once the probing is completed and the data scientist has mined the information,
    that information must then be transformed into a comprehensible and usable structure,
    given the objectives of the effort.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦探测完成，数据科学家已经挖掘出信息，这些信息必须根据工作目标转化为可理解且可用的结构。
- en: Data collection, data preparation, results from interpretation and visualization,
    and reporting is not part of data mining.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集、数据准备、解释和可视化的结果以及报告不属于数据挖掘的范畴。
- en: Common techniques
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见技术
- en: Some of the most common and widely accepted and used data mining (statistical)
    analysis methods are explained in the following sub-sections.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下小节解释了一些最常见且被广泛接受和使用的数据挖掘（统计）分析方法。
- en: Visualization
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化
- en: Visualization of averages, measures of variation, counts, percentages, cross-tabbing,
    and simple correlations help the data scientists in understanding the structure
    of the data. This is also referred to as **data profiling**.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值、变异度量、计数、百分比、交叉表格和简单相关性可帮助数据科学家理解数据结构。这也被称为**数据概况分析**。
- en: Area, temporal, multidimensional, and hierarchical are typical, commonly used,
    and easily understood formats for data visualization.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 区域、时间、 多维和层次化是常见且易于理解的数据可视化格式。
- en: Cluster analysis
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类分析
- en: Cluster analysis is used by the data scientists to place data variables into
    defined collections (that is, clusters) as a way of summarizing the data. Clusters
    should be both internally homogeneous (the variables are like one another) as
    well as externally heterogeneous (the variables are not like members of other
    clusters).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类分析被数据科学家用来将数据变量归入定义好的集合（即聚类），作为数据总结的一种方式。聚类应该在内部是同质的（变量之间相似），而在外部是异质的（变量与其他聚类中的成员不同）。
- en: Hierarchical agglomerative, partitioning, and model-based are all very common
    methods of cluster analysis.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚合法、划分法和基于模型的方法是常见的聚类分析方法。
- en: Correlation analysis
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关分析
- en: Correlation analysis is a method where the data scientists measure the relationship
    between two data variables. This results in something called a **correlation coefficient**,
    which shows if changes to one variable (the independent variable) will result
    in changes to the other (the dependent variable).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 相关分析是一种方法，数据科学家通过该方法衡量两个数据变量之间的关系。由此得出的结果被称为**相关系数**，它展示了一个变量（自变量）的变化是否会导致另一个变量（因变量）的变化。
- en: Common correlation approaches are positive/negative and linear and non-linear.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的相关性分析方法包括正相关/负相关、线性相关和非线性相关。
- en: Discriminant analysis
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 判别分析
- en: Discriminant analysis is used when there is no obvious natural ordering of groups
    to determine if a data variable is a member. With this method, there are predetermined
    groups with specific scores or measures that are used in the classification or
    grouping of the data variables process.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 判别分析用于在没有明显自然排序的群体情况下，判断数据变量是否属于某一类。使用这种方法时，预先设定好一些带有特定评分或度量的群体，并将其用于数据变量分类或分组过程中。
- en: '**Linear discriminant analysis** (**LDA**) is one of the most common approaches
    to discriminate analysis where the data scientist attempts to find a linear combination
    of features that characterize or separates a data variable (into groups).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性判别分析**（**LDA**）是最常见的判别分析方法之一，数据科学家尝试找到特征的线性组合，用于表征或区分数据变量（分成不同组）。'
- en: Factor analysis
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 因子分析
- en: Factor analysis is useful for understanding the reasons for the associations
    (amongst a group of data variables). The main goal is to try and reduce the number
    of variables and to detect structure in the relationships among them (this method
    also results in an overall data reduction).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 因子分析有助于理解数据变量之间关联的原因。其主要目标是减少变量的数量，并在它们之间的关系中检测结构（该方法也有助于整体数据的降维）。
- en: Types of factor analysis used by data scientists are the principal component,
    common, image, alpha, and factor regression.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家使用的因子分析类型包括主成分分析、公共因子分析、图像因子分析、阿尔法因子分析和因子回归分析。
- en: Regression analysis
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归分析
- en: Regression analysis uses the relationship between two or more quantitative variables
    so that one variable (dependent variable) can be predicted from the other(s) (independent
    variables).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析通过研究两个或多个定量变量之间的关系，使得可以根据其他变量（自变量）预测某个变量（因变量）的值。
- en: There are many kinds of regression analysis, including simple linear, multiple
    linear, curvilinear, and multiple curvilinear, as well as logistic regression
    models.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析有很多种类型，包括简单线性回归、多元线性回归、曲线回归和多重曲线回归，以及逻辑回归模型。
- en: Logistic analysis
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归分析
- en: A logistic analysis is a method that is used when the response variable is binary
    or qualitative and attempts to find a best fitting equation using a maximum likelihood
    method to maximize the probability of obtaining the observed results given the
    fitted regression coefficients.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归分析是一种用于响应变量是二元或定性的情况，旨在通过最大似然法找到一个最佳拟合方程，以最大化在已拟合回归系数的条件下得到观测结果的概率。
- en: Some of the common flavours that logistic regression comes in include simple,
    multiple, polytomous, and Poisson logistic regression models.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的常见类型包括简单逻辑回归、多重逻辑回归、多类别逻辑回归和泊松逻辑回归模型。
- en: Purpose
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目的
- en: Through the practice of data mining, a data scientist can achieve (the aforementioned)
    goal of deriving actionable information from long information or data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 通过数据挖掘的实践，数据科学家可以实现（前述）从大量信息或数据中提取可操作信息的目标。
- en: Some have said that the objective of data mining is to discover structure inside
    unstructured (data). For example, you might use data mining to identify customer
    segments to design a promotion targeting high-value customers or an inventory
    control plan to ensure short product shelf life.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 有人曾说数据挖掘的目标是发现无结构数据中的结构。例如，你可以使用数据挖掘来识别客户群体，以设计针对高价值客户的促销活动，或设计一个库存控制计划，以确保短期产品保质期。
- en: One might confuse data querying with data mining. But if we consider the example
    of generating a plan for controlling inventory at a newly opened home improvement
    store, then by simply querying sales transactions to determine the fastest selling
    products from the past few months (from other store locations), we might not be
    successful. Mining demographical information might, however, yield better results,
    as we might identify valid novel, potentially useful, and understandable correlations
    and patterns in the data, which can then be used to predict local consumer purchasing.
    In other words, the objective or purpose of data mining is not reporting but uncovering.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有人可能会混淆数据查询与数据挖掘。但如果我们考虑为新开设的家居改善商店生成库存控制计划的例子，仅通过查询销售交易记录来确定过去几个月（来自其他商店）的最畅销产品，可能不会成功。而挖掘人口统计信息可能会得出更好的结果，因为我们可能会识别出有效的新颖、潜在有用的可理解的关联和模式，这些模式可以用于预测当地消费者的购买行为。换句话说，数据挖掘的目标或目的不是报告，而是发现。
- en: In the next section, we'll take a closer look at the differences between data
    mining and data querying.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将更深入地探讨数据挖掘与数据查询之间的区别。
- en: Mining versus querying
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 挖掘与查询
- en: Data querying is the process of asking specific, structured questions of data
    in search of a specific answer, while data mining is the process of sifting through
    data to identify patterns and relationships using statistical algorithms.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据查询是提出具体、结构化问题来寻找特定答案的过程，而数据挖掘则是通过统计算法筛选数据，以识别模式和关系的过程。
- en: 'The following matrix may help the data developers in gaining an understanding
    of the differences between data querying and data mining:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下矩阵可以帮助数据开发人员理解数据查询与数据挖掘之间的区别：
- en: '| **Example** | **Data querying or mining** |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| **示例** | **数据查询或挖掘** |'
- en: '| What was the total number of technical books sold last month worldwide? |
    Data querying |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 上个月全球销售的技术书籍总数是多少？ | 数据查询 |'
- en: '| What factors affected the type of technical books sold worldwide last month?
    | Data mining |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 上个月影响全球销售的技术书籍类型的因素有哪些？ | 数据挖掘 |'
- en: '| How many different technologies'' technical books were sold last quarter?
    | Data querying |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 上个季度售出了多少种不同技术的技术书籍？ | 数据查询 |'
- en: '| Which technologies were purchased as part of a set? | Data mining |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 哪些技术是作为一套书籍购买的？ | 数据挖掘 |'
- en: '| Does a technology tend to be purchased in hardcopy or electronic version?
    | Data mining |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 一项技术是倾向于购买纸质版还是电子版？ | 数据挖掘 |'
- en: '| Which technical books have repeat customers? | Data mining |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 哪些技术书籍有重复购买的客户？ | 数据挖掘 |'
- en: '| Which is the most sold technical book overall? | Data querying |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 哪本技术书籍是总体销售量最高的？ | 数据查询 |'
- en: Once again, data querying is about reporting the results of events while data
    mining is the process of identifying relationships that may help to understand
    which factors affected the outcome of those events, or they may be used to predict
    future outcomes of similar events.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，数据查询是报告事件结果，而数据挖掘则是识别可能有助于理解哪些因素影响了这些事件结果的关系的过程，或者这些关系可以用于预测类似事件的未来结果。
- en: Choosing R for data mining
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择 R 进行数据挖掘
- en: Although there are many good options to choose from, R is a language and environment
    that has a short learning curve, is very flexible in nature, and is also very
    focused on statistical computing, making it great for manipulating, cleaning,
    summarizing, producing probability statistics, and so on (as well as actually
    creating visualizations with your data); thus, it's a great choice for the exercises
    data mining.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有很多不错的选择，R 是一种学习曲线较短、非常灵活、且专注于统计计算的语言和环境，非常适合用于数据操作、清洗、总结、生成概率统计等（以及使用数据实际创建可视化）；因此，它是进行数据挖掘练习的极佳选择。
- en: 'In addition, here are a few more reasons to learn and use R for data mining
    projects:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这里还有一些学习和使用R进行数据挖掘项目的更多理由：
- en: R is used by a large number of academic statisticians, so it's a tool that is
    not going away
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R被大量学术统计学家使用，所以它是一个不会消失的工具。
- en: R is pretty much platform independent; what you develop will run almost anywhere
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R几乎是平台独立的；你开发的内容几乎可以在任何地方运行。
- en: R has awesome help resources. Just google it and you'll see!
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R有很棒的帮助资源，只需谷歌一下，你就能看到！
- en: To illustrate, we'll explore a few practical data mining examples using the
    R programming language throughout the rest of this chapter.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，我们将在本章的其余部分探索几个使用R编程语言的实际数据挖掘例子。
- en: Visualizations
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化
- en: 'To begin, let''s look at creating a simple visualization of our data, using
    R. In this use case scenario, we have data collected from a theoretical hospital,
    whereupon admission, patient medical history information is collected through
    an online survey. Information is also added to a patient''s file as treatment
    is provided. The file includes many fields, including:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们来看一下如何使用R创建一个简单的数据可视化。在这个使用场景中，我们有来自理论医院的数据，患者在入院时通过在线调查收集病史信息，并在治疗过程中将信息添加到患者档案中。文件包括许多字段，其中包括：
- en: Basic descriptive data for the patient, such as sex, date of birth, height,
    weight, blood type, and so on
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 患者的基本描述数据，例如性别、出生日期、身高、体重、血型等。
- en: Vital statistics, such as blood pressure, heart rate, and so on
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生命体征，例如血压、心率等。
- en: Medical history, such as number of hospital visits, surgeries, major illnesses
    or conditions, is currently under a doctor's care, and so on
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 病史，如住院次数、手术、重大疾病或病情、是否在医生治疗下等。
- en: Demographical statistics, such as occupation, home state, educational background,
    and so on
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口统计学统计数据，例如职业、家乡、教育背景等。
- en: Some additional information is also collected in the file to develop patient
    characteristics and habits, such as the number of times the patient included beef,
    pork, and fowl in his or her weekly diet, if he or she typically uses a butter
    replacement product, and so on
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件中还收集了一些额外的信息，用于开发患者的特点和习惯，例如患者每周饮食中牛肉、猪肉和家禽的摄入次数，是否通常使用黄油替代品等。
- en: Assuming we have been given no further information about the data (other than
    a brief field name list and the knowledge that the data is captured by hospital
    personnel upon patient admission), the next step would be to perform some data
    mining, that is identifying or grouping data and perhaps locating relationships
    between the variables.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们没有得到关于数据的更多信息（除了简要的字段名称列表以及数据是由医院人员在患者入院时采集的），接下来的步骤是进行一些数据挖掘，即识别或分组数据，并可能查找变量之间的关系。
- en: 'To get started, we can read out hospital survey data into an R data frame and
    then use two available R functions to reveal information about our file:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，我们可以将医院调查数据读入R数据框架，然后使用两个可用的R函数来揭示文件中的信息：
- en: '![](img/950b0084-7b4d-4367-949b-3883f928494a.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/950b0084-7b4d-4367-949b-3883f928494a.png)'
- en: The code shown here reads our text file (named `Chapter4.txt`) into an R data
    frame (also named `chapter4`) and then uses the functions `dim` and `names`. The
    `dim` function shows us the file's data structure (there are `5994` records or
    cases in this file and `107` data points or variables, as shown in the screenshot
    we just saw). The `names` function simply lists all the field or variable names
    in our file (partially shown in the screenshot we just saw).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显示的代码将我们的文本文件（名为`Chapter4.txt`）读取到R数据框架中（也名为`chapter4`），然后使用`dim`和`names`函数。`dim`函数展示了文件的数据结构（此文件中有`5994`条记录或案例，以及`107`个数据点或变量，如我们刚才看到的截图所示）。`names`函数则列出了文件中所有字段或变量的名称（部分名称在我们刚才看到的截图中显示）。
- en: R function attributes and `str` are also some very useful R data mining functions
    and would be worth the readers' time to investigate and experiment with further.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: R函数属性和`str`也是一些非常有用的R数据挖掘函数，值得读者花时间深入研究并进行实验。
- en: Initially, a data scientist might begin by looking through the field names for
    some ideas to start with; perhaps the common groups, such as sex, age, and state
    (insured is also a pretty interesting attribute these days!).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，数据科学家可能会通过查看字段名称来寻找一些初步的思路；例如，常见的分组项，如性别、年龄和州（如今“是否投保”也是一个非常有趣的属性！）。
- en: Current smokers
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当前吸烟者
- en: 'Often, a data scientist has an objective in mind when performing data mining.
    So in this example, let''s suppose we are interested in grouping patients who
    are smokers into age groups. Using the variable `current_smoker`, we can use the
    R table function and run the following code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，数据科学家在进行数据挖掘时会有一个目标。在这个例子中，假设我们有兴趣将吸烟患者分成不同的年龄组。使用`current_smoker`变量，我们可以使用R的table函数并运行以下代码：
- en: '[PRE0]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This yields the following information:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下信息：
- en: '![](img/31da38d7-af84-4551-8b2a-015d5a9b1d39.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/31da38d7-af84-4551-8b2a-015d5a9b1d39.png)'
- en: From the results shown here, it seems like we have more non-smokers (`5466`)
    than smokers (`528`), at least in this file or population.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里显示的结果来看，似乎我们有更多的非吸烟者（`5466`）而不是吸烟者（`528`），至少在这个文件或人群中是这样。
- en: 'Next, what we''d like to see (that is, visualize) is the smoker patients in
    our population organized into (or by) age groups. To do this, a logical next step
    as a data scientist would be to understand the `range` of values present in the
    `age` variable. In other words, part of our data mining effort will be to see
    the age of the youngest patient, as well as the age of the oldest patient, within
    our population. Rather than having to slice and dice the data to find this information,
    we can use the R range function, as shown in the following screenshot:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们想看到的（即可视化）是将我们人群中的吸烟患者按年龄组进行组织。为此，数据科学家的下一步逻辑应该是了解`age`变量中的`range`值。换句话说，我们的数据挖掘工作的一部分将是查看我们人群中最年轻患者的年龄以及最年长患者的年龄。我们不需要通过切片和筛选数据来查找这些信息，可以使用R的range函数，如下所示：
- en: '![](img/63fac424-9842-4140-be51-90b52d3dac33.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/63fac424-9842-4140-be51-90b52d3dac33.png)'
- en: 'From these results, the data scientist can now see that we have cases with
    patient ages ranging from 1 to 99 years! Another good idea would be to visualize
    the frequency of the ages of our patients. The data scientist might want to again
    use the R table function to create a histogram:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些结果中，数据科学家现在可以看到我们有患者年龄从1岁到99岁的病例！另一个好主意是可视化我们患者年龄的频率。数据科学家可能希望再次使用R的table函数来创建一个直方图：
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output of the preceding code is:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出结果是：
- en: '![](img/876062c3-b0f2-4597-9d7c-f9ce1fe997df.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/876062c3-b0f2-4597-9d7c-f9ce1fe997df.png)'
- en: 'This R code will generate the following visualization, which provides, even
    more, visibility to our patients'' ages:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这段R代码将生成以下可视化图表，进一步展示我们患者的年龄分布：
- en: '![](img/19b94e0e-09b7-4773-bdac-4cd0b846e07f.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/19b94e0e-09b7-4773-bdac-4cd0b846e07f.png)'
- en: Another interesting bit of information is density estimation. Without much effort,
    we can nest the three R functions, `plot`, `density`, and `table`, to create another
    visual of patient age.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的信息是密度估计。通过不太复杂的操作，我们可以将三个R函数`plot`、`density`和`table`嵌套在一起，创建另一个患者年龄的可视化图表。
- en: 'We can run the following code:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以运行以下代码：
- en: '![](img/66d1d045-173a-4da2-84d4-132131283177.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/66d1d045-173a-4da2-84d4-132131283177.png)'
- en: 'This will generate the following visualization:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下可视化图表：
- en: '![](img/a607895f-588a-421b-995d-d3d159b5078a.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a607895f-588a-421b-995d-d3d159b5078a.png)'
- en: 'Given all this new-found knowledge, perhaps the data scientist will want to
    go ahead and group our cases into six distinct age groups:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于所有这些新获得的知识，也许数据科学家会想继续将我们的病例分成六个不同的年龄组：
- en: Under 22
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 22岁以下
- en: 22 to 34
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 22到34岁
- en: 35 to 44
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 35到44岁
- en: 45 to 54
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 45到54岁
- en: 55 to 64
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 55到64岁
- en: 65 and older
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 65岁及以上
- en: To begin speaking the language of the data scientist, the data developer should
    start using the word cases rather than records (in the file) and population rather
    than the file.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始使用数据科学家的术语，数据开发者应该开始使用“病例”而不是“记录”（在文件中），使用“人群”而不是“文件”。
- en: 'The following R program code groups our cases into current smokers by their
    recorded age and then creates a simple pie chart to visualize the results:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以下R程序代码根据记录的年龄将我们的病例按当前吸烟者进行分组，并创建一个简单的饼图来可视化结果：
- en: '[PRE2]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following is our simple pie chart generated by using the R `pie` function:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们使用R `pie`函数生成的简单饼图：
- en: '![](img/845383f3-5fb7-4068-b846-c48a87672a67.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/845383f3-5fb7-4068-b846-c48a87672a67.png)'
- en: Missing values
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺失值
- en: Critical to the outcome of any analysis is the availability of data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 任何分析结果的关键是数据的可用性。
- en: Suppose there are cases within our population that have values that are missing.
    You may want to ignore (or omit) those cases in your analysis. Rather than spending
    time writing code to deal with these cases, you can use the handy R generic function
    `na`. The `na.omit` function evaluates each case in your file and if it is missing
    any values for any of the variables, it drops that case automatically.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在我们的数据集中有一些案例缺少值。你可能希望在分析中忽略（或省略）这些案例。与其花时间编写代码来处理这些案例，不如使用 R 的通用函数`na`。`na.omit`函数会评估文件中的每个案例，如果某个案例在任何变量上都有缺失值，它会自动删除该案例。
- en: 'The following example shows the use of the R functions `na.omit` and `nrow`
    on a file with missing values:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了 R 函数`na.omit`和`nrow`在一个包含缺失值的文件上的使用：
- en: '![](img/87268f9b-8acb-49d2-a27a-671ee5bc0956.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/87268f9b-8acb-49d2-a27a-671ee5bc0956.png)'
- en: Note the row (case) count before and after the use of `na.omit` (five records
    were dropped).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意使用`na.omit`前后行（案例）数量的变化（删除了五条记录）。
- en: I've overwritten the object `Chapter4` with the updated file; in reality, it
    is a good habit to create a new object so that you have an audit of your data
    before and after any processing.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经用更新的文件覆盖了对象`Chapter4`；实际上，养成创建新对象的好习惯是很有益的，这样在任何处理前后都能保留数据的审计记录。
- en: A cluster analysis
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类分析
- en: 'In this next example, the data scientist wants to take a closer look at our
    cases, but only those that are smokers. So, with R, let''s first create a subset
    of our original cases, including only those cases that are current smokers. As
    we did in the previous example, after we create our subset (named `mysub`), we
    will use the R `nrow` function to verify the number of records in our new population,
    so that we can get an idea of the number of cases in our new population:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个示例中，数据科学家希望更仔细地查看我们的案例，但只关注那些吸烟者。所以，我们在 R 中首先创建一个原始案例的子集，只包含那些当前吸烟的案例。和之前的例子一样，在创建子集（命名为`mysub`）后，我们将使用
    R 的`nrow`函数验证我们新数据集中的记录数，以便了解新数据集中的案例数量：
- en: '[PRE3]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output of the preceding code is:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出是：
- en: '![](img/d05eac96-f095-4229-98cf-502e1c5fefc9.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d05eac96-f095-4229-98cf-502e1c5fefc9.png)'
- en: As per the output we just saw, there are still over 500 cases in our new population.
    So, as a data scientist, we make the decision to pull a random sample of our cases
    (which we will then perform a cluster analysis on) and then, again, validate the
    number of records in our newest population.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们刚刚看到的输出，我们的新数据集仍然有超过500个案例。因此，作为数据科学家，我们决定从我们的案例中随机抽取一部分样本（我们将对其进行聚类分析），然后再次验证我们最新数据集中的记录数。
- en: 'We can use the R `sample` command to create a sample of just 30 cases:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 R 的`sample`命令来创建仅包含30个案例的样本：
- en: '[PRE4]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output of the preceding code is:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出是：
- en: '![](img/9fd427d2-4235-486e-9f54-b6b0c9f402f6.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9fd427d2-4235-486e-9f54-b6b0c9f402f6.png)'
- en: Finally, our data scientist feels that he now has a small enough sampling of
    our cases that is easy enough to work with, so let's go ahead and perform a cluster
    analysis with it. As mentioned earlier in this chapter, hierarchical agglomerative
    is one of the most popular cluster analysis techniques, and so we will use it
    with our random sample of cases.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们的数据科学家觉得现在他已经有了足够小的样本，足以进行处理，所以我们继续用这个样本进行聚类分析。如本章前面提到的，层次聚合聚类是最流行的聚类分析技术之一，因此我们将使用它来处理我们随机抽样的案例。
- en: We can perform the hierarchical agglomerative cluster analysis of our random
    sample of cases using a combination of the R's `dist` and `hclust` functions.
    The `dist` function calculates a distance matrix for your dataset, giving the
    Euclidean distance between any two observations. The `hclust` function performs
    hierarchical clustering on that distance matrix.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 R 的`dist`和`hclust`函数组合对我们随机抽样的案例进行层次聚合聚类分析。`dist`函数计算数据集的距离矩阵，给出任意两条观察值之间的欧几里得距离。`hclust`函数则在该距离矩阵上执行层次聚类。
- en: 'In conclusion, the easiest way to review and understand the results of a hierarchical
    cluster analysis is through visualization of the results. This visualization is
    known as a **dendrogram** (a tree diagram frequently used to illustrate the arrangement
    of the clusters), so we''ll add that code as well:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，回顾和理解层次聚类分析结果的最简单方式是通过结果的可视化。这个可视化通常被称为**树状图**（一种常用于说明聚类安排的树形图），所以我们也会添加这段代码：
- en: '[PRE5]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output of the preceding code is:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出是：
- en: '![](img/48739aaa-fd9f-4b8a-b6fe-1c04ef942a5b.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/48739aaa-fd9f-4b8a-b6fe-1c04ef942a5b.png)'
- en: 'This code sample creates the following visualization:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码示例创建了以下可视化：
- en: '![](img/9ddf3744-4d87-44f5-a1f1-ae718bbb2ab1.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ddf3744-4d87-44f5-a1f1-ae718bbb2ab1.png)'
- en: R offers a long list of options for creating rich visualizations based upon
    data and statistics. It is important for a data scientist to be familiar with
    these options and, perhaps more importantly, understand which type of visualization
    best fits the objective of the analysis.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: R提供了一个长长的选项列表，可以根据数据和统计信息创建丰富的可视化图表。对数据科学家来说，熟悉这些选项非常重要，也许更重要的是理解哪种可视化图表最适合分析的目标。
- en: Dimensional reduction
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 降维
- en: Clustering is intended to group data variables that are found to be interrelated,
    based on observations of their attributes' values. However, given a scenario with
    a large number of attributes, the data scientist will find that some of the attributes
    will usually not be meaningful for a given cluster. In the example, we used earlier
    in this chapter (dealing with patient cases), we could have found this situation.
    Recall that we performed a hierarchical cluster analysis on smokers only. Those
    cases include many attributes, such as, sex, age, weight, height, no_hospital_visits,
    heartrate, state, relationship, Insurance blood type, blood_pressure, education,
    date of birth, current_drinker, currently_on_medications, known_allergies, currently_under_doctors_care,
    ever_operated_on, occupation, heart_attack, rheumatic_fever, heart_murmur, diseases_of_the_arteries,
    and so on.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是旨在基于对属性值的观察，将相关的数据变量分组。然而，考虑到有大量属性的场景，数据科学家会发现，一些属性通常对某个特定的聚类来说没有意义。在我们之前本章中使用的示例（处理病人病例）中，可能会遇到这种情况。回想一下，我们对吸烟者进行了层次聚类分析。那些案例包括许多属性，如性别、年龄、体重、身高、就诊次数、心率、州、关系、保险、血型、血压、教育、出生日期、是否为当前饮酒者、是否正在服药、已知过敏症、是否正在接受医生照护、是否曾做过手术、职业、心脏病发作、风湿热、心脏杂音、动脉疾病等。
- en: As a data scientist, you can use the R function `names`, as we did earlier in
    this chapter, to see the complete list of attributes.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，你可以使用R函数`names`，就像我们在本章前面所做的那样，查看所有属性的完整列表。
- en: Dimensional reduction is a process where the data scientist attempts to reduce
    or limit the number of attributes, or dimensions, within a case. This is referred
    to as reducing the number of random variables under consideration, but what that
    translates to is simply removing columns from a data file, based upon scientific
    theory.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 降维是一个过程，数据科学家尝试减少或限制一个案例中的属性（或维度）数量。这被称为减少考虑中的随机变量数量，但实际上就是根据科学理论，从数据文件中移除某些列。
- en: 'Currently accepted and commonly used approaches to eliminating dimensions include:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当前接受和常用的去除维度的方法包括：
- en: 'Missing data: If a variable (column) has many cases (records) with no values,
    it is not going to add much value; therefore, the column can be removed.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失数据：如果某个变量（列）有很多没有值的案例（记录），它不会增加太多的价值；因此，该列可以被删除。
- en: Remember, earlier in this chapter, we used the R function `na.omit`. This function
    comes in handy for removing entire cases; however, with dimensional reduction,
    we want to omit the entire variable for all cases.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记住，在本章前面，我们使用了R函数`na.omit`。这个函数在删除整个案例时非常有用；然而，使用降维时，我们想要为所有案例删除整个变量。
- en: 'Little variance: Like a variable having a great number of missing values, variables
    with little variation do not add value and can be removed.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小方差：像变量有大量缺失值一样，方差小的变量没有增加价值，也可以被删除。
- en: 'High correlation: Data columns with very similar trends are also likely to
    carry very similar information. In this case, only one of them is needed.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高度相关性：具有相似趋势的数据列也可能携带非常相似的信息。在这种情况下，只需要其中一个。
- en: 'Decision trees: It is a technique that may require a bit more work. It is an
    approach to dimensionality reduction where the data scientist generates a set
    of decision trees against a target attribute and then uses each attribute''s usage
    statistics to find the most informative features (or columns). The columns with
    the lowest statistics may be dropped.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树：这是一种可能需要更多工作的方法。它是一种降维技术，数据科学家通过针对目标属性生成一组决策树，然后利用每个属性的使用统计数据，找出最有信息量的特征（或列）。使用统计数据最少的列可以被删除。
- en: '**Principal component analysis** (**PCA**): It is a process that transforms
    variables in a dataset into a new set of variables called **principal components**.
    The components are ordered by the variables'' possible variance and only those
    with the highest variance are kept.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主成分分析**（**PCA**）：它是一个过程，将数据集中的变量转换为一组新的变量，称为**主成分**。这些成分按变量的可能方差排序，只有那些方差最高的成分才会被保留。'
- en: 'Backward elimination and forward construction: These techniques involve focusing
    on one or more variables, and sequentially removing or adding one additional variable
    at a time and observing the effect. Backward elimination measures effect with
    a tolerable error rate, while forward construction measures by the effect on performance.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后向消除法和前向构造法：这些技术涉及集中关注一个或多个变量，并按顺序一个一个地去除或添加额外的变量并观察其效果。后向消除法通过可接受的误差率来衡量效果，而前向构造法则通过对性能的影响来衡量效果。
- en: Calculating statistical significance
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算统计显著性
- en: Let's now look at a simple example of using a data variables calculated variance
    to determine if it should be removed from an analysis.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一个简单的例子，使用数据变量计算出的方差来决定它是否应该从分析中移除。
- en: Again, using our same patient cases example that we've used throughout this
    chapter, we can use the R function `var` to determine the statistical significance
    of the variables within our population.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 再次使用我们在本章中一直使用的患者案例例子，我们可以使用R函数`var`来确定我们人群中变量的统计显著性。
- en: The R function `var` only works with numeric values.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: R函数`var`仅适用于数值型数据。
- en: 'In the next code, we use the R `var` function to calculate the variance of
    the variable named:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们使用R函数`var`来计算名为的变量的方差：
- en: '[PRE6]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can see that it has a low variance percentage (it doesn''t vary often or
    is not found to have many different values, case by case):'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，它有一个较低的方差百分比（它变化不频繁，或者在不同的案例中没有很多不同的值）：
- en: '![](img/75c4e61f-31b4-4065-b509-fb90f93a9c70.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/75c4e61f-31b4-4065-b509-fb90f93a9c70.png)'
- en: 'If we look at the calculated variance percentage of yet another variable, this
    one named: `No_servings_per_week_regular_or_diet_soda`, we see that it has a higher
    calculated variance (than the previous variable):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看另一个变量的计算方差百分比，名为：`No_servings_per_week_regular_or_diet_soda`，我们会发现它的计算方差（比前一个变量）更高：
- en: '![](img/361f94a8-c1d3-454e-83d2-682bd8f1d3c2.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/361f94a8-c1d3-454e-83d2-682bd8f1d3c2.png)'
- en: 'And finally, if we look at a third variable, this one named `No_servings_per_week_water`,
    we get a third calculated variance:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果我们看一个第三个变量，名为`No_servings_per_week_water`，我们得到第三个计算出的方差：
- en: '![](img/4cb8fc1e-7e8f-4461-8ea9-dca10adf3eaf.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4cb8fc1e-7e8f-4461-8ea9-dca10adf3eaf.png)'
- en: 'From these individual variance calculations, we can see how statistically significant
    each of these variables may be in our case analysis:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些单独的方差计算中，我们可以看到每个变量在我们案例分析中的统计显著性：
- en: '| **Data Variable** | **Calculated Variance** |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| **数据变量** | **计算出的方差** |'
- en: '| `No_servings_per_week_skim_milk` | .003160316 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| `No_servings_per_week_skim_milk` | .003160316 |'
- en: '| `No_servings_per_week_regular_or_diet_soda` | 8.505655 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| `No_servings_per_week_regular_or_diet_soda` | 8.505655 |'
- en: '| `No_servings_per_week_water` | 24.10477 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| `No_servings_per_week_water` | 24.10477 |'
- en: The data variable named `No_servings_per_week_skim_milk` could be certainly
    eliminated from the analysis, and depending upon our data scientists tolerance
    levels, possibly the data variable named `No_servings_per_week_regular_or_diet_soda`
    could be eliminated from our analysis as well.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 名为`No_servings_per_week_skim_milk`的数据变量可以肯定地从分析中剔除，并且根据我们的数据科学家容忍度，名为`No_servings_per_week_regular_or_diet_soda`的数据变量也可能会被从分析中剔除。
- en: 'Using simple R functions, we can visualize our calculated variance data for
    a better understanding:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用简单的R函数，我们可以可视化我们计算出的方差数据，以便更好地理解：
- en: '![](img/a95c2d43-5c75-44d5-ac74-b9dad173e743.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a95c2d43-5c75-44d5-ac74-b9dad173e743.png)'
- en: 'So, we generate the following visualization:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们生成以下可视化：
- en: '![](img/6ba20498-03cb-40ec-9a11-647e77adff0f.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6ba20498-03cb-40ec-9a11-647e77adff0f.png)'
- en: When we eliminate a variable, it is eliminated from all cases within our population.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们去除一个变量时，它会从我们所有的案例中被移除。
- en: Frequent patterning
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高频模式
- en: To gain an understanding of statistical patterning, let us begin with thinking
    about what happens when an urban area is threatened by severe weather and potentially
    hazardous traveling—all the local stores sell out of bread, milk, and eggs!
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解统计模式，让我们首先思考一下当城市地区受到严重天气和潜在危险的旅行威胁时会发生什么——所有本地商店都抢购面包、牛奶和鸡蛋！
- en: Patterning (which is a subfield of data mining) is the process of looking through
    data in an effort to identify previously unknown but potentially useful patterns
    consisting of frequently co-occurring events (such as the stormy weather event
    triggering the sale of bread, milk, and eggs) or objects (such as the products
    bread, milk, and eggs being typically purchased together or bundled together in
    the same shopping cart).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 模式挖掘（数据挖掘的一个子领域）是通过查看数据来识别以前未知但可能有用的模式的过程，这些模式通常由频繁同时发生的事件（例如暴风雨天气触发面包、牛奶和鸡蛋的销售）或对象（例如面包、牛奶和鸡蛋通常一起购买或在同一个购物车中捆绑在一起）组成。
- en: Pattern mining is the process that consists of using or developing custom pattern
    mining logic. This logic might be applied to various types of data sources (such
    as transaction and sequence databases, streams, strings, spatial data, graphs,
    and so on) in an effort to look for various types of patterns.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 模式挖掘是指使用或开发自定义模式挖掘逻辑的过程。该逻辑可能应用于各种类型的数据源（如交易和序列数据库、流数据、字符串、空间数据、图形等），以便查找各种类型的模式。
- en: 'At a higher level, data scientists look for:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在更高层次上，数据科学家寻找：
- en: Interesting patterns
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有趣的模式
- en: Frequent patterns
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频繁模式
- en: Rare patterns
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稀有模式
- en: Patterns with a high confidence
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高置信度模式
- en: The top patterns, and others
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶级模式，以及其他模式
- en: 'Some of the more specific types of patterns that may exist in data include:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一些可能存在于数据中的更具体的模式类型包括：
- en: '**Subgraphs**: The discovery of an interesting graph(s) within a graph or in
    a set of graphs'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子图**：在图或一组图中发现一个有趣的图形'
- en: '**Direct and indirect associations**: Identifying couplings or dependencies
    between objects or events; either implicit or explicit defined'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直接和间接关联**：识别对象或事件之间的耦合或依赖关系；可以是隐式或显式定义的'
- en: '**Trends**: This is also sometimes known as trend analysis, and is the practice
    of collecting seemingly unrelated information and attempting to spot a pattern'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**趋势**：这也有时称为趋势分析，是收集看似无关的信息并尝试找出模式的实践'
- en: '**Periodic patterns**: This is defined as a trend or change in the character
    of an element, either across a period or group'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**周期性模式**：定义为元素在一个周期或组中，特征的变化或趋势'
- en: '**Sequential rules**: This is an add-on to sequential pattern mining, taking
    into account the probability that an identified pattern will be followed'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**序列规则**：这是对序列模式挖掘的扩展，考虑了一个已识别模式被跟随的概率'
- en: '**Lattices**: A partially ordered set in which every two elements have a unique
    least upper bound and a unique greatest lower bound'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**格**：一个部分有序的集合，其中每两个元素都有一个唯一的最小上界和唯一的最大下界'
- en: '**Sequential patterns**: A subsequence that appears in several sequences of
    a data'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**序列模式**：出现在多个数据序列中的子序列'
- en: '**High-utility patterns**: High utility patterns are those patterns that have
    been determined to have higher, greater, or equal to a threshold value'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效模式**：高效模式是指那些已被确定为具有较高、较大或等于阈值的模式'
- en: Frequent item-setting
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 频繁项集
- en: Building on the idea in the previous section (of finding frequent patterns)
    is frequent item-setting. To the data developer, by far the most applicable patterning
    concept is that of frequent item-setting or finding items that are found to be
    frequently a member of a group or set.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节（寻找频繁模式）的基础上，频繁项集是一个扩展概念。对于数据开发者来说，最适用的模式概念是频繁项集或查找经常作为一组或集合成员出现的项。
- en: Using our stormy weather example from earlier in this chapter, one can envision
    the process of searching through a file or database of sales transactions, looking
    for the occasion (that is, the event) where milk, bread, and eggs were purchased
    together as one sale (or one set of products).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以我们前面章节中的暴风雨天气为例，可以设想通过查找销售交易文件或数据库中的过程，寻找那些在一次销售中（或一组产品中）一起购买牛奶、面包和鸡蛋的情形（即事件）。
- en: Frequent item setting also involves determining a minsup or minimum supported
    threshold to be used within an analysis. What this means is that the data scientist
    will determine the minimum occurrence of items that constitute a set.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 频繁项集还涉及确定在分析中使用的最小支持度（minsup）阈值。这意味着数据科学家将确定构成一个集的项的最小出现次数。
- en: Again, going back to our stormy weather example, if the data scientist sets
    a minsup of two to be used, then sales, where just two of the member products
    exist, would be considered a set or pattern.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 再次回到我们暴风雨天气的例子，如果数据科学家设置最小支持度为2，那么仅有两个成员商品的销售将被视为一个集合或模式。
- en: 'Let us consider the following sales transactions:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下销售交易：
- en: '| **Sales ID** | **Items Purchased** | **Qualifies (as a Frequent Item set)**
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| **销售ID** | **购买商品** | **是否符合（作为频繁项集）** |'
- en: '| Sale 1 | Milk, Bread, Eggs | Yes |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 销售 1 | 牛奶，面包，鸡蛋 | 是 |'
- en: '| Sale 2 | Milk, Potatoes | No |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 销售 2 | 牛奶，土豆 | 否 |'
- en: '| Sale 3 | Bread, Eggs, Tea | Yes |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 销售 3 | 面包，鸡蛋，茶 | 是 |'
- en: '| Sale 4 | Eggs, Orange Juice | No |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 销售 4 | 鸡蛋，橙汁 | 否 |'
- en: The most known algorithm for pattern mining, without a doubt, is Apriori, designed
    to be applied to a transaction database to discover patterns in transactions made
    by customers in stores. This algorithm takes as input a minsup threshold set by
    the user and a transaction database containing a set of transactions and outputs
    all the frequent item-sets.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的模式挖掘算法无疑是Apriori，它旨在应用于事务数据库，用于发现客户在商店中进行交易时的模式。该算法以用户设置的最小支持度（minsup）阈值和包含一组事务的事务数据库作为输入，并输出所有频繁项集。
- en: Sequence mining
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列挖掘
- en: Sequence mining evolves the preceding concepts even further. This is a process
    that the data scientist uses to discover a set of patterns that are shared among
    objects but which also have between them a specific order.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 序列挖掘进一步发展了前述概念。这是一个过程，数据科学家用它来发现一组在对象之间共享的模式，并且这些模式之间有特定的顺序。
- en: With sequence mining, we acknowledge that there are sequence rules associated
    with identified sequences. These rules define the pattern's objects and order.
    A sequence can have multiple rules. The support of a sequence rule can be calculated
    or determined by the data scientist by the number of sequences containing the
    rule divided by the total number of sequences. The confidence of a sequence rule
    will be the number of sequences containing the rule divided by the number of sequences
    containing its antecedent.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在序列挖掘中，我们认识到有与已识别序列相关的序列规则。这些规则定义了模式的对象和顺序。一个序列可以有多个规则。序列规则的支持度可以通过数据科学家计算，方法是将包含该规则的序列数量除以总序列数。序列规则的置信度则是将包含该规则的序列数除以包含其前提的序列数。
- en: Overall, the objective of sequential rule mining is to discover all sequential
    rules having a support and confidence no less than two thresholds, given by the
    user named minsup and minconf.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，序列规则挖掘的目标是发现所有支持度和置信度都不低于用户指定的最小支持度（minsup）和最小置信度（minconf）阈值的序列规则。
- en: Summary
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we provided a universal definition for data mining, listed
    the most common techniques used by data scientists, and stated the overall objective
    of the efforts. Data mining was also compared to data querying and, using R, various
    working examples were given to illustrate certain key techniques. Finally, the
    concepts of dimensional reduction, frequent patterning, and sequence mining were
    explored.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们提供了数据挖掘的通用定义，列出了数据科学家最常用的技术，并说明了这些工作的整体目标。数据挖掘还与数据查询进行了比较，并通过R语言提供了各种工作示例，以说明某些关键技术。最后，探讨了降维、频繁模式挖掘和序列挖掘的概念。
- en: The next chapter will be a hands-on introduction to statistical analysis of
    data through the eyes of a data developer, providing instructions for describing
    the nature of data, exploring relationships presented in data, creating a summarization
    model from data, proving the validly of a data model, and employing predictive
    analytics on a data developed model.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将通过数据开发者的视角，手把手介绍数据的统计分析，提供描述数据特征、探索数据中呈现的关系、从数据中创建总结模型、验证数据模型有效性以及在数据开发模型上进行预测分析的指导。
