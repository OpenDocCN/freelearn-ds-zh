- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Cleaning and Exploring Data with Series Operations
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Series 操作清理和探索数据
- en: We can view the recipes in the first few chapters of this book as, essentially,
    diagnostic. We imported some raw data and then generated descriptive statistics
    about key variables. This gave us a sense of how the values for those variables
    were distributed and helped us identify outliers and unexpected values. We then
    examined the relationships between variables to look for patterns, and deviations
    from those patterns, including logical inconsistencies. In short, our primary
    goal so far has been to figure out what is going on with our data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将本书前几章的配方视为本质上是诊断性的。我们导入了一些原始数据，然后生成了关于关键变量的描述性统计数据。这使我们对这些变量的值分布情况有了一个大致的了解，并帮助我们识别出异常值和意外值。然后，我们检查了变量之间的关系，以寻找模式，以及这些模式的偏差，包括逻辑上的不一致性。简而言之，到目前为止，我们的主要目标是弄清楚数据到底发生了什么。
- en: But, not very long into a data exploration and cleaning project, we invariably
    need to alter the initial values for some of our variables across some of our
    observations. For example, we might need to create a new column that is based
    on the values of one or more other columns. Or, we might want to change values
    that are in a certain range, say less than 0, or over some threshold amount, perhaps
    setting them to the mean, or to missing. Fortunately, the pandas Series object
    offers a large number of methods for manipulating data values.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在数据探索和清理项目开始不久后，我们通常需要更改一些变量在某些观察中的初始值。例如，我们可能需要创建一个基于一个或多个其他列值的新列，或者我们可能想要改变某些值，这些值可能在某个范围内，比如小于
    0，或者超过某个阈值，可能需要将它们设置为均值，或者设置为缺失。幸运的是，pandas Series 对象提供了大量用于操作数据值的方法。
- en: The recipes in this chapter demonstrate how to use pandas methods to update
    Series values once we have figured out what needs to be done. Ideally, we need
    to take the time to carefully examine our data before manipulating the values
    of our variables. We should have measures of central tendency, indicators of distribution
    shape and spread, correlations, and visualizations in front of us before we update
    the variable’s values, or before creating new variables based on them. We should
    also have a good sense of outliers and missing values, understand how they affect
    summary statistics, and have preliminary plans for imputing new values or otherwise
    adjusting them.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的配方展示了如何使用 pandas 方法来更新 Series 的值，一旦我们确定了需要做什么。理想情况下，我们需要花时间仔细检查数据，在操作变量值之前。我们应该首先有集中趋势的度量、分布形状和范围的指示、相关性和可视化，然后再更新变量的值，或者基于它们创建新的变量。在更新变量值之前，我们还应该对异常值和缺失值有一个清晰的认识，了解它们如何影响汇总统计数据，并对填补新值或其他调整的初步计划有所准备。
- en: Having done that, we will be ready to perform some data cleaning tasks. These
    tasks usually involve working directly with a pandas Series object, regardless
    of whether we are changing values for an existing Series or creating a new one.
    This often involves changing values conditionally, altering only those values
    that meet specific criteria, or assigning multiple possible values based on existing
    values for that Series, or values for another Series.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些工作后，我们就可以开始进行一些数据清理任务了。这些任务通常涉及直接操作 pandas Series 对象，无论是修改现有 Series 的值，还是创建一个新的
    Series。这通常涉及条件性地更改值，仅更改满足特定标准的值，或者基于该 Series 的现有值或另一个 Series 的值，分配多个可能的值。
- en: How we assign such values varies significantly by the Series’ data type, either
    for the Series to be changed or a criterion Series. Querying and cleaning string
    data bears little resemblance to those tasks with date or numeric data. With strings,
    we often need to evaluate whether some string fragment does or does not have a
    certain value, strip the string of some meaningless characters, or convert the
    value into a numeric or date value. With dates, we might need to look for invalid
    or out-of-range dates, or even calculate date intervals.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分配这些值的方式在很大程度上取决于 Series 的数据类型，无论是要更改的 Series 还是标准 Series。查询和清理字符串数据与处理日期或数值数据的任务有很大不同。对于字符串数据，我们通常需要评估某个字符串片段是否具有某个值，去除字符串中的一些无意义字符，或将其转换为数值或日期值。对于日期数据，我们可能需要查找无效的或超出范围的日期，甚至计算日期间隔。
- en: 'Fortunately, pandas Series have an enormous number of tools for manipulating
    strings, numeric, and date values. We will explore many of the most useful tools
    in this chapter. Specifically, we will cover the following recipes:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，pandas Series 提供了大量用于操作字符串、数值和日期值的工具。在本章中，我们将探讨一些最有用的工具。具体来说，我们将涵盖以下几个例子：
- en: Getting values from a pandas Series
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 pandas Series 中获取值
- en: Showing summary statistics for a pandas Series
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示 pandas Series 的汇总统计信息
- en: Changing Series values
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改 Series 值
- en: Changing Series values conditionally
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有条件地更改 Series 值
- en: Evaluating and cleaning string Series data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估和清理字符串 Series 数据
- en: Working with dates
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理日期
- en: Using OpenAI for Series operations
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenAI 进行 Series 操作
- en: Let’s get started!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need pandas, NumPy, and Matplotlib to complete the recipes in this
    chapter. I used pandas 2.1.4, but the code will run on pandas 1.5.3 or later.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要 pandas、NumPy 和 Matplotlib 来完成本章中的例子。我使用的是 pandas 2.1.4，但该代码也可以在 pandas 1.5.3
    或更高版本上运行。
- en: The code in this chapter can be downloaded from the book’s GitHub repository,
    [https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节中的代码可以从本书的 GitHub 仓库下载，[https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition)。
- en: Getting values from a pandas Series
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 pandas Series 中获取值
- en: A pandas Series is a one-dimensional array-like structure that takes a NumPy
    data type. Each Series also has an index, an array of data labels. If an index
    is not specified when the Series is created, it will be the default index of 0
    through N-1.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: pandas Series 是一种一维的类数组结构，它采用 NumPy 数据类型。每个 Series 也有一个索引，这是数据标签的数组。如果在创建 Series
    时没有指定索引，它将使用默认的 0 到 N-1 的索引。
- en: There are several ways to create a pandas Series, including from a list, dictionary,
    NumPy array, or a scalar. In our data cleaning work, we will most frequently be
    accessing data Series by selecting columns of DataFrames, using either attribute
    access (`dataframename.columname`) or bracket notation (`dataframename['columnname']`).
    Attribute access cannot be used to set values for Series, but bracket notation
    will work for all Series operations.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 pandas Series 的方式有很多种，包括从列表、字典、NumPy 数组或标量中创建。在数据清洗工作中，我们最常通过选择 DataFrame
    的列来访问数据 Series，使用属性访问（`dataframename.columname`）或括号符号（`dataframename['columnname']`）。属性访问不能用来设置
    Series 的值，但括号符号可以用于所有 Series 操作。
- en: In this recipe, we’ll explore several ways we can get values from a pandas Series.
    These techniques are very similar to the methods we used to get rows from a pandas
    DataFrame, which we covered in the *Selecting rows* recipe of *Chapter 3*, *Taking
    the Measure of Your Data*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们将探讨从 pandas Series 中获取值的几种方法。这些技术与我们在 *第 3 章*《数据度量》中介绍的从 pandas DataFrame
    获取行的方法非常相似。
- en: Getting ready
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 做好准备
- en: We will be working with data from the **National Longitudinal Survey** (**NLS**)
    in this recipe—primarily with data about each respondent’s overall high school
    **Grade Point Average** (**GPA**).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们将使用 **国家纵向调查** (**NLS**) 的数据，主要是关于每个受访者的高中 **平均绩点** (**GPA**) 数据。
- en: '**Data note**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据说明**'
- en: The National Longitudinal Survey of Youth is conducted by the United States
    Bureau of Labor Statistics. This survey started with a cohort of individuals in
    1997 who were born between 1980 and 1985, with annual follow-ups each year until
    2023\. Survey data is available for public use at [nlsinfo.org](https://nlsinfo.org).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**国家青少年纵向调查**由美国劳工统计局进行。该调查始于 1997 年，调查对象为 1980 年至 1985 年间出生的一群人，并且每年都会进行跟踪调查，直到
    2023 年。调查数据可供公众使用，网址：[nlsinfo.org](https://nlsinfo.org)。'
- en: How to do it…
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'For this recipe, we select Series values using the bracket operator and the
    `loc` and `iloc` accessors. Let’s get started:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用括号操作符以及 `loc` 和 `iloc` 访问器来选择 Series 值。让我们开始吧：
- en: 'Import the required `pandas` and NLS data:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的`pandas`和 NLS 数据：
- en: '[PRE0]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Note**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: Whether you use the bracket operator, the `loc` accessor, or the `iloc` accessor
    is largely a matter of preference. It is usually easier to use the `loc` accessor
    when you know the index label for the rows you want. When it is easier to refer
    to rows by their absolute position, the bracket operator or `iloc` accessor will
    probably be a better choice. The examples in this recipe illustrate this.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 是否使用括号运算符、`loc` 访问器或 `iloc` 访问器，主要是个人偏好问题。通常，当你知道要访问的行的索引标签时，使用 `loc` 访问器更方便。而当通过绝对位置引用行更为简便时，括号运算符或
    `iloc` 访问器可能会是更好的选择。这个例子中展示了这一点。
- en: Create a Series from the GPA overall column.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 GPA 总体列创建一个 Series。
- en: 'Show the first few values and associated index labels using `head`. The default
    number of values shown for `head` is 5\. The index for the Series is the same
    as the DataFrame’s index, which is `personid`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `head` 显示前几个值及其对应的索引标签。`head` 默认显示的值数量是 5。Series 的索引与 DataFrame 的索引相同，即 `personid`：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Select GPA values using the bracket operator.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用括号运算符选择 GPA 值。
- en: 'Use slicing to create a Series with every value from the first value to the
    fifth. Notice that we get the same values that we got with the `head` method in
    *step 2*. Not including a value to the left of the colon in `gpaoverall[:5]` means
    that it will start from the beginning. `gpaoverall[0:5]` will give the same results.
    Similarly, `gpaoverall[-5:]` shows the values from the fifth to the last position.
    This produces the same results as `gpaoverall.tail()`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 使用切片创建一个 Series，包含从第一个值到第五个值的所有值。注意我们得到了与 *第 2 步* 中 `head` 方法相同的值。在 `gpaoverall[:5]`
    中不包含冒号左边的值意味着它将从开头开始。`gpaoverall[0:5]` 将返回相同的结果。同样，`gpaoverall[-5:]` 显示的是从第五个到最后一个位置的值。这与
    `gpaoverall.tail()` 返回的结果相同：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Select values using the `loc` accessor.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `loc` 访问器选择值。
- en: 'We pass an index label (a value for `personid` in this case) to the `loc` accessor
    to return a scalar. We get a Series if we pass a list of index labels, regardless
    of whether there’s one or more. We can even pass a range, separated by a colon.
    We’ll do this here with `gpaoverall.loc[135335:151672]`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将一个索引标签（在此案例中为 `personid` 的值）传递给 `loc` 访问器以返回一个标量。如果我们传递一个索引标签列表，无论是一个还是多个，我们将得到一个
    Series。我们甚至可以传递一个通过冒号分隔的范围。这里我们将使用 `gpaoverall.loc[135335:151672]`：
- en: '[PRE13]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Select values using the `iloc` accessor.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `iloc` 访问器选择值。
- en: '`iloc` differs from `loc` in that it takes a list of row numbers rather than
    labels. It works similarly to bracket operator slicing. In this step, we pass
    a one-item list with a value of 0\. We then pass a five-item list, `[0,1,2,3,4]`,
    to return a Series containing the first five values. We get the same result if
    we pass `[:5]` to the accessor:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`iloc` 与 `loc` 的区别在于，它接受的是行号列表，而不是标签。它的工作方式类似于括号运算符切片。在这一步中，我们传递一个包含 0 的单项列表。然后，我们传递一个包含五个元素的列表
    `[0,1,2,3,4]`，以返回一个包含前五个值的 Series。如果我们传递 `[:5]` 给访问器，也会得到相同的结果：'
- en: '[PRE20]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Each of these ways of accessing pandas Series values—the bracket operator, the
    `loc` accessor, and the `iloc` accessor—has many use cases, particularly the `loc`
    accessor.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 访问 pandas Series 值的这些方法——括号运算符、`loc` 访问器和 `iloc` 访问器——都有许多使用场景，特别是 `loc` 访问器。
- en: How it works...
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We used the `[]` bracket operator in *step 3* to perform standard Python-like
    slicing to create a Series. This operator allows us to easily select data based
    on position using a list, or a range of values indicated with slice notation.
    This notation takes the form of `[start:end:step]`, where `1` is assumed for `step`
    if no value is provided. When a negative number is used for `start`, it represents
    the number of rows from the end of the original Series.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第 3 步* 中，我们使用 `[]` 括号运算符执行了类似标准 Python 的切片操作来创建一个 Series。这个运算符允许我们根据位置轻松选择数据，方法是使用列表或通过切片符号表示的值范围。该符号的形式为
    `[start:end:step]`，如果没有提供 `step`，则假定 `step` 为 1。当 `start` 使用负数时，它表示从原始 Series
    末尾开始的行数。
- en: The `loc` accessor, used in *step 4*, selects data by index labels. Since `personid`
    is the index for the Series, we can pass a list of one or more `personid` values
    to the `loc` accessor to get a Series with those labels and associated GPA values.
    We can also pass a range of labels to the accessor, which will return a Series
    with GPA values from the index label to the left of the colon and the index label
    to the right inclusive. So, `gpaoverall.loc[135335:151672]` returns a Series with
    GPA values for `personid` between `135335` and `151672`, including those two values.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤4*中使用的`loc`访问器通过索引标签选择数据。由于`personid`是Series的索引，我们可以将一个或多个`personid`值的列表传递给`loc`访问器，以获取具有这些标签及相关GPA值的Series。我们还可以将一个标签范围传递给访问器，它将返回一个包含从冒号左侧到右侧（包括）的索引标签的GPA值的Series。例如，`gpaoverall.loc[135335:151672]`将返回`personid`在`135335`到`151672`之间（包括这两个值）的GPA值的Series。
- en: As shown in *step 5*, the `iloc` accessor takes row positions rather than index
    labels. We can pass either a list of integers or a range using slicing notation.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如*步骤5*所示，`iloc`访问器使用的是行位置，而不是索引标签。我们可以传递一个整数列表或使用切片表示法传递一个范围。
- en: Showing summary statistics for a pandas Series
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 显示pandas Series的汇总统计数据
- en: There are a large number of pandas Series methods for generating summary statistics.
    We can easily get the mean, median, maximum, or minimum values for a Series with
    the `mean`, `median`, `max`, and `min` methods, respectively. The incredibly handy
    `describe` method will return all of these statistics, as well as several others.
    We can also get the Series value at any percentile using `quantile`. These methods
    can be used across all values for a Series, or just for selected values. This
    will be demonstrated in this recipe.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: pandas有许多生成汇总统计数据的方法。我们可以分别使用`mean`、`median`、`max`和`min`方法轻松获得Series的平均值、中位数、最大值或最小值。非常方便的`describe`方法将返回所有这些统计数据，以及其他一些数据。我们还可以使用`quantile`方法获得Series中任意百分位的值。这些方法可以应用于Series的所有值，或者仅用于选定的值。接下来的示例中将展示如何使用这些方法。
- en: Getting ready
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will continue working with the overall GPA column from the NLS.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用NLS中的总体GPA列。
- en: How to do it...
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let’s take a good look at the distribution of the overall GPA for the DataFrame
    and for the selected rows. To do this, follow these steps:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看整个数据框和选定行的总体GPA分布。为此，请按照以下步骤操作：
- en: 'Import `pandas` and `numpy` and load the NLS data:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`和`numpy`并加载NLS数据：
- en: '[PRE28]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Gather some descriptive statistics:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取一些描述性统计数据：
- en: '[PRE29]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Show descriptives for a subset of the Series:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示Series子集的描述性统计数据：
- en: '[PRE35]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Test for a condition across all values.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试所有值中的某一条件。
- en: 'Check for GPA values above 4 and if all the values are above or equal to 0\.
    (We generally expect GPA to be between 0 and 4.) Also, count how many values are
    missing:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 检查GPA值是否超过4，并确保所有值都大于或等于0。（我们通常期望GPA在0到4之间。）还要统计缺失值的数量：
- en: '[PRE43]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Show descriptives for a subset of the Series based on values in a different
    column.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于不同列的值，显示Series的子集描述性统计数据。
- en: 'Show the mean high school GPA for individuals with a wage income in 2020 that’s
    above the 75^(th) percentile, as well as for those with a wage income that’s below
    the 25^(th) percentile:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 显示2020年工资收入高于第75百分位的个人以及低于第25百分位的个人的高中平均GPA：
- en: '[PRE53]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Show descriptives and frequencies for a Series containing categorical data:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示包含分类数据的Series的描述性统计和频率：
- en: '[PRE57]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Once we have a Series, we can use a wide variety of pandas tools to calculate
    descriptive statistics for all or part of that Series.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了Series，我们可以使用pandas的多种工具来计算该Series的描述性统计数据。
- en: How it works…
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The Series `describe` method is quite useful as it gives us a good sense of
    the central tendency and spread of continuous variables. It is also often helpful
    to see the value at each decile. We obtained this in *step 2* by passing a list
    of values ranging from 0.1 to 1.0 to the `quantile` method of the Series.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Series的`describe`方法非常有用，因为它能很好地展示连续变量的集中趋势和分布情况。查看每个十分位的值通常也很有帮助。我们在*步骤2*中通过将0.1到1.0之间的值列表传递给Series的`quantile`方法来获得这些信息。
- en: We can use these methods on subsets of a Series. In *step 3*, we obtained the
    count of GPA values between 3 and 3.5\. We can also select values based on their
    relationship to a summary statistic; for example, `gpaoverall>gpaoverall.quantile(0.99)`
    selects GPA values that are greater than the 99^(th) percentile value. We then
    passed the resulting Series to the `agg` method using method chaining, which returned
    multiple summary statistics (`agg(['count','min','max'])`).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 Series 的子集上使用这些方法。在*第 3 步*中，我们获得了 GPA 值在 3 到 3.5 之间的计数。我们还可以根据与汇总统计量的关系来选择值；例如，`gpaoverall>gpaoverall.quantile(0.99)`
    选择 GPA 值大于第 99^(百分位)的值。然后，我们通过方法链将结果 Series 传递给 `agg` 方法，返回多个汇总统计量（`agg(['count','min','max'])`）。
- en: Sometimes, we need to test whether some condition is true across all the values
    in a Series. The `any` and `all` methods are useful for this. `any` returns `True`
    when at least one value in the Series satisfies the condition (such as (`gpaoverall>4).any()`).
    `all` returns `True` when all the values in the Series satisfy the condition.
    When we chain the test condition with sum (`(gpaoverall>=0).sum()`), we get a
    count of all the `True` values since pandas interprets `True` values as 1 when
    performing numerical operations.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们需要测试某个条件是否在 Series 中的所有值上都成立。`any` 和 `all` 方法对于此操作非常有用。`any` 当 Series 中至少有一个值满足条件时返回
    `True`（例如，`(gpaoverall>4).any()`）。`all` 当 Series 中所有值都满足条件时返回 `True`。当我们将测试条件与
    `sum` 链接时（`(gpaoverall>=0).sum()`），我们可以得到所有 `True` 值的计数，因为 pandas 在执行数值操作时将 `True`
    视为 1。
- en: '`(gpaoverall>4)` is a shorthand for creating a Boolean Series with the same
    index as `gpaoverall`. It has a value of `True` when `gpaoverall` is greater than
    4, and `False` otherwise:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`(gpaoverall>4)` 是一种简写方式，用于创建一个与 `gpaoverall` 具有相同索引的布尔 Series。当 `gpaoverall`
    大于 4 时，其值为 `True`，否则为 `False`：'
- en: '[PRE61]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: We sometimes need to generate summary statistics for a Series that has been
    filtered by another Series. We did this in *step 5* by calculating the mean high
    school GPA for individuals with a wage income that’s above the third quartile,
    as well as for individuals with a wage income that’s below the first quartile.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有时需要为通过另一个 Series 过滤后的 Series 生成汇总统计数据。在*第 5 步*中，我们通过计算工资收入高于第三四分位数的个体的平均高中
    GPA，以及工资收入低于第一四分位数的个体的平均高中 GPA，来完成这项工作。
- en: The `describe` method is most useful with continuous variables, such as `gpaoverall`,
    but it also provides useful information when used with categorical variables,
    such as `maritalstatus` (see *step 6*). This returns the count of non-missing
    values, the number of different values, the category that occurs most frequently,
    and the frequency of that category.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`describe` 方法对于连续变量（如 `gpaoverall`）最为有用，但在与分类变量（如 `maritalstatus`）一起使用时也能提供有价值的信息（见*第
    6 步*）。它返回非缺失值的计数、不同值的数量、最常出现的类别以及该类别的频率。'
- en: However, when working with categorical data, the `value_counts` method is more
    frequently used. It provides the frequency of each category in the Series.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在处理分类数据时，`value_counts` 方法更为常用。它提供了 Series 中每个类别的频率。
- en: There’s more…
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: Working with Series is so fundamental to pandas data cleaning tasks that data
    analysts quickly find that the tools that were used in this recipe are part of
    their daily data cleaning workflow. Typically, not much time elapses between the
    initial data import stage and using Series methods such as `describe`, `mean`,
    `sum`, `isnull`, `all`, and `any`.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Series 是 pandas 数据清理任务中的基础，数据分析师很快就会发现，本篇中使用的工具已成为他们日常数据清理工作流的一部分。通常，从初始数据导入阶段到使用
    Series 方法（如 `describe`、`mean`、`sum`、`isnull`、`all` 和 `any`）之间不会间隔太长时间。
- en: See also
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: We are just scratching the surface of aggregating data in this chapter. We’ll
    go through this more thoroughly in *Chapter 9*, *Fixing Messy Data When Aggregating*.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们只是浅尝辄止地介绍了数据聚合的内容。我们将在*第 9 章*《聚合时修复脏数据》中更详细地讨论这一点。
- en: Changing Series values
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更改 Series 值
- en: During the data cleaning process, we often need to change the values in a data
    Series or create a new one. We can change all the values in a Series, or just
    the values in a subset of our data. Most of the techniques we have been using
    to get values from a Series can be used to update Series values, though some minor
    modifications are necessary.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据清理过程中，我们经常需要更改数据 Series 中的值或创建一个新的 Series。我们可以更改 Series 中的所有值，或仅更改部分数据的值。我们之前用来从
    Series 获取值的大部分技术都可以用来更新 Series 的值，尽管需要进行一些小的修改。
- en: Getting ready
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will work with the overall high school GPA column from the NLS in this recipe.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在本道菜谱中，我们将处理NLS数据中的总体高中GPA列。
- en: How to do it…
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'We can change the values in a pandas Series for all rows, as well as for selected
    rows. We can update a Series with scalars by performing arithmetic operations
    on other Series, and by using summary statistics. Let’s take a look at this:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以为所有行或选择的行更改pandas Series中的值。我们可以通过对其他Series执行算术操作和使用汇总统计来更新Series。让我们来看看这个过程：
- en: 'Import `pandas` and load the NLS data:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`并加载NLS数据：
- en: '[PRE63]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Edit all the values based on a scalar.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于标量编辑所有值。
- en: 'Multiply `gpaoverall` by 100:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 将`gpaoverall`乘以100：
- en: '[PRE64]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Set values using index labels.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用索引标签设置值。
- en: 'Use the `loc` accessor to specify which values to change by index label:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`loc`访问器通过索引标签指定要更改的值：
- en: '[PRE68]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Set values using an operator on more than one Series.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用运算符在多个Series之间设置值。
- en: 'Use the `+` operator to calculate the number of children, which is the sum
    of children who live at home and children who do not live at home:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`+`运算符计算孩子的数量，这个数量是住在家里的孩子和不住在家里的孩子的总和：
- en: '[PRE70]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Use index labels to set values to a summary statistic.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用索引标签设置汇总统计值。
- en: 'Use the `loc` accessor to select `personid` from `100061` to `100292`:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`loc`访问器从`100061`到`100292`选择`personid`：
- en: '[PRE72]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Set values using position.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用位置设置值。
- en: 'Use the `iloc` accessor to select by position. An integer, or slice notation
    (`start:end:step`), can be used to the left of the comma to indicate the rows
    where the values should be changed. An integer is used to the right of the comma
    to select the column. The `gpaoverall` column is in the 16^(th) position (which
    is 15 since the column index is zero-based):'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`iloc`访问器按位置选择。可以使用整数或切片表示法（`start:end:step`）放在逗号左边，指示应该更改的行。逗号右边使用整数来选择列。`gpaoverall`列在第16个位置（由于列索引是从零开始的，所以是第15个位置）：
- en: '[PRE74]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Set the GPA values after filtering.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在筛选后设置GPA值。
- en: 'Change all GPA values over `4` to `4`:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有超过`4`的GPA值更改为`4`：
- en: '[PRE76]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: The preceding steps showed us how to update Series values with scalars, arithmetic
    operations, and summary statistics values.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的步骤展示了如何使用标量、算术操作和汇总统计值更新Series中的值。
- en: How it works…
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: The first thing to observe is that, in *step 2*, pandas vectorizes the multiplication
    by a scalar. It knows that we want to apply the scalar to all rows. Essentially,
    `nls97['gpaoverall'] * 100`, creates a temporary Series with all values set to
    100, and with the same index as the `gpaoverall` Series. It then multiplies `gpaoverall`
    by that Series of 100 values. This is known as broadcasting.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 首先需要注意的是，在*步骤2*中，pandas将标量乘法进行了向量化。它知道我们想将标量应用于所有行。实质上，`nls97['gpaoverall']
    * 100`创建了一个临时Series，所有值都设置为100，且拥有与`gpaoverall` Series相同的索引。然后，它将`gpaoverall`与这个100值的Series相乘。这就是所谓的广播。
- en: We can use a lot of what we learned in the first recipe of this chapter, about
    how to get values from a Series, to select particular values to update. The main
    difference here is that we use the `loc` and `iloc` accessors of the DataFrame
    (`nls97.loc`) rather than the Series (`nls97.gpaoverall.loc`). This is to prevent
    the dreaded `SettingwithCopyWarning`, which warns us about setting values on a
    copy of a DataFrame. `nls97.gpaoverall.loc[[135335]] = 3` triggers that warning,
    while `nls97.loc[[135335], 'gpaoverall'] = 3` does not.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以运用本章第一道菜谱中学到的许多内容，比如如何从Series中获取值，来选择特定的值进行更新。这里的主要区别是，我们使用DataFrame的`loc`和`iloc`访问器（`nls97.loc`），而不是Series的访问器（`nls97.gpaoverall.loc`）。这样做是为了避免令人头疼的`SettingwithCopyWarning`，该警告提示我们在DataFrame的副本上设置值。`nls97.gpaoverall.loc[[135335]]
    = 3`会触发这个警告，而`nls97.loc[[135335], 'gpaoverall'] = 3`则不会。
- en: In *step 4*, we saw how pandas handles numerical operations with two or more
    Series. Operations such as addition, subtraction, multiplication, and division
    are very much like the operations we perform on scalars in standard Python, only
    with vectorization. (This is made possible by pandas index alignment. Remember
    that Series in the same DataFrame will have the same index.) If you are familiar
    with NumPy, then you already have a good idea of how this works.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤4*中，我们看到了pandas如何处理两个或多个Series之间的数值操作。加法、减法、乘法和除法等操作就像我们在标准Python中对标量进行的操作，只不过是向量化的。（这得益于pandas的索引对齐功能。请记住，同一个DataFrame中的Series会有相同的索引。）如果你熟悉NumPy，那么你已经有了对这个过程的良好理解。
- en: There’s more…
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: 'It is useful to notice that `nls97.loc[[135335], ''gpaoverall'']` returns a
    Series, while `nls97.loc[[135335], [''gpaoverall'']]` returns a DataFrame:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到`nls97.loc[[135335], 'gpaoverall']`返回一个Series，而`nls97.loc[[135335], ['gpaoverall']]`返回一个DataFrame，这是很有用的：
- en: '[PRE80]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: If the second argument of the `loc` accessor is a string, it will return a Series.
    If it is a list, even if the list contains only 1 item, it will return a DataFrame.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`loc`访问器的第二个参数是字符串，它将返回一个Series。如果它是一个列表，即使列表只包含一个项，它也会返回一个DataFrame。
- en: For any of the operations we discussed in this recipe, it is good to be mindful
    of how pandas treats missing values. For example, in *step 4*, if either `childathome`
    or `childnotathome` is missing, then the operation will return `missing`. We’ll
    discuss how to handle situations like this in*, Identifying and Fixing Missing
    Values* recipe in the next chapter.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们在本案例中讨论的任何操作，记得关注pandas如何处理缺失值。例如，在*步骤4*中，如果`childathome`或`childnotathome`缺失，那么操作将返回`missing`。我们将在下一章的*识别和修复缺失值*案例中讨论如何处理这种情况。
- en: See also
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '*Chapter 3*, *Taking the Measure of Your Data*, goes into greater detail on
    the use of the `loc` and `iloc` accessors, particularly in the *Selecting rows*
    and *Selecting and organizing columns* recipes.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '*第3章*，*测量你的数据*，更详细地介绍了`loc`和`iloc`访问器的使用，特别是在*选择行*和*选择与组织列*的案例中。'
- en: Changing Series values conditionally
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有条件地更改Series值
- en: Changing Series values is often more complicated than the previous recipe suggests.
    We often need to set Series values based on the values of one or more other Series
    for that row of data. This is complicated further when we need to set Series values
    based on values from *other* rows; say, a previous value for an individual, or
    the mean for a subset. We will deal with these complications in this and the next
    recipe.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 更改Series值通常比前一个案例所示的更为复杂。我们经常需要根据该行数据中一个或多个其他Series的值来设置Series值。当我们需要根据*其他*行的值设置Series值时，这会变得更加复杂；比如，某个人的先前值，或者一个子集的平均值。我们将在本案例和下一个案例中处理这些复杂情况。
- en: Getting ready
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will work with land temperature data and the NLS data in this recipe.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在本案例中，我们将处理土地温度数据和NLS数据。
- en: '**Data note**'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据说明**'
- en: The land temperature dataset contains the average temperature readings (in Celsius)
    in 2023 from over 12,000 stations across the world, though the majority of the
    stations are in the United States. The raw dataset was retrieved from the Global
    Historical Climatology Network integrated database. It has been made available
    for public use by the United States National Oceanic and Atmospheric Administration
    at [https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 土地温度数据集包含了来自全球12,000多个站点在2023年的平均温度数据（单位：摄氏度），尽管大多数站点位于美国。该原始数据集来自全球历史气候网络集成数据库，已由美国国家海洋和大气管理局（NOAA）提供给公众使用，网址：[https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly)。
- en: How to do it…
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做……
- en: 'We will use NumPy’s `where` and `select` methods to assign Series values based
    on the values of that Series, the values of other Series, and summary statistics.
    We’ll then use the `lambda` and `apply` functions to construct more complicated
    criteria for assignment. Let’s get started:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用NumPy的`where`和`select`方法，根据该Series的值、其他Series的值和汇总统计来赋值。然后我们将使用`lambda`和`apply`函数来构建更复杂的赋值标准。我们开始吧：
- en: 'Import `pandas` and `numpy`, and then load the NLS and land temperature data:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`和`numpy`，然后加载NLS和土地温度数据：
- en: '[PRE84]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: Use NumPy’s `where` function to create a categorical Series containing two values.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用NumPy的`where`函数创建一个包含两个值的分类Series。
- en: 'Let’s do a quick check of the distribution of `elevation` values:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来快速检查一下`elevation`值的分布情况：
- en: '[PRE85]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '**Note**'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: You may have noticed that we passed a value of `False` to the `groupby` `observed`
    attribute. This is the default value of observed for all pandas versions prior
    to 2.1.0\. `observed=True` is the default for `groupby` in subsequent pandas versions.
    When `observed` is `True` and there is a column in `groupby` that is categorical,
    only observed values are shown. This does not affect the summary statistics in
    the previous step. I show it only to alert you to the upcoming change in the default
    value. I omit it in the rest of this chapter.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，我们将`False`值传递给了`groupby`的`observed`属性。这是所有pandas版本在2.1.0之前的默认值。在后续的pandas版本中，`groupby`的默认`observed=True`。当`observed`为`True`且`groupby`中包含分类列时，只会显示观察到的值。这不会影响前一步的汇总统计结果。我仅在此处提到它，以提醒你即将发生的默认值变化。在本章其余部分我将忽略它。
- en: Use NumPy’s `where` method to create a categorical Series containing three values.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用NumPy的`where`方法创建一个包含三个值的分类Series。
- en: 'Set values above the 80^(th) percentile to `''High''`, values above the median
    and up to the 80^(th) percentile to `''Medium''`, and the remaining values to
    `''Low''`:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 将80^(th)百分位以上的值设置为`'High'`，介于中位数和80^(th)百分位之间的值设置为`'Medium'`，剩余的值设置为`'Low'`：
- en: '[PRE89]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: Use NumPy’s `select` method to evaluate a list of conditions.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用NumPy的`select`方法来评估一系列条件。
- en: 'Set up a list of test conditions and another list for the result. We want individuals
    with a GPA less than 2 and no degree earned to be in one category, individuals
    with no degree but with a higher GPA to be in a second category, individuals with
    a degree but a low GPA in a third category, and the remaining individuals in a
    fourth category:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 设置一组测试条件，并为结果设置另一个列表。我们希望GPA低于2且没有学位的个人归为一个类别，GPA较高但没有学位的个人归为第二个类别，拥有学位但GPA较低的个人归为第三个类别，剩余的个人归为第四个类别：
- en: '[PRE91]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: While NumPy’s `select` method is very handy for relatively straightforward assignment
    of values conditionally, it can be difficult to use when the assignment is more
    complicated. We can use a user-defined function when `select` would be unwieldy.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然NumPy的`select`方法在相对简单的条件赋值中非常方便，但当赋值操作较为复杂时，它可能会变得难以使用。在这种情况下，我们可以使用自定义函数，而不是使用`select`。
- en: Let’s use `apply` and a user-defined function to do the same Series value assignment
    that we did in the previous step. We create a function, `gethsachieve`, with the
    logic for assigning values to a new variable, `hsachieve2`. We pass this function
    to `apply` and indicate `axis=1` to apply the function to all rows.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用`apply`和自定义函数来执行与前一步相同的Series值赋值操作。我们创建一个名为`gethsachieve`的函数，包含将值分配给新变量`hsachieve2`的逻辑。我们将此函数传递给`apply`并指定`axis=1`，以便将该函数应用于所有行。
- en: We will use this same technique in the next step to handle a more complicated
    assignment, one based on more columns and conditions.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一步中使用相同的技术来处理一个更复杂的赋值操作，该操作基于更多的列和条件。
- en: '[PRE95]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Notice that we get the same values for `hsachieve2` in this step that we got
    for `hsachieve` in the previous step.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这一步中，我们得到了与前一步中`hsachieve`相同的`hsachieve2`值。
- en: Now, let’s use `apply` and a user-defined function for a more complicated calculation,
    one that is based on the values of several variables.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用`apply`和自定义函数进行更复杂的计算，该计算基于多个变量的值。
- en: 'The `getsleepdeprivedreason` function below creates a variable that categorizes
    survey respondents by the possible reasons why they might get fewer than 6 hours
    of sleep a night. We base this on NLS survey responses about a respondent’s employment
    status, the number of children who live with the respondent, wage income, and
    highest grade completed:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的`getsleepdeprivedreason`函数创建一个变量，用于根据调查对象可能因为什么原因导致每晚睡眠时间少于6小时来对其进行分类。我们根据NLS调查中关于受访者的就业状态、与受访者同住的孩子数、工资收入和最高完成的学业年级等信息来进行分类：
- en: '[PRE97]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Use `apply` to run the function for all rows:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`apply`来对所有行运行该函数：
- en: '[PRE98]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: We can use a lambda function with `transform` if we want to work with particular
    columns but we do not need to pass them to a user-defined function. Let’s try
    that by using `lambda` to test several columns in one statement.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们只需要处理特定的列，并且不需要将它们传递给自定义函数，我们可以使用`lambda`函数与`transform`。让我们通过使用`lambda`在一个语句中测试多个列来尝试这个方法。
- en: 'The `colenr` columns have enrollment status in February and October of each
    year for each person. We want to test whether any of the college enrollment columns
    has a value of `3\. 4-year college`. Use `filter` to create a DataFrame of the
    `colenr` columns. Then, use `transform` to call a lambda function that tests the
    first character of each `colenr` column. (We can just look at the first character
    and see whether it has a value of 3.) That is then passed to `any` to evaluate
    whether any (one or more) of the columns has a 3 in the first character. (We only
    show values for college enrollment between 2000 and 2004 due to space considerations,
    but we check all the values for the college enrollment columns between 1997 and
    2022.) This can be seen in the following code:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`colenr`列记录了每个人在每年2月和10月的入学状态。我们想要测试是否有任何一列大学入学状态的值为`3. 4年制大学`。使用`filter`创建一个包含`colenr`列的DataFrame。然后，使用`transform`调用一个lambda函数，测试每个`colenr`列的第一个字符。（我们只需查看第一个字符，判断它是否为3。）接着将其传递给`any`，评估是否有任何（一个或多个）列的第一个字符为3。（由于空间限制，我们只显示2000年至2004年之间的大学入学状态，但我们会检查1997年到2022年之间所有大学入学状态列的值。）这可以通过以下代码看到：'
- en: '[PRE100]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: The preceding steps demonstrate several techniques we can use to set the values
    for a Series conditionally.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 上述步骤展示了几种我们可以用来有条件地设置Series值的技巧。
- en: How it works…
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: If you have used `if-then-else` statements in SQL or Microsoft Excel, then NumPy’s
    `where` should be familiar to you. It follows the form of `where` (test condition,
    clause if `True`, clause if `False`). In *step 2*, we tested whether the value
    of elevation for each row is greater than the value at the 80^(th) percentile.
    If `True`, we returned `'High'`. We returned `'Low'` otherwise. This is a basic
    `if-then-else` construction.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾在SQL或Microsoft Excel中使用过`if-then-else`语句，那么NumPy的`where`对你应该是熟悉的。它的形式是`where`（测试条件，`True`时的表达式，`False`时的表达式）。在*第2步*中，我们测试了每行的海拔值是否大于80^(百分位数)的值。如果为`True`，则返回`'High'`；否则返回`'Low'`。这是一个基本的`if-then-else`结构。
- en: Sometimes, we need to nest a test within a test. We did this in *step 3* to
    create three elevation groups; high, medium, and low. Instead of a simple statement
    in the `False` section (after the second comma), we used another `where` statement.
    This changes it from an `else` clause to an `else if` clause. It takes the form
    of `where`(test condition, statement if `True`, `where`(test condition, statement
    if `True`, statement if `False`)).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们需要将一个测试嵌套在另一个测试中。在*第3步*中，我们为海拔创建了三个组：高，中和低。我们在`False`部分（第二个逗号之后）没有使用简单的语句，而是使用了另一个`where`语句。这将它从`else`语句变成了`else
    if`语句。它的形式是`where`（测试条件，`True`时的语句，`where`（测试条件，`True`时的语句，`False`时的语句））。
- en: It is possible to add many more nested `where` statements, though that is not
    advisable. When we need to evaluate a slightly more complicated test, NumPy’s
    `select` method comes in handy. In *step 4*, we passed a list of tests, as well
    as a list of results of that test, to `select`. We also provided a default value
    of `4\. Did Okay` for any case where none of the tests was `True`. When multiple
    tests are `True`, the first one that is `True` is used.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，可以添加更多嵌套的`where`语句，但并不推荐这样做。当我们需要评估一个稍微复杂一些的测试时，NumPy的`select`方法非常有用。在*第4步*中，我们将测试的列表以及该测试的结果列表传递给了`select`。我们还为没有任何测试为`True`的情况提供了一个默认值`4.
    Did Okay`。当多个测试为`True`时，会使用第一个为`True`的测试。
- en: Once the logic becomes even more complicated, we can use `apply`. The DataFrame
    `apply` method can be used to send each row of a DataFrame to a function by specifying
    `axis=1`. *step 5* demonstrates how to reproduce the same logic as with *step
    4* using `apply` and a user-defined function.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦逻辑变得更加复杂，我们可以使用`apply`。DataFrame的`apply`方法可以通过指定`axis=1`将DataFrame的每一行传递给一个函数。*第5步*演示了如何使用`apply`和用户定义的函数复现与*第4步*相同的逻辑。
- en: In *steps 6* and *7*, we created a Series that categorizes reasons for being
    sleep deprived based on weeks worked, the number of children living with the respondent,
    wage income, and highest grade completed. If the respondent did not work most
    of 2020 and 2021, and if more than two children lived with them, `sleepdeprivedreason`
    is set to “Child Rearing.” If the respondent did not work most of 2020 and 2021
    and two or fewer children lived with them, `sleepdeprivedreason` is set to “Other
    Reasons.” If they worked most of 2020 and 2021, then `sleepdeprivedreason` is
    “Work Pressure” if they had a high salary or completed 4 years of college, and
    is “Income Pressure” otherwise. Of course, these categories are somewhat contrived,
    but they do illustrate how to use a function to create a Series based on complicated
    relationships among other Series.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第6步*和*第7步*中，我们创建了一个Series，基于工作周数、与受访者同住的子女数量、工资收入和最高学历来分类缺乏睡眠的原因。如果受访者在2020年和2021年大部分时间没有工作，且有两个以上的孩子与其同住，则`sleepdeprivedreason`被设置为“育儿”。如果受访者在2020年和2021年大部分时间没有工作，且有两个或更少的孩子与其同住，则`sleepdeprivedreason`被设置为“其他原因”。如果受访者在2020年和2021年大部分时间有工作，则如果他们有高薪或完成了四年的大学学业，`sleepdeprivedreason`为“工作压力”，否则为“收入压力”。当然，这些分类有些人为，但它们确实展示了如何通过函数基于其他Series之间的复杂关系来创建Series。
- en: In *step 8*, we used `transform` to call a lambda function that tests whether
    the first character of each college enrollment value is 3\. But first, we used
    the `filter` DataFrame method to select all the college enrollment columns. We
    could have paired the `lambda` function with `apply` to achieve the same result,
    but `transform` is typically more efficient.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第8步*中，我们使用了`transform`调用一个lambda函数，测试每个大学入学值的第一个字符是否是3。但首先，我们使用`filter`方法从DataFrame中选择所有的大学入学列。我们本可以将`lambda`函数与`apply`搭配使用以实现相同的结果，但`transform`通常更高效。
- en: You may have noticed that we changed the data type of the new Series we created
    in *steps 2* and *3* to `category`. The new Series was an `object` data type initially.
    We reduced memory usage by changing the type to `category`.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到，我们在*第2步*和*第3步*中创建的新Series的数据类型被更改为`category`。这个新Series最初是`object`数据类型。我们通过将类型更改为`category`来减少内存使用。
- en: We used another incredibly useful method in *step 2*, somewhat incidentally.
    `landtemps.groupby(['elevation_group'])` creates a DataFrame `groupby` object
    that we pass to an aggregate (`agg`) function. This gives us a count, min, and
    max for each `elevation_group`, allowing us to confirm that our group classification
    works as expected.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第2步*中使用了另一个非常有用的方法，虽然是有点偶然的。`landtemps.groupby(['elevation_group'])`创建了一个DataFrame的`groupby`对象，我们将其传递给一个聚合（`agg`）函数。这样我们就可以获得每个`elevation_group`的计数、最小值和最大值，从而验证我们的分组分类是否按预期工作。
- en: There’s more…
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: It has been a long time since I have had a data cleaning project that did not
    involve a NumPy `where` or `select` statement, nor a `lambda` or `apply` statement.
    At some point, we need to create or update a Series based on values from one or
    more other Series. It is a good idea to get comfortable with these techniques.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 自从我有一个数据清理项目没有涉及NumPy的`where`或`select`语句，或者`lambda`或`apply`语句以来，已经有很长一段时间了。在某些时候，我们需要基于一个或多个其他Series的值来创建或更新一个Series。熟练掌握这些技术是个好主意。
- en: Whenever there is a built-in pandas function that does what we need, it is better
    to use that than `apply`. The great advantage of `apply` is that it is quite generic
    and flexible, but that is also why it is more resource-intensive than the optimized
    functions. However, it is a great tool when we want to create a Series based on
    complicated relationships between existing Series.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 每当有一个内置的pandas函数能够完成我们的需求时，最好使用它，而不是使用`apply`。`apply`的最大优点是它非常通用且灵活，但也正因为如此，它比优化过的函数更占用资源。然而，当我们想要基于现有Series之间复杂的关系创建一个Series时，它是一个很好的工具。
- en: 'Another way to perform *steps 6* and *7* is to add a lambda function to `apply`.
    This produces the same results:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 执行*第6步*和*第7步*的另一种方式是将一个lambda函数添加到`apply`中。这会产生相同的结果：
- en: '[PRE106]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: One advantage of this approach is that it makes it more clear which Series contribute
    to the calculation.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的一个优点是，它更清晰地显示了哪些Series参与了计算。
- en: See also
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: We’ll go over DataFrame `groupby` objects in detail in *Chapter 9*, *Fixing
    Messy Data When Aggregating*. We examined various techniques we can use to select
    columns from a DataFrame, including `filter`, in *Chapter 3*, *Taking the Measure
    of Your Data*.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*第9章*《聚合时修复杂乱数据》中详细讲解DataFrame的`groupby`对象。我们在*第3章*《了解你的数据》中已经探讨了多种选择DataFrame列的技术，包括`filter`。
- en: Evaluating and cleaning string Series data
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估和清理字符串Series数据
- en: 'There are many string cleaning methods in Python and pandas. This is a good
    thing. Given the great variety of data stored in strings, it is important to have
    a wide range of tools to call upon when performing string evaluation and manipulation:
    when selecting fragments of a string by position, when checking whether a string
    contains a pattern, when splitting a string, when testing a string’s length, when
    joining two or more strings, when changing the case of a string, and so on. We’ll
    explore some of the methods that are used most frequently for string evaluation
    and cleaning in this recipe.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: Python和pandas中有许多字符串清理方法。这是件好事。由于存储在字符串中的数据种类繁多，因此在进行字符串评估和操作时，拥有广泛的工具非常重要：当按位置选择字符串片段时，当检查字符串是否包含某个模式时，当拆分字符串时，当测试字符串长度时，当连接两个或更多字符串时，当改变字符串大小写时，等等。在本食谱中，我们将探索一些最常用于字符串评估和清理的方法。
- en: Getting ready
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will work with the NLS data in this recipe. (The NLS data was actually a
    little too clean for this recipe. To illustrate working with strings with trailing
    spaces, I added trailing spaces to the `maritalstatus` column values.)
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将使用NLS数据。（实际上，NLS数据对于这个食谱来说有点过于干净。为了演示如何处理带有尾随空格的字符串，我在`maritalstatus`列的值后添加了尾随空格。）
- en: How to do it...
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: In this recipe, we will perform some common string evaluation and cleaning tasks.
    We’ll use `contains`, `endswith`, and `findall` to search for patterns, trailing
    blanks, and more complicated patterns, respectively.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将执行一些常见的字符串评估和清理任务。我们将使用`contains`、`endswith`和`findall`来分别搜索模式、尾随空格和更复杂的模式。
- en: 'We will also create a function for processing string values before assigning
    values to a new Series and then use `replace` for simpler processing. Let’s get
    started:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将创建一个处理字符串值的函数，在将值分配给新Series之前，使用`replace`进行更简单的处理。让我们开始吧：
- en: 'Import `pandas` and `numpy`, and then load the NLS data:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`和`numpy`，然后加载NLS数据：
- en: '[PRE107]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Test whether a pattern exists in a string.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试字符串中是否存在某个模式。
- en: 'Use `contains` to examine the `govprovidejobs` (government should provide jobs)
    responses for the “Definitely not” and “Probably not” values. In the `where` call,
    handle missing values first to make sure that they do not end up in the first
    `else` clause (the section after the second comma):'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`contains`来检查`govprovidejobs`（政府应该提供就业）响应中的“绝对不”与“可能不”值。在`where`调用中，首先处理缺失值，确保它们不会出现在第一个`else`分支中（即第二个逗号后的部分）：
- en: '[PRE108]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: Handle leading or trailing spaces in a string.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理字符串中的前导或尾随空格。
- en: 'Create an ever-married Series. First, examine the values of `maritalstatus`.
    Notice that there are two stray values indicating never-married. They are “Never-married”
    with an extra space at the end, unlike the other values of “Never-married” with
    no trailing spaces. Use `startswith` and `endswith` to test for a leading or trailing
    space, respectively. Use `strip` to remove the trailing space before testing for
    ever-married. `strip` removes leading and trailing spaces (`lstrip` removes leading
    spaces, while `rstrip` removes trailing spaces, so `rstrip` would have also worked
    in this example):'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个永婚状态的Series。首先，检查`maritalstatus`的值。注意有两个表示从未结婚的异常值。它们是“Never-married”后有一个额外的空格，而其他“Never-married”的值则没有尾随空格。使用`startswith`和`endswith`分别测试是否有前导空格或尾随空格。使用`strip`去除尾随空格后再测试永婚状态。`strip`去除前导和尾随空格（`lstrip`去除前导空格，`rstrip`去除尾随空格，所以在这个例子中，`rstrip`也能起作用）：
- en: '[PRE112]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '[PRE116]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '[PRE119]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'Use `isin` to compare a string value to a list of values:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`isin`将字符串值与值列表进行比较：
- en: '[PRE120]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: '[PRE121]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: We occasionally need to identify the location of a particular character in a
    string. This is sometimes because we need to get text before or after that point,
    or treat that text differently. Let’s try this with the highest degree attained
    column that we have already worked with. We will create a new column that does
    not have the number prefix. For example, *2\. High School* will become *High School*.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有时需要找出字符串中特定字符的位置。这有时是因为我们需要获取该点之前或之后的文本，或者以不同方式处理这些文本。让我们用之前处理过的“最高学历”列来尝试。我们将创建一个新列，该列不包含数字前缀。例如，*2.
    高中*将变为*高中*。
- en: Use `find` to get the location of the period in `highestdegree` values and retrieve
    the text after that.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`find`获取`highestdegree`值中句点的位置，并提取该位置后的文本。
- en: Before we do that, we assign *99\. Unknown* to missing values. This is not necessary
    but it helps us be clear about how we are handling all values, including the missing
    ones. It also adds a useful complication. After we do that, the leading numbers
    can be 1 or 2 digits.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，我们将*99\. Unknown*分配给缺失值。虽然这不是必要的，但它帮助我们明确处理所有值（包括缺失值）的方式，同时增加了有用的复杂性。完成后，前导数字可以是1位或2位数字。
- en: 'Next, we create a lambda function, `onlytext`, that we will use to identify
    the location of the text we want and then use it to pull that text. We then use
    the `transform` method of the `highestdegree` Series to call the `onlytext` function:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个lambda函数`onlytext`，它将用于识别我们想要的文本的位置，然后利用它提取该文本。然后，我们使用`highestdegree`
    Series的`transform`方法调用`onlytext`函数：
- en: '[PRE122]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: You probably noticed that there is a space between the period and the start
    of the text we want. To account for this, the `onlytext` function pulls text starting
    two spaces over from the period.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到，在句点和我们想要的文本开始之间有一个空格。为了处理这一点，`onlytext`函数会从句点后的两个空格处开始提取文本。
- en: '**Note**'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: We did not need to name a lambda function to achieve the results we wanted.
    We could have just entered a lambda function in the `transform` method. However,
    since we have a number of columns in the NLS data that have a similar prefix,
    it is good to have a function that we can reuse with another column.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现我们想要的结果，我们并不需要给lambda函数命名。我们本可以直接在`transform`方法中输入lambda函数。然而，由于NLS数据中有多个列具有相似的前缀，创建一个可重用的函数来处理其他列是一个不错的选择。
- en: We sometimes need to find all occurrences in a string of a certain value or
    a certain type of value, say a number. The pandas Series function, `findall`,
    can be used to return one or more occurrences of a value in a string. A list is
    returned of the string fragments that satisfy the given criteria. Let’s do a straightforward
    example before moving on to a more complicated one.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们需要查找字符串中某个特定值或某种类型的值（比如数字）出现的所有位置。pandas的`findall`函数可以用来返回字符串中一个或多个匹配的值。它会返回一个包含满足给定条件的字符串片段的列表。在深入更复杂的例子之前，我们先做一个简单的示范。
- en: 'Use `findall` to count the number of times `r` appears for each `maritalstatus`
    value for the first few rows of data. First, show the values for `maritalstatus`,
    then show the list that is returned from `findall` for each value:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`findall`计算每个`maritalstatus`值中`r`出现的次数，展示前几行数据。首先，展示`maritalstatus`的值，然后展示每个值对应的`findall`返回的列表：
- en: '[PRE124]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: Let’s also show a count of the number of times that `r` appears.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还将展示`r`出现的次数。
- en: 'Use `concat` to show the `maritalstatus` value, the list from `findall`, and
    the length of the list all on the same line:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`concat`将`maritalstatus`值、`findall`返回的列表和列表的长度显示在同一行：
- en: '[PRE128]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: We can also use `findall` to return types of values. For example, we can use
    a regular expression to return a list with all numbers in a string. We do that
    in the next couple of steps.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用`findall`返回不同类型的值。例如，我们可以使用正则表达式返回字符串中的所有数字列表。在接下来的几步中，我们将展示这一过程。
- en: 'Use `findall` to create a list of all numbers in the `weeklyhrstv` (hours spent
    each week watching television) string. The `"\d+"` regular expression that’s passed
    to `findall` indicates that we just want numbers:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`findall`创建一个包含所有数字的列表，该列表来源于`weeklyhrstv`（每周花费的电视观看时间）字符串。传递给`findall`的`"\d+"`正则表达式表示我们只想要数字：
- en: '[PRE130]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '[PRE131]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE131]'
- en: Use the list created by `findall` to create a numerical Series from the `weeklyhrstv`
    text.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`findall`创建的列表，从`weeklyhrstv`文本中创建一个数值Series。
- en: 'Let’s define a function that retrieves the last element in the list created
    by `findall` for each value of `weeklyhrstv`. The `getnum` function also adjusts
    that number so that it’s closer to the midpoint of the two numbers, where there
    is more than one number. We then use `apply` to call this function, passing it
    the list created by `findall` for each value. `crosstab` shows that the new `weeklyhrstvnum`
    column does what we want it to do:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来定义一个函数，它为每个`weeklyhrstv`值提取`findall`创建的列表中的最后一个元素。`getnum`函数还会调整该数字，使其更接近这两个数字的中点，当存在多个数字时。然后我们使用`apply`调用这个函数，将`findall`为每个值创建的列表传递给它。`crosstab`显示新的`weeklyhrstvnum`列达到了我们的预期效果：
- en: '[PRE132]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '[PRE134]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: '[PRE135]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: Replace the values in a Series with alternative values.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用替代值替换Series中的值。
- en: 'The `weeklyhrscomputer` (hours spent each week on a computer) Series does not
    sort nicely with its current values. We can fix this by replacing the values with
    letters that indicate order. We’ll start by creating a list containing the old
    values and another list containing the new values that we want. We then use the
    Series `replace` method to replace the old values with the new values. Whenever
    `replace` finds a value from the old values list, it replaces it with a value
    from the same list position in the new list:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '`weeklyhrscomputer`（每周在计算机上花费的时间）Series 目前的值排序不太理想。我们可以通过将这些值替换为表示顺序的字母来解决此问题。我们将首先创建一个包含旧值的列表，以及一个包含新值的列表。然后，使用
    Series 的 `replace` 方法将旧值替换为新值。每当 `replace` 在旧值列表中找到一个值时，它会将其替换为新值列表中相同位置的值：'
- en: '[PRE136]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: '[PRE137]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: '[PRE139]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: The steps in this recipe demonstrate some of the common string evaluation and
    manipulation tasks we can perform in pandas.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱中的步骤演示了我们在 pandas 中可以执行的一些常见字符串评估和操作任务。
- en: How it works...
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理……
- en: We frequently need to examine a string to see whether there is a pattern. We
    can use the string `contains` method to do this. If we know exactly where the
    expected pattern will be, we can use standard slice notation, `[start:stop:step]`,
    to select text from start through stop-1\. (The default value for `step` is 1.)
    For example, in *step 4*, we got the first character from `highestdegree` with
    `nls97.highestdegree.str[0:1]`. We then used `isin` to test whether the first
    string appears in a list of values. (`isin` works for both character and numeric
    data.)
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常需要检查一个字符串，以查看其中是否存在某种模式。我们可以使用字符串的 `contains` 方法来实现这一点。如果我们确切知道期望的模式的位置，可以使用标准的切片符号
    `[start:stop:step]` 来选择从起始位置到结束位置减一的文本。（`step` 的默认值为 1。）例如，在*步骤 4* 中，我们使用 `nls97.highestdegree.str[0:1]`
    获取了 `highestdegree` 的第一个字符。然后，我们使用 `isin` 来测试第一个字符串是否出现在一个值列表中。 (`isin` 适用于字符数据和数值数据。)
- en: Sometimes, we need to pull multiple values from a string that satisfy a condition.
    `findall` is helpful in those situations as it returns a list of all values satisfying
    the condition. It can be paired with a regular expression when we are looking
    for something more general than a literal. In *steps 8* and *9*, we were looking
    for any number.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们需要从字符串中提取多个满足条件的值。在这种情况下，`findall` 非常有用，因为它会返回一个满足条件的所有值的列表。它还可以与正则表达式配合使用，当我们寻找的内容比字面值更为通用时。在*步骤
    8* 和 *步骤 9* 中，我们在寻找任何数字。
- en: There’s more…
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: It is important to be deliberate while handling missing values when creating
    a Series based on values for another Series. Missing values may satisfy the `else`
    condition in a `where` call when that is not our intention. In *steps 2*, *3*,
    and *4*, we made sure that we handled the missing values appropriately by testing
    for them at the beginning of the `where` call.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在根据另一个 Series 的值创建 Series 时，处理缺失值时需要特别小心。缺失值可能会满足 `where` 调用中的 `else` 条件，而这并非我们的意图。在*步骤
    2*、*步骤 3* 和 *步骤 4* 中，我们确保通过在 `where` 调用的开始部分进行缺失值检查，正确处理了缺失值。
- en: We also need to be careful about the casing of the letters when making string
    comparisons. For example, `Probably` and `probably` are not equal. One way to
    get around this is to use the `upper` or `lower` methods when doing comparisons
    when a potential difference in case is not meaningful. `upper("Probably") == upper("PROBABLY")`
    is actually `True`.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在进行字符串比较时，也需要注意字母的大小写。例如，`Probably` 和 `probably` 并不相等。解决这一问题的一种方法是在进行比较时，使用
    `upper` 或 `lower` 方法，以防大小写的差异没有实际意义。`upper("Probably") == upper("PROBABLY")` 实际上是
    `True`。
- en: Working with dates
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理日期
- en: Working with dates is rarely straightforward. Data analysts need to successfully
    parse date values, identify invalid or out-of-range dates, impute dates when they’re
    missing, and calculate time intervals. There are surprising hurdles at each of
    these steps, but we are halfway there once we’ve parsed the date value and have
    a datetime value in pandas. We will start by parsing date values in this recipe
    before working our way through the other challenges.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 处理日期通常并不简单。数据分析师需要成功地解析日期值，识别无效或超出范围的日期，填补缺失的日期，并计算时间间隔。在这些步骤中，每个环节都会遇到意想不到的挑战，但一旦我们成功解析了日期值并获得了
    pandas 中的 datetime 值，就算是迈出了成功的一步。在本食谱中，我们将首先解析日期值，然后再处理接下来的其他挑战。
- en: Getting ready
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will work with the NLS and COVID-19 case daily data in this recipe. The COVID-19
    daily data contains one row for each reporting day for each country. (The NLS
    data was actually a little too clean for this purpose. To illustrate working with
    missing date values, I set one of the values for birth month to missing.)
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将处理NLS和COVID-19每日病例数据。COVID-19每日数据包含每个国家每天的报告数据。（NLS数据实际上对于这个目的来说过于干净。为了说明如何处理缺失的日期值，我将其中一个出生月份的值设置为缺失。）
- en: '**Data note**'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据说明**'
- en: Our World in Data provides COVID-19 public use data at [https://ourworldindata.org/covid-cases](https://ourworldindata.org/covid-cases).
    The data used in this recipe was downloaded on March 3, 2024.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的《全球数据》提供了COVID-19的公共数据，链接：[https://ourworldindata.org/covid-cases](https://ourworldindata.org/covid-cases)。本食谱中使用的数据是于2024年3月3日下载的。
- en: How to do it…
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this recipe, we will convert numeric data into datetime data, first by confirming
    that the data has valid date values and then by using `fillna` to replace missing
    dates. We will then calculate some date intervals; that is, the age of respondents
    for the NLS data and the days since the first COVID-19 case for the COVID-19 daily
    data. Let’s get started:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将把数字数据转换为日期时间数据，首先通过确认数据中是否包含有效的日期值，然后使用`fillna`来替换缺失的日期。接下来，我们将计算一些日期间隔；也就是说，计算NLS数据中受访者的年龄，以及COVID-19每日数据中自首例COVID-19病例以来的天数。让我们开始吧：
- en: 'Import `pandas` and the `relativedelta` module from `dateutils`, and then load
    the NLS and COVID-19 case daily data:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`和`dateutils`中的`relativedelta`模块，然后加载NLS和COVID-19每日病例数据：
- en: '[PRE140]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE140]'
- en: Show the birth month and year values.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示出生月份和年份的值。
- en: 'Notice that there is one missing value for birth month. Other than that, the
    data that we will use to create the `birthdate` Series looks pretty clean:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，出生月份有一个缺失值。除此之外，我们将用来创建`birthdate`序列的数据看起来相当干净：
- en: '[PRE141]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: '[PRE142]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: '[PRE143]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: '[PRE144]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: '[PRE145]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: '[PRE146]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: Use the `fillna` method to set a value for the missing birth month.
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fillna`方法为缺失的出生月份设置值。
- en: 'Pass the average of `birthmonth`, rounded to the nearest integer, to `fillna`.
    This will replace the missing value for `birthmonth` with the mean of `birthmonth`.
    Notice that one more person now has a value of 6 for `birthmonth`:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 将`birthmonth`的平均值（四舍五入为最接近的整数）传递给`fillna`。这将用`birthmonth`的平均值替换缺失的`birthmonth`值。请注意，现在又有一个人将`birthmonth`的值设为6：
- en: '[PRE147]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '[PRE148]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: Use `month` and year `integers` to create a datetime column.
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`month`和年份`integers`来创建日期时间列。
- en: 'We can pass a dictionary to the pandas `to_datetime` function. The dictionary
    needs to contain a key for year, month, and day. Notice that there are no missing
    values for `birthmonth`, `birthyear`, and `birthdate`:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将字典传递给pandas的`to_datetime`函数。字典需要包含年、月和日的键。请注意，`birthmonth`、`birthyear`和`birthdate`没有缺失值：
- en: '[PRE149]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: '[PRE150]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: '[PRE151]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: Calculate age using a datetime column.
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用日期时间列计算年龄。
- en: 'First, define a function that will calculate age when given a start date and
    an end date. Notice that we create a **Timestamp** object, `rundate`, and assign
    it a value of `2024-03-01` to use for the end date of our age calculation:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，定义一个函数，当给定起始日期和结束日期时，计算年龄。请注意，我们创建了一个**Timestamp**对象`rundate`，并将其赋值为`2024-03-01`，以用作年龄计算的结束日期：
- en: '[PRE153]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE153]'
- en: '[PRE154]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: 'We can use the `relativedelta` module instead for the age calculation. We just
    need to do the following:'
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以改用`relativedelta`模块来计算年龄。我们只需要执行以下操作：
- en: '[PRE155]'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE155]'
- en: 'We should confirm that we get the same values as in *step 5*:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该确认我们得到的值与*步骤5*中的值相同：
- en: '[PRE156]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE156]'
- en: '[PRE157]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE157]'
- en: '[PRE158]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE158]'
- en: '[PRE159]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE159]'
- en: Convert a string column into a datetime column.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将字符串列转换为日期时间列。
- en: 'The `casedate` column is an `object` data type, not a `datetime` data type:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '`casedate`列是`object`数据类型，而不是`datetime`数据类型：'
- en: '[PRE160]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE160]'
- en: '[PRE161]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE162]'
- en: '[PRE163]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE163]'
- en: '[PRE164]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE164]'
- en: '[PRE165]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE165]'
- en: 'Show descriptive statistics for the datetime column:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示日期时间列的描述性统计数据：
- en: '[PRE166]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE166]'
- en: '[PRE167]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE167]'
- en: '[PRE168]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE168]'
- en: '[PRE169]'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE169]'
- en: Create a `timedelta` object to capture a date interval.
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`timedelta`对象来捕捉日期间隔。
- en: 'For each day, calculate the number of days since the first case was reported
    for each country. First, create a DataFrame that shows the first day of new cases
    for each country and then merge it with the full COVID-19 cases data. Then, for
    each day, calculate the number of days from `firstcasedate` to `casedate`:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一天，计算自报告首例病例以来，每个国家的天数。首先，创建一个DataFrame，显示每个国家新病例的第一天，然后将其与完整的COVID-19病例数据合并。接着，对于每一天，计算从`firstcasedate`到`casedate`的天数：
- en: '[PRE170]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE170]'
- en: '[PRE171]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE171]'
- en: This recipe showed how it’s possible to parse date values and create a datetime
    Series, as well as how to calculate time intervals.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱展示了如何解析日期值并创建日期时间序列，以及如何计算时间间隔。
- en: How it works…
  id: totrans-379
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'The first task when working with dates in pandas is converting them properly
    into a pandas datetime Series. We tackled a couple of the most common issues in
    *steps 3*, *4*, and *8*: missing values, date conversion from integer parts, and
    date conversion from strings. `birthmonth` and `birthyear` are integers in the
    NLS data. We confirmed that those values are valid values for date months and
    date years. If, for example, there were month values of 0 or 20, the conversion
    to pandas datetime would fail.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 中处理日期时，第一项任务是将其正确转换为 pandas datetime Series。在 *步骤 3*、*4* 和 *8* 中，我们处理了一些最常见的问题：缺失值、从整数部分转换日期和从字符串转换日期。`birthmonth`
    和 `birthyear` 在 NLS 数据中是整数。我们确认这些值是有效的日期月份和年份。如果，举例来说，存在月份值为 0 或 20，则转换为 pandas
    datetime 将失败。
- en: Missing values for `birthmonth` or `birthyear` will result in a missing `birthdate`.
    We used `fillna` for the missing value for `birthmonth`, assigning it to the mean
    value of `birthmonth`. In *step 5*, we calculated an age for each person as of
    March 1, 2024, using the new `birthdate` column. The `calcage` function that we
    created adjusts for individuals whose birth dates come later in the year than
    March 1.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '`birthmonth` 或 `birthyear` 的缺失值将导致 `birthdate` 缺失。我们使用 `fillna` 填充了 `birthmonth`
    的缺失值，将其分配为 `birthmonth` 的平均值。在 *步骤 5* 中，我们使用新的 `birthdate` 列计算了每个人截至 2024 年 3
    月 1 日的年龄。我们创建的 `calcage` 函数会根据出生日期晚于 3 月 1 日的个体进行调整。'
- en: Data analysts often receive data files containing date values as strings. The
    `to_datetime` function is the analyst’s key ally when this happens. It is often
    smart enough to figure out the format of the string date data without us having
    to specify a format explicitly. However, in *step 8*, we told `to_datetime` to
    use the `%Y-%m-%d` format with our data.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析师通常会收到包含日期字符串的文件。当发生这种情况时，`to_datetime` 函数是分析师的得力助手。它通常足够智能，能够自动推断出字符串日期数据的格式，而无需我们明确指定格式。然而，在
    *步骤 8* 中，我们告诉 `to_datetime` 使用 `%Y-%m-%d` 格式处理我们的数据。
- en: '*Step 9* told us that there were 214 unique days where COVID-19 cases were
    reported. The first reported day was January 5, 2020, and the last was February
    4, 2024.'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 9* 告诉我们有 214 个独特的日期报告了 COVID-19 病例。第一次报告的日期是 2020 年 1 月 5 日，最后一次报告的日期是
    2024 年 2 月 4 日。'
- en: 'The first two statements in *step 10* involved techniques (sorting and dropping
    duplicates) that we will not explore in detail until *Chapter 9*, *Fixing Messy
    Data When Aggregating*, and *Chapter 10*, *Addressing Data Issues When Combining
    DataFrames*. All you need to understand here is the objective: creating a DataFrame
    with one row per `location` (country), and with the date of the first reported
    COVID-19 case. We did this by only selecting rows from the full data where `new_cases`
    is greater than 0, before sorting that by `location` and `casedate` and keeping
    the first row for each `location`. We then changed the name of `casedate` to `firstcasedate`
    before merging the new `firstcase` DataFrame with the COVID-19 daily cases data.'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 10* 中的前两条语句涉及了一些技巧（排序和去重），我们将在 *第 9 章*《汇总时修复杂乱数据》和 *第 10 章*《合并 DataFrame
    时处理数据问题》中详细探讨。这里你只需要理解目标：创建一个按 `location`（国家）每行数据表示的 DataFrame，并记录首次报告的 COVID-19
    病例日期。我们通过仅选择全数据中 `new_cases` 大于 0 的行来做到这一点，然后按 `location` 和 `casedate` 排序，并保留每个
    `location` 的第一行。接着，我们将 `casedate` 改名为 `firstcasedate`，然后将新的 `firstcase` DataFrame
    与 COVID-19 日病例数据合并。'
- en: Since both `casedate` and `firstcasedate` are datetime columns, subtracting
    the latter from the former will result in a timedelta value. This gives us a Series
    that is the number of days after the first day of `new_cases` for each country
    for each reporting day. The greatest duration (`dayssincefirstcase`) between a
    reported case date (`casedate`) and date of first case (`firstcasedate`) is 1491
    days, or just over 4 years. This interval calculation is useful if we want to
    track trends by how long the virus has been obviously present in a country, rather
    than by date.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `casedate` 和 `firstcasedate` 都是日期时间列，从后者减去前者将得到一个 timedelta 值。这为我们提供了一个 Series，表示每个国家每个报告日期自
    `new_cases` 首次出现后的天数。报告病例日期（`casedate`）和首次病例日期（`firstcasedate`）之间的最大持续时间（`dayssincefirstcase`）是
    1491 天，约为 4 年多。这个间隔计算对于我们想要按病毒在一个国家明显存在的时间来追踪趋势，而不是按日期来追踪趋势时非常有用。
- en: See also
  id: totrans-386
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: Instead of using `sort_values` and `drop_duplicates` in *step 10*, we could
    have used `groupby` to achieve similar results. We’ll explore `groupby` a fair
    bit in *Chapter 9*, *Fixing Messy Data When Aggregating*. We also did a merge
    in *step 10*. *Chapter 10*, *Addressing Data Issues When Combining DataFrames*,
    will be devoted to this topic.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 与其在*步骤10*中使用`sort_values`和`drop_duplicates`，我们也可以使用`groupby`来实现类似的结果。在*第9章*中，我们将深入探索`groupby`，*在聚合时修复杂乱数据*。我们还在*步骤10*中做了一个合并。*第10章*，*合并DataFrame时解决数据问题*，将专门讨论这个主题。
- en: Using OpenAI for Series operations
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用OpenAI进行Series操作
- en: Many of the Series operations demonstrated in the previous recipes in this chapter
    can be assisted by AI tools, including by PandasAI, with the large language model
    from OpenAI. In this recipe, we examine how to use PandasAI to query Series values,
    create new Series, set Series values conditionally, and do some rudimentary reshaping
    of DataFrames.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 本章之前食谱中演示的许多Series操作可以借助AI工具完成，包括通过PandasAI与OpenAI的大型语言模型一起使用。在这个食谱中，我们研究如何使用PandasAI查询Series的值，创建新的Series，有条件地设置Series的值，并对DataFrame进行一些基础的重塑。
- en: Getting ready
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: We will work with the NLS and COVID-19 case daily data again in this recipe.
    We will also work with PandasAI, which can be installed with `pip install pandasai`.
    You also need to get a token from [openai.com](https://openai.com) to send a request
    to the OpenAI API.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将再次使用NLS和COVID-19每日数据。我们还将使用PandasAI，它可以通过`pip install pandasai`安装。你还需要从[openai.com](https://openai.com)获取一个令牌，以便向OpenAI
    API发送请求。
- en: How to do it...
  id: totrans-392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The following steps create a PandasAI `SmartDataframe` object, and then use
    the chat method of that object to submit natural language instructions for a range
    of Series operations:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤创建一个PandasAI `SmartDataframe`对象，然后使用该对象的聊天方法提交一系列Series操作的自然语言指令：
- en: 'We first need to import the `OpenAI` and `SmartDataframe` modules from PandasAI.
    We also have to instantiate an `llm` object:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先需要从PandasAI导入`OpenAI`和`SmartDataframe`模块。我们还需要实例化一个`llm`对象：
- en: '[PRE172]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE172]'
- en: 'We load the NLS and COVID-19 data and create a `SmartDateFrame` object. We
    pass the `llm` object as well as a pandas DataFrame:'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们加载NLS和COVID-19数据并创建一个`SmartDataframe`对象。我们传入`llm`对象以及一个pandas DataFrame：
- en: '[PRE173]'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE173]'
- en: 'Now we are ready to generate summary statistics on Series from our `SmartDataframe`.
    We can ask for the average for a single Series, or for multiple Series:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们准备好在我们的`SmartDataframe`上生成Series的汇总统计信息。我们可以请求单个Series的平均值，或者多个Series的平均值：
- en: '[PRE174]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE174]'
- en: '[PRE175]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE175]'
- en: '[PRE176]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE176]'
- en: '[PRE177]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE177]'
- en: 'We can also summarize Series values by another Series, usually one that is
    categorical:'
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以通过另一个Series来汇总Series的值，通常是一个分类的Series：
- en: '[PRE178]'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE178]'
- en: '[PRE179]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE179]'
- en: 'We can also create a new Series with the `chat` method of `SmartDataframe`.
    We do not need to use the actual column names. For example, PandasAI will figure
    out that we want the `childathome` Series when we write *child at home*:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以通过`SmartDataframe`的`chat`方法创建一个新的Series。我们不需要使用实际的列名。例如，PandasAI会自动识别我们想要的是`childathome`
    Series，当我们写下*child at home*时：
- en: '[PRE180]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE180]'
- en: '[PRE181]'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE181]'
- en: 'We can use the `chat` method to create Series values conditionally:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用`chat`方法有条件地创建Series值：
- en: '[PRE182]'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE182]'
- en: '[PRE183]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE183]'
- en: 'PandasAI is quite flexible regarding the language you might use here. For example,
    the following provides the same results as in *step 6*:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PandasAI对你在这里使用的语言非常灵活。例如，以下内容提供了与*步骤6*相同的结果：
- en: '[PRE184]'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE184]'
- en: '[PRE185]'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE185]'
- en: 'We can do calculations across a number of similarly named columns:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以对多个同名的列进行计算：
- en: '[PRE186]'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE186]'
- en: This will calculate the average of all `weeksworked00`-`weeksworked22` columns
    and assign that to a new column called `weeksworkedavavg`.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 这将计算所有`weeksworked00`到`weeksworked22`列的平均值，并将其分配给一个名为`weeksworkedavavg`的新列。
- en: 'We can easily impute values where they are missing based on summary statistics:'
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以根据汇总统计轻松地填补缺失的值：
- en: '[PRE187]'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE187]'
- en: '[PRE188]'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE188]'
- en: '[PRE189]'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE189]'
- en: '[PRE190]'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE190]'
- en: 'We can also use PandasAI to do some reshaping, similar to what we did in the
    previous recipe. Recall that we worked with the COVID-19 cases data and wanted
    the first row of data for each country. Let’s do a simplified version of that
    the traditional way first:'
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以使用PandasAI进行一些重塑，类似于我们在之前的食谱中所做的。回顾一下，我们处理了COVID-19病例数据，并希望获取每个国家的第一行数据。让我们首先以传统方式做一个简化版本：
- en: '[PRE191]'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE191]'
- en: '[PRE192]'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE192]'
- en: '[PRE193]'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE193]'
- en: '[PRE194]'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE194]'
- en: 'We can get the same results by creating a `SmartDataframe` and using the `chat`
    method. The natural language I use here is remarkably straightforward, *Show first
    casedate and location and other values for each country*:'
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过创建一个`SmartDataframe`并使用`chat`方法来获得相同的结果。这里使用的自然语言非常简单，*显示每个国家的第一个casedate、location和其他值*：
- en: '[PRE195]'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE195]'
- en: '[PRE196]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE196]'
- en: '[PRE197]'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE197]'
- en: '[PRE198]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE198]'
- en: Notice that PandasAI makes smart choices about the columns to get. We get the
    columns we need rather than all of them. We could have also just passed the names
    of the columns we wanted to the `chat`.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，PandasAI 会智能地选择需要获取的列。我们只获取我们需要的列，而不是所有列。我们也可以直接将我们想要的列名传递给`chat`。
- en: That’s a little PandasAI and OpenAI magic for you! One pretty ordinary sentence
    passed to the `chat` method did all of the work for us.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是一点 PandasAI 和 OpenAI 的魔力！通过传递一句相当普通的句子给`chat`方法，就完成了所有的工作。
- en: How it works…
  id: totrans-435
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Much of the work when using PandasAI is really just importing the relevant libraries
    and instantiating large language model and `SmartDataframe` objects. Once that’s
    done, simple sentences sent to the `chat` method of the `SmartDataframe` are sufficient
    to summarize Series values and create new Series.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PandasAI 时，大部分工作其实就是导入相关库，并实例化大型语言模型和 `SmartDataframe` 对象。完成这些步骤后，只需向 `SmartDataframe`
    的 `chat` 方法发送简单的句子，就足以总结 Series 值并创建新的 Series。
- en: PandasAI excels at generating simple statistics from Series. We don’t even need
    to remember the Series name exactly, as we saw in *step 3*. Often the natural
    language we might use can be more intuitive than traditional pandas methods like
    `groupby`. The *Show satmath average by gender* value passed to `chat` in *step
    4* is a good example of that.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: PandasAI 擅长从 Series 中生成简单的统计信息。我们甚至不需要精确记住 Series 名称，正如我们在*步骤 3*中所见。我们可能使用的自然语言往往比传统的
    pandas 方法（如 `groupby`）更直观。在*步骤 4*中传递给 `chat` 的*按性别显示 satmath 平均值*就是一个很好的例子。
- en: Operations on Series, including the creation of a new Series, is also quite
    straightforward. In *step 5*, we create a total number of children Series (*childnum*)
    by instructing the `SmartDataframe` to add the number of children living at home
    to the number of children not living at home. We don’t even provide the literal
    Series names, *childathome* and *childnotathome* respectively. PandasAI figures
    out what we mean.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 对 Series 进行的操作，包括创建新的 Series，也是相当简单的。在*步骤 5*中，我们通过指示 `SmartDataframe` 将住在家中的孩子数与不住在家中的孩子数相加，创建了一个表示孩子总数的
    Series（*childnum*）。我们甚至没有提供字面上的 Series 名称，*childathome* 和 *childnotathome*。PandasAI
    会自动理解我们的意思。
- en: '*Steps 6* and *7* demonstrate the flexibility that being able to use natural
    language for our Series operations provides. We get the same result if we pass
    *evermarried is ‘No’ when maritalstatus is ‘Never-married’, else ‘Yes’* to `chat`
    in *step 6* or *if maritalstatus is ‘Never-married’ set evermarried2 to ‘No’,
    otherwise ‘Yes’* in *step 7*.'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 6* 和 *7* 展示了使用自然语言进行 Series 操作的灵活性。如果我们在*步骤 6*中将*evermarried 为 ‘No’ 当 maritalstatus
    为 ‘Never-married’，否则为 ‘Yes’*传递给`chat`，或者在*步骤 7*中将*如果 maritalstatus 为 ‘Never-married’，则将
    evermarried2 设置为 ‘No’，否则为 ‘Yes’*传递给`chat`，我们都会得到相同的结果。'
- en: We can also do fairly extensive DataFrame reshaping with simple natural language
    instructions, as in *step 11*. We add *and other values* to the instructions to
    get columns other than *casedate*. PandasAI also figures out that *location* makes
    sense as the index.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过简单的自然语言指令对 DataFrame 进行较为广泛的重塑，正如在*步骤 11*中所示。我们将*and other values*添加到指令中，以获取除了*casedate*之外的列。PandasAI
    还会自动识别出*location*作为索引是有意义的。
- en: There’s more...
  id: totrans-441
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'Given that PandasAI tools are still so new, data scientists are just figuring
    out now how to best integrate these tools into our data cleaning and analysis
    workflow. There are two obvious use cases for PandasAI: 1) checking the accuracy
    of Series operations we do in a more traditional way, and 2) doing Series operations
    in a more intuitive way when pandas or NumPy tools are somewhat less straightforward,
    such as with pandas `groupby` or the NumPy `where` function.'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于 PandasAI 工具仍然非常新，数据科学家们现在才开始弄清楚如何将这些工具最佳地集成到我们的数据清理和分析工作流程中。PandasAI 有两个明显的应用场景：1）检查我们以传统方式进行的
    Series 操作的准确性；2）在 pandas 或 NumPy 工具不够直观时（如 pandas 的 `groupby` 或 NumPy 的 `where`
    函数），以更直观的方式进行 Series 操作。
- en: PandasAI can also be used to build interactive interfaces for querying a data
    store, such as a data dashboard. We can use AI tools to help end users interrogate
    organizational data more effectively. As we saw in *Chapter 3*, *Taking the Measure
    of Your Data*, PandasAI is also great for quickly creating visualizations.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: PandasAI 还可以用于构建交互式界面来查询数据存储，如数据仪表盘。我们可以使用 AI 工具帮助终端用户更有效地查询组织数据。正如我们在*第 3 章*《衡量你的数据》中所看到的，PandasAI
    在快速创建可视化方面也非常出色。
- en: See also
  id: totrans-444
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: We do much more aggregating of data in *Chapter 9*, *Fixing Messy Data When
    Aggregating*, including aggregating data across rows and resampling of date and
    time data.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第9章*，*聚合数据时修复混乱数据*中，我们将进行更多的数据聚合操作，包括跨行聚合数据和重新采样日期和时间数据。
- en: Summary
  id: totrans-446
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This chapter explored a wide range of pandas Series methods for exploring and
    handling data of different types: numeric, strings, and dates. We learned how
    to get values from and generate summary statistics from a Series. We also learned
    how to update Series values, and how to do that for subsets of data or conditionally.
    We also explored specific challenges of working with string or date Series, and
    how to use Series methods to address those challenges. Finally, we saw how PandasAI
    could be used to explore and make changes to Series. In the next chapter, we will
    explore how to identify and fix missing values.'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了多种pandas Series方法，用于探索和处理不同类型的数据：数值、字符串和日期。我们学习了如何从Series中获取值以及如何生成摘要统计信息。我们还了解了如何更新Series中的值，以及如何针对数据子集或根据条件进行更新。我们还探讨了处理字符串或日期Series时的特定挑战，以及如何使用Series方法来应对这些挑战。最后，我们看到如何利用PandasAI来探索和修改Series。在下一章，我们将探索如何识别和修复缺失值。
- en: Join our community on Discord
  id: totrans-448
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://discord.gg/p8uSgEAETX](https://discord.gg/p8uSgEAETX )'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://discord.gg/p8uSgEAETX](https://discord.gg/p8uSgEAETX )'
- en: '![](img/QR_Code10336218961138498953.png)'
  id: totrans-451
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code10336218961138498953.png)'
