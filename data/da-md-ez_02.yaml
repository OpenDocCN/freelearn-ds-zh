- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Getting Started with KNIME
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用 KNIME
- en: 'It''s time to get our hands finally dirty with data as we unveil KNIME, the
    first instrument we find in our data analytics toolkit. This chapter will introduce
    you to the foundational features of any low-code analytics platform and will allow
    you to get started with the universal need you face at the beginning of every
    analytics project: loading and cleaning data.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候亲自接触数据了，让我们揭开 KNIME 的面纱，这是我们数据分析工具包中的第一个工具。本章将向你介绍任何低代码分析平台的基础功能，并帮助你开始进行每个数据分析项目初期的普遍需求：加载和清洗数据。
- en: 'Let''s have a look at the questions this chapter aims to answer:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看本章旨在回答的问题：
- en: What is KNIME and where can I get it?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 KNIME，我在哪里可以下载它？
- en: What are nodes and how do they work?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是节点，它们是如何工作的？
- en: What does a data workflow look like?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据工作流是什么样的？
- en: How can I load some data in KNIME and clean it up?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 KNIME 中加载数据并清洗它？
- en: This is going to be a rather hands-on initiation to the everyday practice of
    data analytics. Since we will spend some time with KNIME, it's worth first getting
    some basic background on it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是一次非常实践性的入门，帮助你了解数据分析的日常操作。由于我们会花一些时间使用 KNIME，因此首先了解一些它的基础知识是值得的。
- en: KNIME (/na�m/) is pronounced like the word *knife* but with an *m* at the end
    instead of an f.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME（/na�m/）的发音类似于单词*knife*，不过结尾是*m*而不是*f*。
- en: KNIME in a nutshell
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: KNIME 简介
- en: '**KNIME** is a low-code data analytics platform known for its ease of use and
    versatility. Let''s go through its most prominent features:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**KNIME** 是一个低代码数据分析平台，以其易用性和多功能性著称。让我们一起来看看它最突出的特点：'
- en: 'KNIME allows the **visual design** of data analytics: this means that you can
    build your sequence of transformation and modeling steps by just drawing it. In
    the same way as you would sketch a flowchart to describe a process using pencil
    and paper, with KNIME you will use a mouse and keyboard to depict what you want
    to do with your data. This is the fundamental difference versus the approach implemented
    in code-based analytics environments: using tools like KNIME means you don''t
    need to write a line of code unless you want to. The visual approach will also
    let you have a clear line of sight of what''s happening with your data at each
    step of the process. This makes even complex procedures intuitive to understand
    and easier to build. For advanced data practitioners like data scientists, this
    means saving a lot of time for debugging a prototype, as they can easily spot
    issues along the way. For business users in need of some data analytics, KNIME
    offers a very hospitable environment, accessible to everyone who wants to learn
    from scratch.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KNIME 允许**可视化设计**数据分析：这意味着你可以通过简单的绘制来构建数据转换和建模步骤。就像你用铅笔和纸画出流程图来描述一个过程一样，使用 KNIME
    时，你将用鼠标和键盘来描绘你想对数据做什么。这与基于代码的分析环境的做法有本质的区别：使用像 KNIME 这样的工具意味着你不需要写一行代码，除非你愿意。可视化的方法还让你清晰地看到数据在每一步操作中的变化。这使得即使是复杂的过程也变得直观易懂，并且更容易构建。对于像数据科学家这样的高级数据从业者来说，这意味着节省了大量调试原型的时间，因为他们可以轻松发现问题所在。对于需要进行数据分析的业务用户，KNIME
    提供了一个非常友好的环境，适合任何想要从零开始学习的人。
- en: 'It is **open source** and free to use: you can download its full version and
    install it on your computer at no cost. Different from what happens with the trial
    version of other products, it offers the complete set of functionalities for data
    analytics without limitations or time constraints. For the sake of completeness:
    KNIME also offers a commercial product (called **KNIME Server**) that enables
    the full operationalization of workflows as real-time applications and services,
    but we will not need to use any of this on our journey.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是**开源**的，且免费使用：你可以免费下载完整版本并安装到你的电脑上，不需要任何费用。与其他产品的试用版不同，它提供了完整的数据分析功能集，没有任何限制或时间约束。为了完整性说明：KNIME
    还提供了商业产品（称为**KNIME Server**），它可以实现工作流的全面操作化，将其转化为实时应用和服务，但在我们的学习过程中不需要使用这些功能。
- en: It offers a rich library of **additional packages** for extending its base functionalities.
    These are available—in most cases—for free. Some of these extensions will let
    you connect KNIME with cloud platforms (like Amazon Web Services or Microsoft
    Azure), access other applications (Twitter or Google Analytics, to mention a few),
    or run specific types of advanced analytics (such as text mining or deep learning).
    Some packages will even let you add some Python or R code into KNIME so that you
    can implement even the most specific and sophisticated functionalities offered
    within their extensive set of libraries. This means that if you know how to program,
    you can leverage that as well in KNIME. The good news is that—in the vast majority
    of cases—you simply don't need to!
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了丰富的**附加包**库，用于扩展其基础功能。这些扩展包大多数情况下是免费的。某些扩展包允许你将KNIME与云平台（如Amazon Web Services或Microsoft
    Azure）连接，访问其他应用（如Twitter或Google Analytics等），或者执行特定类型的高级分析（如文本挖掘或深度学习）。某些包甚至允许你在KNIME中添加Python或R代码，以便你可以实现它们广泛库中提供的最具体和最复杂的功能。这意味着，如果你会编程，你可以在KNIME中利用这项技能。好消息是——在绝大多数情况下——你根本不需要这样做！
- en: 'Lastly, there is a broad and **growing community** of KNIME practitioners around
    the world. This makes it easier to find blogs and forums filled with examples
    (like the KNIME official one, [forum.knime.com](http://forum.knime.com)), tutorials,
    and answers to the most frequent questions you will encounter. Generous KNIME
    users can also share some ready-to-use modules with the rest of the community
    to enable others to replicate them: this further enriches the functionalities
    available out there at the time of need.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，全球有一个广泛而**不断壮大的社区**，由KNIME的用户组成。这使得你更容易找到充满示例的博客和论坛（如KNIME官方论坛，[forum.knime.com](http://forum.knime.com)）、教程以及对你可能遇到的常见问题的答案。慷慨的KNIME用户还可以与其他社区成员分享一些现成的模块，以便其他人复制它们：这进一步丰富了在需要时可用的功能。
- en: All these features make KNIME an all-inclusive tool, to the point that some
    have called it the **Swiss Army knife** of data analytics. Whatever nickname we
    prefer to give it, KNIME is well suited for learning and practicing everyday analytics
    and is certainly a tool worth adding to our kit.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些功能使得KNIME成为一款包罗万象的工具，以至于有些人将其称为数据分析的**瑞士军刀**。无论我们给它什么绰号，KNIME都非常适合用于学习和实践日常分析，绝对是一款值得加入我们工具箱的工具。
- en: 'It''s time to get KNIME up and running on your computer: you can download it
    from the official website [www.knime.com](http://www.knime.com). Just go to the
    **Download** page and get the installation started for your operating system (KNIME
    is available for Windows, Unix, and Mac). When you are done with the installation,
    open the app. At the first run, you might be asked to confirm the location of
    the **Workspace**; this will be the folder where all your projects will be saved.
    After confirming the workspace folder (you can select any location you like),
    you are ready to go: the KNIME interface will be there to welcome you.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候让KNIME在你的计算机上运行起来了：你可以从官网[www.knime.com](http://www.knime.com)下载它。只需进入**下载**页面，开始为你的操作系统安装（KNIME支持Windows、Unix和Mac）。安装完成后，打开应用程序。在首次运行时，你可能需要确认**工作区**的位置；这将是你所有项目保存的文件夹。在确认工作区文件夹后（你可以选择任何你喜欢的位置），你就可以开始使用了：KNIME的界面将欢迎你。
- en: Moving around in KNIME
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在KNIME中移动
- en: 'As we enter the world of KNIME, it makes sense to familiarize ourselves with
    the two keywords we are going to use most often: **nodes** and **workflows**:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进入KNIME的世界时，熟悉我们将最常用的两个关键词是很有意义的：**节点**和**工作流**：
- en: A **node** is the essential building block of any data operation that happens
    in KNIME. Every action you apply on data—like loading a file, filtering out rows,
    applying some formula, or building a machine learning model—is represented by
    a square icon in KNIME, called a **node**.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点**是KNIME中进行任何数据操作的基本构建块。你对数据进行的每一个操作——例如加载文件、过滤行、应用公式或构建机器学习模型——在KNIME中都用一个方形图标表示，称为**节点**。'
- en: A **workflow** is the full sequence of nodes that describe what you want to
    do with your data, from the beginning to the end. To build a data process in KNIME
    you will have to select the nodes you need and connect them in the desired order,
    designing the workflow that is right for you:![](img/B17125_02_01.png)
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作流**是描述你希望对数据进行操作的完整节点序列，从开始到结束。要在KNIME中构建数据处理过程，你需要选择所需的节点，并按所需的顺序连接它们，设计适合你的工作流：![](img/B17125_02_01.png)'
- en: 'Figure 2.1: KNIME user interface: your workbench for crafting analytics'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1：KNIME用户界面：你构建分析的工作台
- en: 'KNIME''s user interface has got all you need to pick and mix nodes to construct
    the workflow that you need. Let''s go through the six fundamental elements of
    the interface that will welcome you as soon as you start the application:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME的用户界面包含了构建你所需工作流所需的所有节点，你可以根据需要自由组合。让我们一起了解一下启动应用程序时界面中的六个基本元素：
- en: '**Explorer**. This is where your workflows will be kept handy and tidy. In
    here you will find: the **LOCAL** workspace, which contains the folders stored
    on your local machine; the KNIME public server, storing many **EXAMPLES** organized
    by topic that you can use for inspiration and replication; the **My-KNIME-Hub**
    space, linked to your user on the KNIME Hub cloud, where you can share private
    and public workflows and reusable modules—called **Components** in KNIME—with
    others (you can create your space for free by registering at [hub.knime.com](http://hub.knime.com)).'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**资源管理器**。这里是你工作流的存放位置，保持它们的整洁有序。在这里你会找到：**LOCAL**工作区，包含存储在你本地计算机上的文件夹；KNIME公共服务器，存储了许多按主题分类的**示例**，你可以用来获取灵感和复制；**My-KNIME-Hub**空间，它与你在KNIME
    Hub云上的账户相关联，你可以与他人分享私人和公共的工作流及可重用模块——这些模块在KNIME中称为**组件**（你可以通过在[hub.knime.com](http://hub.knime.com)注册，免费创建自己的空间）。'
- en: '**Node Repository**. In this space, you can find all the nodes available to
    you, ready to be dragged and dropped into your workflow. Nodes are arranged in
    hierarchical categories: if you click on the chevron sign **>** on the left of
    each header, you will go to the level below. For instance, the first category
    is **IO** (**input/output**) which includes multiple subcategories, such as **Read**,
    **Write**, and **Connectors**. You can search for the node you need by entering
    some keywords in the textbox at the top right. Try entering the word `Excel` in
    the search box: you will obtain all nodes that let you import and export data
    in the Microsoft spreadsheet format. As a painter would find all available colors
    in the palette, the repository will give you access to all available nodes for
    your workflow:![](img/B17125_02_02.png)'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**节点仓库**。在这个空间里，你可以找到所有可用的节点，随时准备拖放到你的工作流中。节点按照层级分类：如果你点击每个标题左侧的**>**符号，你将进入下一级。例如，第一个分类是**IO**（**输入/输出**），其中包含多个子类别，如**读取**、**写入**和**连接器**。你可以通过在右上角的文本框中输入关键词来搜索所需的节点。试着在搜索框中输入`Excel`，你会获得所有允许你导入和导出Microsoft电子表格格式数据的节点。就像画家在调色板中找到所有可用的颜色一样，仓库将为你提供所有可用的节点，供你在工作流中使用：![](img/B17125_02_02.png)'
- en: 'Figure 2.2: The Node Repository lists all the nodes available for you to pick'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.2：节点仓库列出了所有可供你选择的节点
- en: '**Workflow Editor**. This is where the magic happens: in here you will combine
    the nodes you need, connect them as required, and see your workflow come to life.
    Following the analogy we started above with the color palette, the Workflow Editor
    will be the white canvas on which you will paint your data masterpiece.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**工作流编辑器**。这里是魔法发生的地方：在这里你将组合所需的节点，按需连接它们，并看到你的工作流开始运作。沿用我们之前提到的调色板的类比，工作流编辑器就是你用来绘制数据杰作的白色画布。'
- en: '**Node Description**. This is an always-on reference guide for each node. When
    you click on any node—lying either in the repository or in the Workflow Editor—this
    window gets updated with all you need to know about the node. The typical description
    of a node includes three parts: a summary of what it does and how it works, a
    list of the various steps of configuration we can apply (**Dialog Options**),
    and finally, a description of the input and output ports of the node (**Ports**).'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**节点描述**。这是一个始终开启的参考指南，适用于每个节点。当你点击任何一个节点——无论它位于仓库中还是工作流编辑器中——这个窗口都会更新，显示你需要了解的所有关于该节点的信息。节点的典型描述包括三部分内容：它的功能和工作原理的总结、我们可以应用的各种配置步骤列表（**对话框选项**），以及节点的输入输出端口描述（**端口**）。'
- en: '**Outline**. Your workflow can get quite big and you might not be able to see
    it fully within your Workflow Editor: the Outline gives you a full view of the
    workflow and shows which part you are currently visualizing in the Workflow Editor.
    If you drag the blue rectangle around, you can easily jump to the part of the
    workflow you are interested in.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**大纲**。你的工作流可能会变得很大，你可能无法在工作流编辑器中完全查看它：大纲提供了工作流的全貌，并显示你当前在工作流编辑器中查看的部分。如果你拖动蓝色矩形框，你可以轻松跳转到你感兴趣的工作流部分。'
- en: '**Console** and **Node Monitor**. In this section, you will find a couple of
    helpful diagnostics and debugging gadgets. The **Console** will show the full
    description of the latest warnings and errors while the **Node Monitor** shows
    a summary of the data available at the output port of the currently selected node.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**控制台**和**节点监控器**。在这个部分，你会找到几个有用的诊断和调试工具。**控制台**将显示最新的警告和错误的完整描述，而**节点监控器**则显示当前选中节点输出端口上的数据摘要。'
- en: You can personalize the look and feel of the user interface by adding and removing
    elements from the **View** menu. Should you want to go back to the original setup,
    as displayed in the figure above, just click on **View | Reset Perspective...**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过从**视图**菜单中添加和删除元素，来个性化用户界面的外观和感觉。如果你想恢复到原始设置，如上图所示，只需点击**视图 | 重置视角...**。
- en: 'Although these six sections cover all the essential needs, the KNIME user interface
    offers more sections that you might be curious enough to explore. For instance,
    on the left, you have the Workflow Coach, which suggests the next most likely
    node you are going to add to the workflow, based on what other users do. Lastly,
    in the same window of the Node Description, you will find an additional panel
    (look for its header at the top) called KNIME Hub: in here, you can search for
    examples, additional packages, and modules that you can directly drag and drop
    into your workflow, as you would do from the Node Repository.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这六个部分涵盖了所有基本需求，但 KNIME 用户界面还提供了更多可能会引起你好奇的部分。例如，在左侧，你可以看到工作流教练，它会根据其他用户的操作，建议你下一个最可能添加到工作流中的节点。最后，在节点描述的同一窗口中，你会找到一个附加面板（在顶部查找其标题），名为
    KNIME Hub：在这里，你可以搜索示例、附加包和模块，这些可以直接拖放到你的工作流中，方式和从节点库中拖放一样。
- en: Nodes
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 节点
- en: 'Nodes are the backbone of KNIME and we need to feel totally confident with
    them: let''s discover how they work and what types of nodes are available:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 节点是 KNIME 的核心，我们需要对它们有完全的信心：让我们来了解它们是如何工作的，以及有哪些类型的节点可用：
- en: '![](img/B17125_02_03.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_02_03.png)'
- en: 'Figure 2.3: Anatomy of a node in KNIME: the traffic light tells us the current
    status'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3：KNIME 节点的构成：交通信号灯告诉我们当前的状态
- en: 'As you can see from the figure above, nodes look like square icons with some
    text and shapes around them. More precisely:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正如上图所示，节点看起来像是带有一些文本和形状的方形图标。更具体地说：
- en: On top of a node, you will find its **Name** in bold. The name tells you, in
    a nutshell, what that type of node does. For example, to rename some columns in
    a table, we use the node called **Column Rename**.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在节点的顶部，你会看到它的**名称**，以粗体显示。该名称简要地告诉你该类型的节点执行什么操作。例如，要重命名表中的某些列，我们使用的节点叫做**列重命名**。
- en: At the bottom of the square, you find a **Comment** . This is a label that should
    explain the specific role of that node in your workflow. By default, KNIME applies
    a counter to every new node as it gets added to the workflow, like Node 1, Node
    2, and so on. You can modify the comment by just double-clicking on it.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在方框的底部，你会看到一个**注释**。这是一个标签，用于说明该节点在你的工作流中的具体作用。默认情况下，KNIME 会为每个新添加到工作流中的节点应用一个计数器，如节点1、节点2等。你可以通过双击注释来修改它。
- en: 'I strongly encourage you to comment on every single node in your workflow with
    a short description that explains what it does. When workflows get complex you
    will quickly forget what each node was meant to do there. Trust me: it''s a worthy
    investment of your time!'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈建议你在工作流中的每个节点上添加简短的注释，解释该节点的作用。当工作流变得复杂时，你很快就会忘记每个节点的具体功能。相信我：这是一个值得投入时间的事情！
- en: 'Nodes are connected through **Ports**, lying at the left and at the right of
    the square. By convention, the ports on the left are input ports, as they bring
    data into the node, while ports on the right are output ports, carrying the results
    of the node execution. Ports can have different shapes and colors, depending on
    what they carry: most of them are triangles, as they convey data tables, but they
    could be squares (models, connections, images, and more) or circles (variables).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点通过**端口**连接，这些端口位于方框的左右两侧。按照惯例，左侧的端口是输入端口，它们将数据引入节点，而右侧的端口是输出端口，承载节点执行的结果。端口的形状和颜色可能不同，这取决于它们承载的内容：大多数端口是三角形的，因为它们传递数据表，但也可能是方形（模型、连接、图像等）或圆形（变量）。
- en: 'At the bottom of every node, you have a traffic light that signals the current
    **Status** of the node. If the red light is on, the node is not ready yet to do
    its job: it could be that some required data has not been given as an input or
    some configuration step is needed. When the light is amber, the node has all it
    needs and is ready to be executed on your command. The green light is good news:
    it means that the node was successfully executed and the results are available
    at the output ports. Some icons can appear on the traffic light if something is
    not right: a yellow triangle with an exclamation mark indicates a warning while
    a red circle with a cross announces an error. In these cases, you can learn more
    about what went wrong by keeping your mouse on them for a second (a label will
    appear) or by reading the Console.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个节点的底部，您会看到一个交通信号灯，显示节点当前的**状态**。如果红灯亮起，说明节点尚未准备好执行任务：可能是某些必需的数据尚未作为输入提供，或者需要进行一些配置步骤。当信号灯呈琥珀色时，说明节点已经具备所需的一切，准备在您的命令下执行。绿灯表示好消息：意味着节点已成功执行，结果可以在输出端口获得。如果出现某些图标说明有问题：黄色三角形带感叹号表示警告，而红色圆圈带叉表示错误。在这种情况下，您可以将鼠标悬停在图标上几秒钟（会显示一个标签）或通过查看控制台来了解问题所在。
- en: 'As we have already started to see in the Node Repository, there are several
    families of nodes available in KNIME, each responding to a different class of
    data analytics needs. Here are the most popular ones:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 Node Repository 中已经看到的，KNIME 提供了几种类型的节点，每种节点都可以满足不同类别的数据分析需求。以下是最常见的几类：
- en: '**Input & Out**p**ut**: these nodes will bring data in and out of KNIME. Normally,
    input nodes are at the beginning of workflows: they can open files in different
    formats (CSV, Excel, images, webpages, to mention some) or connect to remote databases
    and pull the data they need. As you can see from *Figure 2.4*, the input nodes
    have only output ports on the right and do not have any input ports on the left
    (unless they require a connection with a database). This makes sense as they have
    the role of initiating a workflow by pulling data into it after reading it from
    somewhere. Conversely, output nodes tend to be used at the end of a workflow as
    they can save data to files or cloud locations. They rarely have output ports
    as they close our chain of operations.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入与输出**：这些节点负责将数据导入和导出 KNIME。通常，输入节点位于工作流的开始部分：它们可以打开不同格式的文件（如 CSV、Excel、图像、网页等），或连接到远程数据库并提取所需数据。正如您在*图
    2.4*中看到的，输入节点仅在右侧有输出端口，左侧没有任何输入端口（除非需要与数据库建立连接）。这很有意义，因为它们的作用是通过从某处读取数据后将其导入工作流来启动工作流。相反，输出节点通常在工作流的末尾使用，因为它们可以将数据保存到文件或云端位置。它们很少有输出端口，因为它们结束了我们的操作链。'
- en: '**Manipulation**: These nodes are capable of handling data tables and transforming
    them according to our needs. They can apply steps for aggregating, combining,
    sorting, filtering, and reshaping tables, but also managing missing values, normalizing
    data points, and converting data types. These nodes, together with those in the
    previous family, are virtually unmissable in any data analytics workflow: they
    can jointly clean the data and prepare it in the format required by any subsequent
    step, like creating a model, a report, or a chart. These nodes can have one or
    more input ports and one or more output ports, as they are capable of merging
    and splitting tables.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据处理**：这些节点能够处理数据表并根据我们的需求对其进行转换。它们可以应用聚合、合并、排序、筛选和重塑表格的步骤，还能处理缺失值、数据标准化以及数据类型转换。这些节点与前述节点一起，几乎在任何数据分析工作流中都是必不可少的：它们可以共同清理数据并将其准备成任何后续步骤所需的格式，例如创建模型、报告或图表。这些节点可以有一个或多个输入端口和一个或多个输出端口，因为它们能够合并和拆分表格。'
- en: '**Analytics**: These are the smartest nodes of the pack, able to build statistical
    models and support the implementation of artificial intelligence algorithms. We
    will learn how to use these nodes in the chapters dedicated to machine learning.
    For now, it will be sufficient to keep with us the reassuring thought that even
    complex AI procedures (like creating a deep neural network) can be obtained by
    wisely combining the right modeling nodes, available in our Node Repository. As
    you will notice in *Figure 2.4*, some of the ports are squares as they stand for
    statistical models instead of data tables.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分析**：这些是最聪明的节点，能够构建统计模型并支持人工智能算法的实现。在专门讲解机器学习的章节中，我们将学习如何使用这些节点。现在，最重要的是要有一个安慰人心的想法，那就是即使是复杂的人工智能过程（比如创建深度神经网络）也可以通过明智地组合我们节点库中的正确建模节点来实现。正如你在*图
    2.4*中看到的，某些端口是方形的，它们代表的是统计模型而非数据表。'
- en: '**Flow Control**: Sometimes, our workflows will need to go beyond the simple
    one-branch structure where data flows only once and follows a single chain of
    nodes. These nodes can create loops across branches so we can repeat several steps
    through cycles, like a programmer would do with flow control statements (for those
    of you who can program, think of `while` or `for` constructs). We can also dynamically
    change the behavior of nodes by controlling their configuration through variables.
    These nodes are more advanced and, although we don''t need them most of the time,
    they are a useful resource when the going gets tough.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流程控制**：有时，我们的工作流需要超越简单的单分支结构，其中数据只流动一次，并遵循一条单一的节点链。这些节点可以在各个分支之间创建循环，这样我们就可以通过循环重复多个步骤，就像程序员使用流程控制语句一样（对于会编程的人来说，想想
    `while` 或 `for` 语句）。我们还可以通过变量控制节点的配置，动态地改变节点的行为。这些节点更加高级，尽管我们大多数时候不需要它们，但当遇到困难时，它们是一个有用的资源。'
- en: '**All others**: On top of the ones above, KNIME offers many other types of
    nodes, which can help us with more specific needs. Some nodes let us interact
    systematically with third-party applications through interfaces called **Application
    Programming Interfaces** (**APIs**): for example, an extension called KNIME Twitter
    Connectors lets you search for tweets or download public user information in mass
    to run some analytics on it. Other extensions will let you blend KNIME with programming
    languages like Python and R so you can run snippets of code in KNIME or execute
    KNIME workflows from other environments. You will also have nodes for running
    statistical tests and for building visualizations or full reports.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**其他所有**：除了上面提到的节点外，KNIME 还提供了许多其他类型的节点，可以帮助我们满足更具体的需求。某些节点让我们通过称为**应用程序编程接口**（**APIs**）的接口与第三方应用程序系统地交互：例如，一个名为
    KNIME Twitter Connectors 的扩展让你搜索推文或批量下载公开用户信息，以便进行分析。其他扩展则让你将 KNIME 与 Python 和
    R 等编程语言结合使用，这样你就可以在 KNIME 中运行代码片段，或者从其他环境中执行 KNIME 工作流。你还会有运行统计测试、构建可视化或生成完整报告的节点。'
- en: When you are looking for advanced functionality in KNIME, you can check the
    KNIME Hub or run a search on [nodepit.com](http://nodepit.com), a search engine
    for KNIME workflows, components, and nodes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在 KNIME 中寻找高级功能时，可以访问 KNIME Hub 或在 [nodepit.com](http://nodepit.com) 上进行搜索，这是一个用于搜索
    KNIME 工作流、组件和节点的搜索引擎。
- en: '![](img/B17125_02_04.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_02_04.png)'
- en: 'Figure 2.4: A selection of KNIME nodes by type: these are the LEGO® bricks
    of your data analytics flow'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4：按类型选择的 KNIME 节点：这些是你数据分析流程的 LEGO® 积木
- en: I hope that reading about the broad variety of things you can do with nodes
    has whetted your appetite for more. It's finally time to see nodes in action and
    build a simple KNIME workflow.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望了解可以通过节点完成的各种任务能激起你更大的兴趣。现在是时候看看节点的实际应用，并构建一个简单的 KNIME 工作流了。
- en: Hello World in KNIME
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 KNIME 中的 Hello World
- en: 'As you put together your first workflow, you will learn how to interact with
    KNIME''s user interface to connect, configure, and execute nodes: this is the
    bread and butter of any KNIME user, which you are about to become.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建第一个工作流时，你将学习如何与 KNIME 的用户界面进行交互，连接、配置和执行节点：这就是任何 KNIME 用户的核心，你即将成为其中的一员。
- en: 'The title of this section is a thing for geeks: in fact, when you learn a new
    programming language, `"Hello, World!"` is the first program you get to write.
    It is very simple and is meant to illustrate the basic syntax of a language.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的标题是为技术爱好者准备的：事实上，当你学习一门新的编程语言时，`"Hello, World!"` 是你编写的第一个程序。它非常简单，旨在展示一种语言的基本语法。
- en: 'Let''s imagine we have a simple and repetitive data operation to perform regularly:
    every day we receive a text file in **Comma-Separated Value** (**CSV**) format,
    which reports the cumulative sales generated by country in the year to date. The
    original file has some unnecessary columns and the order of rows is random. We
    need to apply some basic transformation steps so that we end up with a simple
    table showing just two columns: one is the name of the country and the other the
    amount of generated sales. We also want the rows to be sorted by decreasing sales.
    Lastly, we need to convert the file into Excel as it is a format that''s easier
    to read for our colleagues. We can build a KNIME workflow that does exactly that
    once, in a way that we don''t need to repeat the tedious task manually every day.
    Let''s open KNIME Analytics Platform and build our time-saving workflow.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个简单且重复的数据操作需要定期执行：每天我们都会收到一个**逗号分隔值**（**CSV**）格式的文本文件，该文件报告了按国家分列的年初至今的累计销售额。原始文件有一些不必要的列，且行的顺序是随机的。我们需要执行一些基本的转换步骤，以便最终得到一个简单的表格，显示两个列：一个是国家名称，另一个是生成的销售额。我们还希望按降序对行进行排序。最后，我们需要将文件转换为Excel格式，因为这是一个更容易被同事读取的格式。我们可以构建一个KNIME工作流来完成这一任务，从而避免每天手动重复这项繁琐的工作。现在让我们打开KNIME
    Analytics Platform并构建我们的省时工作流。
- en: 'To keep our workflows tidy, we can organize them hierarchically, in folders:
    in KNIME, folders are called **Workflow Groups**. So, let''s start by creating
    a workflow group that will host our first piece of work:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持工作流的整洁，我们可以将其分层组织到文件夹中：在KNIME中，文件夹被称为**工作流组**。因此，我们首先创建一个工作流组来存放我们的第一个工作：
- en: Right-click on the **LOCAL** entry in the KNIME Explorer section (top-left)
    and then click on **New Workflow Group...** in the pop-up menu.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击KNIME Explorer部分（左上角）的**LOCAL**条目，然后在弹出菜单中点击**新建工作流组...**。
- en: Enter the name of your new folder (you can call it `Chapter 2`) and click on
    **Finish**:![Graphical user interface, text, application
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入新文件夹的名称（您可以将其命名为`Chapter 2`），然后点击**完成**：![图形用户界面，文本，应用程序
- en: Description automatically generated](img/B17125_02_05.png)
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_05.png)
- en: 'Figure 2.5: Creating a Workflow Group in KNIME: keep your work tidy by organizing
    it in folders'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.5：在KNIME中创建工作流组：通过将工作组织到文件夹中保持工作整洁
- en: 'You will see that the new folder has appeared in your local workspace. Now
    we can finally create a new workflow within this group. Similar to what you just
    did when creating a group, you just need to follow a few more steps:'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您会看到新文件夹已出现在本地工作区。现在我们可以在此组内创建一个新的工作流。类似于您在创建组时所做的，您只需再执行几步：
- en: Right-click on the newly created workflow group and then on **New KNIME Workflow...**.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击新创建的工作流组，然后选择**新建KNIME工作流...**。
- en: Enter the name of your new workflow (how about `Hello World`?) and then click
    **Finish**. Your workflow will appear in the editor, which at this point will
    look like a sheet of squared paper.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入新工作流的名称（怎么样，`Hello World`？），然后点击**完成**。您的工作流将出现在编辑器中，此时看起来像是一张方格纸。
- en: 'It''s time to load our CSV file into KNIME, using the proper input node. The
    fastest way to do so is to drag and drop the file directly into the Workflow Editor:
    just grab the file named `raw_sales_country.csv` from the folder where it is located
    and drop it anywhere on the blank editor. KNIME will recognize the type of file
    and automatically implement the right node for reading it: in this case, CSV Reader.
    As you drop the file, its configuration dialog will appear. If at any point you
    need to revise its configuration, you can just double-click on the node to obtain
    the same dialog.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是时候将我们的CSV文件加载到KNIME中了，使用适当的输入节点。最快的方法是直接将文件拖放到工作流编辑器中：只需从文件所在的文件夹中获取名为`raw_sales_country.csv`的文件，然后将其拖放到编辑器的空白处。KNIME会自动识别文件类型，并为其实现正确的读取节点：在这种情况下，是CSV读取器。当您拖放文件时，它的配置对话框将会弹出。如果您在任何时候需要修改配置，只需双击节点即可重新打开相同的对话框。
- en: Like we will do every time we meet a new KNIME node on our journey, let's quickly
    discover how it works and how to configure it.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 就像我们在旅途中遇到每个新的KNIME节点时所做的那样，让我们快速了解它是如何工作的，以及如何配置它。
- en: '![](img/B17125_02_06.png) *CSV Reader*'
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B17125_02_06.png) *CSV读取器*'
- en: 'This node (available in the repository under the path **IO > Reader**) reads
    data from a text file stored in a CSV format and makes it available as a table
    in KNIME. This node is pretty handy: it attempts to detect the format of the file
    and recognizes the type of data stored in each column, allowing you to manually
    change it if needed. It also lets you run some basic reformatting on the fly,
    like changing the names of columns. As you see in *Figure 2.6*, its configuration
    window displays multiple tabs, whose headers appear at the top. The first tab
    (**Settings**) lets you set the fundamentals:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点（在**IO > Reader**路径下的库中提供）从存储在 CSV 格式的文本文件中读取数据，并将其作为表格提供给 KNIME。这个节点非常方便：它会尝试检测文件的格式，并识别每列存储的数据类型，如果需要，你可以手动更改它。它还允许你实时进行一些基本的格式调整，比如更改列名。如*图
    2.6*所示，其配置窗口显示了多个标签，标签头出现在顶部。第一个标签（**设置**）让你设置基本参数：
- en: 'In the first section at the top, you can specify the path of the file to be
    read: to do so, just click on the **Browse...** button and select the file. If
    you dragged and dropped your file in the Workflow Editor, this field is pre-populated.
    The node lets you also read multiple files in a folder having the same format,
    by selecting the **Files in folder** mode.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在顶部的第一部分，你可以指定要读取的文件路径：只需点击**浏览...**按钮并选择文件。如果你已经将文件拖放到工作流编辑器中，字段会自动填充。该节点还允许你通过选择**文件夹中的文件**模式来读取文件夹中具有相同格式的多个文件。
- en: 'In the middle section, you can specify the format of the file, like the characters
    used to delimit rows and columns and if it has column headers. All these parameters
    get automatically guessed by the node when a new file is loaded (you can click
    on **Autodetect format** to force a new attempt). One useful option is **Support
    short data rows**: if this box is ticked, the node will keep working even if some
    rows have incomplete data points. The good news is that in most cases you will
    not need to change any of these parameters manually as the automatic detection
    feature is pretty robust.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在中间部分，你可以指定文件的格式，例如用来分隔行和列的字符，以及是否有列标题。当加载新文件时，节点会自动猜测这些参数（你可以点击**自动检测格式**来强制重新尝试）。一个有用的选项是**支持短数据行**：如果选中此框，即使某些行的数据点不完整，节点仍会继续工作。好消息是，在大多数情况下，你不需要手动更改这些参数，因为自动检测功能非常强大。
- en: At the bottom of the tab, you find the **Preview** of the table read in the
    file. This lets you check that the format has been determined correctly.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在标签的底部，你可以看到文件中读取表格的**预览**。这让你可以检查格式是否正确确定。
- en: '![Graphical user interface, table'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，表格'
- en: Description automatically generated](img/B17125_02_07.png)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_07.png)
- en: 'Figure 2.6: Configuration dialog of the CSV Reader node: you can specify which
    file to read and how'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6：CSV Reader 节点的配置对话框：你可以指定要读取的文件及其读取方式
- en: 'If you move to the second tab of the window (called **Transformation**) you
    will have the opportunity to apply some simple reformatting to your table as it
    gets loaded. For instance, you can: change the name of columns (just write the
    new one in the **New name** column), drop some columns you don''t need (untick
    the box on the left of their name), change the column order (drag and drop them
    using your mouse), and change their data type (for instance, from text to numbers).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你切换到窗口的第二个标签页（称为**转换**），你将有机会在加载表格时应用一些简单的格式调整。例如，你可以：更改列名（只需在**新名称**列中输入新的名称）、删除不需要的列（取消勾选其名称左侧的框）、更改列的顺序（使用鼠标拖放），以及更改其数据类型（例如，从文本更改为数字）。
- en: Every column in a KNIME table is associated with a **data type**, indicated
    by a squared letter beside the name of the column. The most common data types
    are strings (indicated by the letter `S`, which are sets of text characters),
    decimal numbers (letter `D`), integer numbers (`I`), long integers (`L`, like
    integers but able to store more digits), and Boolean values (`B`, which can be
    only `FALSE` or `TRUE`).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME 表格中的每一列都有一个与之相关的**数据类型**，该类型通过列名旁边的方形字母表示。最常见的数据类型有字符串（用字母`S`表示，表示文本字符集合）、十进制数（字母`D`）、整数（`I`）、长整数（`L`，与整数类似，但可以存储更多位数的数字）和布尔值（`B`，只能是`FALSE`或`TRUE`）。
- en: You can check the results of your transformation in the preview section at the
    bottom. To be clear, you could do these transformations later in your workflow
    (you have specific KNIME nodes for renaming columns, changing their orders, and
    so on) but it might be just faster and easier to make these changes here on the
    spot, using one single node.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在底部的预览部分检查转换结果。为了更清楚，你也可以在工作流后续步骤中进行这些转换（你有专门的KNIME节点来重命名列、改变列的顺序等），但直接在这里使用一个节点进行这些更改可能会更快更简便。
- en: In case the CSV Reader node fails in reading your data as you required, try
    another node called File Reader. Especially with ill-formatted files, the latter
    node is more robust than CSV Reader, although it cannot transform the structure
    of the table on the fly.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果CSV读取器节点未能按照要求读取数据，可以尝试另一个叫做文件读取器（File Reader）的节点。尤其是对于格式不正确的文件，后者比CSV读取器更稳定，尽管它无法动态转换表格结构。
- en: '![](img/B17125_02_08.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_02_08.png)'
- en: 'Figure 2.7: The transformation tab of the CSV Reader node: reformat your table
    on the fly'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7：CSV读取器节点的转换标签：动态重新格式化你的表格
- en: 'Looking at the preview of the table in the **Settings** tab, it looks like
    the node has done a good job of interpreting the format of the file. We just noticed
    that there are some columns we don''t need to carry and they can be dropped (specifically,
    `country_CODE` and `population_2020`) and, also, that we can simplify some of
    the column names by renaming them. To do this, we need to move to the **Transformation**
    tab: just click on its name at the top of the window.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看**设置**标签中的表格预览，节点似乎已经很好地解释了文件的格式。我们注意到有些列是不需要的，可以删除（具体来说是`country_CODE`和`population_2020`），另外，我们也可以通过重命名简化一些列名。要做到这一点，我们需要转到**转换**标签：只需点击窗口顶部的标签名称。
- en: Let's first remove the columns we don't need, by just unticking the boxes beside
    their names, as shown in *Figure 2.7*.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，通过取消选中不需要的列旁边的框来删除不需要的列，如*图 2.7*所示。
- en: 'Let''s also assign more friendly titles to the other two columns by typing
    them in the **New name** section: let''s rename `country_name` to `Country` and
    `sales_USD` to `Sales`.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们也为另外两列指定更友好的标题，通过在**新名称**部分输入：将`country_name`重命名为`Country`，将`sales_USD`重命名为`Sales`。
- en: The preview of the transformed table looks exactly like we wanted; this means
    we are done with the configuration of this node, and we can close it by clicking
    on the **OK** button.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 经过转换后的表格预览看起来正如我们所希望的那样；这意味着我们已经完成了该节点的配置，可以通过点击**确定**按钮关闭它。
- en: To keep things clear to ourselves and others we want to comment on every node
    in our workflows. Let's start from this very first node. If we double-click on
    the label underneath (which by default will read **Node 1**), we can change it
    to something more meaningful, like `Read raw data`. From this point on, I will
    not mention every time we need to comment on each node—just make it become a habit.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了让自己和他人更清楚明了，我们希望对每个节点进行注释。我们从第一个节点开始。如果我们双击下面的标签（默认情况下会显示**Node 1**），我们可以将其更改为更有意义的内容，如`读取原始数据`。从现在起，我不会每次都提到需要注释每个节点——只需养成这个习惯即可。
- en: 'Our node is displaying an encouraging yellow traffic light: it means it has
    all it needs to fulfill its duty—we just need to say the word. To execute a node
    in KNIME, we can either select it and press F7 on our keyboard or right-click
    on the node to obtain the pop-up menu, as shown in *Figure 2.8*. When it appears,
    click on **Execute**:![Graphical user interface, application'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的节点显示了一个鼓舞人心的黄色交通灯：这意味着它已经具备完成任务所需的一切——我们只需要发出执行指令。要执行KNIME中的节点，我们可以选择该节点并按键盘上的F7，或右键点击节点以显示弹出菜单，如*图
    2.8*所示。当菜单出现时，点击**执行**：![图形用户界面，应用程序
- en: Description automatically generated](img/B17125_02_09.png)
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_02_09.png)
- en: 'Figure 2.8: The pop-up menu in the Workflow Editor: right-click on any node
    to make it appear'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.8：工作流编辑器中的弹出菜单：右键点击任何节点以显示菜单
- en: 'The traffic light turning green is a good sign: our node was successfully executed.
    A useful feature of KNIME is that you can easily inspect what''s going on at each
    step of the flow, by viewing what data is available at the output ports of every
    node. In the pop-up menu obtained by right-clicking on a node, you will find one
    or more icons showing a magnifying lens (normally one for each output port, at
    the bottom of the menu). By clicking on these icons, you will open a window showing
    the data you are after. Let''s do so now: right-click to make the pop-up menu
    appear and then click on **File Table** at the bottom of the menu (alternatively
    you can check out the Node Monitor or use the keyboard shortcut to open the first
    output view of a node, which is Shift + F6). Not surprisingly, we obtain the same
    table we had in preview in the preview step. It seems that, so far, everything
    is working right. We can click **OK** and move on.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交通信号灯变绿是一个好兆头：我们的节点已成功执行。KNIME的一个有用功能是，你可以轻松检查每个流程步骤中发生的情况，通过查看每个节点的输出端口上可用的数据。在右键点击节点后弹出的菜单中，你会找到一个或多个显示放大镜的图标（通常每个输出端口会有一个）。点击这些图标，你会打开一个窗口，查看你需要的数据。现在让我们这么做：右键点击弹出菜单，然后点击菜单底部的**文件表**（或者你可以查看节点监视器，或使用快捷键打开节点的第一个输出视图，快捷键是Shift
    + F6）。不出所料，我们获得了在预览步骤中看到的相同表格。到目前为止，一切似乎都在正常工作。我们可以点击**确定**并继续。
- en: 'The next step is to sort rows by decreasing amounts of sales. We can use a
    node that is meant to do exactly that: Sorter. Let''s add our Sorter node to the
    workflow, pulling it from the Node Repository at the bottom left. You can either
    look it up by typing `Sorter` in the search box or find it in the hierarchy by
    clicking first on **Manipulation**, then **Row**, and—finally—**Transform**. When
    you see the Sorter node, grab it with your mouse and drop it on the workflow,
    at the right of the CSV Reader node.'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是按销售额从高到低排序行。我们可以使用一个专门用来做这件事的节点：排序器。让我们将排序器节点添加到工作流中，从左下角的节点库中拖动它。你可以通过在搜索框中输入`Sorter`来查找它，或者通过依次点击**操作**、**行**和**转换**来在层级结构中找到它。当你看到排序器节点时，使用鼠标拖动并将其放置在CSV读取节点的右侧。
- en: Your node is now lying alone in the workflow while we want it to be cooperating
    with other nodes. In fact, we need it to sort the table output by the CSV Reader,
    so we need to create a connection between the two nodes. In KNIME, we create connections
    by just drawing them with the mouse. Click on the output port of the CSV Reader
    (the little arrow on its right) and while keeping the mouse button pressed, go
    to the input port of the Sorter node. When you release the button, you will see
    a connection appearing between the nodes. This is exactly what we wanted, the
    table given in the output by the CSV Reader has now become an input for the Sorter.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你的节点孤零零地放置在工作流中，但我们希望它能与其他节点协作。事实上，我们需要它来对CSV读取器的表格输出进行排序，所以我们需要在两个节点之间建立连接。在KNIME中，我们只需用鼠标绘制连接即可。点击CSV读取器的输出端口（其右侧的小箭头），并保持按住鼠标按钮，拖动到排序器节点的输入端口。当你松开按钮时，你会看到节点之间出现连接。这正是我们想要的，CSV读取器的输出表格现在成为了排序器的输入。
- en: 'We are now ready to configure the Sorter: let''s learn about our new node.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们现在已经准备好配置排序器：让我们来了解一下我们的新节点。
- en: '**![](img/B17125_02_10.png) *Sorter***'
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**![](img/B17125_02_10.png) *排序器*** '
- en: 'This node (available in the repository in **Manipulation > Row > Transform**)
    can sort the rows of a table according to a set of criteria defined by the user.
    Its configuration is self-explanatory: from the drop-down menu, you can select
    the column you wish to sort by. The radio buttons on the right let you choose
    whether the sorting shall follow an **Ascending** (A to Z or 1 to 9) or **Descending**
    (the other way around) order. You can add additional rules on other columns that
    will come to play to *break the ties* in case multiple rows carry the same value
    in a column. To do so, just click on the **Add Rule** button and you will see
    further drop-down menus appearing. You can change the order of precedence among
    multiple rules by using the **↑** and **↓** arrows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点（在**操作 > 行 > 转换**的节点库中可用）可以根据用户定义的一组标准对表格的行进行排序。它的配置非常直观：从下拉菜单中选择你希望排序的列。右侧的单选按钮让你选择排序是按**升序**（A到Z或1到9）还是**降序**（相反的顺序）。你还可以在其他列上添加附加规则，以便在多个行在某一列中具有相同值时，*打破平局*。只需点击**添加规则**按钮，你就会看到更多的下拉菜单出现。你可以通过使用**↑**和**↓**箭头来更改多个规则的优先顺序：
- en: '![](img/B17125_02_11.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_02_11.png)'
- en: 'Figure 2.9: Configuration window of the node Sorter: define the desired order
    of your rows'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9：节点排序器的配置窗口：定义你所需的行顺序
- en: To open the configuration window of Sorter, you can either double-click on the
    node or right-click on it and then press **Configure…**. You could also just press
    F6 on your keyboard after selecting the node with your mouse.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要打开排序器的配置窗口，你可以双击节点，或右键点击它然后按**配置...**。你也可以在选择节点后直接按F6键。
- en: 'Given our needs, the configuration of the node is straightforward: just select
    `Sales` in the drop-down menu and then click on the second radio button to apply
    a descending order. Press **OK** to close the window.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据我们的需求，节点的配置非常简单：只需在下拉菜单中选择`Sales`，然后点击第二个单选按钮以应用降序排序。按**确定**关闭窗口。
- en: 'The Sorter node is now clear about the input table to use and about the way we
    want the sorting to happen: it is all ready to go. Let''s execute it (F7 or right-click
    and select **Execute**) and open the view showing its output (Shift + F6 or right-click
    and select **Sorted Table**, the last icon with the magnifying lens):![Table'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 排序器节点现在已经清楚了要使用的输入表格以及我们希望排序的方式：一切准备就绪。让我们执行它（按F7或右键点击选择**执行**），并打开显示其输出的视图（按Shift
    + F6或右键点击选择**已排序表格**，最后一个带放大镜图标）：![表格
- en: Description automatically generated](img/B17125_02_12.png)
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_02_12.png)
- en: 'Figure 2.10: Output of Sorter node: our countries are now showing by decreasing
    sales'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.10：排序器节点的输出：我们的国家现在按销售额降序排列
- en: Every row in a KNIME table is associated with a unique label called **Row ID**.
    When a table is created, row IDs are normally generated in the form of a counter
    (`Row0`, `Row1`, `Row2`, and so on) and are preserved along the workflow. That's
    why in the output of the Sorter node you can still find the original row position
    by looking at the Row IDs on the left.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME表格中的每一行都与一个独特的标签相关联，称为**行ID**。当表格创建时，行ID通常以计数器的形式生成（`Row0`、`Row1`、`Row2`等），并在整个工作流中保持一致。这就是为什么在排序器节点的输出中，你仍然可以通过查看左侧的行ID来找到原始的行位置。
- en: 'It looks like we have our countries sorted in the right order and we can proceed
    to the last step: exporting our table as an Excel file.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们的国家已经按正确的顺序排序，现在可以进行最后一步：将表格导出为Excel文件。
- en: '**![](img/B17125_02_13.png) Excel Writer**'
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**![](img/B17125_02_13.png) Excel 写入器**'
- en: 'This node (available within **IO > Write** in the repository) saves data as
    Excel worksheets. The configuration dialog will let you first select the format
    of the file to create (the legacy `.xls` or the latest `.xlsx` one) and where
    to save it (click on the **Browse...** button to select a path). By selecting
    the **if exists** radio buttons, you can specify what to do if a file with that
    name is already there where you want to save it: you can overwrite the old data,
    append the new data as additional rows, or preserve the original file. An important
    option to check is **Write column headers**: when selected, the column names of
    your table are added as headers in the first row of your Excel file.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点（在库中的**IO > Write**下可用）将数据保存为Excel工作表。配置对话框首先让你选择要创建的文件格式（旧版 `.xls` 或最新的
    `.xlsx` 格式），并选择保存路径（点击**浏览...**按钮选择路径）。通过选择**如果存在**单选按钮，你可以指定如果目标文件夹已有同名文件时该如何处理：你可以覆盖旧数据、将新数据作为附加行追加，或保留原文件。一个重要的选项是**写入列标题**：选中此项时，你的表格列名将作为标题添加到Excel文件的第一行。
- en: Although we don't need to do that now, it's useful to know that some KNIME nodes
    can also save files on cloud-based file systems, like Google Drive or Microsoft
    Sharepoint. This is why you also see the option **Add ports | File System Connection**
    when you click on the three dots (**...**) at the bottom left of the node. Another
    useful feature of the node is that it can manage multiple input tables and save
    them as separate worksheets in the same Excel file. To do so, you need to click
    on the three dots on the node and click on **Add ports > Sheet Input Ports**.
    You can give different names to the various sheets by typing in the **Sheets**
    section of the configuration window.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然现在不需要做这个操作，但值得知道的是，一些KNIME节点也可以将文件保存到基于云的文件系统中，比如Google Drive或Microsoft Sharepoint。这就是为什么当你点击节点左下角的三个点（**...**）时，会看到**添加端口
    | 文件系统连接**选项。这个节点的另一个有用功能是，它可以管理多个输入表格并将它们作为不同的工作表保存在同一个Excel文件中。为此，你需要点击节点上的三个点，然后点击**添加端口
    > 工作表输入端口**。你可以通过在配置窗口的**工作表**部分输入不同的名称来为各个工作表命名。
- en: '![](img/B17125_02_14.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_02_14.png)'
- en: 'Figure 2.11: Configuration window of Excel Writer: select where to save your
    output file'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11：Excel Writer 配置窗口：选择保存输出文件的位置
- en: Let's add the Excel Writer node to our workflow, dragging it from the Node Repository,
    and then create a connection between the output port of the Sorter and the input
    node of the Excel Writer.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将 Excel Writer 节点添加到工作流中，从节点库中拖动它，然后在排序器的输出端口和 Excel Writer 的输入节点之间创建连接。
- en: Open the configuration window of the Excel Writer (double-click on it). The
    only configurations we need to add in this case are the location and the name
    of the output file (click on the **Browse...** button, go to the desired folder,
    and type the name of the new file) and, since we might need to repeat this process
    regularly, select the **overwrite** option using the radio button below.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Excel Writer 的配置窗口（双击它）。在这种情况下，我们需要添加的唯一配置是输出文件的位置和名称（点击 **浏览...** 按钮，进入所需文件夹并输入新文件的名称），由于我们可能需要定期重复此过程，所以请选择下方的
    **覆盖** 选项单选按钮。
- en: It's time to run the node (*F7* or right-click and select **Execute**) and open
    the new file in Excel. You'll be pleased to see that the new file looks exactly
    how we wanted.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是时候运行节点了（*F7* 或右键点击并选择 **执行**），然后在 Excel 中打开新文件。你会高兴地看到新文件正如我们所期望的那样。
- en: 'Congratulations on creating your first KNIME workflow! By combining three nodes
    and configuring them appropriately, you implemented a simple data transformation
    routine that you can now repeat in a matter of seconds, whenever it''s needed.
    More importantly, we used this first tutorial to get acquainted with the fundamental
    operations you need to build any workflow, such as pulling the right nodes, configuring
    and executing them, and checking that all works as it should:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你创建了第一个 KNIME 工作流！通过组合三个节点并适当配置它们，你实现了一个简单的数据转换流程，现在你可以在需要时只需几秒钟就重复执行。更重要的是，我们通过这个第一课熟悉了构建任何工作流所需的基本操作，例如拉取合适的节点、配置和执行它们，并检查一切是否按预期运行：
- en: '![Graphical user interface, application'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序'
- en: Description automatically generated](img/B17125_02_15.png)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_15.png)
- en: 'Figure 2.12: Hello World: your first workflow in KNIME'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12：Hello World：你的第一个 KNIME 工作流
- en: 'We now have all we need to start building more complex data operations, discovering
    what other KNIME nodes can do, and this is exactly what we will do in the next
    few pages. Since we don''t want to lose our precious Hello World workflow, it
    would be a good idea to save it: just press Ctrl + S on your keyboard or click
    on the disk icon at the top left of your screen. If you want to share your workflow
    with others, you first need to export it as a standalone file. To do so, right-click
    on the name of the workflow within the KNIME Explorer panel on the left and then
    select **Export KNIME Workflow...**:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们拥有了构建更复杂数据操作所需的一切，接下来我们将探索其他 KNIME 节点的功能，这正是我们接下来几页要做的事情。为了不丢失我们宝贵的 Hello
    World 工作流，最好将其保存：只需按下键盘上的 Ctrl + S 或点击屏幕左上方的磁盘图标。如果你想与其他人分享工作流，首先需要将其导出为独立文件。为此，右键点击
    KNIME Explorer 面板左侧工作流的名称，然后选择 **导出 KNIME 工作流...**：
- en: '![Graphical user interface, text, application'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序'
- en: Description automatically generated](img/B17125_02_16.png)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_16.png)
- en: 'Figure 2.13: How to export a KNIME workflow: you can then share it with whoever
    you like'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13：如何导出 KNIME 工作流：然后你可以与任何人分享它
- en: In the window that appears, you will have to specify the location and name of
    the file with your workflow by clicking on the **Browse...** button. If you keep
    the **Reset Workflow(s) before export** option checked, KNIME will only export
    the definition of the workflow (the nodes' structure and their configuration)
    without any data in it. If you untick it, the data stored in every executed node
    will be exported as well (making your export much larger in size). You can now
    send the resulting file (with `.KNWF` as an extension) via email or save it in
    a safe place. Whoever receives it can import it back in their KNIME installation
    by clicking on **File | Import KNIME Workflow...** and selecting the location
    of the file to import and the destination of the workflow.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在弹出的窗口中，您需要通过点击 **浏览...** 按钮来指定工作流文件的位置和名称。如果勾选了 **在导出前重置工作流** 选项，KNIME 只会导出工作流的定义（节点结构及其配置），不包含任何数据。如果取消勾选，它将导出每个执行节点中存储的数据（使您的导出文件更大）。现在，您可以通过电子邮件发送生成的文件（扩展名为
    `.KNWF`），或者将其保存在安全的位置。接收此文件的人可以通过点击 **文件 | 导入 KNIME 工作流...** 并选择导入文件的位置以及工作流的目标位置，将其导入到他们的
    KNIME 安装中。
- en: Cleaning data
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清理数据
- en: 'Often, when we deal with real-world data analytics, we face a reality that
    is as annoying as ubiquitous: data can be dirty. The format of text and numbers,
    the order of rows and columns, the presence of undesired data points, and the
    lack of some expected values are all possible glitches that can slow down or even
    jeopardize the process of creating some value from data. Indeed, the lower the
    quality of the input data, the less useful the resulting output will be. This
    inconvenient truth is often summarized with the acronym **GIGO**: **Garbage In,
    Garbage Out**. As a consequence, one of the preliminary phases of a data analytics
    workflow is **Data Cleaning**, meaning the process of systematically identifying
    and correcting inaccurate or corrupt data points. Let''s learn how to build a
    full set of data cleaning steps in KNIME through a realistic example.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理真实世界的数据分析时，我们经常会面临一个既令人恼火又普遍存在的现实：数据可能是脏的。文本和数字的格式、行和列的顺序、不需要的数据点的存在以及缺少一些预期值，都是可能的故障，它们会拖慢甚至危及从数据中创造价值的过程。实际上，输入数据的质量越低，结果输出的价值就越小。这个不便的事实通常用缩写
    **GIGO** 来总结：**Garbage In, Garbage Out（垃圾进，垃圾出）**。因此，数据分析工作流的一个初步阶段是 **数据清理**，即系统地识别和修正不准确或损坏的数据点的过程。让我们通过一个实际的例子来学习如何在
    KNIME 中构建完整的数据清理步骤。
- en: 'In this tutorial, we are going to clean a table that captures information on
    the users of an e-commerce website, such as name, age, email address, available
    credit, and so on. This table has been generated by pulling directly from the
    webserver all the available raw data. Our ultimate objective is to create a clean
    list of contactable users, which we can leverage as a mailing list for sending
    email newsletters. Since the list of users constantly changes (as some subscribe
    and unregister themselves every day), we want to build a KNIME workflow that systematically
    cleans the latest data for us every time we want to update our mailing list:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将清理一个捕获电子商务网站用户信息的表格，例如姓名、年龄、电子邮件地址、可用信用等。这个表格是通过直接从 Web 服务器提取所有可用的原始数据生成的。我们的最终目标是创建一个干净的可联系用户列表，利用它作为邮件列表发送电子邮件通讯。由于用户列表不断变化（每天都有一些人订阅或注销），我们希望建立一个
    KNIME 工作流，每次我们想更新邮件列表时，能够系统地清理最新数据：
- en: '![](img/B17125_02_17.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_02_17.png)'
- en: 'Figure 2.14: The raw data: we certainly have some cleaning chores ahead'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.14：原始数据：我们确实面临一些清理任务
- en: 'As you can see from *Figure 2.14*, a first look at the raw table unveils a
    series of data quality flaws to be looked after. For instance:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正如从 *图 2.14* 中可以看到的那样，初步查看原始表格揭示了一系列需要处理的数据质量问题。例如：
- en: Some rows appear to be duplicated.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些行似乎是重复的。
- en: Names and surnames have inconsistent capitalization and some unpleasant blank
    characters. Additionally, instead of having two separate fields for the name,
    we would prefer to have a single column (currently missing) with the full name
    of each person.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 姓名的大小写不一致，并且存在一些不必要的空白字符。此外，当前表格没有单独的姓名字段，我们希望有一个包含每个人全名的单列（目前缺失）。
- en: Some email addresses are wrongly formatted (as they miss the `@` symbol or the
    full domain), making the respective users not contactable.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些电子邮件地址格式错误（缺少 `@` 符号或完整的域名），使得相应的用户无法联系。
- en: Various values are missing, leaving the cell empty.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 各种值缺失，导致单元格为空。
- en: In KNIME, missing values are indicated with a red question mark symbol, `?`.
    For reference, in computer science, a missing value is referred to with the expression
    `NULL`.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 KNIME 中，缺失值通过红色问号符号 `?` 来表示。作为参考，在计算机科学中，缺失值通常用 `NULL` 来表示。
- en: Some credit values are negative. We know that according to company policy these
    users should be considered inactive and shall not be contacted, so we can remove
    them from the list.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些信用值为负数。根据公司政策，我们知道这些用户应该被视为不活跃用户，因此不应与他们联系，我们可以从列表中将其删除。
- en: Some columns are not needed. In this case, we can drop the column holding the
    IP address of the user since it cannot be used for sending a newsletter or to
    personalize its content.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有些列是不需要的。在这种情况下，我们可以删除包含用户 IP 地址的列，因为它无法用于发送通讯或个性化内容。
- en: 'We have an Excel file (`DirtyData.xlsx`) with an excerpt of the raw data, showing
    samples of all those issues listed above. By using this file as a base, we can
    build a KNIME workflow that polishes the data and exports a good-looking and ready-to-use
    mailing list. Let''s do this one step at a time:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个 Excel 文件（`DirtyData.xlsx`），其中包含原始数据的摘录，展示了上述所有问题的样本。通过使用该文件作为基础，我们可以构建一个
    KNIME 工作流，清理数据并导出一个美观且可用的邮件列表。我们一步步来：
- en: 'First of all, we need to create a blank workflow (you can do this as seen in
    the previous example or—alternatively—you can go to **File | New...** and then
    select **New KNIME Workflow**): we can call it `Cleaning data`.'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个空白工作流（你可以按前面的示例操作，或者——也可以——转到 **文件 | 新建...**，然后选择 **新建 KNIME 工作流**）：我们可以将其命名为
    `清理数据`。
- en: To load the data, we can either drag and drop the source file on the Workflow
    Editor or grab the Excel Reader node from the repository and place it in the blank
    editor space.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要加载数据，我们可以将源文件拖放到工作流编辑器中，或从仓库中抓取 Excel Reader 节点并将其放置在空白的编辑空间中。
- en: '![](img/B17125_02_18.png) *Excel Reader*'
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B17125_02_18.png) *Excel Reader*'
- en: 'This node (**IO > Read**) opens Excel files, reads the content of the specified
    worksheet, and makes it available as a table at its output port. In the main tab
    of the configuration dialog, after indicating which file or folder to open (click
    on **Browse...** to change), you can specify (**Sheet selection**) the worksheet
    to consider: by default, the node will read the first sheet available in the workbook
    but you can indicate the name of a specific sheet or its position. If your sheet
    includes the column headers, you can ask KNIME to use them as column names in
    the resulting table: in the section **Column Header**, you can select which row
    contains the column headers. You can also restrict the reading to a portion of
    the sheet, by specifying the range of columns and rows to read within the **Sheet
    area** section. You can check whether the node is configured correctly by looking
    at the bottom of the window, which gives you a preview of what KNIME is reading
    from the file:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点（**IO > 读取**）打开 Excel 文件，读取指定工作表的内容，并将其作为表格提供给输出端口。在配置对话框的主标签页中，指明要打开的文件或文件夹（点击
    **浏览...** 可以更改），然后可以指定（**工作表选择**）要考虑的工作表：默认情况下，节点会读取工作簿中的第一个工作表，但你可以指定某个特定工作表的名称或位置。如果你的工作表包含列标题，可以让
    KNIME 将它们作为结果表中的列名：在 **列标题** 部分，你可以选择包含列标题的行。你还可以通过指定要读取的列和行的范围，在 **工作表区域** 部分限制读取的范围。你可以通过查看窗口底部的预览，检查节点是否已正确配置，预览中显示了
    KNIME 从文件中读取的内容：
- en: '![Graphical user interface, text, application, email'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_02_19.png)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_19.png)
- en: 'Figure 2.15: Configuration of the Excel Reader node: select file, sheets, and
    areas to read'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.15：Excel Reader 节点的配置：选择文件、工作表和读取区域
- en: If you want to apply some transformations (like renaming columns, reordering
    them, and so on) as the data gets read, you can use the **Transformation** tab,
    which works the same as in the CSV Reader node we have already met.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在读取数据时应用一些转换（例如重命名列、重新排序列等），你可以使用 **转换** 标签页，这个功能与我们之前遇到的 CSV Reader 节点相同。
- en: 'Configuring this node will be pretty simple in our case: we should just select
    the file to open and leave all other parameters unchanged as the default selection
    looks good for us. We could use the **Transformation** tab to make some adjustments
    to the format but we will do it later using the appropriate nodes, so we can keep
    it easy for now.'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的案例中，配置这个节点会非常简单：我们只需选择要打开的文件，保持其他所有参数不变，因为默认选择对我们来说是合适的。我们可以使用**转换**选项卡做一些格式调整，但我们稍后会通过适当的节点来完成，因此现在可以先保持简单。
- en: 'To remove the duplicated rows we can use a new node that does exactly that:
    its name is Duplicate Row Filter.'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要移除重复的行，我们可以使用一个新节点，它正是做这件事的：它的名称是“重复行过滤器”。
- en: '![](img/B17125_02_20.png) *Duplicate Row Filter*'
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B17125_02_20.png) *重复行过滤器*'
- en: This node (**Manipulation > Row > Filter**) identifies rows having the same
    values in selected columns and manages them accordingly. In the first tab of the
    configuration window, you select which columns should be considered for the search
    of duplicates.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点（**Manipulation > Row > Filter**）识别在选定列中具有相同值的行，并相应地进行处理。在配置窗口的第一个选项卡中，您可以选择哪些列应被考虑用于重复项搜索。
- en: 'If more than one column is selected, the node will consider duplicates as only
    rows that have exactly the same values across all the selected columns. In the
    configuration of many KNIME nodes, we will be asked to select a subset of columns,
    so it makes sense to spend some time on becoming acquainted with the interface:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果选择了多个列，节点将仅将完全相同的列值视为重复行。在许多 KNIME 节点的配置中，我们需要选择列的子集，因此花些时间熟悉界面是很有意义的：
- en: The panel on the right (having a green border) contains the columns included
    in your selection while the one on the left (red-bordered) displays the excluded
    columns.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右侧面板（有绿色边框）包含您选择的列，而左侧面板（红色边框）则显示排除的列。
- en: By double-clicking on the names of the columns or by using the four arrow buttons
    in the middle, you can transfer the columns across panes.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过双击列名或使用中间的四个箭头按钮，您可以在面板之间转移列。
- en: If you have many columns, you can look them up by name using the **Filter**
    textboxes at the top of each pane.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您有很多列，可以使用每个面板顶部的**过滤器**文本框按名称查找它们。
- en: If you want to select columns by patterns in their names (like the ones starting
    with an `A`) or by type (integers, decimal numbers, strings, and so on), you can
    select the other options available on the radio selector on top (**Wildcard/Regex
    Selection** or **Type Selection**).
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您想按名称模式（例如以`A`开头的列）或按类型（整数、小数、字符串等）选择列，可以选择顶部的单选框中其他可用的选项（**通配符/正则表达式选择**或**类型选择**）。
- en: 'The second tab in the configuration window (titled **Advanced**) lets you decide
    what to do with the duplicate rows once identified (by default, they get removed
    but you can also keep them and add an extra column specifying whether they are
    duplicates or not) and which rows should be kept among the duplicates (by default,
    the first row is kept and all others are removed, but other strategies are available):'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 配置窗口中的第二个选项卡（标题为**高级**）让您决定一旦识别出重复行后要如何处理（默认情况下，重复行会被移除，但您也可以选择保留它们，并添加一个额外的列来指明它们是否为重复行），以及在重复项中应保留哪些行（默认情况下，保留第一行并移除其余行，但也有其他策略可供选择）：
- en: '![Graphical user interface, application, email'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_02_21.png)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_21.png)
- en: 'Figure 2.16: Configuration of the Duplicate Row Filter: select which columns
    to use for detecting duplicate rows'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.16：重复行过滤器的配置：选择用于检测重复行的列
- en: Let's implement the Duplicate Row Filter node and connect it with the output
    port of the Excel Reader. The new node will now show an amber status light, signaling
    that it can run with its default behavior, although we want to do some configuration
    first.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现重复行过滤器节点，并将其与 Excel 阅读器的输出端口连接。新节点现在将显示一个琥珀色的状态灯，表明它可以使用默认行为运行，尽管我们首先希望进行一些配置。
- en: Double-click on the node to enter its configuration window. Since we don't want
    to bombard the same user with multiple emails, we should keep one entry per email
    address, removing all rows having a duplicate address. Hence, from the configuration
    window, we move all columns to the left and we keep only `__Email_Entered` on
    the right. We click on OK and run the node (*F7*).
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 双击节点进入其配置窗口。由于我们不希望给同一个用户发送多封邮件，我们应该保持每个邮箱地址只出现一次，删除所有重复地址的行。因此，在配置窗口中，我们将所有列移到左侧，并且只保留`__Email_Entered`在右侧。然后点击“确定”并运行节点（*F7*）。
- en: Our curiosity makes it impossible to refrain from checking whether this node
    has worked well. So, we have a look at the data appearing on its output port (right-click
    and the last icon with the magnifying lens or *Shift + F6*) and we notice that
    a couple of rows having duplicated email addresses were removed as expected.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的好奇心让我们无法抑制查看该节点是否正常工作的冲动。因此，我们查看其输出端口的数据（右键点击，并点击最后一个带放大镜的图标或*Shift + F6*），并注意到一些重复的邮箱地址行被成功移除，正如预期。
- en: We can now proceed to fix the formatting of names and surnames. To do so, we
    will start using a very versatile node for working on textual data called String
    Manipulation.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们可以继续修正姓名和姓氏的格式了。为此，我们将开始使用一个非常多功能的节点来处理文本数据，叫做字符串操作。
- en: '![](img/B17125_02_22.png) *String Manipulation*'
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B17125_02_22.png) *字符串操作*'
- en: 'This node (**Manipulation > Column > Convert & Replace**) applies transformations
    to strings, making it possible to reformat textual data as needed. The node includes
    a large set of pre-built functions for text manipulation, such as replacement,
    capitalization, and concatenation, among others:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点（**操作 > 列 > 转换与替换**）应用于字符串的转换，使得能够根据需要重新格式化文本数据。该节点包括一组预先构建好的文本操作函数，例如替换、大写化和连接等：
- en: '![](img/B17125_02_23.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_02_23.png)'
- en: 'Figure 2.17: String Manipulation: build your text transformation selecting
    functions and columns to use'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.17：字符串操作：通过选择要使用的功能和列来构建文本转换
- en: 'The configuration window provides several panels:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 配置窗口提供了几个面板：
- en: The **Expression** box is used to specify the overall formula that implements
    the desired transformation. In most cases, you can build the expression by just
    using your mouse, clicking on the functions to use and on the columns upon which
    to apply them.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**表达式**框用于指定执行所需转换的整体公式。在大多数情况下，你可以通过使用鼠标来构建表达式，点击你需要使用的功能和应用的列。'
- en: The **Function** list includes all available transformations. For instance,
    the function `upperCase()` will convert a string in all-capital letters. When
    you double-click on a function here, it will get added to your expression.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**功能**列表包含所有可用的转换功能。例如，`upperCase()` 函数将把字符串转换为全大写字母。当你在这里双击一个功能时，它会被添加到你的表达式中。'
- en: The **Description** box is a handy source of help, showing a description and
    some examples for each available function as soon as you select it from the list.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**描述**框是一个方便的帮助来源，当你从列表中选择一个可用功能时，它会立即显示该功能的描述和一些示例。'
- en: 'The **Column List** will show you all available columns in the table. By double-clicking
    on them, you add them to the expression: they will show with a dollar sign character
    (`$`) on either side to indicate a column.'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**列列表**将显示表格中所有可用的列。双击它们，你可以将它们添加到表达式中：它们会显示为带有美元符号（`$`）的列。'
- en: At the bottom, you find a radio button to decide where to store your result.
    You can either **Append** it as a new column or **Replace** an existing one.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在底部，你可以找到一个单选按钮来决定将结果存储在哪里。你可以选择将其**附加**为新列，或者**替换**现有列。
- en: '*Table 2.1* summarizes the most useful functions available within this node.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '*表 2.1* 总结了此节点中最有用的功能。'
- en: '| Function | Description | Example | Result |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 功能 | 描述 | 示例 | 结果 |'
- en: '| **strip**(*x*) | Removes any whitespace from the beginning and the end of
    a string. | `strip(" Hi! ")` | `"Hi!"` |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| **strip**(*x*) | 删除字符串开头和结尾的任何空白字符。 | `strip(" Hi! ")` | `"Hi!"` |'
- en: '| **upperCase**(*x*),**lowerCase**(*x*) | Converts all characters to upper
    or lower case. | `upperCase("Leonardo")` | `"LEONARDO"` |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| **upperCase**(*x*),**lowerCase**(*x*) | 将所有字符转换为大写或小写。 | `upperCase("Leonardo")`
    | `"LEONARDO"` |'
- en: '| **capitalize**(*x*) | Converts first letters of all words in a string to
    upper case. | `capitalize("bill kiddo")` | `"Bill Kiddo"` |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| **capitalize**(*x*) | 将字符串中所有单词的首字母转换为大写。 | `capitalize("bill kiddo")` |
    `"Bill Kiddo"` |'
- en: '| **compare**(*x*,*y*) | Compares two strings and returns 0 if they are equal
    and -1 or 1 if they differ, depending on their alphabetical sorting. | `compare("Budd","Budd")`
    | `0` |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| **compare**(*x*,*y*) | 比较两个字符串，如果相等返回0，如果不同则返回-1或1，具体取决于它们的字母排序。 | `compare("Budd","Budd")`
    | `0` |'
- en: '| **replace**(*x*,*y*,*z*) | Replaces all occurrences of substring y within
    x with z. | `replace("cool goose","oo","u")` | `"cul guse"` |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| **replace**(*x*,*y*,*z*) | 将字符串x中所有子串y替换为z。 | `replace("cool goose","oo","u")`
    | `"cul guse"` |'
- en: '| **removeChars**(*x*,*y*) | Removes from string x all characters included
    in y. | `removeChars("No vowels!","aeiou")` | `"N wwls!"` |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| **removeChars**(*x*,*y*) | 从字符串x中删除y中包含的所有字符。 | `removeChars("No vowels!","aeiou")`
    | `"N wwls!"` |'
- en: '| **join**(*x*,*y*,...) | Concatenates any number of strings in a single string.
    | `join("Hi ","the","re")` | `"Hi there"` |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| **join**(*x*,*y*,...) | 将多个字符串连接成一个字符串。 | `join("Hi ","the","re")` | `"Hi
    there"` |'
- en: '| **length**(*x*) | Counts the number of characters in a string. | `length("Analytics
    is for everyone!")` | `26` |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| **length**(*x*) | 计算字符串中的字符数。 | `length("Analytics is for everyone!")` |
    `26` |'
- en: 'Table 2.1: Useful functions within String Manipulation'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.1：字符串操作中的有用函数
- en: 'This node is perfect for our needs as we have a few strings to manipulate.
    We need to fix the capitalization of names and surnames, remove those bad-looking
    whitespaces, and create a new column with the full name:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点非常适合我们的需求，因为我们有一些字符串需要处理。我们需要修正名字和姓氏的大小写，去除那些看起来不太美观的空格，并创建一个包含全名的新列：
- en: Let's implement the String Manipulation node, dragging it from the repository
    and connecting the output of the previous node with the input of this new one.
    Double-click on the node and its configuration dialog appears. Let's start with
    the column `First name`. We want to see a nice upper-case character at the beginning
    of every word and we also require whitespaces to be stripped from both ends of
    the string. Let's build the expression by double-clicking first on `capitalize()`
    and `strip()` from the **Function** box and then on `First name` from the **Column
    list**. By clicking in this order, we should have obtained the expression `capitalize(strip($First
    name$))`, which is exactly what we wanted. In this case, we want to substitute
    the raw version of the first name with the result of this expression, so we need
    to select **Replace column** and then `First name`. We are all set so we can click
    on **OK** and close the window.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现字符串操作节点，将其从库中拖动并连接上一个节点的输出和新节点的输入。双击节点后，配置对话框会出现。我们从`First name`列开始。我们希望每个单词的开头都是大写字母，同时要求去除字符串两端的空格。我们可以通过先双击**Function**框中的`capitalize()`和`strip()`，然后再点击**Column
    list**中的`First name`，来构建表达式。按照这个顺序操作，我们应该得到`capitalize(strip($First name$))`，这正是我们需要的。在这种情况下，我们希望将原始版本的名字替换为该表达式的结果，因此我们需要选择**Replace
    column**，然后选择`First name`。设置完成后，点击**OK**即可关闭窗口。
- en: 'Now we want to repeat the same for the surname. We''ll use another String Manipulation
    node for it. To make it faster we can also copy and paste the icon of the node
    from the Workflow Editor, with the usual *Ctrl* + *C* and *Ctrl* + *V* key combinations.
    We need to repeat the configuration described in the previous step: the only difference
    is that now we apply it to column `Surname` instead of `First name`. Just make
    sure that both the expression and the **Replace column** setting refer to `Surname`
    this time.'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们希望对姓氏做相同的处理。我们将使用另一个字符串操作节点来实现。为了加快速度，我们还可以从工作流编辑器中复制并粘贴节点图标，使用常规的*Ctrl*
    + *C* 和 *Ctrl* + *V*快捷键。我们需要重复前一步骤中描述的配置：唯一的不同之处是，这次我们将其应用于`Surname`列，而不是`First
    name`列。只需确保这次表达式和**Replace column**设置都指向`Surname`列即可。
- en: 'Both parts of the name look fine now as they show no extra spaces and boast
    good-looking capitalization. As required by our business case, we need to create
    a new column carrying the full name of each user, combining first name and surname.
    Once again, we can use the String Manipulation node for this: let''s get one more
    node of these in the Workflow Editor, make the connection, and open the configuration
    page. This time, we need to concatenate two strings so we can leverage the `join()`
    function. Let''s double-click first on `join()` from the **Function** box and
    then on `First name` from the **Column list**. Since we want names and surnames
    to be separated by a blank space, we need to add this character on the expression,
    by typing the sequence `," ",` in the expression box just after `$First name$`.
    We complete the expression by double-clicking on the column `Surname` and we are
    done. The overall expression should be: `join($First name$," ",$Surname$)`. Before
    closing, we need to decide where to store the result. This time we want to create
    a new column so we select **Append** and then type the name of the new column,
    which could be Full name. Click on **OK** and check the results.'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在名字的两个部分看起来很好，因为它们没有额外的空格，并且大小写格式也很漂亮。根据我们的业务需求，我们需要创建一个新列，包含每个用户的全名，将名字和姓氏合并在一起。我们可以再次使用字符串操作节点来实现这一点：在工作流编辑器中再添加一个该节点，建立连接并打开配置页面。这次，我们需要连接两个字符串，因此可以使用`join()`函数。首先双击**Function**框中的`join()`，然后双击**Column
    list**中的`First name`。因为我们希望名字和姓氏之间有一个空格，所以需要在表达式中添加这个字符，方法是在`$First name$`后输入`,"
    ",`。最后，通过双击列`Surname`来完成表达式。整体表达式应该是：`join($First name$," ",$Surname$)`。关闭之前，我们需要决定将结果存储在哪里。这次我们希望创建一个新列，所以选择**Append**，然后输入新列的名称，例如Full
    name。点击**OK**并检查结果。
- en: 'Since in the end, we are going to keep only the `Full name` column, we could
    have combined the last three nodes in a single one. In fact, `Full name` can be
    created at once with the expression: `join(capitalize(strip($First name$))," ",capitalize(strip($Surname$)))`.'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于最终我们只会保留`Full name`列，因此可以将最后三个节点合并为一个。实际上，可以使用表达式`join(capitalize(strip($First
    name$))," ",capitalize(strip($Surname$)))`一次性创建`Full name`。
- en: We took the longer route to get some practice with the node. It's up to you
    to decide which version to keep in your workflow.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们选择了较长的路线来练习节点。决定在工作流中保留哪个版本由你决定。
- en: 'With all names fixed, we can move on to the next hurdle and remove the ill-formatted
    email addresses. It''s time to introduce a new node that will be ubiquitous in
    our future KNIME workflows: Row Filter.'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有名字修正后，我们可以继续处理下一个问题，去除格式错误的电子邮件地址。是时候引入一个将在未来KNIME工作流中随处可见的新节点：行过滤器（Row Filter）。
- en: '![](img/B17125_02_24.png) *Row Filter*'
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B17125_02_24.png) *行过滤器（Row Filter）*'
- en: 'This node (**Manipulation > Row > Filter**) applies filters on rows according
    to the criteria you specify. Such criteria can either be based on values of a
    specific column to test (like *all strings starting with A* or *all numbers greater
    than 5.2*) or on the position of the row in the table (for instance *only the
    top 20 rows*). To configure the node, you need to first specify the type of criteria
    you would like to apply using the selector on the left. You also need to specify
    if those rows that match your criteria should be kept in your workflow (**Include
    rows...**) or should be dropped, keeping all others (**Exclude rows...**). You
    have multiple ways to specify the criteria behind your filtering:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点（**Manipulation > Row > Filter**）根据你指定的条件对行进行过滤。此类条件可以基于特定列的值进行测试（例如*所有以A开头的字符串*或*所有大于5.2的数字*），也可以基于表中行的位置进行设置（例如*仅前20行*）。要配置此节点，你需要首先使用左侧的选择器指定希望应用的条件类型。你还需要指定那些符合条件的行是否应保留在工作流中（**Include
    rows...**），或者应该被丢弃，保留所有其他行（**Exclude rows...**）。你有多种方式来指定过滤背后的条件：
- en: 'Filter by **attribute value**: In this case, you will be presented on the right
    with the full list of columns available so that you can pick the one to consider
    for the filtering (**Column to test**). Once you pick the column, you need to
    describe the logic for the selection in the box below (**Matching criteria**).
    You have three options:'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据**属性值**过滤：在这种情况下，右侧会显示可用列的完整列表，你可以选择要用于过滤的列（**Column to test**）。选择列后，你需要在下面的框中描述选择逻辑（**Matching
    criteria**）。你有三个选项：
- en: 'The first one (**use pattern matching**) will check if the value (considered
    as a string) adheres to the pattern you specify in the textbox. You can enter
    a specific value like `maria`: this will match rows like "MARIA" or "Maria," unless
    you check the **case sensitive match** option, which would consider the lower
    and upper cases as different. Another option is to use wild cards in your search
    pattern (remember to tick **contains wild cards**): in this case, the star character
    `"*"` will stand for any sequence of characters (so `"M*"` selects all names starting
    with `"M"` like "Mary" and "Mario") while the question mark `"?"` will match any
    single character (`"H?"` refers to any string of two characters starting with
    "H," so it will include "Hi" and exclude "Hello"). If you want to implement more
    complex searches, you could also use the powerful **Regular Expressions** (**RegEx**),
    which offer great flexibility in setting criteria.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个选项（**使用模式匹配**）将检查值（视为字符串）是否符合你在文本框中指定的模式。你可以输入一个特定的值，比如`maria`：这将匹配类似于“MARIA”或“Maria”的行，除非你勾选**区分大小写匹配**选项，这样会将大小写视为不同的字符。另一个选项是使用通配符进行搜索（记得勾选**包含通配符**）：在这种情况下，星号字符`"*"
    `代表任意字符序列（所以`"M*"`会选择所有以“M”开头的名字，如“Mary”和“Mario”），而问号字符`"?"`则匹配任何单一字符（`"H?"`表示以“H”开头的两个字符的字符串，因此它会匹配“Hi”，但不包括“Hello”）。如果你需要实现更复杂的搜索，也可以使用强大的**正则表达式**（**RegEx**），它在设置条件方面提供了极大的灵活性。
- en: 'The second one (**use range checking**) is great with numbers as it lets you
    set any kind of interval: you can specify a lower bound (including all numbers
    that are greater or equal than that) or an upper bound (lower or equal) or both
    (making it a closed interval).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个选项（**使用范围检查**）对于数字非常有用，因为它允许你设置任何类型的区间：你可以指定一个下界（包括所有大于或等于该值的数字），或者上界（小于或等于该值），或者两个（使其成为闭区间）。
- en: Remember that bounds are always considered as included in the interval. If you
    want to exclude the endpoint of an interval, you need to reverse the logic of
    your filtering. For instance, if you want to include all non-zero, positive numbers
    you need to select the option **Exclude rows by attribute value** and set `0`
    as the upper bound.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，边界总是被视为包含在区间内。如果你想排除区间的端点，你需要反转过滤的逻辑。例如，如果你想包括所有非零正数，你需要选择**按属性值排除行**选项，并将`0`设置为上限。
- en: The third option is to match only the rows that have a missing value in the
    column under test.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个选项是仅匹配在测试列中有缺失值的行。
- en: 'Filter by **row number**: This way you can specify which is the first and the
    last row to match, considering the current sorting order in the table. So if you
    put `1` in the **First row number** selector and then `1` in **Last row number**,
    you will match only the top 10 rows of the table. If you want to match only the
    rows after a certain position, like from the 100th onwards, you can set the threshold
    in the first selector (`100`) and tick the check box below (**to the end of the
    table**).'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按**行号**过滤：这样你可以指定匹配的第一行和最后一行，考虑到当前表格的排序顺序。所以，如果你在**第一行号**选择器中输入`1`，然后在**最后一行号**中输入`1`，你只会匹配表格中的前10行。如果你只想匹配从某个特定位置开始的行，例如从第100行开始，你可以在第一个选择器中设置阈值（`100`），并勾选下方的复选框（**直到表格结束**）。
- en: 'Filter by **row ID**: You could test row IDs against some regular expressions
    as well, although this route is rarely used:![Graphical user interface, text,
    application, email'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按**行ID**过滤：你也可以使用正则表达式测试行ID，尽管这种方法较少使用：![图形用户界面，文本，应用程序，电子邮件
- en: Description automatically generated](img/B17125_02_25.png)
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_25.png)
- en: 'Figure 2.18: Configuration dialog for Row Filter: specify which rows to keep
    or remove from your table'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.18：行过滤器的配置对话框：指定要保留或移除的行
- en: If your filtering criteria require several columns to be tested, you can use
    multiple instances of this node in a series, each time looking at a different
    column. An alternative is to use a different node called Rule-based Row Filter,
    which lets you define several rules for filtering at once. Other nodes, such as
    **Row Filter (Labs)** and **Rule-based Row Filter (Dictionary)**, can do more
    sophisticated filtering if needed. Check them out if you need to.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的过滤标准需要测试多个列，你可以在一系列中使用多个该节点实例，每次查看不同的列。另一种选择是使用一种叫做基于规则的行过滤器的不同节点，它允许你一次定义多个过滤规则。如果需要，其他节点，如**行过滤器（实验室）**和**基于规则的行过滤器（字典）**，可以进行更复杂的过滤。如果你需要，可以查看它们。
- en: 'Let''s see our new node in action straight away as we filter out all the email
    addresses that do not look valid:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们立刻看到新节点的效果，过滤掉所有看起来不合法的电子邮件地址：
- en: Implement the **Row Filter** node, connect it downstream, and open its configuration
    dialog by double-clicking on it. Since we want to keep only the rows matching
    certain column criteria, let's select the first option from the radio button on
    the left (**Include rows by attribute value**) and, on the right, pick the column
    with the email address `__Email_Entered`. One simple pattern we can use for checking
    the validity of an email address is the wild card expression `*@*.*`. This will
    check for all strings that have at least an `@` symbol followed by a dot . with
    some text in between. This is not going to be the most thorough validity check
    for email addresses, but it will certainly spot the ones that are clearly irregular
    and is good enough for us at this stage. Remember to tick the **contains wild
    cards** checkbox and click **OK** to move on.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现 **行过滤器** 节点，将其连接到下游，并通过双击它打开配置对话框。由于我们只想保留符合某些列条件的行，所以我们选择左侧单选按钮中的第一个选项（**按属性值包含行**），然后在右侧选择包含电子邮件地址的列
    `__Email_Entered`。检查电子邮件地址有效性的一个简单模式是通配符表达式 `*@*.*`。它将检查所有包含至少一个 `@` 符号并且后面跟着一个点
    . 和一些文本的字符串。虽然这并不是最彻底的电子邮件地址有效性检查，但它肯定能找出明显不正常的地址，并且在这个阶段对我们来说已经足够了。记得勾选 **包含通配符**
    复选框，然后点击 **确定** 继续。
- en: 'We have yet more filtering to be done. We want to remove all rows displaying
    a negative credit: those users are inactive and should not be added to our mailing
    list. Let''s implement an additional Row Filter node and put it next to the previous
    one, creating the right connections across the ports. We will again use the **Include
    rows by attribute value** option but the matching criteria will be set as range
    checking (second radio button on the right). By setting `0` as **Lower bound**,
    we are good to go since all negative values will be filtered out. We can click
    **OK** and move on to the next challenge.'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还需要进行更多的过滤。我们想删除所有显示负信用的行：这些用户处于非活跃状态，应该从我们的邮件列表中删除。让我们再添加一个行过滤器节点，将其放置在前一个节点旁边，确保正确连接各个端口。我们仍然使用
    **按属性值包含行** 选项，但匹配条件将设置为范围检查（右侧第二个单选按钮）。通过将 `0` 设置为 **下限**，我们可以保证所有负值都会被过滤掉。点击
    **确定** 后，我们可以继续处理下一个任务。
- en: At this point, we want to manage the little red question marks appearing here
    and there in the table, signaling that some values are missing. Also, in this
    case, KNIME offers a powerful node to manage this situation quickly, with a couple
    of clicks.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此时，我们需要处理表格中时不时出现的小红色问号，标示某些值缺失。此外，在这种情况下，KNIME 提供了一个强大的节点，可以通过点击几下快速处理这种情况。
- en: '![](img/B17125_02_26.png) *Missing Value*'
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B17125_02_26.png) *缺失值*'
- en: The node (**Manipulation > Column > Transform**) handles missing values (`NULLs`)
    in a table, offering multiple methods for imputing the best available replacement.
    In the first tab of the configuration window (**Default**), you can define a default
    treatment option for all columns of a certain data type (`strings`, `integer`,
    and `double`) by selecting it in the dropdown menus. The second tab (**Column
    settings**) allows you to set a specific strategy for each individual column by
    double-clicking on the name of the column from the list on the left and setting
    the strategy through the menu that will appear.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点（**操作 > 列 > 转换**）处理表格中的缺失值（`NULLs`），提供多种方法来填补最佳可用的替代值。在配置窗口的第一个选项卡（**默认**）中，你可以通过在下拉菜单中选择数据类型（`字符串`、`整数`、`双精度`），为所有列定义默认处理选项。第二个选项卡（**列设置**）允许你通过双击左侧列表中的列名称并通过弹出的菜单设置每个列的特定策略。
- en: Unless you have a large number of columns that you want to treat with the same
    missing value strategy, it's best to be explicit and use the second tab. That
    way you only impute missing values for the precise columns specified.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你有大量的列需要使用相同的缺失值处理策略，否则最好明确指定并使用第二个选项卡。这样你只会对指定的精确列进行缺失值插补。
- en: 'You have a vast list of possible methods to treat your missing values. The
    most useful ones are:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 你有一个庞大的列表，可以选择不同的方法来处理缺失值。最常用的方法包括：
- en: '**Remove Row**: Gets rid of the row altogether if the value is missing.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**删除行**：如果值缺失，则完全删除该行。'
- en: '**Fix Value**: Replaces the NULL with a specific value you have to enter in
    the box that will appear below. All rows with missing values will get the same
    fix replacement.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**固定值**：用你在下方框中输入的特定值替代NULL。所有缺失值的行将会使用相同的固定替代值。'
- en: '**Minimum**/**Maximum**/**Mean**/**Median**/**Most Frequent Value**: Calculates
    a summary statistic on the distribution over all existing values in the column
    and uses it as a fixed replacement value.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最小值**/**最大值**/**均值**/**中位数**/**众数**：计算列中所有现有值的分布的汇总统计量，并将其作为固定的替代值。'
- en: If you substitute missing values with the median of a numeric column, your imputed
    values are going to stick "in the middle" of the existing distribution, making
    your inference less disruptive and more robust. Of course, this will depend on
    your business cases and on the actual distribution of data, but it's worth giving
    this approach a try.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你用数值列的中位数替代缺失值，那么你填充的值将会“位于”现有分布的“中间”，使得推断结果不那么具有干扰性且更具鲁棒性。当然，这取决于你的业务案例和数据的实际分布，但值得尝试这种方法。
- en: '**Previous/Next**: Replaces the missing value with the previous or the next
    non-missing value in the column, using the current order of rows in the table.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前一个/后一个**：用列中前一个或后一个非缺失值替代缺失值，使用表格中当前的行顺序。'
- en: '**Linear Interpolation**: Substitutes missing values with the linear interpolation
    between the previous and the next non-missing values in the column. If your column
    represents values changing over time (we call them time series), this handler
    might offer a smooth way to fill the gaps.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性插值**：用列中前一个和下一个非缺失值之间的线性插值替代缺失值。如果你的列表示随时间变化的值（我们称之为时间序列），那么这种处理器可能提供一种平滑的方式来填补空缺。'
- en: '**Moving Average**: Substitutes the missing values with a moving average calculated
    over a certain number of non-missing values appearing in the table just before
    the missing value (**lookbehind window**) or after it (**lookahead window**).
    For instance, if you have for a column a sequence of values such as [2, 3, 4,
    NULL] and you apply a lookbehind window of size 2, the NULL value will be substituted
    for 3.5, which is the average of 3 and 4\. For this and the previous handlers,
    you want to make sure your table is properly sorted (like, in a time series, by
    increasing time).![Graphical user interface'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**移动平均**：用计算自缺失值前后的若干个非缺失值的移动平均来替代缺失值（**回溯窗口**或**前瞻窗口**）。例如，如果某列有一系列值如[2, 3,
    4, NULL]，并且你应用一个大小为2的回溯窗口，那么NULL值将被替代为3.5，这是3和4的平均值。对于这一点以及前面提到的处理器，你需要确保你的表格已正确排序（比如，在时间序列中，按时间递增排序）。![图形用户界面'
- en: Description automatically generated](img/B17125_02_27.png)
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_02_27.png)
- en: 'Figure 2.19: Configuration of Missing Value: decide how to manage the empty
    spots of your table'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.19：缺失值配置：决定如何管理表格中的空白位置
- en: 'Going back to our case, we noticed that we have two columns displaying some
    question marks. Let''s manage them appropriately by leveraging the Missing Value
    node:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的例子，我们注意到有两列显示了一些问号。让我们通过利用“缺失值”节点适当管理它们：
- en: 'Drag the Missing Value node on your workflow and connect it properly. Let''s
    jump straight to the second tab of its configuration window (**Column settings**),
    as we want to keep control of which handling strategy we shall adopt for each
    column in need. For column `Age` (double-click on it from the list on the left),
    we can select **Median**: by doing so, we will assign an age to those users missing
    one that is not "far off" the age that most users tend to have in our table. When
    it comes to the number of times users have logged in (`Logins` column) we assume
    that the lack of a value means that they haven''t logged in yet. So the best strategy
    to select will be **Fix Value**, keeping 0 as a default value for all. We can
    click on OK and close this dialog.'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将“缺失值”节点拖到工作流中并正确连接。我们直接跳到配置窗口的第二个标签页（**列设置**），因为我们希望控制针对每个需要处理的列采用哪种处理策略。对于列`年龄`（从左侧列表中双击它），我们可以选择**中位数**：这样，我们将为那些缺少年龄的用户分配一个年龄，这个年龄不会“偏离”大多数用户的年龄。当涉及到用户登录次数（`登录次数`列）时，我们假设缺失值意味着用户尚未登录。因此，选择的最佳策略是**固定值**，将0作为所有缺失值的默认值。我们可以点击“确定”并关闭此对话框。
- en: 'Let''s check how our chain of transformations is looking at the minute. If
    we click on the last node, execute it (*F7*), and check its output port view (*Shift*
    + *F6*), we can breathe a sigh of relief: no missing values, no negative credits,
    and both names and email addresses look reasonably formatted.'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查一下目前转换链的效果。如果我们点击最后一个节点，执行它（*F7*），然后查看其输出端口视图（*Shift* + *F6*），我们可以松一口气：没有缺失值，没有负信用分，并且姓名和电子邮件地址看起来格式合理。
- en: 'The only steps left ahead of us are of an aesthetic nature: we want to drop
    the columns we don''t need, sort the ones remaining, and give them a more intuitive
    name, before finally saving the output file. We are going to need a few more nodes
    to complete this last bit.'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来我们只需要进行一些美学方面的调整：我们希望删除不需要的列，排序剩余的列，并为它们命名更直观的名称，最后保存输出文件。为了完成最后这一步，我们需要一些额外的节点。
- en: '![](img/B17125_02_28.png) *Column Filter*'
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B17125_02_28.png) *列过滤*'
- en: 'This node (**Manipulation > Column > Filter**) drops unneeded columns in a
    table. The only required step for its configuration is to select which columns
    to keep at the output port (the green box on the right) and which ones to filter
    out (the red box on the left):'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点（**操作 > 列 > 过滤**）用于删除表格中不需要的列。配置此节点时唯一需要的步骤是选择在输出端口（右侧绿色框）中保留哪些列，过滤掉哪些列（左侧红色框）：
- en: '![Graphical user interface, application'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序'
- en: Description automatically generated](img/B17125_02_29.png)
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_29.png)
- en: 'Figure 2.20: Configuration of Column Filter: which columns would you like to
    keep?'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.20：列过滤配置：您希望保留哪些列？
- en: Add the Column Filter node to the workflow and exclude the columns we no longer
    need (`First Name`, `Surname`, and `IP_Address`) by moving them onto the left
    panel.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将列过滤节点添加到工作流中，并通过将不再需要的列（`First Name`，`Surname`，和`IP_Address`）移到左侧面板，来排除它们。
- en: '![](img/B17125_02_30.png) *Column Rename*'
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B17125_02_30.png) *列重命名*'
- en: 'The node lets you change the names and the data types of columns. To configure
    it, double-click on the columns you would like to edit (you''ll find a list on
    the left) and tick the **Change** box: you will then be able to enter the new
    names in the box beside. To change the data type of a column and convert all its
    values, you can use the drop-down menu on the right. The menu will be prepopulated
    with a list of possible data types each column can be safely converted into:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点允许您更改列的名称和数据类型。要进行配置，双击您想编辑的列（左侧会列出所有列），然后勾选**更改**框：接着您可以在旁边的框中输入新名称。若要更改列的数据类型并转换所有值，您可以使用右侧的下拉菜单。该菜单会预先填充一个每列可以安全转换为的可能数据类型列表：
- en: '![Graphical user interface, text, application'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序'
- en: Description automatically generated](img/B17125_02_31.png)
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_31.png)
- en: 'Figure 2.21: Configuration of Column Rename: pick the best names for your columns'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.21：列重命名配置：为您的列选择最佳名称
- en: We can now use the Column Rename node to change the headers in our table. The
    only ones that need some makeup are `__Email_Entered`, which can become simply
    `Email`, and `_Credit`, which can be renamed to `Credit`.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用列重命名节点来更改表格中的表头。需要调整的只有`__Email_Entered`，它可以简化为`Email`，以及`_Credit`，它可以重命名为`Credit`。
- en: '![](img/B17125_02_32.png) *Column Resorter*'
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B17125_02_32.png) *列重排序器*'
- en: 'This node (available in **Manipulation > Column > Transform**) changes the
    order of columns in a table. In the configuration window, you will find, on the
    left, all columns available at the input port, and on the right, a series of buttons
    to move them around. Select the column you wish to move across and then click
    on the different buttons to move columns up or down, place columns first or last
    in the table, or sort them in alphabetical order. If different columns appear
    at the input port (imagine the case where your source file is coming in with some
    new columns), they will be placed where the **<any unknown new column>** placeholder
    lies:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点（在**操作 > 列 > 转换**中可用）用于改变表格中列的顺序。在配置窗口中，您会看到左侧显示所有可用的输入端口列，右侧则是一些按钮，用来移动列的位置。选择您希望移动的列，然后点击不同的按钮以将列上移或下移，或将列放在表格的最前面或最后面，或者按字母顺序对列进行排序。如果输入端口中出现了不同的列（比如您的源文件带有一些新列），这些新列会被放置在**<任何未知新列>**占位符的位置：
- en: '![Graphical user interface, application'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序'
- en: Description automatically generated](img/B17125_02_33.png)
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_33.png)
- en: 'Figure 2.22: Configuration of Column Resorter: shuffle your columns to the
    desired order'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.22：列排序器配置：将列重新排列成所需顺序
- en: The last transformation required is to slightly change the order of columns
    in the table. In fact, the **Full name** column was added earlier in the process
    and ended up appearing as the last column while we would like it to be the first.
    Just select the column and click on **Move First** to fix it as needed.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个所需的转换是稍微调整表格中的列顺序。实际上，**全名**列在之前的流程中已经添加，但最终出现在了最后一列，而我们希望它排在第一列。只需选择该列并点击**移到最前**即可按需要调整。
- en: '![](img/B17125_02_34.png) *CSV Writer*'
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B17125_02_34.png) *CSV Writer*'
- en: 'This node (**IO > Write**) saves the input data table into a CSV file on the
    local disk or to a remote location. The only required configuration step is to
    specify the full path of the file to create: you can click on the **Browse...**
    button to select the desired folder. The other configuration steps (not required)
    let you: change the format of the resulting CSV file like column delimiters (**Format**
    section), keep or remove headers as the first row (**Write column header**), and
    compress the newly generated file in `.gzip` format to save space on disk (go
    to the **Advanced Settings** tab for this):'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点 (**IO > Write**) 将输入的数据表保存为本地磁盘或远程位置的 CSV 文件。唯一需要配置的步骤是指定要创建的文件的完整路径：你可以点击**浏览...**按钮来选择所需的文件夹。其他配置步骤（非必需）允许你：更改生成的
    CSV 文件的格式，例如列分隔符（**格式**部分），保留或删除作为第一行的表头（**写入列标题**），以及将新生成的文件压缩为 `.gzip` 格式以节省磁盘空间（这项设置请前往**高级设置**标签页）：
- en: '![Graphical user interface, text, application, email'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面、文本、应用程序、电子邮件'
- en: Description automatically generated](img/B17125_02_35.png)
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_02_35.png)
- en: 'Figure 2.23: Configuration of CSV Writer: save your table as a text file'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.23：CSV 写入器配置：将表格保存为文本文件
- en: The very last step of our process is to save our good-looking table as a CSV
    file. We implement the CSV Writer node, connect it, and do the only piece of required
    configuration, which is to specify where to save the new file and how to name
    it. Click **OK** to close the window and execute the node to finally write the
    file on your disk.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们流程的最后一步是将我们漂亮的表格保存为 CSV 文件。我们实现 CSV 写入节点，连接它，并进行唯一的必要配置，即指定新文件的保存位置和命名方式。点击**确定**以关闭窗口，并执行节点，最终将文件写入磁盘。
- en: 'Well done for completing your second data workflow! The routine required for
    building a clean mailing list out of a messy raw dataset required a dozen nodes
    and some of our time, but the effort was certainly worth it. Now we can clean
    up any number of records whenever we like by just re-running the same workflow,
    making sure that the name of the input file and its path stay the same. To do
    so, you will just need to: reset the workflow (right-click on the name of the
    workflow in the Explorer on the left and then click on **Reset** or just reset
    the first node pressing *F8* after having selected it), and execute it again (the
    simplest way is to just press *Shift* + *F7* on your keyboard or execute the last
    node with a right-click and select **Execute**):'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了第二个数据工作流！从杂乱的原始数据集构建一个干净的邮件列表的过程需要十几个节点和一些时间，但这个努力绝对是值得的。现在我们可以随时通过重新运行相同的工作流来清理任何数量的记录，只需确保输入文件的名称和路径保持不变。为此，你只需：重置工作流（右键点击左侧资源管理器中的工作流名称，然后点击**重置**，或者在选中第一个节点后按
    *F8* 重置它），然后重新执行它（最简单的方式是按 *Shift* + *F7* 键，或者右键点击最后一个节点并选择**执行**）：
- en: '![](img/B17125_02_36.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_02_36.png)'
- en: 'Figure 2.24: The full data cleaning workflow: twelve nodes to make our user
    data spotless'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.24：完整的数据清理工作流：十二个节点让我们的用户数据一尘不染
- en: Summary
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This chapter introduced us to KNIME, the new addition to our data analytics
    toolbox. We learned what KNIME is in a nutshell and got started with its user
    interface, which enables us to combine simple computation units (nodes) into more
    complex analytical routines (workflows) with speed and agility, without having
    to write extensive code. We got started with the ever-present preliminary steps
    of any data work: loading and cleaning up data to make it usable for doing analytics.
    We got acquainted with twelve basic nodes in KNIME that empowered us to create
    repeatable routines, which include: opening files in different formats, sorting
    and filtering data following some logic, manipulating strings, and managing missing
    values and duplicate rows. Not bad for being just on the second chapter!'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了 KNIME，它是我们数据分析工具箱中的新成员。我们简要了解了 KNIME 的概况，并开始使用它的用户界面，这使我们能够快速、灵活地将简单的计算单元（节点）组合成更复杂的分析流程（工作流），而无需编写大量代码。我们从任何数据工作中的常见预备步骤开始：加载和清理数据，使其可用于分析。我们熟悉了
    KNIME 中的十二个基础节点，这些节点使我们能够创建可重复的工作流程，包括：以不同格式打开文件、按照某些逻辑对数据进行排序和过滤、操作字符串，以及管理缺失值和重复行。仅仅第二章就做到这些，已经相当不错了！
- en: Having the basics clearly explained, we can now dare to go further with KNIME.
    In the next chapter, *Chapter 3*, *Transforming Data*, we will learn how to work
    on multiple data tables and to build more complex data workflows for analyzing
    real-world data feeds.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在基础知识已经清楚地讲解之后，我们现在可以大胆地进一步探讨 KNIME。在接下来的章节中，*第三章*，*数据转换*，我们将学习如何处理多个数据表，并构建更复杂的数据工作流，以分析实际的实时数据流。
