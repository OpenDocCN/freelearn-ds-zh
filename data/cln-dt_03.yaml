- en: Chapter 3. Workhorses of Clean Data – Spreadsheets and Text Editors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章 清理数据的工作马 – 电子表格和文本编辑器
- en: 'When designing a home kitchen, the typical layout invokes the classic work
    triangle, the points of which are the refrigerator, sink, and stove. In our Clean
    Data kitchen, we have a few indispensible devices as well. Two of these are the
    humble **spreadsheet** and the **text editor**. Although these unpretentious tools
    are often overlooked, full knowledge of their features can make many cleaning
    tasks quicker and easier. In [Chapter 2](part0020.xhtml#aid-J2B82 "Chapter 2. Fundamentals
    – Formats, Types, and Encodings"), *Fundamentals – Formats, Types, and Encodings*,
    we briefly introduced these two tools in the context of learning about data types
    and file types, but in this chapter, we are ready to dig deeper into:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计家庭厨房时，典型的布局通常会涉及经典的工作三角形，其中的三点是冰箱、水槽和炉子。在我们的清理数据厨房中，也有一些必不可少的工具，其中两个就是朴素的**电子表格**和**文本编辑器**。尽管这些简洁的工具往往被忽视，但充分了解它们的功能可以使许多清理任务变得更加快速和轻松。在[第二章](part0020.xhtml#aid-J2B82
    "第二章 基础 – 格式、类型和编码")，*基础 – 格式、类型和编码*，我们简要介绍了这两种工具，重点讨论了数据类型和文件类型，但在本章中，我们将深入探讨：
- en: Useful functions in Excel and Google Spreadsheets that can help us manipulate
    data, including text to columns, splitting and concatenating strings, searching
    and formatting to find unusual values, sorting, importing spreadsheet data into
    MySQL, and even generating SQL using a spreadsheet
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Excel和Google电子表格中有用的函数，这些函数可以帮助我们处理数据，包括文本转列、分割和合并字符串、搜索和格式化以查找异常值、排序、将电子表格数据导入MySQL，甚至使用电子表格生成SQL语句。
- en: Typical features of a text editor that can automatically extract and manipulate
    data into a more useful format, including searching and replacing with regular
    expressions, altering line beginnings and endings, and column-based editing
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本编辑器的典型功能，包括使用正则表达式进行搜索和替换、修改行首和行尾以及基于列的编辑，以便自动提取和处理数据，使其变得更有用。
- en: A small project where we use features of both of these tools to clean some real-world
    data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个小项目，使用这两种工具的功能清理一些实际数据
- en: Spreadsheet data cleaning
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 电子表格数据清理
- en: 'The utility of the spreadsheet for data cleaning comes from two things: its
    ability to organize data into columns and rows and its suite of built-in functions.
    In this section, we will learn how to use the spreadsheet to its fullest in our
    quest for clean data.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 电子表格在数据清理中的实用性源于两点：它能够将数据组织成列和行，并且具有一整套内置函数。在本节中，我们将学习如何充分利用电子表格，以帮助我们实现清理数据的目标。
- en: Text to columns in Excel
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Excel中的文本转列
- en: 'As spreadsheets are designed to hold data in columns and rows, one of the first
    cleaning tasks we might need to do is arrange our data accordingly. For instance,
    if you paste a large amount of data into Excel or Google Spreadsheets, the software
    will first try to look for a delimiter (such as a comma or tab) and divide the
    data into columns that way. (Refer to [Chapter 2](part0020.xhtml#aid-J2B82 "Chapter 2. Fundamentals
    – Formats, Types, and Encodings"), *Fundamentals – Formats, Types, and Encodings*,
    for a review of delimited data.) Sometimes, the spreadsheet software will not
    find a delimiter, so we will have to provide it more guidance about how to divide
    the data into columns. Consider the following snippet of text from a list of several
    thousand Internet Relay Chat channel topics on Freenode:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由于电子表格是设计用来存储数据在列和行中的，因此我们可能需要做的第一项清理任务就是根据需要整理数据。例如，如果你将大量数据粘贴到Excel或Google电子表格中，软件会首先尝试寻找分隔符（如逗号或制表符），并通过这种方式将数据分割成列。（有关分隔数据的更多信息，请参见[第二章](part0020.xhtml#aid-J2B82
    "第二章 基础 – 格式、类型和编码")，*基础 – 格式、类型和编码*。）有时，电子表格软件可能无法找到分隔符，这时我们需要为它提供更多指导，告诉它如何将数据划分为列。考虑以下来自Freenode上的数千个Internet
    Relay Chat频道主题列表的文本片段：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'To generate a list of channels and their topics in an IRC chat server, use
    the `alis` command, which can be sent as part of either `/query` or `/msg`, depending
    on your server''s settings. On Freenode, the `/msg alis *` command will generate
    a list of channels. More information on IRC chat can be found here: [https://freenode.net/services.shtml](https://freenode.net/services.shtml)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要在IRC聊天服务器中生成频道及其主题的列表，可以使用`alis`命令，该命令可以通过`/query`或`/msg`发送，具体取决于服务器的设置。在Freenode上，`/msg
    alis *`命令将生成一个频道列表。关于IRC聊天的更多信息，可以参考：[https://freenode.net/services.shtml](https://freenode.net/services.shtml)
- en: 'We can see with our human eyes that the first chunk of data is a timestamp,
    followed by `===`, `#` and a channel name, a number (the count of users on the
    channel at the moment the list was constructed), and a description of the channel.
    However, if we paste these lines into Excel or Google Spreadsheets, it is unable
    to automatically make the same observations about what columns should be. The
    rows are detected correctly by the spreadsheet, but the delimiting is too inconsistent
    for columns to be detected automatically. How the data looks when pasted into
    Google Spreadsheets is given in the following image. By highlighting cell A1,
    we can see that the entire line is shown in the formula bar, indicating that the
    entire row has been pasted into cell A1:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过肉眼可以看到，数据的第一部分是时间戳，接着是`===`、`#`和频道名称、一个数字（即构建列表时频道上的用户数量）以及频道描述。然而，如果将这些行粘贴到Excel或Google电子表格中，它无法自动识别哪些应该是列。电子表格能够正确检测行，但由于分隔不一致，无法自动检测出列。当将数据粘贴到Google电子表格中时，数据的显示如下图所示。通过高亮显示单元格A1，我们可以看到整个行都显示在公式栏中，表示整个行已经粘贴到了A1单元格中：
- en: '![Text to columns in Excel](img/image00247.jpeg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![Excel中的文本到列](img/image00247.jpeg)'
- en: How can we easily create columns from this data in the spreadsheet? We would
    like each separate data item to be in its own column. By doing this, we will be
    able to, for example, take an average of the number of users on the channels or
    sort the data by the channel names. Right now, we cannot easily sort or use formulas
    on this data as it is all in one giant text string.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何在电子表格中轻松地从这些数据创建列？我们希望每个单独的数据项都位于自己的列中。通过这种方式，我们可以例如对频道的用户数量进行平均值计算，或根据频道名称对数据进行排序。目前，由于所有数据都在一个巨大的文本字符串中，我们无法轻松地对其进行排序或使用公式。
- en: 'One strategy will be to use Excel''s text-to-columns wizard to split the data
    into recognizable chunks; then, we can reassemble them and strip out extra characters
    if needed. This is shown in the steps mentioned as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一种策略是使用Excel的文本到列向导将数据拆分成可识别的部分；然后，我们可以重新组合它们，并在需要时去除多余的字符。以下是相关步骤：
- en: Highlight column `A`, and launch the text-to-columns wizard (located in the
    Data menu). In step 1, choose a fixed width, and in step 2, double-click on all
    the lines that have been drawn to delimit the description field. The following
    figure shows you how the data should look after delimiting the first few columns
    and removing all the extra lines:![Text to columns in Excel](img/image00248.jpeg)
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高亮显示列`A`，并启动文本到列向导（位于数据菜单中）。在第一步中，选择固定宽度，在第二步中，双击所有绘制的线条以分隔描述字段。下图展示了拆分前几列并移除所有多余行后数据的样子：![Excel中的文本到列](img/image00248.jpeg)
- en: Fixed-width splitting in Excel.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Excel中的固定宽度拆分。
- en: The resulting data looks like the following figure. The first three columns
    are good, but the fixed-width delimiting did not work to separate the count of
    users and channel names in column D. This happened because the channel names are
    not as predictable in length as the previous columns.
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果数据如下图所示。前三列没有问题，但固定宽度拆分未能成功分开列D中的用户计数和频道名称。这是因为频道名称的长度不像前几列那样具有可预测性。
- en: '![Text to columns in Excel](img/image00249.jpeg)'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![Excel中的文本到列](img/image00249.jpeg)'
- en: This is the result after the first round of text-to-columns splitting.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是第一次文本到列拆分后的结果。
- en: We will have to run text-to-columns again but just on column D this time, and
    we will use delimited instead of fixed-width procedure. First, note that there
    are two spaces between the channel name **#eurovision** and the number of users
    (**4**) and two spaces again between **4** and the channel description. Even though
    text-to-columns does not allow us to type two spaces as a delimiter (it allows
    single characters only), we can use the **Find-Replace** dialogue to replace all
    cases of two spaces with a symbol that is not used anywhere else in our text.
    (Perform a **Find** operation first to make sure.) I chose a `^` symbol.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要再次运行文本到列向导，但这次只针对列D，并且使用分隔符方式而非固定宽度方式。首先，注意频道名称**#eurovision**与用户数量（**4**）之间有两个空格，**4**与频道描述之间也有两个空格。尽管文本到列向导不允许我们使用两个空格作为分隔符（它只允许单个字符），我们可以使用**查找-替换**对话框将所有两个空格的情况替换为一个在文本中未使用的符号。（首先执行**查找**操作以确保。）我选择了`^`符号。
- en: This particular step seems a little sloppy, so if you are interested in an alternate
    approach, I do not blame you one bit. Excel is more limited than other tools in
    its ability to find and replace bad text. We will learn how to use regular expressions
    in the *Text editor data cleaning* section later in this chapter.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这一特定步骤看起来有点草率，所以如果你有兴趣尝试另一种方法，我一点也不怪你。与其他工具相比，Excel在查找和替换坏文本方面的功能较为有限。我们将在本章后面的*文本编辑器数据清理*部分学习如何使用正则表达式。
- en: '![Text to columns in Excel](img/image00250.jpeg)'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![Excel中的文本到列](img/image00250.jpeg)'
- en: Adding an unusual delimiting character allows us to split apart the remaining
    columns.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 添加一个不常见的分隔符可以让我们将剩余的列分开。
- en: Now, use **Find-Replace** to remove the `[` and `]` characters from columns
    A and B, replacing them with nothing. (Highlight these columns before starting
    find-replace so that you do not accidentally remove symbols throughout the whole
    sheet.)
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用**查找替换**从A列和B列中移除`[`和`]`字符，并将它们替换为空。 （在开始查找替换之前，高亮显示这些列，以免不小心在整个工作表中删除符号。）
- en: 'Unfortunately, Excel, in its eternal quest to try to help us, turns these into
    dates formatted in a way we might not like: 9/19/2014\. If you want these to go
    back to the way they were (2014-09-19), select the entire column and use the custom
    format dialogue to specify the date format as yyyy-mm-dd.'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不幸的是，Excel为了帮助我们，将这些转换为我们可能不喜欢的日期格式：9/19/2014。如果你想将它们恢复到原来的格式（2014-09-19），请选择整列，并使用自定义格式对话框指定日期格式为yyyy-mm-dd。
- en: The strings in column **F** still have extra space at the beginning. We can
    strip the extra spaces from the front of each string value using the `trim()`
    function. Insert a new column to the left of **F**, and apply the `trim()` function,
    shown as follows:![Text to columns in Excel](img/image00251.jpeg)
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**F**列中的字符串仍然在前面有多余的空格。我们可以使用`trim()`函数去除每个字符串值前面的额外空格。插入一个新列到**F**列的左侧，并应用`trim()`函数，如下所示：![Excel中的文本到列](img/image00251.jpeg)'
- en: This is the result of applying the `trim()` function to strip out leading or
    trailing spaces.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是应用`trim()`函数以去除前导或尾随空格后的结果。
- en: 'We can also apply the `clean()` function to the trimmed text. This will remove
    any of the first 32 ASCII characters: all non-printing control characters that
    may have somehow made their way into these channel descriptions. You can apply
    `clean()` outside `trim()` functions like this: `clean(trim(g1))`.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以对修剪后的文本应用`clean()`函数。这个函数将删除前32个ASCII字符：所有可能进入这些频道描述中的不可打印控制字符。你可以在`trim()`函数外部应用`clean()`，如下所示：`clean(trim(g1))`。
- en: Drag the corner of the F1 box down to apply `clean(trim())` to the rest of the
    cells in column **F**.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将F1框的角拖动到底部，以将`clean(trim())`应用到**F**列的其余单元格。
- en: Select column **F**, copy it, and use **Paste Special Values Only** in column
    **F** so that we can delete column **G**.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**F**列，复制它，并在**F**列中使用**仅粘贴值**，这样我们就可以删除**G**列。
- en: Delete column **G**. Voila, now you have perfectly cleaned data.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除**G**列。瞧，现在你有了完美清理的数据。
- en: Splitting strings
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拆分字符串
- en: A lightweight version of the text to columns feature, available in Google Spreadsheets
    but not in Excel, is the `split()` function. This function just takes a string
    value and splits it into its component pieces. Be aware that you need to provide
    enough new columns for the newly split data to fit into. In the following example,
    we have used the same data as the previous example but created three new columns
    to hold the split values from **D**.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Google 表格中有一个轻量级版本的“文本到列”功能，但 Excel 中没有，那就是`split()`函数。这个函数只是接受一个字符串值，并将其拆分成组成部分。请注意，你需要提供足够的新的列来容纳拆分后的数据。在下面的例子中，我们使用了与之前示例相同的数据，但创建了三个新列来容纳**D**列的拆分值。
- en: '![Splitting strings](img/image00252.jpeg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![拆分字符串](img/image00252.jpeg)'
- en: Concatenating strings
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接字符串
- en: 'The `concatenate()` function takes a number of strings, either as cell references
    or as quoted strings, and attaches them together inside a new cell. In the following
    example, we use the `concatenate()` function to join the date and time strings
    into one. This function is available in both Excel and Google Spreadsheets, as
    shown in the following figure:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`concatenate()`函数接受多个字符串，无论是作为单元格引用还是作为带引号的字符串，并将它们连接到一个新单元格中。在下面的例子中，我们使用`concatenate()`函数将日期和时间字符串连接为一个。这个函数在Excel和Google表格中都有，如下图所示：'
- en: '![Concatenating strings](img/image00253.jpeg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![连接字符串](img/image00253.jpeg)'
- en: Conditional formatting to find unusual values
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 条件格式化以查找异常值
- en: Both Excel and Google spreadsheets have **conditional formatting** features.
    Conditional formatting uses a set of rules to change the appearance (format) of
    a cell or cells depending on whether some criteria are met (condition). We can
    use this to find data that is too high, too low, missing, or otherwise strange.
    Once we have identified it, we can clean it.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Excel和Google电子表格都有**条件格式**功能。条件格式使用一组规则，根据是否满足某些条件（条件）来更改单元格或单元格的外观（格式）。我们可以使用此功能来查找过高、过低、缺失或其他异常的数据显示。一旦我们识别出这些数据，就可以清理它们。
- en: 'Here is an example of how to use conditional formatting in Google Spreadsheets
    to find a row in our sample data that does not include `#` in the channel name
    and has an empty value for the number of chat participants:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个如何在Google电子表格中使用条件格式查找样本数据中不包含`#`的频道名称且聊天室参与者人数为空的行的示例：
- en: '![Conditional formatting to find unusual values](img/image00254.jpeg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![使用条件格式查找异常值](img/image00254.jpeg)'
- en: Here is the result after the background cell colors have been changed to locate
    cells in **D** that do not start with `#` and cells in **E** that are empty. Now
    these problem values can be found easily with a visual inspection.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这是背景单元格颜色已更改后的结果，定位了**D**列中不以`#`开头的单元格，以及**E**列中为空的单元格。现在，这些问题值可以通过视觉检查轻松找到。
- en: '![Conditional formatting to find unusual values](img/image00255.jpeg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![使用条件格式查找异常值](img/image00255.jpeg)'
- en: Sorting to find unusual values
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 排序以查找异常值
- en: If there is too much data for a visual inspection, then we could try to employ
    sorting to find the troublesome data. In either Google Spreadsheets or Excel,
    select the columns you want to sort, which can be the entire sheet, and use the
    **Sort** option in the **Data** menu. This works fairly easily for most of the
    columns, especially if you are looking for data like cell D4.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据量太大，无法进行视觉检查，那么我们可以尝试使用排序来查找问题数据。在Google电子表格或Excel中，选择你想要排序的列，这可以是整个表格，然后使用**数据**菜单中的**排序**选项。这对于大多数列来说非常简单，尤其是当你在查找像D4单元格这样的数据时。
- en: But what happens if you try to sort by column **E** in order to find that missing
    value? Maybe we would like to put all the missing data together so that we can
    delete these rows of data. The value for E4 is empty. Remember from [Chapter 2](part0020.xhtml#aid-J2B82
    "Chapter 2. Fundamentals – Formats, Types, and Encodings"), *Fundamentals – Formats,
    Types, and Encodings*, that NULL (empty in Google Spreadsheets parlance) cannot
    be compared to any other value, so it remains at the bottom of the sorted list
    no matter whether you sort the values in column **E** from low to high or high
    to low.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果你尝试按**E**列排序以查找丢失的值会发生什么呢？也许我们希望将所有缺失的数据放在一起，以便删除这些数据行。E4的值是空的。记住在[第2章](part0020.xhtml#aid-J2B82
    "第2章. 基础知识 – 格式、类型和编码")中提到的，*基础知识 – 格式、类型和编码*，NULL（在Google电子表格中为空）不能与任何其他值进行比较，因此无论你是按从低到高还是从高到低排序**E**列的值，它都会保持在排序列表的底部。
- en: Importing spreadsheet data into MySQL
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将电子表格数据导入MySQL
- en: Now that you have a lovely spreadsheet full of clean data, you might wish to
    store it in a database for the long term.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有了一个满是清洁数据的漂亮电子表格，你可能希望将其存储到数据库中以便长期使用。
- en: Creating CSV from a spreadsheet
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 从电子表格创建CSV
- en: Many database systems will accept data via an import routine built around CSV
    files. If you are using MySQL, there is a `LOAD DATA IN FILE` command that will
    slurp data right into the database from a delimited file, and you can even set
    your own delimiter. First, let's take a look at an example of the command, and
    then we can create the file in Excel according to the parameters we want.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据库系统会通过围绕CSV文件构建的导入程序来接收数据。如果你使用的是MySQL，可以使用`LOAD DATA IN FILE`命令将数据直接从分隔文件导入数据库，甚至可以设置自己的分隔符。首先，让我们看看这个命令的示例，然后我们可以根据需要的参数在Excel中创建文件。
- en: 'From the MySQL command line, we can run:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从MySQL命令行，我们可以运行：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This, of course, assumes that a table has already been created. In this case,
    it is called `freenode_topics`, and it has four columns in it, which appear on
    the last line of this SQL query.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这假设已经创建了一个表格。在这个例子中，它叫做`freenode_topics`，并且它有四列，这些列出现在此SQL查询的最后一行。
- en: The CSV file referenced in this query, `myFile.csv`, will therefore need to
    have the columns in this order and separated by commas.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个查询中引用的CSV文件`myFile.csv`需要按照此顺序排列列，并用逗号分隔。
- en: In Excel, a CSV can be created from the current sheet in a workbook by navigating
    to **File** | **Save As** and then choosing **CSV (MS-DOS)** from the list of
    format options. In Google Spreadsheets, you can accomplish the same thing by navigating
    to **File** | **Downloads** | **CSV**. In both cases, save the file to your local
    system and then launch the MySQL client and proceed through the command line shown
    previously.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Excel 中，可以通过导航到 **文件** | **另存为**，然后从格式选项列表中选择 **CSV (MS-DOS)** 来从当前工作簿的工作表创建
    CSV 文件。在 Google 电子表格中，您可以通过导航到 **文件** | **下载** | **CSV** 来实现相同的操作。在这两种情况下，保存文件到本地系统，然后启动
    MySQL 客户端，并按照之前显示的命令行操作。
- en: Tip
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: If you do not like using the MySQL command-line client, CSV files can also be
    uploaded to a server using MySQL's own Workbench graphical client or using a tool
    like PhpMyAdmin. PhpMyAdmin does have a size limit on the upload file (currently,
    2 MB).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不喜欢使用 MySQL 命令行客户端，还可以通过 MySQL 自带的 Workbench 图形客户端或类似 PhpMyAdmin 的工具将 CSV
    文件上传到服务器。PhpMyAdmin 对上传的文件大小有一个限制（目前为 2MB）。
- en: Generating SQL using a spreadsheet
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用电子表格生成 SQL
- en: Another way to get data into a database seems strange at first, but it can be
    a real timesaver if you are unable—for whatever reason, maybe because of the wrong
    permissions or because of file size limits—to load it via the CSV discussed previously.
    In this method, we will build `INSERT` statements inside the spreadsheet itself
    and then run these commands in the database.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种将数据导入数据库的方法一开始看起来很奇怪，但如果您由于某些原因（可能是权限问题或文件大小限制）无法通过前面讨论的 CSV 文件加载数据，这个方法可能会节省很多时间。在这种方法中，我们将在电子表格中构建
    `INSERT` 语句，然后在数据库中运行这些命令。
- en: If each column in the spreadsheet represents a column in the database, then
    we can simply add the structural components of a SQL `INSERT` command (quoted
    strings, parenthesis, commands, and line-terminating semicolons) around the columns
    in the spreadsheet and concatenate the result together into a giant string of
    `INSERT` commands.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果电子表格中的每一列都代表数据库中的一列，那么我们可以简单地将 SQL `INSERT` 命令的结构组件（带引号的字符串、括号、命令和行结束分号）添加到电子表格中的各列周围，并将结果拼接成一个巨大的
    `INSERT` 命令字符串。
- en: '![Generating SQL using a spreadsheet](img/image00256.jpeg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![使用电子表格生成 SQL](img/image00256.jpeg)'
- en: 'After using the `concatenate(A1:I1)` function to attach all the strings in
    columns A:I, we end up with `INSERT` statements that look like this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `concatenate(A1:I1)` 函数将 A:I 列中的所有字符串连接后，我们得到的 `INSERT` 语句如下所示：
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'These can be pasted into a user-friendly frontend, such as PhpMyAdmin or MySQL
    Workbench. Or, you can save this as a text file (using your text editor), one
    `INSERT` statement after the other. I called my file `inserts.sql`. This file
    can now be imported into the database using the command line and MySQL client,
    as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可以粘贴到用户友好的前端界面中，例如 PhpMyAdmin 或 MySQL Workbench。或者，您可以将其保存为文本文件（使用文本编辑器），每个
    `INSERT` 语句之间用换行分隔。我把我的文件命名为 `inserts.sql`。现在，可以通过命令行和 MySQL 客户端将此文件导入数据库，方法如下：
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Or, it can be imported using the `source` command in the MySQL command-line
    client like this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，它也可以通过在 MySQL 命令行客户端中使用 `source` 命令来导入，命令如下：
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Either one of these will work to get the data into MySQL. If the script is small
    enough, you can also use one of the graphical clients, such as MySQL Workbench.
    Be careful of loading very large scripts into the graphical client, however, as
    the amount of memory on your client machine may not be sufficient to load hundreds
    of gigabytes of SQL. I prefer the second method (`source`) because it prints out
    a success message following each successful insert, so I know my commands are
    good.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 任何一种方法都可以将数据导入 MySQL。如果脚本足够小，您还可以使用图形客户端，如 MySQL Workbench。不过要小心，将非常大的脚本加载到图形客户端中，因为客户端机器的内存可能不足以加载数百GB的
    SQL。我更喜欢第二种方法（`source`），因为它会在每个成功插入后打印出成功消息，这样我就知道我的命令是正确的。
- en: If you are a little unclear about how you would go about creating a text file
    called `inserts.sql`, then the next section is for you. We are going to cover
    more than you ever thought you would want to know about text editors!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不太清楚如何创建名为 `inserts.sql` 的文本文件，那么下一节将为您详细讲解。我们将介绍比您想象的更多文本编辑器相关的内容！
- en: Text editor data cleaning
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本编辑器数据清理
- en: We learned in [Chapter 2](part0020.xhtml#aid-J2B82 "Chapter 2. Fundamentals
    – Formats, Types, and Encodings"), *Fundamentals – Formats, Types, and Encodings*,
    that text editors are the preferred way of reading and creating text files. This
    sounds reasonable and makes perfect sense. What we did not really explain back
    then was that a text editor is sometimes also called a programmer's editor because
    it has many cool features that help folks such as programmers, as well as data
    cleaners, who must deal with text files all day long. We are going to take a tour
    of some of the most useful features now.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第二章](part0020.xhtml#aid-J2B82 "第二章：基础 – 格式、类型和编码")，*基础 – 格式、类型和编码*中学习到，文本编辑器是读取和创建文本文件的首选方式。这听起来很合理，也完全能理解。我们当时没有真正解释的是，文本编辑器有时也被称为程序员的编辑器，因为它具有许多有用的功能，帮助像程序员以及数据清理人员这样的工作者，他们整天都在处理文本文件。我们现在将参观一些最有用的功能。
- en: Tip
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'There are dozens of text editors available for every operating system. Some
    of them cost money, but many are available at no cost. For this chapter, I am
    going to use Text Wrangler, a no cost editor available for OSX (available here:
    [http://www.barebones.com/products/textwrangler](http://www.barebones.com/products/textwrangler)).
    The features shown in this chapter are widely available in most other editors,
    such as Sublime Editor, but you should check the documentation for whatever editor
    you have chosen if the location of a particular feature or tool is not obvious.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 每个操作系统都有数十款文本编辑器可供选择。有些需要付费，但许多都是免费的。在本章中，我将使用Text Wrangler，它是一个免费的编辑器，适用于OSX（可以在此获取：[http://www.barebones.com/products/textwrangler](http://www.barebones.com/products/textwrangler)）。本章展示的功能在大多数其他编辑器中也广泛可用，如Sublime
    Editor，但如果某个特定功能或工具的位置不明显，你应该查看你所选择的编辑器的文档。
- en: Text tweaking
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本调整
- en: Our text editor of choice has a number of useful functions built into it for
    text manipulation. The ones outlined here represent some of the most commonly
    used ones for data cleaning tasks. Keep in mind that you might run dozens of cleaning
    routines on a single text file in the course of cleaning it, so the tips we gave
    in [Chapter 1](part0014.xhtml#aid-DB7S1 "Chapter 1. Why Do You Need Clean Data?"),
    *Why Do You Need Clean Data?*, for how to clearly communicate the changes you
    made will really come in handy here.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择的文本编辑器内置了许多用于文本处理的有用功能。这里列出的功能是数据清理任务中最常用的一些。请记住，在清理过程中，你可能会对单个文本文件执行几十个清理程序，所以我们在[第一章](part0014.xhtml#aid-DB7S1
    "第一章：为什么需要干净的数据？")，*为什么需要干净的数据？*中提供的关于如何清晰地传达你所做更改的提示在这里会非常有用。
- en: '**Changing case** is a very common request in data cleaning. Many times, we
    will inherit data that is all lowercase or all uppercase. The following image
    shows a dialogue within Text Wrangler to perform case changes on a selection of
    text. The keyboard shortcuts are shown to the right of each option.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**更改大小写**是数据清理中非常常见的请求。很多时候，我们会继承完全小写或完全大写的数据。下图展示了Text Wrangler中一个用于对选中文本进行大小写更改的对话框。每个选项旁边显示了键盘快捷键。'
- en: '![Text tweaking](img/image00257.jpeg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![文本调整](img/image00257.jpeg)'
- en: Options for case changes include uppercase and lowercase as well as capitalizing
    the first letter of each word, line, or the first word in a sentence.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 大小写更改的选项包括大写、小写以及将每个单词、每行的第一个字母或句子中的第一个单词大写。
- en: Adding or removing prefixes or suffixes on each line in a selection is another
    common task. I needed to do this for a large amount of text lines the other day
    when I was building a text classifier. I needed to suffix each line with a comma
    and the name of what class (positive or negative) the line exemplified. Here is
    the prefix and suffix dialogue in Text Wrangler. Note how you can either insert
    or remove, but not both, in the same maneuver. If you need to perform both of
    these tasks, perform one, and then perform the other.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择中的每一行添加或删除前缀或后缀是另一个常见的任务。前几天，当我在构建文本分类器时，我需要处理大量的文本行。需要在每一行的末尾加上一个逗号，并标明该行所代表的类别（正面或负面）。以下是Text
    Wrangler中的前缀和后缀对话框。注意，你可以选择插入或删除，但不能在同一操作中同时进行。如果你需要执行这两个任务，先执行一个，然后再执行另一个。
- en: '![Text tweaking](img/image00258.jpeg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![文本调整](img/image00258.jpeg)'
- en: '**Zapping gremlins** is another excellent task for your text editor. Both TextWrangler
    and Sublime Editor for Windows have this feature. In zapping gremlins, the editor
    can look for any characters that are outside of your desired character set, for
    example, control characters, NULL characters, and non-ASCII characters. It can
    either delete them or replace them with their character code. It could also replace
    the gremlins with any character that you specify. This makes them easier to find
    later.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**删除小怪物**是另一个非常适合您使用文本编辑器的任务。TextWrangler 和适用于 Windows 的 Sublime 编辑器都有这个功能。在删除小怪物时，编辑器可以查找任何不在您希望的字符集中的字符，例如控制字符、NULL
    字符和非 ASCII 字符。它可以删除它们，或者将它们替换为它们的字符代码。它还可以将这些小怪物替换为您指定的任何字符。这样可以在之后更容易找到它们。'
- en: '![Text tweaking](img/image00259.jpeg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![文本调整](img/image00259.jpeg)'
- en: The column mode
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列模式
- en: 'When a text editor is in **column mode**, it means that you can select text
    in columns and not just in rows. Here is an example of selection in a normal (non-column)
    mode:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当文本编辑器处于**列模式**时，意味着您可以按列选择文本，而不仅仅是按行选择。这里是正常（非列）模式下的选择示例：
- en: '![The column mode](img/image00260.jpeg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![列模式](img/image00260.jpeg)'
- en: 'Here is an example of a selection in column mode. Hold down the **Option**
    key and select the text in columns. Once the text is selected, you can treat it
    just like you would treat any selected text: you can delete it, cut it or copy
    it onto the clipboard, or use any of the text tweaks we discussed in the preceding
    section as long as they work on a selection.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是列模式下选择的示例。按住**Option**键并选择列中的文本。一旦文本被选中，您可以像处理任何已选文本一样处理它：您可以删除它、剪切它或将其复制到剪贴板，或者使用我们在前一部分中讨论的任何文本调整，只要它们适用于选中的文本。
- en: '![The column mode](img/image00261.jpeg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![列模式](img/image00261.jpeg)'
- en: 'A few limitations of this feature include:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这个功能的一些限制包括：
- en: Each character is one column, so characters should be displayed in a non-proportional,
    typewriter-style typeface.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个字符占用一列，因此字符应以不带比例的打字机风格字体显示。
- en: In Text Wrangler, the column mode only works when line wrapping is turned off.
    Turning off soft wrapping means your lines will extend to the right and not be
    wrapped.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Text Wrangler 中，列模式仅在关闭换行时有效。关闭软换行意味着您的行将延伸到右边，不会被换行。
- en: In Text Wrangler, the vertical height of the column you are drawing must be
    able to be drawn by you manually, so this is a technique for small amounts of
    data (hundreds or thousands of rows, but probably not hundreds *of* thousands
    of rows).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Text Wrangler 中，您绘制的列的垂直高度必须能够手动绘制，因此这是一个用于小规模数据（几百行或几千行，但可能不是几百万行）的技巧。
- en: Heavy duty find and replace
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强力查找与替换
- en: Text editors really shine at manipulating text. It may feel strange to use a
    text editor in the column mode, as that seems like more of a natural task for
    a spreadsheet. Similarly, it may seem awkward to use a spreadsheet for **Find-Replace**
    after you see what a text editor can do.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 文本编辑器在处理文本方面非常出色。使用文本编辑器在列模式下工作可能会让人觉得奇怪，因为这看起来更像是电子表格中的任务。类似地，在您看到文本编辑器能做的事情后，使用电子表格进行**查找-替换**可能会显得有些笨拙。
- en: The main portion of the **Find** dialogue window in Text Wrangler is shown as
    follows. The provided features include options for case-sensitive searches, wrapping
    around, searching in subselections of text, and looking for the given text pattern
    inside either a word or just a portion of a word. You can also paste special characters,
    whitespace (including tabs and line terminators), emojis, and so on, into the
    textbox. The little drop-down boxes to the right of the **Find** box provide additional
    functionality. The top one with the clock icon on it holds a list of recent searches
    and replacements. The bottom one with the letter **g** on it holds a list of built-in
    search patterns that might be useful, and at the bottom of this menu is an option
    to add your own patterns to the list.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Text Wrangler 中**查找**对话框的主要部分如下所示。提供的功能包括大小写敏感的搜索、循环搜索、在文本的子选择中进行搜索以及在单词或单词的一部分中查找给定的文本模式。您还可以将特殊字符、空白（包括制表符和行终止符）、表情符号等粘贴到文本框中。**查找**框右侧的小下拉框提供了额外的功能。带有时钟图标的顶部框包含最近的搜索和替换列表。带有字母**g**的底部框包含一组可能有用的内置搜索模式，在此菜单的底部，还有一个选项可以将您自己的模式添加到列表中。
- en: '![Heavy duty find and replace](img/image00262.jpeg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![强力查找与替换](img/image00262.jpeg)'
- en: One of the most powerful find-replace features is enabled by the **Grep** checkbox.
    Checking this box allows us to use a regular expression pattern for our searches.
    In short, a **regular expression** (**regex**) is a pattern written in a special
    language, made up of symbols, and designed to match against some string text.
    A full treatment of regular expressions is beyond the scope of this book, but
    suffice it to say that they are enormously useful and we will be visiting them
    periodically when we need them to clean data.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个最强大的查找替换功能是通过选中 **Grep** 复选框来启用的。选中此框后，我们可以使用正则表达式模式进行搜索。简而言之，**正则表达式**（**regex**）是一种用特殊语言编写的模式，由符号组成，旨在与某些字符串文本匹配。正则表达式的详细解释超出了本书的范围，但可以说它们非常有用，我们会在需要清理数据时定期使用它们。
- en: Tip
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: The reason the checkbox in the Text Wrangler interface says Grep—and not RegEx
    or Match—is that there are several slight variations on the regular expression
    pattern-matching language. Text Wrangler is signaling to us that it is using the
    one from Grep, a program originally written for Unix and the most common variant.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Text Wrangler 界面中的复选框标示为 Grep——而不是 RegEx 或 Match——是因为正则表达式模式匹配语言存在一些微小的差异。Text
    Wrangler 在提醒我们，它使用的是 Grep 版本，Grep 是最常见的变种，最初是为 Unix 系统编写的程序。
- en: 'Here, we will outline a few of the indispensible regular expression symbols
    that we will use time and again to clean data. For more complicated patterns,
    it is worth consulting a special book or one of the myriad web pages that show
    all kinds of exotic regular expression syntaxes:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将概述一些我们在清理数据时会反复使用的必备正则表达式符号。对于更复杂的模式，值得参考一本专门的书籍或多个展示各种正则表达式语法的网页：
- en: '| Symbol | What it does |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 符号 | 功能 |'
- en: '| --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `$` | Matches the end of the line |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| `$` | 匹配行尾 |'
- en: '| `^` | Matches the beginning of the line |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| `^` | 匹配行首 |'
- en: '| `+` | Matches one or more of the specified characters |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| `+` | 匹配一个或多个指定字符 |'
- en: '| `*` | Matches 0 or more of the specified characters |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| `*` | 匹配零个或多个指定字符 |'
- en: '| `\w` | Matches any word character (0-9, A-z). To match nonword characters,
    use `\W` |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| `\w` | 匹配任意单词字符（0-9，A-z）。要匹配非单词字符，请使用 `\W` |'
- en: '| `\s` | Matches any whitespace character (tab, line feed, or carriage return).
    To match non-whitespace characters, use `\S` |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| `\s` | 匹配任意空白字符（制表符、换行符或回车符）。要匹配非空白字符，请使用 `\S` |'
- en: '| `\t` | Matches a tab character |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| `\t` | 匹配制表符 |'
- en: '| `\r` | Matches a carriage return. Use `\n` for line feed. |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| `\r` | 匹配回车符。使用 `\n` 来匹配换行符。 |'
- en: '| `\` | This is the escape character. It matches the exact character that follows,
    not the regex pattern character. |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| `\` | 这是转义字符。它匹配紧随其后的确切字符，而不是正则表达式模式字符。 |'
- en: Here are a few examples of find-replace combinations so that we can learn how
    Text Wrangler works with regular expressions. Make sure the Grep box is checked.
    If nothing is shown in the replace column, it means that the Replace field should
    be left empty.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些查找替换组合的示例，帮助我们学习如何在 Text Wrangler 中使用正则表达式。确保选中 Grep 框。如果替换列为空，则意味着替换字段应该保持为空。
- en: '| Find | Replace | What it does |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 查找 | 替换 | 功能 |'
- en: '| --- | --- | --- |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `\r` |   | Finds a line feed (line terminator) and replaces it with nothing.
    Another way to phrase this is "make multiple lines into one line". |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| `\r` |   | 查找换行符（行终止符），并将其替换为空。换句话说，就是“将多行合并为一行”。 |'
- en: '| `^\w+` | `-` | Matches the beginning of the line, followed by at least a
    one-word character. Adds a `-` character to the front of the line. |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| `^\w+` | `-` | 匹配行首，后跟至少一个单词字符，并在行前加上一个 `-` 字符。 |'
- en: '| `\\r$` | `\[end\]` | Looks for all lines that end with the actual `\r` characters
    (backslash followed by r) and replaces them with the actual characters `[end]`.
    Note that [ and ] are special regex characters as well, so they will need to be
    escaped to use them as actual characters. |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| `\\r$` | `\[end\]` | 查找所有以实际的 `\r` 字符（反斜杠后跟 r）结尾的行，并将其替换为实际字符 `[end]`。请注意，`[`
    和 `]` 也是正则表达式中的特殊字符，因此在将其作为普通字符使用时需要进行转义。 |'
- en: If regular expressions seem daunting, take heart. First, recall from the *Text
    tweaking* section earlier in this chapter that most text editors, Text Wrangler
    included, have many built-in search and replace features that are built on the
    most common regular expressions. So, you may find that you do not really have
    to write many regular expressions very often. Second, as regular expressions are
    so powerful and so useful, there are a lot of online resources that you can consult
    to learn how to build a complicated regex if you need it.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果正则表达式让你感到畏惧，请放心。首先，回想一下本章早些时候提到的 *文本调整* 部分，大多数文本编辑器，包括 Text Wrangler，都有许多内置的搜索和替换功能，这些功能是基于最常用的正则表达式构建的。因此，你可能会发现自己并不常常需要编写很多正则表达式。其次，正则表达式如此强大和实用，因此有许多在线资源可以供你参考，帮助你学习如何构建复杂的正则表达式，如果你需要的话。
- en: Two of my favorite resources for regex are Stack Overflow ([http://stackoverflow.com](http://stackoverflow.com))
    and regular-expresions.info ([http://regular-expressions.info](http://regular-expressions.info)).
    There are also numerous regular expression testing websites available via a quick
    web search. These sites let you write and test the regular expressions on a sample
    text.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我的两个最喜欢的正则表达式资源是 Stack Overflow（[http://stackoverflow.com](http://stackoverflow.com)）和
    regular-expressions.info（[http://regular-expressions.info](http://regular-expressions.info)）。此外，通过快速的网页搜索，你还可以找到许多正则表达式测试网站。这些网站让你编写并测试正则表达式，应用于样本文本。
- en: A word of caution
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提醒一下
- en: Be careful when using online regex testers, however, as they are usually designed
    to teach a particular flavor of regular expressions, such as for the regex parsers
    inside JavaScript, PHP, or Python. Some of the things you want to do may have
    the same regular expression syntax in your text editor as the one in these languages,
    or they may not. Depending on the complexity of what you are trying to do, it
    may be a better idea just to create a backup copy of your text data (or extract
    a small sample of the text in question into a new file) and experiment on it in
    your own text editor using its regular expression syntax.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在使用在线正则表达式测试工具时要小心，因为它们通常是为教授特定类型的正则表达式而设计的，比如 JavaScript、PHP 或 Python 中的正则表达式解析器。你想做的一些操作，可能在你的文本编辑器中的正则表达式语法与这些语言中的相同，也可能不同。根据你尝试做的事情的复杂程度，最好的方法可能是创建一个文本数据的备份副本（或者将问题文本的一个小样本提取到一个新文件中），然后使用你自己的文本编辑器并根据其正则表达式语法进行实验。
- en: Text sorting and processing duplicates
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本排序与重复处理
- en: 'Once we have experimented with regex a little bit, we notice that our text
    editor will occasionally make these pattern-matching techniques available in other
    menu options, for example, in sorting and duplicate processing. Consider the following
    sorting dialogue to see how a regex can be applied to sorting multiple lines:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们稍微实验了一下正则表达式，我们会注意到我们的文本编辑器偶尔会在其他菜单选项中提供这些模式匹配技术，例如在排序和重复处理中。考虑以下排序对话框，看看如何将正则表达式应用于排序多行：
- en: '![Text sorting and processing duplicates](img/image00263.jpeg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![文本排序与重复处理](img/image00263.jpeg)'
- en: In this case, we can use the **Sort using pattern** checkbox to enter a regular
    expression pattern to sort by. The duplicate processing dialogue is similar. You
    can tell the editor whether to leave the original line or remove it. Interestingly,
    you can also remove the duplicates to another file or to the clipboard if you
    need to use them for something else, such as keeping a log of removed lines, perhaps.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以使用 **按模式排序** 复选框来输入一个正则表达式模式进行排序。重复处理对话框类似。你可以告诉编辑器是否保留原始行或删除它。有趣的是，如果你需要将它们用于其他用途，比如保持已删除行的日志，你还可以将重复项移到另一个文件或剪贴板。
- en: Tip
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: In data cleaning, it is a good idea to at least consider saving the removed
    lines into their own file in case you ever need them again.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据清理中，至少考虑将移除的行保存到单独的文件中，以备将来需要时使用，这是一个好主意。
- en: '![Text sorting and processing duplicates](img/image00264.jpeg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![文本排序与重复处理](img/image00264.jpeg)'
- en: Process Lines Containing
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 包含处理行
- en: One handy feature in Text Wrangler is called **Process Lines Containing**. It
    mixes searching (including the possibility of using a regular expression) with
    line-by-line processing, such as removing the affected lines to another file or
    to the clipboard, or deleting the matching lines.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Text Wrangler 中有一个很实用的功能，叫做 **包含处理行**。它将搜索（包括使用正则表达式的可能性）与逐行处理结合起来，例如将受影响的行移到另一个文件或剪贴板，或者删除匹配的行。
- en: '![Process Lines Containing](img/image00265.jpeg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![包含处理行](img/image00265.jpeg)'
- en: An example project
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个示例项目
- en: In this example project, we will download a spreadsheet, use Excel or a text
    editor to clean it, and then run some simple analyses on it.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例项目中，我们将下载一个电子表格，使用 Excel 或文本编辑器清理它，然后对其进行一些简单的分析。
- en: Step one – state the problem
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步 – 陈述问题
- en: This project is inspired by some data made available by the Chronicle of Higher
    Education, a publication about college and university news and happenings. In
    2012, they created an interactive feature called "Who does your college think
    its peers are?". In this feature, users can enter the name of any US-based college
    or university into a form and see an interactive visualization showing which other
    universities call that target school a **peer**. (Peers are universities that
    are similar in some way.) The original data came from U.S. government reports,
    but the Chronicle has made the data underlying this visualization free for anyone
    to use.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的灵感来源于《高等教育纪事》提供的一些数据，这是一份关于大学和高等院校新闻及事件的出版物。在2012年，他们创建了一个名为“你的大学认为它的同行是谁？”的互动功能。在这个功能中，用户可以输入任何美国大学的名称，并看到一个互动可视化，显示其他哪些大学称目标大学为**同行**。（同行是指在某些方面相似的大学。）原始数据来自美国政府报告，但《高等教育纪事》已将这些数据免费提供给任何人使用。
- en: 'For this example, we are interested in a complimentary question: When University
    X appears on a list, which other universities are on these lists? To answer this
    question, we will need to find all the other universities that are listed with
    University X, and then we will have to count how many times each of their names
    occurs.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们关心的是一个补充性问题：当大学X出现在一个列表中时，哪些其他大学也在这些列表中？为了解答这个问题，我们需要找到所有与大学X一起列出的其他大学，然后统计它们的名字出现了多少次。
- en: Step two – data collection
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二步 – 数据收集
- en: In this step, we will see the procedure to collect data and then clean it in
    a step-by-step manner. The upcoming sections discuss the actions we need to take
    in order to collect proper data for our project.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步中，我们将看到收集数据的过程，并逐步清理它。接下来的部分将讨论我们需要采取的行动，以便为我们的项目收集适当的数据。
- en: Download the data
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下载数据
- en: The data for this project can be downloaded from the original article at [http://chronicle.com/article/Who-Does-Your-College-Think/134222/](http://chronicle.com/article/Who-Does-Your-College-Think/134222/)
    or from the direct link to the spreadsheet at [https://s3.amazonaws.com/03peers/selected_peers.csv.zip](https://s3.amazonaws.com/03peers/selected_peers.csv.zip)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的数据可以通过原文中的[链接](http://chronicle.com/article/Who-Does-Your-College-Think/134222/)下载，或者通过[直接链接到电子表格](https://s3.amazonaws.com/03peers/selected_peers.csv.zip)下载。
- en: The file is zipped, so use your unzip program of choice to unzip the file.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 文件已被压缩，请使用你喜欢的解压软件解压文件。
- en: Get familiar with the data
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 熟悉数据
- en: 'The file inside the ZIP folder has a `.csv` extension, and it indeed is a CSV-delimited
    file with 1,686 rows in it, including a header row. The commas delimit two columns:
    the first column is the name of the university in question, and the second column
    is the list of all the universities that the original one listed as peers. These
    peers are themselves delimited by the pipe (`|`) character. Here is a sample row:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ZIP 文件中的文件具有 `.csv` 扩展名，确实是一个以逗号分隔的 CSV 文件，包含1686行，其中包括一行标题。逗号分隔了两列：第一列是相关大学的名称，第二列是该大学列出的所有同行大学。同行大学之间由管道符号
    (`|`) 分隔。以下是一个示例行：
- en: '[PRE5]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this case, the first column states that Harvard University is the target
    university, and the second column shows that Yale, Princeton, and Stanford have
    been listed by Harvard as its peers.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，第一列表示哈佛大学是目标大学，第二列显示哈佛将耶鲁、普林斯顿和斯坦福列为其同行。
- en: Step three – data cleaning
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三步 – 数据清理
- en: As the goal of this example is to look at one particular university and all
    the times it is listed as some other university's peer, our first goal is to clean
    out any row that does *not* have the target university in it. We will then transform
    the file into a single long list of individual universities. At this point, our
    data will be clean and we will be ready to go to the analysis and visualization
    steps.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本示例的目标是查看某所大学以及它在其他大学的同行名单中的所有出现情况，我们的第一步是清除任何*不*包含目标大学的行。然后，我们将把文件转化为一个包含所有大学的长列表。到那时，我们的数据将已经清理干净，准备好进入分析和可视化步骤。
- en: Extracting relevant lines
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提取相关行
- en: 'Let''s compare two methods for extracting relevant lines: one using a spreadsheet
    and one using a text editor with the techniques outlined in this chapter.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来比较两种提取相关行的方法：一种是使用电子表格，另一种是使用文本编辑器，并应用本章中概述的技术。
- en: Using a spreadsheet
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用电子表格
- en: Open the file in a spreadsheet program, highlight any row that has **Harvard**
    written in it (or your target university of choice) using conditional formatting,
    and delete the rest of the rows.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 打开电子表格程序中的文件，使用条件格式突出显示包含**哈佛大学**（或你选择的目标大学）的任何行，然后删除其余的行。
- en: Using a text editor
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用文本编辑器
- en: Open the file in a text editor and use **Process Lines Containing** to find
    all lines that have the **Harvard University** phrase (or whatever your university
    of choice is) included, and then copy them to a new file.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 打开文件并使用**包含的行处理**来查找所有包含**哈佛大学**短语（或你选择的大学）的行，然后将它们复制到一个新文件中。
- en: '![Using a text editor](img/image00266.jpeg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![使用文本编辑器](img/image00266.jpeg)'
- en: With either option, the result of this process is a new file with 26 lines in
    it, all of which include **Harvard University** somewhere in the line.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 无论使用哪种选项，结果是一个新文件，包含26行，每行都包含**哈佛大学**。
- en: Transform the lines
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转换行
- en: Right now we have a file with 26 lines, each with multiple universities per
    line (wide data). We anticipate that we will probably be reading the file into
    Python at some point to perform a simple frequency count of universities. So,
    we decide that we want to change this to long data, with one university per line.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个包含26行的文件，每行包含多个大学（宽数据）。我们预计将来某个时候会将文件读入Python，以进行简单的大学频率统计。因此，我们决定将其转换为长数据，每行一个大学。
- en: To transform the file so that there is one university per line, we will use
    a text editor and three instances of find and replace. First, we will find commas
    and replace them with `/r` (carriage return).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将文件转换成每行一个大学，我们将使用文本编辑器和三次查找与替换操作。首先，我们将查找逗号并将其替换为`/r`（回车符）。
- en: '![Transform the lines](img/image00267.jpeg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![转换行](img/image00267.jpeg)'
- en: Next, find instances of the pipe character (`|`) and replace it with `\r`. At
    this point, the text file has 749 lines.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，查找管道字符（`|`）并将其替换为`\r`。此时，文本文件有749行。
- en: Finally, we need to remove all instances of **Harvard University**. (Remember,
    we are only interested in peers who are mentioned with Harvard, so we do not need
    Harvard itself in the count.) In Text Wrangler, we can put **Harvard University\r**
    in the **Find** box and leave the **Replace** box empty. This results in 26 lines
    deleted and a grand total of 723 lines in the file.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要删除所有**哈佛大学**的实例。（记住，我们只关心与哈佛大学一起提到的同行，所以我们不需要计入哈佛大学本身。）在Text Wrangler中，我们可以在**查找**框中输入**Harvard
    University\r**，将**替换**框留空。这样会删除26行，文件中的总行数为723行。
- en: Step four – data analysis
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四步 - 数据分析
- en: 'As our main focus is data cleaning, we will not spend too much time on analysis
    or visualization, but here is a quick Python script to count how many times each
    of these peers are mentioned along with Harvard on some university''s list:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的主要关注点是数据清理，因此我们不会花太多时间在分析或可视化上，但这里有一个简短的Python脚本，用于统计每个同行与哈佛大学一同被提到的次数：
- en: '[PRE6]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The results show 232 unique universities and a count of how many times that
    university was mentioned. Here are the first few results. We can interpret these
    results as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示232所独特的大学，以及每所大学被提到的次数。以下是前几项结果。我们可以这样解读这些结果：
- en: '*When Harvard is mentioned as a peer, Yale was also mentioned 26 times*:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*当哈佛大学作为同行被提到时，耶鲁大学也被提到26次*：'
- en: '[PRE7]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: At this point, you can take the list (or some portion of the longer list) and
    feed it into a bar graph or a word cloud or whatever type of visualization you
    think is persuasive or interesting. As the data is comma-delimited, you could
    even easily paste it into a spreadsheet program for further analysis. But at this
    point, we have answered our initial question about which peers are mentioned most,
    given a target university.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，你可以将这个列表（或较长列表的一部分）输入到条形图、词云或任何你认为有说服力或有趣的可视化工具中。由于数据是以逗号分隔的，你甚至可以轻松地将其粘贴到电子表格程序中进行进一步分析。但到目前为止，我们已经回答了初步问题：给定一个目标大学，哪些同行被提到最多。
- en: Summary
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we learned some very practical tips for data cleaning using
    two easily accessible tools: text editors and spreadsheets. We outlined the available
    spreadsheet functions for splitting data, moving it around, finding and replacing
    parts, formatting it, and then putting it back together. Then, we learned how
    to get the most out of a simple text editor, including some of the built-in functions,
    and how to use find and replace and regular expressions most effectively.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了一些非常实用的数据清理技巧，使用了两个易于获取的工具：文本编辑器和电子表格。我们概述了电子表格中可用的函数，用于拆分数据、移动数据、查找和替换部分内容、格式化数据以及将数据重新组合。接着，我们学习了如何最大限度地发挥简单文本编辑器的作用，包括一些内置功能，以及如何最有效地使用查找和替换及正则表达式。
- en: In the next chapter, we will put together a variety of the techniques we have
    learned so far to perform some significant file conversions. Many of the techniques
    we will use will be based on what we have learned in the past two chapters about
    text editing, regular expressions, data types, and file formats, so get ready
    to solve some real-world data cleaning problems.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将把目前为止学到的各种技巧结合起来，进行一些重要的文件转换。我们将使用的许多技巧将基于我们在过去两章中学到的文本编辑、正则表达式、数据类型和文件格式的知识，因此，准备好解决一些真实世界的数据清理问题吧。
