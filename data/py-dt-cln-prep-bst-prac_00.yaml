- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: 'In today’s fast-paced data-driven world, it’s easy to be dazzled by the headlines
    about **artificial intelligence** (**AI**) breakthroughs and advanced **machine
    learning** (**ML**) models. But ask any seasoned data scientist or engineer, and
    they’ll tell you the same thing: *the true foundation of any successful data project
    is not the flashy algorithms or sophisticated models—it’s the data itself, and
    more importantly, how that data* *is prepared*.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天这个快节奏的数据驱动的世界里，人们容易被**人工智能**（**AI**）突破性进展和先进的**机器学习**（**ML**）模型所吸引。但问问任何经验丰富的数据科学家或工程师，他们都会告诉你同样的事情：*任何成功数据项目的真正基础不是炫目的算法或复杂的模型——而是数据本身，
    更重要的是，如何准备这些数据*。
- en: Throughout my career, I have learned that data preprocessing is the unsung hero
    of data science. It’s the meticulous, often complex process that turns raw data
    into a reliable asset, ready for analysis, modeling, and ultimately, decision-making.
    I’ve seen firsthand how the right preprocessing techniques can transform an organization’s
    approach to data, turning potential challenges into powerful opportunities.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的职业生涯中，我学到数据预处理是数据科学中的默默无闻的英雄。它是一个细致且常常复杂的过程，将原始数据转化为可靠的资产，准备好进行分析、建模，最终用于决策。我亲眼见证了正确的预处理技术如何改变一个组织对数据的处理方式，将潜在的挑战转化为强大的机会。
- en: Yet, despite its importance, data preprocessing is often overlooked or undervalued.
    Many see it as a tedious step, a bottleneck that slows down the exciting work
    of building models and delivering insights. But I’ve always believed that this
    phase is where the most critical work happens. After all, even the most sophisticated
    algorithms can’t make up for poor-quality data. That’s why I’ve dedicated much
    of my professional journey to mastering this art—exploring the best tools, techniques,
    and strategies to make preprocessing more efficient, scalable, and aligned with
    the ever-evolving landscape of AI.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管数据预处理如此重要，它常常被忽视或低估。许多人将其视为一个繁琐的步骤，一个拖慢构建模型和提供洞察力的瓶颈。但我一直认为，这个阶段才是最关键的工作阶段。毕竟，即便是最复杂的算法也无法弥补数据质量差的不足。这就是为什么我将自己大部分的职业生涯都奉献给了掌握这一艺术——探索最佳的工具、技术和策略，使得预处理更加高效、可扩展，并且与不断发展的AI领域保持一致。
- en: This book aims to demystify the data preprocessing process, offering both a
    solid grounding in traditional methods and a forward-looking perspective on emerging
    techniques. We’ll explore how Python can be leveraged to clean, transform, and
    organize data more effectively. We’ll also look at how the advent of **large language
    models** (**LLMs**) is redefining what’s possible in this space. These models
    are already proving to be game changers, automating tasks that were once manual
    and time-consuming, and providing new ways to enhance data quality and usability.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在揭开数据预处理过程的神秘面纱，既提供传统方法的扎实基础，也展望了新兴技术的前景。我们将探讨如何利用Python更有效地清理、转换和组织数据。我们还将关注**大语言模型**（**LLMs**）的出现，如何重新定义这个领域的可能性。这些模型已经证明是改变游戏规则的工具，自动化了曾经需要手工完成且耗时的任务，并提供了提升数据质量和可用性的新方法。
- en: Throughout the pages, I’ll share insights from my experiences, the challenges
    faced, and the lessons learned along the way. My hope is to provide you with not
    just a technical roadmap but also a deeper understanding of the strategic importance
    of data preprocessing in today’s data ecosystem. I strongly believe in the philosophy
    of “learning by doing,” so this book includes a wealth of code examples for you
    to follow along with. I encourage you to try these examples, experiment with the
    code, and challenge yourself to apply the techniques to your own datasets.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的过程中，我将分享我的经验、遇到的挑战和一路上学到的教训。我希望不仅能为你提供一个技术性的路线图，还能让你更深入理解数据预处理在当今数据生态系统中的战略重要性。我坚信“通过实践学习”的理念，因此本书包含了大量的代码示例，供你跟随学习。我鼓励你尝试这些示例，实验代码，并挑战自己将这些技术应用到你自己的数据集中。
- en: By the end of this book, you’ll be equipped with the knowledge and skills to
    approach data preprocessing not just as a necessary step but also as a critical
    component of your overall data strategy.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的结尾，你将具备足够的知识和技能，不仅将数据预处理视为一个必要步骤，而是将其视为你整体数据策略中的一个关键组成部分。
- en: So, whether you’re a data scientist, engineer, analyst, or simply someone looking
    to enhance their understanding of data processes, I invite you to join me on this
    journey. Together, we will explore how to harness the power of data preprocessing
    to unlock the full potential of your data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，无论你是数据科学家、工程师、分析师，还是仅仅希望提升数据处理理解的人，我邀请你与我一起踏上这段旅程。我们将共同探索如何利用数据预处理的力量，释放数据的全部潜力。
- en: Who this book is for
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适用对象
- en: This book is for readers with a working knowledge of Python, a good grasp of
    statistical concepts, and some experience in manipulating data. This book will
    not start from scratch but will rather build on existing skills, introducing you
    to sophisticated preprocessing strategies, hands-on code examples, and practical
    exercises that require a degree of familiarity with the core principles of data
    science and analytics.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本书适合具有Python基础知识、较好掌握统计概念，并有一定数据操作经验的读者。本书不会从零开始，而是建立在现有技能的基础上，向你介绍复杂的预处理策略、实践代码示例和实际练习，要求读者对数据科学和分析的核心原理有一定的熟悉程度。
- en: What this book covers
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容
- en: '[*Chapter 1*](B19801_01.xhtml#_idTextAnchor014), *Data Ingestion Techniques*,
    provides a comprehensive overview of the data ingestion process, emphasizing its
    role in collecting and importing data from various sources into storage systems
    for analysis. You will explore different ingestion methods such as batch and streaming
    modes, compare real-time and semi-real-time ingestion, and understand the technologies
    behind data sources. The chapter highlights the advantages, disadvantages, and
    practical applications of these methods.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第1章*](B19801_01.xhtml#_idTextAnchor014)，*数据摄取技术*，提供了关于数据摄取过程的全面概述，强调了它在从各种来源收集和导入数据到存储系统进行分析中的作用。你将探索不同的摄取方法，如批量模式和流模式，比较实时和半实时数据摄取，并了解数据源背后的技术。本章突出了这些方法的优缺点及其实际应用。'
- en: '[*Chapter 2*](B19801_02.xhtml#_idTextAnchor044), *Importance of Data Quality*,
    emphasizes the critical role data quality plays in business decision-making. It
    highlights the risks of using inaccurate, inconsistent, or outdated data, which
    can lead to poor decisions, damaged reputations, and missed opportunities. You
    will explore why data quality is essential, how to measure it across different
    dimensions, and the impact of data silos on maintaining data quality.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第2章*](B19801_02.xhtml#_idTextAnchor044)，*数据质量的重要性*，强调了数据质量在商业决策中的关键作用。它突出了使用不准确、不一致或过时数据的风险，这可能导致错误的决策、损害声誉和错失机会。你将了解为什么数据质量至关重要，如何在不同维度上衡量数据质量，以及数据孤岛对维持数据质量的影响。'
- en: '[*Chapter 3*](B19801_03.xhtml#_idTextAnchor064), *Data Profiling – Understanding
    Data Structure, Quality, and Distribution*, explores data profiling and focuses
    on scrutinizing and validating datasets to understand their structure, patterns,
    and quality. You will learn how to perform data profiling using tools such as
    the pandas Profiler and Great Expectations and understand when to use each tool.
    Additionally, the chapter covers tactics for handling large data volumes and compares
    profiling methods to improve data validation.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第3章*](B19801_03.xhtml#_idTextAnchor064)，*数据剖析——理解数据结构、质量和分布*，探索了数据剖析，重点审视和验证数据集，以理解其结构、模式和质量。你将学习如何使用工具如pandas
    Profiler和Great Expectations进行数据剖析，并了解何时使用每个工具。此外，本章还涉及了处理大量数据的方法，并比较了不同的剖析方法，以提高数据验证的效果。'
- en: '[*Chapter 4*](B19801_04.xhtml#_idTextAnchor116), *Cleaning Messy Data and Data
    Manipulation*, focuses on the key strategies for cleaning and manipulating data,
    enabling efficient and accurate analysis. It covers techniques for renaming columns,
    removing irrelevant or redundant data, fixing inconsistent data types, and handling
    date and time formats. By mastering these methods, you will learn how to enhance
    the quality and reliability of your datasets.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第4章*](B19801_04.xhtml#_idTextAnchor116)，*清理混乱的数据和数据操作*，重点介绍了清理和操作数据的关键策略，帮助实现高效准确的分析。内容包括重命名列、删除无关或冗余数据、修正不一致的数据类型和处理日期时间格式等技术。掌握这些方法后，你将学会如何提升数据集的质量和可靠性。'
- en: '[*Chapter 5*](B19801_05.xhtml#_idTextAnchor136), *Data Transformation* *–*
    *Merging and Concatenating*, explores techniques for transforming and manipulating
    data through merging, joining, and concatenating datasets. It covers methods to
    combine multiple datasets from various sources, handle duplicates effectively,
    and improve merging performance. The chapter also provides practical tricks to
    streamline the merging process, ensuring efficient data integration for insightful
    analysis.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第五章*](B19801_05.xhtml#_idTextAnchor136)，*数据转换* *–* *合并与连接*，探索了通过合并、连接和拼接数据集来转换和操作数据的技术。它涵盖了从多个来源合并数据集、有效处理重复数据并提高合并性能的方法。本章还提供了一些实用技巧，以简化合并过程，确保数据高效集成，便于洞察分析。'
- en: '[*Chapter 6*](B19801_06.xhtml#_idTextAnchor157), *Data Grouping, Aggregation,
    Filtering, and Applying Functions*, covers the essential techniques of data grouping
    and aggregation, which are vital for summarizing large datasets and generating
    meaningful insights. It discusses methods to handle missing or noisy data by aggregating
    values, reducing data volume, and enhancing processing efficiency. The chapter
    also focuses on grouping data by various keys, applying aggregate and custom functions,
    and filtering data to create valuable features for deeper analysis or ML.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第六章*](B19801_06.xhtml#_idTextAnchor157)，*数据分组、聚合、过滤与应用函数*，涵盖了数据分组和聚合的基本技术，这对于总结大数据集并生成有意义的洞察至关重要。本章讨论了通过聚合值、减少数据量和提高处理效率来处理缺失或噪声数据的方法。它还重点讲解了如何通过不同的键对数据进行分组、应用聚合和自定义函数，以及过滤数据，以创建有价值的特征，供深入分析或机器学习使用。'
- en: '[*Chapter 7*](B19801_07.xhtml#_idTextAnchor175), *Data Sinks*, focuses on the
    critical decisions involved in data processing, particularly the selection of
    appropriate data sinks for storage and processing needs. It delves into four essential
    pillars: choosing the right data sink, selecting the correct file type, optimizing
    partitioning strategies, and understanding how to design a scalable online retail
    data platform. The chapter equips you with the tools to enhance efficiency, scalability,
    and performance in data processing pipelines.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第七章*](B19801_07.xhtml#_idTextAnchor175)，*数据接收端*，聚焦于数据处理中的关键决策，特别是选择适合存储和处理需求的数据接收端。它深入探讨了四个基本要素：选择合适的数据接收端、选择正确的文件类型、优化分区策略，以及理解如何设计一个可扩展的在线零售数据平台。本章为你提供了提高数据处理管道效率、可扩展性和性能的工具。'
- en: '[*Chapter 8*](B19801_08.xhtml#_idTextAnchor195), *Detecting and Handling Missing
    Values and Outliers*, delves into techniques for identifying and managing missing
    values and outliers. It covers a range of methods, from statistical approaches
    to advanced ML models, to address these issues effectively. The key areas of focus
    include detecting and handling missing data, identifying univariate and multivariate
    outliers, and managing outliers in various datasets.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第八章*](B19801_08.xhtml#_idTextAnchor195)，*检测与处理缺失值与异常值*，深入探讨了识别和处理缺失值及异常值的技术。它介绍了从统计方法到先进的机器学习模型的多种方法，以有效解决这些问题。本章的重点领域包括检测和处理缺失数据、识别单变量和多变量异常值，以及管理各种数据集中的异常值。'
- en: '[*Chapter 9*](B19801_09.xhtml#_idTextAnchor213), *Normalization and Standardization*,
    covers essential preprocessing techniques such as feature scaling, normalization,
    and standardization, which ensure that ML models can effectively learn from data.
    You will explore different techniques, including scaling features to a range,
    Z-score scaling, and using a robust scaler, to address various data challenges
    in ML tasks.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第九章*](B19801_09.xhtml#_idTextAnchor213)，*归一化与标准化*，涵盖了诸如特征缩放、归一化和标准化等关键预处理技术，这些技术确保机器学习模型能够有效地从数据中学习。你将探索包括将特征缩放到某个范围、Z-score
    缩放和使用鲁棒缩放器等不同技术，以应对机器学习任务中的各种数据挑战。'
- en: '[*Chapter 10*](B19801_10.xhtml#_idTextAnchor223), *Handling Categorical Features*,
    addresses the importance of managing categorical features, which represent non-numerical
    information in datasets. You will learn various encoding techniques, including
    label encoding, one-hot encoding, target encoding, frequency encoding, and binary
    encoding, to transform categorical data for ML models.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第十章*](B19801_10.xhtml#_idTextAnchor223)，*处理类别特征*，讲解了管理类别特征的重要性，类别特征代表数据集中的非数值信息。你将学习多种编码技术，包括标签编码、一热编码、目标编码、频率编码和二进制编码，以将类别数据转化为机器学习模型可以使用的格式。'
- en: '[*Chapter 11*](B19801_11.xhtml#_idTextAnchor246), *Consuming Time Series Data*,
    delves into the fundamentals of time series analysis, covering key concepts, methodologies,
    and applications across various industries. It includes understanding the components
    and types of time series data, identifying and handling missing values, and techniques
    for analyzing trends and patterns over time. The chapter also addresses dealing
    with outliers and feature engineering to enhance predictive modeling with time
    series data.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第 11 章*](B19801_11.xhtml#_idTextAnchor246)，*时间序列数据分析*，深入探讨了时间序列分析的基础知识，涵盖了各行业中的关键概念、方法论和应用。内容包括理解时间序列数据的组成部分和类型，识别和处理缺失值，以及分析趋势和模式的技术。本章还讲解了如何处理异常值和特征工程，以提高时间序列数据预测建模的效果。'
- en: '[*Chapter 12*](B19801_12.xhtml#_idTextAnchor277), *Text Preprocessing in the
    Era of LLMs*, focuses on mastering text preprocessing techniques that are essential
    for optimizing the performance of LLMs. It covers methods for cleaning text, handling
    rare words and spelling variations, chunking, and tokenization strategies. Additionally,
    it addresses the transformation of tokens into embeddings, highlighting the importance
    of adapting preprocessing approaches to maximize the potential of LLMs.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第 12 章*](B19801_12.xhtml#_idTextAnchor277)，*LLM 时代的文本预处理*，重点介绍了掌握文本预处理技术，这些技术对于优化
    LLMs（大语言模型）的性能至关重要。它涵盖了清洗文本、处理稀有词汇和拼写变化、分块以及分词策略的方法。此外，它还讨论了将词元转换为嵌入向量的过程，强调了调整预处理方法以最大化
    LLMs 潜力的重要性。'
- en: '[*Chapter 13*](B19801_13.xhtml#_idTextAnchor302), *Image and Audio Preprocessing
    with LLMs*, examines preprocessing techniques for unstructured data, particularly
    images and audio, to extract meaningful information. It includes methods for image
    preprocessing, such as **optical character recognition** (**OCR**) and image caption
    generation with the BLIP model. The chapter also explores audio data handling,
    including converting audio to text using the Whisper model, providing a comprehensive
    overview of working with multimedia data in the context of LLMs.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第 13 章*](B19801_13.xhtml#_idTextAnchor302)，*使用 LLMs 进行图像和音频预处理*，探讨了针对非结构化数据，特别是图像和音频的预处理技术，以提取有意义的信息。它包括图像预处理方法，如
    **光学字符识别**（**OCR**）和使用 BLIP 模型生成图像描述。本章还探讨了音频数据处理，包括使用 Whisper 模型将音频转换为文本，全面介绍了在
    LLMs 背景下处理多媒体数据的相关内容。'
- en: To get the most out of this book
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了最大限度地发挥本书的效用
- en: To benefit fully from this book, you should have a good knowledge of Python
    and a grasp of data engineering and data science basics.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用本书的内容，你应该具备良好的 Python 基础，并掌握数据工程和数据科学的基本知识。
- en: '| **Software/hardware covered in** **the book** | **Operating** **system requirements**
    |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| **本书涉及的软件/硬件** | **操作系统要求** |'
- en: '| Python 3 | Windows, macOS, or Linux |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| Python 3 | Windows、macOS 或 Linux |'
- en: '| Visual Studio Code (or your preferred IDE) |  |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| Visual Studio Code（或你首选的 IDE）|  |'
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code from the book’s GitHub repository (a link
    is available in the next section). Doing so will help you avoid any potential
    errors related to the copying and pasting** **of code.**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你使用的是本书的电子版，我们建议你自己输入代码，或者通过书中的 GitHub 仓库访问代码（链接会在下一个章节提供）。这样可以避免复制和粘贴代码时可能出现的错误。**'
- en: The GitHub repository follows the chapters of the book, and all the scripts
    are numbered according to the sections within each chapter. Each script is independent
    of the others, so you can move ahead without having to run all the scripts beforehand.
    However, it is critically recommended to follow the flow of the book so that you
    don’t miss any necessary information.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub 仓库遵循本书的章节结构，所有脚本按照每个章节中的部分进行编号。每个脚本是独立的，因此你可以无需事先运行所有脚本就继续往前进行。然而，强烈建议按照书中的流程进行操作，以确保你不会遗漏任何必要的信息。
- en: Download the example code files
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices).
    If there’s an update to the code, it will be updated in the GitHub repository.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从 GitHub 上下载本书的示例代码文件，链接为 [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices)。如果代码有更新，GitHub
    仓库会同步更新。
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的丰富图书和视频目录中还有其他代码包，您可以访问[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)查看。
- en: Conventions used
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了多种文本约定。
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “The delete_entry() function is used to remove an
    entry, showing how data can be deleted from the store”'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`文本中的代码`：表示文本中的代码字、数据库表名、文件夹名称、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 用户名。示例：“delete_entry()
    函数用于删除条目，展示了如何从存储中删除数据”'
- en: 'A block of code is set as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望您注意代码块中的某个特定部分时，相关的行或项目会使用粗体显示：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出如下所示：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For instance, words in menus or dialog boxes appear in **bold**. Here is an example:
    “It involves storing data on remote servers accessed from anywhere via the internet,
    **rather than on** **local devices**”'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要单词或您在屏幕上看到的词。例如，菜单或对话框中的单词以**粗体**显示。示例：“它涉及将数据存储在远程服务器上，可以通过互联网从任何地方访问，而**不是在**
    **本地设备**上”'
- en: Tips or important notes
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 提示或重要注意事项
- en: Appear like this.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如此显示。
- en: Get in touch
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保持联系
- en: Feedback from our readers is always welcome.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：如果您对本书的任何方面有疑问，请通过电子邮件联系我们：[customercare@packtpub.com](mailto:customercare@packtpub.com)，并在邮件主题中注明书名。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已尽力确保内容的准确性，但错误仍然会发生。如果您在本书中发现错误，我们将非常感激您向我们报告。请访问[www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)并填写表单。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上发现我们的作品的非法复制版本，我们将非常感激您提供该位置地址或网站名称。请通过[版权@packt.com](mailto:copyright@packt.com)与我们联系，并附上该材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个领域有专业知识，并且有兴趣写书或为书籍做贡献，请访问[authors.packtpub.com](http://authors.packtpub.com)。'
- en: Share your thoughts
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分享您的想法
- en: Once you’ve read *Python Data Cleaning and Preparation Best Practices*, we’d
    love to hear your thoughts! Please [click here to go straight to the Amazon review
    page](https://packt.link/r/1-837-63474-2) for this book and share your feedback.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您阅读完《Python 数据清理与准备最佳实践》，我们很想听听您的想法！请[点击此处直接进入 Amazon 书评页面](https://packt.link/r/1-837-63474-2)并分享您的反馈。
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您的书评对我们和技术社区都非常重要，将帮助我们确保提供优质内容。
- en: Download a free PDF copy of this book
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载本书的免费 PDF 版本
- en: Thanks for purchasing this book!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您购买本书！
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 您是否喜欢在旅途中阅读，但又无法随身携带纸质书籍？
- en: Is your eBook purchase not compatible with the device of your choice?
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 你的电子书购买是否与所选设备不兼容？
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心，现在每本 Packt 书籍都会附带该书的 DRM-free PDF 版本，免费提供。
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何地方、任何设备上阅读。搜索、复制并粘贴你最喜欢的技术书籍中的代码，直接应用到你的应用程序中。
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 优惠不仅仅如此，你还可以获得独家折扣、时事通讯和每天发送到你邮箱的精彩免费内容
- en: 'Follow these simple steps to get the benefits:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这些简单的步骤即可享受福利：
- en: Scan the QR code or visit the link below
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扫描二维码或访问下面的链接
- en: '![](img/B19801_QR_Free_PDF.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19801_QR_Free_PDF.jpg)'
- en: '[https://packt.link/free-ebook/9781837634743](https://packt.link/free-ebook/9781837634743)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/free-ebook/9781837634743](https://packt.link/free-ebook/9781837634743)'
- en: 2. Submit your proof of purchase
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 提交你的购买证明
- en: 3. That’s it! We’ll send your free PDF and other benefits to your email directly
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 就是这样！我们会直接将免费的PDF和其他福利发送到你的邮箱
- en: 'Part 1: Upstream Data Ingestion and Cleaning'
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一部分：上游数据摄取与清理
- en: This part focuses on the foundational stages of data processing, starting from
    data ingestion to ensuring its quality and structure for downstream tasks. It
    guides readers through the essential steps of importing, cleaning, and transforming
    data, which lay the groundwork for effective data analysis. The chapters explore
    various methods for ingesting data, maintaining high-quality datasets, profiling
    data for better insights, and cleaning messy data to make it ready for analysis.
    Further, it covers advanced techniques like merging, concatenating, grouping,
    and filtering data, along with choosing appropriate data destinations or sinks
    to optimize processing pipelines. Each chapter in this part equips readers with
    the knowledge to handle raw data and turn it into a clean, structured, and usable
    form.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分聚焦于数据处理的基础阶段，从数据摄取开始，确保数据的质量和结构，以便于后续任务的处理。它指导读者完成导入、清理和转换数据的关键步骤，为有效的数据分析奠定基础。章节内容涵盖了多种数据摄取方法、如何保持高质量的数据集、如何进行数据剖析以获得更好的见解，并且如何清理杂乱数据以使其准备好进行分析。此外，还涉及了如合并、连接、分组和过滤数据等高级技术，同时介绍了如何选择合适的数据接收端或存储地，以优化处理管道。本部分的每个章节都为读者提供了处理原始数据、将其转化为干净、结构化且可用形式的知识。
- en: 'This part has the following chapters:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 1*](B19801_01.xhtml#_idTextAnchor014)*, Data Ingestion Techniques*'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第1章*](B19801_01.xhtml#_idTextAnchor014)*，数据摄取技术*'
- en: '[*Chapter 2*](B19801_02.xhtml#_idTextAnchor044)*, Importance of Data Quality*'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第2章*](B19801_02.xhtml#_idTextAnchor044)*，数据质量的重要性*'
- en: '[*Chapter 3*](B19801_03.xhtml#_idTextAnchor064)*, Data Profiling* *–* *Understanding
    Data Structure, Quality, and Distribution*'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第3章*](B19801_03.xhtml#_idTextAnchor064)*，数据剖析* *–* *理解数据结构、质量和分布*'
- en: '[*Chapter 4*](B19801_04.xhtml#_idTextAnchor116)*, Cleaning Messy Data and Data
    Manipulation*'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第4章*](B19801_04.xhtml#_idTextAnchor116)*，清理杂乱数据与数据操作*'
- en: '[*Chapter 5*](B19801_05.xhtml#_idTextAnchor136)*, Data Transformation* *–*
    *Merging and Concatenating*'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B19801_05.xhtml#_idTextAnchor136)*，数据转换* *–* *合并与连接*'
- en: '[*Chapter 6*](B19801_06.xhtml#_idTextAnchor157)*, Data Grouping, Aggregation,
    Filtering, and Applying Functions*'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B19801_06.xhtml#_idTextAnchor157)*，数据分组、聚合、过滤与应用函数*'
- en: '[*Chapter 7*](B19801_07.xhtml#_idTextAnchor175)*, Data Sinks*'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B19801_07.xhtml#_idTextAnchor175)*，数据接收端*'
