- en: Pain Points of Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络的痛点
- en: 'In this chapter, the following recipes will be covered:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将介绍以下内容：
- en: 'Pain Point #1: Importing MNIST images'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 痛点＃1：导入MNIST图像
- en: 'Pain Point #2: Visualizing MNIST images'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 痛点＃2：可视化MNIST图像
- en: 'Pain Point #3: Exporting MNIST images as files'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 痛点＃3：将MNIST图像导出为文件
- en: 'Pain Point #4: Augmenting MNIST images'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 痛点＃4：增强MNIST图像
- en: 'Pain Point #5: Utilizing alternate sources for trained images'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 痛点＃5：利用训练图像的替代来源
- en: 'Pain Point #6: Prioritizing high-level libraries for CNNs'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 痛点＃6：优先考虑用于CNN的高级库
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '**Convolutional neural networks** (**CNNs**) have been enjoying a bit of resurgence
    in the last couple of years. They have shown great success when it comes to image
    recognition. This is quite relevant these days with the advent of modern smartphones
    as anyone now has the ability to take large volumes of pictures of objects and
    post them on social media sites. Just due to this phenomenon, convolutional neural
    networks are in high demand these days.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNN**）在过去几年中一直备受关注。在图像识别方面取得了巨大成功。随着现代智能手机的出现，任何人现在都有能力拍摄大量物体的照片并将其发布在社交媒体网站上，这在当今时代非常相关。正是由于这种现象，卷积神经网络如今需求量很大。'
- en: 'There are several features that make a CNN optimally perform. They require
    the following features:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个特性使CNN能够最佳地执行。它们需要以下特性：
- en: A high volume of training data
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大量的训练数据
- en: Visual and spatial data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视觉和空间数据
- en: An emphasis on filtering (pooling), activation, and convoluting as opposed to
    a fully connected layer that is more apparent in a traditional neural network
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强调过滤（池化）、激活和卷积，而不是传统神经网络中更明显的全连接层
- en: While CNNs have gained great popularity, there are some limitations in working
    with them primarily due to their computational needs as well as the volume of
    training data required to get a well-performing model. We will focus on techniques
    that can be applied to the data that will ultimately assist with the development
    of a convolutional neural network while addressing these limitations. In later
    chapters, we will apply some of these techniques when we develop models for image
    classification.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然CNN已经广受欢迎，但由于其计算需求以及需要大量训练数据来获得性能良好的模型，它们在使用中存在一些局限性。我们将专注于可以应用于数据的技术，这些技术最终将有助于开发卷积神经网络，并解决这些局限性。在后面的章节中，当我们为图像分类开发模型时，我们将应用其中一些技术。
- en: 'Pain Point #1: Importing MNIST images'
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 痛点＃1：导入MNIST图像
- en: 'One of the most common datasets used for image classification is the `MNIST` dataset,
    which is composed of thousands of samples of handwritten digits. The **Modified
    National Institute of Standards and Technology** (**MNIST**) is, according to
    Yann LeCun, Corinna Cortes, and Christopher J.C. Burges, useful for the following
    reasons:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 用于图像分类的最常见数据集之一是`MNIST`数据集，它由成千上万个手写数字样本组成。根据Yann LeCun、Corinna Cortes和Christopher
    J.C. Burges的说法，**修改后的国家标准与技术研究所**（**MNIST**）有以下用途：
- en: It is a good database for people who want to try learning techniques and pattern
    recognition methods on real-world data while spending minimal efforts on preprocessing
    and formatting.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个适合想要尝试在真实世界数据上学习技术和模式识别方法的人的良好数据库，同时在预处理和格式化上花费最少的精力。
- en: 'There are several methods to import the MNIST images into our Jupyter notebook.
    We will cover the following two methods in this chapter:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的Jupyter笔记本中导入MNIST图像有几种方法。在本章中，我们将介绍以下两种方法：
- en: Directly through the TensorFlow library
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接通过TensorFlow库
- en: Manually through the MNIST website
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过MNIST网站手动操作
- en: One thing to note is that we will be primarily using MNIST images as our example
    of how to improve performance within a convolutional neural network. All of these
    techniques that will be applied on MNIST images can be applied to any image that
    will be used to train a CNN.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，我们将主要使用MNIST图像作为我们如何改进卷积神经网络性能的示例。所有这些将应用于MNIST图像的技术都可以应用于用于训练CNN的任何图像。
- en: Getting ready
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The only requirement needed is to install `TensorFlow`. It will likely not
    come pre-installed with the anaconda3 packages; therefore, a simple `pip` install
    will either confirm the availability of `TensorFlow` or install it if not currently
    available. `TensorFlow` can be easily installed in the Terminal, as seen in the
    following screenshot:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一需要的要求是安装`TensorFlow`。它可能不会预先安装在anaconda3软件包中；因此，简单的`pip`安装将确认`TensorFlow`的可用性，或者如果当前不可用，则安装它。`TensorFlow`可以在终端中轻松安装，如下截图所示：
- en: '![](img/00077.jpeg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00077.jpeg)'
- en: How to do it...
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: The `TensorFlow` library has a conveniently built-in set of examples that can
    be used directly. One of those example datasets is `MNIST`. This section will
    walk through the steps of accessing those images.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`TensorFlow`库中有一个方便的内置示例集，可以直接使用。其中一个示例数据集就是`MNIST`。本节将介绍访问这些图像的步骤。'
- en: 'Import `TensorFlow` into the library with an alias of `tf` using the following
    script:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将`TensorFlow`导入库，并使用别名`tf`：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Download and extract images from the library and save to a local folder using
    the following script:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本从库中下载和提取图像，并保存到本地文件夹：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Retrieve a final count of the training and testing datasets that will be used
    to evaluate the accuracy of the image classification using the following script:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本检索将用于评估图像分类准确性的训练和测试数据集的最终计数：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: How it works...
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'This section explains the process used to access the MNIST datasets:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了访问MNIST数据集的过程：
- en: Once we receive a confirmation that the `TensorFlow` library has been properly
    installed, it is imported into the notebook.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们收到确认`TensorFlow`库已正确安装，就将其导入笔记本。
- en: 'We can confirm the version of `TensorFlow` as well as extract the images to
    our local folder of `MNIST/`. The extraction process is visible in the output
    of the notebook, as seen in the following screenshot:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以确认`TensorFlow`的版本，并将图像提取到我们的`MNIST/`本地文件夹中。提取过程可在笔记本的输出中看到，如下截图所示：
- en: '![](img/00078.jpeg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00078.jpeg)'
- en: 'The four extracted files are named the following:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取的四个文件分别命名为：
- en: '`t10k-images-idx3-ubyte.gz`'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`t10k-images-idx3-ubyte.gz`'
- en: '`t10k-labels-idx1-ubyte.gz`'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`t10k-labels-idx1-ubyte.gz`'
- en: '`train-images-idx3-ubyte.gz`'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`train-images-idx3-ubyte.gz`'
- en: '`train-labels-idx1-ubyte.gz`'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`train-labels-idx1-ubyte.gz`'
- en: 'They have been downloaded to the `MNIST/` subfolder as seen in the following
    screenshot:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们已经下载到`MNIST/`子文件夹中，如下截图所示：
- en: '![](img/00079.jpeg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00079.jpeg)'
- en: 'In addition, the four files can be viewed in our notebook, as seen in the following
    screenshot:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，可以在我们的笔记本中查看这四个文件，如下截图所示：
- en: '![](img/00080.jpeg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00080.jpeg)'
- en: The four files are the testing and training images along with the accompanying
    testing and training labels identifying each image in the testing and training
    datasets. Additionally, the `one_hot = True` feature is explicitly defined. This indicates
    that one-hot encoding is active with the labels, which assists with feature selection
    within modeling as each column value will be either 0 or 1.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '这四个文件是测试和训练图像以及相应的测试和训练标签，用于识别测试和训练数据集中的每个图像。此外，明确定义了`one_hot = True`特性。这表明标签使用one-hot编码，有助于模型中的特征选择，因为每列的值将是0或1。 '
- en: 'A subclass of the library is also imported that stores the handwritten images
    of MNIST to the specified local folder. The folder containing all of the images
    should be approximately 12 MB in size for 55,000 training images and 10,000 testing
    images, as seen in the following screenshot:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还导入了库的一个子类，它将MNIST的手写图像存储到指定的本地文件夹中。包含所有图像的文件夹应该大约为12MB，包括55,000张训练图像和10,000张测试图像，如下截图所示：
- en: '![](img/00081.jpeg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00081.jpeg)'
- en: The 10,000 images will be used to test the accuracy of our model that will be
    trained on the 55,000 images.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这10,000张图像将用于测试我们将在55,000张图像上训练的模型的准确性。
- en: There's more...
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Occasionally, there may be errors or warnings when trying to access the MNIST
    datasets directly through `TensorFlow`. As was seen earlier on in the section,
    we received the following warning when importing MNIST:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试通过`TensorFlow`直接访问MNIST数据集时，有时可能会出现错误或警告。就像在本节前面看到的那样，当导入MNIST时，我们收到了以下警告：
- en: 'WARNING:tensorflow:From <ipython-input-3-ceaef6f48460>:2: read_data_sets (from
    tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be
    removed in a future version.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：从<ipython-input-3-ceaef6f48460>:2读取数据集（来自tensorflow.contrib.learn.python.learn.datasets.mnist）已被弃用，并将在将来的版本中删除。
- en: 'Instructions for updating:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 更新说明：
- en: Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 请使用替代方案，例如来自tensorflow/models的official/mnist/dataset.py。
- en: 'The dataset may become deprecated in a future release of `TensorFlow` and therefore,
    no longer be directly accessible. Sometimes we may just encounter a typical *HTTP 403
    error* when extracting the MNIST images through `TensorFlow`. This may be due
    to the website being temporarily unavailable. Have no fear in either case, there
    is a manual approach to downloading the four `.gz` files using the following link:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可能会在未来的`TensorFlow`版本中被弃用，因此不再直接可访问。有时，当通过`TensorFlow`提取MNIST图像时，我们可能会遇到典型的*HTTP
    403错误*。这可能是因为网站暂时不可用。无论哪种情况，都有一种手动方法可以使用以下链接下载这四个`.gz`文件：
- en: '[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
- en: 'The files are located on the website, as seen in the following screenshot:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这些文件位于网站上，如下截图所示：
- en: '![](img/00082.jpeg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00082.jpeg)'
- en: Download the files and save them to an accessible local folder similar to what
    was done with the files that came directly from `TensorFlow`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下载这些文件并将它们保存到一个可访问的本地文件夹，类似于直接从`TensorFlow`获取的文件所做的操作。
- en: See also
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: To learn more about the `MNIST` database of handwritten digits, visit the following
    website: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`MNIST`手写数字数据库的信息，请访问以下网站：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)。
- en: To learn more about one-hot encoding, visit the following website: [https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f.](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于one-hot编码的信息，请访问以下网站：[https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f.](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)
- en: 'Pain Point #2: Visualizing MNIST images'
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 痛点＃2：可视化MNIST图像
- en: Plotting images is often a major pain point when dealing with graphics within
    a Jupyter notebook. Displaying the handwritten images from the training dataset
    is critical, especially when comparing the actual value of the label that is associated
    with the handwritten image.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在Jupyter笔记本中处理图形时，绘制图像通常是一个主要的痛点。显示训练数据集中的手写图像至关重要，特别是当比较与手写图像相关联的标签的实际值时。
- en: Getting ready
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The only Python libraries that will be imported to visualize the handwritten
    images are `numpy` and `matplotlib`. Both should already be available through
    the packages in Anaconda. If for some reason they are not available, they can
    both be `pip` installed at the Terminal using the following commands:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 用于可视化手写图像的唯一Python库是`numpy`和`matplotlib`。这两个库应该已经通过Anaconda中的软件包可用。如果由于某种原因它们不可用，可以在终端使用以下命令进行`pip`安装：
- en: '`pip install matplotlib`'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip install matplotlib`'
- en: '`pip install numpy`'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip install numpy`'
- en: How to do it...
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'This section will walk through the steps to visualize the MNIST handwritten
    images in a Jupyter notebook:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍在Jupyter笔记本中可视化MNIST手写图像的步骤：
- en: 'Import the following libraries, `numpy` and `matplotlib`, and configure `matplotlib`
    to plot `inline` using the following script:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下库，`numpy`和`matplotlib`，并使用以下脚本配置`matplotlib`以进行`inline`绘图：
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Plot the first two sample images using the following script:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本绘制前两个样本图像：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: How it works...
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'This section will walk through the process of how the MNIST handwritten images
    are viewed in a Jupyter notebook:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍在Jupyter笔记本中查看MNIST手写图像的过程：
- en: A loop is generated in Python that will sample two images from the training
    dataset.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Python中生成一个循环，从训练数据集中取样两幅图像。
- en: 'Initially, the images are just a series of values in float format between 0
    and 1 that are stored in a `numpy` array. The value of the array is a labeled
    image called `image`. The `image` array is then reshaped into a 28 x 28 matrix
    called `pixels` that has a black color for any value at 0 and a gray shade color
    for any color that is not 0\. The higher the value, the lighter the gray shade
    of color. An example can be seen in the following screenshot for the digit 8:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最初，图像只是存储在`numpy`数组中的0到1之间的浮点格式的一系列值。数组的值是一个名为`image`的标记图像。然后将`image`数组重塑为一个名为`pixels`的28
    x 28矩阵，其中0处为黑色，非0处为灰色。值越高，灰色越浅。例如，可以在以下截图中看到数字8的示例：
- en: '![](img/00083.jpeg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00083.jpeg)'
- en: 'The output of the loop produces two handwritten images for the numbers 7 and
    3 along with their labels, as seen in the following screenshot:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 循环的输出产生了数字7和3的两幅手写图像以及它们的标签，如下截图所示：
- en: '![](img/00084.jpeg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00084.jpeg)'
- en: In addition to the images being plotted, the label from the training dataset
    is also printed above the image. The label is an array of length 10, with values
    of 0 or 1 only for all 10 digits. For digit 7, the 8th element in the array is
    of value 1 and for digit 3, the 4th element in the array is of value 1\. All other
    values are 0.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了绘制图像外，还会在图像上方打印训练数据集的标签。标签是一个长度为10的数组，对于所有10个数字，只有0或1的值。对于数字7，数组中的第8个元素的值为1，对于数字3，数组中的第4个元素的值为1。所有其他值都为0。
- en: There's more...
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: It may not be immediately obvious what the numeric value of the image is. While
    most will be able to identify that the first image is a 7 and the second image
    is a 3, it would be helpful to have confirmation from the label array.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图像的数值可能不会立即显而易见。虽然大多数人能够确定第一幅图像是7，第二幅图像是3，但从标签数组中获得确认会更有帮助。
- en: There are 10 elements in the array, each referencing a value for labels 0 through
    9 in numeric order. Since the first array has a positive or 1 value in the 8th
    slot, that is an indication that the value of the image is a 7, as 7 in the 8th
    index in the array. All other values should be 0\. Additionally, the second image
    has a value of 1 in the 4th spot, indicating a positive value for 3.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 数组中有10个元素，每个元素引用数字0到9的标签值。由于第一个数组在第8个位置有一个正值或1，这表明图像的值是7，因为7在数组的第8个索引中。所有其他值应为0。此外，第二幅图像在第4个位置有一个值为1，表示3的正值。
- en: See also
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'Leun, Cortes, and Burges discuss why the image pixelations were set at 28 x
    28 in the following statement:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Leun、Cortes和Burges在以下声明中讨论了为什么图像像素设置为28 x 28：
- en: he original black and white (bilevel) images from NIST were size normalized
    to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting
    images contain grey levels as a result of the anti-aliasing technique used by
    the normalization algorithm. The images were centered in a 28x28 image by computing
    the center of mass of the pixels, and translating the image so as to position
    this point at the center of the 28x28 field.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: NIST的原始黑白（双色）图像被尺寸标准化以适应20x20像素的框，同时保持其纵横比。由于标准化算法使用的抗锯齿技术，生成的图像包含灰度级。通过计算像素的质心，并将图像平移到使该点位于28x28区域的中心，将图像置于28x28图像中心。
- en: --Leun, Cortes, and Burges from [http://yann.lecun.com/exdb/mnist/.](http://yann.lecun.com/exdb/mnist/)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: --来自[http://yann.lecun.com/exdb/mnist/.](http://yann.lecun.com/exdb/mnist/)的Leun、Cortes和Burges
- en: 'Pain Point #3: Exporting MNIST images as files'
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 痛点＃3：将MNIST图像导出为文件
- en: We often need to work within the image directly and not as an array vector.
    This section will guide us through converting our arrays to `.png` images.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常需要直接在图像中工作，而不是作为数组向量。本节将指导我们将数组转换为`.png`图像。
- en: Getting ready
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Exporting the vectors to images requires importing the following library:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 将向图像导出向量需要导入以下库：
- en: '`import image from matplotlib`'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`从matplotlib导入图像`'
- en: How to do it...
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: This section walks through the steps to convert a sample of MNIST arrays to
    files in a local folder.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍将MNIST数组样本转换为本地文件的步骤。
- en: 'Create a subfolder to save our images to our main folder of `MNIST/` using
    the following script:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个子文件夹，将我们的图像保存到我们的主文件夹`MNIST/`中，使用以下脚本：
- en: '[PRE5]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Loop through the first 10 samples of MNIST arrays and convert them to `.png`
    files using the following script:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 循环遍历MNIST数组的前10个样本，并使用以下脚本将它们转换为`.png`文件：
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Execute the following script to see the list of images from `image_no_1.png` to `image_no_9.png`:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本以查看从`image_no_1.png`到`image_no_9.png`的图像列表：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: How it works...
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains how the MNIST arrays are converted to images and saved
    to a local folder.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了如何将MNIST数组转换为图像并保存到本地文件夹中。
- en: We create a subfolder called `MNIST/images` to help us store our temporary `.png`
    images and separate them from the MNIST arrays and labels.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个名为`MNIST/images`的子文件夹，以帮助我们存储临时的`.png`图像，并将它们与MNIST数组和标签分开。
- en: Once again we loop through `data.train` images and obtain nine arrays that can
    be used for sampling. The images are then saved as `.png` files to our local directory
    with the following format: `'image_no_{}.png'.format(i), pixels, cmap = 'gray'`
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次循环遍历`data.train`图像，并获得可以用于取样的九个数组。然后将图像保存为`.png`文件到我们的本地目录，格式如下：`'image_no_{}.png'.format(i),
    pixels, cmap = 'gray'`
- en: 'The output of the nine images can be seen in our local directory, as seen in
    the following screenshot:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以在本地目录中看到九个图像的输出，如下截图所示：
- en: '![](img/00085.jpeg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00085.jpeg)'
- en: There's more...
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'In addition to seeing the list of images in our directory, we can also view
    the image in our directory within Linux, as seen in the following screenshot:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 除了查看目录中的图像列表外，我们还可以在Linux中查看目录中的图像，如下截图所示：
- en: '![](img/00086.jpeg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00086.jpeg)'
- en: See also
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about `image.imsave` from `matplotlib` visit the following website:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关`matplotlib`中`image.imsave`的更多信息，请访问以下网站：
- en: '[https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imsave.html](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imsave.html)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://matplotlib.org/api/_as-gen/matplotlib.pyplot.imsave.html](https://matplotlib.org/api/_as-gen/matplotlib.pyplot.imsave.html)'
- en: 'Pain Point #4: Augmenting MNIST images'
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 痛点＃4：增强MNIST图像
- en: One of the main drawbacks of working with image recognition is the lack of variety
    in some of the images available. This may cause the convolutional neural network
    to not operate as optimally as we would like, and return less than ideal results
    due to the lack of variety in the training data. There are techniques available
    to bypass that shortcoming and we discuss one of them in this section.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理图像识别时的主要缺点之一是某些图像的变化不够多样化。这可能导致卷积神经网络的运行不如我们希望的那样理想，并且由于训练数据的缺乏多样性而返回不理想的结果。有一些技术可用于规避这一缺点，我们将在本节中讨论其中一种。
- en: Getting ready
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Once again much of the heavy lifting is already done for us. We will use a popular
    Python package, `augmentor`, that is frequently used with machine learning and
    deep learning modeling to generate additional versions of existing images distorted
    and augmented for variety.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们已经为我们做了大部分繁重的工作。我们将使用一个流行的Python包`augmentor`，它经常与机器学习和深度学习建模一起使用，以生成现有图像的额外版本，经过扭曲和增强以获得更多的变化。
- en: 'The package will first have to be `pip` installed using the following script:
    `pip install augmentor`'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 首先必须使用以下脚本进行`pip`安装：`pip install augmentor`
- en: 'We should then have confirmation that the package is installed, as seen in
    the following screenshot:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们应该得到确认该包已安装，如下截图所示：
- en: '![](img/00087.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00087.jpeg)'
- en: 'We will then need to import the pipeline class from augmentor:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们需要从augmentor中导入pipeline类：
- en: '`from Augmentor import Pipeline`'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from Augmentor import Pipeline`'
- en: How to do it...
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: This section walks through the steps to increase the frequency and augmentation
    of our nine sample images.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了增加我们九个样本图像的频率和增强的步骤。
- en: 'Initialize the `augmentor` function using the following script:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本初始化`augmentor`函数：
- en: '[PRE8]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Execute the following script so that the `augmentor` function can `rotate`
    our images with the following specifications:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，以便`augmentor`函数可以根据以下规格`旋转`我们的图像：
- en: '[PRE9]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Execute the following script so that each image is augmented through two iterations
    10 times each:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，使每个图像通过两次迭代，每次迭代10次增强：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: How it works...
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: This section explains how our nine images are used to create additional images
    that are distorted.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了如何使用我们的九个图像创建额外的扭曲图像。
- en: 'We need to create a `Pipeline` for our image transformation and specify the
    location of the images that will be used.  This ensures the following:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要为图像变换创建一个`Pipeline`并指定将要使用的图像的位置。这确保了以下内容：
- en: The source location of the images
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像的源位置
- en: The number of images that will be transformed
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将要转换的图像数量
- en: The destination location of the images
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像的目标位置
- en: 'We can see that our destination location is created with a subfolder called
    `/output/` as seen in the following screenshot:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到我们的目标位置已创建一个名为`/output/`的子文件夹，如下截图所示：
- en: '![](img/00088.jpeg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00088.jpeg)'
- en: The `augmentor` function is configured to rotate each image up to 25 degrees
    to the right or 25 degrees to the left with a 90 percent probability. Basically,
    the probability configuration determines how often an augmentation takes place.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`augmentor`函数被配置为将每个图像向右旋转25度或向左旋转25度，概率为90%。基本上，概率配置确定增强发生的频率。'
- en: 'A loop is created to go through each image twice and apply two transformations
    to each image; however, since we did add a probability to each transformation
    some images may not get transformed and others may get transformed more than twice.
    Once the transformations are complete, we should get a message indicating so,
    as seen in the following screenshot:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个循环，对每个图像进行两次遍历，并对每个图像应用两次变换；但是，由于我们对每个变换都添加了概率，因此有些图像可能不会被转换，而其他图像可能会被转换超过两次。变换完成后，我们应该收到一条消息，如下截图所示：
- en: '![](img/00089.jpeg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00089.jpeg)'
- en: 'Once we have the augmentations complete, we can visit the `/output/` subdirectory
    and see how each digit is slightly altered, as seen in the following screenshot:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们完成增强，我们可以访问`/output/`子目录，并查看每个数字如何略有改变，如下截图所示：
- en: '![](img/00090.jpeg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00090.jpeg)'
- en: We can see that we have several variations of the digits 3, 1, 8, 0, and 9 all
    with varying degrees of rotation. We now have tripled our sample data set and
    added more variety without having to go out and extract more images for training
    and testing purposes.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到我们有几个数字3、1、8、0和9的变化，都有不同程度的旋转。现在我们已经将样本数据集增加了三倍，并且增加了更多的变化，而不必去提取更多的图像进行训练和测试。
- en: There's more...
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'We only applied the `rotate` transformation; however, there are several transformation
    and augmentation features available to apply to images:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只应用了`rotate`变换；但是，还有几种变换和增强功能可用于图像：
- en: Perspective skewing
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 透视扭曲
- en: Elastic distortions
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弹性变形
- en: Shearing
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剪切
- en: Cropping
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 裁剪
- en: Mirroring
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 镜像
- en: While not all of these transformations will be necessary when looking to increase
    frequency and variety of a training dataset, it may be beneficial to use some
    combination of features and evaluate model performance.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 当寻求增加训练数据集的频率和多样性时，并非所有这些转换都是必要的，但使用一些特征的组合并评估模型性能可能是有益的。
- en: See also
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about `augmentor` visit the following website:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`augmentor`的信息，请访问以下网站：
- en: '[https://augmentor.readthedocs.io/en/master/](https://augmentor.readthedocs.io/en/master/)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://augmentor.readthedocs.io/en/master/](https://augmentor.readthedocs.io/en/master/)'
- en: 'Pain Point #5: Utilizing alternate sources for trained images'
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 痛点＃5：利用训练图像的替代来源
- en: Sometimes there are just not enough resources available to perform a convolutional
    neural network. The resources could be limited from a computational perspective
    or a data collection perspective. In situations like these, we rely on other sources
    to help us with classifying our images.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，没有足够的资源来执行卷积神经网络。这些资源可能来自计算的角度或数据收集的角度。在这种情况下，我们依赖其他来源来帮助我们对图像进行分类。
- en: Getting ready
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The technique for utilizing pre-trained models as the source for testing outcomes
    on other datasets is referred to as transfer learning. The advantage here is that
    much of the CPU resources allotted for training images is outsourced to a pre-trained
    model. Transfer learning has become a common extension of deep learning more recently.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 利用预训练模型作为其他数据集上测试结果的来源的技术称为迁移学习。这里的优势在于，用于训练图像的大部分CPU资源被外包给了预训练模型。迁移学习最近已成为深度学习的常见扩展。
- en: How to do it...
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: This section explains how the process of transfer learning works.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了迁移学习的工作过程。
- en: Collect a series of datasets or images that you are interested in classifying, just
    as you would with traditional machine learning or deep learning.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集一系列数据集或图像，您有兴趣对其进行分类，就像您对传统机器学习或深度学习一样。
- en: Split the dataset into a training and testing split such as 75/25 or 80/20.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集分割为训练和测试集，例如75/25或80/20。
- en: Identify a pre-trained model that will be used to identify the patterns and
    recognition of the images you are looking to classify.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定将用于识别图像模式和识别您希望分类的图像的预训练模型。
- en: Build a deep learning pipeline that connects the training data to the pre-trained
    model and develops the weights and parameters needed to identify the test data.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个深度学习管道，将训练数据连接到预训练模型，并开发识别测试数据所需的权重和参数。
- en: Finally, evaluate the model performance on the test data.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在测试数据上评估模型性能。
- en: How it works...
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains the process of transfer learning when applied to the MNIST
    dataset.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了将迁移学习应用于MNIST数据集的过程。
- en: We are definitely taking a shortcut approach with transfer learning as we are
    either limited in resources, time, or both as we are taking prior work that has
    already been done and hoping that it will help us solve something new.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在使用迁移学习时确实采取了一种捷径的方法，因为我们要么在资源、时间或两者方面受到限制，我们正在利用已经完成的先前工作，并希望它能帮助我们解决一些新问题。
- en: 'Since we are dealing with an image classification problem, we should use a
    pre-trained model that has worked with classifying common images in the past.
    There are many common ones out there but two that stand out are:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们正在处理图像分类问题，因此应使用曾经用于分类常见图像的预训练模型。有许多常见的模型，但其中两个突出的是：
- en: The ResNet model developed at Microsoft.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由微软开发的ResNet模型。
- en: The Inception model developed at Google.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 谷歌开发的Inception模型。
- en: Both models are useful for image classification because both Microsoft and Google
    have a wide spectrum of images that are available to them to train a robust model
    that can extract features at a more detailed level.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于微软和谷歌都拥有广泛的图像库，因此两种模型都对图像分类非常有用，可以在更详细的层面提取特征。
- en: Directly within Spark, there is the ability to build a deep learning pipeline
    and to call about a class called `DeepImageFeaturizer` and apply the `InceptionV3`
    model to a set of features collected from training data. The trained dataset is
    then evaluated on the testing data using some type of binary or multiclassification
    evaluator.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Spark中，有能力构建深度学习管道，并调用一个名为`DeepImageFeaturizer`的类，并将`InceptionV3`模型应用于从训练数据中收集的一组特征。然后使用某种二元或多分类评估器在测试数据上评估训练数据集。
- en: A pipeline within deep learning or machine learning is simply the workflow process
    used to get from an initial environment of data collection to a final evaluation
    or classification environment on the collected data by applying a model.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 深度学习或机器学习中的管道只是用于从数据收集的初始环境到应用模型对收集的数据进行最终评估或分类的工作流程过程。
- en: There's more...
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: As with everything, there are pros and cons to using transfer learning. As we
    discussed earlier on in the section, transfer learning is ideal when you are limited
    in resources to perform your own modeling on a large dataset. There is always
    the chance that the source data at hand does not exhibit many of the features
    unique to it in the pre-trained models leading to poor model performance. There
    is always the option to switch from one pre-trained model to another and evaluate
    model performance. Again, transfer learning is a fail fast approach that can be
    taken when other options are not available.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 与一切一样，使用迁移学习有利有弊。正如我们在本节前面讨论的那样，当您在资源有限时，对大型数据集进行自己的建模时，迁移学习是理想的选择。手头的源数据可能不具备预训练模型中的许多独特特征，导致模型性能不佳。可以随时切换到另一个预训练模型并评估模型性能。再次强调，迁移学习是一种快速失败的方法，当其他选择不可用时可以采取。
- en: See also
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about ResNet at Microsoft, visit the following website:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关微软ResNet的更多信息，请访问以下网站：
- en: '[https://resnet.microsoft.com/](https://resnet.microsoft.com/)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://resnet.microsoft.com/](https://resnet.microsoft.com/)'
- en: 'To learn more about Inception at Google, visit the following website:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关谷歌Inception的更多信息，请访问以下网站：
- en: '[https://www.tensorflow.org/tutorials/image_recognition](https://www.tensorflow.org/tutorials/image_recognition)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.tensorflow.org/tutorials/image_recognition](https://www.tensorflow.org/tutorials/image_recognition)'
- en: 'To learn more specifically about InceptionV3, you can read the following paper
    titled <q class="calibre51">Rethinking the Inception Architecture for Computer
    Vision</q> at Cornell University:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于InceptionV3的信息，您可以阅读康奈尔大学的题为《重新思考计算机视觉的Inception架构》的论文：
- en: '[https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567)'
- en: 'Pain Point #6: Prioritizing high-level libraries for CNNs'
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 痛点＃6：优先考虑用于CNN的高级库
- en: There are many libraries available to perform convolutional neural networks.
    Some of them are considered low-level such as TensorFlow, where much of the configuration
    and setup requires extensive coding. This can be considered a major pain point
    for an inexperienced developer. There are other libraries, such as Keras, that
    are high-level frameworks built on top of libraries such as TensorFlow. These
    libraries require much less code to get up and running with building a convolutional
    neural network. Often times developers getting started with building a neural
    network will try and implement a model with TensorFlow and run into several issues
    along the way. This section will propose initially building a convolutional neural
    network with Keras instead to predict the hand-written images from the MNIST dataset.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多库可用于执行卷积神经网络。其中一些被认为是低级的，比如TensorFlow，其中许多配置和设置需要大量编码。这对于经验不足的开发人员来说可能是一个主要痛点。还有其他库，比如Keras，它是建立在诸如TensorFlow之类的库之上的高级框架。这些库需要更少的代码来构建卷积神经网络。通常，刚开始构建神经网络的开发人员会尝试使用TensorFlow来实现模型，并在途中遇到几个问题。本节将首先建议使用Keras构建卷积神经网络，而不是使用TensorFlow来预测MNIST数据集中的手写图像。
- en: Getting ready
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In this section, we will be working with Keras to train a model for recognizing
    handwritten images from MNIST. You can install Keras by executing the following
    command at the terminal:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用Keras训练一个模型，以识别MNIST中的手写图像。您可以通过在终端执行以下命令来安装Keras：
- en: '[PRE11]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: How to do it...
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: This section walks through the steps to build a model to recognize handwritten
    images from MNIST.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍构建一个模型来识别MNIST中手写图像的步骤。
- en: 'Create testing and training images and labels based on the MNIST dataset from
    the following variables using the following script:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本基于以下变量创建测试和训练图像和标签：
- en: '[PRE12]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Reshape the testing and training arrays using the following script:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本重塑测试和训练数组：
- en: '[PRE13]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Import the following from `keras` to build the convolutional neural network
    model:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`keras`导入以下内容以构建卷积神经网络模型：
- en: '[PRE14]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Set the image ordering using the following script:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本设置图像排序：
- en: '[PRE15]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Initialize the `Sequential` `model` using the following script:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本初始化`Sequential` `model`：
- en: '[PRE16]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Add layers to the `model` using the following script:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本向`model`添加层：
- en: '[PRE17]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Compile the `model` using the following script:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本编译`model`：
- en: '[PRE18]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Train the `model` using the following script:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本训练`model`：
- en: '[PRE19]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Test the `model` performance using the following script:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本测试`model`的性能：
- en: '[PRE20]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How it works...
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains how the convolutional neural network is built on Keras
    to identify handwritten images from MNIST.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了如何在Keras上构建卷积神经网络以识别MNIST中的手写图像。
- en: For any model development, we need to identify our testing and training datasets
    as well as the features and the labels. In our case, it is pretty straightforward
    as the MNIST data from TensorFlow is already broken up into `data.train.images`
    for the features and `data.train.labels` for the labels. Additionally, we want
    to convert the labels into arrays, so we utilize `np.asarray()` for `ytest` and
    `ytrain`.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于任何模型开发，我们需要确定我们的测试和训练数据集以及特征和标签。在我们的情况下，这相当简单，因为来自TensorFlow的MNIST数据已经被分解为`data.train.images`用于特征和`data.train.labels`用于标签。此外，我们希望将标签转换为数组，因此我们利用`np.asarray()`来处理`ytest`和`ytrain`。
- en: 'The arrays for `xtrain`, `xtest`, `ytrain`, and `ytest` are currently not in
    the proper shape to be used for a convolutional neural network within Keras. As
    we identified early on in the chapter, the features for the MNIST images represent
    28 x 28-pixel images and the labels indicate one of ten values from 0 through
    9\. The x-arrays will be reshaped to (,28,28,1) and the y-arrays will be reshaped
    to (,10). The `shape` of the new arrays can be seen in the following screenshot:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`xtrain`、`xtest`、`ytrain`和`ytest`的数组目前不是用于Keras中的卷积神经网络的正确形状。正如我们在本章早期确定的那样，MNIST图像的特征表示为28
    x 28像素图像，标签表示0到9之间的十个值中的一个。x-arrays将被重塑为(,28,28,1)，y-arrays将被重塑为(,10)。新数组的`shape`如下截图所示：'
- en: '![](img/00091.jpeg)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00091.jpeg)'
- en: As mentioned previously, Keras is a high-level library; therefore, it does not
    perform tensor or convolutional operations without the assistance of a lower level
    library such as TensorFlow. In order to configure these operations, we set the
    `backend` to be `K` for `Keras` with the image dimensional ordering, `image_dim_ordering`,
    set to `tf` for TensorFlow.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，Keras是一个高级库；因此，它不会执行张量或卷积操作，而没有低级库（如TensorFlow）的帮助。为了配置这些操作，我们将`backend`设置为`K`，`Keras`的图像维度排序`image_dim_ordering`设置为`tf`，表示TensorFlow。
- en: Please note that the backend could also be set to other low-level libraries,
    such as `Theano`. Instead of `tf`, we would set the dimensional ordering to `th`.
    Additionally, we would need to reconstruct the shaping of the features. However,
    in the past few years, `Theano` has not garnered the same adoption rate `TensorFlow`
    has.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，后端也可以设置为其他低级库，如`Theano`。我们将维度排序设置为`th`。此外，我们需要重构特征的形状。然而，在过去的几年中，`Theano`并没有像`TensorFlow`那样获得同样的采用率。
- en: Once we import the necessary libraries to build the CNN model, we can begin
    constructing the sequences or layers, `Sequential()`, of the model. For demonstration
    purposes, we will keep this model as simple as possible with only 4 layers to
    prove that we can still gain a high accuracy with minimal complexity. Each layer
    is added using the `.add()` method.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们导入构建CNN模型所需的必要库，我们就可以开始构建模型的序列或层，`Sequential()`。为了演示目的，我们将保持这个模型尽可能简单，只有4层，以证明我们仍然可以在最小的复杂性下获得高准确性。每一层都是使用`.add()`方法添加的。
- en: The first layer is set to build a 2-Dimensional (`Conv2D`) convolution layer,
    which is common for spatial images such as the MNIST data. Since it is the first
    layer, we must explicitly define the `input_shape` of the incoming data. Additionally,
    we specify a `kernel_size` that is used to set the height and width of the window
    filter used for convolution. Usually, this is either a 3x3 window or 5x5 window
    for the 32 filters. Additionally, we have to set an activation function for this
    layer and rectified linear units, `relu`, are a good option here for efficiency
    purposes, especially early on in the neural network.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一层被设置为构建一个二维（`Conv2D`）卷积层，这对于空间图像如MNIST数据是常见的。由于这是第一层，我们必须明确定义传入数据的`input_shape`。此外，我们指定一个`kernel_size`，用于设置用于卷积的窗口滤波器的高度和宽度。通常，这是32个滤波器的3x3窗口或5x5窗口。此外，我们必须为这一层设置一个激活函数，对于效率目的，特别是在神经网络的早期阶段，`relu`是一个不错的选择。
- en: Next, the second layer flattens the first layer inputs to retrieve a classification
    that we can use to determine whether the image is one of a possible 10 digits.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，第二层将第一层的输入展平，以获取一个分类，我们可以用来确定图像是否是可能的10个数字之一。
- en: Third, we pass the outputs from the second layer into a `dense` layer that has
    128 hidden layers with another `relu` activation function. The function within
    a densely connected layer incorporates the `input_shape` and `kernel_size` as
    well as the bias to create the output for each of the 128 hidden layers.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三，我们将第二层的输出传递到具有128个隐藏层的另一个具有`relu`激活函数的`dense`层。密集连接层中的函数包括`input_shape`和`kernel_size`以及偏差，以创建每个128个隐藏层的输出。
- en: The final layer is the output that will determine what the predicted value will
    be for the MNIST image. We add another `dense` layer with a `sigmoid` function
    to output probabilities for each of the 10 possible scenarios our MNIST image
    could be. Sigmoid functions are useful for binary or multiclass classification
    outcomes.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一层是输出层，将决定MNIST图像的预测值是什么。我们添加另一个具有`sigmoid`函数的`dense`层，以输出我们的MNIST图像可能的10种情况的概率。Sigmoid函数对于二元或多类分类结果很有用。
- en: The next step is to compile the model using `adam` for the `optimizer` and evaluating
    `accuracy` for the `metrics`. The `adam` optimizer is common for CNN models as
    is using `categorical_crossentropy` as a loss function when dealing with multiclassification
    scenarios for 10 possible outcomes as is our case.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是使用`adam`作为`optimizer`编译模型，并评估`accuracy`作为`metrics`。`adam`优化器对于CNN模型很常见，当处理10种可能结果的多类分类场景时，使用`categorical_crossentropy`作为损失函数也很常见，这也是我们的情况。
- en: 'We train the model using a `batch_size` of `512` images at a time over `5`
    runs or `epochs`. The loss and accuracy of each epoch are captured and can be
    seen in the following screenshot:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`batch_size`为`512`的图像进行`5`次运行或`epochs`来训练模型。每个epoch的损失和准确性都被捕获，并可以在以下截图中看到：
- en: '![](img/00092.jpeg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00092.jpeg)'
- en: 'We calculate the accuracy and the loss rate by evaluating the trained model
    on the test dataset as seen in the following screenshot:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过在测试数据集上评估训练模型来计算准确性和损失率，如下截图所示：
- en: '![](img/00093.jpeg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00093.jpeg)'
- en: Our model seems to be performing well with a 98.6% accuracy rate and a 5% loss
    rate.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的模型似乎表现良好，准确率为98.6%，损失率为5%。
- en: We built a simple convolutional neural network in Keras using five lines of
    code for the actual model design. Keras is a great way to get a model up and running
    in little time and code. Once you are ready to move onto more sophisticated model
    development and control, it may make more sense to build a convolutional neural
    network in TensorFlow.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在Keras中使用了五行代码来构建一个简单的卷积神经网络模型。Keras是一个快速上手的模型设计工具。一旦您准备好转向更复杂的模型开发和控制，可能更有意义的是在TensorFlow中构建卷积神经网络。
- en: There's more...
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'In addition to retrieving the accuracy of the model we can also produce the
    shapes within each layer of the CNN modeling process by executing the following
    script:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 除了获取模型的准确性，我们还可以通过执行以下脚本来产生CNN建模过程中每一层的形状：
- en: '[PRE21]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output of the `model.summary()` can be seen in the following screenshot:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`model.summary()`的输出可以在以下截图中看到：'
- en: '![](img/00094.jpeg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00094.jpeg)'
- en: We see that the output shape of the first layer (None, 24, 24, 32) was flattened
    out into a shape of (None, 18432) by multiplying 24 x 24 x 32 within the second
    layer. Additionally, we see our third and fourth layers have the shape that we
    assigned them using the Dense layer function
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到第一层的输出形状（None, 24, 24, 32）通过在第二层中乘以24 x 24 x 32而展平为形状（None, 18432）。此外，我们看到我们的第三和第四层具有我们使用Dense层函数分配给它们的形状。
- en: See also
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about 2D convolutional layer development in Keras, visit the
    following website:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Keras中2D卷积层开发的信息，请访问以下网站：
- en: '[https://keras.io/layers/convolutional/#conv2d](https://keras.io/layers/convolutional/#conv2d)'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://keras.io/layers/convolutional/#conv2d](https://keras.io/layers/convolutional/#conv2d)'
- en: 'To learn how to build a convolutional neural network in TensorFlow with MNIST
    images, visit the following website:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何在TensorFlow中使用MNIST图像构建卷积神经网络，请访问以下网站：
- en: '[https://www.tensorflow.org/versions/r1.4/get_started/mnist/pros](https://www.tensorflow.org/versions/r1.4/get_started/mnist/pros)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.tensorflow.org/versions/r1.4/get_started/mnist/pros](https://www.tensorflow.org/versions/r1.4/get_started/mnist/pros)'
