- en: '*Chapter 2*: Pachyderm Basics'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第二章*：Pachyderm基础'
- en: '**Pachyderm** is a data science platform that enables data scientists to create
    an end-to-end machine learning workflow that covers the most important stages
    of a machine learning life cycle, starting from data ingestion all the way into
    production.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pachyderm**是一个数据科学平台，使数据科学家能够创建端到端的机器学习工作流，涵盖机器学习生命周期中最重要的阶段，从数据摄取到生产部署。'
- en: If you are familiar with **Git**, a version control and life cycle system for
    code, you will find many similarities between the most important Git and Pachyderm
    concepts. Version control systems such as Git and its hosted version **GitHub**
    have become an industry standard for thousands of developers worldwide. Git enables
    you to keep a history of changes in your code and go back when needed. Data scientists
    deserve a platform that will let them track the versions of their experiments,
    reproduce results when needed, and investigate and correct bias that might crawl
    into one of the stages of the data science life cycle. Pachyderm provides benefits
    similar to Git that enable data scientists to reproduce their experiments and
    effortlessly manage the complete life cycle of the data science workflow.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉**Git**，一个用于代码的版本控制和生命周期管理系统，你会发现Git和Pachyderm的最重要概念之间有许多相似之处。像Git及其托管版本**GitHub**这样的版本控制系统，已成为全球成千上万开发者的行业标准。Git使你能够保存代码更改的历史，并在需要时回溯。数据科学家需要一个平台，能够跟踪实验的版本，必要时重现结果，并调查和纠正可能在数据科学生命周期的某一阶段出现的偏差。Pachyderm提供了类似于Git的好处，使数据科学家能够重现实验并轻松管理数据科学工作流的完整生命周期。
- en: 'This chapter is intended to describe the basics of Pachyderm architecture and
    its main concepts. We will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在描述Pachyderm架构的基础知识及其主要概念。我们将涵盖以下主题：
- en: Reviewing Pachyderm architecture
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回顾Pachyderm架构
- en: Learning about version control primitives
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习版本控制原语
- en: Discovering pipeline elements
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现管道元素
- en: Reviewing Pachyderm architecture
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾Pachyderm架构
- en: This section walks you through the distributed Pachyderm architecture and the
    internals of the Pachyderm solution. But before we dive into the nitty-gritty
    details of Pachyderm infrastructure, let's answer the question that a lot of you
    might have on your mind after reading the introduction—*why can't I use Git or
    any other version control system?* We'll address this question with Git in mind
    as it is the most popular and widely used software version control system, but
    all of the arguments apply to any other similar version control system for source
    code. After we review how Pachyderm is different and similar to Git, we will review
    the Pachyderm internals, Kubernetes, and container runtimes.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将带你了解分布式Pachyderm架构以及Pachyderm解决方案的内部原理。但在深入探讨Pachyderm基础设施的细节之前，让我们先回答你们在阅读简介后可能会有的问题——*为什么我不能使用Git或任何其他版本控制系统？*
    我们将以Git为例来回答这个问题，因为它是最流行和广泛使用的软件版本控制系统，但所有的论点都适用于任何其他类似的源代码版本控制系统。在回顾Pachyderm如何与Git不同及相似之后，我们将回顾Pachyderm的内部原理、Kubernetes和容器运行时。
- en: Why can't I use Git for my data pipelines?
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么我不能使用Git来管理我的数据管道？
- en: '*So, if Pachyderm* *is similar to Git, why can''t I store everything in Git
    rather* *than have multiple tools that I have to learn and support?*, you might
    ask.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*那么，如果Pachyderm* *与Git类似，为什么我不能将所有内容都存储在Git中，而* *是要使用我需要学习和支持的多个工具呢？*，你可能会问。'
- en: While Git is a great open source technology for software engineers, it is not
    tailored to solve the reproducibility problem in data science. This is mainly
    because Git was designed to track versions of files rather than establishing connections
    between data, code, and parameters – the essential parts of each data model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Git是软件工程师常用的开源技术，但它并不专门解决数据科学中的可重现性问题。这主要是因为Git被设计用来跟踪文件版本，而不是建立数据、代码和参数之间的联系——这些是每个数据模型的核心部分。
- en: 'While you can keep your code files in Git, doing so with the training data
    is not possible for the following reasons:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可以将代码文件保存在Git中，但由于以下原因，将训练数据保存在Git中是不可能的：
- en: 'File format support: Git is great for source code, such as text files, scripts,
    and so on, but it does not version non-binary files, such as image or video files.
    Git will detect that a binary file has changed, but it does not provide detailed
    information about the changes like it does in the case of text files. In addition,
    Git replaces the whole binary file, which makes for a dramatic increase in your
    repository when you update it.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件格式支持：Git非常适合源代码管理，例如文本文件、脚本等，但它不支持非二进制文件的版本控制，如图片或视频文件。Git会检测到二进制文件的变化，但不会像文本文件那样提供详细的变更信息。此外，Git会替换整个二进制文件，这使得在更新时你的仓库体积剧增。
- en: 'File size support: Often, image and video files are very large, and Git has
    a file size limitation of 100 MB per file. For best performance, Git recommends
    keeping your repository size below 1 GB, which might not be enough for some machine
    learning and deep learning projects.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件大小支持：通常，图片和视频文件非常大，而Git对每个文件有100MB的大小限制。为了获得最佳性能，Git建议将仓库大小保持在1GB以下，而这对于某些机器学习和深度学习项目可能并不足够。
- en: Cloning a large Git repository and all the associated history of each file can
    be problematic and takes a long time.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 克隆一个大型Git仓库以及每个文件的所有历史记录可能会成为问题，并且需要较长的时间。
- en: Consider these limitations when you plan the tooling for your machine learning
    project.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在计划机器学习项目的工具时，请考虑这些限制。
- en: 'In addition to standard Git repositories, Git offers storage for large files,
    called **Git Large File Storage** (**LFS**). However, this option likely won''t
    provide the needed functionality either. Git LFS has the following disadvantages
    for machine learning projects:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标准的Git仓库，Git还提供了大型文件存储功能，称为**Git大型文件存储**（**LFS**）。然而，这个选项可能也无法提供所需的功能。Git
    LFS在机器学习项目中有以下缺点：
- en: Git LFS requires a server. You either need to set up and maintain your own Git
    LFS server or store it on a third-party online platform. Hosting your own server
    is problematic and requires additional support, and your preferred cloud provider
    might not be supported.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Git LFS需要一个服务器。你需要设置并维护自己的Git LFS服务器，或者将其存储在第三方在线平台上。托管自己的服务器存在问题，需要额外的支持，并且你的首选云服务提供商可能不被支持。
- en: Online Git LFS servers have a limited free tier. For projects that use high-resolution
    images or videos, this likely means that the limit will be reached fairly soon,
    and an upgrade to a paid version will be required.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线Git LFS服务器有一个有限的免费版。对于使用高分辨率图片或视频的项目，这通常意味着很快就会达到限制，需要升级到付费版。
- en: Designed for marketing department purposes, Git LFS seems like a good solution
    for marketing departments to store assets. Everyone else seems to prefer standard
    Git for their non-machine-learning projects.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Git LFS设计初衷是面向营销部门的用途，似乎是一个不错的解决方案，适合营销部门存储资产。其他人则更倾向于在非机器学习项目中使用标准Git。
- en: Now that you know why source code version control systems are not the best solutions
    to work with data, let's review Pachyderm architecture.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道为什么源代码版本控制系统并不是处理数据的最佳解决方案，让我们来回顾一下Pachyderm架构。
- en: Pachyderm architecture diagram
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pachyderm架构图
- en: 'The following diagram shows the Pachyderm architecture:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了Pachyderm架构：
- en: '![Figure 2.1 – Pachyderm architecture'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.1 – Pachyderm架构'
- en: '](img/B17085_02_001.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17085_02_001.jpg)'
- en: Figure 2.1 – Pachyderm architecture
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 – Pachyderm架构
- en: Let's review all the components of this diagram one by one.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一回顾一下这个图中的所有组件。
- en: Kubernetes
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes
- en: Kubernetes, an open source distributed workflow scheduling system, is at Pachyderm's
    core. If you are not familiar with Kubernetes, here is a quick overview.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes，一个开源分布式工作流调度系统，是Pachyderm的核心。如果你不熟悉Kubernetes，下面是一个简要概述。
- en: '**Kubernetes** is the latest stage of infrastructure evolution, which started
    with traditional hardware deployments where data center operators deployed all
    applications on one physical server. The applications would fight over resources,
    which resulted in poor performance in some applications. This didn''t scale well
    and was difficult to manage. Later on, we saw the rise of **virtual machine**
    technology that made the management of physical servers much easier and allowed
    us to run multiple applications on one physical server with better scalability.
    Many data centers still run a lot of virtual machines. **Containers**, the technology
    on which Kubernetes is based, made the infrastructure even leaner by allowing
    containers to share common operating system components and removing the redundant
    copies of the same software parts. Containers can be easily ported from one cloud
    platform to another, provide better resource allocation, and overall are easier
    to manage and support.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes** 是基础设施演进的最新阶段，最早起源于传统硬件部署，在那里数据中心操作员将所有应用程序部署在一台物理服务器上。这些应用程序会争夺资源，导致某些应用程序性能差。这种方式扩展性差，且管理困难。后来，我们看到了**虚拟机**技术的兴起，它使得物理服务器的管理变得更容易，并允许我们在一台物理服务器上运行多个应用程序，且具备更好的可扩展性。许多数据中心至今仍在运行大量虚拟机。**容器**，Kubernetes
    所基于的技术，通过允许容器共享操作系统组件并去除相同软件部分的冗余副本，使得基础设施变得更加精简。容器可以轻松地从一个云平台迁移到另一个平台，提供更好的资源分配，并且整体上更易于管理和支持。'
- en: The function of Kubernetes is to manage containers and collections of containers
    called **Pods**. Today, Kubernetes is the dominant container technology in the
    open source world. Big tech companies might have their own types of schedulers
    – for example, Google has a project called **Borg**, but the majority of others
    are using one or another version of Kubernetes.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的功能是管理容器及其集合，称为**Pods**。如今，Kubernetes 已成为开源世界中主导的容器技术。大科技公司可能有自己的调度程序类型——例如，谷歌有一个叫做
    **Borg** 的项目，但大多数其他公司都在使用某一版本的 Kubernetes。
- en: Companies such as Amazon, Microsoft, and Google offer hosted versions of Kubernetes
    called, respectively, **AWS Elastic Kubernetes Service** (**EKS**), **Microsoft
    Azure Kubernetes Service** (**AKS**), and **Google Kubernetes Engine** (**GKE**).
    Kubernetes can also be installed on-premises by using an automated software provisioning
    tool, such as Ansible, or using one of the specifically designed Kubernetes installation
    tools, such as **Kubespray**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊、微软和谷歌等公司提供了分别被称为**AWS 弹性 Kubernetes 服务**（**EKS**）、**微软 Azure Kubernetes
    服务**（**AKS**）和**谷歌 Kubernetes 引擎**（**GKE**）的托管 Kubernetes 版本。
- en: Some companies, such as DigitalOcean, provide a Kubernetes installation and
    management system that can deploy Kubernetes to a cloud platform of your choice.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一些公司，如 DigitalOcean，提供一个 Kubernetes 安装和管理系统，可以将 Kubernetes 部署到您选择的云平台上。
- en: Now that we know what Kubernetes is, let's review how Pachyderm leverages Kubernetes
    to provide a scalable, reproducible data science solution.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了 Kubernetes 的基本概念，接下来让我们回顾一下 Pachyderm 如何利用 Kubernetes 提供可扩展、可重复的数据科学解决方案。
- en: Helm
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Helm
- en: The tool that deploys Pachyderm on top of Kubernetes is called `values.yaml`
    that you can use with the Pachyderm Helm Chart for local Pachyderm installation
    at [https://github.com/pachyderm/pachyderm/blob/master/doc/docs/master/reference/helm_values.md](https://github.com/pachyderm/pachyderm/blob/master/doc/docs/master/reference/helm_values.md).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 Pachyderm 的工具是 `values.yaml`，您可以使用它与 Pachyderm Helm Chart 一起进行本地 Pachyderm
    安装，详情请见 [https://github.com/pachyderm/pachyderm/blob/master/doc/docs/master/reference/helm_values.md](https://github.com/pachyderm/pachyderm/blob/master/doc/docs/master/reference/helm_values.md)。
- en: In the `values.yaml` file, you can define everything you want to deploy with
    your Pachyderm cluster. For example, you can deploy the Pachyderm UI called Console,
    or not; you can configure storage buckets in your cloud provider; you can specify
    which version of Pachyderm to install, and so on.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `values.yaml` 文件中，您可以定义所有希望与 Pachyderm 集群一起部署的内容。例如，您可以选择部署名为 Console 的 Pachyderm
    用户界面，也可以不部署；您可以在云服务提供商中配置存储桶；您可以指定要安装的 Pachyderm 版本，等等。
- en: Helm Charts are stored in Artifact Hub, located at [https://artifacthub.io/](https://artifacthub.io/).
    You can find Pachyderm at [https://artifacthub.io/packages/helm/pachyderm/pachyderm](https://artifacthub.io/packages/helm/pachyderm/pachyderm).
    We will discuss the Pachyderm Helm Chart in more detail in [*Chapter 5*](B17085_05_Final_SB_Epub.xhtml#_idTextAnchor123),
    *Installing Pachyderm on a Cloud Platform*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Helm Charts 存储在 Artifact Hub，网址为 [https://artifacthub.io/](https://artifacthub.io/)。你可以在
    [https://artifacthub.io/packages/helm/pachyderm/pachyderm](https://artifacthub.io/packages/helm/pachyderm/pachyderm)
    找到 Pachyderm。我们将在 [*第 5 章*](B17085_05_Final_SB_Epub.xhtml#_idTextAnchor123) 中更详细地讨论
    Pachyderm Helm Chart，*在云平台上安装 Pachyderm*。
- en: Pachyderm internals
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pachyderm 内部结构
- en: 'When you deploy Pachyderm locally or on a cloud platform of your choice, the
    underlying Kubernetes orchestrator deploys the following components:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在本地或所选云平台上部署 Pachyderm 时，底层的 Kubernetes 调度器会部署以下组件：
- en: '`Pachyderm Console` (`UI`): The Pachyderm in-browser **User Interface** (**UI**)
    that provides basic Pachyderm functionality.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pachyderm Console`（`UI`）：Pachyderm 浏览器内的 **用户界面**（**UI**），提供基本的 Pachyderm
    功能。'
- en: '`Pachd`: The Pachyderm daemon container that is responsible for managing all
    the main Pachyderm logical operations.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pachd`：Pachyderm 守护进程容器，负责管理所有主要的 Pachyderm 逻辑操作。'
- en: '`postgress`: Pachyderm requires a **PostgreSQL** instance to store metadata.
    PostgreSQL is a relational database popular in many open source and commercial
    solutions. While for testing purposes, an instance of PostgreSQL is shipped with
    the Pachyderm build, for production deployments and workloads, a separate cloud-based
    instance is strongly recommended.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`postgress`：Pachyderm 需要一个 **PostgreSQL** 实例来存储元数据。PostgreSQL 是一个广泛应用于许多开源和商业解决方案的关系型数据库。虽然在测试时，Pachyderm
    构建中自带了一个 PostgreSQL 实例，但对于生产部署和工作负载，强烈建议使用单独的基于云的实例。'
- en: '`etcd`: In older versions of Pachyderm, `etcd` was the key-value store that
    stored information about nodes and administrative metadata. In versions of Pachyderm
    2.0.0 and later, `etcd` only stores a small portion of metadata, while the majority
    is stored in PostgreSQL.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`etcd`：在旧版本的 Pachyderm 中，`etcd` 是存储节点信息和管理元数据的键值存储。在 Pachyderm 2.0.0 及更高版本中，`etcd`
    只存储一小部分元数据，其余的元数据存储在 PostgreSQL 中。'
- en: Each of these components is deployed as a Kubernetes **Pod**—the smallest deployment
    unit of Kubernetes, which can have one or a collection of containers. Unlike in
    other applications, in Pachyderm, each Pod has only one container.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件中的每一个都作为 Kubernetes **Pod** 部署——Kubernetes 的最小部署单元，可以包含一个或多个容器。与其他应用程序不同，在
    Pachyderm 中，每个 Pod 只有一个容器。
- en: In addition to these containers that are deployed during the installation, every
    **Pachyderm pipeline**, a computational component that trains your model, is deployed
    as a separate Kubernetes Pod. These Pods are called **workers**. You can deploy
    an unlimited number of pipelines in your Pachyderm cluster and assign a custom
    amount of resources to each Pod. Pods are completely isolated from each other.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在安装过程中部署的这些容器外，每个 **Pachyderm 管道**（一个训练模型的计算组件）都作为单独的 Kubernetes Pod 部署。这些
    Pod 被称为 **工作节点**（workers）。你可以在 Pachyderm 集群中部署无限数量的管道，并为每个 Pod 分配自定义数量的资源。Pod
    彼此完全隔离。
- en: Other components
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他组件
- en: '*Figure 2.1* has the following components that we have not yet listed:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.1* 包含以下我们尚未列出的组件：'
- en: '**Load Balancer or Ingress Controller**: A networking component of Kubernetes
    that exposes HTTP/HTTPS routes from the cluster to the outside world. By default,
    Kubernetes provides a **ClusterIP** service that enables the services inside the
    cluster to talk to each other. There is no way to access cluster services from
    the outside world. In a production deployment, such as on a cloud platform, you
    need to deploy either an ingress controller or a load balancer to be able to access
    your Pachyderm cluster from the internet. In a local, testing deployment, Pachyderm
    uses port-forwarding. **NodePort** is another way to configure external access.
    However, it is not recommended for production deployments and, therefore, has
    been omitted from the current description. Pachyderm provides a Traefik ingress
    option to install through its Helm Chart.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载均衡器或入口控制器**：Kubernetes 的网络组件，负责将 HTTP/HTTPS 路由从集群暴露到外部世界。默认情况下，Kubernetes
    提供**ClusterIP** 服务，使集群内部的服务可以相互通信，但无法从外部世界访问集群服务。在生产环境中，如云平台上，你需要部署入口控制器或负载均衡器才能通过互联网访问你的
    Pachyderm 集群。在本地测试部署中，Pachyderm 使用端口转发。**NodePort** 是另一种配置外部访问的方式，但不推荐用于生产环境，因此在当前描述中已被省略。Pachyderm
    提供了一种通过 Helm Chart 安装的 Traefik 入口选项。'
- en: '`pachctl` is Pachyderm''s **Command-Line Interface** (**CLI**), which enables
    users to perform advanced operations with Pachyderm pipelines and configure infrastructure
    as needed.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pachctl` 是 Pachyderm 的**命令行界面**（**CLI**），使用户能够执行与 Pachyderm 管道相关的高级操作，并根据需要配置基础设施。'
- en: '**API**: Pachyderm supports programmatical access through a variety of language
    clients, including Python, Go, and others. Many users will find it useful to use
    one of the supported clients or even build their own.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API**：Pachyderm 支持通过多种语言客户端进行编程访问，包括 Python、Go 等。许多用户会发现，使用支持的客户端之一或甚至构建自己的客户端非常有用。'
- en: '**Metadata storage**: etcd collects administrative metadata, which has to be
    stored either on a local disk or a Kubernetes **Persistent Volume** (**PV**),
    which can be on a cloud platform or any other platform of your choice.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据存储**：etcd 收集管理元数据，这些元数据必须存储在本地磁盘或 Kubernetes 的**持久化卷**（**PV**）中，可以存储在云平台或任何其他平台上。'
- en: '**Object Storage**: A location to store your **Pachyderm File System** (**PFS**)
    and the pipeline-related files. Pachyderm supports S3 object storage, such as
    MinIO, Google S3, Azure Blob storage, and Amazon S3\.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对象存储**：用于存储**Pachyderm文件系统**（**PFS**）和与管道相关的文件。Pachyderm 支持 S3 对象存储，如 MinIO、Google
    S3、Azure Blob 存储和 Amazon S3。'
- en: In *Figure 2.1*, the user accesses the Pachyderm cluster through a load balancer
    or ingress controller by using either the Pachyderm dashboard, `pachctl`, or through
    the API by using a language client. The user's call is sent to `pachd`. `pachd`
    processes the request and updates the state of the pipeline and `etcd` accordingly.
    After the pipeline runs, it outputs the result to the configured storage location,
    from where it can be accessed by other third-party applications.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 2.1*中，用户通过负载均衡器或入口控制器访问 Pachyderm 集群，可以使用 Pachyderm 仪表板、`pachctl`，或通过 API
    使用语言客户端进行访问。用户的请求被发送到 `pachd`，`pachd` 处理请求并相应地更新管道和 `etcd` 的状态。管道运行后，将结果输出到配置的存储位置，其他第三方应用程序可以从该位置访问该结果。
- en: Container runtimes
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器运行时
- en: A container runtime is software that executes the code in a container. There
    are many open source container runtimes, such as Docker, container, CRI-O, and
    others. Pachyderm supports the most popular container runtime—Docker. The fact
    that Pachyderm supports only one type of container runtime does not mean limited
    functionality. Most users will find Docker containers sufficient for all their
    needs.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时是执行容器内代码的软件。有许多开源容器运行时，如 Docker、container、CRI-O 等。Pachyderm 支持最流行的容器运行时——Docker。Pachyderm
    仅支持一种容器运行时，并不意味着功能有限。大多数用户会发现，Docker 容器已足够满足他们的所有需求。
- en: To run a container, you need to have a **container image** and a place to store
    it. A container image is a file that contains the immutable code of a program
    that can be executed by the container runtime. Container images are stored in
    **container registries**, storage or repositories that host container images.
    Some container registries are public and others are private. All Pachyderm components
    are packaged as container images and stored in **Docker Hub**, a public container
    registry, meaning that anyone can download those images free of charge.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行容器，你需要有一个**容器镜像**以及一个存储它的地方。容器镜像是一个包含程序不可变代码的文件，可以由容器运行时执行。容器镜像存储在**容器注册表**中，这些是存储或托管容器镜像的库或仓库。部分容器注册表是公开的，另一些则是私有的。所有Pachyderm组件都打包为容器镜像，并存储在**Docker
    Hub**中，这是一种公共容器注册表，任何人都可以免费下载这些镜像。
- en: All your Pachyderm pipelines will have to be packaged as Docker containers and
    stored in a container registry. Your organization might require you to store your
    packages in a private container registry to protect the intellectual property
    of your pipeline. But if you are working on an open source or student project,
    you can store your container images in Docker Hub for free.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的Pachyderm管道都需要打包成Docker容器并存储在容器注册表中。你的组织可能要求你将包存储在私有容器注册表中，以保护管道的知识产权。但如果你是在做开源或学生项目，你可以免费将容器镜像存储在Docker
    Hub中。
- en: Now that we have reviewed the Pachyderm architecture, let's look at Pachyderm
    version control primitives that are foundational in understanding how Pachyderm
    works.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经回顾了Pachyderm架构，让我们来看看Pachyderm版本控制的基本原理，这对于理解Pachyderm的工作原理至关重要。
- en: Learning about version control primitives
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习版本控制原语
- en: As we saw in a previous section, Pachyderm bears similarities to the code version
    control software called Git. If you have participated in developing an open source
    project before, you are likely familiar with Git through the use of a hosted Git
    version, such as GitHub, GitLab, or Gerrit.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的章节中看到的，Pachyderm与名为Git的代码版本控制软件有相似之处。如果你曾参与过开源项目的开发，你可能通过使用托管的Git版本（如GitHub、GitLab或Gerrit）而熟悉Git。
- en: Like with Git, you store your data in **repositories**, upload your data with
    a **commit**, and can have multiple **branches** in your repositories. Pachyderm
    stores the history of your commits and allows you to track changes or the **history**
    of your data back to its origins.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 像使用Git一样，你将数据存储在**仓库**中，通过**提交**上传数据，并且可以在仓库中拥有多个**分支**。Pachyderm存储了你的提交历史，并允许你追溯数据的变化或**历史**，直至其最初的状态。
- en: Pachyderm version control primitives enable you to go back in time and run your
    pipeline against previous versions of your changes. This can be very powerful
    in tracking bias and mistakes that crawl into your pipeline changes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Pachyderm版本控制原语使你能够回溯到过去，并使用管道对先前版本的更改进行处理。这在跟踪偏差和错误（这些可能会悄然进入你的管道更改中）时非常有用。
- en: Let's look at these concepts in more detail.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地了解这些概念。
- en: Repository
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仓库
- en: A Pachyderm **repository** is a filesystem in which you store your data and
    where you store versions of your data. Pachyderm distinguishes between the **input
    repository** and **output repository**.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Pachyderm的**仓库**是一个文件系统，你在其中存储数据并保存数据的不同版本。Pachyderm区分了**输入仓库**和**输出仓库**。
- en: An input repository is a filesystem that you create and where you upload your
    data for further processing either by using a CLI, the UI, or automatically by
    using the API.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 输入仓库是你创建的文件系统，用于上传数据以供进一步处理，可以通过CLI、UI或通过API自动上传。
- en: An output repository is a filesystem that Pachyderm creates automatically, which
    has the same name as the pipeline. This is the location where Pachyderm outputs
    the results of the calculation and from where results can be exported for serving
    as a model.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 输出仓库是Pachyderm自动创建的文件系统，其名称与管道相同。这里是Pachyderm输出计算结果的地方，也是可以从这里导出结果以供作为模型使用的地方。
- en: An important distinction from the Git repositories is that Pachyderm repository
    history is stored in a centralized location, which eliminates the risk of merge
    conflicts. Therefore, there is no equivalent of the `.git` history file in Pachyderm.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 与Git仓库的一个重要区别是，Pachyderm仓库历史被存储在一个集中位置，这消除了合并冲突的风险。因此，Pachyderm没有类似`.git`历史文件的东西。
- en: 'The following diagram demonstrates how internal and external repositories work
    within a pipeline:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了内部和外部仓库在管道中的工作方式：
- en: '![Figure 2.2 – Pachyderm input and output repositories'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.2 – Pachyderm 输入和输出仓库'
- en: '](img/B17085_02_002.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17085_02_002.jpg)'
- en: Figure 2.2 – Pachyderm input and output repositories
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – Pachyderm 输入和输出仓库
- en: The preceding diagram shows a simple use case with just one pipeline. However,
    your workflow could be much more complex with multiple pipelines being intertwined
    and working together to achieve the needed result.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图示展示了一个仅包含一个管道的简单用例。然而，您的工作流可能会更加复杂，多个管道可能会交织在一起共同工作，以实现所需的结果。
- en: Branch
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分支
- en: A **branch** is a Pachyderm line of development that tracks a set of changes
    within a repository. By default, a repository has no branches. The **master branch**
    that we will use in this book is just an example of how you can name your primary
    branch in Pachyderm, and it's not enforced. Typically, you create a branch on
    a repository when you upload initial data in the repository. You can create multiple
    branches to organize your work, but you likely won't use them as extensively as
    in Git. Often, just one branch is enough for all the work. You could create a
    separate branch for a different experiment. All branches are visible to all users,
    so you won't be able to have a local branch, experiment in it, and then merge
    it with the master branch as you do in Git.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**分支**是Pachyderm中的一个开发线，用于跟踪仓库中的一组变更。默认情况下，仓库没有分支。我们在本书中使用的**主分支**只是一个示例，用于说明如何在Pachyderm中命名您的主分支，并不强制要求。通常，在向仓库上传初始数据时，您会在仓库上创建一个分支。您可以创建多个分支来组织您的工作，但通常不会像在Git中那样广泛使用它们。通常，只用一个分支就足够完成所有工作了。您也可以为不同的实验创建一个单独的分支。所有分支对所有用户可见，因此您不能像在Git中那样拥有一个本地分支，在其中进行实验，再与主分支合并。'
- en: 'To create a branch, run the following:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建分支，请运行以下命令：
- en: '[PRE0]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The repository must exist before you can create a branch.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 必须在创建分支之前先存在仓库。
- en: 'To confirm that a branch was created, run the following:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 要确认分支是否已创建，请运行以下命令：
- en: '[PRE1]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The final part of this section will deal with the commit concept.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的最后部分将讨论提交概念。
- en: Commit
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提交
- en: A **commit** is a single immutable changeset of your data. For example, when
    new data is received from a streaming platform, such as **Kafka**, it is written
    to the Pachyderm repository as a new commit with an individual hash identifier.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**提交**是您数据的一个不可更改的变更集。例如，当从流媒体平台（如**Kafka**）接收新数据时，它会作为一个新提交写入到Pachyderm仓库，并附带一个唯一的哈希标识符。'
- en: 'The following diagram illustrates the concept of the commit on a branch in
    Pachyderm:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了Pachyderm中分支提交概念的示意图：
- en: '![Figure 2.3 – A diagram showing Pachyderm commits'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.3 – 显示Pachyderm提交的示意图'
- en: '](img/B17085_02_003.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17085_02_003.jpg)'
- en: Figure 2.3 – A diagram showing Pachyderm commits
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – 显示Pachyderm提交的示意图
- en: Data changes are stored in the repository history. The `HEAD` commit of the
    branch, moves every time a new commit is submitted to the repository. As soon
    as the new data is submitted, the pipeline runs the code against these latest
    changes unless a different behavior is explicitly configured.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 数据变更会存储在仓库历史记录中。每当向仓库提交新提交时，分支的`HEAD`提交会移动。一旦新数据提交，管道会根据这些最新的更改运行代码，除非明确配置了不同的行为。
- en: Now that we know the most important Pachyderm version control primitives, let's
    learn about the Pachyderm pipeline in more detail.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了最重要的Pachyderm版本控制原语，接下来让我们更详细地了解Pachyderm管道。
- en: Discovering pipeline elements
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索管道元素
- en: This section walks you through the main Pachyderm pipeline concepts. The **Pachyderm
    Pipeline System** (**PPS**) is the centerpiece of Pachyderm functionality.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将引导您了解Pachyderm管道的主要概念。**Pachyderm管道系统**（**PPS**）是Pachyderm功能的核心。
- en: A Pachyderm **pipeline** is a sequence of computational tasks that data undergoes
    before it outputs the final result. For example, it could be a series of image
    processing tasks, such as labeling each image or applying a photo filter. Or it
    could be a comparison between two datasets or a finding similarities task.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Pachyderm **管道**是数据在输出最终结果之前经过的一系列计算任务。例如，它可以是一系列图像处理任务，如为每个图像加标签或应用滤镜。也可以是两个数据集的比较或查找相似性任务。
- en: 'A pipeline performs the following three steps:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一个管道执行以下三个步骤：
- en: Downloads the data from a specified location.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从指定位置下载数据。
- en: Applies the transformation steps specified by your cod.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用您代码中指定的转换步骤。
- en: Outputs the result to a specified location.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果输出到指定位置。
- en: 'The following diagram shows how a Pachyderm pipeline works:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了Pachyderm管道的工作原理：
- en: '![Figure 2.4 – Pachyderm pipeline'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.4 – Pachyderm 管道'
- en: '](img/B17085_02_004.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17085_02_004.jpg)'
- en: Figure 2.4 – Pachyderm pipeline
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – Pachyderm 管道
- en: Each Pachyderm pipeline has an input and output repository. An input repository
    is a filesystem within Pachyderm where it is being placed from an outside source.
    This is the location inside of the pipeline Pod under the `/pfs` directory. The
    data can either be pulled by a pipeline or pushed to the input repository by the
    data source system. After the data goes through the transformation, it is placed
    into the output Pachyderm repository, which is located in the /`pfs/out` directory.
    From the output repository, the results can be further consumed by third-party
    applications or other pipelines.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 Pachyderm 管道都有输入和输出仓库。输入仓库是一个文件系统，数据从外部源传入 Pachyderm。它位于管道 Pod 内的 `/pfs`
    目录下。数据可以通过管道拉取，也可以由数据源系统推送到输入仓库。数据经过转换处理后，会被放入输出 Pachyderm 仓库，该仓库位于 `/pfs/out`
    目录下。之后，输出仓库中的结果可以被第三方应用或其他管道进一步使用。
- en: Every time new data lands in the input repository, Pachyderm starts a pipeline
    **job**. The job processes the newly arrived data and places the results in the
    output repository.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 每次新数据到达输入仓库时，Pachyderm 会启动一个管道**任务**。该任务处理新到的数据并将结果放入输出仓库。
- en: Types of pipelines
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道类型
- en: A machine learning pipeline continuously performs the tasks that the data scientists
    coded on the new data. For example, you might want to compare or join two types
    of files together or apply certain parameters to them. To simplify these tasks,
    Pachyderm offers predefined pipelines that can do those things automatically.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道持续执行数据科学家对新数据编写的任务。例如，您可能希望比较或合并两种类型的文件，或对它们应用特定的参数。为了简化这些任务，Pachyderm
    提供了预定义的管道，可以自动完成这些工作。
- en: 'Pachyderm offers the following types of pipelines:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Pachyderm 提供以下类型的管道：
- en: Standard pipeline
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准管道
- en: Cron pipeline
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cron 管道
- en: Spout pipeline
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spout 管道
- en: Service pipeline
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务管道
- en: To create a pipeline, you need to write a **pipeline specification**. A pipeline
    specification is a file in the **YAML Ain't Markup Language** (**YAML**) or **JavaScript
    Object Notation** (**JSON**) format that describes what the pipeline needs to
    do. We will talk about pipeline specifications in more detail in the next chapter.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建管道，您需要编写一个**管道规范**。管道规范是一个文件，采用**YAML 不是标记语言**（**YAML**）或**JavaScript 对象表示法**（**JSON**）格式，描述管道需要执行的任务。我们将在下一章详细讨论管道规范。
- en: Standard pipelines
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标准管道
- en: A **standard pipeline**, or simply a pipeline, is the most straightforward way
    to schedule work in a Pachyderm cluster. This type of pipeline is triggered when
    new data lands in the Pachyderm input repository. The pipeline spawns or resumes
    a Kubernetes Pod to run your code against the newly landed data and outputs the
    result to the output repository. The output repository is created automatically
    and has the same name as the pipeline.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**标准管道**，简称管道，是在 Pachyderm 集群中调度工作的最直接方式。此类管道在新数据进入 Pachyderm 输入仓库时触发。管道启动或恢复一个
    Kubernetes Pod 来运行您的代码，并针对新到的数据生成输出结果，结果将存放在输出仓库中。输出仓库会自动创建，并与管道同名。'
- en: 'The simplest standard pipeline must have the following components:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的标准管道必须包含以下组件：
- en: '`name`: A descriptive name for your pipeline. It is good practice to give your
    pipeline a name that reflects the task it accomplishes. For example, if your code
    analyzes the sentiment of users'' feeds on social media, you might want to call
    it `sentiment-analysis` or something similar.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：管道的描述性名称。为管道命名时，最好选择一个能反映其完成任务的名称。例如，如果您的代码分析社交媒体上用户的情感，您可能希望将其命名为 `sentiment-analysis`
    或类似名称。'
- en: '`transform`: The transformation section of a pipeline contains the information
    about the Docker image that the pipeline needs to pull and use and the code that
    it needs to run in the pipeline container. For example, if you are doing sentiment
    analysis, you probably will use **Natural Language Processing** (**NLP**) tools
    such as **Natural Language Toolkit** (**NLTK**) or **Stanford CoreNLP**. Therefore,
    you can use either an already available Docker image for those tools or build
    your own custom one.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transform`：管道的转换部分包含有关管道需要拉取和使用的 Docker 镜像以及在管道容器中运行的代码的信息。例如，如果您正在进行情感分析，您可能会使用**自然语言处理**（**NLP**）工具，如**自然语言工具包**（**NLTK**）或**斯坦福
    CoreNLP**。因此，您可以使用已有的 Docker 镜像，或者构建自己的定制镜像。'
- en: '`input`: An input repository from which the pipeline grabs data for processing.
    You will need to upload the data to an input repository either through the CLI,
    UI, or API.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input`：一个输入存储库，管道从中获取数据进行处理。您需要通过CLI、UI或API将数据上传到输入存储库。'
- en: 'The following text is an example of a pipeline specification that performs
    sentiment analysis. The pipeline is called `sentiment-analyzer`, uses the Docker
    image called `ntlk-image`, downloads data from the input repository called `feed`,
    and then runs the code stored in the file called `transform_code.py`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的文本是执行情感分析的管道规范示例。该管道称为`sentiment-analyzer`，使用名为`ntlk-image`的Docker镜像，从名为`feed`的输入存储库下载数据，然后运行存储在名为`transform_code.py`的文件中的代码：
- en: '[PRE2]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `glob` parameter defines how to break down data into processable chunks
    that can be spread across multiple Pachyderm workers for better performance. We
    will discuss this parameter in more detail in the next section.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`glob`参数定义如何将数据分解为可在多个Pachyderm工作节点上处理的可处理块，以提高性能。我们将在下一节详细讨论此参数。'
- en: Important note
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You can either put your transformation code in a file like in the example above
    or specify it directly in the `cmd` field. See [*Chapter 3*](B17085_03_Final_SB_Epub.xhtml#_idTextAnchor055),
    *Pachyderm Pipeline Specification*, for more information.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以像上面的示例中那样将转换代码放在文件中，也可以直接在`cmd`字段中指定。有关更多信息，请参阅[*第三章*](B17085_03_Final_SB_Epub.xhtml#_idTextAnchor055)，*Pachyderm管道规范*。
- en: Cron pipelines
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Cron管道
- en: A **Cron** pipeline, or cron, is a pipeline that runs a specific task periodically.
    If you are familiar with the **UNIX** software utility cron, the Cron pipeline
    uses a similar logic—it runs periodically according to the specified schedule
    and performs the same task every time. Unlike the standard pipeline that runs
    every time new data arrives in the input repository, the Cron pipeline runs according
    to a schedule. You might want to use this pipeline to periodically scrape a website
    or a table.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**Cron**管道或cron是定期运行特定任务的管道。如果您熟悉UNIX软件实用程序cron，则Cron管道使用类似的逻辑——它按照指定的时间表定期运行，并每次执行相同的任务。与标准管道不同，标准管道在输入存储库中有新数据到达时运行，Cron管道则按照时间表运行。您可能希望使用此管道定期抓取网站或表。'
- en: A Cron pipeline specification would look very similar to the standard pipeline
    apart from the input section. You need to specify the time interval in the input
    section for your pipeline.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Cron管道规范看起来与标准管道非常相似，除了输入部分。您需要在管道的输入部分指定时间间隔。
- en: 'The following text is an example of a Cron pipeline in YAML format that scrapes
    a website called `my-website` once a day at midnight:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的文本是以YAML格式呈现的Cron管道示例，每天午夜定时抓取名为`my-website`的网站：
- en: '[PRE3]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: All the information about the website URL will go into your `scraper.py` file.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 所有有关网站URL的信息将放入您的`scraper.py`文件中。
- en: Spout pipelines
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 喷口管道
- en: A **s****pout** pipeline, or spout, as the name suggests, is designed to stream
    data from an outside source, such as a publish/subscribe messaging system. In
    your infrastructure, you might have multiple message queue systems. With a Pachyderm
    spout, you can consolidate inputs from all of these systems and inject them into
    a Pachyderm spout pipeline. The spout code is not triggered by any event; instead,
    it runs continuously, listening for new messages.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**s****pout**管道或spout顾名思义，旨在从外部源（例如发布/订阅消息系统）流式传输数据。在您的基础设施中，您可能有多个消息队列系统。通过Pachyderm喷口，您可以将所有这些系统的输入整合到Pachyderm喷口管道中。喷口代码不受任何事件触发；相反，它连续运行，监听新消息的到来。'
- en: Unlike in a standard or a Cron pipeline, spouts do not have an input repository,
    but instead, they listen on a specified address. The port and host can be specified
    either as an `env` variable in the pipeline specification or inside of the container.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 与标准管道或Cron管道不同，喷口没有输入存储库，而是在指定地址上侦听。端口和主机可以在管道规范的`env`变量中或容器内部指定。
- en: Often, a spout is used together with a Pachyderm **Service** pipeline to expose
    the results of the pipeline because the data in the spout's output repository
    cannot be accessed with standard Pachyderm commands.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 常见情况下，一个喷口与Pachyderm **服务**管道一起使用，用于暴露管道的结果，因为喷口输出存储库中的数据无法通过标准的Pachyderm命令访问。
- en: 'The following text is an example of a spout pipeline in YAML format that connects
    to an Amazon `myscript.py`, to the messages:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的文本是以YAML格式呈现的喷口管道示例，连接到Amazon `myscript.py`，用于处理消息：
- en: '[PRE4]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `spout` section is left empty, but this is the place where you can combine
    the spout with a service pipeline to expose the results of the pipeline to the
    outside world.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`spout`部分为空，但这是你可以将喷口与服务管道结合，向外界暴露管道结果的地方。'
- en: Service pipelines
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务管道
- en: A **service** pipeline, or service, is a pipeline that can expose your output
    repository to the outside world. Unlike other pipelines, it does not perform any
    modifications to your data. The only function of this pipeline is to serve the
    results for your pipeline as an API, for example, in the form of a dashboard.
    A service pipeline is often combined with a spout pipeline and is sometimes called
    **spout-service**. However, it can use the results from any other pipeline output
    repository as its own input repository to expose the results.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**服务**管道，或称服务，是一种可以将输出仓库暴露给外部世界的管道。与其他管道不同，它不会对数据进行任何修改。此管道的唯一功能是通过 API 为你的管道结果提供服务，例如以仪表板的形式。服务管道通常与喷口管道结合使用，有时被称为**喷口服务**。然而，它可以使用来自任何其他管道输出仓库的结果作为其输入仓库来暴露这些结果。'
- en: 'A pipeline specification for this pipeline misses the transformation section.
    The following text is an example of a service pipeline in YAML format:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 该管道的管道规范缺少转换部分。以下文本是一个服务管道的 YAML 格式示例：
- en: '[PRE5]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Next, we'll see how Pachyderm works with datum.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看看 Pachyderm 如何处理数据项。
- en: Datum
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据项
- en: '`glob` parameter in the pipeline specification. Pachyderm processes each datum
    independently. If you have more than one worker running your pipeline, Pachyderm
    can schedule datums to run on separate workers for faster processing and, in the
    end, all datums are merged back together in the output repository.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 管道规范中的`glob`参数。Pachyderm 会独立处理每个数据项。如果你有多个工作节点运行管道，Pachyderm 可以将数据项调度到不同的工作节点上进行更快速的处理，最终所有数据项将在输出仓库中合并。
- en: Datums
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 数据项
- en: This is the term used by the Pachyderm folks. Yes, usually, the plural is data,
    but **datums** is how it appears throughout Pachyderm's documentation!
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Pachyderm 团队使用的术语。是的，通常复数形式是 data，但**数据项**在 Pachyderm 的文档中是这样出现的！
- en: 'Breaking down your data into multiple datums provides the following advantages:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据拆分成多个数据项带来以下优势：
- en: Improves performance by scaling your pipeline to multiple Pachyderm workers
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将管道扩展到多个 Pachyderm 工作节点来提高性能
- en: Enables you to process only specific files and folders
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使你能够仅处理特定的文件和文件夹
- en: 'For example, say you have a repository with the following folder structure:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你有一个具有以下文件夹结构的仓库：
- en: '[PRE6]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For this folder structure, you can set the following types of glob patterns:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此文件夹结构，你可以设置以下几种类型的 glob 模式：
- en: '`/`: Process all files and folders as a single datum. This single datum includes
    all files and folders in the `/` directory.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/`：将所有文件和文件夹作为单一的数据项进行处理。这个单一的数据项包括`/`目录中的所有文件和文件夹。'
- en: '`/*`: Process each folder as a separate datum. The resulting number of datums
    is three, including the following:'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/*`：将每个文件夹作为单独的数据项进行处理。结果的数据项数为三个，包括以下内容：'
- en: '[PRE7]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`/*/*`: Process each filesystem object on the `/*/*` level as a separate datum.
    The resulting number of datums is seven, including the following:'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/*/*`：将`/*/*`级别上的每个文件系统对象作为单独的数据项进行处理。结果的数据项数为七个，包括以下内容：'
- en: '[PRE8]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`/*/*/*`: Process each filesystem on the third level. The resulting number
    of datums is five, including the following:'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/*/*/*`：将第三级的每个文件系统对象作为单独的数据项进行处理。结果的数据项数为五个，包括以下内容：'
- en: '[PRE9]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`/**`: Process each file, folder, and subfolder as a separate datum. The resulting
    number is 15, which includes all files and folders listed in the preceding code
    extract:'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/**`：将每个文件、文件夹和子文件夹作为单独的数据项进行处理。结果是15，包括以下代码提取中的所有文件和文件夹：'
- en: '[PRE10]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`/<filesystem>/*`: Process only the files and folders that match the naming
    pattern. For example, if you decide to process only the data in `folder1`, you
    will set your glob pattern to `/folder1/*`. Similarly, you can set just the first
    few letters of a directory name as a glob pattern.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/<filesystem>/*`：仅处理与命名模式匹配的文件和文件夹。例如，如果你只想处理`folder1`中的数据，你将设置 glob 模式为`/folder1/*`。类似地，你可以仅将目录名的前几个字母作为
    glob 模式。'
- en: These are the most commonly used glob patterns. Extended glob patterns are available
    with the Pachyderm's `ohmyglob` library. For more information, see [https://github.com/pachyderm/ohmyglob](https://github.com/pachyderm/ohmyglob).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是最常用的 glob 模式。Pachyderm 的 `ohmyglob` 库提供了扩展的 glob 模式。更多信息请参见 [https://github.com/pachyderm/ohmyglob](https://github.com/pachyderm/ohmyglob)。
- en: Scaling your pipeline with datums
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过数据项扩展管道
- en: One of the biggest advantages of breaking your data into multiple datums is
    the ability to scale your work across multiple pipeline workers to significantly
    improve the performance and the processing time of your pipeline. By default,
    Pachyderm deploys one worker node for each pipeline, but you can increase this
    number as needed by specifying the `parallelism_spec` parameter in the pipeline
    specification.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据分成多个数据项的最大优势之一是可以将工作扩展到多个管道工作节点，从而显著提高管道的性能和处理时间。默认情况下，Pachyderm 为每个管道部署一个工作节点，但你可以根据需要通过在管道规范中指定
    `parallelism_spec` 参数来增加节点数量。
- en: 'The following diagram demonstrates how datums are scaled across multiple workers:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了数据项如何在多个工作节点之间扩展：
- en: '![Figure 2.5 – Scaling a pipeline'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.5 – 扩展管道'
- en: '](img/B17085_02_005.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17085_02_005.jpg)'
- en: Figure 2.5 – Scaling a pipeline
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5 – 扩展管道
- en: In the preceding diagram, the input data is broken down into three workers,
    which simultaneously start the processing. After all of the datums are processed,
    they are merged into the final output result. It is important to emphasize that
    datums only exist inside of a Pachyderm pipeline. They cannot be accessed, mounted,
    or modified in any way.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，输入数据被拆分到三个工作节点上，它们同时开始处理。在所有数据项处理完成后，它们会合并为最终的输出结果。需要强调的是，数据项仅存在于 Pachyderm
    管道内部，不能以任何方式访问、挂载或修改。
- en: Pachyderm inputs
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pachyderm 输入
- en: In Pachyderm, you likely will create multiple repositories to store training
    data, testing data, and parameters. Pachyderm provides an automated way to combine
    files in different repositories in the pipeline to be processed together through
    the use of **inputs**. If you have used SQL before, you might find that these
    types of inputs remind you of SQL operators. However, there is one major difference
    that distinguishes SQL operators from Pachyderm inputs. While in SQL you can create
    matching pairs of rows in each table, Pachyderm inputs work on the file level
    only. This means that you can only combine files or directories inside Pachyderm
    repositories based on their names rather than the contents of the files.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Pachyderm 中，你可能会创建多个仓库来存储训练数据、测试数据和参数。Pachyderm 提供了一种自动化的方法，通过使用 **输入** 将不同仓库中的文件结合在一起，在管道中一起处理。如果你以前使用过
    SQL，可能会发现这些输入类似于 SQL 操作符。然而，有一个主要的区别将 SQL 操作符与 Pachyderm 输入区分开来。在 SQL 中，你可以在每个表中创建匹配的行对，而
    Pachyderm 输入仅在文件级别上工作。这意味着你只能根据文件的名称而不是文件的内容，将 Pachyderm 仓库中的文件或目录结合在一起。
- en: Important note
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This section provides examples of how you can create various Pachyderm inputs.
    These examples are for your reference only and you might want to use some of them
    in your future Pachyderm work after you install and configure Pachyderm. We will
    cover the installation and setup in the *Installing Pachyderm locally* and *Deploying
    Pachyderm on a cloud platform* sections of [*Chapter 3*](B17085_03_Final_SB_Epub.xhtml#_idTextAnchor055),
    *Pachyderm Pipeline Specification*.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了如何创建各种 Pachyderm 输入的示例。这些示例仅供参考，你可能会在安装和配置 Pachyderm 后在未来的工作中使用其中的一些。我们将在
    [*第3章*](B17085_03_Final_SB_Epub.xhtml#_idTextAnchor055)的 *本地安装 Pachyderm* 和 *在云平台上部署
    Pachyderm* 部分中介绍安装和配置。
- en: Cross inputs
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 交叉输入
- en: A `cross` input, or cross, is an input in which each file from one repository
    is combined with a file in the other repository. The set of matched files is determined
    by the glob pattern, and all that data is visible to the pipeline code at the
    time of the pipeline run.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`cross` 输入，或称交叉输入，是一种将一个仓库中的每个文件与另一个仓库中的文件进行结合的输入。匹配文件的集合由全局模式决定，在管道运行时，所有数据都对管道代码可见。'
- en: 'The input part of your pipeline file in YAML format might look like this:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 你的管道文件中的输入部分（YAML 格式）可能如下所示：
- en: '[PRE11]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'For example, you have two Pachyderm repositories, `data` and `parameters`,
    with the following structure and files:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你有两个 Pachyderm 仓库，`data` 和 `parameters`，其结构和文件如下：
- en: '[PRE12]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'If you create a pipeline that creates a cross-product of these repositories
    with a glob pattern set to `/*`, you will get eight datums in total—each file
    from the `data` repository will be combined with each file in the `parameters`
    repository. This is how the files will be processed:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你创建一个管道，该管道通过设置全局模式 `/*` 来创建这些仓库的笛卡尔积，你将总共得到八个数据项——`data` 仓库中的每个文件将与 `parameters`
    仓库中的每个文件结合。这些文件将按以下方式处理：
- en: '[PRE13]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In the preceding output, each pair of files and each line is one datum.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，每对文件和每一行代表一个数据项。
- en: Union inputs
  id: totrans-182
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 联合输入
- en: A union input, or union, is an input that enables you to combine datums from
    one repository with datums in another repository. The total number of datums is
    the sum of datums in all repositories. If we take the same repository structure
    as described in the *Cross inputs* section and, instead of creating a cross-product,
    just add them to each other by using the `union` input, we will have a total of
    five datums.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 一个联合输入（或称为union）是一个允许你将一个仓库中的数据项与另一个仓库中的数据项合并的输入。数据项的总数是所有仓库中数据项的总和。如果我们采用与*交叉输入*部分描述相同的仓库结构，并且不是生成交叉积，而是使用
    `union` 输入将它们相加，我们将得到五个数据项的总数。
- en: 'The `input` part of your pipeline file in YAML format might look like this:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 您的管道文件中的 `input` 部分在 YAML 格式中可能如下所示：
- en: '[PRE14]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following output demonstrates the list of datums for a pipeline with the
    `/*` glob pattern set for both repositories:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出演示了设置了 `/*` 通配符模式的两个仓库的管道数据项列表：
- en: '[PRE15]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Your code processes each file individually and recognizes only one file with
    every run, ignoring all other files.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 您的代码会单独处理每个文件，并且每次运行时只会识别一个文件，忽略其他所有文件。
- en: Join inputs
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 连接输入
- en: A `join_on` parameter in your Pachyderm pipeline.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 您的 Pachyderm 管道中的 `join_on` 参数。
- en: Pachyderm separates **inner joins** and **outer joins**. The difference between
    the two is that an inner join matches pairs of files, skipping files that do not
    match the specified pattern. An outer join acts the same way as an inner join,
    but also includes files that do not match the pattern in the pipeline run. If
    this sounds a bit confusing, the following example should clarify how the pipeline
    works.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Pachyderm 区分 **内部连接** 和 **外部连接**。它们之间的区别在于，内部连接匹配文件对，跳过不符合指定模式的文件。外部连接与内部连接的行为相同，但还包括那些不符合模式的文件在管道运行中。如果这听起来有些混淆，下面的示例应该可以帮助澄清管道的工作方式。
- en: 'Let''s say you have two repositories, `data` and `parameters`, and the `parameters`
    repo has the following structure:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您有两个仓库，`data` 和 `parameters`，并且 `parameters` 仓库具有以下结构：
- en: '[PRE16]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `data` repository has the following structure:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`data` 仓库具有以下结构：'
- en: '[PRE17]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In your pipeline, you might want to match the files by their date. To do so,
    you would have to specify a capturing group of `$1` and a glob pattern, `/`. Here
    is an example of a pipeline specification in YAML format that matches these file
    paths:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的管道中，您可能希望按日期匹配文件。为此，您需要指定捕获组 `$1` 和通配符模式 `/`。以下是一个在 YAML 格式中匹配这些文件路径的管道规范示例：
- en: '[PRE18]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This capturing group in combination with the `/` glob pattern matches five
    pairs of files:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这个捕获组结合 `/` 通配符模式匹配了五对文件：
- en: '[PRE19]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '`/data-0106-2021.txt` and `/data-0107-2021.txt` do not have matching pairs,
    and therefore, Pachyderm would skip them in this run. However, if you want to
    include these in the files in the pipeline run, you can specify `outer_join: true`
    in the `data` repository input to include these files in the pipeline run without
    a pair. This abstract shows how you can add this parameter:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`/data-0106-2021.txt` 和 `/data-0107-2021.txt` 没有匹配的配对，因此 Pachyderm 会在此运行中跳过它们。但是，如果您希望将这些文件包含在管道运行中，可以在
    `data` 仓库输入中指定 `outer_join: true`，以在没有配对的情况下将这些文件包括在管道运行中。以下抽象展示了如何添加此参数：'
- en: '[PRE20]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then the list of datums in your pipeline will look like this:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您的管道中的数据项列表将如下所示：
- en: '[PRE21]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '`data-0106-2021.txt` and `data-0107-2021` are included in the pipeline run
    without a pair.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`data-0106-2021.txt` 和 `data-0107-2021` 在管道运行中被包含，但没有配对。'
- en: Group inputs
  id: totrans-205
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 组输入
- en: A `group_by` pipeline parameter. If we took the same pipeline that we used in
    the inner join input example and replaced `join` with `group` and `join_on` with
    `group_by`, we would get the exact same result as we got with the inner join input.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `group_by` 管道参数。如果我们采用与内部连接输入示例中相同的管道，并将 `join` 替换为 `group`，将 `join_on` 替换为
    `group_by`，我们将得到与内部连接输入相同的结果。
- en: 'The main differences from the join input include the following:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 与连接输入的主要区别包括以下几点：
- en: A group input creates one large datum of the files that match a naming pattern,
    while a join crosses two files that match a pattern and typically creates more
    datums.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个组输入会生成一个包含符合命名模式的文件的大数据项，而连接则会交叉匹配两个符合模式的文件，通常会生成更多的数据项。
- en: A group input enables you to match pairs in a single repository, while a join
    requires at least two repositories.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组输入使您能够在单一仓库中匹配文件对，而连接则需要至少两个仓库。
- en: A group input is primarily useful in time series scenarios when you need to
    group files based on their timestamps.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组输入在时间序列场景中尤其有用，尤其是在您需要根据时间戳对文件进行分组时。
- en: Therefore, you could create a `cron` pipeline with the replacement group that
    matches a specific timestamp.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以创建一个带有替换组的 `cron` 流水线，该替换组匹配特定的时间戳。
- en: 'For example, say you have repository data with the following structure:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你有一个数据仓库，其结构如下：
- en: '[PRE22]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Your pipeline in YAML format might look like this:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 YAML 格式创建如下的流水线：
- en: '[PRE23]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: You have two replacement groups listed in the pipeline. Replacement group one
    matches the month and day in the name of the text file. For example, in the file
    `/data-0104-2021.txt`, it is `0104`. The second replacement group matches the
    year in the timestamp. In the same file, it is `2021`.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 你的流水线中列出了两个替换组。第一个替换组匹配文本文件名称中的月日。例如，在文件 `/data-0104-2021.txt` 中，它是 `0104`。第二个替换组匹配时间戳中的年份。在同一个文件中，它是
    `2021`。
- en: 'If you specify the first matching group in your pipeline, the resulting list
    of datums will include three pairs and seven datums in total:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在流水线中指定了第一个匹配组，最终的数据列表将包含三对数据，总共七个数据项：
- en: '[PRE24]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In the preceding output, the files with the matching day and month, such as
    `0101`, are grouped in one datum. If you change the `group_by` parameter to use
    the second replacement group, meaning grouping by year, the list of datums will
    include two datums, grouping the files by year:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，匹配的日期和月份的文件，如 `0101`，被分组为一个数据项。如果你将 `group_by` 参数更改为使用第二个替换组，即按年份分组，则数据列表将包含两个数据项，将文件按年份分组：
- en: '[PRE25]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In this section, we have learned about the most important Pachyderm pipeline
    primitives and how they differ from each other.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了最重要的 Pachyderm 流水线原语及其相互之间的区别。
- en: Summary
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have learned about the most important Pachyderm version
    control primitives, including repositories, branches, and commits. We reviewed
    that although they are similar to those of the Git version control system, they
    have a few very important differences.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们了解了最重要的 Pachyderm 版本控制原语，包括仓库、分支和提交。我们回顾了这些与 Git 版本控制系统相似，但也存在一些非常重要的区别。
- en: We've learned about the types of Pachyderm pipelines and inputs and how a pipeline
    can be scaled and optimized through the use of glob patterns and datums.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了 Pachyderm 流水线和输入的类型，以及如何通过使用通配符模式和数据项来扩展和优化流水线。
- en: In the next chapter, we will review the Pachyderm pipeline specification in
    more detail and will learn how to use the various pipeline settings to run a pipeline
    in the most efficient way.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更详细地回顾 Pachyderm 流水线规范，并学习如何使用各种流水线设置以最有效的方式运行流水线。
- en: Further reading
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Git documentation: [https://git-scm.com/](https://git-scm.com/)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Git 文档: [https://git-scm.com/](https://git-scm.com/)'
- en: 'Kubernetes documentation: [https://kubernetes.io/docs/home](https://kubernetes.io/docs/home)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kubernetes 文档: [https://kubernetes.io/docs/home](https://kubernetes.io/docs/home)'
- en: 'Helm documentation: [https://helm.sh/docs/](https://helm.sh/docs/)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Helm 文档: [https://helm.sh/docs/](https://helm.sh/docs/)'
