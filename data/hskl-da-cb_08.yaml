- en: Chapter 8. Clustering and Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 聚类与分类
- en: 'This chapter demonstrates algorithms that intelligently cluster and categorize
    data:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了智能地聚类和分类数据的算法：
- en: Implementing the k-means clustering algorithm
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现k-means聚类算法
- en: Implementing hierarchical clustering
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现层次聚类
- en: Using a hierarchical clustering library
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用层次聚类库
- en: Finding the number of clusters
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找聚类的数量
- en: Clustering words by their lexemes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按词根对单词进行聚类
- en: Classifying the parts of speech of words
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对词汇进行词性分类
- en: Identifying key words in a corpus of text
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在文本语料库中识别关键字
- en: Training a parts-of-speech tagger
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练一个词性标注器
- en: Implementing a decision tree classifier
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现决策树分类器
- en: Implementing a k-Nearest Neighbors classifier
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现k-最近邻分类器
- en: Visualizing points using Graphics.EasyPlot
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Graphics.EasyPlot可视化数据点
- en: Introduction
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '![Introduction](img/ch08.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![介绍](img/ch08.jpg)'
- en: Computer algorithms are becoming better and better at analyzing large datasets.
    As their performance enhances, their ability to detect interesting patterns in
    data also improves.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机算法在分析大型数据集方面变得越来越优秀。随着性能的提升，它们检测数据中有趣模式的能力也在增强。
- en: The first few algorithms in this chapter demonstrate how to look at thousands
    of points and identify clusters. A **cluster** is simply a congregation of points
    defined by how closely they lie together. This measure of "closeness" is entirely
    up to us. One of the most popular closeness metrics is the Euclidian distance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章前几个算法展示了如何查看成千上万的数据点并识别聚类。**聚类**只是通过数据点之间的紧密程度来定义的一个集合。这个“紧密度”的度量完全由我们决定。其中一种最常用的紧密度度量是欧几里得距离。
- en: We can understand clusters by looking up at the night sky and pointing at stars
    that appear together. Our ancestors found it convenient to name "clusters" of
    stars, of which we refer to as constellations. We will be finding our own constellations
    in the "sky" of data points.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过仰望夜空并指向看似聚集在一起的星星来理解聚类。我们的祖先发现将星星“聚集”命名为星座很方便。我们将会在数据点的“天空”中找到属于自己的星座。
- en: This chapter also focuses on classifying words. We will label words by their
    parts of speech as well as topic.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还重点介绍了词汇的分类。我们将根据词语的词性以及主题为其标注标签。
- en: We will implement our own decision tree to classify practical data. Lastly,
    we will visualize clusters and points using plotting libraries.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实现自己的决策树来分类实际数据。最后，我们将使用绘图库可视化聚类和数据点。
- en: Implementing the k-means clustering algorithm
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现k-means聚类算法
- en: The k-means clustering algorithm partitions data into k different groups. These
    k groupings are called clusters, and the location of these clusters are adjusted
    iteratively. We compute the arithmetic mean of all the points in a group to obtain
    a centroid point that we use, replacing the previous cluster location.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: k-means聚类算法将数据划分为k个不同的组。这些k个组叫做聚类，而这些聚类的位置是通过迭代调整的。我们计算组内所有点的算术平均值，以获得一个质心点，并用它替代之前的聚类位置。
- en: 'Hopefully, after this succinct explanation, the name *k-means clustering* no
    longer sounds completely foreign. One of the best places to learn more about this
    algorithm is on Coursera: [https://class.coursera.org/ml-003/lecture/78](https://class.coursera.org/ml-003/lecture/78).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 希望通过这个简明的解释，*k-means聚类*这个名字不再听起来完全陌生。了解更多关于该算法的最佳途径之一是在Coursera上：[https://class.coursera.org/ml-003/lecture/78](https://class.coursera.org/ml-003/lecture/78)。
- en: How to do it…
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点……
- en: 'Create a new file, which we call `Main.hs`, and perform the following steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新文件，命名为`Main.hs`，并执行以下步骤：
- en: 'Import the following built-in libraries:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下内置库：
- en: '[PRE0]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Define a type synonym for points shown as follows:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义如下所示的点的类型同义词：
- en: '[PRE1]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Define the Euclidian distance function between two points:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义两点之间的欧几里得距离函数：
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Define the assignment step in the k-means algorithm. Each point will be assigned
    to its closest centroid:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义k-means算法中的分配步骤。每个点将被分配到其最接近的质心：
- en: '[PRE3]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Define the relocation step in the k-means algorithm. Each centroid is relocated
    to the arithmetic mean of its corresponding points:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义k-means算法中的重新定位步骤。每个质心都被重新定位到其对应点的算术平均值：
- en: '[PRE4]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Run the k-means algorithm repeatedly until the centroids no longer move around:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 反复运行k-means算法，直到质心不再移动：
- en: '[PRE5]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Test out the clustering with a couple of hardcoded points. The usual way to
    implement k-means chooses the starting centroids randomly. However, in this recipe,
    we will simply take the first k points:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过几个硬编码点测试聚类。实现 k-means 的通常方法是随机选择起始质心。但是，在这个例子中，我们将简单地采用前 k 个点：
- en: '[PRE6]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After the algorithm converges, the resulting centroids will be as follows:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当算法收敛后，最终的质心将如下所示：
- en: '[PRE7]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: How it works…
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: The algorithm repeatedly follows two procedures until the clusters are found.
    The first procedure is to partition the points by assigning each point to its
    closest centroid. The following diagram shows the data assignment step. Initially,
    there are three centroids represented by a star, square, and circle around three
    different points. The first part of the algorithm assigns each point a corresponding
    centroid.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法重复执行两个过程，直到找到聚类。第一个过程是通过将每个点分配到其最近的质心来分区点。下面的图表显示了数据分配步骤。最初有三个由星号、正方形和圆圈表示的质心，围绕三个不同的点。算法的第一部分将每个点分配到相应的质心。
- en: '![How it works…](img/6331OS_08_01.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理…](img/6331OS_08_01.jpg)'
- en: 'The next step is to relocate the centroids to the center, or arithmetic mean,
    of their corresponding points. In the following diagram, the arithmetic mean of
    each cluster is computed, and the centroid is shifted to the new center:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤是将质心重新定位到它们对应点的中心或算术平均值。在下面的图表中，计算了每个聚类的算术平均值，并将质心移至新的中心：
- en: '![How it works…](img/6331OS_08_02.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理…](img/6331OS_08_02.jpg)'
- en: This algorithm continues until the centroids no longer move around. The final
    categorization of each point is the cluster to which each point belongs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法持续进行，直到质心不再移动。每个点的最终分类是其所属的聚类。
- en: There's more…
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: Although easy to implement and understand, this algorithm has a couple of limitations.
    The output of the k-means clustering algorithm is sensitive to the initial centroids
    chosen. Also, using the Euclidian distance metric forces the clusters to be described
    only by circular regions. Another limitation of k-means clustering is that the
    initial number of clusters k must be specified by the user. The user should visualize
    the data and use their judgment to determine the number of clusters before beginning
    the algorithm. Moreover, the convergence condition for the algorithm is an issue
    for special edge-cases.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管易于实现和理解，但是这种算法有几个局限性。k-means 聚类算法的输出对选择的初始质心敏感。此外，使用欧氏距离度量迫使聚类仅通过圆形区域描述。k-means
    聚类的另一个局限是用户必须指定初始聚类数 k。用户应该可视化数据并根据自己的判断确定算法开始前的聚类数量。此外，算法的收敛条件对于特殊边界情况是一个问题。
- en: See also
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: For another type of clustering algorithm, see the next recipe on *Implementing
    hierarchical clustering*.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于另一种类型的聚类算法，请参阅下一个关于*实现分层聚类*的章节。
- en: Implementing hierarchical clustering
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现分层聚类
- en: Another way to cluster data is by first assuming each data item as its own cluster.
    We can then take a step back and merge together two of the nearest clusters. This
    process forms a hierarchy of clusters.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种聚类数据的方法是首先假设每个数据项是其自身的一个独立聚类。然后，我们可以退一步，合并两个最近的聚类。这个过程形成了一个聚类的层次结构。
- en: Take, for example, an analogy relating to islands and water level. An island
    is nothing more than a mountain tip surrounded by water. Imagine we have islands
    scattered across a sea. If we were to slowly drop the water level of the sea,
    two nearby small islands would merge into a larger island because they are connected
    to the same mountain formation. We can stop the water level from dropping any
    time we have the desired number of larger islands.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，可以类比于岛屿和水平面的类比。岛屿仅仅是被水包围的山顶。想象一下我们在海洋中散布着岛屿。如果我们慢慢降低海洋水位，两个附近的小岛屿将会合并成一个更大的岛屿，因为它们与同一山脉连接。我们可以在得到所需数量的较大岛屿时停止水位的下降。
- en: How to do it…
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'In a new file, which we name `Main.hs`, insert this code:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新文件中，我们命名为`Main.hs`，插入以下代码：
- en: 'Import the built-in functions:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入内置函数：
- en: '[PRE8]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Define a type synonym for points:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为点定义一个类型同义词：
- en: '[PRE9]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Define a convenience function to compute the arithmetic mean of list of points:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个方便的函数来计算点列表的算术平均值：
- en: '[PRE10]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Combine the two clusters that are nearest to each other:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 组合两个最接近的聚类：
- en: '[PRE11]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Run the hierarchical algorithm until there are k clusters:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行分层算法直到有 k 个聚类：
- en: '[PRE12]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Initialize so that every point is its own cluster:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化，使每个点都是其自身的一个聚类：
- en: '[PRE13]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Test the clustering algorithm on some input:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一些输入上测试聚类算法：
- en: '[PRE14]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The algorithm will output the following centroids:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法将输出以下质心：
- en: '[PRE15]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: How it works…
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何工作……
- en: There are two main ways to implement hierarchical clustering. The algorithm
    described in this recipe implements the *agglomerative* bottom-up approach. Each
    point is pre-emptively considered to be a cluster, and at each step the two closest
    clusters merge together. However, another approach to implement is top-down in
    a *divisive* approach where every point starts in one massive cluster that iteratively
    splits the clusters.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类的实现方法主要有两种。本示例中的算法实现了*凝聚型*自底向上的方法。每个点最初被视为一个聚类，在每一步中，两个最接近的聚类合并在一起。然而，另一种实现方法是自顶向下的*分裂型*方法，每个点最开始都在一个大聚类中，并逐步分裂成多个小聚类。
- en: 'In this recipe, we begin by first assuming that every point is its own cluster.
    Then we take a step back and merge two of the nearest clusters. This step repeats
    until a desired convergence state is reached. In our example, we stop once we
    have exactly two clusters. The following diagram shows the three iterations of
    a hierarchical clustering algorithm:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们首先假设每个点都是自己的聚类。然后，我们退后一步，将两个最接近的聚类合并。这一过程重复进行，直到达到期望的收敛状态。在我们的示例中，一旦得到正好两个聚类，我们就停止。下图展示了层次聚类算法的三次迭代过程：
- en: '![How it works…](img/6331OS_08_03.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作……](img/6331OS_08_03.jpg)'
- en: There's more…
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: Like most clustering algorithms, the choice of distance metric greatly affects
    the results. In this recipe, we assumed the Euclidean metric, but depending on
    the data, perhaps the distance metric should be the Manhattan distance or cosine
    similarity.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数聚类算法一样，距离度量的选择对结果有很大影响。在这个示例中，我们假设使用欧几里得度量，但根据数据的不同，可能应该使用曼哈顿距离或余弦相似度。
- en: See also
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: For a non-hierarchical clustering algorithm, see the previous recipe on *Implementing
    the k-means clustering algorithm*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非层次聚类算法，请参见之前的示例*实现 k-means 聚类算法*。
- en: Using a hierarchical clustering library
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用层次聚类库
- en: We will group together a list of points using a hierarchical clustering approach.
    We will start by assuming that each point is its own cluster. The two closest
    clusters merge together and the algorithm repeats until the stopping criteria
    is met. In this algorithm, we will use a library to run hierarchical clustering
    until there are a specific number of clusters remaining.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用层次聚类方法将一组点聚合在一起。我们从假设每个点都是自己的聚类开始。两个最接近的聚类合并在一起，算法重复这一过程，直到满足停止条件为止。在这个算法中，我们将使用一个库来执行层次聚类，直到剩下指定数量的聚类。
- en: Getting ready
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备开始
- en: 'Install the hierarchical clustering package using cabal as follows (documentation
    is available at [http://hackage.haskell.org/package/hierarchical-clustering](http://hackage.haskell.org/package/hierarchical-clustering)):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 cabal 安装层次聚类包，方法如下（文档请参见 [http://hackage.haskell.org/package/hierarchical-clustering](http://hackage.haskell.org/package/hierarchical-clustering)）：
- en: '[PRE16]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: How to do it…
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现……
- en: 'Insert the following code in a new file, which we call `Main.hs`:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下代码插入一个新文件，我们称之为 `Main.hs`：
- en: 'Import the required library:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE17]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Define a Point data type:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个点的数据类型：
- en: '[PRE18]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Define the Euclidian distance metric:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义欧几里得距离度量：
- en: '[PRE19]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Print out the clusters:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出聚类结果：
- en: '[PRE20]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Test the clustering algorithm on some points:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一些点上测试聚类算法：
- en: '[PRE21]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Each of the three clusters are printed out as lists of points:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个聚类输出为点的列表：
- en: '[PRE22]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How it works…
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何工作……
- en: The `dendogram` function has the type `Linkage -> [a] -> (a -> a -> Distance)
    -> Dendogram a`. The linkage describes how distance is calculated. In this recipe,
    we use `SingleLinkage` as the first argument, which means that the distance between
    two clusters is the minimum distance between all their elements.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`dendogram` 函数的类型为 `Linkage -> [a] -> (a -> a -> Distance) -> Dendogram a`。链接方法描述了如何计算距离。在这个示例中，我们使用
    `SingleLinkage` 作为第一个参数，这意味着两个聚类之间的距离是它们所有元素之间的最小距离。'
- en: The second argument is the list of points, followed by a distance metric. The
    result of this function is a **dendogram**, otherwise referred to as a hierarchical
    tree diagram. We use the defined `printCluster` function to display the clusters.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数是点的列表，后面跟着距离度量。该函数的结果是一个**树状图**，也叫做层次树形图。我们使用定义的 `printCluster` 函数来显示聚类结果。
- en: There's more…
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'The other types of linkage in this library include the following mentioned
    along with their description present on Hackage:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 该库中其他类型的链接包括以下内容，并且在 Hackage 上有相应的描述：
- en: '`SingleLinkage`: This is the minimum distance between two clusters.![There''s
    more…](img/6331OS_08_05.jpg)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SingleLinkage`：这是两个聚类之间的最小距离。![还有更多…](img/6331OS_08_05.jpg)'
- en: '*"O(n^2) time and O(n) space, using the SLINK algorithm. This algorithm is
    optimal in both space and time and gives the same answer as the naive algorithm
    using a distance matrix."*'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"O(n^2)时间和O(n)空间，使用SLINK算法。该算法在空间和时间上都是最优的，并且与使用距离矩阵的朴素算法得出的结果相同。"*'
- en: '`CompleteLinkage`: This is the maximum distance between two clusters.![There''s
    more…](img/6331OS_08_06.jpg)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CompleteLinkage`：这是两个聚类之间的最大距离。![还有更多…](img/6331OS_08_06.jpg)'
- en: '*"O(n^3) time and O(n^2) space, using the naive algorithm with a distance matrix.
    Use CLINK if you need more performance."*'
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"O(n^3)时间和O(n^2)空间，使用带距离矩阵的朴素算法。如果需要更高性能，使用CLINK。"*'
- en: Complete linkage with **CLINK** is the same as the previous linkage type, except
    that it uses a faster but not always optimal algorithm.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**CLINK**的完全连接与之前的连接类型相同，只是它使用了一种更快但不总是最优的算法。
- en: '*"O(n^2) time and O(n) space, using the CLINK algorithm. Note that this algorithm
    doesn''t always give the same answer as the naive algorithm using a distance matrix,
    but it''s much faster."*'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"O(n^2)时间和O(n)空间，使用CLINK算法。请注意，该算法并不总是给出与使用距离矩阵的朴素算法相同的结果，但它要快得多。"*'
- en: UPGMA is the average distance between the two clusters.![There's more…](img/6331OS_08_07.jpg)
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UPGMA是两个聚类之间的平均距离。![还有更多…](img/6331OS_08_07.jpg)
- en: '*"O(n^3) time and O(n^2) space, using the naive algorithm with a distance matrix."*'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"O(n^3)时间和O(n^2)空间，使用带距离矩阵的朴素算法。"*'
- en: And lastly, FakeAverageLinkage is similar to the previous UPGMA linkage but
    weighs both clusters equally in its calculations.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，FakeAverageLinkage与之前的UPGMA连接相似，但在计算时对两个聚类赋予相同的权重。
- en: '*"O(n^3) time and O(n^2) space, using the naive algorithm with a distance matrix."*'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"O(n^3)时间和O(n^2)空间，使用带距离矩阵的朴素算法。"*'
- en: See also
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: To use our own hierarchical clustering algorithm, see the previous recipe on
    *Implementing hierarchical clustering*.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 若要使用我们自己的层次聚类算法，请参阅之前的食谱*实现层次聚类*。
- en: Finding the number of clusters
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找聚类数目
- en: Sometimes, we do not know the number of clusters in a dataset, yet most clustering
    algorithms require this information a priori. One way to find the number of clusters
    is to run the clustering algorithm on all possible number of clusters and compute
    the average variance of the clusters. We can then graph the average variance for
    the number of clusters, and identify the number of clusters by finding the first
    fluctuation of the curve.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们并不知道数据集中聚类的数量，但大多数聚类算法需要事先知道这一信息。一种找到聚类数目方法是运行聚类算法，尝试所有可能的聚类数目，并计算每个聚类的平均方差。然后，我们可以绘制聚类数目的平均方差图，并通过找到曲线的第一次波动来确定聚类的数目。
- en: Getting ready
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Review the k-means recipe titled *Implementing the k-means clustering algorithm*.
    We will be using the `kmeans` and `assign` functions defined in that recipe.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 查看标题为*实现k均值聚类算法*的k-means食谱。我们将使用在该食谱中定义的`kmeans`和`assign`函数。
- en: 'Install the Statistics package from cabal:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 从cabal安装Statistics包：
- en: '[PRE23]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: How to do it…
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: Create a new file and insert the following code. We name this file `Main.hs`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新文件并插入以下代码。我们将这个文件命名为`Main.hs`。
- en: 'Import the `variance` function and the helper `fromList` function:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`variance`函数和辅助函数`fromList`：
- en: '[PRE24]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Compute the average of the variance of each cluster:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个聚类的方差平均值：
- en: '[PRE25]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In `main`, define a list of points. Notice how there appears to be three clusters:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`main`中定义一个点的列表。注意这里似乎有三个聚类：
- en: '[PRE26]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Get the average of the variance of each set of clusters:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取每一组聚类的方差平均值：
- en: '[PRE27]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The output will be a list of numbers. Once plotted, we can see that the number
    of clusters is three, which occurs at the knee, or just before local maxima, of
    the curve as shown in the following image:![How to do it…](img/6331OS_08_04.jpg)
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出将是一个数字列表。一旦绘制出来，我们可以看到聚类的数目是三个，这出现在曲线的膝部或局部最大值之前，如下图所示：![如何操作…](img/6331OS_08_04.jpg)
- en: Clustering words by their lexemes
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按照词汇语素对单词进行聚类
- en: 'Words that look alike can easily be clustered together. The clustering algorithm
    in the lexeme-clustering package is based on Janicki''s research paper titled,
    "*A Lexeme-Clustering Algorithm for Unsupervised Learning of Morphology*". A direct
    link to this paper can be found through the following URL: [http://skil.informatik.uni-leipzig.de/blog/wp-content/uploads/proceedings/2012/Janicki2012.37.pdf](http://skil.informatik.uni-leipzig.de/blog/wp-content/uploads/proceedings/2012/Janicki2012.37.pdf).'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来相似的单词可以很容易地被聚类在一起。lexeme-clustering包中的聚类算法基于Janicki的研究论文《*用于无监督学习词法形态的词素聚类算法*》。可以通过以下网址直接访问该论文：[http://skil.informatik.uni-leipzig.de/blog/wp-content/uploads/proceedings/2012/Janicki2012.37.pdf](http://skil.informatik.uni-leipzig.de/blog/wp-content/uploads/proceedings/2012/Janicki2012.37.pdf)。
- en: Getting ready
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: An Internet connection is necessary for this recipe to download the package
    from GitHub.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程需要互联网连接，以便从GitHub下载包。
- en: How to do it…
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做……
- en: 'Follow these steps to install and use the library:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤安装并使用该库：
- en: 'Obtain the lexeme-clustering library from GitHub. If Git is installed, enter
    the following command, otherwise download it from [https://github.com/BinRoot/lexeme-clustering/archive/master.zip](https://github.com/BinRoot/lexeme-clustering/archive/master.zip):'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从GitHub获取lexeme-clustering库。如果已安装Git，输入以下命令，否则从[https://github.com/BinRoot/lexeme-clustering/archive/master.zip](https://github.com/BinRoot/lexeme-clustering/archive/master.zip)下载：
- en: '[PRE28]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Change into the library''s directory:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到库的目录：
- en: '[PRE29]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Install the package:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装该包：
- en: '[PRE30]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Create an input file with a different word on each line:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个每行包含不同单词的输入文件：
- en: '[PRE31]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Run the lexeme-clustering algorithm on the input file:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在输入文件上运行lexeme-clustering算法：
- en: '[PRE32]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The resulting output clusters are then displayed:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 得到的输出聚类结果将会展示出来：
- en: '[PRE33]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: How it works…
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The related words are clustered together by carefully looking at each word's
    **morpheme**, or smallest meaningful component.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仔细观察每个单词的**词素**，即最小的有意义成分，相关的词汇会被聚集在一起。
- en: 'Here''s a short excerpt from the abstract of the research paper of which this
    algorithm is based:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这是基于此算法的研究论文摘要中的一小段摘录：
- en: '*"Initially, a trie of words is built and each node in the trie is considered
    a candidate for stem. The suffixes, with which it occurs, are clustered according
    to mutual information in order to identify inflectional paradigms."*'
  id: totrans-154
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“最初，构建一个单词的前缀树，每个前缀树中的节点都被视为词干的候选。根据互信息对其出现的后缀进行聚类，以识别屈折范式。”*'
- en: See also
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: For clustering points of data, see the previous algorithms on *Implementing
    the k-means clustering algorithm*, *Implementing hierarchical clustering*, and
    *Using a hierarchical clustering library*.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据点进行聚类，请参考之前的算法：*实现k-means聚类算法*、*实现层次聚类*，以及*使用层次聚类库*。
- en: Classifying the parts of speech of words
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对单词词性进行分类
- en: This recipe will demonstrate how to identify the parts of speech of each word
    in a sentence. We will be using a handy library called **chatter**, which contains
    very useful **Natural Language Processing** (**NLP**) tools. It can be obtained
    from Hackage at [http://hackage.haskell.org/package/chatter](http://hackage.haskell.org/package/chatter).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将演示如何识别句子中每个单词的词性。我们将使用一个非常实用的库叫做**chatter**，它包含了很多有用的**自然语言处理**（**NLP**）工具。你可以从Hackage获取该库，地址为[http://hackage.haskell.org/package/chatter](http://hackage.haskell.org/package/chatter)。
- en: NLP is the study of human language embedded in a machine. Our naturally spoken
    or written language may seem obvious to us in our day-to-day lives, but producing
    meaning out of words is still a difficult task for computers.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）是将人类语言嵌入到计算机中的研究领域。我们日常说的或写的语言对我们来说似乎是显而易见的，但要从单词中提取意义仍然是计算机面临的一个难题。
- en: Getting ready
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Install the NLP library using cabal:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 使用cabal安装NLP库：
- en: '[PRE34]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: How to do it…
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做……
- en: 'In a new file, which we name `Main.hs`, enter the following source code:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新文件中，我们命名为`Main.hs`，输入以下源代码：
- en: 'Import the parts of speech library and the pack function:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入词性库和包函数：
- en: '[PRE35]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Obtain the default tagger provided by the library:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取库提供的默认标注器：
- en: '[PRE36]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Feed the `tag` function a tagger and a text to see the corresponding parts
    of speech per each word:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`tag`函数与标注器和文本一起使用，查看每个单词对应的词性：
- en: '[PRE37]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output will be an association list of the word to its part of speech:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出将是单词与其词性的关联列表：
- en: '[PRE38]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: How it works…
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: A parts of speech tagger is trained from a corpus of text. In this example,
    we use the default tagger provided by the library, which trains on the corpus
    in the following directory of the package, `data/models/brown-train.model.gz`.
    This corpus is called the Brown University Standard Corpus of Present-Day American
    English, created in the 1960s.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 词性标注器是从文本语料库中训练出来的。在这个示例中，我们使用库提供的默认标注器，它会在包中的以下目录 `data/models/brown-train.model.gz`
    上进行训练。这个语料库被称为布朗大学现代美式英语标准语料库，创建于 1960 年代。
- en: Definitions of each of the abbreviations such as at, `jjt`, or `nns` can be
    found on [http://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used](http://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 每个缩写词的定义，如 at、`jjt` 或 `nns`，可以在 [http://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used](http://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used)
    找到。
- en: There's more…
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'We can also train our own parts of speech taggers by loading a tagger from
    a file path, `loadTagger :: FilePath -> IO POSTagger`.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还可以通过从文件路径加载标注器来训练我们自己的词性标注器，`loadTagger :: FilePath -> IO POSTagger`。'
- en: See also
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见：
- en: To categorize words as something other than parts of speech, see the next recipe
    on *Identifying key words in a corpus of text*.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 要将单词分类为除词性以外的其他类别，请参见下一节 *识别文本语料库中的关键字*。
- en: Identifying key words in a corpus of text
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别文本语料库中的关键字：
- en: One way to predict the topic of a paragraph or sentence is by identifying what
    the words mean. While the parts of speech give some insight about each word, they
    still don't reveal the connotation of that word. In this recipe, we will use a
    Haskell library to tag words by topics such as `PERSON`, `CITY`, `DATE`, and so
    on.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一种预测段落或句子主题的方法是通过识别单词的含义。虽然词性可以为每个单词提供一些信息，但它们仍然无法揭示该单词的含义。在这个食谱中，我们将使用 Haskell
    库将单词标记为如 `PERSON`、`CITY`、`DATE` 等主题。
- en: Getting ready
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作：
- en: An Internet connection is necessary for this recipe to download the `sequor`
    package.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱需要互联网连接来下载 `sequor` 包。
- en: 'Install it from cabal:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 cabal 安装：
- en: '[PRE39]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Otherwise, follow these directions to install it manually:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，按照以下步骤手动安装：
- en: 'Obtain the latest version of the sequor library by opening up a browser and
    visiting the following URL: [http://hackage.haskell.org/package/sequor](http://hackage.haskell.org/package/sequor).'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过打开浏览器并访问以下网址获取 sequor 库的最新版本：[http://hackage.haskell.org/package/sequor](http://hackage.haskell.org/package/sequor)。
- en: Under the **Downloads** section, download the cabal source package.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **Downloads** 部分，下载 cabal 源代码包。
- en: 'Extract the contents:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取内容：
- en: On Windows, it is easiest to using 7-Zip, an easy-to-use file archiver. Install
    it on your machine by going to [http://www.7-zip.org](http://www.7-zip.org). Then
    using 7-Zip, extract the contents of the tarball.
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Windows 上，使用 7-Zip 是最简单的，它是一款易于使用的文件压缩工具。通过访问 [http://www.7-zip.org](http://www.7-zip.org)
    将其安装到你的机器上。然后使用 7-Zip 提取 tarball 文件的内容。
- en: 'On other operating systems, run the following command to extract the tarball.
    Replace the numbers in the following command to the correct version numbers of
    your download because a new version (that is, 0.7.3) may be out:'
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在其他操作系统上，运行以下命令以提取 tarball 文件。替换命令中的数字为下载的正确版本号，因为可能会有新版本（例如 0.7.3）发布：
- en: '[PRE40]'
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Go into the directory:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入该目录：
- en: '[PRE41]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Make sure to read the `README` file:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保阅读 `README` 文件：
- en: '[PRE42]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Install the library using the following Cabal command:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下 Cabal 命令安装该库：
- en: '[PRE43]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: How to do it…
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: We will set up an input file to feed into the program.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将设置一个输入文件，将其输入到程序中。
- en: 'Create an `input.txt` file using the CoNLL format, which requires one token
    per line, and sentences separated by a blank line:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 CoNLL 格式创建一个 `input.txt` 文件，每行一个标记，句子之间用空行分隔：
- en: '[PRE44]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now run the word tagging on the input:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在运行输入文件的词标注：
- en: '[PRE45]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The result is saved in the `output.txt` file. Open up the file and review the
    corresponding tags found:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果会保存在 `output.txt` 文件中。打开文件并查看找到的相应标签：
- en: '[PRE46]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: How it works…
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'The library uses Collins'' sequence perceptron, based off a paper published
    in 2002 titled "*Discriminative Training Methods for Hidden Markov Models: Theory
    and Experiments with Perceptron Algorithms*". His website ([http://www.cs.columbia.edu/~mcollins/](http://www.cs.columbia.edu/~mcollins/))
    contains comprehensive notes on designing the algorithm used in this recipe.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 该库使用了 Collins 的序列感知机，该感知机基于他于 2002 年发表的论文《*隐马尔可夫模型的判别训练方法：感知机算法的理论与实验*》。他的个人网站
    ([http://www.cs.columbia.edu/~mcollins/](http://www.cs.columbia.edu/~mcollins/))
    包含了关于设计本食谱中使用的算法的详细笔记。
- en: See also
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见：
- en: To use an existing parts of speech tagger, see the previous recipe on *Classifying
    the parts of speech of words*. To train our own parts-of-speech tagger, see the
    next recipe on *Training a parts-of-speech tagger*.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用现有的词性标注器，请参阅之前的食谱 *词性分类*。要训练我们自己的词性标注器，请参阅下一个食谱 *训练词性标注器*。
- en: Training a parts-of-speech tagger
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练词性标注器
- en: We will use a Haskell library, sequor, to train our own parts of speech tagger.
    Then we can use this newly trained model on our own input.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Haskell 库 sequor 来训练我们自己的词性标注器。然后，我们可以在自己的输入数据上使用这个新训练的模型。
- en: Getting ready
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Please refer to the *Getting ready* section of the previous recipe.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅之前食谱中的 *准备就绪* 部分。
- en: How to do it…
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'In a new file, which we name `Main.hs`, enter the following source code:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新文件中，我们将其命名为 `Main.hs`，输入以下源代码：
- en: 'Use the `sequor` executable to train the parts of speech tagger:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `sequor` 可执行文件来训练词性标注器：
- en: The first argument to `sequor` will be `train`, to indicate that we are about
    to train a tagger
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sequor` 的第一个参数将是 `train`，表示我们将要训练一个标注器。'
- en: The next argument is the template-file, `data/all.features`
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下一个参数是模板文件，`data/all.features`。
- en: Then we provide the train-file, `data/train.conll`
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后提供训练文件 `data/train.conll`。
- en: The last file path we need to provide is the location of where to save the trained
    model
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要提供的最后一个文件路径是保存已训练模型的位置。
- en: We can specify a learning rate using the `-rate` flag
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用 `-rate` 标志来指定学习率。
- en: The beam size can be modified using the `-beam` flag
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用 `-beam` 标志修改波束大小。
- en: Change the number of iterations using the `-iter` flag
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `-iter` 标志更改迭代次数。
- en: Use hashing instead of a feature dictionary using the `-hash` flag
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `-hash` 标志代替特征字典进行哈希处理。
- en: Provide a path to the held out data using the `-heldout` flag
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `-heldout` 标志提供一个持有数据的路径。
- en: 'An example of the sequor command in use is as follows:'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个使用 `sequor` 命令的示例如下：
- en: '[PRE47]'
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Test out the trained model on a sample input:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在样本输入上测试已训练的模型：
- en: '[PRE48]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The first few lines of the output `test.labels` file will be:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出 `test.labels` 文件的前几行将是：
- en: '[PRE49]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: How it works…
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'The library uses Collins'' sequence perceptron, based off a paper published
    in 2002 titled "*Discriminative Training Methods for Hidden Markov Models: Theory
    and Experiments with Perceptron Algorithms*". The Hackage documentation can be
    found on [http://hackage.haskell.org/package/sequor](http://hackage.haskell.org/package/sequor).'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '该库使用 Collins 的序列感知器，该感知器基于 2002 年发布的论文 "*Discriminative Training Methods for
    Hidden Markov Models: Theory and Experiments with Perceptron Algorithms*"。Hackage
    文档可以在 [http://hackage.haskell.org/package/sequor](http://hackage.haskell.org/package/sequor)
    找到。'
- en: See also
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: To use an existing parts of speech tagger, see the previous recipe on *Classifying
    the parts of speech of words*.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用现有的词性标注器，请参阅之前的食谱 *词性分类*。
- en: Implementing a decision tree classifier
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现决策树分类器
- en: A decision tree is a model for classifying data effectively. Each child of a
    node in the tree represents a feature about the item we are classifying. Traversing
    down the tree to leaf nodes represent an item's classification. It's often desirable
    to create the smallest possible tree to represent a large sample of data.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是一种有效的分类数据的模型。树中每个节点的子节点代表我们正在分类项目的特征。从树的根节点向下遍历到叶节点表示项目的分类。通常希望创建一个尽可能小的树来表示大量的数据样本。
- en: In this recipe, we implement the ID3 decision tree algorithm in Haskell. It
    is one of the easiest to implement and produces useful results. However, ID3 does
    not guarantee an optimal solution, may be computationally inefficient compared
    to other algorithms, and only supports discrete data. While these issues can be
    addressed by a more complicated algorithm such as C4.5, the code in this recipe
    is enough to get up and running with a working decision tree.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们在 Haskell 中实现了 ID3 决策树算法。它是最容易实现的算法之一，并能产生有用的结果。然而，ID3 并不保证最优解，相比其他算法，它在计算上可能效率较低，并且只支持离散数据。虽然这些问题可以通过更复杂的算法如
    C4.5 来解决，但本食谱中的代码足以让你快速启动并运行一个有效的决策树。
- en: Getting ready
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Create a CSV file representing samples of data. The last column should be the
    classification. Name this file `input.csv`.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 CSV 文件，表示数据样本。最后一列应该是分类。将此文件命名为 `input.csv`。
- en: '![Getting ready](img/6331OS_08_08.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/6331OS_08_08.jpg)'
- en: The weather data is represented with four attributes, namely outlook, temperature,
    humidity, and wind. The last column represents whether it is a good idea to play
    outside.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 天气数据由四个属性表示，即天况、温度、湿度和风速。最后一列表示是否适合户外活动。
- en: 'Import the CSV helper library:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 导入CSV辅助库：
- en: '[PRE50]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: How to do it…
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Insert this code into a new file, which we call `Main.hs`:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 将此代码插入到一个新文件中，我们称之为`Main.hs`：
- en: 'Import the built-in libraries:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入内置库：
- en: '[PRE51]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Define some type synonyms to better understand what data is being passed around:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一些类型别名，以更好地理解传递的数据：
- en: '[PRE52]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Define the main function to read in the CSV file and handle any errors:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义主函数，读取CSV文件并处理任何错误：
- en: '[PRE53]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'If the file was read successfully, remove any invalid CSV records and construct
    a decision tree out of it:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果文件成功读取，去除任何无效的CSV记录并从中构建决策树：
- en: '[PRE54]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Define helper functions to break up the `DataSet` tuple into a list of samples
    or a list of classes:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义辅助函数，将`DataSet`元组拆分为样本列表或类别列表：
- en: '[PRE55]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Calculate the entropy of a list of values:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算一组值的熵：
- en: '[PRE56]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Split an attribute by its features:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按特征拆分一个属性：
- en: '[PRE57]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Obtain each of the entropies from splitting up an attribute by its features:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取从属性特征拆分后的每个熵值：
- en: '[PRE58]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Compute the information gain from splitting up an attribute by its features:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算通过特征拆分属性后的信息增益：
- en: '[PRE59]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Determine which attribute contributes the highest information gain:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定哪个属性贡献了最高的信息增益：
- en: '[PRE60]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Define the data structure for a decision tree that we will soon construct:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义我们即将构建的决策树的数据结构：
- en: '[PRE61]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Split up the dataset by the attribute that contributes the highest information
    gain:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按信息增益最高的属性拆分数据集：
- en: '[PRE62]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Define a helper function to determine if all elements of a list are equal.
    We use this to check if further splitting of the dataset is necessary by checking
    if its classes are identical:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义辅助函数来确定列表中的所有元素是否相等。我们用这个来检查是否需要进一步拆分数据集，通过检查其类别是否相同：
- en: '[PRE63]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Construct the decision tree from a labeling and a dataset of samples:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从标签和样本数据集构建决策树：
- en: '[PRE64]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Run the following code to see the tree printed out:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码查看打印出的树形结构：
- en: '[PRE65]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'It can be visualized using the following diagram:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下图表进行可视化：
- en: '![How to do it…](img/6331OS_08_09.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![如何做…](img/6331OS_08_09.jpg)'
- en: How it works…
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The ID3 algorithm uses the concept of Shannon's entropy to divide up a set of
    samples by the attribute that maximize the information gain. This process is recursively
    repeated until we're dealing with samples of the same classification or when we
    run out of attributes.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ID3算法使用香农熵的概念，通过最大化信息增益的属性将样本集划分开来。这个过程会递归重复，直到处理的是同一分类的样本，或者直到属性用完为止。
- en: In the field of Information Theory, **Entropy** is the measure of unpredictability.
    A fair coin has higher entropy than a biased coin. Entropy can be calculated by
    taking the expected value of the information content, where information content
    of a random variable X has the form — *ln(P(X))*. When the logarithm in the equation
    is to the base of 2, the units of entropy are called *bits*.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息论领域，**熵**是不可预测性的度量。公平的硬币比偏向的硬币具有更高的熵。熵可以通过取信息内容的期望值来计算，其中随机变量X的信息内容形式为*ln(P(X))*。当方程中的对数以2为底时，熵的单位称为*比特*。
- en: Information Gain is the change in entropy from the prior state to the new state.
    It has the equation *IG = H[1] – H[2]*, where *H[1]* is the original entropy of
    the sample. And *H[2]* is the new entropy given an attribute to split.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 信息增益是从先前状态到新状态的熵变化。其公式为*IG = H[1] – H[2]*，其中*H[1]*是样本的原始熵，*H[2]*是在给定属性分裂后的新熵。
- en: Implementing a k-Nearest Neighbors classifier
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现k-最近邻分类器
- en: One simple way to classify an item is to look at only its neighboring data.
    The k-Nearest Neighbors algorithm looks at k items located closest to the item
    in question. The item is then classified as the most common classification of
    its k neighbors. This heuristic has been very promising for a wide variety of
    classification tasks.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单的分类方法是仅查看其邻近数据。k-最近邻算法查看与当前项距离最近的k个项。然后，该项将被分类为其k个邻居中最常见的分类。这种启发式方法在各种分类任务中都表现得非常有前景。
- en: In this recipe, we will implement the k-Nearest Neighbors algorithm using a
    **k-d tree** data structure, which is a binary tree with special properties that
    allow efficient representation of points in a k-dimensional space.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将实现使用**k-d树**数据结构的k-最近邻算法，k-d树是一种具有特殊属性的二叉树，允许在k维空间中高效表示点。
- en: Imagine we have a web server for our hip new website. Every time someone requests
    a web page, our web server will fetch the file and present the page. However,
    bots can easily hammer a web server with thousands of requests, potentially causing
    a denial of service attack. In this recipe, we will classify whether a web request
    is being made by a human or a bot.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个新潮网站的Web服务器。每次有人请求网页时，我们的Web服务器将获取文件并展示页面。然而，机器人可以轻松地向Web服务器发送数千个请求，可能导致拒绝服务攻击。在本教程中，我们将对Web请求进行分类，判断请求者是人类还是机器人。
- en: Getting ready
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Install the `KdTree`, `CSV`, and `iproute` packages using cabal:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 使用cabal安装`KdTree`、`CSV`和`iproute`包：
- en: '[PRE66]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Create a CSV file containing the IP addresses and number of seconds since last
    access. The last field of each CSV record should be the classification *Human*
    or *Bot*. We call our file `input.csv`.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个包含IP地址和自上次访问以来经过的秒数的CSV文件。每条CSV记录的最后一列应为分类 *Human* 或 *Bot*。我们将文件命名为`input.csv`。
- en: '![Getting ready](img/6331OS_08_10.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![准备工作](img/6331OS_08_10.jpg)'
- en: How to do it…
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'After creating a new file called `Main.hs`, we perform the following steps:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 创建名为`Main.hs`的新文件后，执行以下步骤：
- en: 'Import the following packages:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下包：
- en: '[PRE67]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Convert an IPv4 address string into its 32-bit representation:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将IPv4地址字符串转换为32位表示：
- en: '[PRE68]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Parse data from a CSV file to obtain a list of points and their associated
    classifications:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从CSV文件中解析数据，获取点及其相关分类：
- en: '[PRE69]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Find the item in a list that occurs most often:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找列表中最常出现的项：
- en: '[PRE70]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Classify a test point given the KdTree, the number of nearest neighbors to
    use, and the training set of points:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定KdTree、要使用的最近邻居数量以及训练集点，分类一个测试点：
- en: '[PRE71]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Define `main` to read a CSV file and process the data:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`main`以读取CSV文件并处理数据：
- en: '[PRE72]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Handle an error if the CSV cannot be read properly:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果CSV无法正确读取，处理错误：
- en: '[PRE73]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Otherwise create a KdTree from the CSV data and test out a couple of examples:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 否则，从CSV数据创建一个KdTree，并测试几个示例：
- en: '[PRE74]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Run the code to see the resulting classifications of the example points:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行代码以查看示例点的分类结果：
- en: '[PRE75]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: How it works…
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: The k-Nearest Neighbor algorithm looks at the k closest points from the training
    set and returns the most frequent classification between these k points. Since
    we are dealing with points, each of the coordinates should be orderable. Fortunately,
    an IP address has a faint sense of hierarchy that we can leverage. We convert
    an IP to its 32-bit number to obtain a useful ordering that we can treat as a
    coordinate of a point in space.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: k-最近邻算法查看训练集中k个最接近的点，并返回这些k个点中最常见的分类。由于我们处理的是点，每个坐标应该是可排序的。幸运的是，IP地址有一个微弱的层次结构，我们可以利用这一点。我们将IP地址转换为32位数字，以获得一个有用的顺序，将其视为空间中一个点的坐标。
- en: Visualizing points using Graphics.EasyPlot
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Graphics.EasyPlot可视化点
- en: Sometimes, it's convenient to simply visualize data points before clustering
    or classifying to inspect the data. This recipe will feed a list of points to
    a plotting library to easily see a diagram of the data.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，在进行聚类或分类之前，简单地可视化数据点是很方便的，以便检查数据。这个教程将把一个点的列表传递给绘图库，轻松查看数据的图示。
- en: Getting ready
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Install easyplot from cabal:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 从cabal安装easyplot：
- en: '[PRE76]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Create a CSV file containing two-dimensional points:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个包含二维点的CSV文件：
- en: '[PRE77]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: How to do it…
  id: totrans-322
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In a new file, `Main.hs`, follow these steps:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新的文件`Main.hs`中，按照以下步骤操作：
- en: 'Import the required library to read in CSV data as well the library to plot
    points:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库以读取CSV数据，以及用于绘制点的库：
- en: '[PRE78]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Create a helper function to convert a list of string records into a list of
    doubles. For example, we want to convert `[ "1.0,2.0", "3.5,4.5" ]` into `[ (1.0,
    2.0), (3.5, 4.5) ]`:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个辅助函数，将字符串记录列表转换为双精度数列表。例如，我们想将`[ "1.0,2.0", "3.5,4.5" ]`转换为`[ (1.0, 2.0),
    (3.5, 4.5) ]`：
- en: '[PRE79]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'In `main`, parse the CSV file to be used later on:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`main`中，解析CSV文件以供后续使用：
- en: '[PRE80]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'If the CSV file is valid, plot the points using the `plot :: TerminalType ->
    a -> IO Bool` function:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '如果CSV文件有效，使用`plot :: TerminalType -> a -> IO Bool`函数绘制点：'
- en: '[PRE81]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: How it works…
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'The first argument to `plot` tells gnuplot where its output should be displayed.
    For example, we use X11 to output to the X Window System on Linux. Depending on
    the computer, we can choose between different terminal types. The constructors
    for `TerminalType` are the following:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '`plot` 的第一个参数告诉 gnuplot 输出应该显示的位置。例如，我们使用 X11 输出到 Linux 上的 X Window 系统。根据计算机的不同，我们可以在不同的终端类型之间选择。`TerminalType`
    的构造函数如下：'
- en: '`Aqua`: Output on Mac OS X (Aqua Terminal)'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Aqua`: 输出到 Mac OS X（Aqua 终端）'
- en: '`Windows`: Output for MS Windows'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Windows`: 输出为 MS Windows 格式'
- en: '`X11`: Output to the X Window System'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X11`: 输出到 X Window 系统'
- en: '`PS FilePath`: Output into a PostScript file'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PS 文件路径`: 输出为 PostScript 文件'
- en: '`EPS FilePath`: Output into an EPS file path'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EPS 文件路径`: 输出为 EPS 文件路径'
- en: '`PNG FilePath`: Output as Portable Network Graphic into a file'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PNG 文件路径`: 输出为便携网络图形（PNG）并保存为文件'
- en: '`PDF FilePath`: Output as Portable Document Format into a file'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PDF 文件路径`: 输出为便携文档格式（PDF）并保存为文件'
- en: '`SVG FilePath`: Output as Scalable Vector Graphic into a file'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SVG 文件路径`: 输出为可缩放矢量图并保存为文件'
- en: '`GIF FilePath`: Output as Graphics Interchange Format into a file'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GIF 文件路径`: 输出为图形交换格式（GIF）并保存为文件'
- en: '`JPEG FilePath`: Output into a JPEG file'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`JPEG 文件路径`: 输出为 JPEG 文件'
- en: '`Latex FilePath`: Output as LaTeX'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Latex 文件路径`: 输出为 LaTeX 格式'
- en: The second argument to plot is the graph, which may be a `Graph2D`, or `Graph3D`,
    or a list of these.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: plot 的第二个参数是图形，可以是 `Graph2D`、`Graph3D`，或者它们的列表。
