- en: Functional Programming Concepts
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式编程概念
- en: '"Object-oriented programming makes code understandable by encapsulating moving
    parts. Functional programming makes code understandable by minimizing moving parts."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “面向对象编程通过封装移动部分使代码易于理解。函数式编程通过最小化移动部分使代码易于理解。”
- en: '- Michael Feathers'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- Michael Feathers'
- en: 'Using Scala and Spark is a very good combination for learning big data analytics.
    However, along with the OOP paradigm, we also need to know-how why functional
    concepts are important for writing Spark applications that eventually analyze
    your data. As mentioned in the previous chapters, Scala supports two programming
    paradigms: the Object-Oriented Programming paradigm and the Functional programming
    concepts. In [Chapter 2](part0058.html#1NA0K1-21aec46d8593429cacea59dbdcd64e1c),
    *Object-Oriented Scala*, we explored the OOP paradigm in which we have seen how
    to represent real-world objects in blueprints (classes) and then instantiate them
    into objects having real memory representation.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Scala和Spark是学习大数据分析的很好组合。然而，除了面向对象编程范式，我们还需要知道为什么函数式概念对编写最终分析数据的Spark应用程序很重要。正如前几章所述，Scala支持两种编程范式：面向对象编程范式和函数式编程概念。在[第2章](part0058.html#1NA0K1-21aec46d8593429cacea59dbdcd64e1c)中的*面向对象Scala*中，我们探讨了面向对象编程范式，看到了如何在蓝图（类）中表示现实世界对象，然后将其实例化为具有真实内存表示的对象。
- en: In this chapter, we will focus on the second paradigm (i.e. functional programming).
    We will see what functional programming is and how Scala supports it, why it matters,
    and the related advantages of using this concept. More specifically, we will learn
    several topics, such as why Scala is an arsenal for the data scientist, why it
    is important to learn the Spark paradigm, pure functions, and **higher-order functions**
    (**HOFs**). A real-life use case using HOF will also be shown in this chapter.
    Then, we will see how to handle exceptions in the higher-order functions outside
    collections using the standard library of Scala. Finally, we will learn how functional
    Scala affects an object's mutability.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注第二种范式（即函数式编程）。我们将看到函数式编程是什么，Scala如何支持它，为什么它很重要以及使用这个概念的相关优势。具体来说，我们将学习几个主题，比如为什么Scala是数据科学家的武器库，为什么学习Spark范式很重要，纯函数和**高阶函数**（**HOFs**）的相关内容。本章还将展示使用HOF的真实用例。然后，我们将看到如何在Scala的标准库中处理集合外的高阶函数中的异常。最后，我们将学习函数式Scala如何影响对象的可变性。
- en: 'In a nutshell, the following topics will be covered in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本章将涵盖以下主题：
- en: Introduction to functional programming
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数式编程介绍
- en: Functional Scala for the data scientists
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家的函数式Scala
- en: Why functional programming and Scala are important for learning Spark?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么函数式编程和Scala对学习Spark很重要？
- en: Pure functions and higher-order functions
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纯函数和高阶函数
- en: 'Using higher-order functions: A real-life use case'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用高阶函数：一个真实用例
- en: Error handling in functional Scala
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在函数式Scala中处理错误
- en: Functional programming and data mutability
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数式编程和数据可变性
- en: Introduction to functional programming
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式编程介绍
- en: In computer science, `functional programming` (FP) is a programming paradigm
    and a unique style of building the structure and elements of computer programs.
    This uniqueness helps treat the computation as the evaluation of mathematical
    functions and avoids changing-state and mutable data. Thus, by using the FP concept,
    you can learn to code in your own style that ensures the immutability of your
    data. In other words, FP is about writing pure functions, about removing hidden
    inputs and outputs as far as we can, so that as much of our code as possible *just*
    describes a relationship between inputs and outputs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机科学中，`函数式编程`（FP）是一种编程范式和一种构建计算机程序结构和元素的独特风格。这种独特性有助于将计算视为数学函数的评估，并避免改变状态和可变数据。因此，通过使用FP概念，您可以学会以自己的方式编写代码，确保数据的不可变性。换句话说，FP是关于编写纯函数，消除尽可能多的隐藏输入和输出，以便我们的代码尽可能地*只*描述输入和输出之间的关系。
- en: This is not a new concept but the `Lambda Calculus`, which provides the basis
    of FP, was first introduced in the 1930s. However, in the realm of programming
    language, the term functional programming refers to a new style of declarative
    programming paradigm that means programming can be done with the help of control,
    declarations, or expressions instead of classical statements commonly used in
    an old programming language, such as C.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是一个新概念，但`Lambda Calculus`首次出现在上世纪30年代，它为FP提供了基础。然而，在编程语言领域，函数式编程一词指的是一种新的声明式编程范式，意味着编程可以通过控制、声明或表达式来完成，而不是传统语句，比如C语言中常用的语句。
- en: Advantages of functional programming
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式编程的优势
- en: There are some exciting and cool features in FP paradigms such as `composition`,
    `pipelining`, and `higher order functions` that help to avoid writing unfunctional
    code. Alternatively, at least later on, this helps translate a unfunctional program
    into a functional style towards an imperative one. Finally, now let's see how
    we can define the term functional programming from the computer science perspective.
    Functional programming is a common computer science concept in which computations
    and the building structure of the program are treated as if you are evaluating
    mathematical functions that support immutable data and avoid state change. In
    functional programming, each function has the same mapping or output for the same
    input argument values.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式编程范式中有一些令人兴奋和酷炫的特性，比如`组合`、`管道化`和`高阶函数`，有助于避免编写非函数式代码。或者至少在后期，这有助于将非函数式程序转换为函数式风格，朝向命令式风格。最后，现在让我们看看如何从计算机科学的角度定义函数式编程这个术语。函数式编程是计算机科学中的一个常见概念，其中计算和程序的构建结构被视为评估数学函数，支持不可变数据并避免状态改变。在函数式编程中，每个函数对于相同的输入参数值具有相同的映射或输出。
- en: With the need for a complex software comes the need for good structured programs
    and software that are not difficult to write and are debuggable. We also need
    to write extendable code that will save us programming costs in the future and
    can contribute to easy writing and debugging of the code; even more modular software
    that is easy to extend and requires less programming efforts. Due to the latter
    contribution of functional programming, modularity, functional programming is
    considered as a great advantage for software development.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 随着复杂软件的需求，需要良好结构化的程序和易于编写和调试的软件。我们还需要编写可扩展的代码，这将节省我们未来的编程成本，并有助于代码的轻松编写和调试；甚至更模块化的软件，易于扩展，需要较少的编程工作。由于函数式编程的后一种贡献，模块化，函数式编程被认为是软件开发的一大优势。
- en: 'In functional programming, there is a basic building block in its structure
    called functions without side effects (or at least very few) in most of your code.
    Without side effects, the order of evaluation really doesn''t matter. When it
    comes to programming languages views, there are methods to force a particular
    order. In some FP languages (for example, eager languages such as Scheme), which
    have no evaluation order on arguments, you could nest these expressions in their
    own lambda forms as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数式编程中，其结构中有一个基本构建块称为没有副作用的函数（或者至少在大部分代码中没有）。没有副作用，评估的顺序真的无关紧要。在编程语言的观点上，有方法可以强制执行特定的顺序。在一些FP语言（例如，渴望语言如Scheme）中，对参数没有评估顺序，您可以将这些表达式嵌套在它们自己的lambda形式中，如下所示：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In functional programming, writing mathematical functions in which the execution
    order doesn't matter usually makes your code more readable. Sometimes, one will
    argue that we need functions with side effects to be there as well. Actually,
    this is one of the major disadvantages of most functional programming languages
    since it's typically difficult to write functions that don't require any I/O;
    on the other hand, these function that requires I/O are difficult to implement
    in functional programming. From *Figure 1*, it can be seen that Scala is also
    a hybrid language that evolved by taking features from imperative languages such
    as Java and functional language such as Lisp.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数式编程中，编写数学函数，其中执行顺序并不重要，通常会使您的代码更易读。有时，有人会争论我们也需要有副作用的函数。实际上，这是大多数函数式编程语言的主要缺点之一，因为通常很难编写不需要任何I/O的函数；另一方面，在函数式编程中难以实现需要I/O的函数。从*图1*中可以看出，Scala也是一种混合语言，它通过从Java等命令式语言和Lisp等函数式语言中获取特性而发展而来。
- en: But fortunately, here we are dealing with a mixed language in which object-oriented
    and functional programming paradigms are allowed and hence writing such functions
    that require I/O is quite easy. Functional programming also has major advantages
    over basic programming, such as comprehensions and caching.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但幸运的是，在这里我们正在处理一种混合语言，其中允许面向对象和函数式编程范式，因此编写需要I/O的函数非常容易。函数式编程还具有比基本编程更大的优势，例如理解和缓存。
- en: One of the major advantages of functional programming is brevity because with
    functional programming you can write more compact and concise code. Also, concurrency
    is considered one of the major advantages, which is done more easily in functional
    programming. Therefore, functional languages such as Scala provide many other
    features and tools that encourage coders to make an entire paradigm shift to a
    more mathematical way of thinking.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式编程的一个主要优势是简洁，因为使用函数式编程可以编写更紧凑、简洁的代码。并发也被认为是一个主要优势，在函数式编程中更容易实现。因此，像Scala这样的函数式语言提供了许多其他功能和工具，鼓励编程人员对更数学化的思维方式进行整体范式转变。
- en: '![](img/00062.jpeg)**Figure 1:** Shows a conceptual view of using functional
    programming concepts'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1：** 展示了使用函数式编程概念的概念视图'
- en: 'By narrowing the focus to only a small number of composable abstract concepts,
    such as functions, function composition, and abstract algebra, FP concept provides
    several advantages over other paradigms. For example:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将焦点缩小到一小部分可组合的抽象概念，如函数、函数组合和抽象代数，函数式编程概念相对于其他范式提供了几个优势。例如：
- en: '**Closer alignment to mathematical thinking:** You tend to spell out your ideas
    in a format close to mathematical definitions rather than iterative programs.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更贴近数学思维：** 你倾向于以接近数学定义而不是迭代程序的格式表达你的想法。'
- en: '**No (or at least fewer) side effects:** Your functions do not influence other
    functions, which is great for concurrency and parallelization, and also for debugging.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有（或者至少更少）副作用：您的函数不会影响其他函数，这对并发和并行化非常有利，也有利于调试。
- en: '**Fewer lines of code without sacrificing conceptual clarity:** Lisp is more
    powerful than non-functional languages. Although it''s true that you need to spend
    a greater proportion of your project thinking than writing, you will probably
    find that you are more productive eventually.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更少的代码行数而不牺牲概念上的清晰度：** Lisp比非函数式语言更强大。虽然你需要花费更多的时间思考而不是写作，但最终你可能会发现你更有生产力。'
- en: For these exciting features, functional programming achieves significant expressive
    power. For example, machine learning algorithms can take hundreds of lines of
    imperative code to implement yet they can be defined in just a handful of equations.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些令人兴奋的特性，函数式编程实现了显著的表达力。例如，机器学习算法可能需要数百行命令式代码来实现，但在函数式编程中可以用少数方程式来定义。
- en: Functional Scala for the data scientists
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学家的函数式Scala
- en: For performing interactive data cleaning, processing, munging, and analysis,
    many data scientists use R or Python as their favorite tool. However, there are
    many data scientists who tend to get very attached to their favorite tool--that
    is, Python or R and try to solve all data analytics problems or jobs using that
    tool. Thus, introducing them to a new tool can be very challenging in most circumstances
    as the new tool has more syntax and a new set of patterns to learn before using
    the new tool to solve their purpose.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于进行交互式数据清洗、处理、整理和分析，许多数据科学家使用R或Python作为他们最喜欢的工具。然而，有许多数据科学家倾向于非常依赖他们最喜欢的工具--也就是Python或R，并试图使用该工具解决所有数据分析问题或工作。因此，在大多数情况下，向他们介绍新工具可能非常具有挑战性，因为新工具有更多的语法和一套新的模式需要学习才能使用新工具来解决他们的目的。
- en: 'There are other APIs in Spark written in Python and R such as PySpark and SparkR
    respectively that allow you to use them from Python or R. However, most Spark
    books and online examples are written in Scala. Arguably, we think that learning
    how to work with Spark using the same language on which the Spark code has been
    written will give you many advantages over Java, Python, or R as a data scientist:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Spark中还有其他用Python和R编写的API，例如PySpark和SparkR，分别允许您从Python或R中使用它们。然而，大多数Spark书籍和在线示例都是用Scala编写的。我们认为，学习如何使用与Spark代码相同的语言来使用Spark将比Java、Python或R作为数据科学家带来更多优势：
- en: Better performance and removes the data processing overhead
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更好的性能并消除数据处理开销
- en: Provides access to the latest and greatest features of Spark
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供对Spark最新和最优秀的功能的访问
- en: Helps to understand the Spark philosophy in a transparent way
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帮助以透明的方式理解Spark的哲学
- en: Analyzing data means that you are writing Scala code to retrieve data from the
    cluster using Spark and its APIs (that is, SparkR, SparkSQL, Spark Streaming,
    Spark MLlib, and Spark GraphX). Alternatively, you're developing a Spark application
    using Scala to manipulate that data locally on your own machine. In both cases,
    Scala is your real friend and will pay you dividends in time.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 分析数据意味着您正在编写Scala代码，使用Spark及其API（即SparkR、SparkSQL、Spark Streaming、Spark MLlib和Spark
    GraphX）从集群中检索数据。或者，您正在使用Scala开发一个Spark应用程序，在本地机器上操作数据。在这两种情况下，Scala都是您真正的朋友，并将在时间上为您带来回报。
- en: Why FP and Scala for learning Spark?
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要学习Spark的FP和Scala？
- en: In this section, we will discuss why we will learn Spark to solve our data analytics
    problem. We will then discuss why the functional programming concepts in Scala
    are particularly important to make data analysis easier for the data scientists.
    We will also discuss the Spark programming model and its ecosystem to make them
    clearer.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论为什么要学习Spark来解决我们的数据分析问题。然后，我们将讨论为什么Scala中的函数式编程概念对于使数据分析对数据科学家更容易非常重要。我们还将讨论Spark编程模型及其生态系统，以使它们更清晰。
- en: Why Spark?
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么Spark？
- en: 'Spark is a lightning fast cluster computing framework and is mainly designed
    for fast computations. Spark is based on the Hadoop MapReduce model and uses MapReduce
    in more forms and types of computation, such as interactive queries and stream
    processing. One of the main features of Spark is in-memory processing, which helps
    increase the performance and processing speed of an application. Spark supports
    a wide range of applications and workloads, such as the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Spark是一个快速的集群计算框架，主要设计用于快速计算。Spark基于Hadoop MapReduce模型，并在更多形式和类型的计算中使用MapReduce，如交互式查询和流处理。Spark的主要特点之一是内存处理，这有助于提高应用程序的性能和处理速度。Spark支持各种应用程序和工作负载，如以下内容：
- en: Batch-based applications
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于批处理的应用程序
- en: Iterative algorithms that were not possible to run fast before
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以前无法快速运行的迭代算法
- en: Interactive query and streaming
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交互式查询和流处理
- en: 'Also, it doesn''t require much time for you to learn Spark and implement it
    in your applications without the need to understand the inner details of concurrency
    and distributed systems. Spark was implemented in 2009 at AMPLab of UC Berkeley.
    In 2010, they decided to make it open source. Then, Spark became an Apache release
    in 2013 and since then Spark has been considered as the most famous/used Apache-released
    software. Apache Spark became very famous because of its features:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，学习Spark并在应用程序中实现它并不需要太多时间，而无需了解并发和分布式系统的内部细节。Spark是在加州大学伯克利分校的AMPLab于2009年实施的。2010年，他们决定将其开源。然后，Spark在2013年成为Apache发布，并自那时起被认为是最著名/使用最广泛的Apache发布软件。Apache
    Spark因其功能而变得非常出名：
- en: '**Fast computations**: Spark helps you to run applications that are faster
    than Hadoop because of its golden feature--in-memory processing.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速计算**：由于其黄金特性--内存处理，Spark帮助您运行比Hadoop更快的应用程序。'
- en: '**Support for multiple programming languages**: Apache Spark provides wrappers
    and built-in APIs in different languages such as Scala, Java, Python, or even
    R.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持多种编程语言**：Apache Spark提供了不同语言的包装器和内置API，如Scala、Java、Python，甚至R。'
- en: '**More analytics**: As mentioned earlier, Spark supports MapReduce operations
    and it also supports more advanced analytics such as **machine learning** (**MLlib**),
    data streaming, and algorithms for graph processing.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更多的分析**：如前所述，Spark支持MapReduce操作，还支持更高级的分析，如**机器学习**（**MLlib**）、数据流和图处理算法。'
- en: 'As mentioned earlier, Spark is built on top of the Hadoop software and you
    can deploy Spark in different ways:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，Spark是建立在Hadoop软件之上的，您可以以不同的方式部署Spark：
- en: '**Standalone cluster**: This means that Spark will run on top of **Hadoop Distributed
    File System** (**HDFS**) and space will actually be allocated to HDFS. Spark and
    MapReduce will run side by side to serve all the Spark jobs.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**独立集群**：这意味着Spark将在**Hadoop分布式文件系统**（**HDFS**）之上运行，并且空间实际上将分配给HDFS。Spark和MapReduce将并行运行，以服务所有Spark作业。'
- en: '**Hadoop YARN cluster**: This means that Spark simply runs on YARN without
    any root privileges or pre-installations.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop YARN集群**：这意味着Spark只需在YARN上运行，无需任何根权限或预安装。'
- en: '**Mesos cluster**: When a driver program creates a Spark job and starts assigning
    related tasks for scheduling, Mesos determines which computing nodes will handle
    which tasks. We assume that you have already configured and installed Mesos on
    your machine.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mesos集群**：当驱动程序创建一个Spark作业并开始分配相关任务进行调度时，Mesos确定哪些计算节点将处理哪些任务。我们假设您已经在计算机上配置并安装了Mesos。'
- en: '**Deploy on pay-as-you-go cluster**: You can deploy Spark jobs in real cluster
    mode on AWS EC2\. To make your applications run on Spark cluster mode and for
    better scalability, you can consider **Amazon Elastic Compute Cloud** (**EC2**)
    services as **Infrastructure as a Service** (**IaaS**) or **Platform as a Service**
    (**PaaS**).'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**按需部署在集群上**：您可以在AWS EC2上以真实集群模式部署Spark作业。为了使您的应用程序在Spark集群模式下运行并实现更好的可伸缩性，您可以考虑将**Amazon弹性计算云**（**EC2**）服务作为**基础设施即服务**（**IaaS**）或**平台即服务**（**PaaS**）。'
- en: Refer to [Chapter 17](part0511.html#F7AFE1-21aec46d8593429cacea59dbdcd64e1c),
    *Time to Go to ClusterLand - Deploying Spark on a Cluster* and [Chapter 18](part0550.html#GCGLC1-21aec46d8593429cacea59dbdcd64e1c),
    *Testing and Debugging Spark* for how to deploy your data analytics application
    using Scala and Spark on a real cluster.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何在真实集群上使用Scala和Spark部署数据分析应用程序，请参阅[第17章](part0511.html#F7AFE1-21aec46d8593429cacea59dbdcd64e1c)，*前往集群部署Spark*和[第18章](part0550.html#GCGLC1-21aec46d8593429cacea59dbdcd64e1c)，*测试和调试Spark*。
- en: Scala and the Spark programming model
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala和Spark编程模型
- en: 'Spark programming starts with a dataset or a few, usually residing in some
    form of distributed and persistent storage such as HDFS. A typical RDD programming
    model that Spark provides can be described as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Spark编程始于数据集，通常驻留在分布式和持久存储（如HDFS）中。Spark提供的典型RDD编程模型可以描述如下：
- en: From an environment variable, Spark context (the Spark shell provides you with
    a Spark Context or you can make your own, this will be described later in this
    chapter) creates an initial data reference RDD object.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从环境变量、Spark上下文（Spark shell为您提供了一个Spark上下文，或者您可以自己创建，这将在本章后面描述）创建初始数据引用RDD对象。
- en: Transform the initial RDD to create more RDD objects following the functional
    programming style (to be discussed later on).
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按照函数式编程风格（稍后将讨论）转换初始RDD以创建更多RDD对象。
- en: Send the code, algorithms, or applications from the driver program to the cluster
    manager nodes. Then, the cluster manager provides a copy to each computing node.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从驱动程序向集群管理器节点发送代码、算法或应用程序。然后，集群管理器为每个计算节点提供一个副本。
- en: Computing nodes hold a reference to the RDDs in their partition (again, the
    driver program also holds a data reference). However, computing nodes could have
    the input dataset provided by the cluster manager as well.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算节点保存对其分区中的RDD的引用（同样，驱动程序也保存数据引用）。但是，计算节点也可以由集群管理器提供输入数据集。
- en: After a transformation (via either narrow or wider transformation), the result
    to be generated is a brand new RDD, since the original one will not be mutated.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在转换（通过窄转换或宽转换）之后，生成的结果将是全新的RDD，因为原始RDD不会发生变异。
- en: Finally, the RDD object or more (specifically, data reference) is materialized
    through an action to dump the RDD into the storage.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，通过操作将RDD对象或更多（具体来说，数据引用）实现为将RDD转储到存储中。
- en: The driver program can ask the computing nodes for a chunk of results for the
    analysis or visualization of a program.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 驱动程序可以向计算节点请求程序分析或可视化的结果块。
- en: Wait! So far we have moved smoothly. We suppose you will ship your application
    code to the computing nodes in the cluster. Still, you will have to upload or
    send the input datasets to the cluster to be distributed among the computing nodes.
    Even during the bulk upload, you will have to transfer the data across the network.
    We also argue that the size of the application code and results are negligible
    or trivial. Another obstacle is if you want Spark to process the data at scale
    computation, it might require data objects to be merged from multiple partitions
    first. This means we will need to shuffle data among the worker/computing nodes
    that is usually done by `partition()`, `intersection()`, and `join()` transformation
    operations.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 等等！到目前为止，我们一切顺利。我们假设您将把应用程序代码发送到集群中的计算节点。但是，您还需要将输入数据集上传或发送到集群，以便在计算节点之间进行分发。即使在批量上传期间，您也需要通过网络传输数据。我们还认为应用程序代码和结果的大小是可以忽略或微不足道的。另一个障碍是，如果您希望Spark进行规模化计算，可能需要首先从多个分区合并数据对象。这意味着我们需要在工作/计算节点之间进行数据洗牌，通常通过`partition()`、`intersection()`和`join()`转换操作来完成。
- en: Scala and the Spark ecosystem
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala和Spark生态系统
- en: To provide more enhancement and additional big data processing capabilities,
    Spark can be configured and run on top of existing Hadoop-based clusters. The
    core APIs in Spark, on the other hand, are written in Java, Scala, Python, and
    R. Compared to MapReduce, with the more general and powerful programming model,
    Spark also provides several libraries that are part of the Spark ecosystems for
    additional capabilities for general-purpose data processing and analytics, graph
    processing, large-scale structured SQL, and **Machine Learning** (**ML**) areas.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供更多的增强和额外的大数据处理能力，Spark可以配置并运行在现有基于Hadoop的集群之上。另一方面，Spark中的核心API是用Java、Scala、Python和R编写的。与MapReduce相比，Spark提供了更一般和强大的编程模型，还提供了几个库，这些库是Spark生态系统的一部分，用于通用数据处理和分析、图处理、大规模结构化SQL和**机器学习**（**ML**）领域的额外功能。
- en: "The Spark ecosystem consists of the following components as shown (for details\
    \ please refer [Chapter 16\uFEFF](part0480.html#E9OE01-21aec46d8593429cacea59dbdcd64e1c),\
    \ *Spark Tuning*):"
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Spark生态系统包括以下组件（有关详细信息，请参阅[第16章](part0480.html#E9OE01-21aec46d8593429cacea59dbdcd64e1c)，*Spark调优*）：
- en: '**Apache Spark core**: This is the underlying engine for the Spark platform
    on which all the other functionalities are built. Also, it''s the one that provides
    in-memory processing.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Spark核心**：这是Spark平台的基础引擎，所有其他功能都是在其上构建的。此外，它提供了内存处理。'
- en: '**Spark SQL**: As mentioned Spark core is the underlying engine and all the
    other components or features are built upon it. Spark SQL is the Spark component
    that provides support for different data structures (structured and semi-structured
    data).'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark SQL**：如前所述，Spark核心是底层引擎，所有其他组件或功能都是构建在其之上的。Spark SQL是提供对不同数据结构（结构化和半结构化数据）支持的Spark组件。'
- en: '**Spark streaming**: This component is responsible for streaming data for analytics
    and converts them into mini batches that can be used later on for analytics.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark streaming**：这个组件负责流式数据分析，并将其转换为可以后续用于分析的小批处理。'
- en: '**MLlib (Machine Learning Library)**: MLlib is a machine learning framework
    that supports lots of ML algorithms in a distributed fashion.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLlib（机器学习库）**：MLlib是一个支持大量ML算法的分布式机器学习框架。'
- en: '**GraphX**: A distributed graph framework built on top of Spark to express
    user-defined graph components in a parallel fashion.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GraphX**：一个建立在Spark之上的分布式图形框架，以并行方式表达用户定义的图形组件。'
- en: As mentioned earlier, most functional programming languages allow the user to
    write nice, modular, and extensible code. Also, functional programming encourages
    safe ways of programming by writing functions that look like mathematical functions.
    Now, how did Spark make all the APIs work as a single unit? It was possible because
    of the advancement in the hardware and of course, the functional programming concepts.
    Since adding syntactic sugar to easily do lambda expressions is not sufficient
    to make a language functional, this is just the start.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，大多数函数式编程语言允许用户编写漂亮、模块化和可扩展的代码。此外，函数式编程通过编写看起来像数学函数的函数来鼓励安全的编程方式。现在，Spark是如何使所有API作为一个单一单元工作的？这是可能的，因为硬件的进步，当然还有函数式编程的概念。由于添加语法糖以轻松地进行lambda表达式并不足以使一种语言成为函数式的，这只是一个开始。
- en: Although the RDD concept in Spark works quite well, there are many use cases
    where it's a bit complicated due to its immutability. For the following example
    which is the classic example of calculating an average, make the source code robust
    and readable; of course, to reduce the overall cost, one does not want to first
    compute totals, then counts, even if the data is cached in the main memory.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Spark中的RDD概念运行得相当不错，但在许多用例中，由于其不可变性，它有点复杂。对于下面的例子，这是计算平均值的经典例子，使源代码健壮且可读；当然，为了减少总体成本，人们不希望首先计算总数，然后计数，即使数据被缓存在主内存中。
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The DataFrames API (this will be discussed in the later chapters in detail)
    produces equally terse and readable code where the functional API fits well for
    most use cases and minimizes the MapReduce stages; there are many shuffles that
    can cost dramatically and the key reasons for this are as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框架API（这将在后面的章节中详细讨论）产生同样简洁和可读的代码，其中函数API非常适合大多数用例，并最小化了MapReduce阶段；有许多洗牌可能会造成巨大的成本，其主要原因如下：
- en: Large code bases require static typing to eliminate trivial mistakes, such as
    *aeg* instead of *age* instantly
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型代码库需要静态类型以消除微不足道的错误，比如*aeg*而不是*age*立即
- en: Complex code requires transparent APIs to communicate design clearly
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂的代码需要透明的API来清晰地传达设计
- en: 2x speed-ups in the DataFrames API via under-the-hood mutation can be equally
    achieved by encapsulating state via OOP and using mapPartitions and combineByKey
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过封装OOP状态并使用mapPartitions和combineByKey同样可以实现DataFrames API的2倍速度提升
- en: Flexibility and Scala features are required to build functionality quickly
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要灵活性和Scala特性来快速构建功能
- en: The combination of OOP and FP with Spark can make a pretty hard problem easier
    in Barclays. For example, in Barclays, recently an application called Insights
    Engine has been developed to execute an arbitrary number N of near-arbitrary SQL-like
    queries. The application can execute them in a way that can scale with increasing
    N.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在巴克莱，将OOP和FP与Spark结合可以使一个相当困难的问题变得更容易。例如，在巴克莱，最近开发了一个名为Insights Engine的应用程序，用于执行任意数量N个类似SQL的查询。该应用程序可以以一种可以随着N的增加而扩展的方式执行它们。
- en: Now let's talk about pure functions, higher order functions, and anonymous functions,
    which are the three important concepts in the functional programming of Scala.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们谈谈纯函数、高阶函数和匿名函数，这是Scala函数式编程中的三个重要概念。
- en: Pure functions and higher-order functions
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 纯函数和高阶函数
- en: 'From the computer science perspective, functions can have many forms such as
    first order functions, higher-order functions, or pure functions. This is also
    true from the mathematics point of view. Using a higher-order function is a function
    one of the following can be performed:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 从计算机科学的角度来看，函数可以有许多形式，如一阶函数、高阶函数或纯函数。从数学的角度来看也是如此。使用高阶函数可以执行以下操作之一：
- en: Takes one or more functions as arguments to do some operations
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一个或多个函数作为参数来执行一些操作
- en: Returns a function as its result
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一个函数作为其结果返回
- en: All other functions except the higher-order functions are first-order functions.
    However, from the mathematics point of view, higher-order functions are also called
    **operators** or **functionals**. On the other hand, if the return value of a
    function is only determined by its input and of course without observable side
    effects, it is called a **pure function**.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 除了高阶函数之外的所有其他函数都是一阶函数。然而，从数学的角度来看，高阶函数也被称为**操作符**或**函数式**。另一方面，如果一个函数的返回值仅由其输入决定，当然没有可观察的副作用，那么它被称为**纯函数**。
- en: In this section, we will briefly discuss why and how to use different functional
    paradigms in Scala. Especially, pure functions, and higher-order functions will
    be discussed. At the end of this section, a brief overview of using anonymous
    functions will also be provided since this is used frequently while developing
    a Spark application using Scala.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要讨论为什么以及如何在Scala中使用不同的函数式范式。特别是，将讨论纯函数和高阶函数。在本节结束时，还将提供使用匿名函数的简要概述，因为在使用Scala开发Spark应用程序时经常使用它。
- en: Pure functions
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 纯函数
- en: One of the most important principles of functional programming is pure functions.
    So what are pure functions and why do we care about them? In this section, we
    will address this important feature of functional programming. One of the best
    practices of functional programming is to implement your programs such that the
    core of your program/application is made from pure functions and all the I/O functions
    or side effects such as network overhead and exceptions are in an exposed external
    layer.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式编程的最重要原则之一是纯函数。那么纯函数是什么，我们为什么要关心它们？在本节中，我们将讨论函数式编程的这一重要特性。函数式编程的最佳实践之一是实现程序，使得程序/应用程序的核心由纯函数构成，而所有I/O函数或诸如网络开销和异常之类的副作用都在一个公开的外部层中。
- en: So what are the benefits of pure functions? Pure functions are normally smaller
    than normal functions (although it depends on other factors such as programming
    language) and even easier to interpret and understand for the human brain because
    it looks like a mathematical function.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 那么纯函数的好处是什么？纯函数通常比普通函数小（尽管这取决于其他因素，如编程语言），甚至更容易解释和理解，因为它看起来像一个数学函数。
- en: 'Yet, you might argue against this since most developers still find imperative
    programming more understandable! Pure functions are much easier to implement and
    test. Let''s demonstrate this by an example. Suppose we have the following two
    separate functions:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您可能会反对这一点，因为大多数开发人员仍然认为命令式编程更容易理解！纯函数要容易实现和测试得多。让我们通过一个例子来演示这一点。假设我们有以下两个单独的函数：
- en: '[PRE2]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'So in the previous two examples, if you want to test the `pureFunc` pure function,
    we just assert the return value that''s coming from the pure function with what
    we are expecting based on our input such as:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在前面的两个示例中，如果要测试`pureFunc`纯函数，我们只需断言来自纯函数的返回值与我们根据输入所期望的值相匹配即可：
- en: '[PRE3]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'But on the other side, if we wanted to test our `notpureFunc` impure function
    then we need to redirect the standard output and then apply assertion on it. The
    next practical tip is that functional programming makes programmers more productive
    because, as mentioned earlier, pure functions are smaller and easier to write
    and you can easily compose them together. Also, the duplication of code is minimal
    and you can easily reuse your code. Now let''s demonstrate this advantage with
    a better example. Consider these two functions:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 但另一方面，如果我们想测试我们的`notpureFunc`不纯函数，那么我们需要重定向标准输出，然后对其应用断言。下一个实用的提示是，函数式编程使程序员更加高效，因为如前所述，纯函数更小更容易编写，您可以轻松地将它们组合在一起。此外，代码的重复最小化，您可以轻松地重用您的代码。现在让我们通过一个更好的例子来演示这个优势。考虑这两个函数：
- en: '[PRE4]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'However, there might be side effects of mutability; using a pure function (that
    is, without mutability) helps us reason about and test code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，可变性可能会产生副作用；使用纯函数（即没有可变性）有助于我们推理和测试代码：
- en: '[PRE5]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This one is advantageous and very easy to interpret and use. However, let''s
    see another example:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这个优势是有利的，非常容易解释和使用。然而，让我们看另一个例子：
- en: '[PRE6]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, consider how confusing this could be: what will be the output in a multithreaded
    environment? As you can see, we can easily use our pure function, `pureMul`, to
    multiply any sequence of numbers, unlike our `notpureMul` impure function. Let''s
    demonstrate this by the following example:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑一下这可能有多令人困惑：在多线程环境中会输出什么？正如您所看到的，我们可以轻松地使用我们的纯函数`pureMul`来乘以任何一系列数字，而不像我们的`notpureMul`不纯函数。让我们通过以下示例来演示这一点：
- en: '[PRE7]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The complete code for the preceding examples can be shown as follows (methods
    were called using some real values):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 前面示例的完整代码如下所示（使用一些真实值调用了方法）：
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As discussed earlier, you can consider pure functions as one of the most important
    features of functional programming and as a best practice; you need to build the
    core of your application using pure functions.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，您可以将纯函数视为函数式编程的最重要特性之一，并且作为最佳实践；您需要使用纯函数构建应用程序的核心。
- en: 'Functions versus methods:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 函数与方法：
- en: 'In the programming realm, a **function** is a piece of code called by a name.
    Data (as an argument or as a parameter) can be passed to operate on and can return
    data (optionally). All data passed to a function is passed explicitly. A **method,**
    on the other hand, is also a piece of code that is called by a name too. However,
    a method is always associated with an object. Sounds similar? Well! In most cases,
    a method is identical to a function except for two key differences:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在编程领域，**函数**是通过名称调用的一段代码。数据（作为参数）可以传递以进行操作，并且可以返回数据（可选）。传递给函数的所有数据都是显式传递的。另一方面，**方法**也是通过名称调用的一段代码。然而，方法总是与对象相关联。听起来相似？在大多数情况下，方法与函数相同，除了两个关键差异：
- en: 1\. A method is implicitly passed the object on which it was called.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 方法隐式传递了调用它的对象。
- en: 2\. A method is able to operate on data that is contained within the class.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 方法能够操作类中包含的数据。
- en: It is already stated in the previous chapter that an object is an instance of
    a class--the class is the definition, the object is an instance of that data.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中已经说明，对象是类的一个实例--类是定义，对象是该数据的一个实例。
- en: Now it's time to learn about higher-order functions. However, before that, we
    should learn one more important concept in functional Scala--**anonymous functions**.
    Through this, we will also learn how to use the lambda expression with functional
    Scala.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是学习高阶函数的时候了。然而，在此之前，我们应该学习函数式Scala中的另一个重要概念--**匿名函数**。通过这个，我们还将学习如何在函数式Scala中使用lambda表达式。
- en: Anonymous functions
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 匿名函数
- en: 'Sometimes in your code, you don''t want to define a function prior to its usage,
    maybe because you will use it in one place. In functional programming, there''s
    a type of function that is very suitable to this situation. It''s called an anonymous
    function. Let''s demonstrate the use of anonymous functions using the previous
    example of transferring money:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有时在你的代码中，你不想在使用之前定义一个函数，也许是因为你只会在一个地方使用它。在函数式编程中，有一种非常适合这种情况的函数类型。它被称为匿名函数。让我们使用转账的前面示例来演示匿名函数的使用：
- en: '[PRE10]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, let''s call the `TransferMoney()` method with some real value as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们用一些真实的值调用`TransferMoney()`方法如下：
- en: '[PRE11]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Lambda expression:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda表达式：
- en: 'As already stated, Scala supports first-class functions, which means functions
    can be expressed in function-literal syntax as well; functions can be represented
    by objects, called function values. Try the following expression, it creates a
    successor function for integers:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 正如已经说明的，Scala支持头等函数，这意味着函数可以用函数文字语法来表示；函数可以被称为对象，称为函数值。尝试以下表达式，它创建了一个整数的后继函数：
- en: '`scala> var apply = (x:Int) => x+1`'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`scala> var apply = (x:Int) => x+1`'
- en: '`apply: Int => Int = <function1>`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`apply: Int => Int = <function1>`'
- en: 'The apply variable is now a function that can be used in the usual way as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在apply变量是一个可以像下面这样通常使用的函数：
- en: '`scala> var x = apply(7)`'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`scala> var x = apply(7)`'
- en: '`x: Int = 8`'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`x: Int = 8`'
- en: 'What we have done here is simply use the core of a function: the argument list
    followed by the function arrow and the body of the function. This one is not black
    magic but a full-fledged function, only without a given name--that is, anonymous.
    If you define a function this way, there will be no way to refer to that function
    afterward and hence you couldn''t call that function afterward because without
    a name it''s an anonymous one. Also, we have a so-called **lambda expression**!
    It''s just the pure, anonymous definition of a function.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里所做的只是使用函数的核心部分：参数列表，然后是函数箭头和函数体。这不是黑魔法，而是一个完整的函数，只是没有给定的名称--也就是匿名的。如果你以这种方式定义一个函数，将没有办法在之后引用该函数，因此你不能在之后调用该函数，因为没有名称它就是匿名的。此外，我们有一个所谓的**lambda表达式**！它只是一个纯粹的、匿名的函数定义。
- en: 'The output of the preceding code is as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'So, in the previous example instead of declaring a separate `callback` function,
    we passed an anonymous function directly and it did the same job just like the
    `bankFee` function. You can also omit the type in the anonymous function and it
    will be directly inferred based on the passed argument like this:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在前面的示例中，我们直接传递了一个匿名函数，而不是声明一个单独的`callback`函数，它和`bankFee`函数一样完成了相同的工作。你也可以在匿名函数中省略类型，它将根据传递的参数直接推断出类型，就像这样：
- en: '[PRE13]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '[PRE14]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s demonstrate the previous example on the Scala shell as shown in the
    following screenshot:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在Scala shell中演示前面的例子，如下面的截图所示：
- en: '![](img/00066.jpeg)**Figure 6:** Use of the anonymous function in Scala'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/00066.jpeg)**图6：**在Scala中使用匿名函数'
- en: Some programming languages that have functional support use the name lambda
    function instead of anonymous function.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一些支持函数的编程语言使用lambda函数的名称，而不是匿名函数。
- en: Higher-order functions
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高阶函数
- en: In Scala's functional programming, you are allowed to pass functions as parameters
    and even return a function as a result from another function; this defines what
    are called higher-order functions.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在Scala的函数式编程中，你可以允许将函数作为参数传递，甚至从另一个函数中返回一个函数；这定义了所谓的高阶函数。
- en: 'Let''s demonstrate this feature by an example. Consider the following function
    `testHOF` that takes another function `func` and then applies this function to
    its second argument value:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来演示这个特性。考虑以下函数`testHOF`，它接受另一个函数`func`，然后将这个函数应用到它的第二个参数值上：
- en: '[PRE15]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: After demonstrating the basics of Scala's functional programming, now we are
    ready to move to more complex cases of functional programming. As mentioned earlier,
    we can define a higher-order function as a function that accepts other functions
    as arguments and it returns them as a result. If you are coming from an object-oriented
    programming background, you will find it very a different approach, but it will
    become easier to understand as we go on.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在演示了Scala函数式编程的基础知识之后，现在我们准备转向更复杂的函数式编程案例。如前所述，我们可以将高阶函数定义为接受其他函数作为参数并将它们作为结果返回的函数。如果你来自面向对象的编程背景，你会发现这是一种非常不同的方法，但随着我们的学习，你会发现它变得更容易理解。
- en: 'Let''s start by defining a simple function:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义一个简单的函数开始：
- en: '[PRE16]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The previous function is a very simple one. It''s a function that accepts an
    Int value and then returns a quarter of this value in a `Double` type. Let''s
    define another simple function:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的函数非常简单。它是一个接受Int值然后返回这个值的四分之一的函数，返回类型是`Double`。让我们定义另一个简单的函数：
- en: '[PRE17]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The second function `addTwo` is more trivial than the first one. It accepts
    an `Int` value and then adds 2 to it. As you can see, these two functions have
    something in common. Both of them accept `Int` and return another processed value
    that we can call `AnyVal`. Now, let''s define a higher-order function that accepts
    another function among its parameters:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个函数`addTwo`比第一个函数更简单。它接受一个`Int`值，然后将2加到它上。正如你所看到的，这两个函数有一些共同之处。它们都接受`Int`并返回另一个经过处理的值，我们可以称之为`AnyVal`。现在，让我们定义一个接受另一个函数作为参数的高阶函数：
- en: '[PRE18]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see, the preceding function `applyFuncOnRange` accepts two `Int`
    values that work as a beginning and end to a sequence and it accepts a function
    that has the `Int => AnyVal` signature just like the previously defined simple
    functions (`quarterMakder` and `addTwo`). Now let's demonstrate our previous higher-order
    function by passing one of the two simple functions to it as a third argument
    (if you want to pass your own function then make sure that it has the same signature
    `Int => AnyVal`).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，前面的`applyFuncOnRange`函数接受两个`Int`值，作为序列的开始和结束，并接受一个具有`Int => AnyVal`签名的函数，就像先前定义的简单函数（`quarterMakder`和`addTwo`）一样。现在让我们通过将两个简单函数中的一个作为第三个参数传递给它来演示我们之前的高阶函数（如果您想要传递自己的函数，那么请确保它具有相同的签名`Int
    => AnyVal`）。
- en: '**Scala syntax for loop with ranges:** The simplest syntax of using a for loop
    with ranges in Scala is:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**Scala循环范围的语法：**在Scala中使用for循环与范围的最简单语法是：'
- en: '`for( var x <- range ){`'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '`for( var x <- range ){`'
- en: '`statement(s)`'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`语句（s）`'
- en: '`}`'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`}`'
- en: 'Here, the `range` could be a range of numbers and is represented as `i` to
    `j` or sometimes like `i` until `j`. The left-arrow `←` operator is called a generator
    because it''s generating individual values from a range. Let''s see a concrete
    example of this feature:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，“range”可以是一系列数字，表示为“i”到“j”，有时像“i”直到“j”。左箭头“←”操作符被称为生成器，因为它从范围生成单个值。让我们看一个具体的例子：
- en: '`object UsingRangeWithForLoop {`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`object UsingRangeWithForLoop {`'
- en: '`def main(args: Array[String]):Unit= {`'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`def main(args: Array[String]):Unit= {`'
- en: '`var i = 0;`'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`var i = 0;`'
- en: '`// for loop execution with a range`'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: // 使用范围进行for循环执行
- en: '`for( i <- 1 to 10){`'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`for（i <- 1 to 10）{`'
- en: '`println( "Value of i: " + i )`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`println（"i的值：" + i）`'
- en: '`}`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`}`'
- en: '`}`'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`}'
- en: '`}`'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`}`'
- en: 'The output of the preceding code is as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '`Value of i: 1`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: i的值：1
- en: '`Value of i: 2`'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: i的值：2
- en: '`Value of i: 3`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: i的值：3
- en: '`Value of i: 4`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: i的值：4
- en: '`Value of i: 5`'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: i的值：5
- en: '`Value of i: 6`'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: i的值：6
- en: '`Value of i: 7`'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: i的值：7
- en: '`Value of i: 8`'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: i的值：8
- en: '`Value of i: 9`'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: i的值：9
- en: '`Value of i: 10`'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: i的值：10
- en: 'Let''s first define our functions before starting to use them as shown in the
    following screenshot:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始使用它们之前，让我们首先定义我们的函数，如下截图所示：
- en: '![](img/00070.jpeg)**Figure 2:** An example of defining a higher-order function
    in Scala'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：在Scala中定义高阶函数的示例
- en: 'Now, let''s start by calling our higher-order function `applyFuncOnRange` and
    passing the `quarterMaker` function as a third argument:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们首先调用我们的高阶函数`applyFuncOnRange`，并将`quarterMaker`函数作为第三个参数传递：
- en: '![](img/00074.jpeg)**Figure 3:** Calling a higher-order function'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：调用高阶函数
- en: 'We can even apply the other function `addTwo` since it has the same signature
    as shown in the following screenshot:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以应用另一个函数`addTwo`，因为它具有与以下截图中显示的相同签名：
- en: '![](img/00079.jpeg)**Figure 4:** An alternative way of calling a higher-order
    function'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：调用高阶函数的另一种方式
- en: 'Before going into more examples, let''s define what''s called a callback function.
    A callback function is a function that can be passed as an argument to another
    function. Other functions are simply normal functions. Let''s demonstrate more
    examples of using different callback functions. Consider the following higher-order
    function, which is responsible for transferring a specific amount of money from
    your account:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入更多的例子之前，让我们定义所谓的回调函数。回调函数是一个可以作为参数传递给另一个函数的函数。其他函数只是普通函数。让我们演示使用不同回调函数的更多例子。考虑以下高阶函数，负责从您的账户转移特定金额的资金：
- en: '[PRE19]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After calling the `TransferMoney` function on 100:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在100上调用`TransferMoney`函数后：
- en: '[PRE20]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '[PRE21]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: From a functional programming point of view, this code is not ready to be integrated
    into the banking system because you need to apply different validations on the
    money parameters, such as it has to be positive and greater than the specific
    amount specified by the bank. However, here we are just demonstrating the use
    of high-order functions and callback functions.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 从函数式编程的角度来看，这段代码还没有准备好集成到银行系统中，因为您需要对资金参数应用不同的验证，比如它必须是正数，并且大于银行指定的特定金额。然而，在这里，我们只是演示高阶函数和回调函数的使用。
- en: 'So, this example works as follows: you want to transfer a specific amount of
    money to another bank account or money agent. The bank has a specific fee to be
    applied depending on the amount that you are transferring and here comes the role
    of the callback function. It takes the amount of money to transfer and applies
    the bank fee to it in order to come up with the total amount.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个例子的工作方式如下：您想要将特定金额的资金转移到另一个银行账户或资金代理。银行有特定的费用要根据您转移的金额来应用，这就是回调函数的作用。它接受要转移的金额，并对其应用银行手续费，以得出总金额。
- en: 'The `TransferMoney` function takes two parameters: the first one is the money
    to be transferred and the second one is a callback function with the signature
    `Double => Double` that the function applies to the money argument to determine
    the bank fee over the transferred money.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`TransferMoney`函数接受两个参数：第一个是要转移的金额，第二个是一个带有`Double => Double`签名的回调函数，该函数应用于金额参数，以确定转移金额的银行手续费。'
- en: '![](img/00083.jpeg)**Figure 5:** Calling and giving extra power to the higher-order
    function'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：调用并赋予高阶函数额外的权力
- en: 'The complete source code of the preceding examples can be seen as follows (we
    called the methods using some real values):'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例的完整源代码如下（我们使用了一些真实值来调用这些方法）：
- en: '[PRE22]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '[PRE23]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: By using callback functions, you are giving extra power to the higher-order
    function; so, it's a very powerful mechanism to make your program more elegant,
    flexible, and efficient.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用回调函数，您为高阶函数赋予了额外的权力；因此，这是一种使您的程序更加优雅、灵活和高效的强大机制。
- en: Function as a return value
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数作为返回值
- en: 'As mentioned, higher-order functions also support returning a function as a
    result. Let''s demonstrate this by an example:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，高阶函数还支持将函数作为结果返回。让我们通过一个例子来演示这一点：
- en: '[PRE24]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The preceding code segment will produce the following output:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码段将产生以下输出：
- en: '[PRE25]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let''s run the previous example as shown in the following screenshot; it shows
    how to use the function as a return value:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照以下截图中显示的方式运行前面的示例；它展示了如何将函数用作返回值：
- en: '![](img/00087.jpeg)**Figure 7:** Function as a return value'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/00087.jpeg)**图7：**函数作为返回值'
- en: 'The complete code of the preceding example can be seen as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 前面示例的完整代码如下所示：
- en: '[PRE26]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下所示：
- en: '[PRE27]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Now before stopping our discussion on HFO, let's see a real-life example, that
    is, currying using HFO.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束对HFO的讨论之前，让我们看一个现实生活的例子，即使用HFO进行柯里化。
- en: Using higher-order functions
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用高阶函数
- en: 'Suppose you work in a restaurant as a chef and one of your colleagues ask you
    a question: Implement a **HOF** (**higher-order function**) that performs currying.
    Looking for clues? Suppose you have the following two signatures for your HOF:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您在一家餐厅里担任厨师，您的一个同事问您一个问题：实现一个**HOF**（高阶函数），执行柯里化。寻找线索？假设您的HOF有以下两个签名：
- en: '[PRE28]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Similarly, implement a function that performs uncurrying as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，实现一个执行uncurrying的函数，如下所示：
- en: '[PRE29]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, how could you use HOFs to perform the currying operation? Well, you could
    create a trait that encapsulates the signatures of two HOFs (that is, curry and
    uncurry) as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您如何使用HOF来执行柯里化操作呢？嗯，您可以创建一个封装两个HOF签名（即curry和uncurry）的特性，如下所示：
- en: '[PRE30]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, you can implement and extend this trait as an object as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以按照以下方式将此特性实现并扩展为对象：
- en: '[PRE31]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here I have implemented the uncurry first since it's easier. The two curly braces
    after the equals sign are an anonymous function literal for taking two arguments
    (that is, `a` and `b` of types `X` and `Y` respectively). Then, these two arguments
    can be used in a function that also returns a function. Then, it passes the second
    argument to the returned function. Finally, it returns the value of the second
    function. The second function literal takes one argument and returns a new function,
    that is, `curry()`. Eventually, it returns a function when called returns another
    function.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我首先实现了uncurry，因为它更容易。等号后面的两个大括号是一个匿名函数，用于接受两个参数（即类型为`X`和`Y`的`a`和`b`）。然后，这两个参数可以在一个还返回函数的函数中使用。然后，它将第二个参数传递给返回的函数。最后，它返回第二个函数的值。第二个函数字面量接受一个参数并返回一个新的函数，即`curry()`。最终，当调用时返回另一个函数。
- en: 'Now it comes: how to use the preceding object that extends the base trait in
    a real-life implementation. Here''s an example:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在问题来了：如何在实际实现中使用扩展基本特性的前面对象。以下是一个例子：
- en: '[PRE32]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In the preceding object and inside the main method:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的对象和主方法中：
- en: The `addSpicy` holds a function that takes a long as a type and adds 1 to it
    and then prints 4.0.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`addSpicy`保存了一个函数，它将一个long类型的数加1，然后打印出4.0。'
- en: The `increment` holds a function which takes a long as a type and adds 2 to
    it and finally prints 3.0.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`increment`保存了一个函数，它将一个long类型的数加2，最后打印出3.0。'
- en: The `unspicedAdd` holds a function which adds 1 and takes a long as type. Finally,
    it prints 7.0.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unspicedAdd`保存了一个函数，它将1加上并将其类型定义为long。最后，它打印出7.0。'
- en: 'The output of the preceding code is as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下所示：
- en: '[PRE33]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In mathematics and computer science, currying is the technique of translating
    the evaluation of a function that takes multiple arguments (or a tuple of arguments)
    into evaluating a sequence of functions, each with a a single argument. Currying
    is related to, but not the same as, partial application:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学和计算机科学中，柯里化是将接受多个参数（或参数元组）的函数的求值转换为求值一系列函数的技术，每个函数只接受一个参数。柯里化与偏函数应用相关，但并不相同：
- en: '**Currying:** Currying is useful in both practical and theoretical settings.
    In functional programming languages, and many others, it provides a way of automatically
    managing how arguments are passed to functions and exceptions. In theoretical
    computer science, it provides a way to study functions with multiple arguments
    in simpler theoretical models, which provide only one argument.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**柯里化：**柯里化在实际和理论环境中都很有用。在函数式编程语言和许多其他语言中，它提供了一种自动管理函数和异常传递参数的方式。在理论计算机科学中，它提供了一种研究具有多个参数的函数的方式，这些函数在更简单的理论模型中只提供一个参数。'
- en: '**Uncurrying:** Uncurrying is the dual transformation to currying, and can
    be seen as a form of defunctionalization. It takes a function `f` whose return
    value is another function `g` and yields a new function `f′` that takes as parameters
    the arguments for both `f` and `g`, and returns, as a result, the application
    of `f` and subsequently, `g`, to those arguments. The process can be iterated.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**反柯里化：**反柯里化是柯里化的对偶转换，可以看作是一种去函数化的形式。它接受一个返回值为另一个函数`g`的函数`f`，并产生一个新的函数`f′`，该函数接受`f`和`g`的参数作为参数，并作为结果返回`f`和随后`g`对这些参数的应用。这个过程可以迭代。'
- en: So far, we have seen how to deal with pure, higher-order, and anonymous functions
    in Scala. Now, let's have a brief overview on how to extend the higher-order function
    using `Throw`, `Try`, `Either`, and `Future` in the following section.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了如何在Scala中处理纯函数、高阶函数和匿名函数。现在，让我们简要概述如何在接下来的部分中使用`Throw`、`Try`、`Either`和`Future`来扩展高阶函数。
- en: Error handling in functional Scala
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在函数式Scala中的错误处理
- en: So far, we focused on ensuring that the body of a Scala function does what it's
    supposed to and doesn't do anything else (that is, an error or exception). Now,
    in order to make use of any programming and to avoid producing error-prone code
    then you need to know how to catch exceptions and handle errors in this language.
    We will see how to extend higher-order functions outside collections using some
    special features of Scala such as `Try`, `Either`, and `Future`.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们专注于确保Scala函数的主体执行其预期的操作，不做其他事情（即错误或异常）。现在，为了利用任何编程并避免产生容易出错的代码，你需要知道如何在这种语言中捕获异常和处理错误。我们将看到如何使用Scala的一些特殊特性，如`Try`、`Either`和`Future`，来扩展集合之外的高阶函数。
- en: Failure and exceptions in Scala
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala中的故障和异常
- en: 'At first, let''s define what we mean by failures in general (source: [https://tersesystems.com/2012/12/27/error-handling-in-scala/](https://tersesystems.com/2012/12/27/error-handling-in-scala/)):'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义一般情况下我们所说的故障是什么（来源：[https://tersesystems.com/2012/12/27/error-handling-in-scala/](https://tersesystems.com/2012/12/27/error-handling-in-scala/)）：
- en: '**Unexpected internal failure**: The operation fails as the result of an unfulfilled
    expectation, such as a null pointer reference, violated assertions, or simply
    bad state'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**意外的内部故障**：操作失败，因为未实现的期望，比如空指针引用，违反的断言，或者简单的坏状态'
- en: '**Expected internal failure**: The operation fails deliberately as a result
    of internal state, that is, a blacklist or circuit breaker'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预期的内部故障**：操作故意失败，因为内部状态，即黑名单或断路器'
- en: '**Expected external failure**: The operation fails because it is told to process
    some raw input, and will fail if the raw input cannot be processed'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预期的外部故障**：操作失败，因为它被告知处理一些原始输入，并且如果无法处理原始输入，就会失败'
- en: '**Unexpected external failure**: The operation fails because a resource that
    the system depends on is not there: there''s a loose file handle, the database
    connection fails, or the network is down'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**意外的外部故障**：操作失败，因为系统依赖的资源不存在：有一个松散的文件句柄，数据库连接失败，或者网络中断了'
- en: 'Unfortunately, there are no concrete ways of stopping failures unless the failures
    are due to some manageable exceptions. On the other hand, Scala makes *checked
    versus unchecked* very simple: it doesn''t have checked exceptions. All exceptions
    are unchecked in Scala, even `SQLException` and `IOException`, and so on. Now
    let''s see how to handle such exceptions at least.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，除非故障是由一些可管理的异常引起的，否则没有具体的方法来阻止故障。另一方面，Scala使*checked versus unchecked*非常简单：它没有检查异常。在Scala中，所有异常都是未经检查的，甚至`SQLException`和`IOException`等等。现在让我们看看如何至少处理这样的异常。
- en: Throwing exceptions
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 抛出异常
- en: 'A Scala method can throw an exception because of the unexpected workflow. You
    create an exception object and then you throw it with the throw keyword as follows.
    For example:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Scala方法可能会因为意外的工作流程而抛出异常。你创建一个异常对象，然后用`throw`关键字抛出它，如下所示。例如：
- en: '[PRE34]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Note that the primary goal of using exception handling is not to produce friendly
    messages but to exit the normal flow of your Scala program.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，使用异常处理的主要目标不是生成友好的消息，而是退出Scala程序的正常流程。
- en: Catching exception using try and catch
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用try和catch捕获异常
- en: 'Scala allows you to try/catch any exception in a single block and then perform
    pattern matching against it using case blocks. The basic syntax of using `try...catch`
    in Scala is as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: Scala允许你在一个单一的块中尝试/捕获任何异常，然后使用case块对其进行模式匹配。在Scala中使用`try...catch`的基本语法如下：
- en: '[PRE35]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Thus, if you throw an exception, then you need to use the `try...catch` block
    in order to handle it nicely without crashing with an internal exception message:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你抛出异常，那么你需要使用`try...catch`块来优雅地处理它，而不是用内部异常消息崩溃：
- en: '[PRE36]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If there''s no file named `data.txt`, in the path/data under your project tree,
    you will experience `FileNotFoundException` as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在项目树下的路径/数据中没有名为`data.txt`的文件，你将会遇到`FileNotFoundException`，如下所示：
- en: 'The output of the preceding code is as follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '[PRE37]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Now, let's have a brief example of using the `finally` clause in Scala to make
    the `try...catch` block complete.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们简要介绍一下在Scala中使用`finally`子句使`try...catch`块完整的例子。
- en: Finally
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后
- en: 'Suppose you want to execute your code regardless of an exception being thrown
    or not, then you should use the `finally` clause. You can place it inside the
    `try block` as follows. Here is an example:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想执行你的代码，不管是否抛出异常，那么你应该使用`finally`子句。你可以将它放在`try block`中，如下所示。这是一个例子：
- en: '[PRE38]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, here''s the complete example of using `try...catch...finally`:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这是使用`try...catch...finally`的完整示例：
- en: '[PRE39]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '[PRE40]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Next, we will discuss another powerful feature in Scala called `Either`.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论Scala中的另一个强大特性，称为`Either`。
- en: Creating an Either
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个Either
- en: '`Either[X, Y]` is an instance that contains either an instance of `X` or an
    instance of `Y` but not both. We call these subtypes left and right of Either.
    Creating an Either is trivial. But it''s very powerful sometimes to use it in
    your program:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '`Either[X, Y]` 是一个实例，它包含了`X`的实例或`Y`的实例，但不会同时包含两者。我们称这些子类型为Either的左和右。创建一个Either是微不足道的。但有时在程序中使用它非常强大：'
- en: '[PRE41]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, if we pass any arbitrary URL that doesn''t contain `xxx` then we will
    get a `Scala.io.Source` wrapped in a `Right` subtype. If the URL contains `xxx`,
    then we will get a `String` wrapped in a `Left` subtype. To make the preceding
    statement clearer, let''s see the output of the preceding code segment:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们传递任意不包含`xxx`的URL，那么我们将得到一个包装在`Right`子类型中的`Scala.io.Source`。如果URL包含`xxx`，那么我们将得到一个包装在`Left`子类型中的`String`。为了使前面的陈述更清晰，让我们看看前面代码段的输出：
- en: '[PRE42]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Next, we will explore another interesting feature of Scala called `Future` that
    is used to execute tasks in a non-blocking way. This is also a better way to handle
    the results when they finish.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨Scala的另一个有趣特性，称为`Future`，它用于以非阻塞方式执行任务。这也是在任务完成时处理结果的更好方式。
- en: Future
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Future
- en: If you simply want to run tasks in a non-blocking way and need a way to handle
    the results when they finish, Scala provides you with Futures, for example, if
    you want to make multiple web service calls in a parallel fashion and work with
    the results after the web service handles all these calls. An example of using
    Future is provided in the following section.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只是想以非阻塞的方式运行任务，并且需要一种在任务完成时处理结果的方法，Scala为你提供了Futures，例如，如果你想以并行方式进行多个web服务调用，并在web服务处理所有这些调用后处理结果。下面的部分提供了使用Future的例子。
- en: Run one task, but block
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行一个任务，但是阻塞
- en: 'The following example demonstrates how to create a Future and then block the
    sequence of execution in order to wait for its result. Creating Futures is trivial.
    You just need to pass it to the code that you want. The following example performs
    2+2 in the future and then returns the results:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的例子演示了如何创建一个Future，然后阻塞执行顺序以等待其结果。创建Futures很简单。你只需要把它传递给你想要的代码。下面的例子在未来执行2+2，然后返回结果：
- en: '[PRE43]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The `Await.result` method waits up to 2 seconds till the `Future` returns the
    result; if it doesn''t return the result within 2 seconds, it throws the following
    exception you might want to handle or catch:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '`Await.result`方法等待最多2秒，直到`Future`返回结果；如果在2秒内没有返回结果，它会抛出下面的异常，你可能想要处理或捕获：'
- en: '[PRE44]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: It's time to wrap up this chapter. However, I would like to take the chance
    to discuss an important view of mine about functional programming with Scala and
    object mutability.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候结束这一章了。然而，我想借此机会讨论一下我对Scala函数式编程和对象可变性的重要观点。
- en: Functional programming and data mutability
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式编程和数据可变性
- en: Pure functional programming is one of the best practices in functional programming
    and you should stick to it. Writing pure functions will make your programming
    life easier and you will be able to write code that's easy to maintain and extend.
    Also, if you want to parallelize your code then it will be easier to do so if
    you write pure functions.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 纯函数式编程是函数式编程中的最佳实践之一，你应该坚持下去。编写纯函数将使你的编程生活更轻松，你将能够编写易于维护和扩展的代码。此外，如果你想并行化你的代码，那么如果你编写纯函数，这将更容易实现。
- en: If you're an FP purist, one drawback of using functional programming in Scala
    is that Scala supports both OOP and FP (see *Figure 1*), and therefore it's possible
    to mix the two coding styles in the same code base. In this chapter, we have seen
    several examples showing that writing pure functions is easy. However, combining
    them into a complete application is difficult. You might agree that advanced topics
    such as monads make FP intimidating.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一个FP纯粹主义者，在Scala中使用函数式编程的一个缺点是Scala同时支持OOP和FP（见*图1*），因此可能会在同一个代码库中混合这两种编码风格。在本章中，我们看到了几个例子，表明编写纯函数是容易的。然而，将它们组合成一个完整的应用程序是困难的。你可能会同意，像单子这样的高级主题使FP变得令人生畏。
- en: I talked to many people and they think that the recursion doesn't feel reasonably
    natural. When you use immutable objects, you can never mutate them with something
    else. There aren't times when you are allowed to do that. That's the whole point
    of immutable objects! Sometimes what I have experienced is that a pure function
    and data input or output really mixes up. However, when you need to mutate, you
    can create a copy of the object containing your mutated field. Thus, theoretically,
    there's no need to *mix up*. Lastly, using only immutable values and recursion
    can potentially lead to performance problems in terms of CPU usage and RAM.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我和很多人交谈过，他们认为递归并不是很自然的。当你使用不可变对象时，你永远不能用其他东西来改变它们。没有时候你被允许这样做。这就是不可变对象的全部意义！有时我经历过的是，纯函数和数据输入或输出真的混在一起。然而，当你需要改变时，你可以创建一个包含你改变字段的对象的副本。因此，从理论上讲，没有必要*混合*。最后，只使用不可变值和递归可能会导致CPU使用和RAM方面的性能问题。
- en: Summary
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have explored some functional programming concepts in Scala.
    We have seen what functional programming is and how Scala supports it, why it
    matters, and the advantages of using functional concepts. We have seen why learning
    FP concepts is important in learning the Spark paradigm. Pure functions, anonymous
    functions, and higher-order functions were discussed with suitable examples. Later
    in this chapter, we saw how to handle exceptions in the higher-order functions
    outside collections using the standard library of Scala. Finally, we discussed
    how functional Scala affects object mutability.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们探讨了Scala中的一些函数式编程概念。我们看到了函数式编程是什么，以及Scala如何支持它，为什么它很重要，以及使用函数式概念的优势。我们看到了为什么学习FP概念在学习Spark范式中很重要。纯函数、匿名函数和高阶函数都有适当的例子进行了讨论。在本章后期，我们看到了如何在Scala的标准库中处理高阶函数外的集合中的异常。最后，我们讨论了函数式Scala如何影响对象的可变性。
- en: In the next chapter, we will provide an in-depth analysis on the Collections
    API, one of the most prominent features of the standard library.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将对集合API进行深入分析，这是标准库中最突出的特性之一。
