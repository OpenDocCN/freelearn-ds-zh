- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Creating a Distributed Text-to-Image AI System Using the Stable Diffusion Model
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Stable Diffusion 模型创建分布式文本到图像 AI 系统
- en: 'Until now, in this book, we’ve built APIs where all the operations were computed
    inside the request handling. Said another way, before they could get their response,
    the user had to wait for the server to do everything we had defined: request validation,
    database queries, ML predictions, and so on. However, this behavior is not always
    desired or possible.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在这本书中，我们构建的 API 中所有操作都是在请求处理内部计算的。换句话说，用户必须等待服务器完成我们定义的所有操作（如请求验证、数据库查询、ML
    预测等），才能收到他们的响应。然而，并非总是希望或可能要求这种行为。
- en: 'A typical example is email notifications. It happens quite often in a web application
    that we need to send an email to the user because they just registered or they
    performed a specific action. To do this, the server needs to send a request to
    an email server so the email can be sent. This operation could take a few milliseconds.
    If we do this inside the request handling, the response will be delayed until
    we send the email. This is not a very good experience since the user doesn’t really
    care how and when the email is sent. This example is typical of what we usually
    call **background operations**: things that need to be done in our application
    but don’t require direct user interaction.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 典型例子是电子邮件通知。在 Web 应用程序中，我们经常需要向用户发送电子邮件，因为他们刚刚注册或执行了特定操作。为了做到这一点，服务器需要向电子邮件服务器发送请求，以便发送电子邮件。此操作可能需要几毫秒时间。如果我们在请求处理中执行此操作，响应将延迟直到我们发送电子邮件。这不是一个很好的体验，因为用户并不真正关心电子邮件是如何何时发送的。这个例子是我们通常所说的**后台操作**的典型例子：需要在我们的应用程序中完成的事情，但不需要直接用户交互。
- en: Another case is when the user requests an expensive operation that can’t be
    done in a reasonable time. It’s usually the case for complex data exports or heavy
    AI models. In this context, the user would like to get the result directly, but
    doing this in the request handler would block the server process until it’s done.
    If lots of users were requesting this kind of operation, it would quickly make
    our server unresponsive. Besides, some network infrastructure such as proxy or
    web clients, like browsers, have quite strict timeout settings, meaning they will
    usually cancel an operation if it takes too much time to respond.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种情况是当用户请求一个耗时的操作，在合理的时间内无法完成。这通常是复杂数据导出或重型 AI 模型的情况。在这种情况下，用户希望直接获取结果，但如果在请求处理程序中执行此操作，将会阻塞服务器进程，直到完成。如果大量用户请求这种操作，会迅速使我们的服务器无响应。此外，某些网络基础设施，如代理或
    Web 客户端（如浏览器），具有非常严格的超时设置，这意味着如果响应时间过长，它们通常会取消操作。
- en: 'To solve this, we’ll introduce a typical architecture for web applications:
    **web-queue-worker**. As we’ll see in this chapter, we’ll defer the most expensive,
    long operations to a background process, a **worker**. To show you this architecture
    in action, we’ll build our very own AI system to generate images from text prompts
    using the **Stable** **Diffusion** model.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们将引入一个典型的 Web 应用程序架构：**web-queue-worker**。正如我们将在本章中看到的，我们将把最昂贵、耗时最长的操作推迟到后台进程，即**worker**。为了展示这种架构的运行方式，我们将建立我们自己的
    AI 系统，使用**Stable Diffusion**模型根据文本提示生成图像。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将涵盖以下主要话题：
- en: Using the Stable Diffusion model with Hugging Face Diffusers to generate images
    from text prompts
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Stable Diffusion 模型与 Hugging Face Diffusers 生成图像的文本提示
- en: Implementing a worker process using Dramatiq and an image-generation task
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Dramatiq 实现工作进程和图像生成任务
- en: Storing and serving files in object storage
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储和服务于对象存储中的文件
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you’ll require a Python virtual environment, just as we set
    up in [*Chapter 1*](B19528_01.xhtml#_idTextAnchor024), *Python Development* *Environment
    Setup*.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，您将需要一个 Python 虚拟环境，就像我们在[*第 1 章*](B19528_01.xhtml#_idTextAnchor024)中设置的那样，*Python
    开发环境设置*。
- en: 'To run the Stable Diffusion model correctly, we recommend you have a recent
    computer equipped with at least 16 GB of RAM and, ideally, a dedicated GPU with
    8 GB of VRAM. For Mac users, recent models equipped with the M1 Pro or M2 Pro
    chips are also a good fit. If you don’t have that kind of machine, don’t worry:
    we’ll show you ways to run the system anyway – the only drawback is that image
    generation will be slow and show poor results.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确运行 Stable Diffusion 模型，我们建议你使用配备至少 16 GB RAM 的最新计算机，理想情况下还应配备 8 GB VRAM
    的专用 GPU。对于 Mac 用户，配备 M1 Pro 或 M2 Pro 芯片的最新型号也非常适合。如果你没有这种机器，也不用担心：我们会告诉你如何以其他方式运行系统——唯一的缺点是图像生成会变慢并且效果较差。
- en: 'For running the worker, you’ll need a running **Redis server** on your local
    computer. The easiest way is to run it as a Docker container. If you’ve never
    used Docker before, we recommend you read the *Getting started* tutorial in the
    official documentation at [https://docs.docker.com/get-started/](https://docs.docker.com/get-started/).
    Once done, you’ll be able to run a Redis server with this simple command:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行工作程序，你需要在本地计算机上运行**Redis 服务器**。最简单的方法是将其作为 Docker 容器运行。如果你以前从未使用过 Docker，我们建议你阅读官方文档中的*入门教程*，网址为[https://docs.docker.com/get-started/](https://docs.docker.com/get-started/)。完成后，你将能够通过以下简单命令运行
    Redis 服务器：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You’ll find all the code examples of this chapter in the dedicated GitHub repository
    at [https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在专用的 GitHub 仓库中找到本章的所有代码示例，地址为[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14)。
- en: Generating images from text prompts with Stable Diffusion
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Stable Diffusion 从文本提示生成图像
- en: 'Recently, a new generation of AI tools has emerged and fascinated the whole
    world: image-generation models, such as DALL-E or Midjourney. Those models are
    trained on huge amounts of image data and are able to generate completely new
    images from a simple text prompt. These AI models are very good use cases for
    background workers: they take seconds or even minutes to process, and they need
    lots of resources in the CPU, RAM, and even the GPU.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，一种新一代的 AI 工具引起了全世界的关注：图像生成模型，例如 DALL-E 或 Midjourney。这些模型是在大量图像数据上进行训练的，能够从简单的文本提示中生成全新的图像。这些
    AI 模型非常适合作为后台工作程序：它们的处理时间为几秒钟甚至几分钟，并且需要大量的 CPU、RAM 甚至 GPU 资源。
- en: To build our system, we’ll rely on Stable Diffusion, a very popular image-generation
    model that was released in 2022\. This model is available publicly and can be
    run on a modern gaming computer. As we did in the previous chapter, we’ll rely
    on Hugging Face tools for both downloading the model and running it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建我们的系统，我们将依赖于 Stable Diffusion，这是一种非常流行的图像生成模型，发布于 2022 年。该模型是公开的，可以在现代游戏计算机上运行。正如我们在上一章中所做的，我们将依赖
    Hugging Face 工具来下载和运行该模型。
- en: 'Let’s first install the required tools:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们安装所需的工具：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We’re now ready to use diffuser models thanks to Hugging Face.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好通过 Hugging Face 使用扩散模型了。
- en: Implementing the model in a Python script
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Python 脚本中实现模型
- en: 'In the following example, we’ll show you the implementation of a class able
    to instantiate the model and run an image generation. Once again, we’ll apply
    our lazy loading pattern with separate `load_model` and `generate` methods. Let’s
    first focus on `load_model`:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们将展示一个能够实例化模型并运行图像生成的类的实现。再次提醒，我们将应用懒加载模式，使用单独的 `load_model` 和 `generate`
    方法。首先，让我们专注于 `load_model`：
- en: text_to_image.py
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: text_to_image.py
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
- en: The first part of this method aims to find the most efficient way to run the
    model given your computer. These diffusion models are faster when run on the GPU
    – that’s why we check first if there are CUDA (NVIDIA GPU) or MPS (Apple Silicon)
    devices available. If there are none, we fall back to the CPU.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的第一部分旨在根据你的计算机找到最有效的运行模型的方式。当在GPU上运行时，这些扩散模型的速度更快——这就是为什么我们首先检查是否有CUDA（NVIDIA
    GPU）或MPS（Apple Silicon）设备可用。如果没有，我们将退回到CPU。
- en: 'Then, we simply have to create a `StableDiffusionPipeline` pipeline, as provided
    by Hugging Face. We simply have to set the model we want to download from the
    hub. For this example, we chose `runwayml/stable-diffusion-v1-5`. You can find
    its details on Hugging Face: [https://huggingface.co/runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们只需创建一个由Hugging Face提供的`StableDiffusionPipeline`管道。我们只需要设置我们想要从Hub下载的模型。对于这个例子，我们选择了`runwayml/stable-diffusion-v1-5`。你可以在Hugging
    Face上找到它的详细信息：[https://huggingface.co/runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)。
- en: 'We can now focus on the `generate` method:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以专注于`generate`方法：
- en: text_to_image.py
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: text_to_image.py
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
- en: 'You can see it accepts four parameters:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到它接受四个参数：
- en: '`prompt`, which is, of course, the text prompt describing the image we want
    to generate.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`，当然，这是描述我们想要生成的图像的文本提示。'
- en: '`negative_prompt`, which is an optional prompt to tell the model what we absolutely
    don’t want.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt`，这是一个可选的提示，用于告诉模型我们绝对不希望出现的内容。'
- en: '`num_steps`, which is the number of inference steps the model should run. More
    steps lead to a better image, but each iteration delays the inference. The default,
    `50`, should provide a good balance between speed and quality.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_steps`，即模型应执行的推理步骤数。更多步骤会导致更好的图像，但每次迭代都会延迟推理。默认值`50`应该在速度和质量之间提供良好的平衡。'
- en: '`callback`, which is an optional function that will be called at each iteration
    step. This is helpful to be informed about the progress of the generation and
    possibly execute more logic, such as saving the progress in a database.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback`，这是一个可选的函数，它将在每次迭代步骤中被调用。这对于了解生成进度并可能执行更多逻辑（如将进度保存到数据库中）非常有用。'
- en: What does the asterisk (*) in the method signature mean?
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 方法签名中的星号（*）是什么意思？
- en: 'You may have noticed the asterisk, `*`, in the method signature. It tells Python
    that the arguments coming after this symbol should only be treated as keyword-only
    arguments. Said another way, you can only call them like this: `.generate("PROMPT",`
    `negative_prompt="NEGATIVE", num_steps=10)`.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到方法签名中的星号（`*`）。它告诉Python，星号后面的参数应该仅作为关键字参数处理。换句话说，你只能像这样调用它们：`.generate("PROMPT",`
    `negative_prompt="NEGATIVE", num_steps=10)`。
- en: While not necessary, it’s a way to keep your functions clear and self-explanatory.
    It’s especially true if you develop classes or functions that are meant to be
    used by other developers.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不是必须的，但这是一种保持函数清晰且自解释的方式。如果你开发的是供其他开发者使用的类或函数，这尤其重要。
- en: 'Another syntax also exists to force arguments to be positional-only, using
    a slash (`/`) symbol. You can read more about it here: [https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters](https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种语法可以强制参数仅作为位置参数传递，方法是使用斜杠（`/`）符号。你可以在这里阅读更多相关内容：[https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters](https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters)。
- en: 'All we have to do then is to pass those parameters to `pipe`. There are a lot
    more parameters for you to tune if needed, but the default ones should give you
    quite good results. You can find the whole list of them in the Hugging Face documentation:
    [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__).
    This `pipe` object is able to generate several images per prompt, that’s why the
    result of this operation is a list of Pillow images. The default here is to generate
    only one image, so we directly return the first one.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们只需要将这些参数传递给`pipe`。如果需要的话，还有更多的参数可以调节，但默认的参数应该会给你不错的结果。你可以在 Hugging Face
    文档中找到完整的参数列表：[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__)。这个`pipe`对象能够为每个提示生成多张图像，因此该操作的结果是一个Pillow图像列表。这里的默认行为是生成一张图像，所以我们直接返回第一张。
- en: And that’s about it! Once again, Hugging Face makes our lives really easy by
    allowing us to run cutting-edge models in dozens of lines!
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些！再次感谢 Hugging Face，通过允许我们在几十行代码内运行最前沿的模型，真的是让我们的生活变得更轻松！
- en: Executing the Python script
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行 Python 脚本
- en: 'We bet that you’re eager to try it yourself – that’s why we added a small `main`
    script at the bottom of our example:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们敢打赌你急于自己试一试——所以我们在示例的底部添加了一个小的`main`脚本：
- en: text_to_image.py
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: text_to_image.py
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/text_to_image.py)'
- en: This small script instantiates our `TextToImage` class, loads the model, and
    generates an image before saving it to disk. We also define a dummy callback function
    so you can see how it works.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个小脚本实例化了我们的`TextToImage`类，加载了模型，并在保存到磁盘之前生成了图像。我们还定义了一个虚拟回调函数，让你能看到它是如何工作的。
- en: 'When you run this script for the first time, you’ll notice that Hugging Face
    downloads files of several gigabytes to your computer: that’s the Stable Diffusion
    model, and it’s indeed quite big!'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当你第一次运行这个脚本时，你会注意到 Hugging Face 会将几个 GB 的文件下载到你的计算机上：那就是稳定扩散模型，确实相当庞大！
- en: Then, the inference will start. You’ll see a progress bar showing you how many
    inference steps are left, along with the `print` statement from our callback,
    as shown in *Figure 14**.1*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，推理开始了。你会看到一个进度条，显示剩余的推理步骤数，并显示我们回调函数中的`print`语句，如*图 14.1*所示。
- en: '![Figure 14.1 – Stable Diffusion generating an image](img/Figure_14.1_B19528.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.1 – 稳定扩散生成图像](img/Figure_14.1_B19528.jpg)'
- en: Figure 14.1 – Stable Diffusion generating an image
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1 – 稳定扩散生成图像
- en: How much time does it take to generate a single image?
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 生成一张图像需要多长时间？
- en: We’ve run several tests on different types of computers. With a modern NVIDIA
    GPU with 8 GB of RAM or a Mac with an M1 Pro chip, the model is able to generate
    an image with 50 inference steps in *around a minute*, with reasonable RAM usage.
    When run on a CPU, it takes around *5 to 10 minutes* and eats up to 16 GB of RAM.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在不同类型的计算机上进行了多次测试。在配备8 GB RAM的现代NVIDIA GPU或M1 Pro芯片的Mac上，模型能够在*大约一分钟*内生成一张图像，并且内存使用合理。而在CPU上运行时，大约需要*5到10分钟*，并且会占用多达16
    GB的内存。
- en: If the inference is really too slow on your computer, you can try to reduce
    the `num_steps` parameter.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的计算机上推理速度确实太慢，你可以尝试减少`num_steps`参数。
- en: When the inference is done, you’ll find your generated image on the disk along
    with your script. *Figure 14**.2* shows an example of such a result. Nice, isn’t
    it?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当推理完成后，你会在磁盘上找到生成的图像和你的脚本。*图 14.2*展示了这种结果的一个例子。不错吧？
- en: '![Figure 14.2 – Result of a Stable Diffusion image generation](img/Figure_14.2_B19528.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.2 – 稳定扩散图像生成结果](img/Figure_14.2_B19528.jpg)'
- en: Figure 14.2 – Result of a Stable Diffusion image generation
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2 – 稳定扩散图像生成结果
- en: We now have the fundamental brick of our AI system. Now, we need to build an
    API so users can generate their own images. As we’ve just seen, generating a single
    image takes some time. As we said in the introduction, we’ll need to introduce
    a web-queue-worker architecture to make this system reliable and scalable.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经拥有了我们 AI 系统的基础构件。接下来，我们需要构建一个 API，供用户生成自己的图像。正如我们刚刚看到的，生成一张图像需要一些时间。正如我们在介绍中所说的，我们需要引入一个
    Web 队列工作进程架构，使得这个系统既可靠又具有可扩展性。
- en: Creating a Dramatiq worker and defining an image-generation task
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 Dramatiq 工作进程并定义图像生成任务
- en: 'As we mentioned in the introduction of this chapter, it’s not conceivable to
    run our image-generation model directly on our REST API server. As we saw in the
    previous section, the operation can take several minutes and consumes a massive
    amount of memory. To solve this, we’ll define another process, apart from the
    server process, that’ll take care of this image-generation task: the **worker**.
    In essence, a worker can be any program whose role is to compute a task in the
    background.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章的介绍中提到的，直接在我们的 REST API 服务器上运行图像生成模型是不可行的。正如我们在上一节所见，这一操作可能需要几分钟，并消耗大量内存。为了解决这个问题，我们将定义一个独立于服务器进程的其他进程来处理图像生成任务：**工作进程**。本质上，工作进程可以是任何一个在后台执行任务的程序。
- en: In web development, this concept usually implies a bit more than this. A worker
    is a process running continuously in the background, waiting for incoming tasks.
    The tasks are usually sent by the web server, which asks for specific operations
    given the user actions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Web 开发中，这个概念通常意味着比这更多的内容。工作进程是一个持续运行在后台的进程，等待接收任务。这些任务通常由 Web 服务器发送，服务器会根据用户的操作请求执行特定的操作。
- en: Therefore, we see that we need a communication channel between the web server
    and the worker. That’s the role of the **queue**. It’ll accept and stack messages
    coming from the web server and make them available to read for the worker. That’s
    the web-queue-worker architecture. To better understand it, *Figure 14**.4* shows
    you the schema of such an architecture.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到，我们需要一个通信通道来连接 Web 服务器和工作进程。这就是**队列**的作用。队列会接收并堆积来自 Web 服务器的消息，然后将这些消息提供给工作进程读取。这就是
    Web 队列工作进程架构。为了更好地理解这一点，*图 14.4* 展示了这种架构的示意图。
- en: '![Figure 14.3 – Schema of web-queue-worker architecture](img/Figure_14.3_B19528.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.3 – Web 队列工作进程架构示意图](img/Figure_14.3_B19528.jpg)'
- en: Figure 14.3 – Schema of web-queue-worker architecture
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.3 – Web 队列工作进程架构示意图
- en: 'Does it ring a bell? Yes, it’s very similar to what we saw in [*Chapter 8*](B19528_08.xhtml#_idTextAnchor551),
    in the *Handling multiple WebSocket connections and broadcasting messages* section.
    Actually, this is the same principle: we solve the problem of having separate
    processes by having a single central data source.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这是不是让你想起了什么？是的，这与我们在[*第 8 章*](B19528_08.xhtml#_idTextAnchor551)中看到的非常相似，在*处理多个
    WebSocket 连接并广播消息*这一节。实际上，这是同一个原理：我们通过一个中央数据源来解决有多个进程的问题。
- en: 'The great feature of this architecture is that it scales very easily. Imagine
    your application is a huge success and thousands of users want to generate images:
    a single worker wouldn’t be able to meet the demand. Actually, all we need to
    do is to start more worker processes. Since there is a single message broker in
    the architecture, each worker will pull messages as they come, allowing tasks
    to be processed in parallel. They don’t even need to be on the same physical machine.
    This is shown in *Figure 14**.4*.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构的一个伟大特性是它非常容易扩展。试想你的应用程序取得了巨大成功，成千上万的用户想要生成图像：单个工作进程根本无法满足这种需求。事实上，我们所需要做的就是启动更多的工作进程。由于架构中有一个单独的消息代理，每个工作进程会在收到消息时进行拉取，从而实现任务的并行处理。它们甚至不需要位于同一台物理机器上。*图
    14.4* 展示了这一点。
- en: '![Figure 14.4 – Web-queue-worker architecture with multiple workers](img/Figure_14.4_B19528.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.4 – 带有多个工作进程的 Web 队列工作进程架构](img/Figure_14.4_B19528.jpg)'
- en: Figure 14.4 – Web-queue-worker architecture with multiple workers
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.4 – 带有多个工作进程的 Web 队列工作进程架构
- en: In Python, there are several libraries to help implement a worker. They provide
    the required tools to define tasks, schedule them in the queue, and run a process,
    pulling them and executing them. In this book, we’ll use Dramatiq, a lightweight
    but powerful and modern background task-processing library. As we did in [*Chapter
    8*](B19528_08.xhtml#_idTextAnchor551), we’ll use Redis as a message broker.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，有多种库可以帮助实现工作进程。它们提供了定义任务、将任务调度到队列中并运行进程、拉取并执行任务所需的工具。在本书中，我们将使用 Dramatiq，一个轻量级但强大且现代的后台任务处理库。正如我们在
    [*第 8 章*](B19528_08.xhtml#_idTextAnchor551) 中所做的，我们将使用 Redis 作为消息代理。
- en: Implementing a worker
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现一个工作进程
- en: 'As usual, we’ll start by installing the required dependency. Run the following
    command:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们首先安装所需的依赖项。运行以下命令：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This will install Dramatiq with the required dependencies to talk with a Redis
    broker.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这将安装 Dramatiq，并安装与 Redis 代理通信所需的依赖项。
- en: 'In a minimal example, setting up a Dramatiq worker involves two things:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个最小的示例中，设置 Dramatiq 工作进程涉及两件事：
- en: Setting the broker type and URL.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置代理类型和 URL。
- en: Defining tasks by wrapping functions with the `@``dramatiq.actor` decorator.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用 `@``dramatiq.actor` 装饰器来定义任务。
- en: It works very well for the vast majority of tasks, such as sending emails or
    generating exports.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 它非常适合绝大多数任务，比如发送电子邮件或生成导出文件。
- en: In our case, however, we need to load the heavy Stable Diffusion model. As we
    usually do in the FastAPI server with the `startup` event, we want to do this
    only when the process is actually started. To do this with Dramatiq, we implement
    a *middleware*. They allow us to plug custom logic at several key events in the
    lifetime of the worker, including when it’s started.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们的案例中，我们需要加载庞大的 Stable Diffusion 模型。正如我们通常在 FastAPI 服务器中通过 `startup` 事件做的那样，我们希望只有在进程实际启动时才执行这一操作。为了使用
    Dramatiq 实现这一点，我们需要实现一个*中间件*。它们允许我们在工作进程生命周期中的几个关键事件插入自定义逻辑，包括当工作进程启动时。
- en: 'You can see the implementation of our custom middleware in the following sample:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下示例中看到我们自定义中间件的实现：
- en: worker.py
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py)'
- en: 'We define a `TextToImageMiddleware` class whose role is to bear an instance
    of `TextToImage`, the image generation service we defined in the previous section.
    It inherits from the `Middleware` class of Dramatiq. The key thing here is the
    `after_process_boot` method. It’s one of the event hooks exposed by Dramatiq,
    allowing us to plug our own logic. Here, we tell it to load the Stable Diffusion
    model when the worker process has booted up. You can see the full list of supported
    hooks in the official documentation: [https://dramatiq.io/reference.html#middleware](https://dramatiq.io/reference.html#middleware).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个 `TextToImageMiddleware` 类，它的作用是承载 `TextToImage` 的实例，这是我们在上一节中定义的图像生成服务。它继承自
    Dramatiq 的 `Middleware` 类。这里的关键是 `after_process_boot` 方法。它是 Dramatiq 提供的事件钩子之一，允许我们插入自定义逻辑。在这里，我们告诉它在工作进程启动后加载
    Stable Diffusion 模型。你可以在官方文档中查看支持的钩子列表：[https://dramatiq.io/reference.html#middleware](https://dramatiq.io/reference.html#middleware)。
- en: The next lines allow us to configure our worker. We first instantiate an instance
    of our custom middleware. Then, we create a broker class corresponding to the
    technology we chose; in our case, Redis. We take care of adding our middleware
    to this broker before telling Dramatiq to use it. Our worker is now completely
    configured to connect to a Redis broker and load our model at startup.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的几行代码让我们可以配置我们的工作进程。我们首先实例化我们自定义中间件的一个实例。然后，我们创建一个与我们选择的技术相对应的代理类；在我们的案例中是
    Redis。在告诉 Dramatiq 使用它之前，我们需要将中间件添加到这个代理中。我们的工作进程现在已经完全配置好，可以连接到 Redis 代理，并在启动时加载我们的模型。
- en: 'Now, let’s see how we can define a task to generate images:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下如何定义一个任务来生成图像：
- en: worker.py
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/worker.py)'
- en: 'The implementation is straightforward: Dramatiq tasks are actually plain functions
    that we decorated with `@dramatiq.actor`. We can define arguments as we would
    for any other function. However, there is an important pitfall to avoid here:
    when we schedule tasks from our server, the arguments will have to be stored in
    the queue storage. Thus, *Dramatiq will internally serialize the arguments to
    JSON*. It means your task arguments must be serializable data – you can’t have
    arbitrary Python objects, such as class instances or functions.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 实现是直接的：Dramatiq 任务实际上是我们用 `@dramatiq.actor` 装饰的普通函数。我们可以像定义其他函数一样定义参数。然而，这里有一个重要的陷阱需要避免：当我们从服务器调度任务时，参数将必须存储在队列存储中。因此，*Dramatiq
    会将参数内部序列化为 JSON*。这意味着你的任务参数必须是可序列化的数据——你不能有任意的 Python 对象，比如类实例或函数。
- en: The function body calls our `TextToImage` instance loaded in `text_to_image_middleware`,
    before saving the image to the disk. To avoid file overrides, we choose here to
    generate a **UUID**, a **Universally Unique IDentifier**. It’s a big random string
    that’s guaranteed to be unique in each generation. Thanks to this, we can safely
    use it as a filename and be sure it won’t already exist on our disk.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 函数体在将图像保存到磁盘之前，会调用我们在 `text_to_image_middleware` 中加载的 `TextToImage` 实例。为了避免文件覆盖，我们选择在这里生成一个**UUID**，即**通用唯一标识符**。它是一个大的随机字符串，保证每次生成时都是唯一的。凭借这个，我们可以安全地将其作为文件名，并确保它不会在磁盘上已存在。
- en: That’s it for the worker implementation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 worker 实现的内容。
- en: Starting the worker
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启动 worker
- en: 'We don’t have the web server code to call it yet, but we can already try it
    manually. First, make sure you have a Redis server started, as explained in the
    *Technical requirements* section. Then, we can start the Dramatiq worker using
    the following command:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有代码来调用它，但我们可以手动尝试。首先，确保你已经启动了一个 Redis 服务器，正如在*技术要求*部分中所解释的那样。然后，我们可以使用以下命令启动
    Dramatiq worker：
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Dramatiq comes with command-line tools to take care of starting the worker
    processes. The main positional argument is the dotted path of your worker module.
    It’s similar to what we do with Uvicorn. We also set two optional parameters,
    `-p` and `-t`. They control the number of processes and threads Dramatiq will
    start. By default, it starts 10 processes, each one with 8 threads. This means
    there will be 80 workers able to pull and execute tasks. While this default is
    good for common needs, it doesn’t work with our Stable Diffusion model for two
    reasons:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Dramatiq 提供了命令行工具来启动 worker 进程。主要的位置参数是 worker 模块的点路径。这类似于我们在使用 Uvicorn 时的操作。我们还设置了两个可选参数，`-p`
    和 `-t`。它们控制 Dramatiq 启动的进程和线程的数量。默认情况下，它启动 10 个进程，每个进程有 8 个线程。这意味着将会有 80 个 worker
    来拉取并执行任务。虽然这个默认配置适合常见需求，但由于两个原因，它不适用于我们的 Stable Diffusion 模型：
- en: 'Each thread in a process shares the same memory space. This means that if two
    (or more) threads try to generate an image, they will read and write on the same
    objects in memory. For our model here, this causes concurrency problems. We say
    that it’s *not thread-safe*. Hence, each process should start only one thread:
    that’s the point of the `-t` `1` option.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程中的每个线程共享相同的内存空间。这意味着，如果两个（或更多）线程尝试生成图像，它们将对内存中的同一对象进行读写操作。对于我们的模型来说，这会导致并发问题。我们说它是*非线程安全的*。因此，每个进程应该仅启动一个线程：这就是`-t`
    `1`选项的意义所在。
- en: Each process should load the model in memory. This means that if we start 8
    processes, we’ll load the model 8 times. As we saw earlier, it takes quite a huge
    amount of memory, so doing this would probably blow up your computer’s memory.
    To be safe here, we start only one process thanks to the `-p 1` option. If you
    want to try parallelization and see that our worker is able to generate two images
    in parallel, you can try `-p 2` to spawn two processes. Make sure your computer
    can handle it though!
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个进程都应该将模型加载到内存中。这意味着，如果我们启动 8 个进程，我们将加载 8 次模型。正如我们之前所看到的，它需要相当大的内存，所以这样做可能会使你的计算机内存爆炸。为了安全起见，我们仅启动一个进程，使用`-p
    1`选项。如果你想尝试并行化并查看我们的 worker 能否并行生成两张图像，你可以尝试`-p 2`来启动两个进程。但要确保你的计算机能够处理！
- en: 'If you run the preceding command, you should see an output like this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行前面的命令，你应该会看到类似这样的输出：
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can see the output of the Stable Diffusion pipeline checking whether the
    model files are downloaded before the worker is fully started. This means that
    it has been correctly loaded.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过查看 Stable Diffusion 流水线的输出，检查模型文件是否已经下载，直到 worker 完全启动。这意味着它已经正确加载。
- en: Scheduling tasks in the worker
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 worker 中调度任务
- en: 'We can now try to schedule tasks in our worker. For this, we can start a Python
    interactive shell and import the `task` function. Open a new command line and
    run the following commands (make sure you enabled your Python virtual environment):'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以尝试在工作线程中调度任务了。为此，我们可以启动一个Python交互式Shell并导入`task`函数。打开一个新的命令行并运行以下命令（确保你已启用Python虚拟环境）：
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'That’s it – we scheduled a task in the worker! Notice how we used the `send`
    method on our `task` function instead of calling it directly: this is how you
    tell Dramatiq to send it in the queue.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样——我们在工作线程中安排了一个任务！注意我们在`task`函数上使用了`send`方法，而不是直接调用它：这是告诉Dramatiq将其发送到队列中的方式。
- en: If you go back to your worker terminal, you’ll see the Stable Diffusion output
    generating the image. After a moment, you’ll have your image saved on disk. You
    can also try to send two tasks in a row in a short time. You’ll find that Dramatiq
    processes them one after the other.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回到工作线程终端，你会看到Stable Diffusion正在生成图像。过一会儿，你的图像将保存在磁盘上。你还可以尝试在短时间内连续发送两个任务。你会发现Dramatiq会一个接一个地处理它们。
- en: Great job! We have our background process ready and are even able to schedule
    tasks in it. The next step now is to implement a REST API so the users can ask
    for image generation themselves.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！我们的后台进程已经准备好，甚至能够在其中调度任务。下一步就是实现REST API，以便用户可以自己请求图像生成。
- en: Implementing the REST API
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现REST API
- en: 'To schedule tasks in our worker, we need a safe interface users can interact
    with. A REST API is a good choice for this, since it can be easily integrated
    into any software, such as a website or a mobile app. In this section, we’ll very
    quickly review a simple API endpoint we implemented to send image-generation tasks
    into our queue. Here’s the implementation:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要在工作线程中调度任务，我们需要一个用户可以交互的安全接口。REST API是一个不错的选择，因为它可以轻松集成到任何软件中，如网站或移动应用。在这一节中，我们将快速回顾一下我们实现的简单API端点，用于将图像生成任务发送到队列中。以下是实现代码：
- en: api.py
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: api.py
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/api.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/api.py)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/api.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/basic/api.py)'
- en: If you have followed along since the beginning of this book, this shouldn’t
    surprise you. We took care of defining proper Pydantic models to structure and
    validate the endpoint payload. This data is then directly used to send a task
    to Dramatiq, as we saw in the previous section.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从这本书的开头一直跟到现在，这不应该让你感到惊讶。我们已经妥善地定义了合适的Pydantic模型来构建和验证端点负载。然后，这些数据会直接用于发送任务到Dramatiq，正如我们在前一节看到的那样。
- en: In this simple implementation, the output consists only of the message ID, which
    is automatically assigned to each task by Dramatiq. Notice that we set the HTTP
    status code to `202`, which means *Accepted*. Semantically, it means the server
    understood and accepted the request, but the processing has not yet finished or
    even started. It’s specifically designed for cases where the processing is done
    in the background, which is exactly our case here.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的实现中，输出仅包含消息ID，Dramatiq会自动为每个任务分配这个ID。注意我们将HTTP状态码设置为`202`，表示*已接受*。从语义上讲，这意味着服务器已理解并接受了请求，但处理尚未完成，甚至可能还没有开始。它专门用于处理在后台进行的情况，这正是我们在这里的情况。
- en: If you start both the worker and this API, you’ll be able to trigger image generations
    with an HTTP call.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你同时启动工作线程和这个API，你将能够通过HTTP调用触发图像生成。
- en: 'You’re probably wondering here: *That’s nice… But how will the users retrieve
    the result? How will they know whether the task is done?*. You’re right – we didn’t
    talk at all about this problem! Actually, there are two aspects to solve here:
    how do we keep track of the pending tasks and their execution? How do we store
    and serve the resulting images? That’s the subject of the next section.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能在想：*这不错……但是用户怎么才能获取结果呢？他们怎么知道任务是否完成？* 你说得对——我们完全没有讨论这个问题！实际上，这里有两个方面需要解决：我们如何跟踪待处理任务及其执行情况？我们如何存储并提供生成的图像？这就是下一节的内容。
- en: Storing results in a database and object storage
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将结果存储在数据库和对象存储中
- en: 'In the previous section, we showed how to implement a background worker to
    do the heavy computation and an API to schedule tasks on this worker. However,
    we are still missing two important aspects: the user doesn’t have any way to know
    the progress of the task nor to retrieve the final result. Let’s fix this!'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们展示了如何实现一个后台工作程序来执行繁重的计算，以及一个 API 来调度任务给这个工作程序。然而，我们仍然缺少两个重要方面：用户没有任何方式了解任务的进度，也无法获取最终结果。让我们来解决这个问题！
- en: Sharing data between the worker and the API
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在工作程序和 API 之间共享数据
- en: 'As we’ve seen, the worker is a program running in the background executing
    the computations the API has asked it to do. However, the worker doesn’t have
    any way to talk with the API server. That’s expected: since there could be any
    number of server processes, and since they could even run on different physical
    servers, processes cannot communicate directly. It’s always the same problem of
    having a central data source on which processes can write and read data.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，工作程序是一个在后台运行的程序，执行 API 请求它做的计算。然而，工作程序并没有与 API 服务器通信的任何方式。这是预期中的：因为可能有任意数量的服务器进程，且它们甚至可能运行在不同的物理服务器上，因此进程之间不能直接通信。始终是同样的问题：需要有一个中央数据源，供进程写入和读取数据。
- en: 'Actually, the first approach to solve the lack of communication between the
    API and the worker could be to use the same broker we use to schedule tasks: the
    worker could write results in the broker, and the API could read from it. This
    is something possible with most background task libraries, including Dramatiq.
    However, this solution has some limitations, the principal one being the limited
    time we can retain the data. Brokers, such as Redis, are not really suited to
    storing data reliably for a long period. At some point, we’ll need to erase the
    most ancient data to limit memory usage.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，解决 API 和工作程序之间缺乏通信的第一种方法是使用我们用来调度任务的相同代理：工作程序可以将结果写入代理，API 可以从中读取。这在大多数后台任务库中都是可能的，包括
    Dramatiq。然而，这个解决方案有一些局限性，其中最主要的是我们能保留数据的时间有限。像 Redis 这样的代理并不适合长时间可靠地存储数据。在某些时候，我们需要删除最古老的数据以限制内存使用。
- en: 'Yet, we already know of something able to store structured data efficiently:
    a database, of course! That’s the approach we’ll show here. By having a central
    database where we’ll store our image generation requests and results, we’ll be
    able to share information between the worker and the API. For this, we’ll reuse
    a lot of techniques we showed in the *Communicating with a SQL database with SQLAlchemy
    ORM* section of [*Chapter 6*](B19528_06.xhtml#_idTextAnchor346). Let’s go!'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们已经知道有一些东西能够高效地存储结构化数据：当然是数据库！这就是我们在这里展示的方法。通过拥有一个中央数据库，我们可以在其中存储图像生成请求和结果，这样就能在工作程序和
    API 之间共享信息。为此，我们将重用我们在[《第 6 章》](B19528_06.xhtml#_idTextAnchor346)的*使用 SQLAlchemy
    ORM 与 SQL 数据库通信*部分中展示的很多技巧。我们开始吧！
- en: Defining an SQLAlchemy model
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义一个 SQLAlchemy 模型
- en: 'The first step is defining an SQLAlchemy model to store a single image-generation
    task. You can see it as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是定义一个 SQLAlchemy 模型来存储单个图像生成任务。你可以如下所示查看它：
- en: models.py
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: models.py
- en: '[PRE12]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/models.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/models.py)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/models.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/models.py)'
- en: As usual, we define an auto-incremented ID as the primary key. We also add `prompt`,
    `negative_prompt`, and `num_steps` columns, which correspond to the arguments
    we give to the worker task. This way, we’ll be able to directly give the ID to
    the worker, and it’ll take the parameter directly from the object. Besides, it’ll
    allow us to store and remember the parameters we used for a specific generation.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，我们定义一个自增的 ID 作为主键。我们还添加了 `prompt`、`negative_prompt` 和 `num_steps` 列，这些列对应我们传递给工作程序任务的参数。这样，我们就可以直接将
    ID 传递给工作程序，它会直接从对象中获取参数。此外，这还允许我们存储并记住用于特定生成的参数。
- en: The `progress` column is an integer where we’ll store the current progress of
    the generation task.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`progress` 列是一个整数，用来存储当前生成任务的进度。'
- en: Finally, `file_name` will store the actual filename we’ll store on our system.
    We’ll see how we use it in the next section, about object storage.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`file_name` 将存储我们在系统中保存的实际文件名。我们将在下一节中关于对象存储的部分看到如何使用它。
- en: Adapting the API to save image-generation tasks in a database
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将API调整为在数据库中保存图像生成任务
- en: 'With this model at hand, our approach to scheduling image generation in the
    API changes a bit. Instead of directly sending the task to the worker, we first
    create a row in our database and use the ID of this object as input for the worker
    task. The endpoint implementation is shown here:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个模型后，我们对API中图像生成任务的调度方式稍微做了些调整。我们不再直接将任务发送给工作进程，而是首先在数据库中创建一行数据，并将该对象的ID作为输入传递给工作进程任务。端点的实现如下所示：
- en: api.py
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: api.py
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/api.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/api.py)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/api.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/api.py)'
- en: We won’t go into the details about how to create an object in a database with
    SQLAlchemy ORM. If you need a refresher, you can refer to the *Communicating with
    a SQL database with SQLAlchemy ORM* section of [*Chapter 6*](B19528_06.xhtml#_idTextAnchor346).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入讨论如何使用SQLAlchemy ORM在数据库中创建对象。如果你需要复习，可以参考[《第6章》](B19528_06.xhtml#_idTextAnchor346)中的*使用SQLAlchemy
    ORM与SQL数据库通信*部分。
- en: The main thing to notice in this snippet is that we pass the ID of the newly
    created object as an argument of `text_to_image_task`. As we’ll see right after,
    the worker will read it again from the database to retrieve the generation parameters.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，主要需要注意的是我们将新创建对象的ID作为`text_to_image_task`的参数传递。正如我们稍后看到的，工作进程会从数据库中重新读取这个ID，以检索生成参数。
- en: 'The response of this endpoint is simply a representation of our `GeneratedImage`
    model, using the Pydantic schema `GeneratedImageRead`. Thus, the user will get
    a response like this to their request:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 该端点的响应仅仅是我们`GeneratedImage`模型的表示，使用了Pydantic架构`GeneratedImageRead`。因此，用户将会收到类似这样的响应：
- en: '[PRE14]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: It shows the prompt we gave in our request and, most importantly, *it gives
    it an ID*. This means that the user will be able to query for this specific request
    again to retrieve the data and see whether it’s done. That’s the purpose of the
    `get_generated_image` endpoint defined below the previous snippet. We won’t show
    it here, but you can read it in the examples repository.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 它展示了我们在请求中提供的提示，最重要的是，*它给了一个ID*。这意味着用户将能够再次查询此特定请求以检索数据，并查看是否完成。这就是下面定义的`get_generated_image`端点的目的。我们不会在这里展示它，但你可以在示例仓库中阅读到它。
- en: Adapting the worker to read and update image-generation tasks from a database
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将工作进程调整为从数据库中读取和更新图像生成任务
- en: You probably have guessed that we need to change the implementation of our task
    so it can retrieve objects from the database instead of reading the parameters
    directly. Let’s go through this step by step.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经猜到，我们需要改变任务的实现，以便它能从数据库中检索对象，而不是直接读取参数。让我们一步步来进行调整。
- en: The first thing we do is retrieve a `GeneratedImage` from the database using
    the ID we got in the task argument.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们做的第一件事是使用在任务参数中获得的ID从数据库中检索一个`GeneratedImage`。
- en: worker.py
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE15]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: 'To achieve this, you see that we use a helper function called `get_image`.
    It’s defined right above the task. Let’s review it:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，你会看到我们使用了一个名为`get_image`的辅助函数。它定义在任务的上方。让我们来看一下：
- en: worker.py
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE16]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: It may look quite strange, but actually, you are already familiar with most
    of its logic. If you look closely, you’ll see that it defines a nested and private
    function where we define the actual logic to retrieve and save the object using
    SQLAlchemy ORM. Notice that it’s *async*, and that we make great use of async
    I/O patterns, as we’ve seen throughout this book.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来可能有些奇怪，但实际上，你已经对其大部分逻辑非常熟悉了。如果你仔细观察，你会发现它定义了一个嵌套的私有函数，在其中我们定义了实际的逻辑来使用SQLAlchemy
    ORM获取和保存对象。请注意，它是*异步的*，并且我们在其中大量使用了异步I/O模式，正如本书中所展示的那样。
- en: That’s the exact reason why we need a helper function like this. Indeed, Dramatiq
    is not designed to run async functions natively, so we need to manually schedule
    their execution using `asyncio.run`. We already saw this function in [*Chapter
    2*](B19528_02.xhtml#_idTextAnchor032), where we presented async I/O. Its role
    is to run an async function and return its result. That’s how we can call the
    wrapping function synchronously in our task without any issues.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们需要像这样的辅助函数的原因。事实上，Dramatiq并未原生设计为运行异步函数，因此我们需要手动使用`asyncio.run`来调度其执行。我们已经在[*第二章*](B19528_02.xhtml#_idTextAnchor032)中看到过这个函数，那里介绍了异步I/O。它的作用是运行异步函数并返回其结果。这就是我们如何在任务中同步调用包装函数而不出现任何问题。
- en: Other approaches could work to tackle the async I/O problem
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 其他方法也可以解决异步I/O问题。
- en: The approach we show here is the most straightforward and robust one to tackle
    the problem of asynchronous workers.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里展示的方法是解决异步工作者问题最直接且稳健的方法。
- en: Another approach could be to set up a decorator or middleware for Dramatiq so
    it could natively run async functions, but this is complex and subject to bugs.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法可能是为Dramatiq设置装饰器或中间件，使其能够原生支持运行异步函数，但这种方法复杂且容易出现BUG。
- en: We could also consider having another SQLAlchemy engine and session maker that
    works synchronously. However, this would require us to have a lot of duplicated
    things in our code. Besides, this wouldn’t help if we had async functions other
    than SQLAlchemy.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以考虑拥有另一个同步工作的SQLAlchemy引擎和会话生成器。然而，这会导致代码中出现大量重复的内容。而且，如果我们有除了SQLAlchemy之外的其他异步函数，这也无法提供帮助。
- en: 'Now, let’s get back to the implementation of `text_to_image_task`:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回到`text_to_image_task`的实现：
- en: worker.py
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE17]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: 'We define a `callback` function for the Stable Diffusion pipeline. Its role
    is to save the current progress in a database for the current `GeneratedImage`.
    For this, we once again use a helper function, `update_progress`:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为Stable Diffusion管道定义了一个`callback`函数。它的作用是将当前的进度保存到数据库中，针对当前的`GeneratedImage`。为此，我们再次使用了一个辅助函数`update_progress`：
- en: worker.py
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE18]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: We use the same approach we explained for `get_image`, so we can wrap the async
    function.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用与`get_image`相同的方法来包装异步函数。
- en: 'Going back to `text_to_image_task`, we can now call our `TextToImage` model
    to generate an image. It’s exactly the same call we showed in the previous section.
    The only difference is that we take the parameters from the `image` object. We
    also generate a random filename using a UUID:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 回到`text_to_image_task`，我们现在可以调用我们的`TextToImage`模型来生成图像。这与前一节中展示的调用完全相同。唯一的区别是，我们从`image`对象中获取参数。我们还使用UUID生成一个随机的文件名：
- en: worker.py
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE19]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: 'The following part is designed to upload the image to object storage. We’ll
    explain this in more detail in the next section:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分用于将图像上传到对象存储。我们将在下一部分中更详细地解释这一点：
- en: worker.py
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE20]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: 'Finally, we call another helper function, `update_file_name`, to save the random
    filename in the database. It’ll allow us to retrieve the file for the user:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们调用另一个辅助函数`update_file_name`，将随机文件名保存到数据库中。它将允许我们为用户检索该文件：
- en: worker.py
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE21]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: As you can see, the main point of attention throughout this implementation is
    that we read and write information about `GeneratedImage` from and to the database.
    This is how we can *synchronize* between the API server and the worker. That’s
    it for the worker! With this logic, we are able to schedule an image-generation
    task from the API, and the worker is able to regularly update the task progress
    before setting the resulting filename. Thus, from the API, a simple `GET` request
    allows us to see the status of our task.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个实现的重点是我们从数据库中读取和写入`GeneratedImage`的信息。这就是我们如何在 API 服务器和工作进程之间进行*同步*。工作进程的部分就到此为止！有了这个逻辑，我们就可以从
    API 调度一个图像生成任务，而工作进程则能够在设置最终文件名之前定期更新任务进度。因此，通过 API，一个简单的`GET`请求就能让我们看到任务的状态。
- en: Storing and serving files in object storage
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在对象存储中存储和服务文件
- en: The last challenge we have to tackle concerns the storage of our resulting images.
    We need a way to store them reliably while letting users retrieve them easily
    from the internet.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须解决的最后一个挑战是关于存储生成的图像。我们需要一种可靠的方式来存储它们，同时让用户能够轻松地从互联网中检索它们。
- en: 'Traditionally, web applications handled this quite simply. They stored the
    files directly on the server hard disk, in a defined directory, and configured
    their web server to serve those files when accessed under a certain URL. This
    is actually what we did in [*Chapter 13*](B19528_13.xhtml#_idTextAnchor1005),
    in the WebSocket example: we used the `StaticFiles` middleware to statically serve
    the JavaScript script we had on disk.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，Web 应用程序的处理方式非常简单。它们将文件直接存储在服务器的硬盘中，在指定的目录下，并配置其 Web 服务器，当访问某个 URL 时提供这些文件。这实际上是我们在[*第
    13 章*](B19528_13.xhtml#_idTextAnchor1005)中的 WebSocket 示例中做的：我们使用了 `StaticFiles`
    中间件来静态地提供我们磁盘上的 JavaScript 脚本。
- en: While this works well for static files, such as JavaScript or CSS files, for
    which each server has its own copy, it is not suitable for dynamic files uploaded
    by the user or generated by the backend, in particular for complex architectures
    where several processes are run on different physical machines. Once again, this
    is the problem of having a central source of data that the different processes
    read from. In the previous sections, we saw that message brokers and databases
    could solve this issue in several contexts. In the case of arbitrary binary files,
    whether they are images, videos, or simple text files, we need something else.
    Let’s introduce **object storage**.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种方式适用于静态文件，比如每个服务器都有自己副本的 JavaScript 或 CSS 文件，但对于用户上传或后台生成的动态文件来说并不合适，尤其是在多个进程运行在不同物理机器上的复杂架构中。问题再次出现，即不同进程读取的中央数据源问题。在前面的部分，我们看到消息代理和数据库可以在多个场景中解决这个问题。而对于任意的二进制文件，无论是图像、视频还是简单的文本文件，我们需要其他解决方案。让我们来介绍**对象存储**。
- en: 'Object storage is a bit different from the standard file storage we use daily
    in computers, where the disk is organized in a hierarchy of directories and files.
    Instead, object storage will store each file as an object, which includes the
    actual data and all its metadata, such as its name, size, type, and a unique ID.
    The main benefit of such conceptualization is that it’s easier to spread those
    files across multiple physical machines: *we can store billions of files on the
    same object storage*. From the user’s point of view, we just ask for a specific
    file, and the storage will take care of loading the file from the actual physical
    disk.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 对象存储与我们日常在计算机中使用的标准文件存储有所不同，后者中的磁盘是以目录和文件的层次结构组织的。而对象存储将每个文件作为一个对象进行存储，其中包含实际数据及其所有元数据，如文件名、大小、类型和唯一
    ID。这种概念化的主要好处是，它更容易将这些文件分布到多个物理机器上：*我们可以将数十亿个文件存储在同一个对象存储中*。从用户的角度来看，我们只需请求一个特定的文件，存储系统会负责从实际的物理磁盘加载该文件。
- en: In the cloud era, this approach has obviously gained a lot of popularity. In
    2006, **Amazon Web Services** (**AWS**) launched Amazon S3, its own implementation
    of object storage. It gave developers access to virtually unlimited disk space
    to store files using a simple API, all at a very cheap price. Amazon S3 gained
    so much popularity its API became the de facto standard in the industry. Nowadays,
    most cloud object storage, including storage from competitors such as Microsoft
    Azure or Google Cloud, is compatible with the S3 API. Open source implementations
    have also emerged, such as MinIO. The main benefit of this common S3 API is that
    you can use the same code and libraries in your project to talk with any object
    storage provider and easily switch if needed.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在云时代，这种方法显然获得了广泛的关注。2006年，**亚马逊网络服务**（**AWS**）推出了其自有实现的对象存储——Amazon S3。它为开发人员提供了几乎无限的磁盘空间，允许通过一个简单的
    API 存储文件，并且价格非常低廉。Amazon S3 因其广泛的流行，其 API 成为行业事实上的标准。如今，大多数云对象存储，包括微软 Azure 或
    Google Cloud 等竞争对手的存储，都与 S3 API 兼容。开源实现也应运而生，如 MinIO。这个通用的 S3 API 的主要好处是，您可以在项目中使用相同的代码和库与任何对象存储提供商进行交互，并在需要时轻松切换。
- en: To sum up, object storage is a very convenient way to store and serve files
    at scale, no matter the number of processes that need to access this data. At
    the end of this section, the global architecture of our project will look like
    the one shown in *Figure 14**.5*.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，对象存储是一种非常方便的方式，用于大规模存储和提供文件，无论有多少个进程需要访问这些数据。在本节结束时，我们项目的全球架构将像*图 14.5*中所示。
- en: '![Figure 14.5 – Web-queue-worker architecture and object storage](img/Figure_14.5_B19528.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.5 – Web-队列-工作者架构和对象存储](img/Figure_14.5_B19528.jpg)'
- en: Figure 14.5 – Web-queue-worker architecture and object storage
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.5 – Web-队列-工作者架构和对象存储
- en: It’s worth noting that the *object storage will serve the file directly to the
    user*. There won’t be an endpoint where the server would act as a proxy by downloading
    the file from the object storage before sending it to the user. There isn’t much
    benefit in doing it that way, even in terms of authentication. We’ll see that
    S3-compatible storage has built-in mechanisms to protect files from unauthorized
    access.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，*对象存储会直接将文件提供给用户*。不会有一个端点，服务器在从对象存储下载文件后再将其发送给用户。以这种方式操作并没有太大好处，即使在认证方面也是如此。我们将看到，兼容
    S3 的存储具有内建的机制来保护文件不被未授权访问。
- en: Implementing an object storage helper
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现一个对象存储助手
- en: 'Let’s get to the code then! We’ll use the MinIO client for Python, a library
    to interact with any S3-compatible storage. Let’s install it:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们开始写代码吧！我们将使用 MinIO 的 Python 客户端库，这是一个与任何兼容 S3 的存储进行交互的库。让我们先安装它：
- en: '[PRE22]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We can now implement a class to have all the operations we need at hand. Let’s
    first go with the initializer:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以实现一个类，以便手头有我们需要的所有操作。我们先从初始化器开始：
- en: storage.py
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: storage.py
- en: '[PRE23]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
- en: In the initializer of this class, we create a `Minio` client instance. You’ll
    see that we use a `settings` object to pull the storage URL and credentials. Thus,
    it’s very easy to switch them by using environment variables.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在该类的初始化函数中，我们创建了一个 `Minio` 客户端实例。你会看到我们使用一个 `settings` 对象来提取存储 URL 和凭证。因此，使用环境变量就能非常轻松地切换它们。
- en: 'We’ll then implement several methods that’ll help us work with object storage.
    The first one is `ensure_bucket`:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将实现一些方法，帮助我们处理对象存储。第一个方法是 `ensure_bucket`：
- en: storage.py
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: storage.py
- en: '[PRE24]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
- en: The role of this method is to make sure the right bucket is created in our object
    storage. In S3 implementations, a **bucket** is like a folder that you own and
    in which you can store your files. Each file you upload has to be put into an
    existing bucket.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的作用是确保在我们的对象存储中创建了正确的存储桶。在 S3 实现中，**存储桶**就像是你拥有的文件夹，你可以将文件存储在其中。你上传的每个文件都必须放入一个现有的存储桶中。
- en: 'Then, we define `upload_image`:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义了 `upload_image`：
- en: storage.py
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: storage.py
- en: '[PRE25]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
- en: This is for uploading an image to the storage. To simplify things, this method
    accepts a Pillow `Image`, as it’s the result we get at the end of the Stable Diffusion
    pipeline. We implemented some logic to convert this `Image` object into a raw
    stream of bytes suitable for the S3 upload. This method also expects `object_name`,
    which will be the actual name of the file in the storage, along with `bucket_name`.
    Notice that we first ensure the bucket is correctly created before trying to upload
    the file.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于将图像上传到存储的。为了简化操作，该方法接受一个 Pillow `Image` 对象，因为这是我们在 Stable Diffusion 流水线的最后得到的结果。我们实现了一些逻辑，将这个
    `Image` 对象转换为适合 S3 上传的原始字节流。该方法还期望接收 `object_name`，即存储中实际的文件名，以及 `bucket_name`。请注意，我们首先确保存储桶已经正确创建，然后再尝试上传文件。
- en: 'Finally, we add the `get_presigned_url` method:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们添加了 `get_presigned_url` 方法：
- en: storage.py
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: storage.py
- en: '[PRE26]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/storage.py)'
- en: 'This method will help us to serve the file securely to the user. By default,
    for security reasons, files in S3 storage are not accessible by any user on the
    internet. To give access to a file, we can do either of the following:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法将帮助我们安全地将文件提供给用户。出于安全原因，S3 存储中的文件默认对互联网用户不可访问。为了给予文件访问权限，我们可以执行以下任一操作：
- en: Set the file as public so anybody with the URL can access it. This is suitable
    for public files but certainly not for private user files.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文件设置为公开状态，这样任何拥有 URL 的人都能访问它。这个适合公开文件，但对于私密的用户文件则不适用。
- en: Generate a URL with a temporary access key. Thus, we can give access to the
    file to the user, knowing that even if the URL is stolen, the access will be revoked
    after a certain time. The huge benefit of this is that this URL generation happens
    on our API server using the S3 client. Therefore, we could check whether the user
    is correctly authenticated and has the rights to this specific file following
    our own logic before generating the file URL. This is the approach we adopt here,
    and this method generates the pre-signed URL on a specific file in a specific
    bucket for a certain amount of time.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成一个带有临时访问密钥的 URL。这样，我们就可以将文件访问权限提供给用户，即使 URL 被窃取，访问也会在一段时间后被撤销。这带来的巨大好处是，URL
    生成发生在我们的 API 服务器上，使用 S3 客户端。因此，在生成文件 URL 之前，我们可以根据自己的逻辑检查用户是否通过身份验证，并且是否有权访问特定的文件。这就是我们在这里采用的方法，并且此方法会在特定存储桶中的特定文件上生成预签名
    URL，且有效期为一定时间。
- en: As you can see, our class is just a thin wrapper around the MinIO client. All
    we have to do now is to use it to upload the images and get a pre-signed URL from
    the API.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们的类只是 MinIO 客户端的一个薄包装。现在我们要做的就是用它来上传图像并从 API 获取预签名 URL。
- en: Using the object storage helper in the worker
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在工作者中使用对象存储助手
- en: 'In the previous section, we showed the following lines in our task implementation:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们展示了任务实现中的以下几行代码：
- en: worker.py
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: worker.py
- en: '[PRE27]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/worker.py)'
- en: 'Now that we’ve talked about the `Storage` class, you should guess what we’re
    doing here: we take the generated image and its random name and upload it to a
    bucket defined in `settings`. And… That’s it!'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经谈到了 `Storage` 类，你应该能猜到我们在这里做的事情：我们获取生成的图像及其随机名称，并将其上传到 `settings` 中定义的存储桶。就这样！
- en: Generating a pre-signed URL on the server
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在服务器上生成预签名 URL
- en: 'On the API’s side, we implement a new endpoint whose role is to return a pre-signed
    URL for a given `GeneratedImage`:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在 API 端，我们实现了一个新端点，角色是返回给定 `GeneratedImage` 的预签名 URL：
- en: server.py
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: server.py
- en: '[PRE28]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/server.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/server.py)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/server.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter14/complete/server.py)'
- en: Before generating the URL, we first check whether the `file_name` property is
    set on the `GeneratedImage` object. If it’s not, it means the worker has not completed
    the task yet. If it is, we can proceed with the call to the `get_presigned_url`
    method of our `Storage` class.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成 URL 之前，我们首先检查 `GeneratedImage` 对象上是否设置了 `file_name` 属性。如果没有，意味着工作者任务尚未完成。如果有，我们就可以继续调用
    `Storage` 类的 `get_presigned_url` 方法。
- en: Notice that we took care of defining a dependency injection to get our `Storage`
    instance. As we’ve seen throughout this book, using dependencies in FastAPI is
    a very good practice when dealing with external services.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们已经定义了依赖注入来获取 `Storage` 实例。正如本书中所展示的那样，在处理外部服务时，FastAPI 中使用依赖是一个非常好的实践。
- en: Well, it seems that we’re all set! Let’s see it in action.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，看来我们一切准备就绪！让我们看看它如何运行。
- en: Running the image-generation system
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行图像生成系统
- en: 'First of all, we need to populate the environment variables for our project
    with, in particular, a database URL and S3 credentials. To keep things simple,
    we’ll use a simple SQLite database and the MinIO playground for the S3 storage.
    It’s a free and open instance of MinIO object storage that’s perfect for examples
    and toy projects. When going into production, you’ll be able to easily switch
    to any S3-compatible provider. Let’s create a `.env` file at the root of the project:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要为项目填充环境变量，特别是数据库 URL 和 S3 凭据。为了简化，我们将使用一个简单的 SQLite 数据库和 MinIO 的示例平台作为
    S3 存储。MinIO 是一个免费的开源对象存储平台，非常适合示例和玩具项目。当进入生产环境时，你可以轻松切换到任何兼容 S3 的提供商。让我们在项目根目录下创建一个
    `.env` 文件：
- en: '[PRE29]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The storage endpoint, access key, and secret key are the parameters for the
    MinIO playground. Make sure to check their official documentation to see whether
    they have changed since we wrote this book: [https://min.io/docs/minio/linux/developers/python/minio-py.html#id5](https://min.io/docs/minio/linux/developers/python/minio-py.html#id5).'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 存储端点、访问密钥和秘钥是 MinIO 演示环境的参数。确保查看它们的官方文档，以了解自我们编写本书以来是否有所更改：[https://min.io/docs/minio/linux/developers/python/minio-py.html#id5](https://min.io/docs/minio/linux/developers/python/minio-py.html#id5)。
- en: Our `Settings` class will automatically load this file to populate the settings
    we use throughout the code. Make sure to check the *Setting and using environment
    variables* section of [*Chapter 10*](B19528_10.xhtml#_idTextAnchor694) if you
    need a refresher on this concept.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`Settings`类将自动加载此文件，以填充我们在代码中使用的设置。如果你需要复习这一概念，确保查看[*第 10 章*](B19528_10.xhtml#_idTextAnchor694)中的*设置和使用环境变量*部分。
- en: 'We can now run our system. Make sure your Redis server is still running, as
    explained in the *Technical requirements* section. First of all, let’s run the
    FastAPI server:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以运行系统了。确保你的 Redis 服务器仍在运行，正如在*技术要求*部分所解释的那样。首先，让我们启动 FastAPI 服务器：
- en: '[PRE30]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, start the worker:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，启动工作进程：
- en: '[PRE31]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The stack is now ready to generate images. Let’s make a request with HTTPie
    to start a new task:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 堆栈现在已准备好生成图像。让我们使用 HTTPie 发起请求，开始一个新的任务：
- en: '[PRE32]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'A new `GeneratedImage` has been created in the database with the assigned ID
    `1`. The progress is at *0%*; the processing has not started yet. Let’s try to
    query it with our API:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 一个新的`GeneratedImage`已在数据库中创建，分配的 ID 为`1`。进度为*0%*；处理尚未开始。让我们尝试通过 API 查询它：
- en: '[PRE33]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The API returns the same object with all its properties. Notice that the progress
    has been updated and that it’s now at *36%*. After a while, we can try the same
    request again:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: API 返回相同的对象及其所有属性。注意，进度已更新，现在为*36%*。过一会儿，我们可以再次尝试相同的请求：
- en: '[PRE34]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This time, the progress is at *100%* and the filename has been filled. The
    image is ready! We can now ask our API to generate a pre-signed URL for this image:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，进度为*100%*，文件名已经填写。图像准备好了！现在我们可以请求 API 为该图像生成一个预签名 URL：
- en: '[PRE35]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We get a very long URL on the MinIO server. If you open it in your browser,
    you’ll see the image that has just been generated by our system, as you can see
    in *Figure 14**.6*.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 MinIO 服务器上得到了一个非常长的 URL。如果你在浏览器中打开它，你会看到刚刚由我们的系统生成的图像，如*图 14.6*所示。
- en: '![Figure 14.6 – Generated image hosted on object storage](img/Figure_14.6_B19528.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.6 – 生成的图像托管在对象存储中](img/Figure_14.6_B19528.jpg)'
- en: Figure 14.6 – Generated image hosted on object storage
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.6 – 生成的图像托管在对象存储中
- en: 'Quite nice, isn’t it? We now have a fully featured system where the user is
    able to do the following:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 很不错，不是吗？我们现在拥有一个功能齐全的系统，用户能够执行以下操作：
- en: Request to generate images following their own prompt and parameters
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求根据他们自己的提示和参数生成图像
- en: Get information about the progress of the request
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取请求进度的信息
- en: Get the resulting image from reliable storage
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从可靠存储中获取生成的图像
- en: The architecture we see here is already deployable in a cloud environment with
    multiple machines. Typically, we may have a standard, cheap server to serve the
    API and a more expensive one with a dedicated GPU and a good amount of RAM to
    run the worker. The code doesn’t have to change to handle this kind of deployment
    since the communication between processes is handled by the central elements –
    the message broker, the database, and the object storage.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里看到的架构已经可以在具有多台机器的云环境中部署。通常，我们可能会有一台标准的便宜服务器来提供 API 服务，而另一台则是更昂贵的服务器，配有专用
    GPU 和充足的 RAM 来运行工作进程。代码无需更改就可以处理这种部署，因为进程间的通信是由中央元素——消息代理、数据库和对象存储来处理的。
- en: Summary
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Awesome! You may not have realized it yet, but in this chapter, you learned
    how to architect and implement a very complex machine learning system that could
    rival existing image-generation services you see out there. The concepts we showed
    here are essential and are at the heart of all the distributed systems you could
    imagine, whether they are designed to run machine learning models, extraction
    pipelines, or math computations. By using modern tools such as FastAPI and Dramatiq,
    you’ll be able to implement this kind of architecture in a short time with a minimum
    amount of code, leading to a very quick and robust result.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你可能还没有意识到，但在这一章中，你已经学习了如何架构和实现一个非常复杂的机器学习系统，它能与你在外面看到的现有图像生成服务相媲美。我们在这里展示的概念是至关重要的，且是所有你能想象的分布式系统的核心，无论它们是设计用来运行机器学习模型、提取管道，还是数学计算。通过使用像FastAPI和Dramatiq这样的现代工具，你将能够在短时间内用最少的代码实现这种架构，最终得到一个非常快速且稳健的结果。
- en: 'We’re near the end of our journey. Before letting you live your own adventures
    with FastAPI, we’ll study one last important aspect when building data science
    applications: logging and monitoring.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的旅程即将结束。在让你用FastAPI开始自己的冒险之前，我们将研究构建数据科学应用程序时的最后一个重要方面：日志记录和监控。
