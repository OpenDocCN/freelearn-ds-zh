- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Create a Baseline Model Using Databricks AutoML
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Databricks AutoML创建基准模型
- en: In the last chapter, we understood **MLflow** and all its components. After
    running the notebook from [*Chapter 4*](B17875_04.xhtml#_idTextAnchor076), *Understanding
    MLflow Components on Databricks*, you might have recognized how easy it actually
    is to start tracking your ML model training in Databricks using the integrated
    MLflow tracking server. In this chapter, we will cover another new and unique
    feature of **Databricks** called **AutoML**.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们理解了**MLflow**及其所有组件。运行[*第4章*](B17875_04.xhtml#_idTextAnchor076)的笔记本《在Databricks上理解MLflow组件》后，你可能已经意识到，在Databricks中使用集成的MLflow跟踪服务器来开始跟踪你的机器学习模型训练是多么简单。在本章中，我们将介绍另一个新的独特功能——**Databricks**的**AutoML**。
- en: Databricks AutoML, like all the other features that are part of the Databricks
    workspace, is fully integrated with MLflow features and the Feature Store.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks AutoML，像Databricks工作区中的其他所有功能一样，完全与MLflow功能和Feature Store集成。
- en: Databricks AutoML, at the time of writing of this book, supports **classification**,
    **regression**, and **forecasting** use cases using traditional ML algorithms
    and not deep learning. You can see a list of supported algorithms in the second
    section of the chapter.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写本书时，Databricks AutoML支持**分类**、**回归**和**预测**的使用案例，采用的是传统的机器学习算法，而非深度学习。你可以在本章第二部分看到支持的算法列表。
- en: You can use AutoML with a table registered in Databricks’ Hive metastore, feature
    tables, or even upload a new file using the import data functionality in Databricks.
    You can read more about it by clicking the link in the *Further* *reading* section.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用Databricks的Hive元存储中注册的表、特征表，甚至通过Databricks中的导入数据功能上传新的文件来使用AutoML。你可以通过点击*进一步阅读*部分的链接了解更多信息。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Understanding the need for AutoML
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解AutoML的需求
- en: Understanding AutoML in Databricks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Databricks中的AutoML
- en: Running AutoML on our churn prediction dataset
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们的流失预测数据集上运行AutoML
- en: Current limitations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前的限制
- en: Let’s go through the technical requirements for this chapter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来了解本章的技术要求。
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To go through the chapter, we’ll need the following requirements:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过本章内容，我们需要满足以下要求：
- en: we'll need the execution of the notebooks pertaining to [*Chapter 3*](B17875_03.xhtml#_idTextAnchor063),
    which involves the ingestion of raw data from a CSV file into a Delta table and
    the subsequent registration of a new feature table, to have already been completed.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要先执行涉及将CSV文件中的原始数据导入Delta表，并随后注册新的特征表的[*第3章*](B17875_03.xhtml#_idTextAnchor063)的笔记本。
- en: Understanding the need for AutoML
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解AutoML的需求
- en: If you have never worked with any AutoML framework before, you might be wondering
    what AutoML is and when and how it can be useful.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从未使用过任何AutoML框架，可能会想知道什么是AutoML，以及它何时以及如何能发挥作用。
- en: AutoML simplifies the machine learning model development process by automating
    various tasks. It automatically generates baseline models tailored to your specific
    datasets and even offers preconfigured notebooks to kickstart your projects. This
    is particularly appealing to data scientists of all levels of expertise because
    it saves valuable time in the initial stages of model development. Instead of
    manually crafting models from scratch, AutoML provides a quick and efficient way
    to obtain baseline models, making it a valuable tool for both beginners and experienced
    data scientists alike.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML通过自动化各种任务简化了机器学习模型开发过程。它会自动生成针对特定数据集的基准模型，并提供预配置的笔记本来启动你的项目。这对于各个水平的数据科学家都特别有吸引力，因为它能节省模型开发初期的宝贵时间。与其从头开始手动构建模型，不如借助AutoML快速高效地获取基准模型，这使它成为初学者和经验丰富的数据科学家都值得使用的工具。
- en: AutoML makes machine learning not only accessible to citizen data scientists
    and business subject matter experts. AutoML, while undoubtedly a powerful tool,
    also grapples with significant limitations. One notable challenge is its inherent
    black-box nature, which makes it difficult, and at times impossible, to decipher
    which hyperparameters and algorithms are most effective for a particular problem.
    This opacity presents a substantial obstacle when it comes to achieving model
    explainability.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML 不仅让公民数据科学家和业务领域专家可以接触到机器学习。虽然 AutoML 无疑是一个强大的工具，但它也面临着显著的限制。一个明显的挑战是它固有的黑盒特性，这使得很难，有时甚至不可能，解读哪些超参数和算法对于特定问题最有效。这种不透明性在实现模型可解释性时构成了一个实质性的障碍。
- en: Furthermore, many AutoML tools available in the market fall short of supporting
    essential components in the machine learning life cycle, including the critical
    step of operationalizing models for production use. This deficiency can hinder
    the seamless integration of machine learning solutions into real-world applications.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，许多市场上可用的 AutoML 工具未能支持机器学习生命周期中的关键组件，包括将模型投入生产使用这一至关重要的步骤。这一缺陷可能会妨碍机器学习解决方案与实际应用的无缝集成。
- en: It’s important to note that AutoML doesn’t replace the role of a data scientist.
    While it streamlines certain aspects of model development, the expertise and insights
    of a skilled data scientist remain indispensable in ensuring the success of machine
    learning projects.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，AutoML 并不会替代数据科学家的角色。虽然它简化了模型开发的某些方面，但熟练的数据科学家的专业知识和见解仍然是确保机器学习项目成功的不可或缺的因素。
- en: This is where Databricks AutoML actually provides one of its biggest benefits.
    Let’s take a deeper look into AutoML in Databricks and discover how you can use
    it in your model development journey.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 Databricks AutoML 实际上提供的最大好处之一。让我们更深入地了解 Databricks 中的 AutoML，看看你如何在模型开发过程中使用它。
- en: Understanding AutoML in Databricks
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解 Databricks 中的 AutoML
- en: Databricks AutoML uses a glass-box approach to AutoML. When you use Databricks
    AutoML either through the UI or through the supported Python API, it logs every
    combination of model and hyperparameter (trial) as an MLflow run and generates
    Python notebooks with source code corresponding to each model trial. The results
    of all these model trials are logged into the MLflow tracking server. Each of
    the trials can be compared and reproduced. Since you have access to the source
    code, the data scientists can easily rerun a trial after modifying the code. We
    will look at this in more detail when we go over the example.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks AutoML 使用透明盒子方法进行 AutoML。当你通过 UI 或支持的 Python API 使用 Databricks AutoML
    时，它会将每一个模型和超参数组合（试验）作为 MLflow 运行进行日志记录，并生成对应每个模型试验的 Python 笔记本和源代码。所有这些模型试验的结果都会被记录到
    MLflow 跟踪服务器中。每一个试验都可以进行比较和重现。由于你可以访问源代码，数据科学家可以在修改代码后轻松重新运行某个试验。我们将在后面的例子中详细讲解这一点。
- en: Databricks AutoML also prepares the dataset for training and then performs model
    training and hyperparameter tuning on the Databricks cluster. One important thing
    to keep in mind here is that Databricks AutoML spreads hyperparameter tuning trials
    across the cluster. A trial is a unique configuration of hyperparameters associated
    with the model. All the training datasets should fit in a single executor, as
    Databricks AutoML will automatically sample your dataset if you have a large dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks AutoML 还会准备训练数据集，然后在 Databricks 集群上执行模型训练和超参数调优。这里需要注意的一点是，Databricks
    AutoML 会将超参数调优试验分布到整个集群。一个试验是与模型相关的超参数的唯一配置。如果你的数据集很大，所有训练数据集应该适应一个单独的执行器，因为 Databricks
    AutoML 会自动对你的数据集进行抽样。
- en: 'At the time of writing the book, Databricks AutoML supports the following algorithms:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写本书时，Databricks AutoML 支持以下算法：
- en: '| **ML problems** | **Supported algorithms** |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| **机器学习问题** | **支持的算法** |'
- en: '| Classification |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 分类 |'
- en: 'Scikit-learn models:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scikit-learn 模型：
- en: Decision trees
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: Random forests
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Logistic regression
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: XGBoost
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost
- en: LightGBM
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LightGBM
- en: '|'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Regression |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 回归 |'
- en: 'Scikit-learn models:'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scikit-learn 模型：
- en: Linear regression with stochastic gradient descent
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用随机梯度下降的线性回归
- en: Decision trees
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: Random forests
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: XGBoost
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost
- en: LightGBM
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LightGBM
- en: '|'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Forecasting |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 预测 |'
- en: Prophet
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prophet
- en: Auto ARIMA
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Auto ARIMA
- en: '|'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Table 5.1 – Algorithms that Databricks AutoML supports
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5.1 – Databricks AutoML 支持的算法
- en: Let’s understand some of the key capabilities provided by Databricks AutoML
    in more detail.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地了解 Databricks AutoML 提供的一些关键功能。
- en: Sampling large datasets
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大数据集的采样
- en: Sampling is done based on the estimated memory required to load and train models
    on the training dataset. Until ML Runtime 10.5, the data sampling does not depend
    on the VM type or the amount of memory the executor is running on. In ML Runtime
    11.0 and later versions, the sampling mechanism will increase sampling fraction
    and size if a node is compute-optimized with more significant memory.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 采样是根据加载并训练模型所需的内存估算来进行的。在 ML Runtime 10.5 之前，数据采样不依赖于 VM 类型或执行器运行的内存量。在 ML Runtime
    11.0 及更高版本中，如果节点是计算优化的并具有更大的内存，采样机制将增加采样比例和大小。
- en: By default, in Databricks, each executor is configured to execute the same number
    of trials as there are available CPU cores. Additionally, the executor’s available
    memory is evenly distributed among these trials. However, you have the flexibility
    to modify this behavior by adjusting the `spark. task.cpus` configuration parameter.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，在 Databricks 中，每个执行器被配置为执行与可用 CPU 核心数量相同的试验次数。此外，执行器的可用内存会在这些试验之间均匀分配。然而，您可以通过调整
    `spark.task.cpus` 配置参数来灵活修改此行为。
- en: The default setting for `spark.task.cpus` is `1`, which means that each executor
    will run as many trials in parallel as it has CPU cores. If you change this value
    to match the number of available CPU cores on the executor, it will result in
    a different behavior. In this case, only one trial will be executed on the executor
    at a time, but that trial will have access to the full memory capacity of the
    executor. This setting can be useful if you want to provide additional resources
    to each of your trials. This will also increase the size of the sampled dataset.
    AutoML utilizes the PySparks `sampleBy` method ([https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameStatFunctions.sampleBy.html](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameStatFunctions.sampleBy.html))
    for performing stratified sampling for classification problems.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`spark.task.cpus` 的默认设置为 `1`，这意味着每个执行器将并行执行与其 CPU 核心数量相同的试验。如果您将此值更改为与执行器上可用的
    CPU 核心数量相匹配，将会导致不同的行为。在这种情况下，每次只会在执行器上执行一个试验，但该试验将能够访问执行器的全部内存容量。如果您希望为每个试验提供更多资源，这个设置会非常有用。此举也会增加采样数据集的大小。AutoML
    使用 PySparks 的 `sampleBy` 方法（[https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameStatFunctions.sampleBy.html](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameStatFunctions.sampleBy.html)）进行分类问题的分层采样。'
- en: For regression problems, AutoML utilizes the `sample` method ([https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sample.html](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sample.html))
    when sampling is needed.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归问题，AutoML 在需要采样时使用 `sample` 方法（[https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sample.html](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sample.html)）。
- en: '*Sampling is not applicable for* *forecasting problems*.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*采样不适用于* *预测问题*。'
- en: Imbalance data detection
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不平衡数据检测
- en: In Databricks Runtime 11.2 ML and newer versions, when AutoML detects an imbalanced
    dataset for a classification use case, it takes steps to mitigate the imbalance
    within the training dataset. This is accomplished through a combination of downsampling
    the major class(es) and introducing class weights. It’s important to note that
    this balancing process is applied exclusively to the training dataset and doesn’t
    affect the test and validation datasets. This approach guarantees that the model’s
    performance is evaluated based on the original dataset with its true class distribution.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Databricks Runtime 11.2 ML 及更新版本中，当 AutoML 检测到分类用例的类别不平衡时，它会采取措施缓解训练数据集中的不平衡。通过对主类进行下采样和引入类别权重的组合，来实现这一目标。需要注意的是，这个平衡过程仅应用于训练数据集，不会影响测试和验证数据集。这种方法保证了模型性能是基于原始数据集及其真实类别分布来评估的。
- en: To address an imbalanced training dataset, AutoML assigns class weights that
    are inversely proportional to the extent of downsampling applied to a specific
    class. To illustrate, let’s consider a training dataset with 100 samples, where
    95 belong to `Class A` and 5 belong to `Class B`. AutoML reduces this imbalance
    by downsampling `Class A` to 70 samples, effectively reducing it by a ratio of
    70:95, or approximately 0.736\. Meanwhile, the number of samples in `Class B`
    remains at five. To ensure that the final model is properly calibrated and maintains
    the same probability distribution as the input data, AutoML adjusts the class
    weight for `Class A` by the inverse of this ratio, which is approximately 1:0.736,
    or 1.358\. The weight for `Class B` remains at one. These class weights are then
    used during the model training process as a parameter to ensure that samples from
    each class receive appropriate weighting, contributing to a balanced and accurate
    model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决不平衡的训练数据集问题，AutoML会根据对特定类别应用的下采样程度，分配与类别权重成反比的类权重。例如，假设训练数据集中有100个样本，其中95个属于`Class
    A`，5个属于`Class B`。AutoML通过将`Class A`下采样到70个样本来减少这种不平衡，比例约为70:95，即约为0.736。与此同时，`Class
    B`的样本数保持为5。为了确保最终模型得到正确的校准，并且保持与输入数据相同的概率分布，AutoML通过此比例的倒数（约为1:0.736，即1.358）来调整`Class
    A`的类权重。`Class B`的权重保持为1。这些类权重将在模型训练过程中作为参数使用，确保来自每个类别的样本得到适当的加权，从而帮助构建一个平衡且准确的模型。
- en: Splitting data into train/validation/test sets
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据拆分为训练集/验证集/测试集
- en: In Databricks Runtime 10.1 ML and later versions, you have the option to designate
    a time column when performing data splits for classification and regression tasks.
    When you specify this time column, the dataset is divided into training, validation,
    and test sets based on chronological order. The data points from the earliest
    time period are allocated to the training set, followed by the next earliest for
    validation. The most recent data points are reserved for the test set.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在Databricks Runtime 10.1 ML及之后的版本中，您可以在执行分类和回归任务的数据拆分时指定一个时间列。当您指定这个时间列时，数据集将根据时间顺序划分为训练集、验证集和测试集。最早的时间段的数据点会分配到训练集，其次是验证集，最新的数据点则保留在测试集。
- en: In Databricks Runtime 10.1 ML, the time column must be of either the timestamp
    or integer data type. However, starting from Databricks Runtime 10.2 ML, you also
    have the flexibility to choose a string column for this purpose. This enhancement
    offers greater versatility in time-based data splitting for improved model training
    and evaluation.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在Databricks Runtime 10.1 ML中，时间列必须是时间戳或整数数据类型。然而，从Databricks Runtime 10.2 ML开始，您还可以灵活选择字符串列作为时间列。这一增强功能为基于时间的数据拆分提供了更大的灵活性，从而有助于改进模型训练和评估。
- en: Enhancing semantic type detection
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强语义类型检测
- en: Semantic type detection is a powerful feature, introduced in Databricks Runtime
    versions 9.1 LTS ML and beyond, designed to augment AutoML by providing intelligent
    insights into the data types present within each column. *It is essential to note
    that semantic type detection does not apply to forecasting problems or columns
    where custom imputation methods have* *been specified.*
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 语义类型检测是一个强大的功能，它在Databricks Runtime 9.1 LTS ML及以后版本中引入，旨在通过提供对每列中数据类型的智能洞察，增强AutoML的能力。*需要注意的是，语义类型检测不适用于预测问题或已指定自定义填充方法的列。*
- en: 'AutoML conducts a thorough analysis of columns to ascertain whether their semantic
    type differs from the data type specified in the table schema (either Spark or
    pandas). Once discrepancies are identified, AutoML takes specific actions based
    on the detected semantic type. However, it’s important to keep in mind that these
    detections may not always be 100% accurate. The following are the key adjustments
    AutoML can make:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML会对列进行彻底分析，以确定它们的语义类型是否与表架构中指定的数据类型（Spark或pandas）不同。一旦发现不一致，AutoML将根据检测到的语义类型采取具体的行动。然而，值得注意的是，这些检测可能并不总是100%准确。以下是AutoML可以进行的关键调整：
- en: '**String and integer columns with date or timestamp data**: These are intelligently
    recognized as timestamp types, allowing for more precise handling of temporal
    information'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带有日期或时间戳数据的字符串和整数列**：这些列会被智能地识别为时间戳类型，从而更精确地处理时间信息'
- en: '**String columns representing numeric data**: When applicable, these columns
    are converted into numeric types, ensuring that mathematical operations can be
    performed seamlessly'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**表示数值数据的字符串列**：在适用的情况下，这些列会被转换为数值类型，确保可以无缝地进行数学运算'
- en: 'Starting from Databricks Runtime 10.1 ML, AutoML extends its capabilities to
    encompass the following:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从Databricks Runtime 10.1 ML开始，AutoML扩展了其功能，涵盖以下内容：
- en: '**Numeric columns containing categorical IDs**: These are identified as categorical
    features, aiding in more accurate modeling when dealing with categorical data'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**包含类别ID的数值列**：这些列被识别为类别特征，有助于在处理类别数据时进行更准确的建模'
- en: '**String columns containing English text**: Such columns are identified as
    text features, enhancing the understanding of textual data within the dataset'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**包含英文文本的字符串列**：这些列被识别为文本特征，增强了数据集中对文本数据的理解'
- en: 'In Databricks Runtime version 10.1 ML and beyond, users gain the ability to
    manually set semantic types through Python annotations. The following code snippet
    illustrates the syntax for this manual annotation process:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在Databricks Runtime 10.1 ML及以后版本中，用户可以通过Python注解手动设置语义类型。以下代码示例演示了这种手动注解过程的语法：
- en: '[PRE0]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The available semantic types that you can assign manually are as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以手动分配的可用语义类型如下：
- en: '**Categorical**: Appropriate for columns containing values such as IDs'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类别型**：适用于包含诸如ID等值的列'
- en: '**Numeric**: Ideal for columns containing numeric values'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数值型**：适用于包含数值的列'
- en: '**DateTime**: Suitable for columns with timestamp values'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DateTime**：适用于包含时间戳值的列'
- en: '**Text**: Reserved for string columns containing English text'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本**：保留用于包含英文文本的字符串列'
- en: To disable semantic type detection for a specific column, you can use the special
    keyword annotation native.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 若要禁用特定列的语义类型检测，可以使用特殊的关键字注解native。
- en: Shapley value (SHAP) for model explainability
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Shapley值（SHAP）用于模型可解释性
- en: '**Shapley values** (**SHAP**) are a technique grounded in game theory used
    to estimate the significance of each feature in a machine learning model’s predictions.
    AutoML regression and classification notebooks come with built-in code to compute
    these values using the SHAP package. However, because calculating SHAP is highly
    memory-intensive, they are not enabled by default.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**Shapley值**（**SHAP**）是一种基于博弈论的技术，用于估算每个特征在机器学习模型预测中的重要性。AutoML回归和分类笔记本自带计算这些值的内置代码，使用SHAP包进行计算。然而，由于计算SHAP非常占用内存，因此默认情况下未启用。'
- en: To activate and compute SHAP in an AutoML notebook, you need to navigate to
    the `shap_enabled` to `True`, and then rerun the notebook. It’s worth noting that
    SHAP plots won’t be generated in version 11.1 and earlier versions of MLR if the
    dataset includes a `DateTime` column.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 若要在AutoML笔记本中启用并计算SHAP，您需要将`shap_enabled`设置为`True`，然后重新运行笔记本。值得注意的是，如果数据集中包含`DateTime`列，则在版本11.1及更早版本的MLR中将不会生成SHAP图。
- en: Feature Store integration
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征存储集成
- en: In Databricks Runtime version 11.3 LTS ML and subsequent releases, feature tables
    from the Feature Store can be utilized to enhance the base dataset for classification
    and regression tasks. As of version 12.2 LTS ML, this capability extends to augmenting
    the input dataset for a comprehensive set of AutoML challenges, including classification,
    regression, and forecasting.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在Databricks Runtime版本11.3 LTS ML及后续版本中，特征存储中的特征表可用于增强分类和回归任务的基础数据集。从版本12.2 LTS
    ML开始，这一功能扩展到增强输入数据集，以支持一整套AutoML挑战，包括分类、回归和预测。
- en: 'There are certain limitations associated with the current state of AutoML.
    Only the following data types in your dataset are supported:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当前AutoML的状态存在某些限制。仅支持数据集中以下数据类型：
- en: Numeric (`ByteType`, `ShortType`, `IntegerType`, `LongType`, `FloatType`, and
    `DoubleType`)
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值型（`ByteType`、`ShortType`、`IntegerType`、`LongType`、`FloatType`和`DoubleType`）
- en: Boolean
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布尔值
- en: String (categorical or English text)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串（类别或英文文本）
- en: Timestamps (*TimestampType* and *DateType*)
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间戳（*TimestampType*和*DateType*）
- en: '`ArrayType[Numeric]` (Databricks Runtime 10.4 LTS ML and later versions)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ArrayType[Numeric]`（Databricks Runtime 10.4 LTS ML及更高版本）'
- en: '`DecimalType` (Databricks Runtime 11.3 LTS ML and later versions)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DecimalType`（Databricks Runtime 11.3 LTS ML及更高版本）'
- en: You also need to ensure that the source dataset has all unique column names.
    If you utilize AutoML for time series forecasting and want Auto ARIMA, ensure
    that the interval between any two points in the time-series input dataset is the
    same. AutoML will automatically fill the missing timesteps with the previous value
    by default.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要确保源数据集中的所有列名都是唯一的。如果您使用 AutoML 进行时间序列预测，并且希望使用 Auto ARIMA，请确保时间序列输入数据集中的任何两点之间的间隔相同。默认情况下，AutoML
    会自动用前一个值填充缺失的时间步。
- en: Let’s take a look at an example use case for AutoML.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个 AutoML 的示例用例。
- en: Running AutoML on our churn prediction dataset
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在我们的客户流失预测数据集上运行 AutoML
- en: Let’s take a look at how to use Databricks AutoML with our bank customer churn
    prediction dataset.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下如何使用 Databricks AutoML 来预测我们银行客户的流失率。
- en: If you executed the notebooks from [*Chapter 3*](B17875_03.xhtml#_idTextAnchor063),
    *Utilizing the Feature Store*, you will have raw data available as a Delta table
    in your Hive metastore. It has the name `raw_data`. In the [*Chapter 3*](B17875_03.xhtml#_idTextAnchor063)
    code, we read a CSV file from our Git repository with raw data, wrote that as
    a Delta table, and registered it in our integrated metastore. Take a look at `cmd
    15` in your notebook. In your environment, the dataset can be coming from another
    data pipeline or uploaded directly to the Databricks workspace using the *Upload*
    *file* functionality.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您执行了来自[*第 3 章*](B17875_03.xhtml#_idTextAnchor063)的笔记本，*利用功能存储*，您将会在 Hive 元存储中看到原始数据作为
    Delta 表。它的名称为 `raw_data`。在[*第 3 章*](B17875_03.xhtml#_idTextAnchor063)的代码中，我们从
    Git 仓库读取了一个 CSV 文件，将其作为 Delta 表写入，并在我们的集成元存储中注册它。请查看您笔记本中的 `cmd 15`。在您的环境中，数据集可能来自另一个数据管道，或通过
    *上传文件* 功能直接上传到 Databricks 工作区。
- en: To view the tables, you need to have your cluster up and running.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看表格，您需要确保集群已启动并运行。
- en: '![Figure 5.1 – The location of the raw dataset](img/B17875_05_01.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.1 – 原始数据集的位置](img/B17875_05_01.jpg)'
- en: Figure 5.1 – The location of the raw dataset
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – 原始数据集的位置
- en: Let’s create our first Databricks AutoML experiment.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建第一个 Databricks AutoML 实验。
- en: Important note
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'Make sure that before following the next steps, you have a cluster up and running
    that has the following configuration:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在执行下一步之前，您的集群已启动并运行，并且配置如下：
- en: Single-node or multi-node
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 单节点或多节点
- en: Access mode as a single user
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以单用户模式访问
- en: The Databricks runtime version is set to 13.3 LTS ML or higher
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 运行时版本设置为 13.3 LTS ML 或更高版本
- en: '*Worker Type/Driver Type* is any VM type with at least four cores'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*工作节点类型/驱动程序类型* 是至少有四个核心的任何虚拟机类型'
- en: '*No additional libraries should be installed on the cluster other than those
    pre-installed in Databricks Runtime for machine learning. AutoML is not compatible
    with clusters operating in shared* *access mode.*'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*集群上不应安装除 Databricks 运行时为机器学习预装的库之外的任何其他库。AutoML 不兼容在共享访问模式下运行的集群。*'
- en: On the left tab, click on **Experiments**.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧选项卡中，点击**实验**。
- en: '![Figure 5.2 – The location of the Experiments tab](img/B17875_05_02.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2 – 实验选项卡的位置](img/B17875_05_02.jpg)'
- en: Figure 5.2 – The location of the Experiments tab
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – 实验选项卡的位置
- en: On the top of this page, click on **Create AutoML Experiment**. This will bring
    you to the AutoML configuration page.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此页面顶部，点击**创建 AutoML 实验**。这将引导您进入 AutoML 配置页面。
- en: '![Figure 5.3 – How to create a new AutoML experiment (1)](img/B17875_05_03.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.3 – 如何创建新的 AutoML 实验 (1)](img/B17875_05_03.jpg)'
- en: Figure 5.3 – How to create a new AutoML experiment (1)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 – 如何创建新的 AutoML 实验 (1)
- en: As an alternative, you can click on **New** and then select **AutoML Experiment**.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为替代方案，您可以点击**新建**，然后选择**AutoML 实验**。
- en: '![Figure 5.4 – An alternative way to create an AutoML experiment](img/B17875_05_04.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.4 – 创建 AutoML 实验的另一种方式](img/B17875_05_04.jpg)'
- en: Figure 5.4 – An alternative way to create an AutoML experiment
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 – 创建 AutoML 实验的另一种方式
- en: 'To get started, you need to enter the following basic information:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要开始，您需要输入以下基本信息：
- en: '**For the purpose of this cluster**: This is what cluster configuration you
    want the AutoML to run on. You can reuse the same cluster we created for [*Chapter
    3*](B17875_03.xhtml#_idTextAnchor063), *Utilizing the Feature Store*, and [*Chapter
    4*](B17875_04.xhtml#_idTextAnchor076), *Understanding MLflow Components* *on Databricks.*'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对于该集群的目的**：这是您希望 AutoML 运行的集群配置。您可以重用我们在[*第 3 章*](B17875_03.xhtml#_idTextAnchor063)中为*利用功能存储*创建的集群，和在[*第
    4 章*](B17875_04.xhtml#_idTextAnchor076)中为*理解 MLflow 组件*创建的集群。'
- en: '**ML problem type**: Regression, classification, or forecasting.'
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习问题类型**：回归、分类或预测。'
- en: '**Dataset**: The dataset containing all the features and label/target column.'
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集**：包含所有特征和标签/目标列的数据集。'
- en: '![Figure 5.5 – How to create a new AutoML experiment (2)](img/B17875_05_05.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.5 – 如何创建一个新的 AutoML 实验 (2)](img/B17875_05_05.jpg)'
- en: Figure 5.5 – How to create a new AutoML experiment (2)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 – 如何创建一个新的 AutoML 实验 (2)
- en: '**Prediction target**: This is specific to the classification problem at hand.
    Once you select your dataset for running AutoML, this will auto-populate with
    all the columns and you can select your target column.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测目标**：这对于当前的分类问题是特定的。当您选择用于运行 AutoML 的数据集时，系统会自动填充所有列，您可以选择目标列。'
- en: '![Figure 5.6 – Showing how to create a new AutoML experiment (3)](img/B17875_05_006.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.6 – 展示如何创建一个新的 AutoML 实验 (3)](img/B17875_05_006.jpg)'
- en: Figure 5.6 – Showing how to create a new AutoML experiment (3)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 – 展示如何创建一个新的 AutoML 实验 (3)
- en: '**Experiment name**: This is the name that is used to track all your trials.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验名称**：这是用于跟踪所有试验的名称。'
- en: Optionally, you can also select what features from your selected table need
    to be included when running the trials. In our case, `RowNumber`, `CustomerId`,
    and `Surname` don’t add any value to our analysis, so we will remove them from
    selection.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选地，您还可以选择在运行试验时需要从选定的表格中包含哪些特性。在我们的案例中，`RowNumber`、`CustomerId` 和 `Surname`
    对我们的分析没有任何帮助，因此我们将从选择中移除它们。
- en: '![Figure 5.7 – How to create a new AutoML experiment (4)](img/B17875_05_007.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.7 – 如何创建一个新的 AutoML 实验 (4)](img/B17875_05_007.jpg)'
- en: Figure 5.7 – How to create a new AutoML experiment (4)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 – 如何创建一个新的 AutoML 实验 (4)
- en: Optionally, you can also select how you would want to handle missing values
    in your dataset.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 可选地，您还可以选择如何处理数据集中的缺失值。
- en: In versions 10.4 LTS ML and higher of Databricks Runtime, you can define the
    approach for handling `null` values. Within the UI, you can select your desired
    imputation technique via the **Impute with** drop-down menu located within the
    table **Schema** section.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Databricks Runtime 10.4 LTS ML 及更高版本中，您可以定义处理 `null` 值的方法。在用户界面中，您可以通过表格 **Schema**
    部分的 **Impute with** 下拉菜单选择您希望使用的填充技术。
- en: It’s worth noting that AutoML automatically chooses an appropriate imputation
    strategy based on both the data type and the content of the column in question.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，AutoML 会根据数据类型和相关列的内容自动选择合适的填充策略。
- en: '![Figure 5.8 – How to create a new AutoML experiment (5)](img/B17875_05_08.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.8 – 如何创建一个新的 AutoML 实验 (5)](img/B17875_05_08.jpg)'
- en: Figure 5.8 – How to create a new AutoML experiment (5)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 – 如何创建一个新的 AutoML 实验 (5)
- en: That’s it! Those are the only five things you need to do to start using glassbox
    AutoML with Databricks.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！这就是您开始使用 Databricks 中的 Glassbox AutoML 所需要做的五件事。
- en: 'There are some advanced configurations as well, such as what metrics you want
    to optimize when selecting the best-performing model or what supported training
    framework you want to include to run trials on:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些高级配置，例如在选择最佳表现模型时，您希望优化哪些指标，或者您希望包含哪些支持的训练框架来运行试验：
- en: The evaluation metric serves as the primary scoring metric for runs.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估指标作为运行的主要评分指标。
- en: Starting from Databricks Runtime 10.3 ML, it’s possible to exclude certain training
    frameworks. By default, AutoML uses frameworks listed under its algorithms.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Databricks Runtime 10.3 ML 开始，您可以排除某些训练框架。默认情况下，AutoML 使用其算法下列出的框架。
- en: 'Stopping conditions are customizable. The defaults are as follows:'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止条件是可定制的。默认设置如下：
- en: Stop after 120 minutes for forecasting experiments.
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于预测实验，120 分钟后停止。
- en: For classification and regression experiments in Databricks Runtime 10.5 ML
    and earlier versions, stop after 60 minutes or after 200 trials—whichever comes
    first. Starting from Databricks Runtime 11.0 ML, the number of trials is not a
    stopping condition.
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 Databricks Runtime 10.5 ML 及更早版本中的分类和回归实验，停止条件为 60 分钟或 200 次试验，以先到者为准。从 Databricks
    Runtime 11.0 ML 开始，试验次数不再作为停止条件。
- en: From Databricks Runtime 10.1 ML, AutoML incorporates early stopping for classification
    and regression if the validation metric ceases to improve.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Databricks Runtime 10.1 ML 开始，AutoML 为分类和回归任务引入了早停策略，如果验证指标停止改进，则会提前停止。
- en: Also starting from Databricks Runtime 10.1 ML, you can select a time column
    for chronological data splitting in classification and regression tasks.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Databricks Runtime 10.1 ML 开始，您还可以选择用于分类和回归任务中时间序列数据拆分的时间列。
- en: You can specify a DBFS location for saving the training dataset in the **Data
    directory** field. If left blank, the dataset is saved as an MLflow artifact.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在**数据目录**字段中指定一个 DBFS 位置来保存训练数据集。如果留空，数据集将作为 MLflow 产物保存。
- en: '![Figure 5.9 – How to create a new AutoML experiment (6)](img/B17875_05_09.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.9 – 如何创建一个新的 AutoML 实验 (6)](img/B17875_05_09.jpg)'
- en: Figure 5.9 – How to create a new AutoML experiment (6)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 – 如何创建一个新的 AutoML 实验 (6)
- en: To enhance the richness of your dataset, you can seamlessly integrate an existing
    feature table. Simply scroll to the bottom of the page and click on the **Join
    Features** option. This will grant you access to a configuration panel where you
    can precisely specify which feature tables you want to merge with your existing
    dataset and establish the key or keys that will underpin this merging process,
    effectively linking the datasets.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强数据集的丰富性，你可以无缝地集成现有的特征表。只需滚动到页面底部并点击**连接特征**选项。这将带你进入一个配置面板，在那里你可以精确指定要与现有数据集合并的特征表，并建立一个或多个键来支撑这个合并过程，从而有效地链接数据集。
- en: However, it’s important to note that for the sake of this example, we will not
    be incorporating the *Feature store* table into the *merge* operation. This approach
    empowers you to bolster your dataset with additional information from selected
    feature tables, elevating its utility for analytical or machine-learning endeavors
    while omitting the Feature Store table from this particular exercise.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，为了这个示例，我们将不会将*特征存储*表包含在*合并*操作中。此方法使你能够通过从选定的特征表中获取额外信息来增强数据集，从而提高其在分析或机器学习任务中的实用性，同时在这个练习中省略特征存储表。
- en: 'Now we simply need to hit **start AutoML**:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只需要点击**开始 AutoML**：
- en: 'Our AutoML experiment is now executing and is the current state visible in
    the UI. As AutoML progresses, it produces the following three artifacts:'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的 AutoML 实验现在正在执行，并且当前状态在用户界面中可见。随着 AutoML 的进展，它会生成以下三个产物：
- en: It generates a detailed data exploration notebook with source code to outline
    any skews or concerns, such as missing data or zeros. It uses the `pandas.profiling`
    package automatically to do this. You can view this notebook by clicking **View
    data** **exploration notebook**.
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它生成一个详细的数据探索笔记本，包含源代码，旨在概述任何偏差或问题，例如缺失数据或零值。它会自动使用`pandas.profiling`包来完成此操作。你可以通过点击**查看数据**
    **探索笔记本**来查看此笔记本。
- en: '![Figure 5.10 – How to access the auto-generated exploratory data analysis
    notebook](img/B17875_05_010.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.10 – 如何访问自动生成的数据探索分析笔记本](img/B17875_05_010.jpg)'
- en: Figure 5.10 – How to access the auto-generated exploratory data analysis notebook
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – 如何访问自动生成的数据探索分析笔记本
- en: 'The data exploration notebook also displays the correlation between the different
    features:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 数据探索笔记本还显示了不同特征之间的相关性：
- en: '![ Figure 5.11 – Correlation graphs generated by the exploratory data analysis
    notebook](img/B17875_05_011.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.11 – 由数据探索分析笔记本生成的相关性图](img/B17875_05_011.jpg)'
- en: Figure 5.11 – Correlation graphs generated by the exploratory data analysis
    notebook
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 – 由数据探索分析笔记本生成的相关性图
- en: You can see the experiment trials containing source code for every run being
    performed on our dataset. The source code is listed under your workspace under
    your user directory in a folder called `databricks_automl`.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以看到实验试验，里面包含了每次在我们的数据集上运行的源代码。源代码列在你的工作区下的用户目录中的一个名为`databricks_automl`的文件夹中。
- en: '![Figure 5.12 – The location of various notebooks with code relating to each
    trial](img/B17875_05_12.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.12 – 各种笔记本的位置，包含与每次试验相关的代码](img/B17875_05_12.jpg)'
- en: Figure 5.12 – The location of various notebooks with code relating to each trial
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 – 各种笔记本的位置，包含与每次试验相关的代码
- en: The notebook with the best model is also generated from AutoML after all the
    trials have finished execution. This notebook walks you through all the steps
    performed to feature engineer and train the ML model. The trial is logged automatically
    in the tracking server. The notebook also contains code for feature transformation.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳模型的笔记本也会在所有试验执行完成后由 AutoML 自动生成。这个笔记本会引导你完成所有特征工程和训练 ML 模型的步骤。试验会在追踪服务器中自动记录。笔记本还包含特征转换的代码。
- en: '![Figure 5.13 – The location of the notebook that logs the best model identified
    by AutoMl](img/B17875_05_13.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.13 – 记录由 AutoMl 识别的最佳模型的笔记本位置](img/B17875_05_13.jpg)'
- en: Figure 5.13 – The location of the notebook that logs the best model identified
    by AutoMl
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13 – 记录由 AutoMl 识别的最佳模型的笔记本位置
- en: It also utilizes SHAP ([https://pypi.org/project/shap/](https://pypi.org/project/shap/))
    to log feature importance.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 它还利用SHAP（[https://pypi.org/project/shap/](https://pypi.org/project/shap/)）记录特征重要性。
- en: '![Figure 5.14 – A sample SHAP value graph auto-generated as part of the best
    model notebook](img/B17875_05_14.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图5.14 – 一个示例的SHAP值图，作为最佳模型笔记本的一部分自动生成](img/B17875_05_14.jpg)'
- en: Figure 5.14 – A sample SHAP value graph auto-generated as part of the best model
    notebook
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14 – 一个示例的SHAP值图，作为最佳模型笔记本的一部分自动生成
- en: This notebook also explains how you can finally utilize the trained model using
    the various deployment options, which we will discuss later in [*Chapter 6*](B17875_06.xhtml#_idTextAnchor100),
    *Model Versioning* *and Webhooks*.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本笔记本还解释了如何最终利用已训练的模型，通过各种部署选项，我们将在稍后的[*第6章*](B17875_06.xhtml#_idTextAnchor100)，*模型版本控制*
    *和Webhook*中进行讨论。
- en: You can compare the various trials through the UI.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过UI比较不同的实验。
- en: You can also utilize the Python API to kick off AutoML for classification, forecasting,
    or regression. Using the Python API, you can also retrieve the best model programmatically
    from the AutoML experiment and use it for inference.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你也可以利用Python API启动AutoML进行分类、预测或回归。通过Python API，你还可以以编程方式从AutoML实验中提取最佳模型并用于推理。
- en: 'This is an example code for kicking off classification:'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是一个启动分类任务的示例代码：
- en: '[PRE1]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can read more about the various parameters at [https://docs.databricks.com/applications/machine-learning/automl.html#classification-and-regression](https://docs.databricks.com/applications/machine-learning/automl.html#classification-and-regression).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://docs.databricks.com/applications/machine-learning/automl.html#classification-and-regression](https://docs.databricks.com/applications/machine-learning/automl.html#classification-and-regression)查看更多关于各种参数的信息。
- en: Summary
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered the importance of AutoML and how it can help data
    scientists get started and become productive with the problem at hand. We then
    covered the Databricks AutoML glassbox approach, which makes it easy to interpret
    model results and automatically capture lineage. We also learned how Databricks
    AutoML is integrated with the MLflow tracking server within the Databricks workspace.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了AutoML的重要性，以及它如何帮助数据科学家快速上手并高效解决手头的问题。然后我们介绍了Databricks AutoML的玻璃盒方法，这使得模型结果更易于解释，并能够自动捕获血缘关系。我们还学习了Databricks
    AutoML如何与Databricks工作区中的MLflow追踪服务器集成。
- en: In the next chapters, we will go over managing your ML model’s life cycle using
    the MLflow model registry and Webhooks in more detail.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将更详细地介绍如何使用MLflow模型注册表和Webhooks管理机器学习模型的生命周期。
- en: Further reading
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'Here are some other useful links:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些其他有用的链接：
- en: 'Databricks, *What is* *AutoML?*: ([https://docs.databricks.com/applications/machine-learning/automl.html#databricks-automl](https://docs.databricks.com/applications/machine-learning/automl.html#databricks-automl))'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Databricks，*什么是* *AutoML?*：([https://docs.databricks.com/applications/machine-learning/automl.html#databricks-automl](https://docs.databricks.com/applications/machine-learning/automl.html#databricks-automl))
- en: 'Databricks, *Import* *data*: ([https://docs.databricks.com/data/data.html#import-data-1](https://docs.databricks.com/data/data.html#import-data-1))'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Databricks，*导入* *数据*：([https://docs.databricks.com/data/data.html#import-data-1](https://docs.databricks.com/data/data.html#import-data-1))
- en: 'Part 3: ML Governance and Deployment'
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分：机器学习治理与部署
- en: You will learn how to utilize the MLFlow model registry to manage model versioning
    and transition to production from various stages and use webhooks to set up alerts
    and monitoring.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 你将学习如何利用MLFlow模型注册表来管理模型版本，并从不同阶段过渡到生产环境，同时使用webhook设置警报和监控。
- en: 'This section has the following chapters:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包含以下章节：
- en: '[*Chapter 6*](B17875_06.xhtml#_idTextAnchor100), *Model Versioning and Webhooks*'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B17875_06.xhtml#_idTextAnchor100)，*模型版本控制与Webhooks*'
- en: '[*Chapter 7*](B17875_07.xhtml#_idTextAnchor108), *Model Deployment Approaches*'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B17875_07.xhtml#_idTextAnchor108)，*模型部署方法*'
- en: '[*Chapter 8*](B17875_08.xhtml#_idTextAnchor122), *Automating ML Workflows Using
    Databricks Jobs*'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B17875_08.xhtml#_idTextAnchor122)，*使用Databricks Jobs自动化ML工作流*'
- en: '[*Chapter 9*](B17875_09.xhtml#_idTextAnchor129), *Model Drift Detection and
    Retraining*'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B17875_09.xhtml#_idTextAnchor129)，*模型漂移检测与再训练*'
- en: '[*Chapter 10*](B17875_10.xhtml#_idTextAnchor142), *Using CI/CD to Automate
    Model Retraining and Redeployment*'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B17875_10.xhtml#_idTextAnchor142)，*使用CI/CD自动化模型再训练与重新部署*'
