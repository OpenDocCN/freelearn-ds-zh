- en: '16'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '16'
- en: Derivatives and Gradients
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼æ•°ä¸æ¢¯åº¦
- en: Now that we understand why multivariate functions and high-dimensional spaces
    are more complex than the single-variable case we studied earlier, itâ€™s time to
    see how to do things in the general case.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬ç†è§£äº†ä¸ºä»€ä¹ˆå¤šå˜é‡å‡½æ•°å’Œé«˜ç»´ç©ºé—´æ¯”ä¹‹å‰å­¦ä¹ çš„å•å˜é‡æƒ…å†µæ›´å¤æ‚ï¼Œæ˜¯æ—¶å€™çœ‹çœ‹å¦‚ä½•åœ¨ä¸€èˆ¬æƒ…å†µä¸‹å¤„ç†è¿™äº›é—®é¢˜äº†ã€‚
- en: To recap quickly, our goal in machine learning is to optimize functions with
    millions of variables. For instance, think about a neural network N(x,w) trained
    for binary classification, where
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¿«é€Ÿå›é¡¾ä¸€ä¸‹ï¼Œæˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ ä¸­çš„ç›®æ ‡æ˜¯ä¼˜åŒ–æ‹¥æœ‰æ•°ç™¾ä¸‡ä¸ªå˜é‡çš„å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘ä¸€ä¸ªä¸ºäºŒå…ƒåˆ†ç±»è®­ç»ƒçš„ç¥ç»ç½‘ç»œN(x,w)ï¼Œå…¶ä¸­
- en: x âˆˆâ„^n is the input data,
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x âˆˆâ„^næ˜¯è¾“å…¥æ•°æ®ï¼Œ
- en: w âˆˆâ„^m is the vector compressing all of the weight parameters,
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: w âˆˆâ„^mæ˜¯å‹ç¼©æ‰€æœ‰æƒé‡å‚æ•°çš„å‘é‡ï¼Œ
- en: and N(x,w) âˆˆ [0,1] is the prediction, representing the probability of belonging
    to the positive class.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è€ŒN(x,w) âˆˆ [0,1]æ˜¯é¢„æµ‹å€¼ï¼Œè¡¨ç¤ºå±äºæ­£ç±»çš„æ¦‚ç‡ã€‚
- en: In the case of, say, binary cross-entropy loss, we have the loss function
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¯”å¦‚äºŒå…ƒäº¤å‰ç†µæŸå¤±çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æœ‰æŸå¤±å‡½æ•°
- en: '![ d L(w ) = âˆ’ âˆ‘ y log N (x ,w ), i i k=1 ](img/file1457.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![ d L(w ) = âˆ’ âˆ‘ y log N (x ,w ), i i k=1 ](img/file1457.png)'
- en: where x[i] is the i-th data point with ground truth y[i] âˆˆ{0,1}. See, I told
    you that we have to write much more in multivariable calculus. (Weâ€™ll talk about
    binary cross-entropy loss in ChapterÂ [20](ch032.xhtml#the-expected-value).)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­x[i]æ˜¯ç¬¬iä¸ªæ•°æ®ç‚¹ï¼ŒçœŸå®å€¼y[i] âˆˆ{0,1}ã€‚çœ‹ï¼Œæˆ‘å‘Šè¯‰è¿‡ä½ ï¼Œæˆ‘ä»¬åœ¨å¤šå˜é‡å¾®ç§¯åˆ†ä¸­è¦å†™æ›´å¤šå†…å®¹ã€‚ï¼ˆæˆ‘ä»¬å°†åœ¨ç¬¬[20](ch032.xhtml#the-expected-value)ç« è®¨è®ºäºŒå…ƒäº¤å‰ç†µæŸå¤±ã€‚ï¼‰
- en: 'Training the neural network is the same as finding a global minimum of L(w),
    if it exists. We have already seen how we can do optimization in a single variable:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒç¥ç»ç½‘ç»œä¸å¯»æ‰¾L(w)çš„å…¨å±€æœ€å°å€¼æ˜¯ä¸€æ ·çš„ï¼Œå¦‚æœå®ƒå­˜åœ¨çš„è¯ã€‚æˆ‘ä»¬å·²ç»çœ‹åˆ°å¦‚ä½•åœ¨å•å˜é‡æƒ…å†µä¸‹è¿›è¡Œä¼˜åŒ–ï¼š
- en: figure out the direction of increase by calculating the derivative,
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡è®¡ç®—å¯¼æ•°æ¥æ‰¾å‡ºå¢åŠ çš„æ–¹å‘ï¼Œ
- en: take a small step,
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡‡å–ä¸€ä¸ªå°æ­¥éª¤ï¼Œ
- en: then iterate.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç„¶åè¿›è¡Œè¿­ä»£ã€‚
- en: 'For this to work in multiple variables, we need to generalize the concept of
    the derivative. We can quickly discover the issue: since division with a vector
    is not defined, the difference quotient'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿è¿™åœ¨å¤šå˜é‡æƒ…å†µä¸‹æœ‰æ•ˆï¼Œæˆ‘ä»¬éœ€è¦æ¨å¹¿å¯¼æ•°çš„æ¦‚å¿µã€‚æˆ‘ä»¬å¯ä»¥è¿…é€Ÿå‘ç°é—®é¢˜ï¼šå› ä¸ºå‘é‡çš„é™¤æ³•æ²¡æœ‰å®šä¹‰ï¼Œæ‰€ä»¥å·®å•†
- en: '![f(x)âˆ’-f-(y-) xâˆ’ y ](img/file1458.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![f(x)âˆ’-f-(y-) xâˆ’ y ](img/file1458.png)'
- en: 'makes no sense when f : â„^n â†’â„ is a function of n variables and x,y âˆˆâ„^n are
    n-dimensional vectors.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 'å½“f : â„^n â†’â„æ˜¯ä¸€ä¸ªnå˜é‡çš„å‡½æ•°ä¸”x,y âˆˆâ„^næ˜¯nç»´å‘é‡æ—¶ï¼Œè¿™ä¸ªå…¬å¼æ²¡æœ‰æ„ä¹‰ã€‚'
- en: How can we make sense of it, then? This is what weâ€™ll learn in the following
    chapter.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆæˆ‘ä»¬è¯¥å¦‚ä½•ç†è§£å®ƒå‘¢ï¼Ÿè¿™å°±æ˜¯æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ç« å­¦ä¹ çš„å†…å®¹ã€‚
- en: 16.1 Partial and total derivatives
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.1 åå¯¼æ•°ä¸å…¨å¯¼æ•°
- en: 'Letâ€™s take a look at multivariable functions more closely! For the sake of
    simplicity, let f : â„Â² â†’â„ be our function of two variables. To emphasize the dependence
    on the individual variables, we often write'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®©æˆ‘ä»¬æ›´ä»”ç»†åœ°çœ‹çœ‹å¤šå˜é‡å‡½æ•°ï¼ä¸ºäº†ç®€åŒ–èµ·è§ï¼Œè®¾f : â„Â² â†’â„ä¸ºæˆ‘ä»¬çš„äºŒå…ƒå‡½æ•°ã€‚ä¸ºäº†å¼ºè°ƒå¯¹å•ä¸ªå˜é‡çš„ä¾èµ–ï¼Œæˆ‘ä»¬é€šå¸¸å†™æˆ'
- en: '![f(x1,x2), x1,x2 âˆˆ â„. ](img/file1459.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![f(x1,x2), x1,x2 âˆˆ â„. ](img/file1459.png)'
- en: 'Hereâ€™s the trick: by fixing one of the variables, we obtain the two single-variable
    functions! That is, if x[1] âˆˆâ„Â² is fixed, we have xâ†’f(x[1],x), and if x[2] âˆˆâ„Â²
    is fixed, we have xâ†’f(x,x[2]), both of which are well-defined univariate functions.
    Think about this as slicing the function graph with a plane parallel to the xâˆ’z
    or the y âˆ’z axes, as illustrated by FigureÂ [16.1](#). The part cut out by the
    plane is a single-variable function.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸ªæŠ€å·§ï¼šé€šè¿‡å›ºå®šå…¶ä¸­ä¸€ä¸ªå˜é‡ï¼Œæˆ‘ä»¬å°±èƒ½å¾—åˆ°ä¸¤ä¸ªå•å˜é‡å‡½æ•°ï¼ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœå›ºå®šx[1] âˆˆâ„Â²ï¼Œæˆ‘ä»¬å°±å¾—åˆ°xâ†’f(x[1],x)ï¼Œå¦‚æœå›ºå®šx[2]
    âˆˆâ„Â²ï¼Œæˆ‘ä»¬å°±å¾—åˆ°xâ†’f(x,x[2])ï¼Œè¿™ä¸¤è€…éƒ½æ˜¯å®šä¹‰è‰¯å¥½çš„å•å˜é‡å‡½æ•°ã€‚æŠŠè¿™ä¸ªçœ‹ä½œæ˜¯é€šè¿‡å¹³è¡Œäºxâˆ’zæˆ–yâˆ’zè½´çš„å¹³é¢æ¥åˆ‡å‰²å‡½æ•°å›¾åƒï¼Œå°±åƒå›¾16.1æ‰€ç¤ºã€‚è¢«å¹³é¢åˆ‡å‰²å‡ºæ¥çš„éƒ¨åˆ†æ˜¯ä¸€ä¸ªå•å˜é‡å‡½æ•°ã€‚
- en: '![PIC](img/file1462.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1462.png)'
- en: 'FigureÂ 16.1: Slicing the surface with the x âˆ’z plane'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾16.1ï¼šç”¨xâˆ’zå¹³é¢åˆ‡å‰²æ›²é¢
- en: 'We can define the derivative of these functions by the limit of difference
    quotients. These are called the partial derivatives:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡å·®å•†çš„æé™æ¥å®šä¹‰è¿™äº›å‡½æ•°çš„å¯¼æ•°ã€‚è¿™äº›è¢«ç§°ä¸ºåå¯¼æ•°ï¼š
- en: '![âˆ‚f-- f(x,x2)-âˆ’-f(x1,x2) âˆ‚x1 (x1,x2 ) = xliâ†’mx1 x âˆ’ x1 , âˆ‚f f(x ,x) âˆ’ f(x
    ,x ) ----(x1,x2 ) = lim ---1---------1--2-. âˆ‚x2 xâ†’x2 x âˆ’ x2 ](img/file1463.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚f-- f(x,x2)-âˆ’-f(x1,x2) âˆ‚x1 (x1,x2 ) = xliâ†’mx1 x âˆ’ x1 , âˆ‚f f(x ,x) âˆ’ f(x
    ,x ) ----(x1,x2 ) = lim ---1---------1--2-. âˆ‚x2 xâ†’x2 x âˆ’ x2 ](img/file1463.png)'
- en: (Keep in mind that x[1] signifies the variable in ![âˆ‚f- âˆ‚x1](img/file1464.png),
    but an actual scalar value in the argument of ![âˆ‚f- âˆ‚x1](img/file1465.png)(x[1],x[2]).
    This can be quite confusing, but youâ€™ll soon learn to make sense of it.)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆè¯·è®°ä½ï¼Œx[1]è¡¨ç¤º![âˆ‚f- âˆ‚x1](img/file1464.png)ä¸­çš„å˜é‡ï¼Œä½†åœ¨![âˆ‚f- âˆ‚x1](img/file1465.png)(x[1],x[2])çš„å‚æ•°ä¸­æ˜¯ä¸€ä¸ªå®é™…çš„æ ‡é‡å€¼ã€‚è¿™å¯èƒ½ä¼šè®©äººæ„Ÿåˆ°å›°æƒ‘ï¼Œä½†ä½ å¾ˆå¿«å°±èƒ½ç†è§£å®ƒã€‚ï¼‰
- en: 'The definition is similar for general multivariable functions; we just have
    to write much more. There, the partial derivative of f : â„^n â†’â„ at the point x
    = (x[1],â€¦,x[n]) with respect to the i-th variable is defined by'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¯¹äºä¸€èˆ¬çš„å¤šå˜é‡å‡½æ•°ï¼Œå®šä¹‰æ˜¯ç±»ä¼¼çš„ï¼›æˆ‘ä»¬åªéœ€è¦å†™å¾—æ›´å¤šã€‚åœ¨é‚£é‡Œï¼Œf : â„^n â†’â„ åœ¨ç‚¹x = (x[1],â€¦,x[n])å¤„å…³äºç¬¬iä¸ªå˜é‡çš„åå¯¼æ•°é€šè¿‡ä»¥ä¸‹æ–¹å¼å®šä¹‰ï¼š'
- en: '![L(U,V ) = {f : U â†’ V | f is linear}](img/equation_(21).png)(16.1)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U â†’ V | f is linear}](img/equation_(21).png)(16.1)'
- en: 'One of the biggest challenges in multivariable calculus is to manage the ever-growing
    notational complexity. Just take a look at the difference quotient above:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤šå˜é‡å¾®ç§¯åˆ†ä¸­ï¼Œæœ€å¤§çš„æŒ‘æˆ˜ä¹‹ä¸€å°±æ˜¯ç®¡ç†ä¸æ–­å¢åŠ çš„ç¬¦å·å¤æ‚æ€§ã€‚åªè¦çœ‹çœ‹ä¸Šé¢çš„å·®å•†ï¼š
- en: '![f(x1,...,x,...,xn)-âˆ’-f(x1,...,xi,...,xn). x âˆ’ xi ](img/file1468.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![f(x1,...,x,...,xn)-âˆ’-f(x1,...,xi,...,xn). x âˆ’ xi ](img/file1468.png)'
- en: This is not the prettiest to look at, and this kind of notational complexity
    can pile up fast. Fortunately, linear algebra comes to the rescue! Not only can
    we compact the variables into the vector x = (x[1],â€¦,x[n]), we can use the standard
    basis
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸æ˜¯æœ€ç¾è§‚çš„è¡¨ç¤ºæ–¹å¼ï¼Œå¹¶ä¸”è¿™ç§ç¬¦å·å¤æ‚æ€§å¯èƒ½ä¼šè¿…é€Ÿå †ç§¯ã€‚å¹¸è¿çš„æ˜¯ï¼Œçº¿æ€§ä»£æ•°æ¥è§£æ•‘æˆ‘ä»¬ï¼æˆ‘ä»¬ä¸ä»…å¯ä»¥å°†å˜é‡å‹ç¼©æˆå‘é‡x = (x[1],â€¦,x[n])ï¼Œè¿˜å¯ä»¥ä½¿ç”¨æ ‡å‡†åŸº
- en: '![ei = (0,...,0, 1 ,0,...,0) â—Ÿâ—â—œâ— i- th component ](img/file1469.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![ei = (0,...,0, 1 ,0,...,0) â—Ÿâ—â—œâ— i- th component ](img/file1469.png)'
- en: to write the difference quotients as
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å·®å•†å†™æˆ
- en: '![f(x+-hei)-âˆ’-f(x), h âˆˆ â„. h ](img/file1470.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![f(x+-hei)-âˆ’-f(x), h âˆˆ â„. h ](img/file1470.png)'
- en: Thus, ([19.1](#)) can be compacted. With this newly found form, we are ready
    to make a concise and formal definition for partial derivatives.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œ([19.1](#)) å¯ä»¥ç®€åŒ–ã€‚é€šè¿‡è¿™ç§æ–°å‘ç°çš„å½¢å¼ï¼Œæˆ‘ä»¬å‡†å¤‡å¥½ä¸ºåå¯¼æ•°åšå‡ºç®€æ´å’Œæ­£å¼çš„å®šä¹‰ã€‚
- en: Definition 66\. (Partial derivatives)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 66\.ï¼ˆåå¯¼æ•°ï¼‰
- en: 'Let f : â„^n â†’â„ be a function of n variables. The partial derivative of f at
    the point x = (x[1],â€¦,x[n]) with respect to the i-th variable is defined by'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾f : â„^n â†’â„ æ˜¯ä¸€ä¸ªnå˜é‡çš„å‡½æ•°ã€‚fåœ¨ç‚¹x = (x[1],â€¦,x[n])å¤„å…³äºç¬¬iä¸ªå˜é‡çš„åå¯¼æ•°é€šè¿‡ä»¥ä¸‹æ–¹å¼å®šä¹‰ï¼š'
- en: '![-âˆ‚f-(x ) = lim f(x-+-hei)âˆ’-f-(x-). âˆ‚xi hâ†’0 h ](img/file1471.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![-âˆ‚f-(x ) = lim f(x-+-hei)âˆ’-f-(x-). âˆ‚xi hâ†’0 h ](img/file1471.png)'
- en: If the above limit exists, we say that f is partially differentiable with respect
    to the i-th variable x[i].
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸Šè¿°æé™å­˜åœ¨ï¼Œæˆ‘ä»¬ç§°fåœ¨ç¬¬iä¸ªå˜é‡x[i]å¤„æ˜¯éƒ¨åˆ†å¯å¾®çš„ã€‚
- en: The partial derivative is again a vector-scalar function. Because of this, it
    is often written as ![-âˆ‚- âˆ‚xi](img/file1472.png)f, reflecting on the fact that
    the symbol ![âˆ‚-- âˆ‚xi](img/file1473.png) can be thought of as a function that maps
    functions to functions. I know, this is a bit abstract, but youâ€™ll get used to
    it quickly.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åå¯¼æ•°å†æ¬¡æ˜¯ä¸€ä¸ªå‘é‡-æ ‡é‡å‡½æ•°ã€‚å› ä¸ºè¿™ä¸ªåŸå› ï¼Œå®ƒé€šå¸¸è¢«å†™ä½œ ![-âˆ‚- âˆ‚xi](img/file1472.png)fï¼Œåæ˜ å‡ºç¬¦å· ![âˆ‚-- âˆ‚xi](img/file1473.png)
    å¯ä»¥è¢«çœ‹ä½œä¸€ä¸ªå°†å‡½æ•°æ˜ å°„åˆ°å‡½æ•°çš„å‡½æ•°ã€‚æˆ‘çŸ¥é“ï¼Œè¿™æœ‰ç‚¹æŠ½è±¡ï¼Œä½†ä½ å¾ˆå¿«å°±ä¼šä¹ æƒ¯çš„ã€‚
- en: As usual, there are several alternative notations for the partial derivatives.
    Among others, the symbols
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å¾€å¸¸ä¸€æ ·ï¼Œåå¯¼æ•°æœ‰å‡ ç§æ›¿ä»£ç¬¦å·ã€‚åŒ…æ‹¬ç¬¦å·
- en: f[x[i]](x),
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: f[x[i]](x),
- en: D[i]f(x),
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: D[i]f(x),
- en: âˆ‚[i]f(x)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: âˆ‚[i]f(x)
- en: denote the i-th partial derivative of f at x. For simplicity, weâ€™ll use the
    old-school ![-âˆ‚f âˆ‚xi](img/file1474.png)(x).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ç¤ºfåœ¨xå¤„çš„ç¬¬iä¸ªåå¯¼æ•°ã€‚ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è€å¼ç¬¦å· ![-âˆ‚f âˆ‚xi](img/file1474.png)(x)ã€‚
- en: Itâ€™s best to start with a few examples to illustrate the concept of partial
    derivatives.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å¥½ä»å‡ ä¸ªä¾‹å­å¼€å§‹ï¼Œæ¥è¯´æ˜åå¯¼æ•°çš„æ¦‚å¿µã€‚
- en: Example 1\. Let
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 1\. è®©
- en: '![f(x1,x2) = x21 + x22\. ](img/file1475.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![f(x1,x2) = x21 + x22\. ](img/file1475.png)'
- en: To calculate, say, âˆ‚fâˆ•âˆ‚x[1], we fix the second variable and treat x[2] as a
    constant. Formally, we obtain the single-variable function
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è®¡ç®—ï¼Œä¾‹å¦‚ï¼Œâˆ‚fâˆ•âˆ‚x[1]ï¼Œæˆ‘ä»¬å›ºå®šç¬¬äºŒä¸ªå˜é‡ï¼Œå¹¶å°†x[2]è§†ä¸ºå¸¸æ•°ã€‚å½¢å¼ä¸Šï¼Œæˆ‘ä»¬å¾—åˆ°å•å˜é‡å‡½æ•°
- en: '![ 1 2 2 f (x) := x + x2, x2 âˆˆ â„, ](img/file1476.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 2 2 f (x) := x + x2, x2 âˆˆ â„, ](img/file1476.png)'
- en: 'whose derivative gives the first partial derivative:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶å¯¼æ•°ç»™å‡ºäº†ç¬¬ä¸€ä¸ªåå¯¼æ•°ï¼š
- en: '![ 1 âˆ‚f-(x ,x ) = df-(x ) = 2x . âˆ‚x1 1 2 dx 1 1 ](img/file1477.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 âˆ‚f-(x ,x ) = df-(x ) = 2x . âˆ‚x1 1 2 dx 1 1 ](img/file1477.png)'
- en: Similarly, we get that
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![âˆ‚f âˆ‚x-(x1,x2) = 2x2\. 2 ](img/file1478.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚f âˆ‚x-(x1,x2) = 2x2\. 2 ](img/file1478.png)'
- en: Once you are comfortable with the mental gymnastics of fixing variables, youâ€™ll
    be able to perform partial differentiation without writing out all the intermediate
    steps.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ä½ ä¹ æƒ¯äº†å›ºå®šå˜é‡çš„æ€ç»´æ–¹å¼ï¼Œå°±å¯ä»¥åœ¨ä¸å†™å‡ºæ‰€æœ‰ä¸­é—´æ­¥éª¤çš„æƒ…å†µä¸‹æ‰§è¡Œåå¾®åˆ†ã€‚
- en: Example 2\. Letâ€™s see a more complicated example. Define
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 2\. è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªæ›´å¤æ‚çš„ä¾‹å­ã€‚å®šä¹‰
- en: '![f(x1,x2) = sin(x21 + x2). ](img/file1479.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![f(x1,x2) = sin(x21 + x2). ](img/file1479.png)'
- en: 'By fixing x[2], we obtain a composite function. Thus the chain rule is used
    to calculate the first partial derivative:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å›ºå®šx[2]ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªå¤åˆå‡½æ•°ã€‚å› æ­¤ï¼Œé“¾å¼æ³•åˆ™ç”¨äºè®¡ç®—ç¬¬ä¸€ä¸ªåå¯¼æ•°ï¼š
- en: '![ âˆ‚f ----(x1,x2 ) = 2x1 cos(x21 + x2). âˆ‚x1 ](img/file1480.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‚f ----(x1,x2 ) = 2x1 cos(x21 + x2). âˆ‚x1 ](img/file1480.png)'
- en: Similarly, we obtain that
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![âˆ‚f-- 2 âˆ‚x2(x1,x2) = cos(x1 + x2). ](img/file1481.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚f-- 2 âˆ‚x2(x1,x2) = cos(x1 + x2). ](img/file1481.png)'
- en: (I highly advise you to carry out the above calculations step by step as an
    exercise, even if you understand all the intermediate steps.)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆæˆ‘å¼ºçƒˆå»ºè®®æ‚¨é€æ­¥è¿›è¡Œä¸Šè¿°è®¡ç®—ï¼Œå³ä½¿æ‚¨ç†è§£æ‰€æœ‰ä¸­é—´æ­¥éª¤ï¼Œä¹Ÿè¦ä½œä¸ºç»ƒä¹ å®Œæˆã€‚ï¼‰
- en: Example 3\. Finally, letâ€™s see a function that is partially differentiable in
    one variable but not in the other. Define the function
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 3\. æœ€åï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸ªåœ¨ä¸€ä¸ªå˜é‡ä¸Šéƒ¨åˆ†å¯å¾®ä½†åœ¨å¦ä¸€ä¸ªå˜é‡ä¸Šä¸å¯å¾®çš„å‡½æ•°ã€‚å®šä¹‰å‡½æ•°
- en: '![ ( |{ âˆ’ 1 if x2 <0, f(x1,x2) = |( 1 otherwise. ](img/file1482.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![ ( |{ âˆ’ 1 if x2 <0, f(x1,x2) = |( 1 otherwise. ](img/file1482.png)'
- en: As f(x[1],x[2]) does not depend on x[1], we can see that by fixing x[2], the
    resulting function is constant. Thus,
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº f(x[1],x[2]) ä¸ä¾èµ–äº x[1]ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œé€šè¿‡å›ºå®š x[2]ï¼Œç»“æœå‡½æ•°æ˜¯å¸¸æ•°ã€‚å› æ­¤ï¼Œ
- en: '![-âˆ‚f-(x ,x ) = 0 âˆ‚x1 1 2 ](img/file1483.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![-âˆ‚f-(x ,x ) = 0 âˆ‚x1 1 2 ](img/file1483.png)'
- en: holds everywhere. However, in x[2], there is a discontinuity at 0; thus, ![âˆ‚f-
    âˆ‚x2](img/file1484.png) is undefined there.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰€æœ‰åœ°æ–¹æˆç«‹ã€‚ç„¶è€Œï¼Œåœ¨ x[2] ä¸­ï¼Œ0 å¤„å­˜åœ¨ä¸è¿ç»­æ€§ï¼›å› æ­¤ï¼Œ![-âˆ‚f âˆ‚x2](img/file1484.png) åœ¨è¯¥å¤„æœªå®šä¹‰ã€‚
- en: 16.1.1 The gradient
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.1.1 æ¢¯åº¦
- en: If a function is partially differentiable in every variable, we can compact
    the derivatives together in a single vector to form the gradient.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸€ä¸ªå‡½æ•°åœ¨æ¯ä¸ªå˜é‡ä¸Šéƒ½éƒ¨åˆ†å¯å¾®ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰çš„å¯¼æ•°åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„å‘é‡æ¥å½¢æˆæ¢¯åº¦ã€‚
- en: Definition 67\. (The gradient)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 67\. ï¼ˆæ¢¯åº¦ï¼‰
- en: 'Let f : â„^n â†’ â„ be a function that is partially differentiable in all of its
    variables. Then, its gradient is defined by the (column) vector'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ f : â„^n â†’ â„ æ˜¯ä¸€ä¸ªåœ¨å…¶æ‰€æœ‰å˜é‡ä¸Šéƒ¨åˆ†å¯å¾®çš„å‡½æ•°ã€‚é‚£ä¹ˆï¼Œå…¶æ¢¯åº¦ç”±ï¼ˆåˆ—ï¼‰å‘é‡å®šä¹‰ä¸º'
- en: '![ âŒŠ âŒ‹ âˆ‚âˆ‚x1f (x ) ||-âˆ‚-f (x )|| âˆ‡f(x ) := ||âˆ‚x2 . || âˆˆ â„n Ã—1\. |âŒˆ .. |âŒ‰ -âˆ‚-
    âˆ‚xnf (x ) ](img/file1485.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ âˆ‚âˆ‚x1f (x ) ||-âˆ‚-f (x )|| âˆ‡f(x ) := ||âˆ‚x2 . || âˆˆ â„n Ã—1\. |âŒˆ .. |âŒ‰ -âˆ‚-
    âˆ‚xnf (x ) ](img/file1485.png)'
- en: A few remarks are in order. First, the symbol âˆ‡ is called nabla, a symbol that
    was conceived to denote gradients.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦åšä¸€äº›è¯´æ˜ã€‚é¦–å…ˆï¼Œç¬¦å· âˆ‡ è¢«ç§°ä¸º nablaï¼Œæ˜¯ä¸€ä¸ªç”¨äºè¡¨ç¤ºæ¢¯åº¦çš„ç¬¦å·ã€‚
- en: Second, the gradient can be thought of as a vector-vector function. To see that,
    consider the already familiar function f(x[1],x[2]) = x[1]Â² + x[2]Â². The gradient
    of f is
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒï¼Œæ¢¯åº¦å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªå‘é‡-å‘é‡å‡½æ•°ã€‚ä¸ºäº†ç†è§£è¿™ä¸€ç‚¹ï¼Œè€ƒè™‘å·²ç»ç†Ÿæ‚‰çš„å‡½æ•° f(x[1],x[2]) = x[1]Â² + x[2]Â²ã€‚f çš„æ¢¯åº¦æ˜¯
- en: '![ âŒŠ âŒ‹ 2x1 âˆ‡f (x1,x2) = âŒˆ âŒ‰ , 2x2 ](img/file1486.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ 2x1 âˆ‡f (x1,x2) = âŒˆ âŒ‰ , 2x2 ](img/file1486.png)'
- en: or
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…
- en: '![âˆ‡f (x ) = 2x ](img/file1487.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‡f (x ) = 2x ](img/file1487.png)'
- en: in vectorized form. We can visualize this by drawing the vector âˆ‡f(x[1],x[2])
    at each point (x[1],x[2]) âˆˆâ„Â².
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥å‘é‡åŒ–å½¢å¼è¡¨ç¤ºã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨æ¯ä¸ªç‚¹ (x[1],x[2]) âˆˆ â„Â² ç”»å‡ºå‘é‡ âˆ‡f(x[1],x[2]) æ¥å¯è§†åŒ–è¿™ä¸€ç‚¹ã€‚
- en: '![PIC](img/file1488.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1488.png)'
- en: 'FigureÂ 16.2: The vector field given by the gradient of x[1]Â² + x[2]Â²'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 16.2ï¼šç”± x[1]Â² + x[2]Â² çš„æ¢¯åº¦ç»™å‡ºçš„å‘é‡åœº
- en: 'Thus, you can think about âˆ‡f as a vector-vector function âˆ‡f : â„^n â†’â„^n. The
    gradient at a given point x is obtained by evaluating this function, yielding
    (âˆ‡f)(x).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 'å› æ­¤ï¼Œæ‚¨å¯ä»¥å°† âˆ‡f çœ‹ä½œæ˜¯ä¸€ä¸ªå‘é‡-å‘é‡å‡½æ•° âˆ‡f : â„^n â†’ â„^nã€‚ç»™å®šç‚¹ x å¤„çš„æ¢¯åº¦æ˜¯é€šè¿‡è¯„ä¼°è¯¥å‡½æ•°å¾—åˆ°çš„ï¼Œå¾—åˆ° (âˆ‡f)(x)ã€‚'
- en: For clarity, the parentheses are omitted, arriving at the all familiar notation
    âˆ‡f(x).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¸…æ™°èµ·è§ï¼Œçœç•¥äº†æ‹¬å·ï¼Œå¾—åˆ°äº†å¤§å®¶ç†Ÿæ‚‰çš„ç¬¦å· âˆ‡f(x)ã€‚
- en: 16.1.2 Higher order partial derivatives
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.1.2 é«˜é˜¶åå¯¼æ•°
- en: 'The partial derivatives of a vector-scalar function f : â„^n â†’â„ are vector-scalar
    functions themselves. Thus, we can perform partial differentiation one more time!'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 'å‘é‡-æ ‡é‡å‡½æ•° f : â„^n â†’ â„ çš„åå¯¼æ•°æœ¬èº«ä¹Ÿæ˜¯å‘é‡-æ ‡é‡å‡½æ•°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å†è¿›è¡Œä¸€æ¬¡åå¾®åˆ†ï¼'
- en: If they exist, the second order partial derivatives are defined by
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå®ƒä»¬å­˜åœ¨ï¼ŒäºŒé˜¶åå¯¼æ•°ç”±ä»¥ä¸‹å…¬å¼å®šä¹‰ï¼š
- en: '![L(U,V ) = {f : U â†’ V | f is linear}](img/equation_(22).png)(16.2)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U â†’ V | f æ˜¯çº¿æ€§å‡½æ•°}](img/equation_(22).png)(16.2)'
- en: where a âˆˆâ„^n is an arbitrary vector. (When the second partial differentiation
    takes place with respect to the same variable, ([16.2](ch026.xhtml#higher-order-partial-derivatives))
    is abbreviated by ![âˆ‚2f âˆ‚x2i](img/file1494.png)(a).)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ a âˆˆ â„^n æ˜¯ä»»æ„å‘é‡ã€‚ï¼ˆå½“ç¬¬äºŒæ¬¡åå¯¼æ•°æ˜¯å…³äºåŒä¸€å˜é‡çš„åå¯¼æ—¶ï¼Œ([16.2](ch026.xhtml#higher-order-partial-derivatives))
    ç”± ![âˆ‚2f âˆ‚x2i](img/file1494.png)(a) ç®€å†™è¡¨ç¤ºã€‚ï¼‰
- en: 'The definition begs the question: is the order of differentiation interchangeable?
    That is, does'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå®šä¹‰å¼•å‡ºäº†ä¸€ä¸ªé—®é¢˜ï¼šæ±‚å¯¼çš„é¡ºåºæ˜¯å¦å¯ä»¥äº’æ¢ï¼Ÿä¹Ÿå°±æ˜¯è¯´ï¼Œæ˜¯å¦æœ‰
- en: '![ 2 2 --âˆ‚-f--(a) = -âˆ‚-f--(a) âˆ‚xiâˆ‚xj âˆ‚xjâˆ‚xi ](img/file1495.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 2 --âˆ‚-f--(a) = -âˆ‚-f--(a) âˆ‚xiâˆ‚xj âˆ‚xjâˆ‚xi ](img/file1495.png)'
- en: 'hold? The answer is quite surprising: the order is interchangeable under some
    mild assumptions, but not in the general case. There is a famous theorem about
    it which we wonâ€™t prove, but itâ€™s essential to know.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆç›¸å½“ä»¤äººæƒŠè®¶ï¼šåœ¨ä¸€äº›æ¸©å’Œçš„å‡è®¾ä¸‹ï¼Œæ±‚å¯¼é¡ºåºæ˜¯å¯ä»¥äº’æ¢çš„ï¼Œä½†åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ä¸æ˜¯ã€‚å…³äºè¿™ä¸€ç‚¹æœ‰ä¸€ä¸ªè‘—åçš„å®šç†ï¼Œæˆ‘ä»¬ä¸ä¼šè¯æ˜ï¼Œä½†å®ƒæ˜¯éå¸¸é‡è¦çš„ã€‚
- en: Theorem 98\.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 98\.
- en: 'Let f : â„^n â†’ â„ be an arbitrary vector-scalar function and let a âˆˆ â„^n. If
    there is a small ball B(ğœ€,a) âŠ†â„^n centered at a such that f has continuous second-order
    partial derivatives at all points of B(ğœ€,a), then'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾f : â„^n â†’ â„ä¸ºä»»æ„çš„å‘é‡-æ ‡é‡å‡½æ•°ï¼Œä¸”a âˆˆ â„^nã€‚å¦‚æœå­˜åœ¨ä¸€ä¸ªä»¥aä¸ºä¸­å¿ƒçš„çƒB(ğœ–,a) âŠ† â„^nï¼Œä½¿å¾—fåœ¨B(ğœ–,a)çš„æ‰€æœ‰ç‚¹å¤„å…·æœ‰è¿ç»­çš„äºŒé˜¶åå¯¼æ•°ï¼Œåˆ™'
- en: '![--âˆ‚2f-- -âˆ‚2f--- âˆ‚xi âˆ‚xj(a) = âˆ‚xjâˆ‚xi(a) ](img/file1496.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![--âˆ‚2f-- -âˆ‚2f--- âˆ‚xi âˆ‚xj(a) = âˆ‚xjâˆ‚xi(a)](img/file1496.png)'
- en: holds for all i = 1,â€¦,n.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ‰€æœ‰i = 1,â€¦,næˆç«‹ã€‚
- en: TheoremÂ [98](ch026.xhtml#x1-456002r98) is known as either Schwarzâ€™s theorem,
    Clairautâ€™s theorem, or Youngâ€™s theorem.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç†[98](ch026.xhtml#x1-456002r98)è¢«ç§°ä¸ºæ–½ç“¦èŒ¨å®šç†ã€å…‹è±ç½—å®šç†æˆ–æ¨æ°å®šç†ã€‚
- en: 16.1.3 The total derivative
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.1.3 æ€»å¯¼æ•°
- en: Partial derivatives seem to generalize the notion of differentiability for multivariable
    functions. However, something is missing. Letâ€™s revisit the single-variable case
    for a moment.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: åå¯¼æ•°ä¼¼ä¹å°†å¯å¾®æ€§çš„æ¦‚å¿µæ¨å¹¿åˆ°å¤šå˜é‡å‡½æ•°ã€‚ç„¶è€Œï¼Œä¼¼ä¹è¿˜æœ‰ä»€ä¹ˆç¼ºå¤±ã€‚è®©æˆ‘ä»¬ç¨å¾®å›é¡¾ä¸€ä¸‹å•å˜é‡çš„æƒ…å†µã€‚
- en: 'Recall that according to TheoremÂ [77](ch020.xhtml#x1-199002r77), the differentiability
    of a single-variable function f : â„ â†’â„ at a given point a is equivalent to a local
    approximation of f by the linear function'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›æƒ³ä¸€ä¸‹ï¼Œæ ¹æ®å®šç†[77](ch020.xhtml#x1-199002r77)ï¼Œå•å˜é‡å‡½æ•°f : â„ â†’ â„åœ¨ç»™å®šç‚¹aå¤„çš„å¯å¾®æ€§ç­‰ä»·äºç”±çº¿æ€§å‡½æ•°è¿›è¡Œçš„å±€éƒ¨è¿‘ä¼¼'
- en: '![l(x ) = f(a) + fâ€²(a)(x âˆ’ a). ](img/file1497.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![l(x ) = f(a) + fâ€²(a)(x âˆ’ a).](img/file1497.png)'
- en: If x is close to a, l(x) is also close to f(x). Moreover, this is the best linear
    approximation we can do around a. In a single variable, this is equivalent to
    differentiation.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœxé è¿‘aï¼Œl(x)ä¹Ÿå°†æ¥è¿‘f(x)ã€‚æ­¤å¤–ï¼Œè¿™æ˜¯æˆ‘ä»¬åœ¨aé™„è¿‘æ‰€èƒ½åšçš„æœ€ä½³çº¿æ€§è¿‘ä¼¼ã€‚åœ¨å•å˜é‡ä¸­ï¼Œè¿™ç›¸å½“äºæ±‚å¯¼ã€‚
- en: 'This gives us an idea: even though difference quotients like ![f(x)âˆ’f(y) xâˆ’y](img/file1498.png)
    do not exist in multiple variables, the best local approximation with a multivariable
    linear function does!'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™äº†æˆ‘ä»¬ä¸€ä¸ªæƒ³æ³•ï¼šå°½ç®¡åƒ![f(x)âˆ’f(y) xâˆ’y](img/file1498.png)è¿™æ ·çš„å·®å•†åœ¨å¤šå˜é‡ä¸­ä¸å­˜åœ¨ï¼Œä½†å¤šå˜é‡çº¿æ€§å‡½æ•°çš„æœ€ä½³å±€éƒ¨è¿‘ä¼¼å´å­˜åœ¨ï¼
- en: Thus, the notion of total differentiability is born.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ€»å¯å¾®æ€§çš„æ¦‚å¿µå°±æ­¤è¯ç”Ÿã€‚
- en: Definition 68\. (Total differentiability)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 68.ï¼ˆæ€»å¯å¾®æ€§ï¼‰
- en: 'Let f : â„^n â†’â„ be a function of n variables. We say that f is totally differentiable
    (or sometimes just differentiable for short) at a âˆˆâ„^n if there exists a row vector
    D[f](a) âˆˆâ„^(1Ã—n) such that'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾f : â„^n â†’ â„ä¸ºä¸€ä¸ªnå˜é‡çš„å‡½æ•°ã€‚å¦‚æœfåœ¨a âˆˆ â„^nå¤„å®Œå…¨å¯å¾®ï¼ˆæˆ–ç®€ç§°ä¸ºå¯å¾®ï¼‰ï¼Œåˆ™å­˜åœ¨ä¸€ä¸ªè¡Œå‘é‡D[f](a) âˆˆ â„^(1Ã—n)ï¼Œä½¿å¾—'
- en: f(x) = f(a) + D[f](a)(x âˆ’ a) + o(âˆ¥x âˆ’ aâˆ¥) (16.3)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: f(x) = f(a) + D[f](a)(x âˆ’ a) + o(âˆ¥x âˆ’ aâˆ¥) (16.3)
- en: holds for all x âˆˆB(ğœ€,a), where ğœ€/span>0 and B(ğœ€,a) is defined by
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ‰€æœ‰x âˆˆ B(ğœ–,a)ï¼Œå…¶ä¸­ğœ–/span>0ï¼ŒB(ğœ–,a)ç”±ä¸‹å¼å®šä¹‰
- en: '![B(ğœ€,a) = {x âˆˆ â„n : âˆ¥x âˆ’ aâˆ¥} <ğœ€. ](img/file1499.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![B(ğœ–,a) = {x âˆˆ â„n : âˆ¥x âˆ’ aâˆ¥} <ğœ–.](img/file1499.png)'
- en: (In other words, B(ğœ€,a) is a ball of radius ğœ€/span>0 around a.) When exists,
    the vector D[f](a) is called the total derivative of f at a.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆæ¢å¥è¯è¯´ï¼ŒB(ğœ–,a)æ˜¯ä»¥aä¸ºä¸­å¿ƒï¼ŒåŠå¾„ä¸ºğœ–/span>0çš„çƒã€‚ï¼‰å½“å­˜åœ¨æ—¶ï¼Œå‘é‡D[f](a)ç§°ä¸ºfåœ¨aå¤„çš„æ€»å¯¼æ•°ã€‚
- en: Recall that when it is not stated explicitly, we use column vectors, because
    we want to write our linear transformations in the form Ax, where A âˆˆâ„^(mÃ—n) and
    x âˆˆâ„^(nÃ—1). Thus, the â€œdimensionologyâ€ of the formula
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›æƒ³ä¸€ä¸‹ï¼Œå½“æ²¡æœ‰æ˜ç¡®è¯´æ˜æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨åˆ—å‘é‡ï¼Œå› ä¸ºæˆ‘ä»¬å¸Œæœ›å°†çº¿æ€§å˜æ¢å†™æˆAxçš„å½¢å¼ï¼Œå…¶ä¸­A âˆˆ â„^(mÃ—n)ä¸”x âˆˆ â„^(nÃ—1)ã€‚å› æ­¤ï¼Œå…¬å¼çš„â€œç»´åº¦å­¦â€ '
- en: '![ f(x) = f(a) + Df (a )(xâˆ’ a )+o(âˆ¥x âˆ’ aâˆ¥) âˆˆ â„1Ã—1 â—Ÿâ—1â—œÃ—â—1 â—Ÿâ—â—œ1â—Ã—1 â—Ÿ-â—1â—œÃ— â—n
    â—Ÿ-â—â—œnÃ—â—1 âˆˆâ„ âˆˆâ„ âˆˆâ„ âˆˆâ„ ](img/file1500.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![ f(x) = f(a) + Df (a )(xâˆ’ a )+o(âˆ¥x âˆ’ aâˆ¥) âˆˆ â„1Ã—1 â—Ÿâ—1â—œÃ—â—1 â—Ÿâ—â—œ1â—Ã—1 â—Ÿ-â—1â—œÃ— â—n
    â—Ÿ-â—â—œnÃ—â—1 âˆˆâ„ âˆˆâ„ âˆˆâ„ âˆˆâ„ ](img/file1500.png)'
- en: works out. (Donâ€™t be fooled, â„^(1Ã—1) is a scalar.)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—å¾—å‡ºã€‚ï¼ˆåˆ«è¢«æ„šå¼„äº†ï¼Œâ„^(1Ã—1)æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚ï¼‰
- en: Letâ€™s unravel the notion of total differentiability. The form ([16.3](ch026.xhtml#x1-257003r68))
    implies that a totally differentiable function f equals to the linear part f(a)
    + D[f](a)(x âˆ’a) plus a small error.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è§£å¼€æ€»å¯å¾®æ€§çš„æ¦‚å¿µã€‚å½¢å¼ï¼ˆ[16.3](ch026.xhtml#x1-257003r68)ï¼‰æ„å‘³ç€ä¸€ä¸ªå®Œå…¨å¯å¾®çš„å‡½æ•°fç­‰äºçº¿æ€§éƒ¨åˆ†f(a) + D[f](a)(x
    âˆ’ a)åŠ ä¸Šä¸€ä¸ªå°è¯¯å·®ã€‚
- en: The surface given by the linear part is called the tangent plane. We can visualize
    it for functions of two variables.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±çº¿æ€§éƒ¨åˆ†ç»™å‡ºçš„è¡¨é¢ç§°ä¸ºåˆ‡å¹³é¢ã€‚æˆ‘ä»¬å¯ä»¥ä¸ºäºŒå˜é‡å‡½æ•°å¯è§†åŒ–å®ƒã€‚
- en: '![PIC](img/file1501.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1501.png)'
- en: 'FigureÂ 16.3: The tangent plane'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾16.3ï¼šåˆ‡å¹³é¢
- en: Unsurprisingly, the partial and total derivatives share an intimate connection.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å‡ºæ‰€æ–™ï¼Œåå¯¼æ•°å’Œæ€»å¯¼æ•°æœ‰ç€å¯†åˆ‡çš„å…³ç³»ã€‚
- en: Theorem 99\. (Total derivative and the partial derivatives)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç†99.ï¼ˆæ€»å¯¼æ•°ä¸åå¯¼æ•°ï¼‰
- en: 'Let f : â„^n â†’â„ be a function that is totally differentiable at a âˆˆâ„^n. Then,
    all of its partial derivatives exist at a and'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾f : â„^n â†’ â„ä¸ºä¸€ä¸ªåœ¨a âˆˆ â„^nå¤„å®Œå…¨å¯å¾®çš„å‡½æ•°ã€‚åˆ™ï¼Œå®ƒçš„æ‰€æœ‰åå¯¼æ•°åœ¨aå¤„éƒ½å­˜åœ¨ï¼Œå¹¶ä¸”'
- en: f(x) = f(a) + âˆ‡f(a)^T (x âˆ’ a) + o(âˆ¥x âˆ’ aâˆ¥) (16.4)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: f(x) = f(a) + âˆ‡f(a)^T (x âˆ’ a) + o(âˆ¥x âˆ’ aâˆ¥) (16.4)
- en: holds for all a in some B(ğœ€,a), ğœ€/span>0\. (That is, D[f](a) = âˆ‡f(a)^T .)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ‰€æœ‰ a âˆˆ B(ğœ€,a)ï¼Œğœ€/span>0ï¼Œæˆç«‹ã€‚ï¼ˆå³ï¼ŒD[f](a) = âˆ‡f(a)^T ã€‚ï¼‰
- en: In other words, the equation ([16.4](ch026.xhtml#x1-257006r99)) gives that the
    coefficients of the best linear approximation are equal to the partial derivatives.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæ–¹ç¨‹ ([16.4](ch026.xhtml#x1-257006r99)) è¡¨æ˜æœ€ä½³çº¿æ€§è¿‘ä¼¼çš„ç³»æ•°ç­‰äºåå¯¼æ•°ã€‚
- en: Proof. Because f is totally differentiable at a, the definition gives that f
    can be written in the form
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚å› ä¸º f åœ¨ a å¤„æ˜¯å®Œå…¨å¯å¾®çš„ï¼Œå®šä¹‰å‘Šè¯‰æˆ‘ä»¬ f å¯ä»¥å†™æˆå¦‚ä¸‹å½¢å¼
- en: '![f(x) = f(a)+ Df (a)(xâˆ’ a)+ o(âˆ¥x âˆ’ aâˆ¥), ](img/file1502.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![f(x) = f(a)+ Df (a)(xâˆ’ a)+ o(âˆ¥x âˆ’ aâˆ¥), ](img/file1502.png)'
- en: where D[f](a) = (d[1],â€¦,d[n]) is the vector that describes the coefficients
    of the linear part.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ D[f](a) = (d[1],â€¦,d[n]) æ˜¯æè¿°çº¿æ€§éƒ¨åˆ†ç³»æ•°çš„å‘é‡ã€‚
- en: Our goal is to show that
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è¯æ˜
- en: '![ f-(a-+-hei)âˆ’-f-(a) hliâ†’m0 h = di, ](img/file1503.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![ f-(a-+-hei)âˆ’-f-(a) hliâ†’m0 h = di, ](img/file1503.png)'
- en: where e[i] is the unit (column) vector whose i-th component is 1, while the
    others are 0.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ e[i] æ˜¯å•ä½ï¼ˆåˆ—ï¼‰å‘é‡ï¼Œå…¶ç¬¬ i ä¸ªåˆ†é‡ä¸º 1ï¼Œå…¶ä½™åˆ†é‡ä¸º 0ã€‚
- en: Letâ€™s do a quick calculation! Based on what we know, we have
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¿«é€Ÿåšä¸ªè®¡ç®—ï¼æ ¹æ®æˆ‘ä»¬æ‰€çŸ¥é“çš„ï¼Œæˆ‘ä»¬æœ‰
- en: '![f(a-+-hei)âˆ’-f(a)-= Df-(a)hei +-o(âˆ¥heiâˆ¥) h h = Df (a)ei + o(1) = di + o(1),
    ](img/file1504.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![f(a-+-hei)âˆ’-f(a)-= Df-(a)hei +-o(âˆ¥heiâˆ¥) h h = Df (a)ei + o(1) = di + o(1),
    ](img/file1504.png)'
- en: thus confirming that lim[hâ†’0]![f(a+hei)âˆ’-f(a)- h](img/file1505.png) = d[i],
    which is what we had to show.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è€Œç¡®è®¤ lim[hâ†’0]![f(a+hei)âˆ’-f(a)- h](img/file1505.png) = d[i]ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬éœ€è¦è¯æ˜çš„ã€‚
- en: Whatâ€™s all the hassle with total differentiation, then? TheoremÂ [99](ch026.xhtml#x1-257006r99)
    tells us that total differentiability is a stronger condition than partial differentiability.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæ€»å¾®åˆ†çš„éº»çƒ¦åœ¨å“ªé‡Œå‘¢ï¼Ÿå®šç†Â [99](ch026.xhtml#x1-257006r99) å‘Šè¯‰æˆ‘ä»¬ï¼Œæ€»å¾®åˆ†æ˜¯æ¯”åå¾®åˆ†æ›´å¼ºçš„æ¡ä»¶ã€‚
- en: 'Surprisingly, the other direction is not true: the existence of partial derivatives
    does not imply total differentiability, as the example'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ºäººæ„æ–™çš„æ˜¯ï¼Œåæ–¹å‘ä¸æˆç«‹ï¼šåå¯¼æ•°çš„å­˜åœ¨å¹¶ä¸æ„å‘³ç€æ€»å¾®åˆ†æ€§ï¼Œå¦‚ç¤ºä¾‹æ‰€ç¤ºã€‚
- en: '![ ( |{ f (x, y) = 1 if x = 0 or y = 0, |( 0 otherwise ](img/file1506.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![ ( |{ f (x, y) = 1 å¦‚æœ x = 0 æˆ– y = 0, |( 0 å¦åˆ™ ](img/file1506.png)'
- en: illustrates. This function has all its partial derivatives at 0, yet the total
    derivative does not exist. (You can convince yourself by either drawing a figure,
    or noting that the function 1 âˆ’d^T x can never be o(âˆ¥xâˆ¥), regardless of the choice
    of d.)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å›¾æ‰€ç¤ºã€‚è¿™ä¸ªå‡½æ•°åœ¨ 0 å¤„æœ‰æ‰€æœ‰çš„åå¯¼æ•°ï¼Œä½†æ€»å¯¼æ•°ä¸å­˜åœ¨ã€‚ï¼ˆä½ å¯ä»¥é€šè¿‡ç”»å›¾æˆ–æ³¨æ„åˆ°å‡½æ•° 1 âˆ’d^T x æ°¸è¿œä¸å¯èƒ½æ˜¯ o(âˆ¥xâˆ¥) æ¥è¯æ˜è¿™ä¸€ç‚¹ï¼Œæ— è®º
    d çš„é€‰æ‹©å¦‚ä½•ã€‚ï¼‰
- en: Remark 11\. (The total derivative as an operator)
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å¤‡æ³¨ 11\. ï¼ˆæ€»å¯¼æ•°ä½œä¸ºç®—å­ï¼‰
- en: 'Just like for single-variable functions, the total derivative of f : â„^n â†’â„
    is a function D[f] : â„^n â†’â„^n.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 'å°±åƒå•å˜é‡å‡½æ•°ä¸€æ ·ï¼Œf : â„^n â†’â„ çš„æ€»å¯¼æ•°æ˜¯ä¸€ä¸ªå‡½æ•° D[f] : â„^n â†’â„^nã€‚'
- en: 'At the highest level of abstraction, we can think about the total derivative
    as an operator that maps a vector-scalar function to a vector-vector function:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ€é«˜å±‚æ¬¡çš„æŠ½è±¡ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ€»å¯¼æ•°çœ‹ä½œæ˜¯ä¸€ä¸ªç®—å­ï¼Œå®ƒå°†ä¸€ä¸ªå‘é‡æ ‡é‡å‡½æ•°æ˜ å°„åˆ°ä¸€ä¸ªå‘é‡å‘é‡å‡½æ•°ï¼š
- en: '![ n â„ n â„n D : (â„ ) â†’ (â„ ) , D : f â†¦â†’ D , f ](img/file1507.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![ n â„ n â„n D : (â„ ) â†’ (â„ ) , D : f â†¦â†’ D , f ](img/file1507.png)'
- en: where A^B denotes the set of all functions mapping A to B.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ A^B è¡¨ç¤ºå°† A æ˜ å°„åˆ° B çš„æ‰€æœ‰å‡½æ•°çš„é›†åˆã€‚
- en: You are not required to understand this at all, but trust me, the more abstract
    your thinking is, the more powerful youâ€™ll be.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¸éœ€è¦å®Œå…¨ç†è§£è¿™ä¸€ç‚¹ï¼Œä½†ç›¸ä¿¡æˆ‘ï¼Œä½ çš„æ€ç»´è¶ŠæŠ½è±¡ï¼Œä½ å°±ä¼šè¶Šå¼ºå¤§ã€‚
- en: 16.1.4 Directional derivatives
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.1.4 æ–¹å‘å¯¼æ•°
- en: 'So far, we have talked about two kinds of derivatives: partial derivatives
    that describe the rate of change along a fixed axis, and total derivatives that
    give the best linear approximation of the function at a given point.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è°ˆäº†ä¸¤ç§å¯¼æ•°ï¼šæè¿°æ²¿å›ºå®šè½´å˜åŒ–é€Ÿç‡çš„åå¯¼æ•°ï¼Œä»¥åŠç»™å‡ºç»™å®šç‚¹å‡½æ•°æœ€ä½³çº¿æ€§è¿‘ä¼¼çš„æ€»å¯¼æ•°ã€‚
- en: Partial derivatives are only concerned with a few particular directions. However,
    this is not the end of the story in multiple variables. With the standard orthonormal
    basis vectors e[i], the partial derivatives are defined by
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: åå¯¼æ•°åªå…³æ³¨å‡ ä¸ªç‰¹å®šçš„æ–¹å‘ã€‚ç„¶è€Œï¼Œåœ¨å¤šå˜é‡ä¸­ï¼Œè¿™ä¸æ˜¯æ•…äº‹çš„å…¨éƒ¨ã€‚é€šè¿‡æ ‡å‡†çš„æ­£äº¤å½’ä¸€åŸºå‘é‡ e[i]ï¼Œåå¯¼æ•°çš„å®šä¹‰ä¸º
- en: '![L(U,V ) = {f : U â†’ V | f is linear}](img/equation_(23).png)(16.5)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U â†’ V | f æ˜¯çº¿æ€§çš„}](img/equation_(23).png)(16.5)'
- en: As we saw earlier, these describe the rate of change along the dimensions. However,
    the standard orthonormal vectors are just a few special directions.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ï¼Œè¿™äº›æè¿°äº†æ²¿å„ç»´åº¦çš„å˜åŒ–é€Ÿç‡ã€‚ç„¶è€Œï¼Œæ ‡å‡†çš„æ­£äº¤å½’ä¸€å‘é‡ä»…æ˜¯ä¸€äº›ç‰¹å®šçš„æ–¹å‘ã€‚
- en: What about an arbitrary direction v? Can we define the derivative along these?
    Sure! There is nothing stopping us from replacing e[i] with v in ([16.5](ch026.xhtml#directional-derivatives)).
    Thus, directional derivatives are born.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆåœ¨ä»»æ„æ–¹å‘ v ä¸‹å‘¢ï¼Ÿæˆ‘ä»¬å¯ä»¥å®šä¹‰æ²¿è¿™äº›æ–¹å‘çš„å¯¼æ•°å—ï¼Ÿå½“ç„¶ï¼æ²¡æœ‰ä»»ä½•ä¸œè¥¿é˜»æ­¢æˆ‘ä»¬åœ¨ ([16.5](ch026.xhtml#directional-derivatives))
    ä¸­ç”¨ v æ›¿æ¢ e[i]ã€‚å› æ­¤ï¼Œæ–¹å‘å¯¼æ•°åº”è¿è€Œç”Ÿã€‚
- en: Definition 69\. (Directional derivatives)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 69.ï¼ˆæ–¹å‘å¯¼æ•°ï¼‰
- en: 'Let f : â„^n â†’â„ be a function of n variables and let v âˆˆâ„^n be an arbitrary
    vector. The directional derivative of f along v is defined by the limit'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ f : â„^n â†’â„ æ˜¯ä¸€ä¸ª n ä¸ªå˜é‡çš„å‡½æ•°ï¼Œv âˆˆâ„^n æ˜¯ä¸€ä¸ªä»»æ„å‘é‡ã€‚f åœ¨ v æ–¹å‘ä¸Šçš„æ–¹å‘å¯¼æ•°ç”±æé™å®šä¹‰ï¼š'
- en: '![âˆ‚f f(a + hv) âˆ’ f(a) âˆ‚v-:= lhimâ†’0 -------h--------. ](img/file1510.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚f f(a + hv) âˆ’ f(a) âˆ‚v-:= lhimâ†’0 -------h--------. ](img/file1510.png)'
- en: 'Good news: the directional derivatives can be described in terms of the gradient!'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½æ¶ˆæ¯ï¼šæ–¹å‘å¯¼æ•°å¯ä»¥é€šè¿‡æ¢¯åº¦æ¥æè¿°ï¼
- en: Theorem 100\.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 100.
- en: 'Let f : â„^n â†’â„ be a function of n variables. If f is totally differentiable
    at a âˆˆâ„^n, then its directional derivatives exist in all directions, and'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ f : â„^n â†’â„ æ˜¯ä¸€ä¸ª n ä¸ªå˜é‡çš„å‡½æ•°ã€‚å¦‚æœ f åœ¨ a âˆˆâ„^n å¤„å…¨å¾®åˆ†ï¼Œé‚£ä¹ˆå®ƒåœ¨æ‰€æœ‰æ–¹å‘ä¸Šçš„æ–¹å‘å¯¼æ•°éƒ½å­˜åœ¨ï¼Œå¹¶ä¸”'
- en: '![âˆ‚f(a) = âˆ‡f (a)Tv. âˆ‚v ](img/file1511.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚f(a) = âˆ‡f (a)Tv. âˆ‚v ](img/file1511.png)'
- en: Proof. Because of the total differentiability, TheoremÂ [103](ch026.xhtml#x1-263004r103)
    gives that
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚ç”±äºå…¨å¾®åˆ†æ€§ï¼Œå®šç†Â [103](ch026.xhtml#x1-263004r103) è¡¨æ˜ï¼š
- en: '![f (x ) = f (a )+ âˆ‡f (a)T(x âˆ’ a)+ o(âˆ¥x âˆ’ aâˆ¥) ](img/file1512.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![f (x ) = f (a )+ âˆ‡f (a)T(x âˆ’ a)+ o(âˆ¥x âˆ’ aâˆ¥) ](img/file1512.png)'
- en: around a. Thus,
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ a é™„è¿‘ã€‚å› æ­¤ï¼Œ
- en: '![f(a+ hv )âˆ’ f (a ) hâˆ‡f (a)Tv + o(h) ----------------= ---------------- h h
    = âˆ‡f (a)Tv + o(1), ](img/file1513.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![f(a+ hv )âˆ’ f (a ) hâˆ‡f (a)Tv + o(h) ----------------= ---------------- h h
    = âˆ‡f (a)Tv + o(1), ](img/file1513.png)'
- en: giving that
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å‡ºï¼š
- en: '![âˆ‚f-(a) = lim f-(a-+-hv-)âˆ’-f(a) âˆ‚v hâ†’0 h = lim âˆ‡f (a)Tv + o(1) hâ†’0 = âˆ‡f (a)T
    v, ](img/file1514.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚f-(a) = lim f-(a-+-hv-)âˆ’-f(a) âˆ‚v hâ†’0 h = lim âˆ‡f (a)Tv + o(1) hâ†’0 = âˆ‡f (a)T
    v, ](img/file1514.png)'
- en: as we needed to show.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬æ‰€éœ€çš„é‚£æ ·è¯æ˜ã€‚
- en: 'In other words, TheoremÂ [100](ch026.xhtml#x1-258003r100) gives that no matter
    the direction v, the directional derivative can be written in terms of the gradient
    and v. If you think about this for a minute, this is quite amazing: the rates
    of change along n special directions determine the rate of change in any other
    direction.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œå®šç†Â [100](ch026.xhtml#x1-258003r100) è¡¨ç¤ºï¼Œæ— è®ºæ–¹å‘ v å¦‚ä½•ï¼Œæ–¹å‘å¯¼æ•°éƒ½å¯ä»¥ç”¨æ¢¯åº¦å’Œ v æ¥è¡¨ç¤ºã€‚å¦‚æœä½ ä»”ç»†æƒ³ä¸€æƒ³ï¼Œè¿™çœŸçš„å¾ˆæƒŠäººï¼šæ²¿ç€
    n ä¸ªç‰¹å®šæ–¹å‘çš„å˜åŒ–ç‡å†³å®šäº†å…¶ä»–ä»»ä½•æ–¹å‘çš„å˜åŒ–ç‡ã€‚
- en: 16.1.5 Properties of the gradient
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.1.5 æ¢¯åº¦çš„æ€§è´¨
- en: In one variable, we have learned that if the derivative of f is positive at
    some a, then f is increasing around a. (If the derivative is negative, f is decreasing.)
    If we think about the derivative f^â€²(a) as a one-dimensional vector, then the
    derivative points towards the direction of increase.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸€ç»´æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å·²ç»å­¦åˆ°ï¼Œå¦‚æœ f åœ¨æŸä¸ª a å¤„çš„å¯¼æ•°ä¸ºæ­£ï¼Œé‚£ä¹ˆ f åœ¨ a é™„è¿‘æ˜¯å¢åŠ çš„ã€‚ï¼ˆå¦‚æœå¯¼æ•°ä¸ºè´Ÿï¼Œåˆ™ f æ˜¯å‡å°‘çš„ã€‚ï¼‰å¦‚æœæˆ‘ä»¬å°† f'(a)
    çœ‹ä½œä¸€ä¸ªä¸€ç»´å‘é‡ï¼Œé‚£ä¹ˆå¯¼æ•°æŒ‡å‘å¢å¤§çš„æ–¹å‘ã€‚
- en: Is this true in higher dimensions? Yes, and this is what makes gradient descent
    work.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åœ¨é«˜ç»´ç©ºé—´ä¸­ä¹Ÿæˆç«‹å—ï¼Ÿæ˜¯çš„ï¼Œè¿™å°±æ˜¯æ¢¯åº¦ä¸‹é™æ³•æœ‰æ•ˆçš„åŸå› ã€‚
- en: Theorem 101\. (The gradient determines the direction of the increase)
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 101.ï¼ˆæ¢¯åº¦å†³å®šå¢åŠ çš„æ–¹å‘ï¼‰
- en: 'Let f : â„^n â†’â„ be a function of n variables, and suppose that f is totally
    differentiable at a âˆˆâ„^n.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ f : â„^n â†’â„ æ˜¯ä¸€ä¸ª n ä¸ªå˜é‡çš„å‡½æ•°ï¼Œå‡è®¾ f åœ¨ a âˆˆâ„^n å¤„å…¨å¾®åˆ†ã€‚'
- en: Then
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶å
- en: '![L(U,V ) = {f : U â†’ V | f is linear}](img/equation_(24).png)(16.6)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U â†’ V | f is linear}](img/equation_(24).png)(16.6)'
- en: I know, ([16.6](ch026.xhtml#x1-259002r101)) is pretty overloaded, so letâ€™s unpack
    it. First, letâ€™s start with the mysterious argmax. For a given function f,
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çŸ¥é“ï¼Œ([16.6](ch026.xhtml#x1-259002r101)) å¾ˆå¤æ‚ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æ¥è¯¦ç»†è§£æä¸€ä¸‹ã€‚é¦–å…ˆï¼Œä»ç¥ç§˜çš„ argmax å¼€å§‹ã€‚å¯¹äºç»™å®šçš„å‡½æ•°
    fï¼Œ
- en: '![argmaxx âˆˆSf(x) ](img/file1517.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![argmaxx âˆˆSf(x) ](img/file1517.png)'
- en: denotes the values that maximize f on the set S. As the maximum may not be unique,
    argmax can yield a set. (The definition of argmin is the same, but with minimum
    instead of maximum.)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ç¤ºåœ¨é›†åˆ S ä¸Šæœ€å¤§åŒ– f çš„å€¼ã€‚ç”±äºæœ€å¤§å€¼å¯èƒ½ä¸å”¯ä¸€ï¼Œargmax å¯èƒ½ä¼šå¾—åˆ°ä¸€ä¸ªé›†åˆã€‚ï¼ˆargmin çš„å®šä¹‰ç›¸åŒï¼Œåªæ˜¯å–æœ€å°å€¼è€Œä¸æ˜¯æœ€å¤§å€¼ã€‚ï¼‰
- en: Thus, in English, ([16.6](ch026.xhtml#x1-259002r101)) states that the unit direction
    that maximizes the directional derivative at a âˆˆâ„^n is the normalized gradient.
    Now we are ready to see the proof!
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè‹±æ–‡ä¸­ï¼Œ([16.6](ch026.xhtml#x1-259002r101)) è¡¨æ˜ï¼Œåœ¨ a âˆˆâ„^n å¤„ï¼Œæœ€å¤§åŒ–æ–¹å‘å¯¼æ•°çš„å•ä½æ–¹å‘æ˜¯å½’ä¸€åŒ–çš„æ¢¯åº¦ã€‚ç°åœ¨æˆ‘ä»¬å‡†å¤‡å¥½çœ‹åˆ°è¯æ˜äº†ï¼
- en: Proof. Do you remember the Cauchy-Schwarz inequality (TheoremÂ [8](ch008.xhtml#x1-43003r8))?
    It was a long time ago, so letâ€™s recall! In the vector space â„^n, the Cauchy-Schwarz
    inequality tells us that for any x,y âˆˆâ„^n,
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚ä½ è¿˜è®°å¾—æŸ¯è¥¿-æ–½ç“¦èŒ¨ä¸ç­‰å¼ï¼ˆå®šç†Â [8](ch008.xhtml#x1-43003r8)ï¼‰å—ï¼Ÿé‚£æ˜¯å¾ˆä¹…ä»¥å‰çš„äº‹äº†ï¼Œè®©æˆ‘ä»¬æ¥å›é¡¾ä¸€ä¸‹ï¼åœ¨å‘é‡ç©ºé—´ â„^n
    ä¸­ï¼ŒæŸ¯è¥¿-æ–½ç“¦èŒ¨ä¸ç­‰å¼å‘Šè¯‰æˆ‘ä»¬ï¼Œå¯¹äºä»»ä½• x, y âˆˆâ„^nï¼Œ
- en: '![xT y â‰¤ âˆ¥xâˆ¥âˆ¥yâˆ¥. ](img/file1518.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![xT y â‰¤ âˆ¥xâˆ¥âˆ¥yâˆ¥. ](img/file1518.png)'
- en: Now, as TheoremÂ [100](ch026.xhtml#x1-258003r100) implies, the directional derivatives
    can be written as
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæ­£å¦‚å®šç†[100](ch026.xhtml#x1-258003r100)æ‰€æš—ç¤ºçš„ï¼Œæ–¹å‘å¯¼æ•°å¯ä»¥å†™ä½œ
- en: '![âˆ‚f- T âˆ‚v(a) = âˆ‡f (a) v. ](img/file1519.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚f- T âˆ‚v(a) = âˆ‡f (a) v. ](img/file1519.png)'
- en: Combined with the Cauchy-Schwarz inequality, we get that
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“åˆæŸ¯è¥¿-æ–½ç“¦èŒ¨ä¸ç­‰å¼ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![âˆ‚f ---(a) = âˆ‡f (a)T v âˆ‚v â‰¤ âˆ¥ âˆ‡f (a )âˆ¥âˆ¥v âˆ¥. ](img/file1520.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚f ---(a) = âˆ‡f (a)T v âˆ‚v â‰¤ âˆ¥ âˆ‡f (a )âˆ¥âˆ¥v âˆ¥. ](img/file1520.png)'
- en: By restricting the directions to unit vectors,
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å°†æ–¹å‘é™åˆ¶ä¸ºå•ä½å‘é‡ï¼Œ
- en: '![L(U,V ) = {f : U â†’ V | f is linear}](img/equation_(25).png)(16.7)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U â†’ V | f æ˜¯çº¿æ€§çš„}](img/equation_(25).png)(16.7)'
- en: follows. Thus, the directional derivatives must be less than or equal to the
    gradientâ€™s norm. (At least, along a direction vector with unit length.)
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æ­¤ï¼Œæ–¹å‘å¯¼æ•°å¿…é¡»å°äºæˆ–ç­‰äºæ¢¯åº¦çš„èŒƒæ•°ã€‚ï¼ˆè‡³å°‘ï¼Œåœ¨å•ä½é•¿åº¦çš„æ–¹å‘å‘é‡ä¸Šã€‚ï¼‰
- en: However, by letting v[0] = âˆ‡f(a)âˆ•âˆ¥âˆ‡f(a)âˆ¥, we obtain that
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œé€šè¿‡è®© v[0] = âˆ‡f(a)âˆ•âˆ¥âˆ‡f(a)âˆ¥ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![âˆ‚f--(a ) = âˆ‡f (a)Tv0 âˆ‚v0 âˆ‡f (a)Tâˆ‡f (a) = ---âˆ¥âˆ‡f-(a)âˆ¥-- 2 = âˆ¥âˆ‡f-(a)âˆ¥- âˆ¥âˆ‡f
    (a)âˆ¥ = âˆ¥âˆ‡f (a)âˆ¥. ](img/file1522.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚f--(a ) = âˆ‡f (a)Tv0 âˆ‚v0 âˆ‡f (a)Tâˆ‡f (a) = ---âˆ¥âˆ‡f-(a)âˆ¥-- 2 = âˆ¥âˆ‡f-(a)âˆ¥- âˆ¥âˆ‡f
    (a)âˆ¥ = âˆ¥âˆ‡f (a)âˆ¥. ](img/file1522.png)'
- en: Thus, with the choice v[0] = ![-âˆ‡f(a)-](img/file1523.png), equality can be attained
    in ([16.7](#)). This means that ![](img/file1524.png) maximizes the directional
    derivative at a, which is what we had to prove.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œé€šè¿‡é€‰æ‹© v[0] = ![-âˆ‡f(a)-](img/file1523.png)ï¼Œå¯ä»¥åœ¨([16.7](#))ä¸­è¾¾åˆ°ç­‰å¼ã€‚è¿™æ„å‘³ç€ ![](img/file1524.png)
    åœ¨ a ç‚¹æœ€å¤§åŒ–äº†æ–¹å‘å¯¼æ•°ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦è¯æ˜çš„ã€‚
- en: With that, we have the basics of differentiation in multiple variables under
    our belt. To sum up, we have learned that the difference quotient definition of
    the derivative does not generalize directly for multiple variables, but we can
    fix all but one variables to make the difference quotient work, thus obtaining
    partial derivatives.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°æ­¤ï¼Œæˆ‘ä»¬å·²ç»æŒæ¡äº†å¤šå˜é‡çš„å¾®åˆ†åŸºç¡€ã€‚æ€»ç»“ä¸€ä¸‹ï¼Œæˆ‘ä»¬å·²ç»å­¦åˆ°ï¼Œå¯¼æ•°çš„å·®å•†å®šä¹‰ä¸èƒ½ç›´æ¥æ¨å¹¿åˆ°å¤šå˜é‡ï¼Œä½†æˆ‘ä»¬å¯ä»¥å°†é™¤ä¸€ä¸ªå˜é‡å¤–çš„å…¶ä»–å˜é‡å›ºå®šï¼Œä»è€Œä½¿å·®å•†æˆç«‹ï¼Œä»è€Œå¾—åˆ°åå¯¼æ•°ã€‚
- en: On the other hand, the linear approximation definition works in multiple dimensions,
    but instead of
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼Œçº¿æ€§è¿‘ä¼¼å®šä¹‰åœ¨å¤šç»´ç©ºé—´ä¸­ä¹Ÿé€‚ç”¨ï¼Œä½†ä¸æ˜¯
- en: '![ â€² f(a)+ f (a)(xâˆ’ a), f : â„ â†’ â„, x,a âˆˆ â„, ](img/file1525.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![ â€² f(a)+ f (a)(xâˆ’ a), f : â„ â†’ â„, x,a âˆˆ â„, ](img/file1525.png)'
- en: like we had in one variable, we obtain
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åƒæˆ‘ä»¬åœ¨å•å˜é‡æ—¶é‚£æ ·ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![f (a )+ âˆ‡f (a)T(xâˆ’ a), f : â„n â†’ â„, x,a âˆˆ â„n, ](img/file1526.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![f (a )+ âˆ‡f (a)T(xâˆ’ a), f : â„n â†’ â„, x,a âˆˆ â„n, ](img/file1526.png)'
- en: where the analogue of the derivative is the gradient vector âˆ‡f(a) âˆˆâ„^n.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œå¯¼æ•°çš„ç±»æ¯”æ˜¯æ¢¯åº¦å‘é‡ âˆ‡f(a) âˆˆâ„^nã€‚
- en: Even when we were studying differentiation in one variable for the first time,
    I told you that the local linear approximation definition would be useful someday.
    That time is now, and we are reaping the benefits. Soon, weâ€™ll see gradient descent
    in its full glory.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿æˆ‘ä»¬ç¬¬ä¸€æ¬¡å­¦ä¹ å•å˜é‡å¾®åˆ†æ—¶ï¼Œæˆ‘ä¹Ÿæ›¾å‘Šè¯‰ä½ ï¼Œå±€éƒ¨çº¿æ€§è¿‘ä¼¼å®šä¹‰æ€»æœ‰ä¸€å¤©ä¼šæ´¾ä¸Šç”¨åœºã€‚é‚£ä¸ªæ—¶å€™å°±æ˜¯ç°åœ¨ï¼Œæˆ‘ä»¬æ­£åœ¨æ”¶è·æˆæœã€‚å¾ˆå¿«ï¼Œæˆ‘ä»¬å°†å…¨é¢äº†è§£æ¢¯åº¦ä¸‹é™ã€‚
- en: 16.2 Derivatives of vector-valued functions
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.2 å‘é‡å€¼å‡½æ•°çš„å¯¼æ•°
- en: 'In a single variable, defining higher-order derivatives is easy. We simply
    have to keep repeating differentiation:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å•å˜é‡æƒ…å†µä¸‹ï¼Œå®šä¹‰é«˜é˜¶å¯¼æ•°æ˜¯å¾ˆç®€å•çš„ã€‚æˆ‘ä»¬åªéœ€è¦ä¸æ–­åœ°è¿›è¡Œæ±‚å¯¼ï¼š
- en: '![ â€²â€² â€² â€² f (x) = (f (x)), fâ€²â€²â€²(x) = (fâ€²â€²(x))â€², ](img/file1527.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![ â€²â€² â€² â€² f (x) = (f (x)), fâ€²â€²â€²(x) = (fâ€²â€²(x))â€², ](img/file1527.png)'
- en: and so on. However, this is not that straightforward with multivariable functions.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ç­‰ç­‰ã€‚ç„¶è€Œï¼Œå¯¹äºå¤šå˜é‡å‡½æ•°æ¥è¯´ï¼Œè¿™å¹¶ä¸æ˜¯é‚£ä¹ˆç®€å•ã€‚
- en: So far, we have only talked about gradients, the generalization of the derivative
    for vector-scalar functions.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬åªè®¨è®ºäº†æ¢¯åº¦ï¼Œè¿™æ˜¯å‘é‡-æ ‡é‡å‡½æ•°çš„å¯¼æ•°çš„æ¨å¹¿ã€‚
- en: 'As âˆ‡f(a) is a column vector, the gradient is a vector-vector function âˆ‡ : â„^n
    â†’â„^n. We only know how to compute the derivative of vector-scalar functions. Itâ€™s
    time to change that!'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç”±äº âˆ‡f(a) æ˜¯åˆ—å‘é‡ï¼Œæ¢¯åº¦æ˜¯ä¸€ä¸ªå‘é‡-å‘é‡å‡½æ•° âˆ‡ : â„^n â†’â„^nã€‚æˆ‘ä»¬åªçŸ¥é“å¦‚ä½•è®¡ç®—å‘é‡-æ ‡é‡å‡½æ•°çš„å¯¼æ•°ã€‚æ˜¯æ—¶å€™æ”¹å˜è¿™ä¸€ç‚¹äº†ï¼'
- en: 16.2.1 The derivatives of curves
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2.1 æ›²çº¿çš„å¯¼æ•°
- en: Curves, often describing the solutions of dynamical systems, are one of the
    most important objects in mathematics. We donâ€™t explicitly use them in machine
    learning, but they are underneath algorithms such as gradient descent. (Where
    we traverse a discretized curve leading to a local minimum.)
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: æ›²çº¿ï¼Œé€šå¸¸æè¿°åŠ¨æ€ç³»ç»Ÿçš„è§£ï¼Œæ˜¯æ•°å­¦ä¸­æœ€é‡è¦çš„å¯¹è±¡ä¹‹ä¸€ã€‚è™½ç„¶æˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ ä¸­å¹¶ä¸æ˜¾å¼ä½¿ç”¨å®ƒä»¬ï¼Œä½†å®ƒä»¬åœ¨è¯¸å¦‚æ¢¯åº¦ä¸‹é™çš„ç®—æ³•ä¸­æ½œåœ¨åœ°èµ·ä½œç”¨ã€‚ï¼ˆåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éå†ä¸€ä¸ªç¦»æ•£åŒ–çš„æ›²çº¿ï¼Œæœ€ç»ˆåˆ°è¾¾å±€éƒ¨æœ€å°å€¼ã€‚ï¼‰
- en: Formally, a curve â€“ that is, a scalar-vector function â€“ is given by a function
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å½¢å¼ä¸Šè®²ï¼Œæ›²çº¿â€”â€”å³æ ‡é‡-å‘é‡å‡½æ•°â€”â€”ç”±ä¸€ä¸ªå‡½æ•°ç»™å‡º
- en: '![ âŒŠÎ³ (t)âŒ‹ | 1 | n ||Î³2(t)|| n(Ã—1) Î³ : â„ â†’ â„ , Î³ (t) = || .. || âˆˆ â„ , âŒˆ . âŒ‰
    Î³n(t) ](img/file1528.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠÎ³ (t)âŒ‹ | 1 | n ||Î³2(t)|| n(Ã—1) Î³ : â„ â†’ â„ , Î³ (t) = || .. || âˆˆ â„ , âŒˆ . âŒ‰
    Î³n(t) ](img/file1528.png)'
- en: 'where the Î³[i] : â„ â†’â„ functions are good old single-variable scalar-scalar
    functions. As the independent variable often represents time, it is customary
    to denote it with t.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 'å…¶ä¸­ Î³[i] : â„ â†’â„ å‡½æ•°æ˜¯ç»å…¸çš„ä¸€å…ƒæ ‡é‡-æ ‡é‡å‡½æ•°ã€‚ç”±äºè‡ªå˜é‡é€šå¸¸è¡¨ç¤ºæ—¶é—´ï¼Œå› æ­¤ä¹ æƒ¯ä¸Šç”¨ t æ¥è¡¨ç¤ºå®ƒã€‚'
- en: 'We can differentiate Î³ componentwise:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€åˆ†é‡åœ°å¯¹ Î³ æ±‚å¯¼ï¼š
- en: '![ âŒŠ âŒ‹ Î³â€²1(t) ||Î³â€²(t)|| Î³â€²(t) := || 2\. || âˆˆ â„n(Ã—1). |âŒˆ .. |âŒ‰ â€² Î³n(t) ](img/file1529.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ Î³â€²1(t) ||Î³â€²(t)|| Î³â€²(t) := || 2\. || âˆˆ â„n(Ã—1). |âŒˆ .. |âŒ‰ â€² Î³n(t) ](img/file1529.png)'
- en: If we indeed imagine Î³(t) as a trajectory in space, Î³^â€²(t) is the tangent vector
    to Î³ at t. Since the differentiation is componentwise, TheoremÂ [77](ch020.xhtml#x1-199002r77)
    implies that if Î³ is differentiable at some a âˆˆâ„,
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ç¡®å®å°† Î³(t) æƒ³è±¡ä¸ºç©ºé—´ä¸­çš„ä¸€æ¡è½¨è¿¹ï¼Œåˆ™ Î³â€²(t) æ˜¯ Î³ åœ¨ t å¤„çš„åˆ‡å‘é‡ã€‚ç”±äºå¾®åˆ†æ˜¯é€åˆ†é‡è¿›è¡Œçš„ï¼Œå®šç† [77](ch020.xhtml#x1-199002r77)
    è¯´æ˜ï¼Œå¦‚æœ Î³ åœ¨æŸä¸ª a âˆˆâ„ å¤„å¯å¾®ï¼Œ
- en: Î³(t) = Î³(a) + Î³â€²(t)^T (t âˆ’ a) + o(|t âˆ’ a|) (16.8)
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: Î³(t) = Î³(a) + Î³â€²(t)^T (t âˆ’ a) + o(|t âˆ’ a|) ï¼ˆ16.8ï¼‰
- en: 'there. The equation ([16.8](ch026.xhtml#the-derivatives-of-curves)) is a true
    vectorized formula: some components are vectors, and some are scalars. Yet, this
    is simple and makes perfect sense to us. Hiding the complexities of vectors and
    matrices is the true power of linear algebra.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é‚£é‡Œã€‚æ–¹ç¨‹å¼ï¼ˆ[16.8](ch026.xhtml#the-derivatives-of-curves)ï¼‰æ˜¯ä¸€ä¸ªçœŸæ­£çš„å‘é‡åŒ–å…¬å¼ï¼šä¸€äº›åˆ†é‡æ˜¯å‘é‡ï¼Œä¸€äº›æ˜¯æ ‡é‡ã€‚ç„¶è€Œï¼Œè¿™å¾ˆç®€å•ï¼Œå¹¶ä¸”å¯¹æˆ‘ä»¬æ¥è¯´éå¸¸æœ‰æ„ä¹‰ã€‚éšè—å‘é‡å’ŒçŸ©é˜µçš„å¤æ‚æ€§æ˜¯çº¿æ€§ä»£æ•°çš„çœŸæ­£åŠ›é‡ã€‚
- en: 'It is easy to see that for any two curves Î³,Î· : â„ â†’â„^n, differentiation is
    additive, as (Î³ + Î·)^â€² = Î³^â€² + Î·^â€². What happens when we compose a scalar-vector
    function with a vector-scalar one?'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¾ˆå®¹æ˜“çœ‹å‡ºï¼Œå¯¹äºä»»æ„ä¸¤æ¡æ›²çº¿ Î³, Î· : â„ â†’â„^nï¼Œå¾®åˆ†æ˜¯å¯åŠ çš„ï¼Œå³ (Î³ + Î·)^â€² = Î³^â€² + Î·^â€²ã€‚å½“æˆ‘ä»¬å°†æ ‡é‡-å‘é‡å‡½æ•°ä¸å‘é‡-æ ‡é‡å‡½æ•°å¤åˆæ—¶ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿ'
- en: 'This situation is commonplace in machine learning. If, say, L : â„^n â†’â„ describes
    the loss function and Î³ : â„ â†’â„^n is our trajectory in the parameter space â„^n,
    the composite function f(Î³(t)) describes the model loss at time t. Thus, to compute
    (f âˆ˜Î³)^â€², we have to generalize the chain rule.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 'è¿™ç§æƒ…å†µåœ¨æœºå™¨å­¦ä¹ ä¸­éå¸¸å¸¸è§ã€‚æ¯”å¦‚ï¼Œå‡è®¾ L : â„^n â†’â„ æè¿°çš„æ˜¯æŸå¤±å‡½æ•°ï¼Œè€Œ Î³ : â„ â†’â„^n æ˜¯æˆ‘ä»¬åœ¨å‚æ•°ç©ºé—´ â„^n ä¸­çš„è½¨è¿¹ï¼Œå¤åˆå‡½æ•°
    f(Î³(t)) æè¿°äº†æ—¶é—´ t æ—¶åˆ»çš„æ¨¡å‹æŸå¤±ã€‚å› æ­¤ï¼Œä¸ºäº†è®¡ç®— (f âˆ˜Î³)^â€²ï¼Œæˆ‘ä»¬å¿…é¡»æ¨å¹¿é“¾å¼æ³•åˆ™ã€‚'
- en: Theorem 102\. (The chain rule for composing scalar-vector and vector-scalar
    functions)
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 102.ï¼ˆæ ‡é‡-å‘é‡å‡½æ•°å’Œå‘é‡-æ ‡é‡å‡½æ•°å¤åˆçš„é“¾å¼æ³•åˆ™ï¼‰
- en: 'Let Î³ : â„ â†’â„^n and f : â„^n â†’â„ be arbitrary functions. If Î³ is differentiable
    at some a âˆˆâ„ and f is differentiable at Î³(a), then f âˆ˜Î³ : â„ â†’â„ is also differentiable
    at a and'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ Î³ : â„ â†’â„^n å’Œ f : â„^n â†’â„ ä¸ºä»»æ„å‡½æ•°ã€‚å¦‚æœ Î³ åœ¨æŸä¸ª a âˆˆâ„ å¤„å¯å¾®ï¼Œä¸” f åœ¨ Î³(a) å¤„å¯å¾®ï¼Œåˆ™ f âˆ˜Î³ : â„
    â†’â„ ä¹Ÿåœ¨ a å¤„å¯å¾®ï¼Œä¸”'
- en: '![(f âˆ˜Î³)â€²(a) = âˆ‡f (Î³(a))TÎ³â€²(a ) ](img/file1530.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![(f âˆ˜Î³)â€²(a) = âˆ‡f (Î³(a))TÎ³â€²(a ) ](img/file1530.png)'
- en: there.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é‚£é‡Œã€‚
- en: Proof. As f is differentiable at Î³(a), TheoremÂ [99](ch026.xhtml#x1-257006r99)
    gives
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚ç”±äº f åœ¨ Î³(a) å¤„å¯å¾®ï¼Œå®šç† [99](ch026.xhtml#x1-257006r99) ç»™å‡ºï¼š
- en: '![f(Î³(t)) = f (Î³ (a )) + âˆ‡f (Î³(a))T (Î³ (t)âˆ’ Î³ (a )) + o(âˆ¥Î³(t) âˆ’ Î³(a)âˆ¥). ](img/file1531.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![f(Î³(t)) = f (Î³ (a )) + âˆ‡f (Î³(a))T (Î³ (t)âˆ’ Î³ (a )) + o(âˆ¥Î³(t) âˆ’ Î³(a)âˆ¥). ](img/file1531.png)'
- en: Thus,
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œ
- en: '![(f âˆ˜Î³ )â€²(a) = lim f(Î³(t))âˆ’-f(Î³(a)) tâ†’a tâˆ’ a T Î³(t)âˆ’-Î³(a)- = âˆ‡f (Î³(a)) litâ†’ma
    [ tâˆ’ a + o(1)] T â€² = âˆ‡f (Î³(a)) Î³ (a), ](img/file1532.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![(f âˆ˜Î³ )â€²(a) = lim f(Î³(t))âˆ’f(Î³(a)) tâ†’a tâˆ’ a T Î³(t)âˆ’Î³(a)- = âˆ‡f (Î³(a)) litâ†’ma
    [ tâˆ’ a + o(1)] T â€² = âˆ‡f (Î³(a)) Î³ (a), ](img/file1532.png)'
- en: which is what we had to prove.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬è¦è¯æ˜çš„ã€‚
- en: 16.2.2 The Jacobian and Hessian matrices
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2.2 é›…å¯æ¯”çŸ©é˜µå’Œæµ·æ£®çŸ©é˜µ
- en: 'Now, our task is to extend the derivative for vector-vector functions, so let
    f : â„^n â†’â„^m be one. By writing out the output of f explicitly, we can decompose
    it into multiple components:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç°åœ¨ï¼Œæˆ‘ä»¬çš„ä»»åŠ¡æ˜¯å°†å¯¼æ•°æ‰©å±•åˆ°å‘é‡-å‘é‡å‡½æ•°ã€‚è®¾ f : â„^n â†’â„^m ä¸ºä¸€ä¸ªè¿™æ ·çš„å‡½æ•°ã€‚é€šè¿‡æ˜¾å¼åœ°å†™å‡º f çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶åˆ†è§£ä¸ºå¤šä¸ªåˆ†é‡ï¼š'
- en: '![ âŒŠ âŒ‹ | f1(x )| f(x) = |âŒˆ ... |âŒ‰ âˆˆ â„m (Ã—1) fm(x ) ](img/file1533.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ | f1(x )| f(x) = |âŒˆ ... |âŒ‰ âˆˆ â„m (Ã—1) fm(x ) ](img/file1533.png)'
- en: 'where f[i] : â„^n â†’â„ are vector-scalar functions.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 'å…¶ä¸­ f[i] : â„^n â†’â„ æ˜¯å‘é‡-æ ‡é‡å‡½æ•°ã€‚'
- en: The natural idea is to compute the partial derivatives for f[i], compacting
    them into a matrix. And so we shall!
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç„¶çš„æƒ³æ³•æ˜¯è®¡ç®— f[i] çš„åå¯¼æ•°ï¼Œå°†å®ƒä»¬å‹ç¼©æˆä¸€ä¸ªçŸ©é˜µã€‚æˆ‘ä»¬å°±è¿™ä¹ˆåšï¼
- en: Definition 70\. (The Jacobian matrix)
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 70.ï¼ˆé›…å¯æ¯”çŸ©é˜µï¼‰
- en: 'Let f : â„^n â†’â„^m be an arbitrary vector-vector function, and suppose that'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ f : â„^n â†’â„^m ä¸ºä»»æ„çš„å‘é‡-å‘é‡å‡½æ•°ï¼Œå‡è®¾'
- en: '![f(x) = (f (x ),...,f (x)), 1 m ](img/file1534.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![f(x) = (f (x ),...,f (x)), 1 m ](img/file1534.png)'
- en: 'where all f[i] : â„^n â†’ â„ are (partially) differentiable at some a âˆˆ â„^n. The
    matrix'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 'å…¶ä¸­æ‰€æœ‰çš„ f[i] : â„^n â†’ â„ éƒ½æ˜¯åœ¨æŸä¸ª a âˆˆ â„^n å¤„ï¼ˆéƒ¨åˆ†ï¼‰å¯å¾®çš„ã€‚çŸ©é˜µä¸º'
- en: '![ âŒŠ âˆ‚f1 âˆ‚f1 âˆ‚f1 âŒ‹ | âˆ‚x1(a) âˆ‚x2(a) ... âˆ‚xn(a)| | âˆ‚f2(a) âˆ‚f2(a) ... âˆ‚f2(a)|
    Jf(a) := || âˆ‚x1\. âˆ‚x2\. . âˆ‚xn. || âˆˆ â„m Ã—n |âŒˆ .. .. .. .. |âŒ‰ âˆ‚fm- âˆ‚fm- âˆ‚fm-- âˆ‚x1
    (a) âˆ‚x2 (a) ... âˆ‚xn(a) ](img/file1535.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âˆ‚f1 âˆ‚f1 âˆ‚f1 âŒ‹ | âˆ‚x1(a) âˆ‚x2(a) ... âˆ‚xn(a)| | âˆ‚f2(a) âˆ‚f2(a) ... âˆ‚f2(a)|
    Jf(a) := || âˆ‚x1\. âˆ‚x2\. . âˆ‚xn. || âˆˆ â„m Ã—n |âŒˆ .. .. .. .. |âŒ‰ âˆ‚fm- âˆ‚fm- âˆ‚fm-- âˆ‚x1
    (a) âˆ‚x2 (a) ... âˆ‚xn(a) ](img/file1535.png)'
- en: is called the Jacobian of f at a.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¢«ç§°ä¸º f åœ¨ a å¤„çš„ Jacobianã€‚
- en: 'In other words, the rows of the Jacobian are the gradients of f[i]:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼ŒJacobian çš„è¡Œæ˜¯ f[i] çš„æ¢¯åº¦ï¼š
- en: '![ âŒŠ T âŒ‹ | âˆ‡f1(a) | || âˆ‡f2(a)T || || . || Jf(a) = | .. |. ||âˆ‡f (a )T || âŒˆ m
    âŒ‰ ](img/file1536.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ T âŒ‹ | âˆ‡f1(a) | || âˆ‡f2(a)T || || . || Jf(a) = | .. |. ||âˆ‡f (a )T || âŒˆ m
    âŒ‰ ](img/file1536.png)'
- en: 'I have good news: the best local linear approximation of f around a is given
    by'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æœ‰ä¸ªå¥½æ¶ˆæ¯ï¼šf åœ¨ a é™„è¿‘çš„æœ€ä½³å±€éƒ¨çº¿æ€§è¿‘ä¼¼ç”±ä¸‹å¼ç»™å‡º
- en: '![f(x ) = f(a)+ J (a)(x âˆ’ a)+ o(âˆ¥x âˆ’ aâˆ¥), f ](img/file1537.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![f(x ) = f(a)+ J (a)(x âˆ’ a)+ o(âˆ¥x âˆ’ aâˆ¥), f ](img/file1537.png)'
- en: if the best local linear approximation exists. Thus, the Jacobian is a proper
    generalization of the gradient.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæœ€ä½³å±€éƒ¨çº¿æ€§è¿‘ä¼¼å­˜åœ¨ã€‚äºæ˜¯ï¼ŒJacobian æˆä¸ºæ¢¯åº¦çš„é€‚å½“æ¦‚æ‹¬ã€‚
- en: 'We can use the Jacobian to generalize the notion of second-order derivatives
    for vector-scalar functions: by computing the Jacobian of the gradient, we obtain
    a special matrix, the analogue of the second derivative.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ Jacobian æ¥æ¦‚æ‹¬å‘é‡-æ ‡é‡å‡½æ•°çš„äºŒé˜¶å¯¼æ•°çš„æ¦‚å¿µï¼šé€šè¿‡è®¡ç®—æ¢¯åº¦çš„ Jacobianï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªç‰¹æ®Šçš„çŸ©é˜µï¼Œå®ƒæ˜¯äºŒé˜¶å¯¼æ•°çš„ç±»æ¯”ã€‚
- en: Definition 71\. (The Hessian matrix)
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 71.ï¼ˆHessian çŸ©é˜µï¼‰
- en: 'Let f : â„^n â†’â„ be an arbitrary vector-scalar function, and suppose that all
    of its second-order partial derivatives exist at a âˆˆâ„^n.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ f : â„^n â†’â„ æ˜¯ä¸€ä¸ªä»»æ„çš„å‘é‡-æ ‡é‡å‡½æ•°ï¼Œå¹¶å‡è®¾å…¶æ‰€æœ‰äºŒé˜¶åå¯¼æ•°åœ¨ a âˆˆâ„^n å¤„å­˜åœ¨ã€‚'
- en: The matrix
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ©é˜µ
- en: '![ âŒŠ âŒ‹ âˆ‚2f2(a) -âˆ‚2f-(a) ... -âˆ‚2f-(a) || âˆ‚x21 âˆ‚x1âˆ‚2x2 âˆ‚x1âˆ‚2xn || || âˆ‚âˆ‚x2fâˆ‚x1(a
    ) âˆ‚âˆ‚xf2(a) ... âˆ‚xâˆ‚2âˆ‚fxn(a)|| nÃ—n Hf (a) := | .. 2.. .. .. | âˆˆ â„ |âŒˆ . . . . |âŒ‰
    -âˆ‚2f--(a ) -âˆ‚2f-(a) ... âˆ‚2f2(a) âˆ‚xnâˆ‚x1 âˆ‚xnâˆ‚x2 âˆ‚xn ](img/file1538.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ âˆ‚2f2(a) -âˆ‚2f-(a) ... -âˆ‚2f-(a) || âˆ‚x21 âˆ‚x1âˆ‚2x2 âˆ‚x1âˆ‚2xn || || âˆ‚âˆ‚x2fâˆ‚x1(a
    ) âˆ‚âˆ‚xf2(a) ... âˆ‚xâˆ‚2âˆ‚fxn(a)|| nÃ—n Hf (a) := | .. 2.. .. .. | âˆˆ â„ |âŒˆ . . . . |âŒ‰
    -âˆ‚2f--(a ) -âˆ‚2f-(a) ... âˆ‚2f2(a) âˆ‚xnâˆ‚x1 âˆ‚xnâˆ‚x2 âˆ‚xn ](img/file1538.png)'
- en: is called the Hessian of f at a.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¢«ç§°ä¸º f åœ¨ a å¤„çš„ Hessianã€‚
- en: In other words,
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œ
- en: '![Hf (a) = J âˆ‡f(a)T ](img/file1539.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![Hf (a) = J âˆ‡f(a)T ](img/file1539.png)'
- en: holds by definition. Moreover, if f behaves nicely (for instance, all second-order
    partial derivatives exist and are continuous), TheoremÂ [98](ch026.xhtml#x1-456002r98)
    implies that the Hessian is symmetric; that is, H[f](a) = H[f](a)^T .
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å®šä¹‰å¾—ä»¥æˆç«‹ã€‚æ­¤å¤–ï¼Œå¦‚æœ f è¡Œä¸ºè‰¯å¥½ï¼ˆä¾‹å¦‚ï¼Œæ‰€æœ‰äºŒé˜¶åå¯¼æ•°éƒ½å­˜åœ¨ä¸”è¿ç»­ï¼‰ï¼Œå®šç†[98](ch026.xhtml#x1-456002r98)è¡¨æ˜ Hessian
    æ˜¯å¯¹ç§°çš„ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼ŒH[f](a) = H[f](a)^Tã€‚
- en: 16.2.3 The total derivative for vector-vector functions
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2.3 å‘é‡-å‘é‡å‡½æ•°çš„æ€»å¯¼æ•°
- en: One last generalization. (I promise.) Recall that the existence of the gradient
    (that is, partial differentiability) doesnâ€™t imply total differentiability for
    vector-scalar functions, as the example
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€ä¸ªæ¦‚æ‹¬ã€‚ï¼ˆæˆ‘ä¿è¯ã€‚ï¼‰å›å¿†ä¸€ä¸‹ï¼Œæ¢¯åº¦çš„å­˜åœ¨ï¼ˆå³ï¼Œéƒ¨åˆ†å¯å¾®æ€§ï¼‰å¹¶ä¸æ„å‘³ç€å‘é‡-æ ‡é‡å‡½æ•°çš„æ•´ä½“å¯å¾®æ€§ï¼Œå¦‚è¯¥ä¾‹æ‰€ç¤º
- en: '![ ( |{ f (x, y) = 1 if x = 0 or y = 0, |( 0 otherwise ](img/file1540.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![ ( |{ f (x, y) = 1 if x = 0 or y = 0, |( 0 otherwise ](img/file1540.png)'
- en: shows at zero.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾ç¤ºåœ¨é›¶å¤„ã€‚
- en: This is true for vector-vector functions as well, as the Jacobian is the generalization
    of the gradient, not the total derivative.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå‘é‡-å‘é‡å‡½æ•°åŒæ ·æˆç«‹ï¼Œå› ä¸º Jacobian æ˜¯æ¢¯åº¦çš„æ¦‚æ‹¬ï¼Œè€Œä¸æ˜¯æ€»å¯¼æ•°ã€‚
- en: It is best to rip the band-aid off quickly and define the total derivative for
    vector-vector functions. The definition will be a bit abstract, but trust me,
    the investment will pay off when talking about the chain rule. (Which is the foundation
    of backpropagation, the algorithm that makes gradient descent computationally
    feasible.)
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å¥½å¿«é€Ÿâ€œæ’•ä¸‹åˆ›å¯è´´â€ï¼Œå¹¶ä¸ºå‘é‡-å‘é‡å‡½æ•°å®šä¹‰æ€»å¯¼æ•°ã€‚è¿™ä¸ªå®šä¹‰å¯èƒ½æœ‰ç‚¹æŠ½è±¡ï¼Œä½†ç›¸ä¿¡æˆ‘ï¼Œè¿™é¡¹æŠ•èµ„å°†åœ¨è®¨è®ºé“¾å¼æ³•åˆ™æ—¶å¾—åˆ°å›æŠ¥ã€‚ï¼ˆé“¾å¼æ³•åˆ™æ˜¯åå‘ä¼ æ’­ç®—æ³•çš„åŸºç¡€ï¼Œè€Œåå‘ä¼ æ’­ä½¿å¾—æ¢¯åº¦ä¸‹é™çš„è®¡ç®—æˆä¸ºå¯èƒ½ã€‚ï¼‰
- en: Definition 72\. (Total differentiability of vector-vector functions)
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 72.ï¼ˆå‘é‡-å‘é‡å‡½æ•°çš„æ•´ä½“å¯å¾®æ€§ï¼‰
- en: 'Let f : â„^n â†’â„^m be an arbitrary vector-vector function. We say that f is totally
    differentiable (or sometimes just differentiable in short) at a âˆˆâ„^n if there
    exists a matrixD[f](a) âˆˆâ„^(mÃ—n) such that'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ f : â„^n â†’â„^m æ˜¯ä¸€ä¸ªä»»æ„çš„å‘é‡-å‘é‡å‡½æ•°ã€‚æˆ‘ä»¬è¯´ f åœ¨ a âˆˆâ„^n å¤„æ˜¯æ•´ä½“å¯å¾®çš„ï¼ˆæˆ–ç®€ç•¥åœ°ç§°ä¸ºå¯å¾®çš„ï¼‰ï¼Œå¦‚æœå­˜åœ¨çŸ©é˜µ D[f](a)
    âˆˆâ„^(mÃ—n)ï¼Œä½¿å¾—'
- en: f(x) = f(a) + D[f](a)(x âˆ’ a) + o(âˆ¥x âˆ’ aâˆ¥) (16.9)
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: f(x) = f(a) + D[f](a)(x âˆ’ a) + o(âˆ¥x âˆ’ aâˆ¥)ï¼ˆ16.9ï¼‰
- en: holds for all x âˆˆB(ğœ€,a), where ğœ€/span>0 and B(ğœ€,a) is defined by
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ‰€æœ‰ x âˆˆB(ğœ–,a) éƒ½æˆç«‹ï¼Œå…¶ä¸­ ğœ–/span>0 ä¸” B(ğœ–,a) å®šä¹‰ä¸º
- en: '![B(ğœ€,a) = {x âˆˆ â„n : âˆ¥x âˆ’ aâˆ¥ <ğœ€}. ](img/file1541.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![B(ğœ–,a) = {x âˆˆ â„n : âˆ¥x âˆ’ aâˆ¥ <ğœ–}. ](img/file1541.png)'
- en: (In other words, B(ğœ€,a) is a ball of radius ğœ€/span>0 around a.) When exists,
    the matrix D[f](a) is called the total derivative of f at a.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆæ¢å¥è¯è¯´ï¼ŒB(ğœ–,a) æ˜¯ä»¥ a ä¸ºä¸­å¿ƒã€åŠå¾„ä¸º ğœ–/span>0 çš„çƒä½“ã€‚ï¼‰å½“å­˜åœ¨æ—¶ï¼ŒçŸ©é˜µ D[f](a) è¢«ç§°ä¸º f åœ¨ a å¤„çš„æ€»å¯¼æ•°ã€‚
- en: Notice that DefinitionÂ [72](ch026.xhtml#x1-263002r72) is almost verbatim to
    DefinitionÂ [68](ch026.xhtml#x1-257003r68), except that the â€œderivativeâ€ is a matrix
    this time.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„åˆ°å®šä¹‰[72](ch026.xhtml#x1-263002r72)å‡ ä¹ä¸å®šä¹‰[68](ch026.xhtml#x1-257003r68)å®Œå…¨ç›¸åŒï¼Œå”¯ä¸€ä¸åŒçš„æ˜¯è¿™æ¬¡â€œå¯¼æ•°â€æ˜¯ä¸€ä¸ªçŸ©é˜µã€‚
- en: You are probably not surprised to hear that its relation with the Jacobian is
    the same as the gradient and the total derivative in the vector-scalar case.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½ä¸æƒŠè®¶åœ°å¬åˆ°ï¼Œå®ƒä¸é›…å¯æ¯”çŸ©é˜µçš„å…³ç³»ä¸å‘é‡-æ ‡é‡æƒ…å†µä¸‹çš„æ¢¯åº¦å’Œå…¨å¯¼æ•°ç›¸åŒã€‚
- en: Theorem 103\. (Total derivative and the partial derivatives)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç†103.ï¼ˆå…¨å¯¼æ•°ä¸åå¯¼æ•°ï¼‰
- en: 'Let f : â„^n â†’â„^m be a function that is totally differentiable at a âˆˆâ„^n. Then,
    all of its partial derivatives exist at a and'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾f : â„^n â†’â„^mæ˜¯ä¸€ä¸ªåœ¨a âˆˆâ„^nå¤„å®Œå…¨å¯å¾®çš„å‡½æ•°ã€‚é‚£ä¹ˆï¼Œå®ƒçš„æ‰€æœ‰åå¯¼æ•°åœ¨aå¤„å­˜åœ¨ï¼Œå¹¶ä¸”'
- en: '![Df (a) = Jf(a ). ](img/file1542.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![Df (a) = Jf(a ). ](img/file1542.png)'
- en: The proof is almost identical to the one of TheoremÂ [99](ch026.xhtml#x1-257006r99),
    with more complex notations. I strongly recommend you work it out line by line,
    as this kind of mental gymnastics helps significantly to get used to matrices
    in practice.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜å‡ ä¹ä¸å®šç†[99](ch026.xhtml#x1-257006r99)çš„è¯æ˜ç›¸åŒï¼Œåªæ˜¯ç¬¦å·æ›´å¤æ‚ã€‚æˆ‘å¼ºçƒˆå»ºè®®ä½ é€è¡Œæ¨å¯¼ï¼Œå› ä¸ºè¿™ç§è„‘åŠ›è®­ç»ƒæœ‰åŠ©äºä½ æ›´å¥½åœ°é€‚åº”çŸ©é˜µçš„å®é™…åº”ç”¨ã€‚
- en: Componentwise, the total derivative can be written as
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‰åˆ†é‡æ¥çœ‹ï¼Œå…¨å¯¼æ•°å¯ä»¥å†™æˆ
- en: '![ âŒŠ âˆ‚f1 âˆ‚f1 âˆ‚f1- âŒ‹ | âˆ‚x1(a) âˆ‚x2(a) ... âˆ‚xn (a )| | âˆ‚f2(a) âˆ‚f2(a) ... âˆ‚f2-(a
    )| Df(a) = || âˆ‚x1\. âˆ‚x2\. . âˆ‚xn. ||âˆˆ â„m Ã—n. |âŒˆ .. .. .. .. |âŒ‰ âˆ‚fm-(a) âˆ‚fm(a) ...
    âˆ‚fm-(a) âˆ‚x1 âˆ‚x2 âˆ‚xn ](img/file1543.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âˆ‚f1 âˆ‚f1 âˆ‚f1- âŒ‹ | âˆ‚x1(a) âˆ‚x2(a) ... âˆ‚xn (a )| | âˆ‚f2(a) âˆ‚f2(a) ... âˆ‚f2-(a
    )| Df(a) = || âˆ‚x1\. âˆ‚x2\. . âˆ‚xn. ||âˆˆ â„m Ã—n. |âŒˆ .. .. .. .. |âŒ‰ âˆ‚fm-(a) âˆ‚fm(a) ...
    âˆ‚fm-(a) âˆ‚x1 âˆ‚x2 âˆ‚xn ](img/file1543.png)'
- en: By introducing the notation
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¼•å…¥è®°å·
- en: '![ âŒŠ âŒ‹ âˆ‚âˆ‚fx1(a ) || âˆ‚fi2 || || âˆ‚xi(a )|| -âˆ‚f(a) = | ... | âˆˆ â„m Ã—1, âˆ‚xi || âˆ‚f
    || |âŒˆ âˆ‚mxi (a)|âŒ‰ ](img/file1544.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ âˆ‚âˆ‚fx1(a ) || âˆ‚fi2 || || âˆ‚xi(a )|| -âˆ‚f(a) = | ... | âˆˆ â„m Ã—1, âˆ‚xi || âˆ‚f
    || |âŒˆ âˆ‚mxi (a)|âŒ‰ ](img/file1544.png)'
- en: the total derivative D[f](a) can be written in the block-forms
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: å…¨å¯¼æ•°D[f](a)å¯ä»¥å†™æˆå—çŠ¶å½¢å¼ã€‚
- en: '![ [-âˆ‚f -âˆ‚f -âˆ‚f ] Df (a ) = âˆ‚x1(a) âˆ‚x2(a) ... âˆ‚xn(a) ](img/file1545.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![ [-âˆ‚f -âˆ‚f -âˆ‚f ] Df (a ) = âˆ‚x1(a) âˆ‚x2(a) ... âˆ‚xn(a) ](img/file1545.png)'
- en: and
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œ
- en: '![ âŒŠ âŒ‹ âˆ‡f1 (a )T || T || D (a ) = || âˆ‡f2 (a ) || . f | ... | âŒˆ âŒ‰ âˆ‡fm (a)T ](img/file1546.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ âˆ‡f1 (a )T || T || D (a ) = || âˆ‡f2 (a ) || . f | ... | âŒˆ âŒ‰ âˆ‡fm (a)T ](img/file1546.png)'
- en: 16.2.4 Derivatives and function operations
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2.4 å¯¼æ•°ä¸å‡½æ•°è¿ç®—
- en: 'We have generalized the notion of derivatives as far as possible for us. Now
    itâ€™s time to study their relations with the two essential function operations:
    addition and composition. (As there is no vector multiplication in higher dimensional
    spaces, the product and ratio of vector-vector functions are undefined.)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»å°†å¯¼æ•°çš„æ¦‚å¿µæ¨å¹¿åˆ°å°½å¯èƒ½å¹¿æ³›çš„ç¨‹åº¦ã€‚ç°åœ¨æ˜¯æ—¶å€™ç ”ç©¶å®ƒä»¬ä¸ä¸¤ä¸ªåŸºæœ¬çš„å‡½æ•°è¿ç®—â€”â€”åŠ æ³•å’Œå¤åˆâ€”â€”ä¹‹é—´çš„å…³ç³»äº†ã€‚ï¼ˆç”±äºé«˜ç»´ç©ºé—´ä¸­æ²¡æœ‰å‘é‡ä¹˜æ³•ï¼Œå‘é‡-å‘é‡å‡½æ•°çš„ä¹˜ç§¯å’Œæ¯”å€¼æ˜¯æœªå®šä¹‰çš„ã€‚ï¼‰
- en: 'Letâ€™s start with the simpler one: addition.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»æ›´ç®€å•çš„å¼€å§‹ï¼šåŠ æ³•ã€‚
- en: Theorem 104\. (Linearity of the total derivative)
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç†104.ï¼ˆå…¨å¯¼æ•°çš„çº¿æ€§æ€§è´¨ï¼‰
- en: 'Let f,g : â„^n â†’â„^m be two vector-vector functions that are differentiable at
    some a âˆˆâ„^n, and let Î±,Î² âˆˆâ„ be two arbitrary scalars.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾f,g : â„^n â†’â„^mæ˜¯ä¸¤ä¸ªåœ¨æŸä¸ªa âˆˆâ„^nå¤„å¯å¾®çš„å‘é‡-å‘é‡å‡½æ•°ï¼Œä¸”è®¾Î±,Î² âˆˆâ„ä¸ºä¸¤ä¸ªä»»æ„æ ‡é‡ã€‚'
- en: Then, Î±f + Î²g is also differentiable at a and
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼ŒÎ±f + Î²gåœ¨aå¤„ä¹Ÿæ˜¯å¯å¾®çš„ï¼Œå¹¶ä¸”
- en: '![D Î±f+ Î²g(a) = Î±Df (a)+ Î²Dg (a ) ](img/file1547.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![D Î±f+ Î²g(a) = Î±Df (a)+ Î²Dg (a ) ](img/file1547.png)'
- en: there.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£é‡Œã€‚
- en: Proof. Because of the total differentiability, ([16.9](ch026.xhtml#x1-263002r72))
    implies that
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚ç”±äºå…¨å¾®åˆ†ï¼Œï¼ˆ[16.9](ch026.xhtml#x1-263002r72)ï¼‰æ„å‘³ç€
- en: '![Î±f(x) + Î²g(x) = Î±f(a) + Î²g(a) + (Î±D (a )+ Î²D (a))(x âˆ’ a) f g + o(âˆ¥xâˆ’ aâˆ¥),
    ](img/file1548.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![Î±f(x) + Î²g(x) = Î±f(a) + Î²g(a) + (Î±D (a )+ Î²D (a))(x âˆ’ a) f g + o(âˆ¥xâˆ’ aâˆ¥),
    ](img/file1548.png)'
- en: which implies
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€
- en: '![DÎ±f+Î²g(a) = Î±Df (a)+ Î²Dg (a). ](img/file1549.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![DÎ±f+Î²g(a) = Î±Df (a)+ Î²Dg (a). ](img/file1549.png)'
- en: This is what we had to show.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬éœ€è¦å±•ç¤ºçš„å†…å®¹ã€‚
- en: Linearity is always nice, but what we need is the ultimate generalization of
    the chain rule. We previously saw the special case of composing a scalar-vector
    and a vector-vector function (see TheoremÂ [102](ch026.xhtml#x1-261003r102)), but
    we need to go one step further.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§æ˜¯å§‹ç»ˆå¯å–çš„ï¼Œä½†æˆ‘ä»¬éœ€è¦çš„æ˜¯é“¾å¼æ³•åˆ™çš„ç»ˆææ¨å¹¿ã€‚æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°è¿‡æ ‡é‡-å‘é‡å’Œå‘é‡-å‘é‡å‡½æ•°çš„ç‰¹æ®Šæƒ…å†µï¼ˆè§å®šç†[102](ch026.xhtml#x1-261003r102)ï¼‰ï¼Œä½†æˆ‘ä»¬éœ€è¦æ›´è¿›ä¸€æ­¥ã€‚
- en: The multivariable chain rule is extremely important in machine learning. A neural
    network is a composite function, with layers acting as components. During gradient
    descent, we use the chain rule to calculate the derivative of this composition.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šå˜é‡é“¾å¼æ³•åˆ™åœ¨æœºå™¨å­¦ä¹ ä¸­æå…¶é‡è¦ã€‚ç¥ç»ç½‘ç»œæ˜¯ä¸€ä¸ªå¤åˆå‡½æ•°ï¼Œå±‚æ¬¡ç»“æ„å……å½“äº†å…¶ç»„æˆéƒ¨åˆ†ã€‚åœ¨æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨é“¾å¼æ³•åˆ™æ¥è®¡ç®—è¿™ä¸ªå¤åˆå‡½æ•°çš„å¯¼æ•°ã€‚
- en: Theorem 105\. (Multivariable chain rule)
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç†105.ï¼ˆå¤šå˜é‡é“¾å¼æ³•åˆ™ï¼‰
- en: 'Let f : â„^m â†’â„^l and g : â„^n â†’â„^m be two vector-vector functions. If g is totally
    differentiable at a âˆˆâ„^n and f is totally differentiable at g(a), then f âˆ˜g is
    also totally differentiable at a and'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾f : â„^m â†’â„^lï¼Œg : â„^n â†’â„^mæ˜¯ä¸¤ä¸ªå‘é‡-å‘é‡å‡½æ•°ã€‚å¦‚æœgåœ¨a âˆˆ â„^nå¤„å®Œå…¨å¯å¾®ï¼Œä¸”fåœ¨g(a)å¤„å®Œå…¨å¯å¾®ï¼Œåˆ™f âˆ˜gåœ¨aå¤„ä¹Ÿå®Œå…¨å¯å¾®ï¼Œå¹¶ä¸”'
- en: D[fâˆ˜g](a) = D[f](g(a)) D[g](a) (16.10)
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: D[fâˆ˜g](a) = D[f](g(a)) D[g](a) (16.10)
- en: holds.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: æˆç«‹ã€‚
- en: To our advantage, the derivative of a composed function ([16.10](ch026.xhtml#x1-264004r105))
    is given by the product of two matrices. Since matrix multiplication can be done
    lightning fast, this is good news.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æˆ‘ä»¬æœ‰åˆ©çš„æ˜¯ï¼Œå¤åˆå‡½æ•°çš„å¯¼æ•°ï¼ˆ[16.10](ch026.xhtml#x1-264004r105)ï¼‰ç”±ä¸¤ä¸ªçŸ©é˜µçš„ä¹˜ç§¯ç»™å‡ºã€‚ç”±äºçŸ©é˜µä¹˜æ³•å¯ä»¥å¿«é€Ÿè¿›è¡Œï¼Œè¿™æ˜¯ä¸ªå¥½æ¶ˆæ¯ã€‚
- en: We will see two proofs for TheoremÂ [105](ch026.xhtml#x1-264004r105). One is
    done with a faster-than-light engine, while the other shows much more by reducing
    the general case to TheoremÂ [102](ch026.xhtml#x1-261003r102). Both provide a ton
    of insight. Letâ€™s start with the heavy machinery.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†çœ‹åˆ°å®šç†[105](ch026.xhtml#x1-264004r105)çš„ä¸¤ä¸ªè¯æ˜ã€‚ä¸€ä¸ªä½¿ç”¨è¶…å…‰é€Ÿå¼•æ“ï¼Œå¦ä¸€ä¸ªé€šè¿‡å°†ä¸€èˆ¬æƒ…å†µç®€åŒ–ä¸ºå®šç†[102](ch026.xhtml#x1-261003r102)å±•ç¤ºäº†æ›´å¤šå†…å®¹ã€‚ä¸¤è€…éƒ½æä¾›äº†ä¸°å¯Œçš„è§è§£ã€‚è®©æˆ‘ä»¬ä»é‡å‹æœºæ¢°å¼€å§‹ã€‚
- en: Proof. (First method.)
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚ï¼ˆç¬¬ä¸€ç§æ–¹æ³•ã€‚ï¼‰
- en: As f is totally differentiable at g(a), the equation ([16.9](ch026.xhtml#x1-263002r72))
    implies
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºfåœ¨g(a)å¤„å®Œå…¨å¯å¾®ï¼Œæ–¹ç¨‹ï¼ˆ[16.9](ch026.xhtml#x1-263002r72)ï¼‰æ„å‘³ç€
- en: '![f(g(x)) = f(g(a))+ D (g (a ))(g(x) âˆ’ g(a))+ o(âˆ¥g(x)âˆ’ g(a)âˆ¥). f ](img/file1550.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![f(g(x)) = f(g(a)) + D(g(a))(g(x) âˆ’ g(a)) + o(âˆ¥g(x) âˆ’ g(a)âˆ¥). f ](img/file1550.png)'
- en: In turn, again because of the total differentiability of g at a, we have
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: åè¿‡æ¥ï¼Œç”±äºgåœ¨aå¤„å®Œå…¨å¯å¾®ï¼Œæˆ‘ä»¬æœ‰
- en: '![g(x)âˆ’ g(a) = Dg (a)(xâˆ’ a)+ o(âˆ¥x âˆ’ aâˆ¥). ](img/file1551.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![g(x)âˆ’ g(a) = Dg (a)(xâˆ’ a)+ o(âˆ¥x âˆ’ aâˆ¥). ](img/file1551.png)'
- en: Thus, we can continue our calculation by
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­è®¡ç®—
- en: '![f(g (x )) = f(g(a))+ Df (g(a))(g(x )âˆ’ g(a))+ o(âˆ¥g(x) âˆ’ g(a)âˆ¥) = f(g(a))+
    D (g(a))D (a)(x âˆ’ a) f g + Df (g (a ))[o(âˆ¥xâˆ’ a âˆ¥)+ o(âˆ¥g(x)âˆ’ g(a)âˆ¥)], â—Ÿ-----------------â—â—œ----------------â—
    =o (âˆ¥xâˆ’aâˆ¥) ](img/file1552.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![f(g (x )) = f(g(a)) + Df (g(a))(g(x )âˆ’ g(a)) + o(âˆ¥g(x) âˆ’ g(a)âˆ¥) = f(g(a))
    + D (g(a))D (a)(x âˆ’ a) f g + Df (g (a ))[o(âˆ¥xâˆ’ a âˆ¥)+ o(âˆ¥g(x)âˆ’ g(a)âˆ¥)], â—Ÿ-----------------â—â—œ----------------â—
    =o (âˆ¥xâˆ’aâˆ¥) ](img/file1552.png)'
- en: showing that f âˆ˜g is totally differentiable at a with total derivative
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜f âˆ˜gåœ¨aå¤„å®Œå…¨å¯å¾®ï¼Œä¸”å…·æœ‰å…¨å¯¼æ•°
- en: '![Dfâˆ˜g(a) = Df(g (a ))Dg (a), ](img/file1553.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![Dfâˆ˜g(a) = Df(g(a))Dg(a), ](img/file1553.png)'
- en: which is what we needed to show.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬éœ€è¦å±•ç¤ºçš„å†…å®¹ã€‚
- en: Now, about that second proof.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå…³äºç¬¬äºŒä¸ªè¯æ˜ã€‚
- en: Proof. (Second method.)
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚ï¼ˆç¬¬äºŒç§æ–¹æ³•ã€‚ï¼‰
- en: Letâ€™s unpack D[fâˆ˜g](a) a bit. Writing out the components of f âˆ˜g, we have
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç¨å¾®åˆ†æä¸€ä¸‹D[fâˆ˜g](a)ã€‚å†™å‡ºfâˆ˜gçš„å„ä¸ªç»„æˆéƒ¨åˆ†ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![ âŒŠ âŒ‹ | (f âˆ˜g )1(x )| | (f âˆ˜g )2(x )| (f âˆ˜ g)(x) = || . || âˆˆ â„l, x âˆˆ â„n. |âŒˆ
    .. |âŒ‰ (f âˆ˜ g)(x) l ](img/file1554.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ | (f âˆ˜g )1(x )| | (f âˆ˜g )2(x )| (f âˆ˜ g)(x) = || . || âˆˆ â„l, x âˆˆ â„n. |âŒˆ
    .. |âŒ‰ (f âˆ˜ g)(x) l ](img/file1554.png)'
- en: By definition, the i-th row and j-th column of D[fâˆ˜g](a) is
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®å®šä¹‰ï¼ŒD[fâˆ˜g](a)çš„ç¬¬iè¡Œç¬¬jåˆ—æ˜¯
- en: '![ âˆ‚ (f âˆ˜g )i (Dfâˆ˜g(a))i,j = ---âˆ‚x---(a). j ](img/file1555.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‚ (f âˆ˜g )i (Dfâˆ˜g(a))i,j = ---âˆ‚x---(a). j ](img/file1555.png)'
- en: If you look at it long enough, youâ€™ll realize that ![âˆ‚(fâˆ˜g) --âˆ‚xji](img/file1556.png)(a)
    is the derivative of a single variable function. Indeed, the function to be differentiated
    is the composition of the curve
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¶³å¤Ÿé•¿æ—¶é—´çœ‹å®ƒï¼Œä½ ä¼šæ„è¯†åˆ°![âˆ‚(fâˆ˜g) --âˆ‚xji](img/file1556.png)(a)æ˜¯å•å˜é‡å‡½æ•°çš„å¯¼æ•°ã€‚äº‹å®ä¸Šï¼Œè¦æ±‚å¯¼çš„å‡½æ•°æ˜¯æ›²çº¿çš„ç»„åˆ
- en: '![Î³ : t â†¦â†’ g(a1,...,ajâˆ’1,t,aj+1,...,an) ](img/file1557.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![Î³ : t â†¦â†’ g(a1,...,ajâˆ’1,t,aj+1,...,an) ](img/file1557.png)'
- en: 'and the vector-scalar function f[i] : â„^m â†’ â„. Thus, the chain rule for the
    composition of scalar-vector and vector-scalar functions (given by TheoremÂ [102](ch026.xhtml#x1-261003r102))
    can be applied:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä»¥åŠå‘é‡-æ ‡é‡å‡½æ•°f[i] : â„^m â†’ â„ã€‚å› æ­¤ï¼Œæ ‡é‡-å‘é‡å’Œå‘é‡-æ ‡é‡å‡½æ•°çš„é“¾å¼æ³•åˆ™ï¼ˆç”±å®šç†[102](ch026.xhtml#x1-261003r102)ç»™å‡ºï¼‰å¯ä»¥åº”ç”¨ï¼š'
- en: '![âˆ‚(f âˆ˜g)i T âˆ‚ --âˆ‚x----(a) = âˆ‡fi(g(a)) âˆ‚x--g(a), j j ](img/file1558.png)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚(f âˆ˜g)i T âˆ‚ --âˆ‚x----(a) = âˆ‡fi(g(a)) âˆ‚x--g(a), j j ](img/file1558.png)'
- en: where ![âˆ‚âˆ‚xj](img/file1559.png)g(a) is the componentwise derivative
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­![âˆ‚âˆ‚xj](img/file1559.png)g(a)æ˜¯æŒ‰åˆ†é‡è®¡ç®—çš„å¯¼æ•°
- en: '![ âŒŠ âŒ‹ âˆ‚g1(a) || âˆ‚âˆ‚g2xj(a)|| -âˆ‚-- || -âˆ‚xj--|| âˆ‚xj g(a) = | .. | . |âŒˆ . |âŒ‰ âˆ‚gmâˆ‚(xa)
    j ](img/file1560.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ âˆ‚g1(a) || âˆ‚âˆ‚g2xj(a)|| -âˆ‚-- || -âˆ‚xj--|| âˆ‚xj g(a) = | .. | . |âŒˆ . |âŒ‰ âˆ‚gmâˆ‚(xa)
    j ](img/file1560.png)'
- en: To sum up, we have
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“ä¸€ä¸‹ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![ ](img/file1561.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![ ](img/file1561.png)'
- en: This is the element in the i-th row and j-th column of the matrix product D[f](g(a))D[g](a),
    hence
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯çŸ©é˜µä¹˜ç§¯D[f](g(a))D[g](a)ä¸­ç¬¬iè¡Œç¬¬jåˆ—çš„å…ƒç´ ï¼Œå› æ­¤
- en: '![ ](img/file1562.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![ ](img/file1562.png)'
- en: which is what we had to show.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬å¿…é¡»å±•ç¤ºçš„å†…å®¹ã€‚
- en: With the concept of total derivatives for vector-vector functions and the general
    chain rule under our belt, we are ready to actually do things with multivariable
    functions. Thus, our next stop lays the foundations of optimization.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æŒæ¡å‘é‡-å‘é‡å‡½æ•°çš„å…¨å¯¼æ•°æ¦‚å¿µå’Œä¸€èˆ¬çš„é“¾å¼æ³•åˆ™ï¼Œæˆ‘ä»¬å‡†å¤‡å¥½å®é™…å¤„ç†å¤šå˜é‡å‡½æ•°äº†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„ä¸‹ä¸€ç«™æ˜¯å¥ å®šä¼˜åŒ–çš„åŸºç¡€ã€‚
- en: 16.3 Summary
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.3 æ€»ç»“
- en: 'You know by now: half the success in mathematics is picking the right representations
    and notations. Although multivariable calculus can seem insanely complex, itâ€™s
    a cakewalk if we have a good understanding of linear algebra. This is why we started
    our entire journey with vectors and matrices! Going from f(x[1],â€¦,x[n]) to f(x)
    is a big deal.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ç°åœ¨åº”è¯¥çŸ¥é“ï¼šæ•°å­¦æˆåŠŸçš„ä¸€åŠåœ¨äºé€‰æ‹©æ­£ç¡®çš„è¡¨ç¤ºæ³•å’Œç¬¦å·ã€‚å°½ç®¡å¤šå˜é‡å¾®ç§¯åˆ†çœ‹èµ·æ¥å¼‚å¸¸å¤æ‚ï¼Œä½†å¦‚æœæˆ‘ä»¬å¯¹çº¿æ€§ä»£æ•°æœ‰å¾ˆå¥½çš„ç†è§£ï¼Œå®ƒå°±å˜å¾—è½»æ¾äº†ã€‚è¿™ä¹Ÿæ˜¯æˆ‘ä»¬ä¸ºä½•ä»å‘é‡å’ŒçŸ©é˜µå¼€å§‹çš„åŸå› ï¼ä»
    f(x[1],â€¦,x[n]) åˆ° f(x) æ˜¯ä¸€é¡¹é‡è¦çš„è¿›å±•ã€‚
- en: In this chapter, we have learned that differentiation in multiple dimensions
    is slightly more complicated than in the single-variable case. First, we have
    the partial derivatives defined by
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å­¦åˆ°äº†å¤šç»´åº¦çš„å¾®åˆ†æ¯”å•å˜é‡æƒ…å†µç¨å¾®å¤æ‚ä¸€äº›ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰äº†åå¯¼æ•°ï¼š
- en: '![âˆ‚f-(a) = lim f(a+-hei)-âˆ’-f(a), a âˆˆ â„n, âˆ‚xi hâ†’0 h ](img/file1563.png)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‚f-(a) = lim f(a+-hei)-âˆ’-f(a), a âˆˆ â„n, âˆ‚xi hâ†’0 h ](img/file1563.png)'
- en: 'where e[i] is the vector whose i-th component is one, while the others are
    zero. We can think about ![âˆ‚âˆ‚fx- i](img/file1564.png) as the derivative of the
    single-variable function obtained by fixing all but the i-th variable of f. Together,
    the partial derivatives form the gradient:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œe[i] æ˜¯ä¸€ä¸ªå‘é‡ï¼Œå…¶ç¬¬ i ä¸ªåˆ†é‡ä¸º 1ï¼Œå…¶ä»–åˆ†é‡ä¸º 0ã€‚æˆ‘ä»¬å¯ä»¥å°† ![âˆ‚âˆ‚fx- i](img/file1564.png) è§†ä¸ºé€šè¿‡å›ºå®š
    f çš„é™¤ç¬¬ i ä¸ªå˜é‡å¤–æ‰€æœ‰å˜é‡æ‰€å¾—åˆ°çš„å•å˜é‡å‡½æ•°çš„å¯¼æ•°ã€‚æ‰€æœ‰çš„åå¯¼æ•°ç»„æˆæ¢¯åº¦ï¼š
- en: '![ âŒŠ-âˆ‚- âŒ‹ |âˆ‚x1f (a )| ||âˆ‚âˆ‚x2f (a )|| nÃ—1 âˆ‡f (a ) := || .. || âˆˆ â„ . âŒˆ . âŒ‰ -âˆ‚-f
    (a ) âˆ‚xn ](img/file1565.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ-âˆ‚- âŒ‹ |âˆ‚x1f (a )| ||âˆ‚âˆ‚x2f (a )|| nÃ—1 âˆ‡f (a ) := || .. || âˆˆ â„ . âŒˆ . âŒ‰ -âˆ‚-f
    (a ) âˆ‚xn ](img/file1565.png)'
- en: However, the partial derivatives are not exactly the perfect analogue of the
    univariate derivatives. There, we learned that the derivative is the best local
    linear approximation, and this is the version that can be generalized to multiple
    variables. Thus, we say that f is totally differentiable at a âˆˆâ„^n if it can be
    written in the form
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œåå¯¼æ•°å¹¶ä¸å®Œå…¨æ˜¯å•å˜é‡å¯¼æ•°çš„å®Œç¾ç±»æ¯”ã€‚åœ¨å•å˜é‡çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çŸ¥é“å¯¼æ•°æ˜¯æœ€å¥½çš„å±€éƒ¨çº¿æ€§è¿‘ä¼¼ï¼Œè€Œè¿™æ­£æ˜¯å¯ä»¥æ¨å¹¿åˆ°å¤šå˜é‡çš„ç‰ˆæœ¬ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¯´ f åœ¨ a
    âˆˆ â„^n å¤„æ˜¯å…¨å¾®åˆ†çš„ï¼Œå¦‚æœå®ƒå¯ä»¥å†™æˆä»¥ä¸‹å½¢å¼ï¼š
- en: '![f(x) = f(a) + âˆ‡f (a )T (x âˆ’ a) + o(âˆ¥xâˆ’ a âˆ¥). ](img/file1566.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![f(x) = f(a) + âˆ‡f (a )T (x âˆ’ a) + o(âˆ¥xâˆ’ a âˆ¥). ](img/file1566.png)'
- en: In machine learning, one of the most essential tools is the multivariable chain
    rule
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæœ€é‡è¦çš„å·¥å…·ä¹‹ä¸€å°±æ˜¯å¤šå˜é‡é“¾å¼æ³•åˆ™ã€‚
- en: '![Dfâˆ˜g(a) = Df(g (a))Dg (a), ](img/file1567.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![Dfâˆ˜g(a) = Df(g (a))Dg (a), ](img/file1567.png)'
- en: which is used to compute the derivatives in practice. Without the chain rule,
    we wouldnâ€™t have any effective method to compute the gradient. In turn, as the
    name suggests, the gradient is the cornerstone of gradient descent. We already
    understand the single-variable version, so itâ€™s time to dive deep into the general
    one. See you in the next chapter!
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ç”¨æ¥å®é™…è®¡ç®—å¯¼æ•°çš„å·¥å…·ã€‚å¦‚æœæ²¡æœ‰é“¾å¼æ³•åˆ™ï¼Œæˆ‘ä»¬å°±æ²¡æœ‰æœ‰æ•ˆçš„æ–¹æ³•æ¥è®¡ç®—æ¢¯åº¦ã€‚å› æ­¤ï¼Œæ­£å¦‚åå­—æ‰€ç¤ºï¼Œæ¢¯åº¦æ˜¯æ¢¯åº¦ä¸‹é™æ³•çš„åŸºçŸ³ã€‚æˆ‘ä»¬å·²ç»ç†è§£äº†å•å˜é‡ç‰ˆæœ¬ï¼Œç°åœ¨æ˜¯æ—¶å€™æ·±å…¥ç ”ç©¶ä¸€èˆ¬çš„å¤šå˜é‡ç‰ˆæœ¬äº†ã€‚ä¸‹ä¸€ç« è§ï¼
- en: 16.4 Problems
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.4 é—®é¢˜
- en: Problem 1\. Compute the partial derivatives and the Hessian matrix of the following
    functions.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜ 1. è®¡ç®—ä»¥ä¸‹å‡½æ•°çš„åå¯¼æ•°å’Œ Hessian çŸ©é˜µã€‚
- en: (a) f(x[1],x[2]) = x[1]^(3x[2]Â²) + 2x[1]x[2] + x[2]Â³ (b) f(x[1],x[2]) = e^(x[1]Â²âˆ’x[2])
    + sin(x[1]x[2]) (c) f(x[1],x[2]) = ln(x[1]Â² + x[2]Â²) + x[1]e^(x[2]) (d) f(x[1],x[2])
    = cos(x[1]x[2]) + x[1]Â² sin(x[2]) (e) f(x[1],x[2]) = f(x[1],x[2]) = ![x2+x2 x11âˆ’x22](img/file1568.png)
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: (a) f(x[1],x[2]) = x[1]^(3x[2]Â²) + 2x[1]x[2] + x[2]Â³ (b) f(x[1],x[2]) = e^(x[1]Â²âˆ’x[2])
    + sin(x[1]x[2]) (c) f(x[1],x[2]) = ln(x[1]Â² + x[2]Â²) + x[1]e^(x[2]) (d) f(x[1],x[2])
    = cos(x[1]x[2]) + x[1]Â² sin(x[2]) (e) f(x[1],x[2]) = f(x[1],x[2]) = ![x2+x2 x11âˆ’x22](img/file1568.png)
- en: Problem 2\. Compute the Jacobian matrix of the following functions.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜ 2. è®¡ç®—ä»¥ä¸‹å‡½æ•°çš„ Jacobian çŸ©é˜µã€‚
- en: (a)
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![ âŒŠ âŒ‹ x21x2 + ex2 f(x1,x2) = âŒˆ x2âŒ‰ sin(x1x2)+ x1e ](img/file1569.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ x21x2 + ex2 f(x1,x2) = âŒˆ x2âŒ‰ sin(x1x2)+ x1e ](img/file1569.png)'
- en: (b)
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![ âŒŠ âŒ‹ ln(x21 + x22) + x1x2 f(x1,x2) = âŒˆ 2 x1 âŒ‰ cos(x1)+ x 2e ](img/file1570.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ ln(x21 + x22) + x1x2 f(x1,x2) = âŒˆ 2 x1 âŒ‰ cos(x1)+ x 2e ](img/file1570.png)'
- en: (c)
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: '![ âŒŠ âŒ‹ x3 âˆ’ x2 f(x1,x2) = âŒˆ 1 2 âŒ‰ ex1x2 + x1 cos(x2 ) ](img/file1571.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ x3 âˆ’ x2 f(x1,x2) = âŒˆ 1 2 âŒ‰ ex1x2 + x1 cos(x2 ) ](img/file1571.png)'
- en: (d)
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: (d)
- en: '![ âŒŠ âŒ‹ âŒˆ tan (x1x2 )+ x32 âŒ‰ f(x1,x2 ) = âˆ˜x2-+-x2-+ sin(x ) 1 2 1 ](img/file1572.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ âŒˆ tan (x1x2 )+ x32 âŒ‰ f(x1,x2 ) = âˆ˜x2-+-x2-+ sin(x ) 1 2 1 ](img/file1572.png)'
- en: (e)
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: (e)
- en: '![ âŒŠ âŒ‹ x ex2 âˆ’ ln(1 + x2) f(x1,x2) = âŒˆ 1 1 âŒ‰ x22cos(x1)+ x1x2 ](img/file1573.png)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ x ex2 âˆ’ ln(1 + x2) f(x1,x2) = âŒˆ 1 1 âŒ‰ x22cos(x1)+ x1x2 ](img/file1573.png)'
- en: Problem 3\. Let f(x[1],x[2]) = x[1]![âˆ˜ |x2|-](img/file1574.png). Show that f
    is partially differentiable but not totally differentiable at (0,0).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜ 3. è®¾ f(x[1],x[2]) = x[1]![âˆ˜ |x2|-](img/file1574.png)ã€‚è¯æ˜ f åœ¨ (0,0) å¤„æ˜¯éƒ¨åˆ†å¯å¾®çš„ï¼Œä½†ä¸æ˜¯å…¨å¾®çš„ã€‚
- en: Join our community on Discord
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ å…¥æˆ‘ä»¬çš„ Discord ç¤¾åŒº
- en: Read this book alongside other users, Machine Learning experts, and the author
    himself. Ask questions, provide solutions to other readers, chat with the author
    via Ask Me Anything sessions, and much more. Scan the QR code or visit the link
    to join the community. [https://packt.link/math](https://packt.link/math)
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶ä»–ç”¨æˆ·ã€æœºå™¨å­¦ä¹ ä¸“å®¶ä»¥åŠä½œè€…æœ¬äººä¸€èµ·é˜…è¯»æœ¬ä¹¦ã€‚æé—®ã€ä¸ºå…¶ä»–è¯»è€…æä¾›è§£å†³æ–¹æ¡ˆã€é€šè¿‡é—®æˆ‘ä»»ä½•é—®é¢˜ç¯èŠ‚ä¸ä½œè€…äº¤æµï¼Œç­‰ç­‰ã€‚æ‰«æäºŒç»´ç æˆ–è®¿é—®é“¾æ¥åŠ å…¥ç¤¾åŒºã€‚[https://packt.link/math](https://packt.link/math)
- en: '![PIC](img/file1.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1.png)'
