- en: '20'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '20'
- en: The Expected Value
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: æœŸæœ›å€¼
- en: In the last chapter, we learned about probability distributions, the objects
    that represent probabilistic models as sequences or functions. After all, there
    is the entire field of calculus to help us deal with functions, so they open up
    a wide array of mathematical tools.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šä¸€ç« ï¼Œæˆ‘ä»¬å­¦ä¹ äº†æ¦‚ç‡åˆ†å¸ƒï¼Œå³è¡¨ç¤ºæ¦‚ç‡æ¨¡å‹çš„å¯¹è±¡ï¼Œä½œä¸ºåºåˆ—æˆ–å‡½æ•°ã€‚æ¯•ç«Ÿï¼Œæ•´ä¸ªå¾®ç§¯åˆ†é¢†åŸŸå¯ä»¥å¸®åŠ©æˆ‘ä»¬å¤„ç†å‡½æ•°ï¼Œå› æ­¤å®ƒä»¬ä¸ºæˆ‘ä»¬æä¾›äº†å¹¿æ³›çš„æ•°å­¦å·¥å…·ã€‚
- en: However, we might not need all the information available. Sometimes, simple
    descriptive statistics such as mean, variance, or median suffice. Even in machine
    learning, loss functions are given in terms of them. For instance, the famous
    mean-squared error
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæˆ‘ä»¬å¯èƒ½å¹¶ä¸éœ€è¦æ‰€æœ‰å¯ç”¨çš„ä¿¡æ¯ã€‚æœ‰æ—¶ï¼Œç®€å•çš„æè¿°æ€§ç»Ÿè®¡ï¼Œå¦‚å‡å€¼ã€æ–¹å·®æˆ–ä¸­ä½æ•°å°±è¶³å¤Ÿäº†ã€‚å³ä¾¿åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼ŒæŸå¤±å‡½æ•°ä¹Ÿä»¥è¿™äº›é‡ä¸ºåŸºç¡€ã€‚ä¾‹å¦‚ï¼Œè‘—åçš„å‡æ–¹è¯¯å·®
- en: '![ n MSE (x,y ) =-1âˆ‘ (f(x )âˆ’ y )2, x,y âˆˆ â„n n i i i=1 ](img/file1893.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![ n MSE (x,y ) =-1âˆ‘ (f(x )âˆ’ y )2, x,y âˆˆ â„n n i i i=1 ](img/file1893.png)'
- en: is the variance of the prediction error. Deep down, these familiar quantities
    are rooted in probability theory, and weâ€™ll devote this chapter to learning about
    them.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯é¢„æµ‹è¯¯å·®çš„æ–¹å·®ã€‚æ·±å±‚æ¬¡ä¸Šï¼Œè¿™äº›ç†Ÿæ‚‰çš„é‡éƒ½æ ¹æ¤äºæ¦‚ç‡è®ºä¸­ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬ç« ä¸­ä¸“é—¨å­¦ä¹ å®ƒä»¬ã€‚
- en: 20.1 Discrete random variables
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.1 ç¦»æ•£éšæœºå˜é‡
- en: Letâ€™s play a simple game. I toss a coin, and if it comes up heads, you win $1
    . If it is tails, you lose $2 .
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç©ä¸€ä¸ªç®€å•çš„æ¸¸æˆã€‚æˆ‘æŠ•æ·ä¸€æšç¡¬å¸ï¼Œå¦‚æœæ˜¯æ­£é¢ï¼Œä½ èµ¢å¾—$1ã€‚å¦‚æœæ˜¯åé¢ï¼Œä½ è¾“æ‰$2ã€‚
- en: Up until now, we were dealing with questions like the probability of winning.
    Say, for the coin toss, whether you win or lose, we have
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨å¤„ç†åƒæ˜¯è·èƒœçš„æ¦‚ç‡ç­‰é—®é¢˜ã€‚æ¯”å¦‚ï¼ŒæŠ•æ·ç¡¬å¸æ—¶ï¼Œæ— è®ºä½ èµ¢è¿˜æ˜¯è¾“ï¼Œæˆ‘ä»¬æœ‰
- en: '![P(heads) = P(tails) = 1\. 2 ](img/file1894.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![P(æ­£é¢) = P(åé¢) = 1\. 2 ](img/file1894.png)'
- en: Despite the equal chances of winning and losing, should you play this game?
    Letâ€™s find out.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡èµ¢å’Œè¾“çš„æœºä¼šç›¸ç­‰ï¼Œä½ æ˜¯å¦åº”è¯¥ç©è¿™ä¸ªæ¸¸æˆå‘¢ï¼Ÿè®©æˆ‘ä»¬ä¸€æ¢ç©¶ç«Ÿã€‚
- en: After n rounds, your earnings can be calculated by the number of heads times
    $1 minus the number of tails times $2 . If we divide total earnings by n, we obtain
    your average winnings per round. That is,
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨nè½®ä¹‹åï¼Œä½ çš„æ”¶ç›Šå¯ä»¥é€šè¿‡æ­£é¢æ¬¡æ•°ä¹˜ä»¥$1ï¼Œå‡å»åé¢æ¬¡æ•°ä¹˜ä»¥$2æ¥è®¡ç®—ã€‚å¦‚æœæˆ‘ä»¬å°†æ€»æ”¶ç›Šé™¤ä»¥nï¼Œå°±å¾—åˆ°æ¯è½®çš„å¹³å‡å¥–é‡‘ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œ
- en: '![ total-winnings- your average winnings = n 1â‹…#heads âˆ’ 2â‹…#tails = --------------------
    n = 1â‹… #heads âˆ’ 2â‹… #tails, n n ](img/file1895.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![ æ€»å¥–é‡‘- ä½ çš„å¹³å‡å¥–é‡‘ = n 1â‹…#æ­£é¢ âˆ’ 2â‹…#åé¢ = -------------------- n = 1â‹… #æ­£é¢ âˆ’ 2â‹… #åé¢,
    n n ](img/file1895.png)'
- en: 'where #heads and #tails denote the number of heads and tails respectively.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ#æ­£é¢å’Œ#åé¢åˆ†åˆ«è¡¨ç¤ºæ­£é¢å’Œåé¢çš„æ¬¡æ•°ã€‚
- en: Recall the frequentist interpretation of probability from SectionÂ [18.2.7](ch030.xhtml#how-to-interpret-probability)?
    According to our intuition, we should have
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜è®°å¾—æ¥è‡ªç¬¬[18.2.7](ch030.xhtml#how-to-interpret-probability)èŠ‚çš„é¢‘ç‡å­¦æ´¾å¯¹æ¦‚ç‡çš„è§£é‡Šå—ï¼Ÿæ ¹æ®æˆ‘ä»¬çš„ç›´è§‰ï¼Œæˆ‘ä»¬åº”è¯¥æœ‰
- en: '![ lim #heads- = P(heads) = 1, nâ†’ âˆ n 2 #tails- 1- lniâ†’mâˆ n = P(tails) = 2\.
    ](img/file1896.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![ lim #æ­£é¢- = P(æ­£é¢) = 1, nâ†’ âˆ n 2 #åé¢- 1- lniâ†’mâˆ n = P(åé¢) = 2\. ](img/file1896.png)'
- en: This means that if you play long enough, your average winnings per round is
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€ï¼Œå¦‚æœä½ ç©å¾—è¶³å¤Ÿé•¿ï¼Œä½ æ¯è½®çš„å¹³å‡å¥–é‡‘æ˜¯
- en: '![your average winnings = 1â‹…P (heads)âˆ’ 2 â‹…P(tails) = âˆ’ 1\. 2 ](img/file1897.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![ä½ çš„å¹³å‡å¥–é‡‘ = 1â‹…P(æ­£é¢)âˆ’ 2â‹…P(åé¢) = âˆ’ 1\. 2 ](img/file1897.png)'
- en: So, as you are losing half a dollar per round on average, you definitely shouldnâ€™t
    play this game.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ—¢ç„¶ä½ æ¯è½®å¹³å‡äºæŸåŠç¾å…ƒï¼Œé‚£ä¹ˆä½ è‚¯å®šä¸åº”è¯¥ç©è¿™ä¸ªæ¸¸æˆã€‚
- en: Letâ€™s formalize this argument with a random variable. Say, if X describes your
    winnings per round, we have
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡éšæœºå˜é‡æ¥æ­£å¼åŒ–è¿™ä¸ªè®ºç‚¹ã€‚å‡è®¾ï¼Œå¦‚æœXè¡¨ç¤ºä½ æ¯è½®çš„å¥–é‡‘ï¼Œæˆ‘ä»¬æœ‰
- en: '![ 1 P(X = 1) = P (X = âˆ’ 2) =-, 2 ](img/file1898.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 P(X = 1) = P (X = âˆ’ 2) =-, 2 ](img/file1898.png)'
- en: so the average winnings can be written as
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¹³å‡å¥–é‡‘å¯ä»¥è¡¨ç¤ºä¸º
- en: '![average value of X = 1 â‹…P(X = 1)âˆ’ 2 â‹…P(X = âˆ’ 2) 1 = âˆ’ -. 2 ](img/file1899.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![Xçš„å¹³å‡å€¼ = 1 â‹…P(X = 1) âˆ’ 2 â‹…P(X = âˆ’ 2) 1 = âˆ’ -. 2 ](img/file1899.png)'
- en: With a bit of a pattern matching, we find that for a general discrete random
    variable X, the formula looks like
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä¸€ç‚¹æ¨¡å¼åŒ¹é…ï¼Œæˆ‘ä»¬å‘ç°å¯¹äºä¸€èˆ¬çš„ç¦»æ•£éšæœºå˜é‡Xï¼Œå…¬å¼çœ‹èµ·æ¥åƒ
- en: '![ âˆ‘ average value of X = (value)â‹…P (X = value). value ](img/file1900.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘ Xçš„å¹³å‡å€¼ = (å€¼)â‹…P(X = å€¼)ã€‚å€¼ ](img/file1900.png)'
- en: And from this, the definition of expected value is born.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸­ï¼ŒæœŸæœ›å€¼çš„å®šä¹‰åº”è¿è€Œç”Ÿã€‚
- en: Definition 92\. (The expected value of discrete random variables)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰92.ï¼ˆç¦»æ•£éšæœºå˜é‡çš„æœŸæœ›å€¼ï¼‰
- en: 'Let (Î©,Î£,P) be a probability space, and X : Î© â†’{x[1],x[2],â€¦} be a discrete
    random variable. The expected value of X is defined by'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾(Î©, Î£, P)ä¸ºä¸€ä¸ªæ¦‚ç‡ç©ºé—´ï¼ŒX : Î© â†’{x[1], x[2], â€¦}ä¸ºç¦»æ•£éšæœºå˜é‡ã€‚Xçš„æœŸæœ›å€¼å®šä¹‰ä¸º'
- en: '![ğ”¼ [X ] := âˆ‘ x P (X = x ). k k k ](img/file1901.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼ [X ] := âˆ‘ x P (X = x ). k k k ](img/file1901.png)'
- en: (Note that if X assumes finitely many values, the sum only contains a finite
    number of terms.)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆæ³¨æ„ï¼Œå¦‚æœXå–æœ‰é™å¤šä¸ªå€¼ï¼Œåˆ™å’Œä¸­åªåŒ…å«æœ‰é™ä¸ªé¡¹ã€‚ï¼‰
- en: In English, the expected value describes the average value of a random variable
    in the long run. The expected value is also called the mean and is often denoted
    by Î¼. Instead of using random variables, weâ€™ll often use the expected value symbol
    by plugging in distributions, like ğ”¼[Bernoulli(p)]. Although this is mathematically
    not precise, 1) it is simpler in certain cases, 2) and the expected value only
    depends on the distribution anyway.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è‹±è¯­ä¸­ï¼ŒæœŸæœ›å€¼æè¿°çš„æ˜¯éšæœºå˜é‡åœ¨é•¿æœŸè¿è¡Œä¸­çš„å¹³å‡å€¼ã€‚æœŸæœ›å€¼ä¹Ÿå«åšå‡å€¼ï¼Œé€šå¸¸ç”¨Î¼è¡¨ç¤ºã€‚æˆ‘ä»¬å¸¸å¸¸ä¸ä½¿ç”¨éšæœºå˜é‡ï¼Œè€Œæ˜¯é€šè¿‡ä»£å…¥åˆ†å¸ƒæ¥ä½¿ç”¨æœŸæœ›å€¼ç¬¦å·ï¼Œæ¯”å¦‚ğ”¼[Bernoulli(p)]ã€‚è™½ç„¶ä»æ•°å­¦ä¸Šçœ‹è¿™ä¸å¤Ÿç²¾ç¡®ï¼Œä½†1ï¼‰åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå®ƒæ›´ç®€å•ï¼Œ2ï¼‰è€Œä¸”æœŸæœ›å€¼åæ­£åªä¾èµ–äºåˆ†å¸ƒã€‚
- en: Itâ€™s time for examples.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯æ—¶å€™çœ‹ä¸€äº›ä¾‹å­äº†ã€‚
- en: Example 1\. Expected value of the Bernoulli distribution. (See the definition
    of the Bernoulli distribution in SectionÂ [19.2.1](ch031.xhtml#the-bernoulli-distribution).)
    Let X âˆ¼ Bernoulli(p). Its expected value is quite simple to compute, as
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 1. ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æœŸæœ›å€¼ã€‚ï¼ˆè¯·å‚è§[19.2.1](ch031.xhtml#the-bernoulli-distribution)èŠ‚ä¸­çš„ä¼¯åŠªåˆ©åˆ†å¸ƒå®šä¹‰ã€‚ï¼‰è®¾X
    âˆ¼ Bernoulli(p)ã€‚å®ƒçš„æœŸæœ›å€¼å¾ˆå®¹æ˜“è®¡ç®—ï¼Œè®¡ç®—å¦‚ä¸‹ï¼š
- en: '![ğ”¼[X] = 0â‹…P (X = 0 )+ 1â‹…P (X = 1) = = 0â‹…(1 âˆ’ p)+ 1 â‹…p = p. ](img/file1902.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼[X] = 0â‹…P (X = 0 )+ 1â‹…P (X = 1) = = 0â‹…(1 âˆ’ p)+ 1 â‹…p = p. ](img/file1902.png)'
- en: 'Weâ€™ve seen this before: the introductory example with the simple game is the
    transformed Bernoulli distribution 3 â‹… Bernoulli(1âˆ•2) âˆ’ 2.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹‹å‰è§è¿‡è¿™ä¸ªï¼šç®€å•æ¸¸æˆçš„å…¥é—¨ä¾‹å­å®é™…ä¸Šæ˜¯å˜æ¢åçš„ä¼¯åŠªåˆ©åˆ†å¸ƒ 3 â‹… ä¼¯åŠªåˆ©(1âˆ•2) âˆ’ 2ã€‚
- en: Example 2\. Expected value of the binomial distribution. (See the definition
    of the binomial distribution in SectionÂ [19.2.2](ch031.xhtml#the-binomial-distribution).)
    Let X âˆ¼ Binomial(n,p). Then
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 2. äºŒé¡¹åˆ†å¸ƒçš„æœŸæœ›å€¼ã€‚ï¼ˆè¯·å‚è§[19.2.2](ch031.xhtml#the-binomial-distribution)èŠ‚ä¸­çš„äºŒé¡¹åˆ†å¸ƒå®šä¹‰ã€‚ï¼‰è®¾X
    âˆ¼ Binomial(n,p)ã€‚é‚£ä¹ˆ
- en: '![ âˆ‘n ğ”¼[X] = kP (X = k ) k=0 âˆ‘n (n ) = k pk(1 âˆ’ p)nâˆ’k k=0 k âˆ‘n = k----n!---
    pk(1 âˆ’ p)nâˆ’k. k=0 k!(n âˆ’ k)! ](img/file1903.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘n ğ”¼[X] = kP (X = k ) k=0 âˆ‘n (n ) = k pk(1 âˆ’ p)nâˆ’k k=0 k âˆ‘n = k----n!---
    pk(1 âˆ’ p)nâˆ’k. k=0 k!(n âˆ’ k)! ](img/file1903.png)'
- en: 'The plan is the following: absorb that k with the fraction ![--n!--- k!(nâˆ’k)!](img/file1904.png),
    and adjust the sum such that its terms form the probability mass function for
    Binomial(n âˆ’ 1,p). As n âˆ’k = (n âˆ’ 1) âˆ’ (k âˆ’ 1), we have'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡åˆ’å¦‚ä¸‹ï¼šå¸æ”¶é‚£ä¸ªkä¸åˆ†æ•°![--n!--- k!(nâˆ’k)!](img/file1904.png)ï¼Œå¹¶è°ƒæ•´å’Œï¼Œä½¿å…¶é¡¹å½¢æˆäºŒé¡¹åˆ†å¸ƒ(Binomial(n
    âˆ’ 1,p))çš„æ¦‚ç‡è´¨é‡å‡½æ•°ã€‚ç”±äºn âˆ’k = (n âˆ’ 1) âˆ’ (k âˆ’ 1)ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![ âˆ‘n ğ”¼[X ] = k ---n!----pk(1âˆ’ p)nâˆ’k k=0 k!(n âˆ’ k)! âˆ‘n = np ---------(n-âˆ’-1)!--------pkâˆ’1(1
    âˆ’ p)(nâˆ’1)âˆ’(kâˆ’1) k=1(k âˆ’ 1)!((n âˆ’ 1)âˆ’ (k âˆ’ 1))! nâˆ’1 = np âˆ‘ ---(n-âˆ’-1)!--pk(1âˆ’ p)(nâˆ’1âˆ’k)
    k!(n âˆ’ 1âˆ’ k)! k=0 nâˆ‘âˆ’1 = np P (Binomial(nâˆ’ 1,p) = k) k=0 = np. ](img/file1905.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘n ğ”¼[X ] = k ---n!----pk(1âˆ’ p)nâˆ’k k=0 k!(n âˆ’ k)! âˆ‘n = np ---------(n-âˆ’-1)!--------pkâˆ’1(1
    âˆ’ p)(nâˆ’1)âˆ’(kâˆ’1) k=1(k âˆ’ 1)!((n âˆ’ 1)âˆ’ (k âˆ’ 1))! nâˆ’1 = np âˆ‘ ---(n-âˆ’-1)!--pk(1âˆ’ p)(nâˆ’1âˆ’k)
    k!(n âˆ’ 1âˆ’ k)! k=0 nâˆ‘âˆ’1 = np P (Binomial(nâˆ’ 1,p) = k) k=0 = np. ](img/file1905.png)'
- en: This computation might not look like the simplest, but once you get familiar
    with the trick, itâ€™ll be like second nature for you.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè®¡ç®—çœ‹èµ·æ¥å¯èƒ½ä¸ç®—æœ€ç®€å•ï¼Œä½†ä¸€æ—¦ä½ ç†Ÿæ‚‰äº†è¿™ä¸ªæŠ€å·§ï¼Œå®ƒå°†å˜å¾—åƒç¬¬äºŒå¤©æ€§ä¸€æ ·ã€‚
- en: Example 3\. Expected value of the geometric distribution. (See the definition
    of the geometric distribution in SectionÂ [19.2.3](ch031.xhtml#the-geometric-distribution).)
    Let X âˆ¼ Geo(p). We need to calculate
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 3. å‡ ä½•åˆ†å¸ƒçš„æœŸæœ›å€¼ã€‚ï¼ˆè¯·å‚è§[19.2.3](ch031.xhtml#the-geometric-distribution)èŠ‚ä¸­çš„å‡ ä½•åˆ†å¸ƒå®šä¹‰ã€‚ï¼‰è®¾X
    âˆ¼ Geo(p)ã€‚æˆ‘ä»¬éœ€è¦è®¡ç®—
- en: '![ âˆ‘âˆ ğ”¼[X ] = k (1 âˆ’ p)kâˆ’1p. k=1 ](img/file1906.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘âˆ ğ”¼[X ] = k (1 âˆ’ p)kâˆ’1p. k=1 ](img/file1906.png)'
- en: Do you remember the geometric series ([19.2](#))? This is almost it, except
    for the k term, which throws a monkey wrench into our gears. To fix that, weâ€™ll
    use another magic trick. Recall that
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¿˜è®°å¾—å‡ ä½•çº§æ•°å—ï¼Ÿ([19.2](#)) è¿™å‡ ä¹å°±æ˜¯å®ƒï¼Œé™¤äº†é‚£ä¸ªké¡¹ï¼Œå®ƒè®©æˆ‘ä»¬çš„è®¡ç®—å˜å¾—å¤æ‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¦ä¸€ä¸ªé­”æ³•æŠ€å·§ã€‚å›å¿†ä¸€ä¸‹ï¼Œ
- en: '![ 1 âˆ‘âˆ ----- = xk. 1 âˆ’ x k=0 ](img/file1907.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 âˆ‘âˆ ----- = xk. 1 âˆ’ x k=0 ](img/file1907.png)'
- en: Now, we are going to differentiate the geometric series, thus obtaining
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å°†å¯¹å‡ ä½•çº§æ•°è¿›è¡Œå¾®åˆ†ï¼Œä»è€Œå¾—åˆ°
- en: '![ d 1 d âˆ‘âˆ k dx-1-âˆ’-x = dx- x k=0 âˆ‘âˆ d k = dx-x k=0 âˆ‘âˆ kâˆ’ 1 = kx , k=1 ](img/file1908.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![ d 1 d âˆ‘âˆ k dx-1-âˆ’-x = dx- x k=0 âˆ‘âˆ d k = dx-x k=0 âˆ‘âˆ kâˆ’ 1 = kx , k=1 ](img/file1908.png)'
- en: where we used the linearity of the derivative and the pleasant analytic properties
    of the geometric series. Mathematicians would scream upon the sight of switching
    the derivative and the infinite sum, but donâ€™t worry, everything here is correct
    as is. (Mathematicians are really afraid of interchanging limits. Mind you, for
    a good reason!)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨äº†å¯¼æ•°çš„çº¿æ€§æ€§è´¨å’Œå‡ ä½•çº§æ•°çš„è‰¯å¥½è§£ææ€§è´¨ã€‚æ•°å­¦å®¶ä»¬çœ‹åˆ°äº¤æ¢å¯¼æ•°å’Œæ— ç©·å’Œæ—¶ä¼šå°–å«ï¼Œä½†åˆ«æ‹…å¿ƒï¼Œè¿™é‡Œçš„ä¸€åˆ‡éƒ½æ˜¯æ­£ç¡®çš„ã€‚ï¼ˆæ•°å­¦å®¶ä»¬çœŸçš„å®³æ€•äº¤æ¢æé™ã€‚ä½ å¾—çŸ¥é“ï¼Œä»–ä»¬æœ‰ç†ç”±è¿™ä¹ˆåšï¼ï¼‰
- en: On the other hand,
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼Œ
- en: '![d---1--- ---1---- dx 1âˆ’ x = (1 âˆ’ x)2, ](img/file1909.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![d---1--- ---1---- dx 1âˆ’ x = (1 âˆ’ x)2, ](img/file1909.png)'
- en: thus
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤
- en: '![ âˆ âˆ‘ kâˆ’1 ---1---- kx = (1âˆ’ x )2\. k=1 ](img/file1910.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ âˆ‘ kâˆ’1 ---1---- kx = (1âˆ’ x )2\. k=1 ](img/file1910.png)'
- en: Combining all of these, we finally have
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç»¼åˆä»¥ä¸Šæ‰€æœ‰å†…å®¹ï¼Œæˆ‘ä»¬æœ€ç»ˆå¾—å‡º
- en: '![ âˆ‘âˆ ğ”¼[X ] = k (1 âˆ’ p)kâˆ’1p k=1 âˆâˆ‘ = p k(1âˆ’ p)kâˆ’1 k=1 1 1 = p-2 = -. p p ](img/file1911.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘âˆ ğ”¼[X ] = k (1 âˆ’ p)kâˆ’1p k=1 âˆâˆ‘ = p k(1âˆ’ p)kâˆ’1 k=1 1 1 = p-2 = -. p p ](img/file1911.png)'
- en: Example 4\. Expected value of the constant random variable. Let c âˆˆâ„ be an arbitrary
    constant, and let X be the random variable that assumes the value c everywhere.
    As X is a discrete random variable, its expected value is simply
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹4\. å¸¸æ•°éšæœºå˜é‡çš„æœŸæœ›å€¼ã€‚ä»¤c âˆˆâ„ä¸ºä»»æ„å¸¸æ•°ï¼ŒXä¸ºä¸€ä¸ªåœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½å–å€¼ä¸ºcçš„éšæœºå˜é‡ã€‚ç”±äºXæ˜¯ç¦»æ•£éšæœºå˜é‡ï¼Œå®ƒçš„æœŸæœ›å€¼å°±æ˜¯
- en: '![ğ”¼[X ] = câ‹…P (X = c) = c. ](img/file1912.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼[X ] = câ‹…P (X = c) = c. ](img/file1912.png)'
- en: I know, this example looks silly, but it can be quite useful. When it is clear,
    we abuse the notation by denoting the constant c as the random variable itself.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çŸ¥é“ï¼Œè¿™ä¸ªä¾‹å­çœ‹èµ·æ¥å¾ˆå‚»ï¼Œä½†å®ƒå®é™…ä¸Šå¯ä»¥éå¸¸æœ‰ç”¨ã€‚å½“æƒ…å†µæ¸…æ™°æ—¶ï¼Œæˆ‘ä»¬é€šè¿‡å°†å¸¸æ•°cè¡¨ç¤ºä¸ºéšæœºå˜é‡æœ¬èº«æ¥æ»¥ç”¨ç¬¦å·ã€‚
- en: 20.1.1 The expected value in poker
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.1.1 æ‰‘å…‹ä¸­çš„æœŸæœ›å€¼
- en: One more example before we move on. I was a mediocre no-limit Texas holdâ€™em
    player a while ago, and the first time I heard about the expected value was years
    before I studied probability theory.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»§ç»­ä¹‹å‰å†ä¸¾ä¸€ä¸ªä¾‹å­ã€‚æ›¾ç»ï¼Œæˆ‘æ˜¯ä¸€ä¸ªä¸­ç­‰æ°´å¹³çš„æ— é™æ³¨å¾·å·æ‰‘å…‹ç©å®¶ï¼Œè€Œæˆ‘ç¬¬ä¸€æ¬¡å¬è¯´æœŸæœ›å€¼æ˜¯åœ¨å­¦ä¹ æ¦‚ç‡è®ºä¹‹å‰çš„å‡ å¹´ã€‚
- en: According to the rules of Texas holdâ€™em, each player holds two cards on their
    own, while five more shared cards are dealt. The shared cards are available for
    everyone, and the player with the strongest hand wins.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®å¾·å·æ‰‘å…‹çš„è§„åˆ™ï¼Œæ¯ä¸ªç©å®¶è‡ªå·±æŒæœ‰ä¸¤å¼ ç‰Œï¼ŒåŒæ—¶å‘äº”å¼ å…¬å…±ç‰Œã€‚è¿™äº›å…¬å…±ç‰Œå¯¹æ¯ä¸ªç©å®¶éƒ½å¯ç”¨ï¼ŒæŒæœ‰æœ€å¼ºç‰Œçš„ç©å®¶è·èƒœã€‚
- en: FigureÂ [20.1](#) shows how the table looks before the last card (the river)
    is revealed.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾[20.1](#)å±•ç¤ºäº†æœ€åä¸€å¼ ç‰Œï¼ˆæ²³ç‰Œï¼‰æ­ç¤ºä¹‹å‰æ¡Œé¢çš„æ ·å­ã€‚
- en: '![PIC](img/file1913.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1913.png)'
- en: 'FigureÂ 20.1: The poker table before the river card'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾20.1ï¼šæ²³ç‰Œä¹‹å‰çš„æ‰‘å…‹æ¡Œ
- en: There is money in the pot to be won, but to see the river, you have to call
    the opponentâ€™s bet. The question is, should you? Expected value to the rescue.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: åº•æ± é‡Œæœ‰é’±å¯ä»¥èµ¢ï¼Œä½†è¦çœ‹åˆ°æ²³ç‰Œï¼Œä½ å¿…é¡»è·Ÿæ³¨å¯¹æ‰‹çš„ä¸‹æ³¨ã€‚é—®é¢˜æ˜¯ï¼Œä½ åº”è¯¥è¿™ä¹ˆåšå—ï¼ŸæœŸæœ›å€¼æ¥å¸®å¿™ã€‚
- en: Letâ€™s build a probabilistic model. We would win the pot with certain river cards
    but lose with all the others. If X represents our winnings, then
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ã€‚æŸäº›æ²³ç‰Œï¼ˆriver cardï¼‰èƒ½è®©æˆ‘ä»¬èµ¢å¾—åº•æ± ï¼Œè€Œå…¶ä»–æ‰€æœ‰æ²³ç‰Œåˆ™è®©æˆ‘ä»¬å¤±å»ã€‚è‹¥Xä»£è¡¨æˆ‘ä»¬çš„è·èƒœé‡‘é¢ï¼Œåˆ™
- en: '![ #winning cards P(X = pot) = ---------------, #remaining cards P (X = âˆ’ bet)
    = --#losing-cards-. #remaining cards ](img/file1914.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![ #winning cards P(X = pot) = ---------------, #remaining cards P (X = âˆ’ bet)
    = --#losing-cards-. #remaining cards ](img/file1914.png)'
- en: Thus, the expected value is
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒæœŸæœ›å€¼æ˜¯
- en: '![ğ”¼[X] = potâ‹…P (X = pot )âˆ’ betâ‹…P (X = âˆ’ bet) #winning cards #losing cards =
    potâ‹… ----------------âˆ’ betâ‹…----------------. #remaining cards #remaining cards
    ](img/file1915.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼[X] = potâ‹…P (X = pot )âˆ’ betâ‹…P (X = âˆ’ bet) #winning cards #losing cards =
    potâ‹… ----------------âˆ’ betâ‹…----------------. #remaining cards #remaining cards
    ](img/file1915.png)'
- en: When is the expected value positive? With some algebra, we obtain that ğ”¼[X]/span>0
    if and only if
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æœŸæœ›å€¼ä»€ä¹ˆæ—¶å€™ä¸ºæ­£ï¼Ÿé€šè¿‡ä¸€äº›ä»£æ•°è¿ç®—ï¼Œæˆ‘ä»¬å¾—åˆ°ğ”¼[X]/span>0 å½“ä¸”ä»…å½“
- en: '![#winning-cards bet- #losing cards > pot, ](img/file1916.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![#winning-cards bet- #losing cards > pot, ](img/file1916.png)'
- en: which is called positive pot odds. If this is satisfied, making the bet is the
    right call. You might lose a hand with positive pot odds, but in the long term,
    your winnings will be positive.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¢«ç§°ä¸ºæ­£åº•æ± èµ”ç‡ã€‚å¦‚æœæ»¡è¶³è¿™ä¸€æ¡ä»¶ï¼Œä¸‹æ³¨æ˜¯æ­£ç¡®çš„é€‰æ‹©ã€‚å°½ç®¡åœ¨å•æ‰‹ç‰Œä¸­ä½ å¯èƒ½ä¼šè¾“ï¼Œä½†ä»é•¿è¿œæ¥çœ‹ï¼Œä½ çš„æ”¶ç›Šå°†æ˜¯æ­£çš„ã€‚
- en: Of course, pot odds are extremely hard to determine in practice. For instance,
    you donâ€™t know what others hold, and counting the cards that would win the pot
    for you is not possible unless you have a good read on the opponents. Poker is
    much more than just math. Good players choose their bet specifically to throw
    off their opponentsâ€™ pot odds.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œåº•æ± èµ”ç‡åœ¨å®è·µä¸­éå¸¸éš¾ä»¥ç¡®å®šã€‚ä¾‹å¦‚ï¼Œä½ ä¸çŸ¥é“åˆ«äººæŒæœ‰ä»€ä¹ˆç‰Œï¼Œé™¤éä½ å¯¹å¯¹æ‰‹æœ‰å¾ˆå¥½çš„é˜…è¯»èƒ½åŠ›ï¼Œå¦åˆ™æ— æ³•è®¡ç®—å‡ºå“ªäº›ç‰Œä¼šä¸ºä½ èµ¢å¾—åº•æ± ã€‚æ‰‘å…‹è¿œä¸æ­¢æ˜¯æ•°å­¦ã€‚ä¼˜ç§€çš„ç©å®¶ä¼šç‰¹åˆ«é€‰æ‹©ä¸‹æ³¨æ–¹å¼ï¼Œæ¥è®©å¯¹æ‰‹çš„åº•æ± èµ”ç‡äº§ç”Ÿè¯¯å¯¼ã€‚
- en: Now that we understand the idea behind the expected value, letâ€™s move on to
    the general case!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬ç†è§£äº†æœŸæœ›å€¼çš„åŸºæœ¬æ¦‚å¿µï¼Œè®©æˆ‘ä»¬ç»§ç»­æ¢è®¨ä¸€èˆ¬æƒ…å†µï¼
- en: 20.2 Continuous random variables
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.2 è¿ç»­éšæœºå˜é‡
- en: So far, we have only defined the expected value for discrete random variables.
    As ğ”¼[X] describes the average value of X in the long run, it should exist for
    continuous random variables as well.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬åªä¸ºç¦»æ•£éšæœºå˜é‡å®šä¹‰äº†æœŸæœ›å€¼ã€‚ç”±äºğ”¼[X]æè¿°çš„æ˜¯Xåœ¨é•¿æ—¶é—´å†…çš„å¹³å‡å€¼ï¼Œå› æ­¤å®ƒå¯¹äºè¿ç»­éšæœºå˜é‡ä¹Ÿåº”è¯¥æ˜¯å­˜åœ¨çš„ã€‚
- en: 'The interpretation of the expected value was simple: outcome times probability,
    summed over all potential values. However, there is a snag with continuous random
    variables: we donâ€™t have such a mass distribution, as the probabilities of individual
    outcomes are zero: P(X = x) = 0\. Moreover, we canâ€™t sum uncountably many values.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æœŸæœ›å€¼çš„è§£é‡Šå¾ˆç®€å•ï¼šç»“æœä¹˜ä»¥æ¦‚ç‡ï¼Œå¯¹æ‰€æœ‰å¯èƒ½çš„å€¼æ±‚å’Œã€‚ç„¶è€Œï¼Œè¿ç»­éšæœºå˜é‡æœ‰ä¸€ä¸ªé—®é¢˜ï¼šæˆ‘ä»¬æ²¡æœ‰è¿™æ ·çš„è´¨é‡åˆ†å¸ƒï¼Œå› ä¸ºå•ä¸ªç»“æœçš„æ¦‚ç‡ä¸ºé›¶ï¼šP(X = x) =
    0ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ— æ³•å¯¹æ— ç©·å¤šä¸ªå€¼æ±‚å’Œã€‚
- en: What can we do?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬èƒ½åšä»€ä¹ˆå‘¢ï¼Ÿ
- en: Wishful thinking. This is one of the most powerful techniques in mathematics,
    and I am not joking.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€å¢æƒ…æ„¿çš„æƒ³æ³•ã€‚è¿™æ˜¯æ•°å­¦ä¸­æœ€å¼ºå¤§çš„æŠ€å·§ä¹‹ä¸€ï¼Œæˆ‘ä¸æ˜¯åœ¨å¼€ç©ç¬‘ã€‚
- en: Hereâ€™s the plan. Weâ€™ll pretend that the expected value of a continuous random
    variable is well-defined, and let our imagination run free. Say goodbye to mathematical
    precision, and allow our intuition to unfold. Instead of the probability of a
    given outcome, we can talk about X landing in a small interval. First, we divide
    up the set of real numbers into really small parts. To be more precise, let x[0]/span>x[1]/span>â€¦/span>x[n]
    be a granular partition of the real line. If the partition is refined enough,
    we should have
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡åˆ’æ˜¯è¿™æ ·çš„ã€‚æˆ‘ä»¬å‡è®¾è¿ç»­éšæœºå˜é‡çš„æœŸæœ›å€¼æ˜¯å®šä¹‰è‰¯å¥½çš„ï¼Œè®©æˆ‘ä»¬çš„æƒ³è±¡åŠ›è‡ªç”±å‘æŒ¥ã€‚å‘Šåˆ«æ•°å­¦ç²¾ç¡®æ€§ï¼Œè®©æˆ‘ä»¬çš„ç›´è§‰å±•å¼€ã€‚ä¸å…¶è°ˆè®ºæŸä¸€ç»“æœçš„æ¦‚ç‡ï¼Œæˆ‘ä»¬å¯ä»¥è®¨è®º
    X è½åœ¨ä¸€ä¸ªå°åŒºé—´å†…ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†å®æ•°é›†åˆ’åˆ†ä¸ºéå¸¸å°çš„éƒ¨åˆ†ã€‚æ›´ç²¾ç¡®åœ°è¯´ï¼Œè®¾ x[0]/span>x[1]/span>â€¦/span>x[n] æ˜¯å®æ•°çº¿çš„ç²¾ç»†åˆ’åˆ†ã€‚å¦‚æœåˆ’åˆ†è¶³å¤Ÿç²¾ç»†ï¼Œæˆ‘ä»¬åº”è¯¥å¾—åˆ°ï¼š
- en: ğ”¼[X] â‰ˆ âˆ‘[k=1]^n x[k] P(x[kâˆ’1] â‰¤ X â‰¤ x[k]) (20.1)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ğ”¼[X] â‰ˆ âˆ‘[k=1]^n x[k] P(x[kâˆ’1] â‰¤ X â‰¤ x[k]) (20.1)
- en: 'The probabilities in ([20.1](ch032.xhtml#continuous-random-variables)) can
    be expressed in terms of the CDF:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ ([20.1](ch032.xhtml#continuous-random-variables)) ä¸­çš„æ¦‚ç‡å¯ä»¥ç”¨ CDF è¡¨ç¤ºï¼š
- en: '![ n n âˆ‘ x P(x <X â‰¤ X ) = âˆ‘ x (F (x ) âˆ’ F (x )). k kâˆ’1 k k X k X kâˆ’1 k=1 k=1
    ](img/file1917.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![ n n âˆ‘ x P(x <X â‰¤ X ) = âˆ‘ x (F (x ) âˆ’ F (x )). k kâˆ’1 k k X k X kâˆ’1 k=1 k=1
    ](img/file1917.png)'
- en: 'These increments remind us of the difference quotients. We donâ€™t quite have
    these inside the sum, but with a â€œfancy multiplication with one,â€ we can achieve
    this:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¢é‡è®©æˆ‘ä»¬æƒ³èµ·äº†å·®åˆ†å•†ã€‚è™½ç„¶åœ¨æ±‚å’Œä¸­æˆ‘ä»¬æ²¡æœ‰å®Œå…¨å¾—åˆ°è¿™äº›ï¼Œä½†é€šè¿‡â€œå·§å¦™çš„ä¹˜ä»¥ 1â€ï¼Œæˆ‘ä»¬å¯ä»¥å®ç°è¿™ä¸€ç‚¹ï¼š
- en: '![âˆ‘n âˆ‘n xk(FX (xk)âˆ’ FX (xkâˆ’1)) = xk(xk âˆ’ xkâˆ’1)FX-(xk)âˆ’-FX-(xkâˆ’1). k=1 k=1 xk
    âˆ’ xkâˆ’ 1 ](img/file1918.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ‘n âˆ‘n xk(FX (xk)âˆ’ FX (xkâˆ’1)) = xk(xk âˆ’ xkâˆ’1)FX-(xk)âˆ’-FX-(xkâˆ’1). k=1 k=1 xk
    âˆ’ xkâˆ’ 1 ](img/file1918.png)'
- en: If the x[i]-s are close to each other (and we can select them to be arbitrarily
    close), the difference quotients are close to the derivative of F[X], which is
    the density function f[X]. Thus,
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ x[i] å½¼æ­¤æ¥è¿‘ï¼ˆè€Œä¸”æˆ‘ä»¬å¯ä»¥é€‰æ‹©å®ƒä»¬ä»»æ„æ¥è¿‘ï¼‰ï¼Œé‚£ä¹ˆå·®åˆ†å•†æ¥è¿‘äº F[X] çš„å¯¼æ•°ï¼Œå³å¯†åº¦å‡½æ•° f[X]ã€‚å› æ­¤ï¼Œ
- en: '![FX (xk)âˆ’ FX (xkâˆ’1) âˆ‘n FX (xk)âˆ’ FX (xkâˆ’1) âˆ‘n -----x-âˆ’-x-------- â‰ˆ fX (xk )
    xk(xk âˆ’ xkâˆ’1)-----x-âˆ’-x-------- â‰ˆ xk(xk âˆ’ xk âˆ’1)fX(xk). k kâˆ’ 1 k=1 k kâˆ’ 1 k=1
    ](img/file1919.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![FX (xk)âˆ’ FX (xkâˆ’1) âˆ‘n FX (xk)âˆ’ FX (xkâˆ’1) âˆ‘n -----x-âˆ’-x-------- â‰ˆ fX (xk )
    xk(xk âˆ’ xkâˆ’1)-----x-âˆ’-x-------- â‰ˆ xk(xk âˆ’ xk âˆ’1)fX(xk). k kâˆ’ 1 k=1 k kâˆ’ 1 k=1
    ](img/file1919.png)'
- en: 'This is a Riemann-sum, defined by ([14.7](#))! Hence, the last sum is close
    to a Riemann-integral:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªé»æ›¼å’Œï¼Œå®šä¹‰è§äº ([14.7](#))ï¼å› æ­¤ï¼Œæœ€åçš„å’Œæ¥è¿‘äºé»æ›¼ç§¯åˆ†ï¼š
- en: '![ n âˆ« âˆ‘ âˆ xk(xk âˆ’ xkâˆ’1)fX(xk) â‰ˆ âˆ’âˆ xfX (x)dx. k=1 ](img/file1920.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![ n âˆ« âˆ‘ âˆ xk(xk âˆ’ xkâˆ’1)fX(xk) â‰ˆ âˆ’âˆ xfX (x)dx. k=1 ](img/file1920.png)'
- en: Although we were not exactly precise in our argument, all of the above can be
    made mathematically correct. (But we are not going to do it here, as it is not
    relevant to us.) Thus, we finally obtain the formula of the expected value for
    continuous random variables.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æˆ‘ä»¬åœ¨æ¨ç†ä¸­å¹¶æ²¡æœ‰å®Œå…¨ç²¾ç¡®ï¼Œä½†ä»¥ä¸Šæ‰€æœ‰å†…å®¹éƒ½å¯ä»¥åœ¨æ•°å­¦ä¸Šå¾—åˆ°æ­£ç¡®å¤„ç†ã€‚ï¼ˆä¸è¿‡æˆ‘ä»¬è¿™é‡Œä¸åšï¼Œå› ä¸ºå®ƒä¸æˆ‘ä»¬æ— å…³ã€‚ï¼‰å› æ­¤ï¼Œæˆ‘ä»¬æœ€ç»ˆå¾—åˆ°äº†è¿ç»­éšæœºå˜é‡æœŸæœ›å€¼çš„å…¬å¼ã€‚
- en: Definition 93\. (The expected value of continuous random variables)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 93. ï¼ˆè¿ç»­éšæœºå˜é‡çš„æœŸæœ›å€¼ï¼‰
- en: 'Let (Î©,Î£,P) be a probability space, and X : Î© â†’â„ be a continuous random variable.
    The expected value of X is defined by'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ (Î©,Î£,P) æ˜¯ä¸€ä¸ªæ¦‚ç‡ç©ºé—´ï¼ŒX : Î© â†’ â„ æ˜¯ä¸€ä¸ªè¿ç»­éšæœºå˜é‡ã€‚X çš„æœŸæœ›å€¼ç”±ä»¥ä¸‹å…¬å¼å®šä¹‰ï¼š'
- en: '![ âˆ« âˆ ğ”¼ [X ] := xfX(x)dx. âˆ’âˆ ](img/file1921.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« âˆ ğ”¼ [X ] := xfX(x)dx. âˆ’âˆ ](img/file1921.png)'
- en: As usual, letâ€™s see some examples first.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œå¾€å¸¸ä¸€æ ·ï¼Œè®©æˆ‘ä»¬å…ˆçœ‹ä¸€äº›ä¾‹å­ã€‚
- en: Example 1\. Expected value of the uniform distribution. (See the definition
    of the uniform distribution in SectionÂ [19.3.4](ch031.xhtml#the-uniform-distribution2).)
    Let X âˆ¼ Uniform(a,b). Then
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 1. å‡åŒ€åˆ†å¸ƒçš„æœŸæœ›å€¼ã€‚ï¼ˆå‚è§ [19.3.4](ch031.xhtml#the-uniform-distribution2) èŠ‚ä¸­å¯¹å‡åŒ€åˆ†å¸ƒçš„å®šä¹‰ã€‚ï¼‰è®¾
    X âˆ¼ Uniform(a,b)ã€‚åˆ™
- en: '![ âˆ« âˆ 1 ğ”¼[X ] = x-----dx âˆ’ âˆ bâˆ«âˆ’ a --1-- b = b âˆ’ a xdx [ a ]x=b = ---1---x2
    2(b âˆ’ a) x=a a + b = --2--, ](img/file1922.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« âˆ 1 ğ”¼[X ] = x-----dx âˆ’ âˆ bâˆ«âˆ’ a --1-- b = b âˆ’ a xdx [ a ]x=b = ---1---x2
    2(b âˆ’ a) x=a a + b = --2--, ](img/file1922.png)'
- en: which is the midpoint of the interval [a,b], where the Uniform(a,b) lives.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¡¨ç¤ºåŒºé—´ [a,b] çš„ä¸­ç‚¹ï¼Œå…¶ä¸­ Uniform(a,b) åˆ†å¸ƒå­˜åœ¨ã€‚
- en: Example 2\. Expected value of the exponential distribution. (See the definition
    of the exponential distribution in SectionÂ [19.3.5](ch031.xhtml#the-exponential-distribution).)
    Let X âˆ¼ exp(Î»). Then, we need to calculate the integral
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 2\. æŒ‡æ•°åˆ†å¸ƒçš„æœŸæœ›å€¼ã€‚ï¼ˆå‚è§ç¬¬[19.3.5](ch031.xhtml#the-exponential-distribution)èŠ‚ä¸­å…³äºæŒ‡æ•°åˆ†å¸ƒçš„å®šä¹‰ã€‚ï¼‰è®¾
    X âˆ¼ exp(Î»)ã€‚ç„¶åï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—ç§¯åˆ†
- en: '![ âˆ« âˆ âˆ’ Î»x ğ”¼[X ] = xÎ»e dx. 0 ](img/file1923.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« âˆ âˆ’ Î»x ğ”¼[X ] = xÎ»e dx. 0 ](img/file1923.png)'
- en: 'We can do this via integration by parts (TheoremÂ [95](ch022.xhtml#x1-238002r95)):
    by letting f(x) = x and g^â€²(x) = Î»e^(âˆ’Î»x), we have'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ†éƒ¨ç§¯åˆ†æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼ˆå®šç†[95](ch022.xhtml#x1-238002r95)ï¼‰ï¼šè®¾ f(x) = x ä¸” g^â€²(x) = Î»e^(âˆ’Î»x)ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![ âˆ« âˆ ğ”¼ [X ] = xÎ»eâˆ’Î»xdx 0 [ ]x=âˆ âˆ« âˆ = âˆ’ xeâˆ’Î»x x=0 + eâˆ’ Î»xdx â—Ÿ-----â—=â—œ0-----â—
    0 [ ]x=âˆ = âˆ’ 1-eâˆ’Î»x Î» x=0 1- = Î». ](img/file1924.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« âˆ ğ”¼ [X ] = xÎ»eâˆ’Î»xdx 0 [ ]x=âˆ âˆ« âˆ = âˆ’ xeâˆ’Î»x x=0 + eâˆ’ Î»xdx â—Ÿ-----â—=â—œ0-----â—
    0 [ ]x=âˆ = âˆ’ 1-eâˆ’Î»x Î» x=0 1- = Î». ](img/file1924.png)'
- en: 20.3 Properties of the expected value
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.3 æœŸæœ›å€¼çš„æ€§è´¨
- en: As usual, the expected value has several useful properties. Most importantly,
    the expected value is linear with respect to the random variable.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œå¾€å¸¸ä¸€æ ·ï¼ŒæœŸæœ›å€¼å…·æœ‰å‡ ä¸ªæœ‰ç”¨çš„æ€§è´¨ã€‚æœ€é‡è¦çš„æ˜¯ï¼ŒæœŸæœ›å€¼å¯¹éšæœºå˜é‡æ˜¯çº¿æ€§çš„ã€‚
- en: Theorem 129\. (Linearity of the expected value)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 129\. ï¼ˆæœŸæœ›å€¼çš„çº¿æ€§ï¼‰
- en: 'Let (Î©,Î£,P) be a probability space, and let X,Y : Î© â†’ â„ be two random variables.
    Moreover, let a,b âˆˆâ„ be two scalars. Then'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ (Î©,Î£,P) ä¸ºä¸€ä¸ªæ¦‚ç‡ç©ºé—´ï¼Œä¸”è®© X, Y : Î© â†’ â„ ä¸ºä¸¤ä¸ªéšæœºå˜é‡ã€‚è¿›ä¸€æ­¥è®¾ a, b âˆˆ â„ ä¸ºä¸¤ä¸ªæ ‡é‡ã€‚é‚£ä¹ˆ'
- en: '![ğ”¼[aX + bY ] = ağ”¼ [X ]+ bğ”¼ [Y ] ](img/file1925.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼[aX + bY ] = ağ”¼ [X ]+ bğ”¼ [Y ] ](img/file1925.png)'
- en: holds.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å…¬å¼æˆç«‹ã€‚
- en: We are not going to prove this theorem here, but know that linearity is an essential
    tool. Do you recall the game that we used to introduce the expected value for
    discrete random variables? I toss a coin, and if it comes up heads, you win $1\.
    Tails, you lose $2\. If you think about it for a minute, this is the
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿™é‡Œä¸ä¼šè¯æ˜è¿™ä¸ªå®šç†ï¼Œä½†è¦çŸ¥é“çº¿æ€§æ˜¯ä¸€ä¸ªé‡è¦çš„å·¥å…·ã€‚ä½ è¿˜è®°å¾—æˆ‘ä»¬ç”¨æ¥å¼•å…¥ç¦»æ•£éšæœºå˜é‡æœŸæœ›å€¼çš„æ¸¸æˆå—ï¼Ÿæˆ‘æ·ç¡¬å¸ï¼Œå¦‚æœæ­£é¢æœä¸Šï¼Œä½ èµ¢å¾— $1ï¼›åé¢æœä¸Šï¼Œä½ è¾“æ‰
    $2ã€‚å¦‚æœä½ æ€è€ƒä¸€ä¸‹ï¼Œè¿™å°±æ˜¯
- en: '![X = 3â‹…Bernoulli(1âˆ•2)âˆ’ 2 ](img/file1926.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![X = 3â‹…Bernoulli(1âˆ•2)âˆ’ 2 ](img/file1926.png)'
- en: distribution, and as such,
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†å¸ƒï¼Œå› æ­¤ï¼Œ
- en: '![ğ”¼[X] = ğ”¼[3â‹…Bernoulli(1 âˆ•2)âˆ’ 2] = 3â‹…ğ”¼ [Bernoulli(1 âˆ•2)]âˆ’ 2 = 3â‹… 1âˆ’ 2 2 1-
    = âˆ’ 2\. ](img/file1927.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼[X] = ğ”¼[3â‹…Bernoulli(1 âˆ•2)âˆ’ 2] = 3â‹…ğ”¼ [Bernoulli(1 âˆ•2)]âˆ’ 2 = 3â‹… 1âˆ’ 2 2 1-
    = âˆ’ 2\. ](img/file1927.png)'
- en: Of course, linearity goes way beyond this simple example. As youâ€™ve gotten used
    to this already, linearity is a crucial property in mathematics. We love linearity.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œçº¿æ€§è¿œä¸æ­¢è¿™ä¸ªç®€å•çš„ä¾‹å­ã€‚æ­£å¦‚ä½ å·²ç»ä¹ æƒ¯äº†çš„é‚£æ ·ï¼Œçº¿æ€§æ˜¯æ•°å­¦ä¸­çš„ä¸€ä¸ªå…³é”®æ€§è´¨ã€‚æˆ‘ä»¬å–œæ¬¢çº¿æ€§ã€‚
- en: Remark 20\.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å¤‡æ³¨ 20\.
- en: Notice that TheoremÂ [129](ch032.xhtml#x1-331002r129) did not say that X and
    Y have to be both discrete or both continuous. Even though we have only defined
    the expected value in such cases, there is a general definition that works for
    all random variables.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå®šç†[129](ch032.xhtml#x1-331002r129)å¹¶æœªè¯´æ˜ X å’Œ Y å¿…é¡»éƒ½æ˜¯ç¦»æ•£çš„æˆ–éƒ½æ˜¯è¿ç»­çš„ã€‚å°½ç®¡æˆ‘ä»¬åªåœ¨è¿™ç§æƒ…å†µä¸‹å®šä¹‰äº†æœŸæœ›å€¼ï¼Œä½†å­˜åœ¨ä¸€ä¸ªé€‚ç”¨äºæ‰€æœ‰éšæœºå˜é‡çš„é€šç”¨å®šä¹‰ã€‚
- en: The snag is, it requires a familiarity with measure theory, falling way outside
    of our scope. Suffice to say, the theorem works as is.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜åœ¨äºï¼Œå®ƒéœ€è¦ç†Ÿæ‚‰æµ‹åº¦ç†è®ºï¼Œè€Œè¿™è¶…å‡ºäº†æˆ‘ä»¬çš„èŒƒå›´ã€‚åªéœ€çŸ¥é“ï¼Œè¿™ä¸ªå®šç†æŒ‰åŸæ ·æˆç«‹ã€‚
- en: If the expected value of a sum is the sum of the expected values, does the same
    apply to the product? Not in general, but fortunately, this works for independent
    random variables. (See DefinitionÂ [84](ch031.xhtml#x1-305002r84) for the definition
    of independent random variables.)
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå’Œçš„æœŸæœ›å€¼æ˜¯å„è‡ªæœŸæœ›å€¼çš„å’Œï¼Œé‚£ä¹ˆä¹˜ç§¯æ˜¯å¦ä¹Ÿé€‚ç”¨ï¼Ÿä¸€èˆ¬æ¥è¯´ä¸é€‚ç”¨ï¼Œä½†å¹¸è¿çš„æ˜¯ï¼Œè¿™åœ¨ç‹¬ç«‹éšæœºå˜é‡çš„æƒ…å†µä¸‹æˆç«‹ã€‚ï¼ˆå‚è§å®šç†[84](ch031.xhtml#x1-305002r84)ï¼Œå…¶ä¸­ç»™å‡ºäº†ç‹¬ç«‹éšæœºå˜é‡çš„å®šä¹‰ã€‚ï¼‰
- en: Theorem 130\. (Expected value of the product of independent random variables)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 130\. ï¼ˆç‹¬ç«‹éšæœºå˜é‡ä¹˜ç§¯çš„æœŸæœ›å€¼ï¼‰
- en: 'Let (Î©,Î£,P) be a probability space, and let X,Y : Î© â†’â„ be two independent random
    variables.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ (Î©,Î£,P) ä¸ºä¸€ä¸ªæ¦‚ç‡ç©ºé—´ï¼Œä¸”è®© X, Y : Î© â†’ â„ ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„éšæœºå˜é‡ã€‚'
- en: Then
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶å
- en: '![ğ”¼ [XY ] = ğ”¼ [X ]ğ”¼[Y] ](img/file1928.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼ [XY ] = ğ”¼ [X ]ğ”¼[Y] ](img/file1928.png)'
- en: holds.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: å…¬å¼æˆç«‹ã€‚
- en: This property is extremely useful, as weâ€™ll see in the next section, where weâ€™ll
    talk about variance and covariance.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ€§è´¨éå¸¸æœ‰ç”¨ï¼Œæ­£å¦‚æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å°†è®¨è®ºæ–¹å·®å’Œåæ–¹å·®ã€‚
- en: 'One more property thatâ€™ll help us to calculate the expected value of functions
    of the random variable, such as XÂ² or sinX:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªå¸®åŠ©æˆ‘ä»¬è®¡ç®—éšæœºå˜é‡å‡½æ•°æœŸæœ›å€¼çš„æ€§è´¨ï¼Œæ¯”å¦‚ XÂ² æˆ– sinXï¼š
- en: Theorem 131\. (Law of the unconscious statistician)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 131\. ï¼ˆæ— æ„è¯†ç»Ÿè®¡å­¦å®¶çš„æ³•åˆ™ï¼‰
- en: 'Let (Î©,Î£,P) be a probability space, let X : Î© â†’ â„ be a random variable, and
    let g : â„ â†’â„ be an arbitrary function.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ (Î©,Î£,P) ä¸ºä¸€ä¸ªæ¦‚ç‡ç©ºé—´ï¼Œè®¾ X : Î© â†’ â„ ä¸ºä¸€ä¸ªéšæœºå˜é‡ï¼Œä¸”è®¾ g : â„ â†’ â„ ä¸ºä¸€ä¸ªä»»æ„å‡½æ•°ã€‚'
- en: (a) If X is discrete with possible values x[1],x[2],â€¦, then
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: (a) å¦‚æœ X æ˜¯ç¦»æ•£çš„ï¼Œä¸”å¯èƒ½çš„å–å€¼ä¸º x[1], x[2], â€¦ï¼Œé‚£ä¹ˆ
- en: '![ âˆ‘ ğ”¼[g(X)] = g(xn)P (X = xn). n ](img/file1929.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘ ğ”¼[g(X)] = g(xn)P (X = xn). n ](img/file1929.png)'
- en: (b) If X is continuous with the probability density function f[X](x), then
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: (b) å¦‚æœXæ˜¯å…·æœ‰æ¦‚ç‡å¯†åº¦å‡½æ•°f[X](x)çš„è¿ç»­å‹éšæœºå˜é‡ï¼Œåˆ™
- en: '![ âˆ« âˆ ğ”¼[g(X )] = g(x)f (x)dx. âˆ’âˆ X ](img/file1930.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« âˆ ğ”¼[g(X )] = g(x)f (x)dx. âˆ’âˆ X ](img/file1930.png)'
- en: Thus, calculating ğ”¼[XÂ²] for a continuous random variable can be done by simply
    taking
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè®¡ç®—è¿ç»­éšæœºå˜é‡çš„ğ”¼[XÂ²]å¯ä»¥é€šè¿‡ç®€å•åœ°å–
- en: '![ âˆ« âˆ ğ”¼[X2] = x2fX (x)dx, âˆ’âˆ ](img/file1931.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« âˆ ğ”¼[XÂ²] = xÂ²fX (x)dx, âˆ’âˆ ](img/file1931.png)'
- en: which will be used all the time.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­è¢«é¢‘ç¹ä½¿ç”¨ã€‚
- en: 20.4 Variance
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.4 æ–¹å·®
- en: Plainly speaking, the expected value measures the average value of the random
    variable. However, even though both Uniform(âˆ’1,1) and Uniform(âˆ’100,100) have zero
    expected value, the latter is much more spread out than the former. Thus, ğ”¼[X]
    is not a good descriptor of the random variable X.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€å•æ¥è¯´ï¼ŒæœŸæœ›å€¼è¡¡é‡çš„æ˜¯éšæœºå˜é‡çš„å¹³å‡å€¼ã€‚ç„¶è€Œï¼Œå³ä½¿Uniform(âˆ’1,1)å’ŒUniform(âˆ’100,100)çš„æœŸæœ›å€¼éƒ½æ˜¯é›¶ï¼Œåè€…çš„åˆ†å¸ƒå´æ¯”å‰è€…è¦å¹¿æ³›å¾—å¤šã€‚å› æ­¤ï¼Œğ”¼[X]å¹¶ä¸æ˜¯æè¿°éšæœºå˜é‡Xçš„å¥½æ–¹æ³•ã€‚
- en: To add one more layer, we measure the average deviation from the expected value.
    This is done via the variance and the standard deviation.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å†åŠ ä¸€å±‚ï¼Œæˆ‘ä»¬è¡¡é‡çš„æ˜¯æœŸæœ›å€¼çš„å¹³å‡åå·®ã€‚è¿™æ˜¯é€šè¿‡æ–¹å·®å’Œæ ‡å‡†å·®æ¥å®ç°çš„ã€‚
- en: Definition 94\. (Variance and standard deviation)
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 94\. (æ–¹å·®ä¸æ ‡å‡†å·®)
- en: 'Let (Î©,Î£,P) be a probability space, let X : Î© â†’â„ be a random variable, and
    let Î¼ = ğ”¼[X] be its expected value. The variance of X is defined by'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾(Î©, Î£, P)ä¸ºä¸€ä¸ªæ¦‚ç‡ç©ºé—´ï¼Œè®¾X : Î© â†’ â„ä¸ºä¸€ä¸ªéšæœºå˜é‡ï¼Œä¸”Î¼ = ğ”¼[X]ä¸ºå…¶æœŸæœ›å€¼ã€‚Xçš„æ–¹å·®å®šä¹‰ä¸º'
- en: '![ [ 2] Var [X ] := ğ”¼ (X âˆ’ Î¼ ) , ](img/file1932.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![ [ 2] æ–¹å·® [X ] := ğ”¼ (X âˆ’ Î¼ ) , ](img/file1932.png)'
- en: while its standard deviation is defined by
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶æ ‡å‡†å·®å®šä¹‰ä¸º
- en: '![Std[X] := âˆ˜Var--[X-]. ](img/file1933.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![Std[X] := âˆ˜æ–¹å·®--[X-]. ](img/file1933.png)'
- en: Take note that in the literature, the expected value is often denoted by Î¼,
    while the standard deviation is denoted by Ïƒ. Together, they form two of the most
    important descriptors of a random variable.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œåœ¨æ–‡çŒ®ä¸­ï¼ŒæœŸæœ›å€¼é€šå¸¸ç”¨Î¼è¡¨ç¤ºï¼Œè€Œæ ‡å‡†å·®ç”¨Ïƒè¡¨ç¤ºã€‚äºŒè€…ä¸€èµ·æ„æˆäº†æè¿°éšæœºå˜é‡çš„ä¸¤ä¸ªæœ€é‡è¦çš„æŒ‡æ ‡ã€‚
- en: FigureÂ [20.2](#) shows a visual interpretation of the mean and standard deviation
    in the case of a normal distribution. The mean shows the average value, while
    the standard deviation can be interpreted as the average deviation from the mean.
    (Weâ€™ll talk about the normal distribution in detail later, so donâ€™t worry if it
    is not yet familiar to you.)
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾[20.2](#)å±•ç¤ºäº†åœ¨æ­£æ€åˆ†å¸ƒæƒ…å†µä¸‹ï¼Œå‡å€¼å’Œæ ‡å‡†å·®çš„å¯è§†åŒ–è§£é‡Šã€‚å‡å€¼è¡¨ç¤ºå¹³å‡å€¼ï¼Œè€Œæ ‡å‡†å·®å¯ä»¥è§£é‡Šä¸ºå¹³å‡åç¦»å‡å€¼çš„ç¨‹åº¦ã€‚ï¼ˆæˆ‘ä»¬ç¨åä¼šè¯¦ç»†è®¨è®ºæ­£æ€åˆ†å¸ƒï¼Œæ‰€ä»¥å¦‚æœç°åœ¨è¿˜ä¸ç†Ÿæ‚‰ï¼Œä¹Ÿä¸ç”¨æ‹…å¿ƒã€‚ï¼‰
- en: '![PIC](img/file1934.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1934.png)'
- en: 'FigureÂ 20.2: Mean (Î¼) and standard deviation ![(Ïƒ) ](img/file1935.png) of the
    standard normal distribution'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾20.2ï¼šæ ‡å‡†æ­£æ€åˆ†å¸ƒçš„å‡å€¼(Î¼)å’Œæ ‡å‡†å·® !(Ïƒ) ](img/file1935.png)
- en: The usual method of calculating variance is not taking the expected value of
    (X âˆ’Î¼)Â², but taking the expected value of XÂ² and subtracting Î¼Â² from it. This
    is shown by the following proposition.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—æ–¹å·®çš„å¸¸ç”¨æ–¹æ³•ä¸æ˜¯å–(X âˆ’ Î¼)Â²çš„æœŸæœ›å€¼ï¼Œè€Œæ˜¯å–XÂ²çš„æœŸæœ›å€¼å¹¶ä»ä¸­å‡å»Î¼Â²ã€‚ä»¥ä¸‹å‘½é¢˜å±•ç¤ºäº†è¿™ä¸€ç‚¹ã€‚
- en: Proposition 5\.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: å‘½é¢˜ 5\.
- en: 'Let (Î©,Î£,P) be a probability space, and let X : Î© â†’â„ be a random variable.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾(Î©, Î£, P)ä¸ºä¸€ä¸ªæ¦‚ç‡ç©ºé—´ï¼Œä¸”X : Î© â†’ â„ä¸ºä¸€ä¸ªéšæœºå˜é‡ã€‚'
- en: Then
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶å
- en: '![Var[X] = ğ”¼[X2 ]âˆ’ ğ”¼[X ]2\. ](img/file1936.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![æ–¹å·®[X] = ğ”¼[XÂ² ]âˆ’ ğ”¼[X ]Â²\. ](img/file1936.png)'
- en: Proof. Let Î¼ = ğ”¼[X]. Because of the linearity of the expected value, we have
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚è®¾Î¼ = ğ”¼[X]ã€‚ç”±äºæœŸæœ›å€¼çš„çº¿æ€§æ€§è´¨ï¼Œæˆ‘ä»¬æœ‰
- en: '![Var[X ] = ğ”¼[(X âˆ’ Î¼)2] = ğ”¼[X2 âˆ’ 2Î¼X + Î¼2] = ğ”¼[X ]2 âˆ’ 2Î¼ğ”¼ [X ]+ Î¼2 2 2 2 =
    ğ”¼[X ] âˆ’ 2Î¼ + Î¼ = ğ”¼[X2 ]âˆ’ Î¼2 = ğ”¼[X2 ]âˆ’ ğ”¼[X ]2, ](img/file1937.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![æ–¹å·®[X ] = ğ”¼[(X âˆ’ Î¼)Â²] = ğ”¼[XÂ² âˆ’ 2Î¼X + Î¼Â²] = ğ”¼[X ]Â² âˆ’ 2Î¼ğ”¼ [X ]+ Î¼Â² 2 2 2 = ğ”¼[X
    ] âˆ’ 2Î¼ + Î¼ = ğ”¼[XÂ² ]âˆ’ Î¼Â² = ğ”¼[XÂ² ]âˆ’ ğ”¼[X ]Â², ](img/file1937.png)'
- en: which is what we had to show.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦è¯æ˜çš„ã€‚
- en: Is the variance linear as well? No, but there are some important identities
    regarding scalar multiplication and addition.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹å·®ä¹Ÿå…·æœ‰çº¿æ€§æ€§è´¨å—ï¼Ÿä¸ï¼Œä½†å…³äºæ ‡é‡ä¹˜æ³•å’ŒåŠ æ³•ï¼Œæœ‰ä¸€äº›é‡è¦çš„æ’ç­‰å¼ã€‚
- en: Theorem 132\. (Variance and the linear operations)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 132\. (æ–¹å·®ä¸çº¿æ€§è¿ç®—)
- en: 'Let (Î©,Î£,P) be a probability space, and let X : Î© â†’â„ be a random variable.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾(Î©, Î£, P)ä¸ºä¸€ä¸ªæ¦‚ç‡ç©ºé—´ï¼Œä¸”X : Î© â†’ â„ä¸ºä¸€ä¸ªéšæœºå˜é‡ã€‚'
- en: (a) Let a âˆˆâ„ be an arbitrary constant. Then
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: (a) è®¾a âˆˆ â„ä¸ºä»»æ„å¸¸æ•°ã€‚é‚£ä¹ˆ
- en: '![ 2 Var[aX ] = a Var[X ]. ](img/file1938.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 æ–¹å·®[aX ] = a æ–¹å·®[X ]. ](img/file1938.png)'
- en: '(b) Let Y : Î© â†’â„ be a random variable that is independent from X. Then'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '(b) è®¾Y : Î© â†’ â„ä¸ºä¸€ä¸ªä¸Xç‹¬ç«‹çš„éšæœºå˜é‡ã€‚é‚£ä¹ˆ'
- en: '![Var[X + Y ] = Var[X ]+ Var[Y]. ](img/file1939.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![æ–¹å·®[X + Y ] = æ–¹å·®[X ]+ æ–¹å·®[Y]. ](img/file1939.png)'
- en: Proof. (a) Let Î¼[X] = ğ”¼[X]. Then we have
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚(a) è®¾Î¼[X] = ğ”¼[X]ã€‚åˆ™æˆ‘ä»¬æœ‰
- en: '![ [ ] [ ] Var[aX ] = ğ”¼ (aX âˆ’ a Î¼X)2 = ğ”¼ a2(X âˆ’ Î¼X )2 [ ] = a2ğ”¼ (X âˆ’ Î¼X )2
    = a2Var[X ], ](img/file1940.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![ [ ] [ ] Var[aX ] = ğ”¼ (aX âˆ’ a Î¼X)2 = ğ”¼ a2(X âˆ’ Î¼X )2 [ ] = a2ğ”¼ (X âˆ’ Î¼X )2
    = a2Var[X ], ](img/file1940.png)'
- en: which is what we had to show. (b) Let Î¼[Y] = ğ”¼[Y ]. Then, due to the linearity
    of the expected value, we have
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦å±•ç¤ºçš„ç»“æœã€‚ï¼ˆbï¼‰ä»¤Î¼[Y] = ğ”¼[Y]ã€‚ç„¶åï¼Œç”±äºæœŸæœ›å€¼çš„çº¿æ€§æ€§è´¨ï¼Œæˆ‘ä»¬æœ‰ï¼š
- en: '![ [ 2] Var[X + Y ] = ğ”¼ (X + Y âˆ’ (Î¼X + Î¼Y )) [ 2] = ğ”¼ ((X âˆ’ Î¼X ) + (Y âˆ’ Î¼Y))
    = ğ”¼ [(X âˆ’ Î¼X)2]+ 2ğ”¼[(X âˆ’ Î¼X )(Y âˆ’ Î¼Y)] + ğ”¼[(Y âˆ’ Î¼Y )2]. ](img/file1941.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![ [ 2] Var[X + Y ] = ğ”¼ (X + Y âˆ’ (Î¼X + Î¼Y )) [ 2] = ğ”¼ ((X âˆ’ Î¼X ) + (Y âˆ’ Î¼Y))
    = ğ”¼ [(X âˆ’ Î¼X)2]+ 2ğ”¼[(X âˆ’ Î¼X )(Y âˆ’ Î¼Y)] + ğ”¼[(Y âˆ’ Î¼Y )2]. ](img/file1941.png)'
- en: Now, as X and Y are independent, ğ”¼[XY ] = ğ”¼[X]ğ”¼[Y ]. Thus, due to the linearity
    of the expected value,
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œç”±äºXå’ŒYæ˜¯ç‹¬ç«‹çš„ï¼Œğ”¼[XY ] = ğ”¼[X]ğ”¼[Y]ã€‚å› æ­¤ï¼Œç”±äºæœŸæœ›å€¼çš„çº¿æ€§æ€§è´¨ï¼Œ
- en: '![ [ ] [ ] ğ”¼ (X âˆ’ Î¼X )(Y âˆ’ Î¼Y) = ğ”¼ XY âˆ’ X Î¼Y âˆ’ Î¼X Y + Î¼X Î¼Y = ğ”¼[XY ] âˆ’ ğ”¼[X
    Î¼ ]âˆ’ ğ”¼ [Î¼ Y ]+ Î¼ Î¼ [ ] [ ] [Y ] X [ ] X Y = ğ”¼ X ğ”¼ Y âˆ’ ğ”¼ X Î¼Y âˆ’ Î¼X ğ”¼ Y + Î¼X Î¼Y
    = Î¼XÎ¼Y âˆ’ Î¼XÎ¼Y âˆ’ Î¼XÎ¼Y + Î¼XÎ¼Y = 0\. ](img/file1942.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![ [ ] [ ] ğ”¼ (X âˆ’ Î¼X )(Y âˆ’ Î¼Y) = ğ”¼ XY âˆ’ X Î¼Y âˆ’ Î¼X Y + Î¼X Î¼Y = ğ”¼[XY ] âˆ’ ğ”¼[X
    Î¼ ]âˆ’ ğ”¼ [Î¼ Y ]+ Î¼ Î¼ [ ] [ ] [Y ] X [ ] X Y = ğ”¼ X ğ”¼ Y âˆ’ ğ”¼ X Î¼Y âˆ’ Î¼X ğ”¼ Y + Î¼X Î¼Y
    = Î¼XÎ¼Y âˆ’ Î¼XÎ¼Y âˆ’ Î¼XÎ¼Y + Î¼XÎ¼Y = 0\. ](img/file1942.png)'
- en: Thus, continuing the first calculation,
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œç»§ç»­è¿›è¡Œç¬¬ä¸€æ¬¡è®¡ç®—ï¼Œ
- en: '![Var[X + Y ] = ğ”¼ [(X âˆ’ Î¼ )2]+ 2ğ”¼[(X âˆ’ Î¼ )(Y âˆ’ Î¼ )] + ğ”¼[(Y âˆ’ Î¼ )2] X X Y Y
    = ğ”¼ [(X âˆ’ Î¼X)2]+ ğ”¼[(Y âˆ’ Î¼Y )2], ](img/file1943.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![Var[X + Y ] = ğ”¼ [(X âˆ’ Î¼ )2]+ 2ğ”¼[(X âˆ’ Î¼ )(Y âˆ’ Î¼ )] + ğ”¼[(Y âˆ’ Î¼ )2] X X Y Y
    = ğ”¼ [(X âˆ’ Î¼X)2]+ ğ”¼[(Y âˆ’ Î¼Y )2], ](img/file1943.png)'
- en: which is what we had to show.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦å±•ç¤ºçš„ç»“æœã€‚
- en: 20.4.1 Covariance and correlation
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.4.1 åæ–¹å·®å’Œç›¸å…³æ€§
- en: Expected value and variance measure a random variable in isolation. However,
    in real problems, we need to discover relations between separate measurements.
    Say, X describes the price of a given real estate, while Y measures its size.
    These are certainly related, but one does not determine the other. For instance,
    the location might be a differentiator between the prices.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: æœŸæœ›å€¼å’Œæ–¹å·®åº¦é‡äº†ä¸€ä¸ªéšæœºå˜é‡çš„ç‹¬ç«‹æ€§ã€‚ç„¶è€Œï¼Œåœ¨å®é™…é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å‘ç°ä¸åŒæµ‹é‡ä¹‹é—´çš„å…³ç³»ã€‚å‡è®¾ï¼ŒXè¡¨ç¤ºç»™å®šæˆ¿åœ°äº§çš„ä»·æ ¼ï¼Œè€ŒYè¡¨ç¤ºå…¶é¢ç§¯ã€‚è¿™ä¸¤è€…è‚¯å®šæ˜¯ç›¸å…³çš„ï¼Œä½†å¹¶ä¸æ˜¯äº’ç›¸å†³å®šçš„ã€‚ä¾‹å¦‚ï¼Œä½ç½®å¯èƒ½æ˜¯ä»·æ ¼å·®å¼‚çš„å› ç´ ã€‚
- en: The simplest statistical way of measuring similarity is the covariance and correlation.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: æµ‹é‡ç›¸ä¼¼æ€§çš„æœ€ç®€å•ç»Ÿè®¡æ–¹æ³•æ˜¯åæ–¹å·®å’Œç›¸å…³æ€§ã€‚
- en: Definition 95\. (Covariance and correlation)
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 95.ï¼ˆåæ–¹å·®ä¸ç›¸å…³æ€§ï¼‰
- en: 'Let (Î©,Î£,P) be a probability space, let X,Y : Î© â†’ â„ be two random variables,
    and let Î¼[X] = ğ”¼[X],Î¼[Y] = ğ”¼[Y ] be their expected values and Ïƒ[X] = Std[X],Ïƒ[Y]
    = Std[Y ] their standard deviations.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾(Î©,Î£,P)ä¸ºæ¦‚ç‡ç©ºé—´ï¼Œè®¾X,Y : Î© â†’ â„ä¸ºä¸¤ä¸ªéšæœºå˜é‡ï¼Œä¸”Î¼[X] = ğ”¼[X]ï¼ŒÎ¼[Y] = ğ”¼[Y]ä¸ºå®ƒä»¬çš„æœŸæœ›å€¼ï¼ŒÏƒ[X] = Std[X]ï¼ŒÏƒ[Y]
    = Std[Y]ä¸ºå®ƒä»¬çš„æ ‡å‡†å·®ã€‚'
- en: (a) The covariance of X and Y is defined by
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Xå’ŒYçš„åæ–¹å·®ç”±ä¸‹å¼å®šä¹‰ï¼š
- en: '![ [ ] Cov [X,Y ] := ğ”¼ (X âˆ’ Î¼X )(Y âˆ’ Î¼Y ). ](img/file1944.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![ [ ] Cov [X,Y ] := ğ”¼ (X âˆ’ Î¼X )(Y âˆ’ Î¼Y ). ](img/file1944.png)'
- en: (b) The correlation of X and Y is defined by
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Xå’ŒYçš„ç›¸å…³æ€§ç”±ä¸‹å¼å®šä¹‰ï¼š
- en: '![ Cov[X, Y] Corr [X, Y ] := ---------. ÏƒXÏƒY ](img/file1945.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![ Cov[X, Y] Corr [X, Y ] := ---------. ÏƒXÏƒY ](img/file1945.png)'
- en: Similarly to variance, the definition of covariance can be simplified to provide
    an easier way of calculating its exact value.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼äºæ–¹å·®ï¼Œåæ–¹å·®çš„å®šä¹‰å¯ä»¥ç®€åŒ–ï¼Œä»è€Œæä¾›ä¸€ç§æ›´ç®€ä¾¿çš„è®¡ç®—å…¶ç¡®åˆ‡å€¼çš„æ–¹æ³•ã€‚
- en: Proposition 6\.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: å‘½é¢˜ 6\.
- en: 'Let (Î©,Î£,P) be a probability space, let X,Y : Î© â†’ â„ be two random variables,
    and let Î¼[X] = ğ”¼[X],Î¼[Y] = ğ”¼[Y ] be their expected values.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾(Î©,Î£,P)ä¸ºæ¦‚ç‡ç©ºé—´ï¼Œè®¾X,Y : Î© â†’ â„ä¸ºä¸¤ä¸ªéšæœºå˜é‡ï¼Œä¸”Î¼[X] = ğ”¼[X]ï¼ŒÎ¼[Y] = ğ”¼[Y]ä¸ºå®ƒä»¬çš„æœŸæœ›å€¼ã€‚'
- en: Then
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶å
- en: '![Cov[X, Y] = ğ”¼[XY ]âˆ’ Î¼X Î¼Y . ](img/file1946.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![Cov[X, Y] = ğ”¼[XY ]âˆ’ Î¼X Î¼Y . ](img/file1946.png)'
- en: Proof. This is just a simple calculation. According to the definition, we have
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ï¼šè¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„è®¡ç®—ã€‚æ ¹æ®å®šä¹‰ï¼Œæˆ‘ä»¬æœ‰ï¼š
- en: '![ [ ] Cov[X, Y] = ğ”¼ (X âˆ’ Î¼X )(Y âˆ’ Î¼Y) [ ] = ğ”¼ XY âˆ’ X Î¼Y âˆ’ Î¼X Y + Î¼X Î¼Y = ğ”¼[XY
    ] âˆ’ ğ”¼[X Î¼ ]âˆ’ ğ”¼[Î¼ Y ]+ Î¼ Î¼ [ ] [ ]Y X[ ] X Y = ğ”¼ XY âˆ’ ğ”¼ X Î¼Y âˆ’ Î¼X ğ”¼ Y + Î¼X Î¼Y [
    ] = ğ”¼ XY âˆ’ Î¼X Î¼Y âˆ’ Î¼X Î¼Y + Î¼X Î¼Y = ğ”¼[XY ]âˆ’ Î¼X Î¼Y , ](img/file1947.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![ [ ] Cov[X, Y] = ğ”¼ (X âˆ’ Î¼X )(Y âˆ’ Î¼Y) [ ] = ğ”¼ XY âˆ’ X Î¼Y âˆ’ Î¼X Y + Î¼X Î¼Y = ğ”¼[XY
    ] âˆ’ ğ”¼[X Î¼ ]âˆ’ ğ”¼[Î¼ Y ]+ Î¼ Î¼ [ ] [ ]Y X[ ] X Y = ğ”¼ XY âˆ’ ğ”¼ X Î¼Y âˆ’ Î¼X ğ”¼ Y + Î¼X Î¼Y [
    ] = ğ”¼ XY âˆ’ Î¼X Î¼Y âˆ’ Î¼X Î¼Y + Î¼X Î¼Y = ğ”¼[XY ]âˆ’ Î¼X Î¼Y , ](img/file1947.png)'
- en: which is what we had to show.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦å±•ç¤ºçš„ç»“æœã€‚
- en: One of the most important properties of covariance and correlation is that they
    are zero for independent random variables.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: åæ–¹å·®å’Œç›¸å…³æ€§çš„ä¸€ä¸ªæœ€é‡è¦çš„æ€§è´¨æ˜¯ï¼Œå¯¹äºç‹¬ç«‹çš„éšæœºå˜é‡ï¼Œå®ƒä»¬çš„å€¼ä¸ºé›¶ã€‚
- en: Theorem 133\.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 133\.
- en: 'Let (Î©,Î£,P) be a probability space, and let X,Y : Î© â†’â„ be two independent random
    variables.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾(Î©,Î£,P)ä¸ºæ¦‚ç‡ç©ºé—´ï¼Œä¸”X,Y : Î© â†’ â„ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„éšæœºå˜é‡ã€‚'
- en: Then, Cov[X,Y ] = 0\. (And consequently, Corr[X,Y ] = 0 as well.)
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼ŒCov[X,Y ] = 0\. ï¼ˆå› æ­¤ï¼ŒCorr[X,Y ] = 0 ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ï¼‰
- en: The proof follows straight from the definition and TheoremÂ [130](ch032.xhtml#x1-331005r130),
    so this is left as an exercise for you.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ç›´æ¥æ¥è‡ªå®šä¹‰å’Œå®šç†[130](ch032.xhtml#x1-331005r130)ï¼Œæ‰€ä»¥è¿™éƒ¨åˆ†ç•™ç»™ä½ åšç»ƒä¹ ã€‚
- en: 'Take note, as this is extra important: independence implies zero covariance,
    but zero covariance does not imply independence. Here is an example.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œè¿™ä¸€ç‚¹éå¸¸é‡è¦ï¼šç‹¬ç«‹æ€§æ„å‘³ç€é›¶åæ–¹å·®ï¼Œä½†é›¶åæ–¹å·®å¹¶ä¸æ„å‘³ç€ç‹¬ç«‹æ€§ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªä¾‹å­ã€‚
- en: Let X be a discrete random variable with the probability mass function
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾ X æ˜¯ä¸€ä¸ªç¦»æ•£éšæœºå˜é‡ï¼Œå…¶æ¦‚ç‡è´¨é‡å‡½æ•°ä¸ºï¼š
- en: '![ 1 P(X = âˆ’ 1) = P (X = 0) = P(X = 1) = 3, ](img/file1948.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 P(X = âˆ’ 1) = P (X = 0) = P(X = 1) = 3, ](img/file1948.png)'
- en: and let Y = XÂ².
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸”è®¾ Y = XÂ²ã€‚
- en: The expected value of X is
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: X çš„æœŸæœ›å€¼æ˜¯
- en: '![ğ”¼ [X ] = (âˆ’ 1)â‹…P (X = âˆ’ 1)+ 0 â‹…P (X = 0)+ 1 â‹…P (X = 1) = âˆ’ 1-+ 0 + 1- 3 3
    = 0, ](img/file1949.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼ [X ] = (âˆ’ 1)â‹…P (X = âˆ’ 1)+ 0 â‹…P (X = 0)+ 1 â‹…P (X = 1) = âˆ’ 1-+ 0 + 1- 3 3
    = 0, ](img/file1949.png)'
- en: while the law of the unconscious statistician (TheoremÂ [131](ch032.xhtml#x1-331006r131))
    gives that
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œæ— æ„è¯†ç»Ÿè®¡å­¦å®¶çš„æ³•åˆ™ï¼ˆå®šç†[131](ch032.xhtml#x1-331006r131)ï¼‰è¡¨æ˜ï¼š
- en: '![ 2 ğ”¼[Y ] = ğ”¼[X ] = 1 â‹…P(X = âˆ’ 1) + 0â‹…P (X = 0) + 1â‹…P (X = 1 ) 1- 1- = 3 +
    0+ 3 2 = -, 3 ](img/file1950.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 ğ”¼[Y ] = ğ”¼[X ] = 1 â‹…P(X = âˆ’ 1) + 0â‹…P (X = 0) + 1â‹…P (X = 1 ) 1- 1- = 3 +
    0+ 3 2 = -, 3 ](img/file1950.png)'
- en: and
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œ
- en: '![ğ”¼[XY ] = ğ”¼[X3] = 0\. ](img/file1951.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼[XY ] = ğ”¼[X3] = 0\. ](img/file1951.png)'
- en: Thus,
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œ
- en: '![Cov [X,Y ] = ğ”¼ [XY ]âˆ’ ğ”¼[X ]ğ”¼ [Y ] 3 2 = ğ”¼ [X ]âˆ’ ğ”¼ [X ]ğ”¼[X ] 2- = 0 âˆ’ 0â‹… 3
    = 0\. ](img/file1952.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![Cov [X,Y ] = ğ”¼ [XY ]âˆ’ ğ”¼[X ]ğ”¼ [Y ] 3 2 = ğ”¼ [X ]âˆ’ ğ”¼ [X ]ğ”¼[X ] 2- = 0 âˆ’ 0â‹… 3
    = 0\. ](img/file1952.png)'
- en: 'However, X and Y are not independent, as Y = XÂ² is a function of X. (I shamelessly
    stole this example from a brilliant Stack Overflow thread, which you should read
    here for more on this question: [https://stats.stackexchange.com/questions/179511/why-zero-correlation-does-not-necessarily-imply-independence](https://stats.stackexchange.com/questions/179511/why-zero-correlation-does-not-necessarily-imply-independence))'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼ŒX å’Œ Y ä¸æ˜¯ç‹¬ç«‹çš„ï¼Œå› ä¸º Y = XÂ² æ˜¯ X çš„ä¸€ä¸ªå‡½æ•°ã€‚ï¼ˆæˆ‘æ¯«ä¸ç¾æ„§åœ°å€Ÿç”¨äº†è¿™ä¸ªä¾‹å­ï¼Œæ¥è‡ªä¸€ä¸ªç²¾å½©çš„ Stack Overflow è®¨è®ºï¼Œä½ åº”è¯¥é˜…è¯»æ›´å¤šå…³äºè¿™ä¸ªé—®é¢˜çš„å†…å®¹ï¼š[https://stats.stackexchange.com/questions/179511/why-zero-correlation-does-not-necessarily-imply-independence](https://stats.stackexchange.com/questions/179511/why-zero-correlation-does-not-necessarily-imply-independence)ï¼‰
- en: Do you recall that we interpreted the concept of probability as the relative
    frequency of occurrences? Now that we have the expected value under our belt,
    we can finally make this precise. Letâ€™s look at the famous law of large numbers!
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æ˜¯å¦è¿˜è®°å¾—æˆ‘ä»¬å¦‚ä½•å°†æ¦‚ç‡çš„æ¦‚å¿µè§£é‡Šä¸ºäº‹ä»¶å‘ç”Ÿçš„ç›¸å¯¹é¢‘ç‡ï¼Ÿç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»æŒæ¡äº†æœŸæœ›å€¼ï¼Œæˆ‘ä»¬ç»ˆäºå¯ä»¥ç²¾ç¡®åœ°æè¿°è¿™ä¸ªæ¦‚å¿µäº†ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹è‘—åçš„å¤§æ•°æ³•åˆ™ï¼
- en: 20.5 The law of large numbers
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.5 å¤§æ•°æ³•åˆ™
- en: 'Weâ€™ll continue our journey with a quite remarkable and famous result: the law
    of large numbers. You have probably already heard several faulty arguments invoking
    the law of large numbers. For instance, gamblers are often convinced that their
    bad luck will end soon because of said law. This is one of the most frequently
    misused mathematical terms, and we are here to clear that up.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ç»§ç»­å‰è¿›ï¼Œæ¢ç´¢ä¸€ä¸ªç›¸å½“æ˜¾è‘—ä¸”è‘—åçš„ç»“æœï¼šå¤§æ•°æ³•åˆ™ã€‚ä½ å¯èƒ½å·²ç»å¬è¿‡ä¸€äº›é”™è¯¯çš„å…³äºå¤§æ•°æ³•åˆ™çš„è®ºç‚¹ã€‚ä¾‹å¦‚ï¼ŒèµŒå¾’ä»¬å¸¸å¸¸ç›¸ä¿¡ä»–ä»¬çš„ä¸å¹¸å¾ˆå¿«å°±ä¼šç»“æŸï¼Œå› ä¸ºå¤§æ•°æ³•åˆ™ã€‚è¿™æ˜¯æœ€å¸¸è¢«è¯¯ç”¨çš„æ•°å­¦æœ¯è¯­ä¹‹ä¸€ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œå°†æ¾„æ¸…è¿™ä¸€ç‚¹ã€‚
- en: Weâ€™ll do this in two passes. First, we are going to see an intuitive interpretation,
    then add the technical but important mathematical details. Iâ€™ll try to be gentle.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åˆ†ä¸¤æ­¥è¿›è¡Œã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†çœ‹åˆ°ä¸€ä¸ªç›´è§‚çš„è§£é‡Šï¼Œç„¶åæ·»åŠ æŠ€æœ¯æ€§ä½†é‡è¦çš„æ•°å­¦ç»†èŠ‚ã€‚æˆ‘ä¼šå°½é‡æ¸©å’Œä¸€äº›ã€‚
- en: 20.5.1 Tossing coinsâ€¦
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.5.1 æŠ•æ·ç¡¬å¸â€¦â€¦
- en: First, letâ€™s toss some coins again. If we toss coins repeatedly, what is the
    relative frequency of heads in the long run?
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬å†æŠ•å‡ æ¬¡ç¡¬å¸ã€‚å¦‚æœæˆ‘ä»¬é‡å¤æŠ•æ·ç¡¬å¸ï¼Œé•¿æœŸæ¥çœ‹ï¼Œæ­£é¢æœä¸Šçš„ç›¸å¯¹é¢‘ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: 'We should have a pretty good guess already: the average number of heads should
    converge to P(heads) = p as well. Why? Because we saw this when studying the frequentist
    interpretation of probability in SectionÂ [18.2.7](ch030.xhtml#how-to-interpret-probability).'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”è¯¥å·²ç»æœ‰äº†ä¸€ä¸ªç›¸å½“ä¸é”™çš„çŒœæµ‹ï¼šæ­£é¢æœä¸Šçš„å¹³å‡æ¬¡æ•°ä¹Ÿåº”è¯¥è¶‹å‘äº P(æ­£é¢) = pã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºæˆ‘ä»¬åœ¨ç¬¬[18.2.7](ch030.xhtml#how-to-interpret-probability)èŠ‚ç ”ç©¶æ¦‚ç‡çš„é¢‘ç‡è§£é‡Šæ—¶çœ‹åˆ°è¿‡è¿™ä¸ªç°è±¡ã€‚
- en: Our simulation showed that the relative frequency of heads does indeed converge
    to the true probability. This time, weâ€™ll carry the simulation a bit further.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ¨¡æ‹Ÿæ˜¾ç¤ºï¼Œæ­£é¢æœä¸Šçš„ç›¸å¯¹é¢‘ç‡ç¡®å®è¶‹å‘äºçœŸå®çš„æ¦‚ç‡ã€‚è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬å°†è¿›ä¸€æ­¥è¿›è¡Œæ¨¡æ‹Ÿã€‚
- en: First, to formulate the problem, letâ€™s introduce the independent random variables
    X[1],X[2],â€¦ that are distributed along Bernoulli(p), where X[i] = 0 if the toss
    results in tails, while X[i] = 1 if it is heads. We are interested in the long-term
    behavior of
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œä¸ºäº†æ„é€ é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥ç‹¬ç«‹éšæœºå˜é‡ X[1], X[2], â€¦ï¼Œå®ƒä»¬çš„åˆ†å¸ƒæ˜¯ä¼¯åŠªåˆ©(p)ï¼Œå…¶ä¸­ X[i] = 0 è¡¨ç¤ºæŠ•æ·ç»“æœä¸ºåé¢ï¼Œè€Œ X[i]
    = 1 è¡¨ç¤ºæŠ•æ·ç»“æœä¸ºæ­£é¢ã€‚æˆ‘ä»¬å…³æ³¨çš„æ˜¯
- en: '![-- X1-+-â‹…â‹…â‹…+-Xn- Xn = n . ](img/file1953.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![-- X1-+-â‹…â‹…â‹…+-Xn- Xn = n . ](img/file1953.png)'
- en: X[n] is called the sample average. We have already seen that the sample average
    gets closer and closer to p as n grows. Letâ€™s see the simulation one more time,
    before we go any further. (The parameter p is selected to be 1âˆ•2 for the sake
    of the example.)
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: X[n] è¢«ç§°ä¸ºæ ·æœ¬å¹³å‡å€¼ã€‚æˆ‘ä»¬å·²ç»çœ‹åˆ°ï¼Œéšç€nçš„å¢å¤§ï¼Œæ ·æœ¬å¹³å‡å€¼è¶Šæ¥è¶Šæ¥è¿‘pã€‚è®©æˆ‘ä»¬åœ¨ç»§ç»­ä¹‹å‰å†çœ‹ä¸€æ¬¡æ¨¡æ‹Ÿç»“æœã€‚ï¼ˆä¸ºäº†æ–¹ä¾¿ç¤ºä¾‹ï¼Œå‚æ•°pé€‰æ‹©ä¸º1âˆ•2ã€‚ï¼‰
- en: '[PRE0]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: And here is the plot.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å›¾è¡¨ã€‚
- en: '[PRE1]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![PIC](img/file1954.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1954.png)'
- en: 'FigureÂ 20.3: Relative frequency of the coin tosses'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾20.3ï¼šæ·ç¡¬å¸çš„ç›¸å¯¹é¢‘ç‡
- en: 'Nothing new so far. However, if you have a sharp eye, you might ask the question:
    is this just an accident? After all, we are studying the average'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢æ²¡æœ‰ä»€ä¹ˆæ–°å†…å®¹ã€‚ç„¶è€Œï¼Œå¦‚æœä½ çœ¼å°–çš„è¯ï¼Œå¯èƒ½ä¼šé—®ï¼šè¿™åªæ˜¯å¶ç„¶å—ï¼Ÿæ¯•ç«Ÿï¼Œæˆ‘ä»¬ç ”ç©¶çš„æ˜¯å¹³å‡å€¼ã€‚
- en: '![-- X1-+-â‹…â‹…â‹…+-Xn- Xn = n , ](img/file1955.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![-- X1-+-â‹…â‹…â‹…+-Xn- Xn = n , ](img/file1955.png)'
- en: which is (almost) a binomially distributed random variable! To be more precise,
    if X[i] âˆ¼ Bernoulli(p), then
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å‡ ä¹æ˜¯ä¸€ä¸ªäºŒé¡¹åˆ†å¸ƒçš„éšæœºå˜é‡ï¼æ›´å‡†ç¡®åœ°è¯´ï¼Œå¦‚æœ X[i] âˆ¼ ä¼¯åŠªåˆ©åˆ†å¸ƒ(p)ï¼Œåˆ™
- en: '![-- Xn âˆ¼ 1Binomial(n,p). n ](img/file1956.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![-- Xn âˆ¼ 1Binomial(n,p). n ](img/file1956.png)'
- en: (We saw this earlier when discussing the sums of discrete random variables in
    SectionÂ [19.2.7](ch031.xhtml#sums-of-discrete-random-variables).)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆæˆ‘ä»¬åœ¨è®¨è®ºç¦»æ•£éšæœºå˜é‡çš„å’Œæ—¶å·²ç»çœ‹åˆ°è¿‡è¿™ä¸ªå†…å®¹ï¼Œåœ¨ç¬¬[19.2.7](ch031.xhtml#sums-of-discrete-random-variables)èŠ‚ä¸­ã€‚ï¼‰
- en: At this point, it is far from guaranteed that this distribution will be concentrated
    around a single value. So, letâ€™s do some more simulations. This time, weâ€™ll toss
    a coin a thousand times to see the distribution of the averages. Quite meta, I
    know.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæ— æ³•ä¿è¯è¿™ä¸ªåˆ†å¸ƒä¼šé›†ä¸­åœ¨å•ä¸€çš„å€¼é™„è¿‘ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬åšæ›´å¤šçš„æ¨¡æ‹Ÿã€‚è¿™æ¬¡ï¼Œæˆ‘ä»¬å°†æ·ç¡¬å¸ä¸€åƒæ¬¡ï¼Œçœ‹çœ‹æ ·æœ¬å¹³å‡å€¼çš„åˆ†å¸ƒæƒ…å†µã€‚ç¡®å®å¾ˆæœ‰metaçš„æ„Ÿè§‰ï¼Œæˆ‘çŸ¥é“ã€‚
- en: '[PRE2]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can visualize the distributions on histograms.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨ç›´æ–¹å›¾ä¸Šå¯è§†åŒ–è¿™äº›åˆ†å¸ƒã€‚
- en: '[PRE3]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![PIC](img/file1957.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1957.png)'
- en: 'FigureÂ 20.4: Sample average distributions of coin tosses'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾20.4ï¼šæ·ç¡¬å¸çš„æ ·æœ¬å¹³å‡å€¼åˆ†å¸ƒ
- en: In other words, the probability of X[n] falling far from p becomes smaller and
    smaller. For any small ğœ€, we can formulate the probability of â€œX[n] falling farther
    from p than ğœ€â€ as P(|X[n] âˆ’p|ğœ€).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼ŒX[n]è¿œç¦»pçš„æ¦‚ç‡ä¼šå˜å¾—è¶Šæ¥è¶Šå°ã€‚å¯¹äºä»»ä½•å°çš„ğœ–ï¼Œæˆ‘ä»¬å¯ä»¥å°†â€œX[n]è¿œç¦»pè¶…è¿‡ğœ–â€çš„æ¦‚ç‡è¡¨ç¤ºä¸ºP(|X[n] âˆ’p| > ğœ–)ã€‚
- en: Thus, mathematically speaking, our guess is
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä»æ•°å­¦è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬çš„çŒœæµ‹æ˜¯
- en: '![ -- nlâ†’imâˆ P(|Xn âˆ’ p| >ğœ€) = 0\. ](img/file1958.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![ -- nlâ†’imâˆ P(|Xn âˆ’ p| >ğœ–) = 0\. ](img/file1958.png)'
- en: Again, is this just an accident, and were we just lucky to study an experiment
    where this is true? Would the same work for random variables other than Bernoulli
    ones? What will the sample averages converge to? (If they converge at all.)
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œè¿™åªæ˜¯å¶ç„¶å—ï¼Ÿæˆ‘ä»¬æ˜¯å¦ä»…ä»…å¹¸è¿åœ°ç ”ç©¶äº†ä¸€ä¸ªç¬¦åˆè¿™ä¸ªè§„å¾‹çš„å®éªŒï¼Ÿå¯¹äºé™¤ä¼¯åŠªåˆ©éšæœºå˜é‡å¤–çš„å…¶ä»–éšæœºå˜é‡æ˜¯å¦ä¹Ÿæˆç«‹ï¼Ÿæ ·æœ¬å¹³å‡å€¼æœ€ç»ˆä¼šæ”¶æ•›åˆ°ä»€ä¹ˆåœ°æ–¹ï¼Ÿï¼ˆå¦‚æœå®ƒä»¬ç¡®å®ä¼šæ”¶æ•›çš„è¯ã€‚ï¼‰
- en: Weâ€™ll find out.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¼šæ‰¾åˆ°ç­”æ¡ˆçš„ã€‚
- en: 20.5.2 â€¦rolling diceâ€¦
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.5.2 â€¦æ·éª°å­â€¦
- en: Letâ€™s play dice. To keep things simple, we are interested in the average value
    of a roll in the long run. To build a proper probabilistic model, letâ€™s introduce
    random variables!
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥ç©æ·éª°å­ã€‚ä¸ºäº†ç®€åŒ–é—®é¢˜ï¼Œæˆ‘ä»¬å…³æ³¨çš„æ˜¯é•¿æœŸæ·éª°å­çš„å¹³å‡å€¼ã€‚ä¸ºäº†å»ºç«‹ä¸€ä¸ªåˆé€‚çš„æ¦‚ç‡æ¨¡å‹ï¼Œæˆ‘ä»¬æ¥å¼•å…¥éšæœºå˜é‡ï¼
- en: A single roll is uniformly distributed on {1,2,â€¦,6}, and each roll is independent
    from the others. So, let X[1],X[2],â€¦ be independent random variables, each distributed
    according to Uniform({1,2,â€¦,6}).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: å•æ¬¡æ·éª°å­æ˜¯å‡åŒ€åˆ†å¸ƒåœ¨{1,2,â€¦,6}ä¸Šçš„ï¼Œå¹¶ä¸”æ¯æ¬¡æ·éª°å­ç›¸äº’ç‹¬ç«‹ã€‚å› æ­¤ï¼Œè®¾ X[1], X[2], â€¦ ä¸ºç‹¬ç«‹éšæœºå˜é‡ï¼Œæ¯ä¸ªéšæœºå˜é‡éƒ½æŒ‰ç…§å‡åŒ€åˆ†å¸ƒUniform({1,2,â€¦,6})åˆ†å¸ƒã€‚
- en: How does the sample average X[n] behave? Simulation time. Weâ€™ll randomly generate
    1000 rolls, then explore how X[n] behaves.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: æ ·æœ¬å¹³å‡å€¼ X[n] ä¼šæ€ä¹ˆå˜åŒ–ï¼Ÿæ˜¯æ—¶å€™è¿›è¡Œæ¨¡æ‹Ÿäº†ã€‚æˆ‘ä»¬å°†éšæœºç”Ÿæˆ1000æ¬¡æ·éª°å­çš„ç»“æœï¼Œç„¶åæ¢ç´¢ X[n] çš„å˜åŒ–æƒ…å†µã€‚
- en: '[PRE4]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Again, to obtain a bit of an insight, weâ€™ll visualize the averages on a plot.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ä¸ºäº†è·å¾—ä¸€äº›ç›´è§‚çš„ç†è§£ï¼Œæˆ‘ä»¬å°†åœ¨å›¾è¡¨ä¸Šå¯è§†åŒ–è¿™äº›å¹³å‡å€¼ã€‚
- en: '[PRE5]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![PIC](img/file1959.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1959.png)'
- en: 'FigureÂ 20.5: Sample averages of rolling a six-sided dice'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾20.5ï¼šæ·å…­é¢éª°å­çš„æ ·æœ¬å¹³å‡å€¼
- en: 'The first thing to note is that these are suspiciously close to 3.5\. This
    is not a probability, but the expected value:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™äº›æ•°å€¼å¼‚å¸¸æ¥è¿‘3.5ã€‚è¿™ä¸æ˜¯ä¸€ä¸ªæ¦‚ç‡ï¼Œè€Œæ˜¯æœŸæœ›å€¼ï¼š
- en: '![ğ”¼[X1 ] = ğ”¼[X2] = â‹…â‹…â‹… = 3.5\. ](img/file1960.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼[X1 ] = ğ”¼[X2] = â‹…â‹…â‹… = 3.5\. ](img/file1960.png)'
- en: For Bernoulli(p) distributed random variables, the expected value coincides
    with the probability p. However, this time, X[n] does not have a nice and explicit
    distribution like in the case of coin tosses, where the sample averages were binomially
    distributed. So, letâ€™s roll some more dice to estimate how X[n] is distributed.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¼¯åŠªåˆ©(p)åˆ†å¸ƒçš„éšæœºå˜é‡ï¼ŒæœŸæœ›å€¼ä¸æ¦‚ç‡pç›¸åŒã€‚ç„¶è€Œï¼Œè¿™ä¸€æ¬¡ï¼ŒX[n] å¹¶ä¸åƒæ·ç¡¬å¸æ—¶é‚£æ ·æœ‰ä¸€ä¸ªæ˜ç¡®çš„åˆ†å¸ƒï¼Œæ ·æœ¬å¹³å‡å€¼ä¹Ÿä¸å†æ˜¯äºŒé¡¹åˆ†å¸ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ¥å¤šæ·ä¸€äº›éª°å­ï¼Œä¼°è®¡
    X[n] çš„åˆ†å¸ƒæƒ…å†µã€‚
- en: '[PRE6]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![PIC](img/file1961.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1961.png)'
- en: 'FigureÂ 20.6: Sample average distributions of dice rolls'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 20.6ï¼šæ·éª°å­æ—¶çš„æ ·æœ¬å¹³å‡åˆ†å¸ƒ
- en: It seems like, once more, the distribution of X[n] is concentrated around ğ”¼[X[1]].
    Our intuition tells us that this is not an accident; that this phenomenon is true
    for a wide range of random variables.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹èµ·æ¥ï¼Œä¸€æ¬¡åˆä¸€æ¬¡åœ°ï¼ŒX[n] çš„åˆ†å¸ƒé›†ä¸­åœ¨ ğ”¼[X[1]] é™„è¿‘ã€‚æˆ‘ä»¬çš„ç›´è§‰å‘Šè¯‰æˆ‘ä»¬ï¼Œè¿™ä¸æ˜¯å¶ç„¶ï¼›è¿™ä¸€ç°è±¡å¯¹äºå¹¿æ³›çš„éšæœºå˜é‡éƒ½æˆç«‹ã€‚
- en: 'Let me spoil the surprise: this is indeed the case, and weâ€™ll see this now.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘å‰§é€ä¸€ä¸‹ï¼šè¿™ç¡®å®æ˜¯è¿™æ ·ï¼Œæˆ‘ä»¬ç°åœ¨å°±æ¥çœ‹ã€‚
- en: 20.5.3 â€¦and all the rest
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.5.3 â€¦ä»¥åŠå…¶ä½™éƒ¨åˆ†
- en: 'This time, let X[1],X[2],â€¦ be a sequence of independent and identically distributed
    (i.i.d.) random variables. Not coin tosses, not dice rolls, but any distribution.
    We saw that the sample average X[n] seems to converge to the joint expected value
    of the X[i]-s:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ¬¡ï¼Œè®¾ X[1],X[2],â€¦ æ˜¯ä¸€åˆ—ç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆi.i.d.ï¼‰çš„éšæœºå˜é‡ã€‚ä¸æ˜¯æ·ç¡¬å¸ï¼Œä¸æ˜¯æ·éª°å­ï¼Œè€Œæ˜¯ä»»ä½•åˆ†å¸ƒã€‚æˆ‘ä»¬çœ‹åˆ°æ ·æœ¬å¹³å‡å€¼ X[n] ä¼¼ä¹æ”¶æ•›äº
    X[i]-s çš„è”åˆæœŸæœ›å€¼ï¼š
- en: '![â€²â€²- â€²â€² Xn â†’ ğ”¼[X1] ](img/file1962.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![â€²â€²- â€²â€² Xn â†’ ğ”¼[X1] ](img/file1962.png)'
- en: 'Note the quotation marks: X[n] is not a number but a random variable. Thus,
    we canâ€™t (yet) speak about convergence.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„å¼•å·ï¼šX[n] ä¸æ˜¯ä¸€ä¸ªæ•°å­—ï¼Œè€Œæ˜¯ä¸€ä¸ªéšæœºå˜é‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿˜ä¸èƒ½è°ˆè®ºæ”¶æ•›ã€‚
- en: In mathematically precise terms, what we saw previously is that for large enough
    n-s, the sample average X[n] is highly unlikely to fall far from the joint expected
    value Î¼ = ğ”¼[X[1]]; that is,
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ•°å­¦ä¸Šç²¾ç¡®æ¥è¯´ï¼Œæˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„æ˜¯ï¼Œå½“ n è¶³å¤Ÿå¤§æ—¶ï¼Œæ ·æœ¬å¹³å‡å€¼ X[n] å¾ˆä¸å¯èƒ½è¿œç¦»è”åˆæœŸæœ›å€¼ Î¼ = ğ”¼[X[1]]ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼Œ
- en: lim[nâ†’âˆ] P(|X[n] âˆ’ Î¼| > ğœ€) = 0 (20.2)
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: lim[nâ†’âˆ] P(|X[n] âˆ’ Î¼| > ğœ–) = 0 (20.2)
- en: holds for all ğœ€/span>0\.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ‰€æœ‰ ğœ–/span>0\ éƒ½æˆç«‹ã€‚
- en: The limit ([20.2](ch032.xhtml#and-all-the-rest)) seems hard to prove right now
    even in the simple case of coin tossing. There, X[n] âˆ¼![1n](img/file1963.png)
    Binomial(n,p), thus
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: æé™ï¼ˆ[20.2](ch032.xhtml#and-all-the-rest)ï¼‰ç°åœ¨ä¼¼ä¹å¾ˆéš¾è¯æ˜ï¼Œå³ä½¿æ˜¯åœ¨ç®€å•çš„æ·ç¡¬å¸çš„æƒ…å†µä¸‹ã€‚åœ¨é‚£é‡Œï¼ŒX[n] âˆ¼![1n](img/file1963.png)
    äºŒé¡¹åˆ†å¸ƒ(n,p)ï¼Œå› æ­¤
- en: '![ âŒŠn(p+ ğœ€)âŒ‹ ( ) -- âˆ‘ n k nâˆ’k P(|Xn âˆ’ Î¼ | >ğœ€) = 1 âˆ’ k p (1 âˆ’ p) , k=âŒŠn(pâˆ’ ğœ€)âŒ‹
    ](img/file1964.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠn(p+ ğœ–)âŒ‹ ( ) -- âˆ‘ n k nâˆ’k P(|Xn âˆ’ Î¼ | >ğœ–) = 1 âˆ’ k p (1 âˆ’ p) , k=âŒŠn(pâˆ’ ğœ–)âŒ‹
    ](img/file1964.png)'
- en: where the symbol âŒŠxâŒ‹ denotes the largest integer that is smaller than x. This
    does not look friendly at all. (I leave the verification as an exercise.)
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ç¬¦å· âŒŠxâŒ‹ è¡¨ç¤ºå°äº x çš„æœ€å¤§æ•´æ•°ã€‚è¿™çœ‹èµ·æ¥ä¸€ç‚¹ä¹Ÿä¸å‹å¥½ã€‚ï¼ˆæˆ‘æŠŠéªŒè¯ç•™ä½œç»ƒä¹ ã€‚ï¼‰
- en: Thus, our plan is the following.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬çš„è®¡åˆ’å¦‚ä¸‹ã€‚
- en: Find a way to estimate P(jX[n]âˆ’Î¼j/span>ğœ€) in a way that is independent from
    the distribution of the X[i]-s.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰¾ä¸€ç§ä¼°è®¡ P(jX[n]âˆ’Î¼j/span>ğœ–) çš„æ–¹æ³•ï¼Œä½¿å…¶ä¸ X[i]-s çš„åˆ†å¸ƒæ— å…³ã€‚
- en: Use the upper estimate to show lim[nâ†’âˆ]P(jX[n] âˆ’Î¼j/span>ğœ€) = 0.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¸Šç•Œä¼°è®¡æ¥è¯æ˜ lim[nâ†’âˆ]P(jX[n] âˆ’Î¼j/span>ğœ–) = 0ã€‚
- en: Letâ€™s go.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼€å§‹å§ã€‚
- en: 20.5.4 The weak law of large numbers
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.5.4 å¤§æ•°æ³•åˆ™çš„å¼±æ³•åˆ™
- en: First, the upper estimates. There are two general inequalities thatâ€™ll help
    us to deal with P(jX[n] âˆ’Î¼j â‰¥ğœ€).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆæ˜¯ä¸Šç•Œä¼°è®¡ã€‚æœ‰ä¸¤ä¸ªä¸€èˆ¬ä¸ç­‰å¼å¯ä»¥å¸®åŠ©æˆ‘ä»¬å¤„ç† P(jX[n] âˆ’Î¼j â‰¥ğœ–)ã€‚
- en: Theorem 134\. (Markovâ€™s inequality)
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 134. ï¼ˆé©¬å°”å¯å¤«ä¸ç­‰å¼ï¼‰
- en: 'Let (Î©,Î£,P) be a probability space and let X : Î© â†’ [0,âˆ) be a nonnegative random
    variable. Then'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ (Î©,Î£,P) æ˜¯ä¸€ä¸ªæ¦‚ç‡ç©ºé—´ï¼Œä¸” X : Î© â†’ [0,âˆ) æ˜¯ä¸€ä¸ªéè´Ÿéšæœºå˜é‡ã€‚é‚£ä¹ˆ'
- en: '![ ğ”¼[X ] P (X â‰¥ t) â‰¤ ----- t ](img/file1965.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![ ğ”¼[X ] P (X â‰¥ t) â‰¤ ----- t ](img/file1965.png)'
- en: holds for any t âˆˆ (0,âˆ).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä»»æ„ t âˆˆ (0,âˆ)ï¼Œæ­¤ä¸ç­‰å¼éƒ½æˆç«‹ã€‚
- en: Proof. We have to separate the discrete and the continuous cases. The proofs
    are almost identical, so Iâ€™ll only do the discrete case here, while the continuous
    is left for you as an exercise to test your understanding.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ï¼šæˆ‘ä»¬éœ€è¦åˆ†ç¦»ç¦»æ•£æƒ…å†µå’Œè¿ç»­æƒ…å†µã€‚è¯æ˜å‡ ä¹å®Œå…¨ç›¸åŒï¼Œæ‰€ä»¥æˆ‘åªä¼šåšç¦»æ•£æƒ…å†µï¼Œè¿ç»­æƒ…å†µç•™ç»™ä½ ä½œä¸ºç»ƒä¹ æ¥éªŒè¯ä½ çš„ç†è§£ã€‚
- en: 'So, let X : Î© â†’ {x[1],x[2],â€¦} be a discrete random variable (where x[k] â‰¥ 0
    for all k), and t âˆˆ (0,âˆ) be an arbitrary positive real number.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ X : Î© â†’ {x[1],x[2],â€¦} æ˜¯ä¸€ä¸ªç¦»æ•£å‹éšæœºå˜é‡ï¼ˆå…¶ä¸­ x[k] â‰¥ 0 å¯¹æ‰€æœ‰ k æˆç«‹ï¼‰ï¼Œä¸” t âˆˆ (0,âˆ) æ˜¯ä¸€ä¸ªä»»æ„çš„æ­£å®æ•°ã€‚'
- en: Then
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆ
- en: ğ”¼[X]
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ğ”¼[X]
- en: = âˆ‘ [k=1]^âˆx [k]P(X = x[k])
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: = âˆ‘ [k=1]^âˆx [k]P(X = x[k])
- en: = âˆ‘ [k:x[k]/span>tx[k]P(X = x[k]) + âˆ‘ [k:x[k]â‰¥t]x[k]P(X = x[k]),]
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: = âˆ‘ [k:x[k]/span>tx[k]P(X = x[k]) + âˆ‘ [k:x[k]â‰¥t]x[k]P(X = x[k]),]
- en: 'where the sum âˆ‘ [k:x[k]/span>t only accounts for k-s with x[k]/span>t, and
    similarly, âˆ‘ [k] : x[k] â‰¥t only accounts for k-s with x[k] â‰¥t.]'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 'å…¶ä¸­å’Œ âˆ‘ [k:x[k]/span>t ä»…ä»…è®¡ç®—äº† x[k]/span>t çš„ k-sï¼Œç±»ä¼¼åœ°ï¼Œâˆ‘ [k] : x[k] â‰¥t ä»…è®¡ç®—äº† x[k]
    â‰¥t çš„ k-sã€‚'
- en: As the x[k]-s are nonnegative by assumption, we can estimate ğ”¼[X] from below
    by omitting one of them. Thus,
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå‡è®¾ x[k]-s ä¸ºéè´Ÿæ•°ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€šè¿‡å¿½ç•¥å…¶ä¸­ä¸€ä¸ªæ¥ä»ä¸‹æ–¹ä¼°è®¡ ğ”¼[X]ã€‚å› æ­¤ï¼Œ
- en: '![ âˆ‘ âˆ‘ ğ”¼[X ] = xkP (X = xk )+ xkP (X = xk) k:x < k:x â‰¥t âˆ‘k k â‰¥ xkP (X = xk
    ) k:xkâ‰¥t âˆ‘ â‰¥ t P (X = xk ) k:xkâ‰¥t = tP(X â‰¥ t), ](img/file1966.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘ âˆ‘ ğ”¼[X ] = xkP (X = xk )+ xkP (X = xk) k:x < k:x â‰¥t âˆ‘k k â‰¥ xkP (X = xk
    ) k:xkâ‰¥t âˆ‘ â‰¥ t P (X = xk ) k:xkâ‰¥t = tP(X â‰¥ t), ](img/file1966.png)'
- en: from which Markovâ€™s inequality
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸­å¯ä»¥å¾—åˆ°é©¬å°”å¯å¤«ä¸ç­‰å¼
- en: '![P (X â‰¥ t) â‰¤ ğ”¼[X-] t ](img/file1967.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![P (X â‰¥ t) â‰¤ ğ”¼[X-] t ](img/file1967.png)'
- en: follows.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸‹ã€‚
- en: The law of large numbers is only one step away from Markovâ€™s inequality. This
    last step is so useful that it deserves to be its own theorem. Meet the famous
    inequality of Chebyshev.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§æ•°æ³•åˆ™ä»…ä¸€æ­¥ä¹‹é¥ï¼Œæ¥è¿‘äºé©¬å°”å¯å¤«ä¸ç­‰å¼ã€‚æœ€åè¿™ä¸€æ­¥éå¸¸æœ‰ç”¨ï¼Œå€¼å¾—æˆä¸ºä¸€ä¸ªç‹¬ç«‹çš„å®šç†ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹è‘—åçš„åˆ‡æ¯”é›ªå¤«ä¸ç­‰å¼ã€‚
- en: Theorem 135\. (Chebyshevâ€™s inequality)
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 135\.ï¼ˆåˆ‡æ¯”é›ªå¤«ä¸ç­‰å¼ï¼‰
- en: 'Let (Î©,Î£,P) be a probability space and let X : Î© â†’â„ be a random variable with
    finite variance ÏƒÂ² = Var[X]/span>âˆand expected value ğ”¼[X] = Î¼.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ (Î©, Î£, P) ä¸ºä¸€ä¸ªæ¦‚ç‡ç©ºé—´ï¼ŒX : Î© â†’â„ æ˜¯ä¸€ä¸ªå…·æœ‰æœ‰é™æ–¹å·® ÏƒÂ² = Var[X] å’ŒæœŸæœ›å€¼ ğ”¼[X] = Î¼ çš„éšæœºå˜é‡ã€‚'
- en: Then
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶å
- en: '![ Ïƒ2 P(|X âˆ’ Î¼| â‰¥ t) â‰¤ -t2- ](img/file1968.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![ Ïƒ2 P(|X âˆ’ Î¼| â‰¥ t) â‰¤ -t2- ](img/file1968.png)'
- en: holds for all t âˆˆ (0,âˆ).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ‰€æœ‰ t âˆˆ (0,âˆ) æˆç«‹ã€‚
- en: Proof. As |X âˆ’Î¼| is a nonnegative random variable, we can apply TheoremÂ [134](ch032.xhtml#x1-338002r134)
    to obtain
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚ç”±äº |X âˆ’ Î¼| æ˜¯ä¸€ä¸ªéè´Ÿéšæœºå˜é‡ï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨å®šç† [134](ch032.xhtml#x1-338002r134) å¾—åˆ°
- en: '![P (|X âˆ’ Î¼| â‰¥ t) = P(|X âˆ’ Î¼|2 â‰¥ t2) 2 â‰¤ ğ”¼[|X--âˆ’-Î¼|-]. t2 ](img/file1969.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![P (|X âˆ’ Î¼| â‰¥ t) = P(|X âˆ’ Î¼|2 â‰¥ t2) 2 â‰¤ ğ”¼[|X--âˆ’-Î¼|-]. t2 ](img/file1969.png)'
- en: However, as ğ”¼[|X âˆ’Î¼|Â²] = Var[X] = ÏƒÂ², we have
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œç”±äº ğ”¼[|X âˆ’ Î¼|Â²] = Var[X] = ÏƒÂ²ï¼Œæˆ‘ä»¬æœ‰
- en: '![ 2 2 P(|X âˆ’ Î¼ | â‰¥ t) â‰¤ ğ”¼-[|X-âˆ’2Î¼-|] = Ïƒ2 t t ](img/file1970.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 2 P(|X âˆ’ Î¼ | â‰¥ t) â‰¤ ğ”¼-[|X-âˆ’2Î¼-|] = Ïƒ2 t t ](img/file1970.png)'
- en: which is what we had to show.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦è¯æ˜çš„ã€‚
- en: And with that, we are ready to precisely formulate and prove the law of large
    numbers. After all this setup, the (weak) law of large numbers is just a small
    step away. Here it is in its full glory.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿™äº›å†…å®¹ï¼Œæˆ‘ä»¬å‡†å¤‡å¥½ç²¾ç¡®åœ°è¡¨è¿°å’Œè¯æ˜å¤§æ•°æ³•åˆ™ã€‚ç»è¿‡æ‰€æœ‰è¿™äº›å‡†å¤‡ï¼Œï¼ˆå¼±ï¼‰å¤§æ•°æ³•åˆ™åªæ˜¯ä¸€æ­¥ä¹‹é¥ã€‚ä»¥ä¸‹æ˜¯å®ƒçš„å®Œæ•´å½¢å¼ã€‚
- en: Theorem 136\. (The weak law of large numbers)
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 136\.ï¼ˆå¼±å¤§æ•°æ³•åˆ™ï¼‰
- en: Let X[1],X[2],â€¦ be a sequence of independent and identically distributed random
    variables with finite expected value Î¼ = ğ”¼[X[1]] and variance ÏƒÂ² = Var[X[1]],
    and let
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾ X[1], X[2], â€¦ ä¸ºä¸€åˆ—ç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡ï¼Œå…¶æœŸæœ›å€¼ Î¼ = ğ”¼[X[1]] å’Œæ–¹å·® ÏƒÂ² = Var[X[1]]ï¼Œä¸”
- en: '![-- X1 + â‹…â‹…â‹…+ Xn Xn = ------------- n ](img/file1971.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![-- X1 + â‹…â‹…â‹…+ Xn Xn = ------------- n ](img/file1971.png)'
- en: be their sample average. Then
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾å®ƒä»¬çš„æ ·æœ¬å¹³å‡å€¼ä¸ºã€‚ç„¶å
- en: '![lim P (|X- âˆ’ Î¼| â‰¥ ğœ€) = 0 nâ†’ âˆ n ](img/file1972.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![lim P (|X- âˆ’ Î¼| â‰¥ ğœ€) = 0 nâ†’ âˆ n ](img/file1972.png)'
- en: holds for any ğœ€/span>0\.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹ä»»ä½• ğœ€/span>0\ æˆç«‹ã€‚
- en: Proof. As the X[i]-s are independent, the variance of the sample average is
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚ç”±äº X[i] æ˜¯ç‹¬ç«‹çš„ï¼Œæ ·æœ¬å¹³å‡å€¼çš„æ–¹å·®ä¸º
- en: '![ -- [ X1 + â‹…â‹…â‹…+ Xn ] Var[Xn ] = Var ------------- n = -1-Var[X1 + â‹…â‹…â‹…+ Xn]
    n2 = -1-(Var[X ]+ â‹…â‹…â‹…+ Var[X ]) n2 1 n n Ïƒ2 Ïƒ2 = -n2- = n-. ](img/file1973.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![ -- [ X1 + â‹…â‹…â‹…+ Xn ] Var[Xn ] = Var ------------- n = -1-Var[X1 + â‹…â‹…â‹…+ Xn]
    n2 = -1-(Var[X ]+ â‹…â‹…â‹…+ Var[X ]) n2 1 n n Ïƒ2 Ïƒ2 = -n2- = n-. ](img/file1973.png)'
- en: Now, by using Chebyshevâ€™s inequality from TheoremÂ [135](ch032.xhtml#x1-338003r135),
    we obtain
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œé€šè¿‡ä½¿ç”¨å®šç† [135](ch032.xhtml#x1-338003r135) ä¸­çš„åˆ‡æ¯”é›ªå¤«ä¸ç­‰å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°
- en: '![ -- -- Var[Xn-] -Ïƒ2- P (|Xn âˆ’ Î¼ | â‰¥ ğœ€) â‰¤ ğœ€2 = n ğœ€2\. ](img/file1974.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![ -- -- Var[Xn-] -Ïƒ2- P (|Xn âˆ’ Î¼ | â‰¥ ğœ€) â‰¤ ğœ€2 = n ğœ€2\. ](img/file1974.png)'
- en: Thus,
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œ
- en: '![0 â‰¤ lim P(|Xn âˆ’ Î¼ | â‰¥ ğœ€) nâ†’ âˆ -Ïƒ2- â‰¤ nlâ†’imâˆ nğœ€2 = 0, ](img/file1975.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![0 â‰¤ lim P(|Xn âˆ’ Î¼ | â‰¥ ğœ€) nâ†’ âˆ -Ïƒ2- â‰¤ nlâ†’imâˆ nğœ€2 = 0, ](img/file1975.png)'
- en: hence
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤
- en: '![ -- nliâ†’mâˆ P(|Xn âˆ’ Î¼ | â‰¥ ğœ€) = 0, ](img/file1976.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![ -- nliâ†’mâˆ P(|Xn âˆ’ Î¼ | â‰¥ ğœ€) = 0, ](img/file1976.png)'
- en: which is what we needed to show.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦è¯æ˜çš„ã€‚
- en: TheoremÂ [136](ch032.xhtml#x1-338004r136) is not all that can be said about the
    sample averages. There is a stronger result, showing that the sample averages
    do in fact converge to the mean with probability 1.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† [136](ch032.xhtml#x1-338004r136) ä¸æ˜¯å…³äºæ ·æœ¬å¹³å‡å€¼çš„å…¨éƒ¨å†…å®¹ã€‚è¿˜æœ‰æ›´å¼ºçš„ç»“æœï¼Œè¡¨æ˜æ ·æœ¬å¹³å‡å€¼ç¡®å®ä»¥æ¦‚ç‡ 1 æ”¶æ•›åˆ°å‡å€¼ã€‚
- en: 20.5.5 The strong law of large numbers
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.5.5 å¼ºå¤§æ•°æ³•åˆ™
- en: Why is TheoremÂ [136](ch032.xhtml#x1-338004r136) called the â€œweakâ€ law? Think
    about the statement
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆå®šç† [136](ch032.xhtml#x1-338004r136) è¢«ç§°ä¸ºâ€œå¼±â€å¤§æ•°æ³•åˆ™ï¼Ÿæƒ³æƒ³è¿™ä¸ªå£°æ˜
- en: lim[nâ†’âˆ] P(|X[n] âˆ’ Î¼| â‰¥ ğœ€) = 0 (20.3)
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: lim[nâ†’âˆ] P(|X[n] âˆ’ Î¼| â‰¥ ğœ€) = 0 (20.3)
- en: for a moment. For a given Ï‰ âˆˆ Î©, this doesnâ€™t tell us anything about the convergence
    of a concrete sample average
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨ç­‰ç‰‡åˆ»ã€‚å¯¹äºç»™å®šçš„ Ï‰ âˆˆ Î©ï¼Œè¿™å¹¶æ²¡æœ‰å‘Šè¯‰æˆ‘ä»¬å…·ä½“æ ·æœ¬å¹³å‡å€¼çš„æ”¶æ•›æƒ…å†µã€‚
- en: '![X- (Ï‰) = X1(Ï‰-)+-â‹…â‹…â‹…+-Xn-(Ï‰-), n n ](img/file1977.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![X- (Ï‰) = X1(Ï‰-)+-â‹…â‹…â‹…+-Xn-(Ï‰-), n n ](img/file1977.png)'
- en: it just tells us that in a probabilistic sense, X[n] is concentrated around
    the joint expected value Î¼. In a sense, ([20.3](ch032.xhtml#the-strong-law-of-large-numbers))
    is a weaker version of
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒåªæ˜¯å‘Šè¯‰æˆ‘ä»¬ï¼Œåœ¨æ¦‚ç‡æ„ä¹‰ä¸Šï¼ŒX[n] é›†ä¸­åœ¨è”åˆæœŸæœ›å€¼ Î¼ å‘¨å›´ã€‚ä»æŸç§æ„ä¹‰ä¸Šè®²ï¼Œ([20.3](ch032.xhtml#the-strong-law-of-large-numbers))
    æ˜¯
- en: '![P( lim X- = Î¼ ) = 1, nâ†’ âˆ n ](img/file1978.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![P( lim X- = Î¼ ) = 1, nâ†’ âˆ n ](img/file1978.png)'
- en: hence the terminology weak law of large numbers.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè¿™å°±æ˜¯æ‰€è°“çš„å¼±å¤§æ•°æ³•åˆ™ã€‚
- en: Do we have a stronger result than TheoremÂ [136](ch032.xhtml#x1-338004r136)?
    Yes, we do.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ˜¯å¦æœ‰æ¯”å®šç† [136](ch032.xhtml#x1-338004r136) æ›´å¼ºçš„ç»“æœï¼Ÿæ˜¯çš„ï¼Œæœ‰ã€‚
- en: Theorem 137\. (The strong law of large numbers)
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 137\.ï¼ˆå¼ºå¤§æ•°æ³•åˆ™ï¼‰
- en: Let X[1],X[2],â€¦ be a sequence of independent and identically distributed random
    variables with finite expected value Î¼ = ğ”¼[X[1]] and variance ÏƒÂ² = Var[X[1]],
    and let
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾X[1],X[2],â€¦æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡åºåˆ—ï¼Œå…·æœ‰æœ‰é™çš„æœŸæœ›å€¼Î¼ = ğ”¼[X[1]]å’Œæ–¹å·®ÏƒÂ² = Var[X[1]]ï¼Œå¹¶ä¸”è®¾
- en: '![-- X + â‹…â‹…â‹…+ X Xn = -1---------n- n ](img/file1979.png)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![-- X + â‹…â‹…â‹…+ X Xn = -1---------n- n ](img/file1979.png)'
- en: be their sample average. Then
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾å®ƒä»¬æ˜¯æ ·æœ¬å‡å€¼ã€‚é‚£ä¹ˆ
- en: '![P( lim Xn = Î¼ ) = 1\. nâ†’ âˆ ](img/file1980.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![P( lim Xn = Î¼ ) = 1\. nâ†’ âˆ ](img/file1980.png)'
- en: We are not going to prove this, just know that the sample average will converge
    to the mean with probability one.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸ä¼šè¯æ˜è¿™ä¸€ç‚¹ï¼Œåªéœ€è¦çŸ¥é“æ ·æœ¬å‡å€¼ä¼šä»¥æ¦‚ç‡1æ”¶æ•›åˆ°å‡å€¼ã€‚
- en: Remark 21\. (Convergence of random variables)
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨ 21.ï¼ˆéšæœºå˜é‡çš„æ”¶æ•›æ€§ï¼‰
- en: What we have seen in the weak and strong laws of large numbers are not unique
    to sample averages. Similar phenomena can be observed in other cases, thus, these
    types of convergences have their own exact definitions.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨å¤§æ•°æ³•åˆ™çš„å¼±æ³•åˆ™å’Œå¼ºæ³•åˆ™ä¸­çœ‹åˆ°çš„ç°è±¡å¹¶éä»…é™äºæ ·æœ¬å‡å€¼ã€‚åœ¨å…¶ä»–æƒ…å†µä¸‹ä¹Ÿå¯ä»¥è§‚å¯Ÿåˆ°ç±»ä¼¼çš„ç°è±¡ï¼Œå› æ­¤ï¼Œè¿™äº›ç±»å‹çš„æ”¶æ•›æ€§æœ‰å…¶å„è‡ªçš„ç²¾ç¡®å®šä¹‰ã€‚
- en: If X[1],X[2],â€¦ is a sequence of random variables, we say that
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœX[1],X[2],â€¦æ˜¯ä¸€ä¸ªéšæœºå˜é‡åºåˆ—ï¼Œæˆ‘ä»¬ç§°
- en: (a) X[n] converges in probability towards X if
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: (a) å¦‚æœX[n]åœ¨æ¦‚ç‡ä¸Šæ”¶æ•›åˆ°Xï¼Œåˆ™
- en: '![ lim P(|Xn âˆ’ X | â‰¥ ğœ€) = 0 nâ†’ âˆ ](img/file1981.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![ lim P(|Xn âˆ’ X | â‰¥ ğœ€) = 0 nâ†’ âˆ ](img/file1981.png)'
- en: for all ğœ€/span>0\. Convergence in probability is denoted by X[n]![âˆ’Pâ†’](img/file1982.png)X.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ‰€æœ‰ğœ€/span>0\. æ¦‚ç‡æ”¶æ•›è¡¨ç¤ºä¸ºX[n]![âˆ’Pâ†’](img/file1982.png)Xã€‚
- en: (b) X[n] converges almost surely towards X if
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: (b) å¦‚æœX[n]å‡ ä¹ç¡®å®šåœ°æ”¶æ•›åˆ°Xï¼Œåˆ™
- en: '![P( lim Xn = X ) = 1 nâ†’ âˆ ](img/file1983.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![P( lim Xn = X ) = 1 nâ†’ âˆ ](img/file1983.png)'
- en: holds. Almost sure convergence is denoted by X[n]![âˆ’aâˆ’.â†’ s.](img/file1984.png)X.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: æˆç«‹ã€‚å‡ ä¹ç¡®å®šçš„æ”¶æ•›è¡¨ç¤ºä¸ºX[n]![âˆ’aâˆ’.â†’ s.](img/file1984.png)Xã€‚
- en: Thus, the weak and strong laws of large numbers state that in certain cases,
    the sample averages converge to the expected value both in probability and almost
    surely.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¤§æ•°æ³•åˆ™çš„å¼±æ³•åˆ™å’Œå¼ºæ³•åˆ™æŒ‡å‡ºï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ ·æœ¬å‡å€¼åœ¨æ¦‚ç‡ä¸Šå’Œå‡ ä¹ç¡®å®šåœ°éƒ½æ”¶æ•›åˆ°æœŸæœ›å€¼ã€‚
- en: 20.6 Information theory
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.6 ä¿¡æ¯è®º
- en: If you have already trained a machine learning model in your practice, chances
    are you are already familiar with the mean-squared error
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å·²ç»åœ¨å®è·µä¸­è®­ç»ƒè¿‡æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¯èƒ½å·²ç»ç†Ÿæ‚‰å‡æ–¹è¯¯å·®ã€‚
- en: '![ n 1-âˆ‘ 2 n MSE (x,y) = n (f(xi)âˆ’ yi), x, y âˆˆ â„ , i=1 ](img/file1985.png)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![ n 1-âˆ‘ 2 n MSE (x,y) = n (f(xi)âˆ’ yi), x, y âˆˆ â„ , i=1 ](img/file1985.png)'
- en: 'where f : â„^n â†’â„ represents our model, x âˆˆâ„^n is the vector of one-dimensional
    observations, and y âˆˆâ„^n is the ground truth. After learning all about the expected
    value, this sum should be familiar: if we assume a probabilistic viewpoint and
    let X and Y be the random variables describing the data, then the mean-squared
    error can be written as the expected value'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 'å…¶ä¸­ï¼Œf : â„^n â†’â„è¡¨ç¤ºæˆ‘ä»¬çš„æ¨¡å‹ï¼Œx âˆˆâ„^næ˜¯ä¸€ä¸ªä¸€ç»´è§‚æµ‹å‘é‡ï¼Œy âˆˆâ„^næ˜¯çœŸå®å€¼ã€‚å­¦å®ŒæœŸæœ›å€¼åï¼Œè¿™ä¸ªæ±‚å’Œå¼åº”è¯¥æ˜¯ç†Ÿæ‚‰çš„ï¼šå¦‚æœæˆ‘ä»¬å‡è®¾ä¸€ä¸ªæ¦‚ç‡è§†è§’ï¼Œå¹¶è®©Xå’ŒYæ˜¯æè¿°æ•°æ®çš„éšæœºå˜é‡ï¼Œé‚£ä¹ˆå‡æ–¹è¯¯å·®å¯ä»¥è¡¨ç¤ºä¸ºæœŸæœ›å€¼ã€‚'
- en: '![ [ ] MSE (x, y) = ğ”¼ (f(X )âˆ’ Y )2\. ](img/file1986.png)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
  zh: '![ [ ] MSE (x, y) = ğ”¼ (f(X )âˆ’ Y )2\. ](img/file1986.png)'
- en: However, the mean-squared error is not suitable for classification problems.
    For instance, if the task is to classify the object of an image, the output is
    a discrete probability distribution for each sample. In this situation, we could
    use the so-called cross-entropy, defined by
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå‡æ–¹è¯¯å·®å¹¶ä¸é€‚ç”¨äºåˆ†ç±»é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä»»åŠ¡æ˜¯åˆ†ç±»ä¸€å¼ å›¾åƒçš„ç‰©ä½“ï¼Œè¾“å‡ºå°†æ˜¯æ¯ä¸ªæ ·æœ¬çš„ç¦»æ•£æ¦‚ç‡åˆ†å¸ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ‰€è°“çš„äº¤å‰ç†µï¼Œå…¶å®šä¹‰ä¸º
- en: '![ n H [p,q] = âˆ’ âˆ‘ p logq i i i=1 ](img/file1987.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![ n H [p,q] = âˆ’ âˆ‘ p logq i i i=1 ](img/file1987.png)'
- en: where p âˆˆâ„^n denotes the one-hot encoded vector of the class label for a single
    data sample, and q âˆˆâ„^n is the class label prediction, forming a probability distribution.
    (One-hot encoding is the process where we represent a finite set of possible class
    labels, such as {a,b,c} as zero-one vectors, like
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œp âˆˆâ„^nè¡¨ç¤ºå•ä¸ªæ•°æ®æ ·æœ¬çš„ç±»åˆ«æ ‡ç­¾çš„ç‹¬çƒ­ç¼–ç å‘é‡ï¼Œq âˆˆâ„^næ˜¯ç±»åˆ«æ ‡ç­¾é¢„æµ‹ï¼Œå½¢æˆä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚ï¼ˆç‹¬çƒ­ç¼–ç æ˜¯å°†ä¸€ä¸ªæœ‰é™çš„ç±»åˆ«æ ‡ç­¾é›†åˆï¼Œå¦‚{a,b,c}ï¼Œè¡¨ç¤ºä¸ºé›¶ä¸€å‘é‡çš„è¿‡ç¨‹ï¼Œä¾‹å¦‚
- en: '![a â† â†’ (1,0,0), b â† â†’ (0,1,0), c â† â†’ (0,0,1). ](img/file1988.png)'
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![a â† â†’ (1,0,0), b â† â†’ (0,1,0), c â† â†’ (0,0,1). ](img/file1988.png)'
- en: We do this because itâ€™s easier to work with vectors and matrices than with strings.)
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿™æ ·åšæ˜¯å› ä¸ºå¤„ç†å‘é‡å’ŒçŸ©é˜µæ¯”å¤„ç†å­—ç¬¦ä¸²æ›´å®¹æ˜“ã€‚)
- en: 'Not that surprisingly, H[p,q] is also an expected value, but itâ€™s much more
    than that: it quantifies the information content of the distribution q compared
    to the ground truth distribution q.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸ä»¤äººæƒŠè®¶ï¼ŒH[p,q]ä¹Ÿæ˜¯ä¸€ä¸ªæœŸæœ›å€¼ï¼Œä½†å®ƒè¿œä¸æ­¢å¦‚æ­¤ï¼šå®ƒé‡åŒ–äº†åˆ†å¸ƒqä¸çœŸå®åˆ†å¸ƒqä¹‹é—´çš„ä¿¡æ¯å†…å®¹ã€‚
- en: But what is information in a mathematical sense? Letâ€™s dive in.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åœ¨æ•°å­¦æ„ä¹‰ä¸Šï¼Œä»€ä¹ˆæ˜¯ä¿¡æ¯ï¼Ÿè®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ã€‚
- en: 20.6.1 Guess the number
  id: totrans-348
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.6.1 çŒœæ•°å­—
- en: Letâ€™s start with a simple game. I have thought of an integer between 0 and 7,
    and your job is to find out which one by asking yes-no questions.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„æ¸¸æˆå¼€å§‹ã€‚æˆ‘å·²ç»æƒ³å¥½äº†ä¸€ä¸ªä»‹äº 0 åˆ° 7 ä¹‹é—´çš„æ•´æ•°ï¼Œä½ çš„ä»»åŠ¡æ˜¯é€šè¿‡æ˜¯éé—®é¢˜æ‰¾å‡ºè¿™ä¸ªæ•°å­—ã€‚
- en: '![PIC](img/file1989.png)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1989.png)'
- en: 'FigureÂ 20.7: Which number am I thinking of?'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 20.7ï¼šæˆ‘åœ¨æƒ³å“ªä¸ªæ•°å­—ï¼Ÿ
- en: 'One possible strategy is to guess the numbers one by one. In other words, the
    sequence of your questions are:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§å¯èƒ½çš„ç­–ç•¥æ˜¯é€ä¸€çŒœæµ‹æ•°å­—ã€‚æ¢å¥è¯è¯´ï¼Œä½ çš„é—®é¢˜é¡ºåºæ˜¯ï¼š
- en: Is it 0?
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯ 0 å—ï¼Ÿ
- en: Is it 1?
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯ 1 å—ï¼Ÿ
- en: '![.. . ](img/file1990.png)'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![.. . ](img/file1990.png)'
- en: Is it 7?
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯ 7 å—ï¼Ÿ
- en: Although this strategy works, it is not an effective one. Why? Consider the
    average number of questions. Let the random variable X denote the number I have
    picked. As X is uniformly distributed â€” that is, P(X = k) = 1âˆ•8 for all k = 0,â€¦,7
    â€” the probability of asking exactly k questions is
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡è¿™ä¸ªç­–ç•¥æœ‰æ•ˆï¼Œä½†å¹¶ä¸æ˜¯æœ€æœ‰æ•ˆçš„ã€‚ä¸ºä»€ä¹ˆï¼Ÿè€ƒè™‘ä¸€ä¸‹å¹³å‡é—®é¢˜æ•°ã€‚è®¾éšæœºå˜é‡ X è¡¨ç¤ºæˆ‘é€‰æ‹©çš„æ•°å­—ã€‚ç”±äº X æ˜¯å‡åŒ€åˆ†å¸ƒçš„â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼ŒP(X = k)
    = 1/8ï¼Œå¯¹äºæ‰€æœ‰ k = 0,â€¦,7â€”â€”é‚£ä¹ˆæ°å¥½é—® k ä¸ªé—®é¢˜çš„æ¦‚ç‡ä¸º
- en: '![P(#questions = k) = P(X = k âˆ’ 1) = 1 8 ](img/file1991.png)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![P(#questions = k) = P(X = k âˆ’ 1) = 1 8 ](img/file1991.png)'
- en: as well. Thus, the number of questions needed is also uniformly distributed
    on {1,â€¦,8}, thus
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ã€‚å› æ­¤ï¼Œæ‰€éœ€çš„é—®é¢˜æ•°ä¹Ÿåœ¨ {1,â€¦,8} ä¸Šå‡åŒ€åˆ†å¸ƒï¼Œå› æ­¤
- en: '![ âˆ‘8 ğ”¼[#questions] = kP (#questions = k ) k=1 8 = 1-âˆ‘ k 8 k=1 = 1-8â‹…9-= 9-,
    8 2 2 ](img/file1992.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘8 ğ”¼[#questions] = kP (#questions = k ) k=1 8 = 1-âˆ‘ k 8 k=1 = 1-8â‹…9-= 9-,
    8 2 2 ](img/file1992.png)'
- en: where we have used that âˆ‘ [k=1]^n = ![n(n+1) 2](img/file1993.png).
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»ä½¿ç”¨äº† âˆ‘ [k=1]^n = ![n(n+1) 2](img/file1993.png)ã€‚
- en: Can we do better than this? Yes. In the previous sequential strategy, each question
    has a small chance of hitting, and a large chance of eliminating, only one potential
    candidate. Itâ€™s easy to see that the best would be to eliminate half the search
    space with each question.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬èƒ½åšå¾—æ¯”è¿™ä¸ªæ›´å¥½å—ï¼Ÿå¯ä»¥ã€‚åœ¨ä¹‹å‰çš„é¡ºåºç­–ç•¥ä¸­ï¼Œæ¯ä¸ªé—®é¢˜å‘½ä¸­ç›®æ ‡çš„æœºä¼šè¾ƒå°ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹åªä¼šæ’é™¤ä¸€ä¸ªæ½œåœ¨çš„å€™é€‰é¡¹ã€‚å¾ˆå®¹æ˜“çœ‹å‡ºï¼Œæœ€å¥½çš„æ–¹æ³•æ˜¯æ¯ä¸ªé—®é¢˜éƒ½èƒ½å°†æœç´¢ç©ºé—´å‡åŠã€‚
- en: Say, the number I thought of is 2\. By asking â€œis the number larger than 3â€?,
    the answer trims out four of the candidates.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯”å¦‚ï¼Œæˆ‘æƒ³åˆ°çš„æ•°å­—æ˜¯ 2ã€‚é€šè¿‡é—®â€œè¿™ä¸ªæ•°å­—å¤§äº 3 å—ï¼Ÿâ€ï¼Œç­”æ¡ˆå¯ä»¥æ’é™¤å››ä¸ªå€™é€‰é¡¹ã€‚
- en: '![PIC](img/file1994.png)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1994.png)'
- en: 'FigureÂ 20.8: The search space after the question is the number larger than
    3?'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 20.8ï¼šé—®é¢˜åæœç´¢ç©ºé—´æ˜¯æ¯” 3 å¤§çš„æ•°å­—å—ï¼Ÿ
- en: 'Each subsequent question cuts the remaining possibilities in half. In the case
    of X = 2, the three questions are the following:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªåç»­çš„é—®é¢˜éƒ½ä¼šå°†å‰©ä½™çš„å¯èƒ½æ€§å‡åŠã€‚ä»¥ X = 2 ä¸ºä¾‹ï¼Œä¸‰ä¸ªé—®é¢˜å¦‚ä¸‹ï¼š
- en: Is X â‰¥ 4? (no)
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X â‰¥ 4 å—ï¼Ÿï¼ˆå¦ï¼‰
- en: Is X â‰¥ 2? (yes)
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X â‰¥ 2 å—ï¼Ÿï¼ˆæ˜¯ï¼‰
- en: Is X â‰¥ 3? (no)
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X â‰¥ 3 å—ï¼Ÿï¼ˆå¦ï¼‰
- en: This is the so-called binary search, illustrated by FigureÂ [20.9](#).
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æ‰€è°“çš„äºŒåˆ†æŸ¥æ‰¾ï¼Œå¦‚å›¾ [20.9](#) æ‰€ç¤ºã€‚
- en: '![PIC](img/file1995.png)'
  id: totrans-371
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1995.png)'
- en: 'FigureÂ 20.9: Figuring out the answer with binary search'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 20.9ï¼šé€šè¿‡äºŒåˆ†æŸ¥æ‰¾å¾—å‡ºç­”æ¡ˆ
- en: 'If we write down the answers for our three consecutive questions (X â‰¥ 4, X
    â‰¥ 2, X â‰¥ 3) as a zero-one sequence, we obtain 010\. If this looks familiar, itâ€™s
    not an accident: 010 is 2 in binary. In fact, all of the answers can be coded
    using their binary form:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å°†ä¸‰ä¸ªè¿ç»­é—®é¢˜çš„ç­”æ¡ˆï¼ˆX â‰¥ 4, X â‰¥ 2, X â‰¥ 3ï¼‰å†™æˆä¸€ä¸ªäºŒè¿›åˆ¶åºåˆ—ï¼Œæˆ‘ä»¬å¾—åˆ° 010ã€‚å¦‚æœè¿™çœ‹èµ·æ¥å¾ˆç†Ÿæ‚‰ï¼Œé‚£å¹¶éå¶ç„¶ï¼š010 æ˜¯äºŒè¿›åˆ¶çš„
    2ã€‚äº‹å®ä¸Šï¼Œæ‰€æœ‰ç­”æ¡ˆéƒ½å¯ä»¥ç”¨å…¶äºŒè¿›åˆ¶å½¢å¼è¿›è¡Œç¼–ç ï¼š
- en: '![0 = 0002, 1 = 0012, 2 = 0102, 3 = 0112 4 = 1002, 5 = 1012, 6 = 1102, 7 =
    1112\. ](img/file1996.png)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
  zh: '![0 = 0002, 1 = 0012, 2 = 0102, 3 = 0112 4 = 1002, 5 = 1012, 6 = 1102, 7 =
    1112\. ](img/file1996.png)'
- en: 'Thus, we can reformulate our three questions:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥é‡æ–°è¡¨è¿°æˆ‘ä»¬çš„ä¸‰ä¸ªé—®é¢˜ï¼š
- en: Is 1 the 1st digit of X in binary?
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1 æ˜¯ X çš„ç¬¬ä¸€ä¸ªäºŒè¿›åˆ¶ä½å—ï¼Ÿ
- en: Is 1 the 2nd digit of X in binary?
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1 æ˜¯ X çš„ç¬¬äºŒä¸ªäºŒè¿›åˆ¶ä½å—ï¼Ÿ
- en: Is 1 the 3rd digit of X in binary?
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1 æ˜¯ X çš„ç¬¬ä¸‰ä¸ªäºŒè¿›åˆ¶ä½å—ï¼Ÿ
- en: 'As the above example shows, guessing the number is equivalent to finding the
    binary representation of the objects to be guessed. Each digit represents exactly
    one bit of information. (In this case, the representation is the actual binary
    form.) Binary codings have an additional perk: we no longer have to sequentially
    go through the questions, we can ask them simultaneously. From now on, instead
    of questions, weâ€™ll talk about binary representations (codings) and their bits.'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸Šä¾‹æ‰€ç¤ºï¼ŒçŒœæ•°å­—ç­‰åŒäºæ‰¾å‡ºå¾…çŒœæ•°å­—çš„äºŒè¿›åˆ¶è¡¨ç¤ºã€‚æ¯ä¸€ä½ä»£è¡¨ä¸€ä½ä¿¡æ¯ã€‚ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¡¨ç¤ºå°±æ˜¯å®é™…çš„äºŒè¿›åˆ¶å½¢å¼ã€‚ï¼‰äºŒè¿›åˆ¶ç¼–ç æœ‰ä¸€ä¸ªé¢å¤–çš„å¥½å¤„ï¼šæˆ‘ä»¬ä¸å†éœ€è¦é¡ºåºåœ°æé—®ï¼Œå¯ä»¥åŒæ—¶é—®å¤šä¸ªé—®é¢˜ã€‚ä»ç°åœ¨èµ·ï¼Œæˆ‘ä»¬å°†ä¸å†è®¨è®ºé—®é¢˜ï¼Œè€Œæ˜¯è®¨è®ºäºŒè¿›åˆ¶è¡¨ç¤ºï¼ˆç¼–ç ï¼‰åŠå…¶ä½ã€‚
- en: 'Notice that the number of bits is the same for each outcome of X. Thus, as
    this strategy always requires three bits, their average number is three as well:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæ¯ä¸ª X çš„ç»“æœæ‰€éœ€çš„ä½æ•°æ˜¯ç›¸åŒçš„ã€‚å› æ­¤ï¼Œè¿™ç§ç­–ç•¥å§‹ç»ˆéœ€è¦ä¸‰ä¸ªä½ï¼Œå› æ­¤å®ƒä»¬çš„å¹³å‡æ•°é‡ä¹Ÿæ˜¯ä¸‰ï¼š
- en: '![ 7 7 ğ”¼ [#bits] = âˆ‘ 3â‹…P (X = k ) = âˆ‘ 3â‹… 1-= 3\. 8 k=0 k=0 ](img/file1997.png)'
  id: totrans-381
  prefs: []
  type: TYPE_IMG
  zh: '![ 7 7 ğ”¼ [#bits] = âˆ‘ 3â‹…P (X = k ) = âˆ‘ 3â‹… 1-= 3\. 8 k=0 k=0 ](img/file1997.png)'
- en: Can we do better than the three questions on average? No.Â I invite you to come
    up with your arguments, but weâ€™ll see this later.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬èƒ½åšå¾—æ¯”å¹³å‡ä¸‰æ¬¡æé—®æ›´å¥½å—ï¼Ÿä¸èƒ½ã€‚æˆ‘é‚€è¯·ä½ æå‡ºä½ çš„è®ºæ®ï¼Œä½†æˆ‘ä»¬ç¨åä¼šçœ‹åˆ°è¿™ä¸€ç‚¹ã€‚
- en: Where does the number three in the above come from? In general, if we have 2^k
    possible choices, then log [2]2^k = k questions will be enough to find the answer.
    (As each question cuts the set of possible answers in half.) In other words, we
    have
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°çš„ä¸‰å·æ•°å­—æ¥è‡ªå“ªé‡Œï¼Ÿä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ 2^k ä¸ªå¯èƒ½çš„é€‰æ‹©ï¼Œé‚£ä¹ˆ log [2]2^k = k ä¸ªé—®é¢˜å°±è¶³å¤Ÿæ‰¾åˆ°ç­”æ¡ˆã€‚ï¼ˆå› ä¸ºæ¯ä¸ªé—®é¢˜éƒ½ä¼šå°†å¯èƒ½ç­”æ¡ˆçš„èŒƒå›´å‡åŠã€‚ï¼‰æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æœ‰
- en: '![ âˆ‘7 ğ”¼[#bits] = P (X = k )log2 23 k=0 7 = âˆ‘ P (X = k )log P(X = k)âˆ’1\. 2 k=0
    ](img/file1998.png)'
  id: totrans-384
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘7 ğ”¼[#bits] = P (X = k )log2 23 k=0 7 = âˆ‘ P (X = k )log P(X = k)âˆ’1\. 2 k=0
    ](img/file1998.png)'
- en: Thus, the value log [2]P(X = k)^(âˆ’1) is the number of bits needed to represent
    k in our coding. In other words,
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œlog [2]P(X = k)^(âˆ’1) çš„å€¼æ˜¯æˆ‘ä»¬ç¼–ç ä¸­è¡¨ç¤º k æ‰€éœ€è¦çš„æ¯”ç‰¹æ•°ã€‚æ¢å¥è¯è¯´ï¼Œ
- en: '![ğ”¼[#bits] = ğ”¼[log2P (X = k)âˆ’1]. ](img/file1999.png)'
  id: totrans-386
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼[#bits] = ğ”¼[log2P (X = k)âˆ’1]. ](img/file1999.png)'
- en: 'Letâ€™s get a bit ahead of ourselves: this is the famous entropy of the random
    variable X, and the quantity log [2]P(X = k)^(âˆ’1) is the so-called information
    content of the event X = k.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æå‰ä¸€ç‚¹ï¼šè¿™å°±æ˜¯è‘—åçš„éšæœºå˜é‡ X çš„ç†µï¼Œè€Œ log [2]P(X = k)^(âˆ’1) æ˜¯æ‰€è°“çš„äº‹ä»¶ X = k çš„ä¿¡æ¯é‡ã€‚
- en: However, at this point, these concepts are quite unclear. What does log [2]P(X
    = k)^(âˆ’1) have to do with information? Why canâ€™t we represent k better than log
    [2]P(X = k)^(âˆ’1) bits? Weâ€™ll see the answers soon.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œåˆ°æ­¤ä¸ºæ­¢ï¼Œè¿™äº›æ¦‚å¿µè¿˜å¾ˆä¸æ¸…æ¥šã€‚log [2]P(X = k)^(âˆ’1) ä¸ä¿¡æ¯æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸èƒ½ç”¨æ¯” log [2]P(X = k)^(âˆ’1)
    æ›´å¥½çš„æ–¹å¼æ¥è¡¨ç¤º k çš„æ¯”ç‰¹æ•°ï¼Ÿæˆ‘ä»¬å¾ˆå¿«å°±ä¼šçœ‹åˆ°ç­”æ¡ˆã€‚
- en: '20.6.2 Guess the number 2: Electric Boogaloo'
  id: totrans-389
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.6.2 çŒœæ•°å­— 2ï¼šç”µæ°”æ³¢å¤é²
- en: Letâ€™s play the guessing game again but with a twist this time. Now, I have picked
    a number from {0,1,2}, and you have to guess which one. The catch is, I am twice
    as likely to select 0 than the others.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å†ç©ä¸€æ¬¡çŒœæ•°å­—çš„æ¸¸æˆï¼Œä½†è¿™æ¬¡æœ‰ç‚¹ä¸åŒã€‚æˆ‘ç°åœ¨ä» {0,1,2} ä¸­é€‰äº†ä¸€ä¸ªæ•°å­—ï¼Œä½ å¾—çŒœæ˜¯å“ªä¸€ä¸ªã€‚éš¾ç‚¹æ˜¯ï¼Œæˆ‘é€‰æ‹© 0 çš„æ¦‚ç‡æ˜¯å…¶ä»–æ•°å­—çš„ä¸¤å€ã€‚
- en: In probabilistic terms, if X denotes the number I picked, then P(X = 0) = 1âˆ•2,
    while P(X = 1) = P(X = 2) = 1âˆ•4.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¦‚ç‡è®ºä¸­ï¼Œå¦‚æœ X è¡¨ç¤ºæˆ‘é€‰çš„æ•°å­—ï¼Œé‚£ä¹ˆ P(X = 0) = 1âˆ•2ï¼Œè€Œ P(X = 1) = P(X = 2) = 1âˆ•4ã€‚
- en: 'What is the best strategy? There are two key facts to recall:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ä½³ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿæœ‰ä¸¤ä¸ªå…³é”®äº‹å®éœ€è¦è®°ä½ï¼š
- en: good questions cut the search space in half,
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¥½çš„é—®é¢˜ä¼šå°†æœç´¢ç©ºé—´å‡å°‘ä¸€åŠï¼Œ
- en: and asking questions is equivalent to finding a binary encoding of the outcomes.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æé—®ç›¸å½“äºæ‰¾åˆ°è¿™äº›ç»“æœçš„äºŒè¿›åˆ¶ç¼–ç ã€‚
- en: However, as we are looking for the encoding that is optimal on average, cutting
    the search space in half with each digit is not meant in a numeric way. Rather,
    in a probabilistic one. Thus, if 0 is indeed twice as likely, representing 0,1,2
    by
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œç”±äºæˆ‘ä»¬åœ¨å¯»æ‰¾å¹³å‡æœ€ä¼˜çš„ç¼–ç ï¼Œä¸èƒ½ç®€å•åœ°ç†è§£ä¸ºæ¯ä¸ªæ•°å­—å°†æœç´¢ç©ºé—´å‡å°‘ä¸€åŠã€‚è¿™ç§ç†è§£åº”å½“æ˜¯æ¦‚ç‡æ€§çš„ã€‚æ‰€ä»¥ï¼Œå¦‚æœ 0 çš„ç¡®æ˜¯æ›´æœ‰å¯èƒ½çš„ï¼Œé‚£ä¹ˆé€šè¿‡
- en: '![0 âˆ¼ 0, 1 âˆ¼ 01, 2 âˆ¼ 10, ](img/file2000.png)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
  zh: '![0 âˆ¼ 0, 1 âˆ¼ 01, 2 âˆ¼ 10, ](img/file2000.png)'
- en: the average number of bits is
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: å¹³å‡æ¯”ç‰¹æ•°æ˜¯
- en: '![ğ”¼[#bits] = P (X = 0) â‹…1+ P (X = 1) â‹…2+ P (X = 2) â‹…2 = P (X = 0) log22 + P
    (X = 1)log24 + P (X = 2)log24 2 âˆ‘ âˆ’1 = P(X = k)log2P (X = k) k=0 = 3-. 2 ](img/file2001.png)'
  id: totrans-398
  prefs: []
  type: TYPE_IMG
  zh: '![ğ”¼[#bits] = P (X = 0) â‹…1+ P (X = 1) â‹…2+ P (X = 2) â‹…2 = P (X = 0) log22 + P
    (X = 1)log24 + P (X = 2)log24 2 âˆ‘ âˆ’1 = P(X = k)log2P (X = k) k=0 = 3-. 2 ](img/file2001.png)'
- en: Once more, we have arrived at the familiar logarithmic formula. We are one step
    closer to grasping the meaning of the mysterious quantity log [2]P(X = k)^(âˆ’1).
    The smaller it is, the more questions we need; equivalently, the more bits we
    need to represent k within our encoding to avoid information loss.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: å†ä¸€æ¬¡ï¼Œæˆ‘ä»¬èµ°åˆ°äº†ç†Ÿæ‚‰çš„å¯¹æ•°å…¬å¼ã€‚æˆ‘ä»¬ç¦»ç†è§£è¿™ä¸ªç¥ç§˜é‡ log [2]P(X = k)^(âˆ’1) æ›´è¿‘ä¸€æ­¥äº†ã€‚å®ƒè¶Šå°ï¼Œæˆ‘ä»¬éœ€è¦çš„é—®é¢˜å°±è¶Šå¤šï¼›åŒæ ·åœ°ï¼Œæˆ‘ä»¬åœ¨ç¼–ç ä¸­è¡¨ç¤º
    k æ‰€éœ€çš„æ¯”ç‰¹æ•°ä¹Ÿè¶Šå¤šï¼Œä»¥é¿å…ä¿¡æ¯ä¸¢å¤±ã€‚
- en: So, what are these mysterious quantities exactly?
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œè¿™äº›ç¥ç§˜çš„é‡åˆ°åº•æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ
- en: 20.6.3 Information and entropy
  id: totrans-401
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.6.3 ä¿¡æ¯ä¸ç†µ
- en: It is time to formulate the general problem. Suppose that our random variable
    X assumes a number from the set {1,2,â€¦,N}, each with probability p[k] = P(X =
    k). Upon repeatedly observing X, what is the average information content of our
    observations?
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯æ—¶å€™å¯¹è¿™ä¸ªé—®é¢˜è¿›è¡Œä¸€èˆ¬åŒ–äº†ã€‚å‡è®¾æˆ‘ä»¬çš„éšæœºå˜é‡ X ä»é›†åˆ {1,2,â€¦,N} ä¸­å–ä¸€ä¸ªæ•°ï¼Œæ¯ä¸ªæ•°çš„æ¦‚ç‡æ˜¯ p[k] = P(X = k)ã€‚åœ¨åå¤è§‚å¯Ÿ
    X åï¼Œæˆ‘ä»¬çš„è§‚å¯Ÿçš„å¹³å‡ä¿¡æ¯é‡æ˜¯å¤šå°‘ï¼Ÿ
- en: According to what weâ€™ve learned, we are looking for the quantity
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æˆ‘ä»¬æ‰€å­¦åˆ°çš„ï¼Œæˆ‘ä»¬æ­£åœ¨å¯»æ‰¾çš„é‡æ˜¯
- en: '![ âˆ‘N ğ”¼ [I (X )] = âˆ’ p logp , k=1 k k ](img/file2002.png)'
  id: totrans-404
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘N ğ”¼ [I (X )] = âˆ’ p logp , k=1 k k ](img/file2002.png)'
- en: 'where I : â„• â†’â„ denotes the information I(k) = âˆ’log p[k]. Previously, we have
    seen two special cases where I(k) is the average number of questions needed to
    guess k. (Equivalently, the information is the average number of bits in k using
    the optimal encoding.)'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 'å…¶ä¸­I : â„• â†’ â„è¡¨ç¤ºä¿¡æ¯I(k) = âˆ’log p[k]ã€‚ä¹‹å‰ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°ä¸¤ä¸ªç‰¹æ®Šæƒ…å†µï¼Œå…¶ä¸­I(k)æ˜¯çŒœæµ‹kæ‰€éœ€çš„å¹³å‡é—®é¢˜æ•°ã€‚ï¼ˆç­‰ä»·åœ°ï¼Œä¿¡æ¯æ˜¯ä½¿ç”¨æœ€ä¼˜ç¼–ç æ—¶kçš„å¹³å‡æ¯”ç‰¹æ•°ã€‚ï¼‰'
- en: What is the information in general?
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆä¸€èˆ¬æ¥è¯´ï¼Œä¿¡æ¯æ˜¯ä»€ä¹ˆï¼Ÿ
- en: 'Letâ€™s look for I as an unknown function of the probabilities: I(x) = f(P(X
    = x)). What can f be? There are two key properties of thatâ€™ll lead us to the answer.
    First, the more probable an event is, the less information content there is. (Recall
    the previous example, where the most probable outcome required the least amount
    of bits in our binary representation.)'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æŠŠIè§†ä¸ºæ¦‚ç‡çš„æœªçŸ¥å‡½æ•°ï¼šI(x) = f(P(X = x))ã€‚é‚£ä¹ˆfå¯èƒ½æ˜¯ä»€ä¹ˆï¼Ÿæœ‰ä¸¤ä¸ªå…³é”®æ€§è´¨å°†å¼•å¯¼æˆ‘ä»¬æ‰¾åˆ°ç­”æ¡ˆã€‚é¦–å…ˆï¼Œäº‹ä»¶è¶Šå¯èƒ½å‘ç”Ÿï¼Œä¿¡æ¯å«é‡å°±è¶Šå°‘ã€‚ï¼ˆå›æƒ³ä¸€ä¸‹ä¹‹å‰çš„ä¾‹å­ï¼Œæœ€å¯èƒ½çš„ç»“æœéœ€è¦æœ€å°‘çš„æ¯”ç‰¹æ•°è¿›è¡ŒäºŒè¿›åˆ¶è¡¨ç¤ºã€‚ï¼‰
- en: 'Second, as a function of the probabilities, the information is additive: f(pq)
    = f(p) + f(q). Why? Suppose that I have picked two numbers, independently from
    each other, and now you have to guess those two. You can do this sequentially,
    applying the optimal strategy to the first one, then the second one.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶æ¬¡ï¼Œä½œä¸ºæ¦‚ç‡çš„å‡½æ•°ï¼Œä¿¡æ¯æ˜¯å¯åŠ çš„ï¼šf(pq) = f(p) + f(q)ã€‚ä¸ºä»€ä¹ˆï¼Ÿå‡è®¾æˆ‘ç‹¬ç«‹åœ°é€‰æ‹©äº†ä¸¤ä¸ªæ•°å­—ï¼Œç°åœ¨ä½ éœ€è¦çŒœæµ‹è¿™ä¸¤ä¸ªæ•°å­—ã€‚ä½ å¯ä»¥é¡ºåºè¿›è¡Œï¼Œé¦–å…ˆåº”ç”¨æœ€ä¼˜ç­–ç•¥çŒœæµ‹ç¬¬ä¸€ä¸ªï¼Œç„¶åçŒœæµ‹ç¬¬äºŒä¸ªã€‚
- en: In mathematical terms, f(p) is
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨æ•°å­¦è¯­è¨€æ¥è¯´ï¼Œf(p)æ˜¯
- en: continuous,
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿ç»­çš„ï¼Œ
- en: strictly increasing, that is, f(p)/span>f(q) for any p/span>q,
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸¥æ ¼é€’å¢ï¼Œå³å¯¹äºä»»ä½•p > qï¼Œæœ‰f(p) > f(q)ï¼Œ
- en: and additive, that is, f(pq) = f(p) + f(q) for any p,q.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸”å¯åŠ æ€§ï¼Œå³å¯¹äºä»»ä½•p, qï¼Œæœ‰f(pq) = f(p) + f(q)ã€‚
- en: Iâ€™ll spare you the mathematical details, but with a bit of calculus magic, we
    can confidently conclude that the only option is f(p) = âˆ’log [a]p, where a/span>1\.
    Seemingly, information depends on the base, but as
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¼šçœç•¥æ•°å­¦ç»†èŠ‚ï¼Œä½†é€šè¿‡ä¸€ç‚¹å¾®ç§¯åˆ†é­”æ³•ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªä¿¡åœ°å¾—å‡ºå”¯ä¸€çš„é€‰é¡¹æ˜¯f(p) = âˆ’log [a]pï¼Œå…¶ä¸­a > 1ã€‚è¡¨é¢ä¸Šçœ‹ï¼Œä¿¡æ¯ä¼¼ä¹ä¾èµ–äºåŸºæ•°ï¼Œä½†å®é™…ä¸Š
- en: '![log x = logax-, b logab ](img/file2005.png)'
  id: totrans-414
  prefs: []
  type: TYPE_IMG
  zh: '![log x = logax-, b logab ](img/file2005.png)'
- en: the choice of base only influences the information and entropy up to a multiplicative
    scaling factor. Thus, using the natural logarithm is the simplest choice.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæ•°çš„é€‰æ‹©ä»…ä¼šå½±å“ä¿¡æ¯å’Œç†µçš„ä¹˜æ³•å°ºåº¦å› å­ã€‚å› æ­¤ï¼Œä½¿ç”¨è‡ªç„¶å¯¹æ•°æ˜¯æœ€ç®€å•çš„é€‰æ‹©ã€‚
- en: So, here is the formal definition at last.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œè¿™é‡Œç»ˆäºç»™å‡ºäº†æ­£å¼å®šä¹‰ã€‚
- en: Definition 96\. (Information)
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 96.ï¼ˆä¿¡æ¯ï¼‰
- en: Let X be a discrete random variable with probability mass function {P(X = x[k])}[k].
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾Xä¸ºå…·æœ‰æ¦‚ç‡è´¨é‡å‡½æ•°{P(X = x[k])}[k]çš„ç¦»æ•£éšæœºå˜é‡ã€‚
- en: The information of the event X = x[k] is defined by
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹ä»¶X = x[k]çš„ä¿¡æ¯å®šä¹‰ä¸º
- en: '![I(xk) := âˆ’ logP (X = xk ) = logP (X = xk )âˆ’ 1\. ](img/file2006.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![I(xk) := âˆ’ logP (X = xk ) = logP (X = xk )âˆ’ 1\. ](img/file2006.png)'
- en: (Note that whenever the base of log is not indicated, we are using the natural
    base e.) To emphasize the dependency of the information on X, weâ€™ll sometimes
    explicitly denote the connection by I[X](x[k]).
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆæ³¨æ„ï¼Œå½“æ²¡æœ‰æŒ‡å®šå¯¹æ•°çš„åŸºæ•°æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨è‡ªç„¶å¯¹æ•°eã€‚ï¼‰ä¸ºäº†å¼ºè°ƒä¿¡æ¯ä¾èµ–äºXï¼Œæˆ‘ä»¬æœ‰æ—¶ä¼šæ˜ç¡®è¡¨ç¤ºå…¶å…³ç³»ä¸ºI[X](x[k])ã€‚
- en: Armed with the notion of information, we are ready to define entropy, the average
    amount of information per observation. This quantity is named after Claude Shannon,
    who essentially founded information theory in his epic paper â€œA Mathematical Theory
    of Communication.â€
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: å‡­å€Ÿä¿¡æ¯çš„æ¦‚å¿µï¼Œæˆ‘ä»¬å‡†å¤‡å¥½å®šä¹‰ç†µï¼Œå³æ¯æ¬¡è§‚å¯Ÿçš„å¹³å‡ä¿¡æ¯é‡ã€‚è¿™ä¸ªé‡ä»¥Claude Shannonçš„åå­—å‘½åï¼Œä»–åœ¨å…¶å²è¯—è®ºæ–‡ã€Šé€šä¿¡çš„æ•°å­¦ç†è®ºã€‹ä¸­å¥ å®šäº†ä¿¡æ¯ç†è®ºçš„åŸºç¡€ã€‚
- en: Definition 97\. (Shannon entropy)
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 97.ï¼ˆé¦™å†œç†µï¼‰
- en: Let X be a discrete random variable with probability mass function {P(X = x[k])}[k].
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾Xä¸ºå…·æœ‰æ¦‚ç‡è´¨é‡å‡½æ•°{P(X = x[k])}[k]çš„ç¦»æ•£éšæœºå˜é‡ã€‚
- en: The entropy of X is defined by
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: Xçš„ç†µå®šä¹‰ä¸º
- en: '![H[X ] := ğ”¼[I(X )] âˆ‘âˆ = âˆ’ P(X = xk)logP (X = xk). k=1 ](img/file2007.png)'
  id: totrans-426
  prefs: []
  type: TYPE_IMG
  zh: '![H[X ] := ğ”¼[I(X )] âˆ‘âˆ = âˆ’ P(X = xk)logP (X = xk). k=1 ](img/file2007.png)'
- en: Even though H[X] is called the Shannon entropy, weâ€™ll just simply refer to it
    as entropy, unless an explicit distinction is needed.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡H[X]è¢«ç§°ä¸ºé¦™å†œç†µï¼Œä½†æˆ‘ä»¬å°†ç®€å•åœ°ç§°ä¹‹ä¸ºç†µï¼Œé™¤ééœ€è¦æ˜ç¡®åŒºåˆ†ã€‚
- en: One of the first things we can notice is that H[X] â‰¥ 0\. This is shown in the
    following proposition.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°çš„ç¬¬ä¸€ä»¶äº‹æ˜¯H[X] â‰¥ 0ã€‚è¿™ä¸€ç‚¹åœ¨ä¸‹é¢çš„å‘½é¢˜ä¸­æœ‰æ‰€ä½“ç°ã€‚
- en: Proposition 7\. (The nonnegativity of entropy)
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: å‘½é¢˜ 7.ï¼ˆç†µçš„éè´Ÿæ€§ï¼‰
- en: Let X be an arbitrary discrete random variable. Then H[X] â‰¥ 0.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾Xä¸ºä»»æ„ç¦»æ•£éšæœºå˜é‡ã€‚é‚£ä¹ˆH[X] â‰¥ 0ã€‚
- en: Proof. By definition,
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜ã€‚æ ¹æ®å®šä¹‰ï¼Œ
- en: '![ âˆ‘ H [X ] = P(X = xk)logP (X = xk)âˆ’1\. k ](img/file2008.png)'
  id: totrans-432
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘ H [X ] = P(X = xk)logP (X = xk)âˆ’1\. k ](img/file2008.png)'
- en: 'First, suppose that P(X = x[k])â‰ 0 for all k. Then, as 0 P(X = x[k]) â‰¤ 1, the
    information is nonnegative: log P(X = x[k])^(âˆ’1) â‰¥ 0\. Hence, as all terms in
    the defining sum are nonnegative, H[X] is nonnegative as well.'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œå‡è®¾å¯¹äºæ‰€æœ‰çš„kï¼ŒP(X = x[k])â‰ 0ã€‚é‚£ä¹ˆï¼Œç”±äº0 â‰¤ P(X = x[k]) â‰¤ 1ï¼Œä¿¡æ¯æ˜¯éè´Ÿçš„ï¼šlog P(X = x[k])^(âˆ’1)
    â‰¥ 0ã€‚å› æ­¤ï¼Œå®šä¹‰å’Œä¸­çš„æ‰€æœ‰é¡¹éƒ½æ˜¯éè´Ÿçš„ï¼ŒH[X]ä¹Ÿæ˜¯éè´Ÿçš„ã€‚
- en: If P(X = x[k]) = 0 for some k, then, as lim[xâ†’0+]xlog x = 0, the expression
    0 â‹… log 0 is taken to be 0\. Thus, H[X] is still nonnegative.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœP(X = x[k]) = 0å¯¹äºæŸäº›kï¼Œé‚£ä¹ˆï¼Œç”±äºlim[xâ†’0+]xlog x = 0ï¼Œè¡¨è¾¾å¼0 â‹… log 0è¢«è§†ä¸º0ã€‚å› æ­¤ï¼ŒH[X]ä»ç„¶æ˜¯éè´Ÿçš„ã€‚
- en: Computing the entropy in practice is hard, as we have to evaluate sums that
    involve logarithms. However, there are a few special cases that shed some much
    needed light on the concept of entropy. Letâ€™s look at them!
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šè®¡ç®—ç†µæ˜¯å›°éš¾çš„ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦è¯„ä¼°åŒ…å«å¯¹æ•°çš„æ±‚å’Œã€‚ç„¶è€Œï¼Œä»ç„¶æœ‰å‡ ä¸ªç‰¹æ®Šæƒ…å†µä¸ºç†µçš„æ¦‚å¿µæä¾›äº†æœ‰ä»·å€¼çš„å¯ç¤ºã€‚è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ï¼
- en: Example 1\. The discrete uniform distribution. (See the definition of the discrete
    uniform distribution in SectionÂ [19.2.4](ch031.xhtml#the-uniform-distribution).)
    Let X âˆ¼ Uniform({1,â€¦,n}). Then
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 1\. ç¦»æ•£å‡åŒ€åˆ†å¸ƒã€‚ï¼ˆè§ç¬¬[19.2.4](ch031.xhtml#the-uniform-distribution)èŠ‚å¯¹ç¦»æ•£å‡åŒ€åˆ†å¸ƒçš„å®šä¹‰ã€‚ï¼‰è®¾X
    âˆ¼ Uniform({1,â€¦,n})ã€‚åˆ™
- en: '![ âˆ‘n H [X ] = âˆ’ -1log 1- k=1n n âˆ‘n = 1logn k=1 n = log n. ](img/file2009.png)'
  id: totrans-437
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘n H [X ] = âˆ’ -1log 1- k=1n n âˆ‘n = 1logn k=1 n = log n. ](img/file2009.png)'
- en: 'By now, we have an intuitive understanding of entropy as the average amount
    of information per observation. Take a wild guess: how does the entropy of the
    uniform distribution compare amongst all other distributions concentrated on {1,2,â€¦,n}?
    Is it above or below average? Is it perhaps minimal or maximal?'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»å¯¹ç†µæœ‰äº†ç›´è§‚çš„ç†è§£ï¼Œå³æ¯æ¬¡è§‚æµ‹çš„å¹³å‡ä¿¡æ¯é‡ã€‚çŒœçŒœçœ‹ï¼šåœ¨æ‰€æœ‰é›†ä¸­äº{1,2,â€¦,n}çš„åˆ†å¸ƒä¸­ï¼Œå‡åŒ€åˆ†å¸ƒçš„ç†µå¦‚ä½•ä¸å…¶ä»–åˆ†å¸ƒç›¸æ¯”ï¼Ÿæ˜¯é«˜äºè¿˜æ˜¯ä½äºå¹³å‡æ°´å¹³ï¼Ÿæ˜¯æœ€å°çš„è¿˜æ˜¯æœ€å¤§çš„ï¼Ÿ
- en: Weâ€™ll reveal the answer by the end of this chapter, but take a minute to ponder
    this question before moving on to the next example.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨æœ¬ç« æœ«å°¾æ­ç¤ºç­”æ¡ˆï¼Œä½†åœ¨ç»§ç»­ä¸‹ä¸€ä¸ªç¤ºä¾‹ä¹‹å‰ï¼ŒèŠ±ä¸€åˆ†é’Ÿæ€è€ƒè¿™ä¸ªé—®é¢˜ã€‚
- en: Example 2\. The single-point distribution. (See the definition of the single-point
    distribution in SectionÂ [19.2.5](ch031.xhtml#the-singlepoint-distribution)) Let
    X âˆ¼Î´(a). Then
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 2\. å•ç‚¹åˆ†å¸ƒã€‚ï¼ˆè§ç¬¬[19.2.5](ch031.xhtml#the-singlepoint-distribution)èŠ‚å¯¹å•ç‚¹åˆ†å¸ƒçš„å®šä¹‰ï¼‰è®¾X
    âˆ¼Î´(a)ã€‚åˆ™
- en: '![H [X ] = âˆ’ 1 â‹…log 1 = 0\. ](img/file2010.png)'
  id: totrans-441
  prefs: []
  type: TYPE_IMG
  zh: '![H [X ] = âˆ’ 1 â‹…log 1 = 0\. ](img/file2010.png)'
- en: In other words, as the event X = a is certain, no information is gained upon
    observing X. Now think back to the previous example. As X âˆ¼Î´(k) is concentrated
    on {1,2,â€¦,n} for all k = 1,2,â€¦,n, give the previous question one more thought.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œç”±äºäº‹ä»¶X = aæ˜¯ç¡®å®šçš„ï¼Œè§‚å¯ŸXæ—¶æ²¡æœ‰è·å¾—ä»»ä½•ä¿¡æ¯ã€‚ç°åœ¨å›æƒ³ä¸€ä¸‹ä¹‹å‰çš„ä¾‹å­ã€‚ç”±äºX âˆ¼Î´(k)é›†ä¸­äº{1,2,â€¦,n}ï¼Œå¯¹äºæ‰€æœ‰k = 1,2,â€¦,nï¼Œå†æ€è€ƒä¸€ä¸‹ä¹‹å‰çš„é—®é¢˜ã€‚
- en: Letâ€™s see a partial answer in the next example.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åœ¨ä¸‹ä¸€ä¸ªç¤ºä¾‹ä¸­çœ‹åˆ°éƒ¨åˆ†ç­”æ¡ˆã€‚
- en: Example 3\. The Bernoulli distribution. (See the definition of the Bernoulli
    distribution in SectionÂ [19.2.1](ch031.xhtml#the-bernoulli-distribution)). Let
    X âˆ¼ Bernoulli(p). Then, it is easy to see that
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 3\. ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚ï¼ˆè§ç¬¬[19.2.1](ch031.xhtml#the-bernoulli-distribution)èŠ‚å¯¹ä¼¯åŠªåˆ©åˆ†å¸ƒçš„å®šä¹‰ï¼‰ã€‚è®¾X
    âˆ¼ Bernoulli(p)ã€‚åˆ™ï¼Œå¾ˆå®¹æ˜“çœ‹å‡º
- en: '![H [X ] = âˆ’ plogp âˆ’ (1âˆ’ p)log(1âˆ’ p). ](img/file2011.png)'
  id: totrans-445
  prefs: []
  type: TYPE_IMG
  zh: '![H [X ] = âˆ’ plogp âˆ’ (1âˆ’ p)log(1âˆ’ p). ](img/file2011.png)'
- en: Which value of p maximizes the entropy? To find the maxima of H[X], we can turn
    to the derivatives. (Recall how the derivative and second derivative can be used
    for optimization, as claimed by TheoremÂ [87](ch021.xhtml#x1-214004r87).)
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: å“ªä¸ªpå€¼æœ€å¤§åŒ–ç†µï¼Ÿä¸ºäº†æ‰¾åˆ°H[X]çš„æå¤§å€¼ï¼Œæˆ‘ä»¬å¯ä»¥æ±‚å¯¼ã€‚ï¼ˆå›æƒ³ä¸€ä¸‹ï¼Œå¯¼æ•°å’ŒäºŒé˜¶å¯¼æ•°å¦‚ä½•ç”¨äºä¼˜åŒ–ï¼Œæ­£å¦‚å®šç†[87](ch021.xhtml#x1-214004r87)æ‰€è¿°ã€‚ï¼‰
- en: Thus, let f(p) = H[X] = âˆ’plog p âˆ’ (1 âˆ’p)log(1 âˆ’p). Then,
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè®¾f(p) = H[X] = âˆ’plog p âˆ’ (1 âˆ’p)log(1 âˆ’p)ã€‚åˆ™ï¼Œ
- en: '![fâ€²(p) = âˆ’ logp + log(1âˆ’ p) = log 1-âˆ’-p, p fâ€²â€²(p) = âˆ’ 1-âˆ’--1--. p 1 âˆ’ p ](img/file2012.png)'
  id: totrans-448
  prefs: []
  type: TYPE_IMG
  zh: '![fâ€²(p) = âˆ’ logp + log(1âˆ’ p) = log 1-âˆ’-p, p fâ€²â€²(p) = âˆ’ 1-âˆ’--1--. p 1 âˆ’ p ](img/file2012.png)'
- en: By solving f^â€²(p) = 0, we obtain that p = 1âˆ•2, which is the only potential extrema
    of f(p). As f^(â€²â€²)(1âˆ•2) = âˆ’4/span>0, we see that p = 1âˆ•2 is indeed a local maximum.
    Letâ€™s plot f(p) to obtain a visual confirmation as well.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è§£f^â€²(p) = 0ï¼Œæˆ‘ä»¬å¾—åˆ°p = 1âˆ•2ï¼Œè¿™æ˜¯f(p)çš„å”¯ä¸€æ½œåœ¨æå€¼ç‚¹ã€‚ç”±äºf^(â€²â€²)(1âˆ•2) = âˆ’4/span>0ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°p =
    1âˆ•2ç¡®å®æ˜¯ä¸€ä¸ªå±€éƒ¨æœ€å¤§å€¼ã€‚è®©æˆ‘ä»¬ç»˜åˆ¶f(p)å›¾åƒï¼Œä»¥è·å¾—ç›´è§‚çš„ç¡®è®¤ã€‚
- en: '[PRE8]'
  id: totrans-450
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![PIC](img/file2013.png)'
  id: totrans-451
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file2013.png)'
- en: 'FigureÂ 20.10: The entropy of the Bernoulli distribution'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 20.10ï¼šä¼¯åŠªåˆ©åˆ†å¸ƒçš„ç†µ
- en: For p = 1âˆ•2, that is, where the entropy of Bernoulli(p) is maximal, we have
    a uniform distribution on the two-element set {0,1}. On the other hand, for p
    = 0 or p = 1, where the entropy is minimal, Bernoulli(p) is a single-point distribution.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºp = 1âˆ•2ï¼Œå³å½“ä¼¯åŠªåˆ©åˆ†å¸ƒçš„ç†µè¾¾åˆ°æœ€å¤§å€¼æ—¶ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªåœ¨äºŒå…ƒé›†åˆ{0,1}ä¸Šçš„å‡åŒ€åˆ†å¸ƒã€‚å¦ä¸€æ–¹é¢ï¼Œå½“p = 0æˆ–p = 1æ—¶ï¼Œç†µæœ€å°ï¼Œä¼¯åŠªåˆ©åˆ†å¸ƒåˆ™ä¸ºå•ç‚¹åˆ†å¸ƒã€‚
- en: 'As every random variable on {0,1} is Bernoulli-distributed, we seem to have
    a partial answer to our question: the uniform distribution maximizes entropy,
    while single-point ones minimize it.'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº {0,1} ä¸Šçš„æ¯ä¸ªéšæœºå˜é‡éƒ½æ˜¯ä¼¯åŠªåˆ©åˆ†å¸ƒçš„ï¼Œæˆ‘ä»¬ä¼¼ä¹å·²ç»æœ‰äº†éƒ¨åˆ†ç­”æ¡ˆï¼šå‡åŒ€åˆ†å¸ƒæœ€å¤§åŒ–ç†µï¼Œè€Œå•ç‚¹åˆ†å¸ƒæœ€å°åŒ–ç†µã€‚
- en: As the following theorem indicates, this is true in general as well.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸‹å®šç†æ‰€ç¤ºï¼Œè¿™åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ä¹Ÿæ˜¯æˆç«‹çš„ã€‚
- en: Theorem 138\. (The uniform distribution and maximal entropy)
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç† 138ï¼ï¼ˆå‡åŒ€åˆ†å¸ƒä¸æœ€å¤§ç†µï¼‰
- en: 'Let E = {x[1],â€¦,x[n]}be a finite set, and let X : Î© â†’E be a random variable
    that assumes values in E. Then,'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾ E = {x[1],â€¦,x[n]} æ˜¯ä¸€ä¸ªæœ‰é™é›†ï¼Œä¸”è®¾ X : Î© â†’E ä¸ºä¸€ä¸ªå–å€¼äº E çš„éšæœºå˜é‡ã€‚é‚£ä¹ˆï¼Œ'
- en: '![H [X] â‰¤ H [Uniform (E)], ](img/file2014.png)'
  id: totrans-458
  prefs: []
  type: TYPE_IMG
  zh: '![H [X] â‰¤ H [Uniform (E)], ](img/file2014.png)'
- en: and H[X] = H[Uniform(E)] if and only if X is uniformly distributed on E.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” H[X] = H[Uniform(E)] å½“ä¸”ä»…å½“ X åœ¨ E ä¸Šæ˜¯å‡åŒ€åˆ†å¸ƒçš„ã€‚
- en: We are not going to show this here, but there are several proofs out there.
    For instance, Bishopâ€™s classic Pattern Recognition and Machine Learning uses the
    Lagrange multiplier method to explicitly find the maximum of the multivariable
    function f(p[1],â€¦,p[n]) = âˆ’âˆ‘ [k=1]^np[k] log p[k]; feel free to check it out for
    the details.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿™é‡Œä¸ä¼šå±•ç¤ºè¿™ä¸ªï¼Œä½†æœ‰è®¸å¤šè¯æ˜å¯ä»¥å‚è€ƒã€‚ä¾‹å¦‚ï¼ŒBishop çš„ç»å…¸è‘—ä½œã€Šæ¨¡å¼è¯†åˆ«ä¸æœºå™¨å­¦ä¹ ã€‹ä½¿ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•æ¥æ˜¾å¼åœ°æ‰¾åˆ°å¤šå˜é‡å‡½æ•° f(p[1],â€¦,p[n])
    = âˆ’âˆ‘ [k=1]^np[k] log p[k] çš„æœ€å¤§å€¼ï¼›æœ‰å…´è¶£çš„è¯å¯ä»¥æŸ¥çœ‹å…¶ä¸­çš„è¯¦ç»†å†…å®¹ã€‚
- en: What if we donâ€™t restrict our discrete random variable to a finite set? In that
    case, the Shannon entropy has no upper limit. In the problem set of this chapter,
    youâ€™ll see that the entropy of the geometric distribution is
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ä¸å°†ç¦»æ•£å‹éšæœºå˜é‡é™åˆ¶åœ¨æœ‰é™é›†ä¸Šï¼Œæ€ä¹ˆåŠï¼Ÿåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒShannon ç†µæ²¡æœ‰ä¸Šé™ã€‚åœ¨æœ¬ç« çš„é—®é¢˜é›†ä¸­ï¼Œä½ å°†çœ‹åˆ°å‡ ä½•åˆ†å¸ƒçš„ç†µæ˜¯
- en: '![H [Geo (p)] = âˆ’ plogp-+-(1âˆ’-p)-log(1-âˆ’-p). p ](img/file2015.png)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
  zh: '![H [Geo (p)] = âˆ’ plogp-+-(1âˆ’-p)-log(1-âˆ’-p). p ](img/file2015.png)'
- en: It is easy to see that lim[pâ†’0]H[Geo(p)] = âˆ. Letâ€™s plot this!
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå®¹æ˜“çœ‹å‡º lim[pâ†’0]H[Geo(p)] = âˆã€‚æˆ‘ä»¬æ¥ç»˜åˆ¶ä¸€ä¸‹å›¾åƒï¼
- en: '[PRE9]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![PIC](img/file2016.png)'
  id: totrans-465
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file2016.png)'
- en: 'FigureÂ 20.11: The entropy of the geometric distribution'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 20.11ï¼šå‡ ä½•åˆ†å¸ƒçš„ç†µ
- en: Thus, the Shannon entropy can assume any nonnegative value.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒShannon ç†µå¯ä»¥å–ä»»ä½•éè´Ÿå€¼ã€‚
- en: 20.6.4 Differential entropy
  id: totrans-468
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.6.4 å¾®åˆ†ç†µ
- en: So far, we have only defined the entropy for discrete random variables.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬åªä¸ºç¦»æ•£å‹éšæœºå˜é‡å®šä¹‰äº†ç†µã€‚
- en: Does it translate to continuous ones as well? Yes. The formula ğ”¼[ âˆ’ log f[X](X)]
    can be directly applied for continuous random variables, yielding the so-called
    differential entropy. Here is the formal definition.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¦ä¹Ÿé€‚ç”¨äºè¿ç»­å‹éšæœºå˜é‡ï¼Ÿæ˜¯çš„ã€‚å…¬å¼ ğ”¼[ âˆ’ log f[X](X)] å¯ä»¥ç›´æ¥åº”ç”¨äºè¿ç»­å‹éšæœºå˜é‡ï¼Œå¾—åˆ°æ‰€è°“çš„å¾®åˆ†ç†µã€‚è¿™é‡Œæ˜¯å…¶æ­£å¼å®šä¹‰ã€‚
- en: Definition 98\. (Differential entropy)
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ 98ï¼ï¼ˆå¾®åˆ†ç†µï¼‰
- en: Let X be a continuous random variable. The differential entropy of X is defined
    by the formula
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾ X ä¸ºä¸€ä¸ªè¿ç»­å‹éšæœºå˜é‡ã€‚X çš„å¾®åˆ†ç†µé€šè¿‡ä»¥ä¸‹å…¬å¼å®šä¹‰ï¼š
- en: '![ âˆ« âˆ H [X ] := âˆ’ f (x )log f (x)dx, âˆ’âˆ X X ](img/file2017.png)'
  id: totrans-473
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« âˆ H [X ] := âˆ’ f (x )log f (x)dx, âˆ’âˆ X X ](img/file2017.png)'
- en: where f[X] denotes the probability density function of X.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ f[X] è¡¨ç¤º X çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚
- en: 'Now comes the surprise. Can we derive the formula from the Shannon entropy?
    We are going to approach the problem like we did when we defined the expected
    value for continuous random variables in SectionÂ [20.2](ch032.xhtml#continuous-random-variables):
    approximate the continuous random variable with a discrete one, then see where
    the Shannon entropy converges.'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¥äº†ä¸€ä¸ªæƒŠå–œã€‚æˆ‘ä»¬èƒ½ä» Shannon ç†µæ¨å¯¼å‡ºè¿™ä¸ªå…¬å¼å—ï¼Ÿæˆ‘ä»¬å°†åƒåœ¨å®šä¹‰è¿ç»­å‹éšæœºå˜é‡çš„æœŸæœ›å€¼æ—¶é‚£æ ·å¤„ç†è¿™ä¸ªé—®é¢˜ï¼šç”¨ç¦»æ•£å‹éšæœºå˜é‡æ¥é€¼è¿‘è¿ç»­å‹éšæœºå˜é‡ï¼Œç„¶åçœ‹çœ‹
    Shannon ç†µæ”¶æ•›åˆ°å“ªé‡Œã€‚
- en: 'Thus, let X : Î© â†’â„ be a continuous random variable, and let [a,b] âŠ†â„ be a (large)
    interval, so large that P(X![âˆˆâˆ•](img/file2018.png)[a,b]) is extremely small. Weâ€™ll
    subdivide [a,b] into n equal parts by'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 'å› æ­¤ï¼Œè®¾ X : Î© â†’â„ ä¸ºè¿ç»­å‹éšæœºå˜é‡ï¼Œè®¾ [a,b] âŠ†â„ ä¸ºä¸€ä¸ªï¼ˆè¾ƒå¤§çš„ï¼‰åŒºé—´ï¼Œä½¿å¾— P(X![âˆˆâˆ•](img/file2018.png)[a,b])
    æå°ã€‚æˆ‘ä»¬å°† [a,b] åˆ†å‰²ä¸º n ç­‰ä»½ï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š'
- en: '![ k(bâˆ’ a) xk = a+ -------, k = 0,1,...,n, n ](img/file2019.png)'
  id: totrans-477
  prefs: []
  type: TYPE_IMG
  zh: '![ k(bâˆ’ a) xk = a+ -------, k = 0,1,...,n, n ](img/file2019.png)'
- en: and define the approximating random variable X^((n)) by
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶é€šè¿‡ä»¥ä¸‹æ–¹å¼å®šä¹‰é€¼è¿‘çš„éšæœºå˜é‡ X^((n))ï¼š
- en: '![ ( (n) |{ xk if x âˆˆ (xk âˆ’1,xk] for some k = 1,2,...,n, X (Ï‰ ) := | ( 0 otherwise.
    ](img/file2020.png)'
  id: totrans-479
  prefs: []
  type: TYPE_IMG
  zh: '![ ( (n) |{ xk if x âˆˆ (xk âˆ’1,xk] for some k = 1,2,...,n, X (Ï‰ ) := | ( 0 otherwise.
    ](img/file2020.png)'
- en: This way, the entropy of X^((n)) is given by
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·ï¼ŒX^((n)) çš„ç†µç”±ä»¥ä¸‹å…¬å¼ç»™å‡ºï¼š
- en: '![ (n) âˆ‘n (n) (n) H [X ] = âˆ’ P (X = xk)logP (X = xk). k=1 ](img/file2021.png)'
  id: totrans-481
  prefs: []
  type: TYPE_IMG
  zh: '![ (n) âˆ‘n (n) (n) H [X ] = âˆ’ P (X = xk)logP (X = xk). k=1 ](img/file2021.png)'
- en: However, due to how we defined X^((n)),
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œç”±äºæˆ‘ä»¬å®šä¹‰äº† X^((n)),
- en: '![ âˆ« (n) xk P(X = xk) = P(xkâˆ’ 1 <X â‰¤ Xk ) = x fX (x)dx, kâˆ’1 ](img/file2022.png)'
  id: totrans-483
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« (n) xk P(X = xk) = P(xkâˆ’ 1 <X â‰¤ Xk ) = x fX (x)dx, kâˆ’1 ](img/file2022.png)'
- en: where f[X] is the density function of X. Now, the mean value theorem for definite
    integrals (TheoremÂ [93](ch022.xhtml#x1-235008r93)) gives that there is a Î¾[k]
    âˆˆ [x[kâˆ’1],x[k]] such that
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­f[X]æ˜¯Xçš„å¯†åº¦å‡½æ•°ã€‚ç°åœ¨ï¼Œå®šç§¯åˆ†çš„å‡å€¼å®šç†ï¼ˆå®šç†[93](ch022.xhtml#x1-235008r93)ï¼‰è¡¨æ˜ï¼Œå­˜åœ¨Î¾[k] âˆˆ [x[kâˆ’1],x[k]]ï¼Œä½¿å¾—
- en: '![âˆ« xk f (Î¾ ) fX (x)dx = (xk âˆ’ xkâˆ’ 1)fX (Î¾k) = -X---k-, xkâˆ’1 n ](img/file2023.png)'
  id: totrans-485
  prefs: []
  type: TYPE_IMG
  zh: '![âˆ« xk f (Î¾ ) fX (x)dx = (xk âˆ’ xkâˆ’ 1)fX (Î¾k) = -X---k-, xkâˆ’1 n ](img/file2023.png)'
- en: thus, in conclusion,
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ€»ç»“æ¥è¯´ï¼Œ
- en: '![ (n) fX-(Î¾k) P (X = xk ) = n . ](img/file2024.png)'
  id: totrans-487
  prefs: []
  type: TYPE_IMG
  zh: '![ (n) fX-(Î¾k) P (X = xk ) = n . ](img/file2024.png)'
- en: (Recall that as the partition x[0]/span>x[1]/span>â€¦/span>x[n] is equidistant,
    x[k] âˆ’x[kâˆ’1] = 1âˆ•n.)
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆå›æƒ³ä¸€ä¸‹ï¼Œx[0]/span>x[1]/span>â€¦/span>x[n]çš„åˆ’åˆ†æ˜¯ç­‰è·çš„ï¼Œx[k] âˆ’x[kâˆ’1] = 1âˆ•nã€‚ï¼‰
- en: Now, using P(X^((n)) = x[k]) = ![fX(Î¾k) n](img/file2025.png), we obtain
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä½¿ç”¨P(X^((n)) = x[k]) = ![fX(Î¾k) n](img/file2025.png)ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°
- en: '![ âˆ‘n H[X (n)] = âˆ’ P (X (n) = xk )log P(X (n) = xk) k=1 n = âˆ’ âˆ‘ fX-(Î¾k)-log
    fX-(Î¾k)- n n k=n1 n = âˆ’ âˆ‘ fX-(Î¾k)-log f (Î¾ )+ log nâˆ‘ fX(Î¾k). n X k n k=1 k=1 ](img/file2026.png)'
  id: totrans-490
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘n H[X (n)] = âˆ’ P (X (n) = xk )log P(X (n) = xk) k=1 n = âˆ’ âˆ‘ fX-(Î¾k)-log
    fX-(Î¾k)- n n k=n1 n = âˆ’ âˆ‘ fX-(Î¾k)-log f (Î¾ )+ log nâˆ‘ fX(Î¾k). n X k n k=1 k=1 ](img/file2026.png)'
- en: Both of these terms are Riemann-sums, approximating the integral of the functions
    inside. If n is large, and the interval [a,b] is big enough, then
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸¤ä¸ªé¡¹éƒ½æ˜¯é»æ›¼å’Œï¼Œè¿‘ä¼¼å‡½æ•°å†…éƒ¨çš„ç§¯åˆ†ã€‚å¦‚æœnå¾ˆå¤§ï¼Œå¹¶ä¸”åŒºé—´[a,b]è¶³å¤Ÿå¤§ï¼Œé‚£ä¹ˆ
- en: '![ n âˆ« âˆ’ âˆ‘ fX-(Î¾k)logf (Î¾ ) â‰ˆ âˆ’ âˆ f (x)logf (x)dx = h[X ], n X k âˆ’âˆ X X k=1
    ](img/file2027.png)'
  id: totrans-492
  prefs: []
  type: TYPE_IMG
  zh: '![ n âˆ« âˆ’ âˆ‘ fX-(Î¾k)logf (Î¾ ) â‰ˆ âˆ’ âˆ f (x)logf (x)dx = h[X ], n X k âˆ’âˆ X X k=1
    ](img/file2027.png)'
- en: and
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸”
- en: '![ n âˆ« âˆ âˆ‘ fX-(Î¾k)-â‰ˆ f (x)dx = 1, n âˆ’ âˆ X k=1 ](img/file2028.png)'
  id: totrans-494
  prefs: []
  type: TYPE_IMG
  zh: '![ n âˆ« âˆ âˆ‘ fX-(Î¾k)-â‰ˆ f (x)dx = 1, n âˆ’ âˆ X k=1 ](img/file2028.png)'
- en: implying
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€
- en: '![H [X (n)] â‰ˆ h [X ]+ logn. ](img/file2029.png)'
  id: totrans-496
  prefs: []
  type: TYPE_IMG
  zh: '![H [X (n)] â‰ˆ h [X ]+ logn. ](img/file2029.png)'
- en: This is quite surprising, as one would expect H[X^((n))] to converge towards
    h(X). This is not the case. In fact,
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆä»¤äººæƒŠè®¶ï¼Œå› ä¸ºäººä»¬é€šå¸¸ä¼šæœŸæœ›H[X^((n))]ä¼šæ”¶æ•›åˆ°h(X)ã€‚ä½†äº‹å®å¹¶éå¦‚æ­¤ã€‚
- en: '![ lim (H [X (n)]âˆ’ log n) = h[X ] nâ†’ âˆ ](img/file2030.png)'
  id: totrans-498
  prefs: []
  type: TYPE_IMG
  zh: '![ lim (H [X (n)]âˆ’ log n) = h[X ] nâ†’ âˆ ](img/file2030.png)'
- en: holds.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿æŒã€‚
- en: Itâ€™s time for the examples.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯ç¤ºä¾‹æ—¶é—´ã€‚
- en: Example 1\. The uniform distribution. (See the definition of the uniform distribution
    in SectionÂ [19.3.4](ch031.xhtml#the-uniform-distribution2).) Let X âˆ¼ Uniform(a,b).
    Then,
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹1. å‡åŒ€åˆ†å¸ƒã€‚ï¼ˆè§[19.3.4](ch031.xhtml#the-uniform-distribution2)èŠ‚ä¸­çš„å‡åŒ€åˆ†å¸ƒå®šä¹‰ã€‚ï¼‰è®¾Xâˆ¼Uniform(a,b)ã€‚é‚£ä¹ˆï¼Œ
- en: '![ âˆ« b -1--- --1-- h[X ] = âˆ’ bâˆ’ a log bâˆ’ a dx a = log(bâˆ’ a), ](img/file2031.png)'
  id: totrans-502
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« b -1--- --1-- h[X ] = âˆ’ bâˆ’ a log bâˆ’ a dx a = log(bâˆ’ a), ](img/file2031.png)'
- en: 'which is similar to the discrete uniform case. However, there is one notable
    difference: h(X) is negative when bâˆ’a/span>1\. This is in stark contrast with
    the Shannon entropy, which is always nonnegative.'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ç¦»æ•£å‡åŒ€åˆ†å¸ƒçš„æƒ…å†µç›¸ä¼¼ã€‚ç„¶è€Œï¼Œæœ‰ä¸€ä¸ªæ˜¾è‘—çš„åŒºåˆ«ï¼šå½“bâˆ’a/span>1æ—¶ï¼Œh(X)æ˜¯è´Ÿçš„ã€‚è¿™ä¸é¦™å†œç†µå½¢æˆé²œæ˜å¯¹æ¯”ï¼Œåè€…å§‹ç»ˆæ˜¯éè´Ÿçš„ã€‚
- en: Example 2\. The normal distribution. (See the definition of the normal distribution
    in SectionÂ [19.3.6](ch031.xhtml#the-normal-distribution).) Let X âˆ¼ğ’©(Î¼,ÏƒÂ²). Then,
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹2. æ­£æ€åˆ†å¸ƒã€‚ï¼ˆè§[19.3.6](ch031.xhtml#the-normal-distribution)èŠ‚ä¸­çš„æ­£æ€åˆ†å¸ƒå®šä¹‰ã€‚ï¼‰è®¾Xâˆ¼ğ’©(Î¼,ÏƒÂ²)ã€‚é‚£ä¹ˆï¼Œ
- en: '![ âˆ« âˆ 1 (xâˆ’Î¼)2 ( 1 (xâˆ’Î¼)2) h[X ] = âˆ’ -âˆš---eâˆ’ 2Ïƒ2 log -âˆš----eâˆ’ 2Ïƒ2 dx âˆ’ âˆ Ïƒ
    2Ï€âˆ« Ïƒ 2Ï€ âˆ« ( âˆš ---) âˆ --1---âˆ’ (xâˆ’2ÏƒÎ¼2)2- âˆ (xâˆ’-Î¼-)2---1---âˆ’ (xâˆ’2Î¼Ïƒ)22 = log Ïƒ
    2Ï€ âˆ’âˆ Ïƒâˆš 2Ï€e dx+ âˆ’ âˆ 2Ïƒ2 Ïƒâˆš 2Ï€e dx â—Ÿ--------â—â—œ--------â— â—Ÿ------------â—â—œ------------â—
    =1 = 21Ïƒ2Var[X ]= 12 1 ( 2 ) = 2- 1+ log(Ïƒ 2Ï€ ) . ](img/file2032.png)'
  id: totrans-505
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« âˆ 1 (xâˆ’Î¼)2 ( 1 (xâˆ’Î¼)2) h[X ] = âˆ’ -âˆš---eâˆ’ 2Ïƒ2 log -âˆš----eâˆ’ 2Ïƒ2 dx âˆ’ âˆ Ïƒ
    2Ï€âˆ« Ïƒ 2Ï€ âˆ« ( âˆš ---) âˆ --1---âˆ’ (xâˆ’2ÏƒÎ¼2)2- âˆ (xâˆ’-Î¼-)2---1---âˆ’ (xâˆ’2Î¼Ïƒ)22 = log Ïƒ
    2Ï€ âˆ’âˆ Ïƒâˆš 2Ï€e dx+ âˆ’ âˆ 2Ïƒ2 Ïƒâˆš 2Ï€e dx â—Ÿ--------â—â—œ--------â— â—Ÿ------------â—â—œ------------â—
    =1 = 21Ïƒ2Var[X ]= 12 1 ( 2 ) = 2- 1+ log(Ïƒ 2Ï€ ) . ](img/file2032.png)'
- en: Depending on the value of Ïƒ, the value of h[X] can be negative here as well.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®Ïƒçš„å€¼ï¼Œè¿™é‡Œh[X]çš„å€¼ä¹Ÿå¯èƒ½æ˜¯è´Ÿçš„ã€‚
- en: Previously, we have seen that for discrete distributions on a given finite set,
    the uniform distribution maximizes entropy, as TheoremÂ [138](ch032.xhtml#x1-343023r138)
    claims.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹‹å‰æˆ‘ä»¬å·²ç»çœ‹åˆ°ï¼Œå¯¹äºç»™å®šæœ‰é™é›†åˆä¸Šçš„ç¦»æ•£åˆ†å¸ƒï¼Œå‡åŒ€åˆ†å¸ƒæœ€å¤§åŒ–ç†µï¼Œæ­£å¦‚å®šç†[138](ch032.xhtml#x1-343023r138)æ‰€è¿°ã€‚
- en: What is the analogue of TheoremÂ [138](ch032.xhtml#x1-343023r138) for continuous
    distributions? Take a wild guess. If we let X be any continuous distribution,
    then, as we have seen,
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ç»­åˆ†å¸ƒçš„å®šç†[138](ch032.xhtml#x1-343023r138)çš„ç±»ä¼¼ç‰©æ˜¯ä»€ä¹ˆï¼Ÿå¤§èƒ†çŒœä¸€ä¸‹ã€‚å¦‚æœæˆ‘ä»¬è®¾Xä¸ºä»»ä½•è¿ç»­åˆ†å¸ƒï¼Œé‚£ä¹ˆï¼Œæ­£å¦‚æˆ‘ä»¬å·²ç»çœ‹åˆ°çš„ï¼Œ
- en: '![h[Uniform (a,b)] = log(bâˆ’ a), ](img/file2033.png)'
  id: totrans-509
  prefs: []
  type: TYPE_IMG
  zh: '![h[Uniform (a,b)] = log(bâˆ’ a), ](img/file2033.png)'
- en: which can assume any real number. Similarly to the discrete case, we have to
    make restrictions; this time, weâ€™ll fix the variance. Here is the result.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶å€¼å¯ä»¥æ˜¯ä»»æ„å®æ•°ã€‚ä¸ç¦»æ•£æƒ…å½¢ç±»ä¼¼ï¼Œæˆ‘ä»¬å¿…é¡»åšä¸€äº›é™åˆ¶ï¼›è¿™æ¬¡ï¼Œæˆ‘ä»¬å°†å›ºå®šæ–¹å·®ã€‚ç»“æœå¦‚ä¸‹ã€‚
- en: Theorem 139\. (Maximizing the differential entropy)
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: å®šç†139.ï¼ˆæœ€å¤§åŒ–å¾®åˆ†ç†µï¼‰
- en: Let X be a continuous random variable with variance ÏƒÂ². Then
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾Xæ˜¯ä¸€ä¸ªæ–¹å·®ä¸ºÏƒÂ²çš„è¿ç»­éšæœºå˜é‡ã€‚é‚£ä¹ˆ
- en: '![h[X ] â‰¤ h [ğ’© (0,Ïƒ2)], ](img/file2034.png)'
  id: totrans-513
  prefs: []
  type: TYPE_IMG
  zh: '![h[X ] â‰¤ h [ğ’© (0,Ïƒ2)], ](img/file2034.png)'
- en: and h[X] = h[ğ’©(0,ÏƒÂ²)] if and only if X âˆ¼ğ’©(Î¼,ÏƒÂ²).
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸”h[X] = h[ğ’©(0,ÏƒÂ²)] å½“ä¸”ä»…å½“ X âˆ¼ğ’©(Î¼,ÏƒÂ²)ã€‚
- en: Again, we are not going to prove this. You can check Bishopâ€™s Pattern Recognition
    and Machine Learning for more details.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸æ‰“ç®—è¯æ˜è¿™ä¸ªã€‚ä½ å¯ä»¥å‚è€ƒæ¯”ISHOPçš„ã€Šæ¨¡å¼è¯†åˆ«ä¸æœºå™¨å­¦ä¹ ã€‹è·å–æ›´å¤šç»†èŠ‚ã€‚
- en: 20.7 The Maximum Likelihood Estimation
  id: totrans-516
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.7 æœ€å¤§ä¼¼ç„¶ä¼°è®¡
- en: I am an evangelist for simple ideas. Stop me any time you want, but whichever
    field I was in, Iâ€™ve always been able to find a small set of mind-numbingly simple
    ideas making the entire shebang work. (Not that you could interrupt me, as this
    is a book. Jokeâ€™s on you!)
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯ç®€å•æƒ³æ³•çš„ä¼ æ’­è€…ã€‚éšæ—¶å¯ä»¥æ‰“æ–­æˆ‘ï¼Œä½†æ— è®ºæˆ‘åœ¨å“ªä¸ªé¢†åŸŸï¼Œæˆ‘æ€»æ˜¯èƒ½æ‰¾åˆ°ä¸€å°å¥—æå…¶ç®€å•çš„æƒ³æ³•ï¼Œä½¿æ•´ä¸ªå·¥ä½œå¾—ä»¥è¿è½¬ã€‚ï¼ˆè™½ç„¶ä½ ä¸å¯èƒ½æ‰“æ–­æˆ‘ï¼Œå› ä¸ºè¿™æ˜¯ä¸€æœ¬ä¹¦ã€‚ç¬‘è¯æ˜¯å¯¹ä½ çš„ï¼ï¼‰
- en: 'Let me give you a concrete example thatâ€™s on my mind. What do you think enabled
    the rise of deep learning, including neural networks with billions of parameters?
    Three ideas as simple as ABC:'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ç»™ä½ ä¸¾ä¸ªæˆ‘è„‘æµ·ä¸­çš„å…·ä½“ä¾‹å­ã€‚ä½ è®¤ä¸ºæ˜¯ä»€ä¹ˆæ¨åŠ¨äº†æ·±åº¦å­¦ä¹ çš„å´›èµ·ï¼ŒåŒ…æ‹¬å…·æœ‰æ•°åäº¿å‚æ•°çš„ç¥ç»ç½‘ç»œï¼Ÿæœ‰ä¸‰ä¸ªåƒABCä¸€æ ·ç®€å•çš„æƒ³æ³•ï¼š
- en: that you can optimize the loss function by going against its gradient (no matter
    the number of parameters),
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥é€šè¿‡åå‘æ¢¯åº¦ä¼˜åŒ–æŸå¤±å‡½æ•°ï¼ˆæ— è®ºå‚æ•°çš„æ•°é‡æ˜¯å¤šå°‘ï¼‰ï¼Œ
- en: that you can efficiently compute the gradient with a clever application of the
    chain rule and matrix multiplication,
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥é€šè¿‡å·§å¦™åº”ç”¨é“¾å¼æ³•åˆ™å’ŒçŸ©é˜µä¹˜æ³•æ¥é«˜æ•ˆåœ°è®¡ç®—æ¢¯åº¦ï¼Œ
- en: and that we can perform matrix operations blazingly fast on a GPU.
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¹¶ä¸”æˆ‘ä»¬å¯ä»¥åœ¨GPUä¸Šä»¥æå¿«çš„é€Ÿåº¦è¿›è¡ŒçŸ©é˜µè¿ç®—ã€‚
- en: Sure, thereâ€™s a great tower of work built upon these ideas, but these three
    lie at the very foundation of machine learning today. Ultimately, these enable
    you to converse with large language models. To have your car cruise around town
    while you read the newspaper. To predict the exact shape of massive amino-acid
    chains called proteins, responsible for building up every living thing. (Including
    you.)
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œåœ¨è¿™äº›æƒ³æ³•çš„åŸºç¡€ä¸Šå»ºç«‹äº†ä¸€ä¸ªåºå¤§çš„å·¥ä½œä½“ç³»ï¼Œä½†è¿™ä¸‰ç‚¹æ„æˆäº†ä»Šå¤©æœºå™¨å­¦ä¹ çš„åŸºç¡€ã€‚æœ€ç»ˆï¼Œè¿™äº›ä½¿ä½ èƒ½å¤Ÿä¸å¤§å‹è¯­è¨€æ¨¡å‹å¯¹è¯ã€‚è®©ä½ çš„è½¦åœ¨åŸå¸‚ä¸­è‡ªåŠ¨å·¡èˆªï¼ŒåŒæ—¶ä½ é˜…è¯»æŠ¥çº¸ã€‚é¢„æµ‹å·¨å¤§çš„æ°¨åŸºé…¸é“¾çš„å‡†ç¡®å½¢çŠ¶ï¼Œè¿™äº›æ°¨åŸºé…¸é“¾æ„æˆäº†æ¯ä¸€ä¸ªç”Ÿç‰©ä½“ã€‚ï¼ˆåŒ…æ‹¬ä½ ã€‚ï¼‰
- en: Gradient descent, backpropagation, and high-performance linear algebra are on
    the practical side of the metaphorical machine learning coin. If we conjure up
    a parametric model, we can throw some extremely powerful tools at it.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢¯åº¦ä¸‹é™ã€åå‘ä¼ æ’­å’Œé«˜æ•ˆçš„çº¿æ€§ä»£æ•°å±äºéšå–»ä¸­æœºå™¨å­¦ä¹ ç¡¬å¸çš„å®ç”¨é¢ã€‚å¦‚æœæˆ‘ä»¬æ„å»ºä¸€ä¸ªå‚æ•°åŒ–æ¨¡å‹ï¼Œå¯ä»¥æŠ•å…¥ä¸€äº›æå…¶å¼ºå¤§çš„å·¥å…·æ¥è¿›è¡Œå¤„ç†ã€‚
- en: But where do our models come from?
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æˆ‘ä»¬çš„æ¨¡å‹ä»å“ªé‡Œæ¥ï¼Ÿ
- en: 'As Iâ€™ve said, there is a small set of key ideas that go a long way. We are
    about to meet one: the maximum likelihood estimation.'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œå­˜åœ¨ä¸€å°å¥—å…³é”®çš„æƒ³æ³•ï¼Œå®ƒä»¬èµ·åˆ°äº†è‡³å…³é‡è¦çš„ä½œç”¨ã€‚æˆ‘ä»¬å³å°†é‡åˆ°å…¶ä¸­ä¹‹ä¸€ï¼šæœ€å¤§ä¼¼ç„¶ä¼°è®¡ã€‚
- en: 20.7.1 Probabilistic modeling 101
  id: totrans-526
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.7.1 æ¦‚ç‡å»ºæ¨¡å…¥é—¨
- en: As a self-proclaimed evangelist of simple ideas, Iâ€™ll start with a simple example
    to illustrate a simple idea.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸€ä¸ªè‡ªå°ä¸ºç®€å•æ€æƒ³çš„ä¼ æ’­è€…ï¼Œæˆ‘å°†ä»ä¸€ä¸ªç®€å•çš„ä¾‹å­å¼€å§‹ï¼Œæ¥è¯´æ˜ä¸€ä¸ªç®€å•çš„æƒ³æ³•ã€‚
- en: 'Pick up a coin and toss it a few times, recording each outcome. The question
    is, once more, simple: whatâ€™s the probability of heads? We canâ€™t just immediately
    assume p = 1âˆ•2, that is, a fair coin. For instance, one side of our coin could
    be coated with lead, resulting in a bias. To find out, letâ€™s perform some statistics.
    (Rolling up my sleeves, throwing down my gloves.)'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹¿èµ·ä¸€æšç¡¬å¸ï¼ŒæŠ•æ·å‡ æ¬¡å¹¶è®°å½•æ¯æ¬¡çš„ç»“æœã€‚é—®é¢˜å†æ¬¡ç®€å•ï¼šæ­£é¢çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿæˆ‘ä»¬ä¸èƒ½ç«‹å³å‡è®¾ p = 1âˆ•2ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œç¡¬å¸æ˜¯å…¬å¹³çš„ã€‚ä¾‹å¦‚ï¼Œç¡¬å¸çš„ä¸€é¢å¯èƒ½è¢«æ¶‚ä¸Šé“…ï¼Œä»è€Œäº§ç”Ÿåå·®ã€‚ä¸ºäº†å¼„æ¸…æ¥šè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æ¥åšä¸€äº›ç»Ÿè®¡ã€‚ï¼ˆå·èµ·è¢–å­ï¼Œä¸¢ä¸‹æ‰‹å¥—ã€‚ï¼‰
- en: 'Mathematically speaking, we can model coin tosses with the Bernoulli distribution
    (SectionÂ [19.2.1](ch031.xhtml#the-bernoulli-distribution)):'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ•°å­¦è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¼¯åŠªåˆ©åˆ†å¸ƒæ¥å»ºæ¨¡ç¡¬å¸æŠ•æ·ï¼ˆç¬¬[19.2.1èŠ‚](ch031.xhtml#the-bernoulli-distribution)ï¼‰ï¼š
- en: '![P(X = 1) = p, P(X = 0) = 1 âˆ’ p, ](img/file2035.png)'
  id: totrans-530
  prefs: []
  type: TYPE_IMG
  zh: '![P(X = 1) = p, P(X = 0) = 1 âˆ’ p, ](img/file2035.png)'
- en: where
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­
- en: X is the random variable representing the outcome of a single toss,
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X æ˜¯è¡¨ç¤ºå•æ¬¡æŠ•æ·ç»“æœçš„éšæœºå˜é‡ï¼Œ
- en: X = 1 for heads and X = 0 for tails,
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X = 1 è¡¨ç¤ºæ­£é¢ï¼ŒX = 0 è¡¨ç¤ºåé¢ï¼Œ
- en: and p âˆˆ [0,1] is the probability of heads.
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¹¶ä¸” p âˆˆ [0,1] æ˜¯æ­£é¢çš„æ¦‚ç‡ã€‚
- en: Thatâ€™s just the model. Weâ€™re here to estimate the parameter p, and this is what
    we have statistics for.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯æ¨¡å‹ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä¼°è®¡å‚æ•° pï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬ç»Ÿè®¡å­¦å¯ä»¥å¤„ç†çš„ã€‚
- en: Tossing up the coin n times yields the zero-one sequence x[1],x[2],â€¦,x[n], where
    each x[i] is a realization of a Bernoulli-distributed random variable X[i] âˆ¼ Bernoulli(p),
    independent of each other.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ç¡¬å¸æŠ•æ· n æ¬¡å¾—åˆ°é›¶ä¸€åºåˆ— x[1], x[2], â€¦, x[n]ï¼Œå…¶ä¸­æ¯ä¸ª x[i] éƒ½æ˜¯ä¼¯åŠªåˆ©åˆ†å¸ƒçš„éšæœºå˜é‡ X[i] âˆ¼ ä¼¯åŠªåˆ©(p) çš„ä¸€ä¸ªå®ç°ï¼Œä¸”å½¼æ­¤ç‹¬ç«‹ã€‚
- en: As we saw previously when discussing the law of large numbers (TheoremÂ [137](ch032.xhtml#x1-339002r137)),
    one natural idea is to compute the sample mean to estimate p, which is coincidentally
    the expected value of X. To move beyond empirical estimates, letâ€™s leverage that,
    this time, we have a probabilistic model.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬åœ¨è®¨è®ºå¤§æ•°æ³•åˆ™æ—¶æ‰€çœ‹åˆ°çš„ï¼ˆå®šç†Â [137](ch032.xhtml#x1-339002r137)ï¼‰ï¼Œä¸€ä¸ªè‡ªç„¶çš„æƒ³æ³•æ˜¯é€šè¿‡è®¡ç®—æ ·æœ¬å‡å€¼æ¥ä¼°è®¡pï¼Œè€Œè¿™æ°å¥½æ˜¯Xçš„æœŸæœ›å€¼ã€‚ä¸ºäº†è¶…è¶Šç»éªŒä¼°è®¡ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸ªæœºä¼šï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨æœ‰ä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ã€‚
- en: 'The key question is this: which parameter p is the most likely to produce our
    sample?'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: å…³é”®é—®é¢˜æ˜¯ï¼šå“ªä¸ªå‚æ•°pæœ€æœ‰å¯èƒ½ç”Ÿæˆæˆ‘ä»¬çš„æ ·æœ¬ï¼Ÿ
- en: In the language of probability, this question is answered by maximizing the
    likelihood function
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¦‚ç‡çš„è¯­è¨€ä¸­ï¼Œè¿™ä¸ªé—®é¢˜é€šè¿‡æœ€å¤§åŒ–ä¼¼ç„¶å‡½æ•°æ¥å›ç­”
- en: '![ n âˆ LLH (p;x1,...,xn) = P(Xi = xi | p), i=1 ](img/file2036.png)'
  id: totrans-540
  prefs: []
  type: TYPE_IMG
  zh: '![ n âˆ LLH (p;x1,...,xn) = P(Xi = xi | p), i=1 ](img/file2036.png)'
- en: where P(X[i] = x[i]âˆ£p) represents the probability of observing x[i] given a
    fixed parameter p. The larger the LLH(p;x[1],â€¦,x[n]), the more likely the parameter
    p is. In other words, our estimate of p is going to be
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­P(X[i] = x[i]âˆ£p)è¡¨ç¤ºåœ¨å›ºå®šå‚æ•°pä¸‹è§‚å¯Ÿåˆ°x[i]çš„æ¦‚ç‡ã€‚LLH(p;x[1],â€¦,x[n])è¶Šå¤§ï¼Œå‚æ•°pè¶Šæœ‰å¯èƒ½ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬å¯¹pçš„ä¼°è®¡å°†æ˜¯ï¼š
- en: '![Ë†p = argmaxp âˆˆ[0,1]LLH (p;x1,...,xn). ](img/file2037.png)'
  id: totrans-542
  prefs: []
  type: TYPE_IMG
  zh: '![Ë†p = argmaxp âˆˆ[0,1]LLH (p;x1,...,xn). ](img/file2037.png)'
- en: Letâ€™s find it.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥æ±‚è§£å®ƒã€‚
- en: In our concrete case, P(X[i] = x[i]âˆ£p) can be written as
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„å…·ä½“æƒ…å†µä¸‹ï¼ŒP(X[i] = x[i]âˆ£p) å¯ä»¥å†™æˆï¼š
- en: '![ (| {p if xi = 1, P(Xi = xi | p) = | (1 âˆ’ p if xi = 0\. ](img/file2038.png)'
  id: totrans-545
  prefs: []
  type: TYPE_IMG
  zh: '![ (| {p if xi = 1, P(Xi = xi | p) = | (1 âˆ’ p if xi = 0\. ](img/file2038.png)'
- en: Algebra doesnâ€™t welcome if-else type functions, so with a clever mathematical
    trick, we write P(X[i] = x[i]âˆ£p) as
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£æ•°ä¸å–œæ¬¢if-elseç±»å‹çš„å‡½æ•°ï¼Œå› æ­¤ï¼Œé€šè¿‡ä¸€ä¸ªå·§å¦™çš„æ•°å­¦æŠ€å·§ï¼Œæˆ‘ä»¬å°†P(X[i] = x[i]âˆ£p)å†™æˆï¼š
- en: '![ x 1âˆ’x P(Xi = xi | p) = p i(1âˆ’ p ) i, ](img/file2039.png)'
  id: totrans-547
  prefs: []
  type: TYPE_IMG
  zh: '![ x 1âˆ’x P(Xi = xi | p) = p i(1âˆ’ p ) i, ](img/file2039.png)'
- en: making the likelihood function be
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿å¾—ä¼¼ç„¶å‡½æ•°ä¸ºï¼š
- en: '![ âˆn LLH (p;x1,...,xn) = pxi(1 âˆ’ p)1âˆ’xi. i=1 ](img/file2040.png)'
  id: totrans-549
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆn LLH (p;x1,...,xn) = pxi(1 âˆ’ p)1âˆ’xi. i=1 ](img/file2040.png)'
- en: (Weâ€™ll often write LLH(p) to minimize notational complexity.)
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆæˆ‘ä»¬é€šå¸¸ä¼šå†™LLH(p)æ¥ç®€åŒ–ç¬¦å·å¤æ‚æ€§ã€‚ï¼‰
- en: 'This is still not easy to optimize, as it is composed of the product of exponential
    functions. So, hereâ€™s another mathematical trick: take the logarithm to turn the
    product into a sum.'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä»ç„¶ä¸å®¹æ˜“ä¼˜åŒ–ï¼Œå› ä¸ºå®ƒæ˜¯ç”±æŒ‡æ•°å‡½æ•°çš„ä¹˜ç§¯ç»„æˆçš„ã€‚æ‰€ä»¥ï¼Œè¿™é‡Œæœ‰å¦ä¸€ä¸ªæ•°å­¦æŠ€å·§ï¼šå–å¯¹æ•°ï¼Œå°†ä¹˜ç§¯è½¬æ¢ä¸ºå’Œã€‚
- en: 'As the logarithm is increasing, it wonâ€™t change the optima, so weâ€™re good to
    go:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå¯¹æ•°æ˜¯é€’å¢çš„ï¼Œå®ƒä¸ä¼šæ”¹å˜æœ€ä¼˜è§£ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç»§ç»­ï¼š
- en: '![ âˆn log LLH (p) = log pxi(1âˆ’ p )1âˆ’xi i=1 âˆ‘n [ ] = log pxi(1 âˆ’ p)1âˆ’xi i=1
    âˆ‘n [ ] = logpxi + log(1âˆ’ p)1âˆ’xi i=1 âˆ‘n âˆ‘n = logp xi + log(1 âˆ’ p) (1âˆ’ xi). i=1
    i=1 ](img/file2041.png)'
  id: totrans-553
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆn log LLH (p) = log pxi(1âˆ’ p )1âˆ’xi i=1 âˆ‘n [ ] = log pxi(1 âˆ’ p)1âˆ’xi i=1
    âˆ‘n [ ] = logpxi + log(1âˆ’ p)1âˆ’xi i=1 âˆ‘n âˆ‘n = logp xi + log(1 âˆ’ p) (1âˆ’ xi). i=1
    i=1 ](img/file2041.png)'
- en: Trust me, this is much better. According to the second derivative test (TheoremÂ [87](ch021.xhtml#x1-214004r87)),
    we can find the maxima by
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸ä¿¡æˆ‘ï¼Œè¿™æ ·å¥½å¤šäº†ã€‚æ ¹æ®äºŒé˜¶å¯¼æ•°æ£€éªŒï¼ˆå®šç†Â [87](ch021.xhtml#x1-214004r87)ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ï¼š
- en: solving ![ddp](img/file2042.png) log LLH(p) = 0 to find the critical point pÌ‚
    ,
  id: totrans-555
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è§£ ![ddp](img/file2042.png) log LLH(p) = 0 æ¥æ‰¾åˆ°ä¸´ç•Œç‚¹pÌ‚ï¼Œ
- en: then showing that pÌ‚ is a maximum because ![-d2- dp2](img/file2045.png) log
    LLH(p)/span>0.
  id: totrans-556
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åè¯æ˜pÌ‚æ˜¯æœ€å¤§å€¼ï¼Œå› ä¸º ![-d2- dp2](img/file2045.png) log LLH(p)/span>0ã€‚
- en: Letâ€™s get to it.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ã€‚
- en: As ![ddp](img/file2046.png) log p = ![1p](img/file2047.png) and ![ddp-](img/file2048.png)
    log(1 âˆ’p) = âˆ’![11âˆ’p](img/file2049.png), we have
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº ![ddp](img/file2046.png) log p = ![1p](img/file2047.png) å’Œ ![ddp-](img/file2048.png)
    log(1 âˆ’p) = âˆ’![11âˆ’p](img/file2049.png)ï¼Œæˆ‘ä»¬æœ‰ï¼š
- en: '![d 1 âˆ‘n 1 âˆ‘n --logLLH (p;x1,...,xn) = -- xi âˆ’ ----- (1âˆ’ xi). dp p i=1 1âˆ’ p
    i=1 ](img/file2050.png)'
  id: totrans-559
  prefs: []
  type: TYPE_IMG
  zh: '![d 1 âˆ‘n 1 âˆ‘n --logLLH (p;x1,...,xn) = -- xi âˆ’ ----- (1âˆ’ xi). dp p i=1 1âˆ’ p
    i=1 ](img/file2050.png)'
- en: Solving ![ddp](img/file2051.png) log LLH(p;x[1],â€¦,x[n]) = 0 yields a single
    solution
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: è§£ ![ddp](img/file2051.png) log LLH(p;x[1],â€¦,x[n]) = 0 å¾—åˆ°ä¸€ä¸ªè§£
- en: '![ 1 âˆ‘n Ë†p = -- xi. n i=1 ](img/file2052.png)'
  id: totrans-561
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 âˆ‘n Ë†p = -- xi. n i=1 ](img/file2052.png)'
- en: (Pick up a pen and paper and calculate the solution yourself.) Regarding the
    second derivative, we have
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆæ‹¿èµ·ä¸€æ”¯ç¬”å’Œçº¸ï¼Œè‡ªå·±è®¡ç®—ä¸€ä¸‹ç­”æ¡ˆã€‚ï¼‰å…³äºäºŒé˜¶å¯¼æ•°ï¼Œæˆ‘ä»¬æœ‰ï¼š
- en: '![d2 1 âˆ‘n 1 âˆ‘n --2 logLLH (p) = âˆ’ -2 xi âˆ’-------2 (1âˆ’ xi), dp p i=1 (1 âˆ’ p)
    i=1 ](img/file2053.png)'
  id: totrans-563
  prefs: []
  type: TYPE_IMG
  zh: '![d2 1 âˆ‘n 1 âˆ‘n --2 logLLH (p) = âˆ’ -2 xi âˆ’-------2 (1âˆ’ xi), dp p i=1 (1 âˆ’ p)
    i=1 ](img/file2053.png)'
- en: which is uniformly negative. Thus, pÌ‚ = ![1n](img/file2055.png) âˆ‘ [i=1]^nx[i]
    is indeed a (local) maximum. Yay!
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯å‡åŒ€è´Ÿçš„ã€‚å› æ­¤ï¼ŒpÌ‚ = ![1n](img/file2055.png) âˆ‘ [i=1]^nx[i] ç¡®å®æ˜¯ä¸€ä¸ªï¼ˆå±€éƒ¨ï¼‰æœ€å¤§å€¼ã€‚è€¶ï¼
- en: 'In this case, the maximum likelihood estimate is identical to the sample mean.
    Trust me, this is one of the rare exceptions. Think of it as validating the sample
    mean: weâ€™ve obtained the same estimate through different trains of thought, so
    it must be good.'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡ä¸æ ·æœ¬å‡å€¼ç›¸åŒã€‚ç›¸ä¿¡æˆ‘ï¼Œè¿™æ˜¯ä¸€ä¸ªç½•è§çš„ä¾‹å¤–ã€‚æŠŠå®ƒçœ‹ä½œæ˜¯å¯¹æ ·æœ¬å‡å€¼çš„éªŒè¯ï¼šæˆ‘ä»¬é€šè¿‡ä¸åŒçš„æ€è·¯è·å¾—äº†ç›¸åŒçš„ä¼°è®¡å€¼ï¼Œæ‰€ä»¥å®ƒä¸€å®šæ˜¯æ­£ç¡®çš„ã€‚
- en: 20.7.2 Modeling heights
  id: totrans-566
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.7.2 å»ºæ¨¡é«˜åº¦
- en: Letâ€™s continue with another example. The coin-tossing example demonstrated the
    discrete case. Itâ€™s time to move into the continuous domain!
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»§ç»­è¿›è¡Œå¦ä¸€ä¸ªä¾‹å­ã€‚æŠ›ç¡¬å¸çš„ä¾‹å­å±•ç¤ºäº†ç¦»æ•£æƒ…å†µã€‚ç°åœ¨æ˜¯è¿›å…¥è¿ç»­é¢†åŸŸçš„æ—¶å€™äº†ï¼
- en: This time, we are measuring the heights of a high school class, and we want
    to build a probabilistic model of it. A natural idea is to assume the heights
    to come from a normal distribution X âˆ¼ğ’©(Î¼,ÏƒÂ²). (Check SectionÂ [19.3.6](ch031.xhtml#the-normal-distribution)
    for the normal distribution.)
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬æ­£åœ¨æµ‹é‡ä¸€ä¸ªé«˜ä¸­ç­çº§çš„èº«é«˜ï¼Œå¹¶å¸Œæœ›å»ºç«‹ä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ã€‚ä¸€ä¸ªè‡ªç„¶çš„æƒ³æ³•æ˜¯å‡è®¾èº«é«˜æ¥è‡ªäºæ­£æ€åˆ†å¸ƒ X âˆ¼ğ’©(Î¼,ÏƒÂ²)ã€‚ ï¼ˆæŸ¥çœ‹ç¬¬ [19.3.6](ch031.xhtml#the-normal-distribution)
    èŠ‚äº†è§£æ­£æ€åˆ†å¸ƒã€‚ï¼‰
- en: Our job is to estimate the expected value Î¼ and the variance ÏƒÂ². Letâ€™s go, maximum
    likelihood!
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„å·¥ä½œæ˜¯ä¼°è®¡æœŸæœ›å€¼ Î¼ å’Œæ–¹å·® ÏƒÂ²ã€‚æ¥å§ï¼Œæœ€å¤§ä¼¼ç„¶ï¼
- en: 'To make the problem mathematically precise, we have the measurements x[1],â€¦,x[n],
    coming from independent and identically distributed random variables X[i] âˆ¼ğ’©(Î¼,ÏƒÂ²).
    However, thereâ€™s a snag: as our random variables are continuous,'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿é—®é¢˜åœ¨æ•°å­¦ä¸Šç²¾ç¡®ï¼Œæˆ‘ä»¬æœ‰æµ‹é‡å€¼ x[1],â€¦,x[n]ï¼Œå®ƒä»¬æ¥è‡ªç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡ X[i] âˆ¼ğ’©(Î¼,ÏƒÂ²)ã€‚ç„¶è€Œï¼Œå‡ºç°äº†ä¸€ä¸ªé—®é¢˜ï¼šå› ä¸ºæˆ‘ä»¬çš„éšæœºå˜é‡æ˜¯è¿ç»­çš„ï¼Œ
- en: '![ âˆn P (X1 = x1,...,Xn = xn | Î¼, Ïƒ2) = P (Xi = xi | Î¼, Ïƒ2) = 0\. i=1 ](img/file2056.png)'
  id: totrans-571
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆn P (X1 = x1,...,Xn = xn | Î¼, Ïƒ2) = P (Xi = xi | Î¼, Ïƒ2) = 0\. i=1 ](img/file2056.png)'
- en: '(As all terms of the product are zero.) How can we define the likelihood function,
    then? No worries: even though we donâ€™t have a mass function, we have density!
    Thus, the likelihood function defined by'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆå› ä¸ºæ‰€æœ‰é¡¹çš„ä¹˜ç§¯ä¸ºé›¶ã€‚ï¼‰é‚£ä¹ˆæˆ‘ä»¬è¯¥å¦‚ä½•å®šä¹‰ä¼¼ç„¶å‡½æ•°å‘¢ï¼Ÿåˆ«æ‹…å¿ƒï¼šè™½ç„¶æˆ‘ä»¬æ²¡æœ‰è´¨é‡å‡½æ•°ï¼Œä½†æˆ‘ä»¬æœ‰å¯†åº¦ï¼å› æ­¤ï¼Œç”±ä»¥ä¸‹å®šä¹‰ä¼¼ç„¶å‡½æ•°ï¼š
- en: '![ âˆn LLH (Î¼, Ïƒ;x1,...,xn) = fX (xi) i=1 i n 2 = âˆ -âˆš1--eâˆ’ (xi2âˆ’ÏƒÎ¼2), i=1 Ïƒ
    2Ï€ ](img/file2057.png)'
  id: totrans-573
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆn LLH (Î¼, Ïƒ;x1,...,xn) = fX (xi) i=1 i n 2 = âˆ -âˆš1--eâˆ’ (xi2âˆ’ÏƒÎ¼2), i=1 Ïƒ
    2Ï€ ](img/file2057.png)'
- en: where f[X[i]](x) is the probability density function of X[i].
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ f[X[i]](x) æ˜¯ X[i] çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚
- en: 'Letâ€™s maximize it. The idea is similar: take the logarithm, find the critical
    points, then use the second derivative test. Here we go:'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥æœ€å¤§åŒ–å®ƒã€‚æ€è·¯æ˜¯ç±»ä¼¼çš„ï¼šå–å¯¹æ•°ï¼Œæ‰¾åˆ°ä¸´ç•Œç‚¹ï¼Œç„¶åä½¿ç”¨äºŒé˜¶å¯¼æ•°æ£€éªŒã€‚å¼€å§‹å§ï¼š
- en: '![ 1 1 âˆ‘n 2 log LLH (Î¼,Ïƒ) = nlog -âˆš----âˆ’ Ïƒ2- (xi âˆ’ Î¼) . Ïƒ 2Ï€ i=1 ](img/file2058.png)'
  id: totrans-576
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 1 âˆ‘n 2 log LLH (Î¼,Ïƒ) = nlog -âˆš----âˆ’ Ïƒ2- (xi âˆ’ Î¼) . Ïƒ 2Ï€ i=1 ](img/file2058.png)'
- en: Just the usual business from now on. The derivatives are given by
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ç°åœ¨èµ·ï¼Œç…§å¸¸è¿›è¡Œã€‚å¯¼æ•°å¦‚ä¸‹ï¼š
- en: '![ âˆ‘n âˆ‚--log LLH (Î¼,Ïƒ) = -2- (xi âˆ’ Î¼), âˆ‚Î¼ Ïƒ2 i=1 âˆ‘n âˆ‚--log LLH (Î¼,Ïƒ) = âˆ’ n-âˆ’
    -2- (xi âˆ’ Î¼)2\. âˆ‚Ïƒ Ïƒ Ïƒ3 i=1 ](img/file2059.png)'
  id: totrans-578
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘n âˆ‚--log LLH (Î¼,Ïƒ) = -2- (xi âˆ’ Î¼), âˆ‚Î¼ Ïƒ2 i=1 âˆ‘n âˆ‚--log LLH (Î¼,Ïƒ) = âˆ’ n-âˆ’
    -2- (xi âˆ’ Î¼)2\. âˆ‚Ïƒ Ïƒ Ïƒ3 i=1 ](img/file2059.png)'
- en: With a bit of number-crunching (that you should attempt to carry out by yourself),
    we get that âˆ‚Î¼ log LLH(Î¼,Ïƒ) = 0 implies
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä¸€ç‚¹æ•°å­—è¿ç®—ï¼ˆä½ åº”è¯¥å°è¯•è‡ªå·±å®Œæˆï¼‰ï¼Œæˆ‘ä»¬å¾—åˆ° âˆ‚Î¼ log LLH(Î¼,Ïƒ) = 0 è¿™æ„å‘³ç€
- en: '![ -1âˆ‘n Î¼ = n xi, i=1 ](img/file2061.png)'
  id: totrans-580
  prefs: []
  type: TYPE_IMG
  zh: '![ -1âˆ‘n Î¼ = n xi, i=1 ](img/file2061.png)'
- en: and ![-âˆ‚ âˆ‚Ïƒ](img/file2062.png) log LLH(Î¼,Ïƒ) implies
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œ ![-âˆ‚ âˆ‚Ïƒ](img/file2062.png) log LLH(Î¼,Ïƒ) è¿™æ„å‘³ç€
- en: '![ âˆ‘n Ïƒ = -1 (xi âˆ’ Î¼ )2\. n i=1 ](img/file2063.png)'
  id: totrans-582
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘n Ïƒ = -1 (xi âˆ’ Î¼ )2\. n i=1 ](img/file2063.png)'
- en: 'We wonâ€™t do the second derivative test here, but trust me: itâ€™s a maximum,
    leaving us with the estimates'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿™é‡Œä¸åšäºŒé˜¶å¯¼æ•°æ£€éªŒï¼Œä½†ç›¸ä¿¡æˆ‘ï¼šè¿™æ˜¯ä¸€ä¸ªæœ€å¤§å€¼ï¼Œç»“æœç»™å‡ºæˆ‘ä»¬ä¼°è®¡å€¼
- en: '![ n Ë†Î¼ = -1âˆ‘ x, n i=1 i n Ë†Ïƒ = -1âˆ‘ (x âˆ’ Î¼Ë†)2\. n i i=1 ](img/file2064.png)'
  id: totrans-584
  prefs: []
  type: TYPE_IMG
  zh: '![ n Ë†Î¼ = -1âˆ‘ x, n i=1 i n Ë†Ïƒ = -1âˆ‘ (x âˆ’ Î¼Ë†)2\. n i i=1 ](img/file2064.png)'
- en: 'Again, the sample mean and variance. Think of it this way: defaulting to the
    sample mean and variance is the simplest thing to do, yet even clever methods
    like the maximum likelihood estimation yield them as parameter estimates.'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡æåˆ°ï¼Œæ ·æœ¬å‡å€¼å’Œæ–¹å·®ã€‚å¯ä»¥è¿™æ ·ç†è§£ï¼šé»˜è®¤ä½¿ç”¨æ ·æœ¬å‡å€¼å’Œæ–¹å·®æ˜¯æœ€ç®€å•çš„æ–¹æ³•ï¼Œä½†å³ä¾¿æ˜¯åƒæœ€å¤§ä¼¼ç„¶ä¼°è®¡è¿™æ ·èªæ˜çš„æ–¹æ³•ï¼Œä¹Ÿä¼šæŠŠå®ƒä»¬ä½œä¸ºå‚æ•°ä¼°è®¡å€¼ã€‚
- en: After working out the above two examples in detail, we are ready to abstract
    away the details and introduce the general problem.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¯¦ç»†è§£ç­”ä¸Šè¿°ä¸¤ä¸ªä¾‹å­åï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½æŠ½è±¡æ‰ç»†èŠ‚ï¼Œå¼•å…¥ä¸€èˆ¬é—®é¢˜ã€‚
- en: 20.7.3 The general method
  id: totrans-587
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.7.3 ä¸€èˆ¬æ–¹æ³•
- en: Weâ€™ve seen how maximum likelihood estimation works. Now, itâ€™s time to construct
    the abstract mathematical framework.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»çœ‹è¿‡æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„å·¥ä½œåŸç†ã€‚ç°åœ¨ï¼Œæ˜¯æ—¶å€™æ„å»ºæŠ½è±¡çš„æ•°å­¦æ¡†æ¶äº†ã€‚
- en: Definition 99\. (The likelihood function)
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰99.ï¼ˆä¼¼ç„¶å‡½æ•°ï¼‰
- en: Let P[ğœƒ] be a probability distribution parametrized by the parameter ğœƒ âˆˆâ„^k,
    and let x[1],â€¦,x[n] âˆˆ â„^d be an independent realization of the probability distribution.
    (That is, the samples are coming from independent and identically distributed
    random variables X[1],â€¦,X[n], distributed according to P[ğœƒ].)
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾P[ğœƒ]æ˜¯ç”±å‚æ•°ğœƒ âˆˆâ„^kå‚æ•°åŒ–çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä¸”x[1],â€¦,x[n] âˆˆ â„^dæ˜¯è¯¥æ¦‚ç‡åˆ†å¸ƒçš„ç‹¬ç«‹å®ç°ã€‚ï¼ˆå³æ ·æœ¬æ¥è‡ªç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡X[1],â€¦,X[n]ï¼Œå…¶åˆ†å¸ƒç”±P[ğœƒ]ç»™å‡ºã€‚ï¼‰
- en: The likelihood function of ğœƒ given the sample x[1],â€¦,x[n] is defined by
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å®šæ ·æœ¬x[1],â€¦,x[n]ï¼Œğœƒçš„ä¼¼ç„¶å‡½æ•°å®šä¹‰ä¸ºï¼š
- en: (a)
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![ âˆn LLH (ğœƒ;x1,...,xn) := P ğœƒ(Xi = xi) i=1 ](img/file2065.png)'
  id: totrans-593
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆn LLH (ğœƒ;x1,...,xn) := P ğœƒ(Xi = xi) i=1 ](img/file2065.png)'
- en: if P[ğœƒ] is discrete, and
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœP[ğœƒ]æ˜¯ç¦»æ•£çš„ï¼Œå¹¶ä¸”
- en: (b)
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![ âˆn LLH (ğœƒ;x1,...,xn) := fğœƒ(xi) i=1 ](img/file2066.png)'
  id: totrans-596
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆn LLH (ğœƒ;x1,...,xn) := fğœƒ(xi) i=1 ](img/file2066.png)'
- en: if P[ğœƒ] is continuous, where f[ğœƒ] is the probability density function of P[ğœƒ].
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœP[ğœƒ]æ˜¯è¿ç»­çš„ï¼Œå…¶ä¸­f[ğœƒ]æ˜¯P[ğœƒ]çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚
- en: 'Weâ€™ve already seen two examples of the likelihood function: for the Bernoulli-distribution
    Bernoulli(p), given by'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†ä¸¤ä¸ªä¼¼ç„¶å‡½æ•°çš„ç¤ºä¾‹ï¼šå¯¹äºä¼¯åŠªåˆ©åˆ†å¸ƒBernoulli(p)ï¼Œç»™å®šï¼š
- en: '![ âˆn LLH (p;x1,...,xn) = pxi(1 âˆ’ p)1âˆ’xi, i=1 ](img/file2067.png)'
  id: totrans-599
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆn LLH (p;x1,...,xn) = pxi(1 âˆ’ p)1âˆ’xi, i=1 ](img/file2067.png)'
- en: and for the normal distribution ğ’©(Î¼,Ïƒ), given by
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ­£æ€åˆ†å¸ƒğ’©(Î¼,Ïƒ)ï¼Œç»™å®šï¼š
- en: '![ n 2 LLH (Î¼, Ïƒ;x ,...,x ) = âˆ -âˆš1--eâˆ’ (xi2âˆ’ÏƒÎ¼2). 1 n i=1 Ïƒ 2Ï€ ](img/file2068.png)'
  id: totrans-601
  prefs: []
  type: TYPE_IMG
  zh: '![ n 2 LLH (Î¼, Ïƒ;x ,...,x ) = âˆ -âˆš1--eâˆ’ (xi2âˆ’ÏƒÎ¼2). 1 n i=1 Ïƒ 2Ï€ ](img/file2068.png)'
- en: Intuitively, the likelihood function LLH(ğœƒ;x[1],â€¦,x[n]) expresses the probability
    of our observation x[1],â€¦,x[n] if the parameter ğœƒ is indeed true. The maximum
    likelihood estimate is the parameter ![Ë†ğœƒ](img/file2069.png) that maximizes this
    probability; that is, under which the observation is the most likely.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ç›´è§‚ä¸Šè®²ï¼Œä¼¼ç„¶å‡½æ•°LLH(ğœƒ;x[1],â€¦,x[n])è¡¨ç¤ºå½“å‚æ•°ğœƒä¸ºçœŸæ—¶ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°çš„x[1],â€¦,x[n]çš„æ¦‚ç‡ã€‚æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ˜¯é€šè¿‡æœ€å¤§åŒ–æ­¤æ¦‚ç‡å¾—åˆ°çš„å‚æ•°![Ë†ğœƒ](img/file2069.png)ï¼›å³åœ¨è¿™ä¸ªå‚æ•°ä¸‹ï¼Œè§‚å¯Ÿç»“æœæœ€å¯èƒ½å‘ç”Ÿã€‚
- en: Definition 100\. (The maximum likelihood estimate)
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰100. ï¼ˆæœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼‰
- en: Let P[ğœƒ] be a probability distribution parametrized by the parameter ğœƒ âˆˆâ„^k,
    and let x[1],â€¦,x[n] âˆˆ â„^d be an independent realization of the probability distribution.
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾P[ğœƒ]æ˜¯ç”±å‚æ•°ğœƒ âˆˆâ„^kå‚æ•°åŒ–çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä¸”x[1],â€¦,x[n] âˆˆ â„^dæ˜¯è¯¥æ¦‚ç‡åˆ†å¸ƒçš„ç‹¬ç«‹å®ç°ã€‚
- en: The maximum likelihood estimate of ğœƒ is given by
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: ğœƒçš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡ç”±ä»¥ä¸‹å…¬å¼ç»™å‡ºï¼š
- en: '![Ë†ğœƒ = argmax ğœƒâˆˆâ„kLLH (ğœƒ;x1,...,xn ). ](img/file2070.png)'
  id: totrans-606
  prefs: []
  type: TYPE_IMG
  zh: '![Ë†ğœƒ = argmax ğœƒâˆˆâ„kLLH (ğœƒ;x1,...,xn ). ](img/file2070.png)'
- en: In both examples, we used the logarithm to turn the product into a sum. Use
    it once and itâ€™s a trick; use it (at least) twice and itâ€™s a method. Hereâ€™s the
    formal definition.
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸¤ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¯¹æ•°è¿ç®—å°†ä¹˜ç§¯è½¬åŒ–ä¸ºå’Œã€‚ç”¨ä¸€æ¬¡æ˜¯æŠ€å·§ï¼›ç”¨ï¼ˆè‡³å°‘ï¼‰ä¸¤æ¬¡å°±æ˜¯æ–¹æ³•ã€‚è¿™æ˜¯æ­£å¼å®šä¹‰ã€‚
- en: Definition 101\. (The log-likelihood function)
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰101. ï¼ˆå¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼‰
- en: Let P[ğœƒ] be a probability distribution parametrized by the parameter ğœƒ âˆˆâ„^k,
    and let x[1],â€¦,x[n] âˆˆ â„^d be an independent realization of the probability distribution.
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾P[ğœƒ]æ˜¯ç”±å‚æ•°ğœƒ âˆˆâ„^kå‚æ•°åŒ–çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä¸”x[1],â€¦,x[n] âˆˆ â„^dæ˜¯è¯¥æ¦‚ç‡åˆ†å¸ƒçš„ç‹¬ç«‹å®ç°ã€‚
- en: The log-likelihood function of ğœƒ given the sample x[1],â€¦,x[n] is defined by
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å®šæ ·æœ¬x[1],â€¦,x[n]ï¼Œğœƒçš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°å®šä¹‰ä¸ºï¼š
- en: '![logLLH (ğœƒ;x1,...,xn), ](img/file2071.png)'
  id: totrans-611
  prefs: []
  type: TYPE_IMG
  zh: '![logLLH (ğœƒ;x1,...,xn), ](img/file2071.png)'
- en: where LLH(ğœƒ;x[1],â€¦,x[n]) is the likelihood function.
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­LLH(ğœƒ;x[1],â€¦,x[n])æ˜¯ä¼¼ç„¶å‡½æ•°ã€‚
- en: In a classical statistical setting, the maximum likelihood estimation is done
    via
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»å…¸ç»Ÿè®¡å­¦ä¸­ï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡æ˜¯é€šè¿‡ä»¥ä¸‹æ–¹æ³•è¿›è¡Œçš„ï¼š
- en: pulling a parametric probabilistic model out from the mathematicianâ€™s hat,
  id: totrans-614
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»æ•°å­¦å®¶çš„å¸½å­é‡ŒæŠ½å‡ºä¸€ä¸ªå‚æ•°åŒ–çš„æ¦‚ç‡æ¨¡å‹ï¼Œ
- en: massaging the (log-)likelihood function until we obtain an analytically manageable
    form,
  id: totrans-615
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡è°ƒæ•´ï¼ˆå¯¹æ•°ï¼‰ä¼¼ç„¶å‡½æ•°ç›´åˆ°è·å¾—ä¸€ä¸ªè§£æä¸Šå¯å¤„ç†çš„å½¢å¼ï¼Œ
- en: and solving âˆ‡LLH = 0 (or âˆ‡log LLH = 0) to obtain the parameter estimate.
  id: totrans-616
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡æ±‚è§£âˆ‡LLH = 0ï¼ˆæˆ–âˆ‡log LLH = 0ï¼‰æ¥è·å¾—å‚æ•°ä¼°è®¡ã€‚
- en: 'Statistics can be extremely powerful under specific circumstances, but letâ€™s
    face it: the above method has quite a few weaknesses. First, constructing a tractable
    probabilistic model is a challenging task, burdened by the expertsâ€™ inherent bias.
    (Itâ€™s no accident that I indirectly compared the modeling process to pulling a
    rabbit out of a hat.) Moreover, the more complex the model, the more complex the
    likelihood function is. Which, in turn, increases the complexity of our optimization
    problem.'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡å­¦åœ¨ç‰¹å®šæƒ…å†µä¸‹å¯ä»¥éå¸¸å¼ºå¤§ï¼Œä½†æˆ‘ä»¬å¾—é¢å¯¹ç°å®ï¼šä¸Šè¿°æ–¹æ³•æœ‰ä¸å°‘ç¼ºç‚¹ã€‚é¦–å…ˆï¼Œæ„å»ºä¸€ä¸ªå¯å¤„ç†çš„æ¦‚ç‡æ¨¡å‹æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¸”å®¹æ˜“å—åˆ°ä¸“å®¶å›ºæœ‰åè§çš„å½±å“ã€‚ï¼ˆæˆ‘å°†å»ºæ¨¡è¿‡ç¨‹é—´æ¥åœ°æ¯”ä½œä»å¸½å­é‡ŒæŠ½å‡ºä¸€åªå…”å­ï¼Œç»éå¶ç„¶ã€‚ï¼‰æ­¤å¤–ï¼Œæ¨¡å‹è¶Šå¤æ‚ï¼Œä¼¼ç„¶å‡½æ•°ä¹Ÿè¶Šå¤æ‚ã€‚è¿™åè¿‡æ¥å¢åŠ äº†æˆ‘ä»¬ä¼˜åŒ–é—®é¢˜çš„å¤æ‚åº¦ã€‚
- en: Why did we spend quite a few pages learning this ancient technique, then?
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£æˆ‘ä»¬ä¸ºä»€ä¹ˆè¦èŠ±è¿™ä¹ˆå¤šé¡µæ¥å­¦ä¹ è¿™ç§å¤è€çš„æŠ€å·§å‘¢ï¼Ÿ
- en: Because its idea is fundamental in machine learning, weâ€™ll arrive at (somewhere
    near the) state of the art by breaking down its barriers one by one. Is modeling
    hard? Letâ€™s construct a function with BILLIONS of parameters thatâ€™ll do the job.
    Is optimization computationally intensive? Fear not. We have clusters of GPUs
    at our disposal.
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºè¿™ä¸ªæ€æƒ³åœ¨æœºå™¨å­¦ä¹ ä¸­è‡³å…³é‡è¦ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸€æ­¥æ­¥çªç ´å®ƒçš„éšœç¢ï¼Œæœ€ç»ˆè¾¾åˆ°ï¼ˆæˆ–æ¥è¿‘ï¼‰æœ€å…ˆè¿›çš„æ°´å¹³ã€‚å»ºæ¨¡éš¾å—ï¼Ÿæˆ‘ä»¬æ¥æ„é€ ä¸€ä¸ªæ‹¥æœ‰æ•°åäº¿å‚æ•°çš„å‡½æ•°æ¥å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚ä¼˜åŒ–è®¡ç®—å¯†é›†å—ï¼Ÿä¸ç”¨æ‹…å¿ƒï¼Œæˆ‘ä»¬æœ‰é›†ç¾¤çš„GPUå¯ä»¥ä½¿ç”¨ã€‚
- en: 20.7.4 The German tank problem
  id: totrans-620
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.7.4 å¾·å›½å¦å…‹é—®é¢˜
- en: One more example before finishing up, straight from World War II. Imagine you
    are an Allied intelligence officer tasked to estimate the size of a German armored
    division. (That is, to guess the number of tanks.)
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: å†ä¸¾ä¸€ä¸ªä¾‹å­ï¼Œæ¥è‡ªäºŒæˆ˜æ—¶æœŸã€‚å‡è®¾ä½ æ˜¯ä¸€ä¸ªç›Ÿå†›æƒ…æŠ¥å®˜å‘˜ï¼Œè´Ÿè´£ä¼°ç®—å¾·å†›è£…ç”²å¸ˆçš„è§„æ¨¡ã€‚ï¼ˆä¹Ÿå°±æ˜¯ï¼ŒçŒœæµ‹å¦å…‹çš„æ•°é‡ã€‚ï¼‰
- en: 'There was no satellite imagery back in the day, so thereâ€™s only a little to
    go on, except for a tiny piece of information: the serial numbers of the enemyâ€™s
    destroyed tanks. What can we do with these?'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£æ—¶å€™æ²¡æœ‰å«æ˜Ÿå›¾åƒå¯ä¾›å‚è€ƒï¼Œå› æ­¤é™¤äº†ä¸€ä¸ªå°å°çš„ä¿¡æ¯æ¥æºâ€”â€”æ•Œæ–¹æ‘§æ¯å¦å…‹çš„åºåˆ—å·ï¼Œæˆ‘ä»¬å‡ ä¹æ²¡æœ‰å…¶ä»–å¯ä»¥ä¾èµ–çš„èµ„æ–™ã€‚æˆ‘ä»¬èƒ½ä»è¿™äº›ä¿¡æ¯ä¸­åšäº›ä»€ä¹ˆå‘¢ï¼Ÿ
- en: Without detailed knowledge of the manufacturing process, we can assume that
    the tanks are labeled sequentially as they roll out from the factory. We also
    donâ€™t know how the tanks are distributed between the battlefields.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ²¡æœ‰è¯¦ç»†äº†è§£åˆ¶é€ è¿‡ç¨‹çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å‡è®¾è¿™äº›å¦å…‹åœ¨å‡ºå‚æ—¶æŒ‰é¡ºåºç¼–å·ã€‚æˆ‘ä»¬ä¹Ÿä¸çŸ¥é“è¿™äº›å¦å…‹æ˜¯å¦‚ä½•åœ¨æˆ˜åœºä¹‹é—´åˆ†é…çš„ã€‚
- en: 'These two pieces of knowledge (or lack of knowledge, to be more precise) translate
    to a simple probabilistic model: encountering an enemy tank is the same as drawing
    from the distribution Uniform(N), where N is the total number of tanks. Thus,
    if x[1],â€¦,x[n] are the serial numbers of destroyed tanks, we can use the maximum
    likelihood method to estimate N.'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸¤å—çŸ¥è¯†ï¼ˆæˆ–è€…æ›´ç²¾ç¡®åœ°è¯´ï¼Œç¼ºä¹çŸ¥è¯†ï¼‰è½¬åŒ–ä¸ºä¸€ä¸ªç®€å•çš„æ¦‚ç‡æ¨¡å‹ï¼šé‡åˆ°æ•Œæ–¹å¦å…‹å°±åƒä»å‡åŒ€åˆ†å¸ƒUniform(N)ä¸­æŠ½å–æ ·æœ¬ï¼Œå…¶ä¸­Næ˜¯å¦å…‹çš„æ€»æ•°ã€‚å› æ­¤ï¼Œå¦‚æœx[1],â€¦,x[n]æ˜¯æ‘§æ¯å¦å…‹çš„åºåˆ—å·ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æœ€å¤§ä¼¼ç„¶æ³•æ¥ä¼°è®¡Nã€‚
- en: Letâ€™s do it. The likelihood function for the discrete uniform distribution Uniform(N)
    is given by
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ã€‚ç¦»æ•£å‡åŒ€åˆ†å¸ƒUniform(N)çš„ä¼¼ç„¶å‡½æ•°ç”±ä»¥ä¸‹å…¬å¼ç»™å‡ºï¼š
- en: '![ âˆn LLH (N ) = P (Xi = xi), i=1 ](img/file2072.png)'
  id: totrans-626
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆn LLH (N ) = P (Xi = xi), i=1 ](img/file2072.png)'
- en: 'where the probability P(X[i] = x[i]) has a quite peculiar form:'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œæ¦‚ç‡P(X[i] = x[i])æœ‰ä¸€ä¸ªç›¸å½“ç‹¬ç‰¹çš„å½¢å¼ï¼š
- en: '![ ( |{ -1 P (X = x ) = N if xi âˆˆ {1,...,N }, i i |( 0 otherwise. ](img/file2073.png)'
  id: totrans-628
  prefs: []
  type: TYPE_IMG
  zh: '![ ( |{ -1 P (X = x ) = N if xi âˆˆ {1,...,N }, i i |( 0 otherwise. ](img/file2073.png)'
- en: Keeping in mind that x[1],â€¦,x[n] â‰¤N (as no observed serial number can be larger
    than the total number of tanks), we have
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ï¼Œx[1],â€¦,x[n] â‰¤Nï¼ˆå› ä¸ºæ²¡æœ‰è§‚å¯Ÿåˆ°çš„åºåˆ—å·ä¼šå¤§äºå¦å…‹çš„æ€»æ•°ï¼‰ï¼Œæˆ‘ä»¬æœ‰
- en: '![ ( |{ -1- LLH (N ) = Nn if N <max {x1,...,xn}, |( 0 otherwise. ](img/file2074.png)'
  id: totrans-630
  prefs: []
  type: TYPE_IMG
  zh: '![ ( |{ -1- LLH (N ) = Nn if N <max {x1,...,xn}, |( 0 otherwise. ](img/file2074.png)'
- en: 'Ponder on this a minute: the larger the N, the smaller the LLH(N) is. Thus,
    the maximum likelihood estimate is the smallest possible choice'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³ä¸€æƒ³ï¼šNè¶Šå¤§ï¼ŒLLH(N)å°±è¶Šå°ã€‚å› æ­¤ï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡æ˜¯æœ€å°çš„å¯èƒ½é€‰æ‹©ã€‚
- en: '![NË†= max {x1,...,xn }. ](img/file2075.png)'
  id: totrans-632
  prefs: []
  type: TYPE_IMG
  zh: '![NË†= max {x1,...,xn }. ](img/file2075.png)'
- en: In other words, our guess about the number of tanks is the largest serial number
    weâ€™ve encountered.
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬å¯¹å¦å…‹æ•°é‡çš„çŒœæµ‹å°±æ˜¯æˆ‘ä»¬é‡åˆ°çš„æœ€å¤§åºåˆ—å·ã€‚
- en: What do you think about this estimate? I wonâ€™t lie; I am not a big fan. The
    German tank problem highlights the importance of modeling assumptions in statistics.
    The final estimate ![Ë†N](img/file2076.png) is the outcome of our choice of Uniform(N).
    Common wisdom in machine learning is â€œgarbage in, garbage out.â€ It is true for
    modeling as well.
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æ€ä¹ˆçœ‹è¿™ä¸ªä¼°è®¡ï¼Ÿæˆ‘ä¸éª—ä½ ï¼Œæˆ‘è‡ªå·±å¹¶ä¸ç‰¹åˆ«å–œæ¬¢ã€‚å¾·å›½å¦å…‹é—®é¢˜å‡¸æ˜¾äº†å»ºæ¨¡å‡è®¾åœ¨ç»Ÿè®¡å­¦ä¸­çš„é‡è¦æ€§ã€‚æœ€ç»ˆçš„ä¼°è®¡![Ë†N](img/file2076.png)æ˜¯æˆ‘ä»¬é€‰æ‹©Uniform(N)çš„ç»“æœã€‚æœºå™¨å­¦ä¹ ä¸­çš„å¸¸è§æ™ºæ…§æ˜¯â€œåƒåœ¾è¿›ï¼Œåƒåœ¾å‡ºâ€ã€‚å»ºæ¨¡ä¹Ÿæ˜¯å¦‚æ­¤ã€‚
- en: 20.8 Summary
  id: totrans-635
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.8 å°ç»“
- en: In this chapter, we have learned about the concept of the expected value. Mathematically
    speaking, the expected value is defined by
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬äº†è§£äº†æœŸæœ›å€¼çš„æ¦‚å¿µã€‚ä»æ•°å­¦ä¸Šè®²ï¼ŒæœŸæœ›å€¼çš„å®šä¹‰æ˜¯
- en: '![ âˆ‘ ğ”¼[X ] = xkP (X = xk) k ](img/file2077.png)'
  id: totrans-637
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘ ğ”¼[X ] = xkP (X = xk) k ](img/file2077.png)'
- en: for discrete random variables and
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¦»æ•£éšæœºå˜é‡å’Œ
- en: '![ âˆ« âˆ ğ”¼[X ] = xfX(x)dx âˆ’âˆ ](img/file2078.png)'
  id: totrans-639
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ« âˆ ğ”¼[X ] = xfX(x)dx âˆ’âˆ ](img/file2078.png)'
- en: 'for continuous ones. Although these formulas involve possibly infinite sums
    and integrals, the underlying meaning is simple: ğ”¼[X] represents the average outcome
    of X, weighted by the underlying probability distribution.'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿ç»­å‹éšæœºå˜é‡ã€‚è¿™äº›å…¬å¼è™½ç„¶å¯èƒ½æ¶‰åŠæ— é™å’Œä¸ç§¯åˆ†ï¼Œä½†å…¶åŸºæœ¬å«ä¹‰å¾ˆç®€å•ï¼šğ”¼[X] ä»£è¡¨ X çš„å¹³å‡ç»“æœï¼ŒæŒ‰å…¶åº•å±‚æ¦‚ç‡åˆ†å¸ƒåŠ æƒã€‚
- en: 'According to the law of large numbers, the expected value also describes a
    long-term average: if the independent and identically distributed random variables
    X[1],X[2],â€¦ describe the outcomes of a repeated experiment â€” say, betting a hand
    in poker â€” then the sample average converges to the joint expected value, that
    is,'
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®å¤§æ•°æ³•åˆ™ï¼ŒæœŸæœ›å€¼ä¹Ÿæè¿°äº†ä¸€ä¸ªé•¿æœŸçš„å¹³å‡å€¼ï¼šå¦‚æœç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡ X[1], X[2], â€¦ æè¿°äº†ä¸€ä¸ªé‡å¤å®éªŒçš„ç»“æœâ€”â€”æ¯”å¦‚è¯´ï¼Œåœ¨æ‰‘å…‹ä¸­ä¸‹æ³¨â€”â€”é‚£ä¹ˆæ ·æœ¬å¹³å‡å€¼å°†æ”¶æ•›åˆ°è”åˆæœŸæœ›å€¼ï¼Œå³ï¼Œ
- en: '![ 1 âˆ‘n lim -- Xi = ğ”¼[X1 ] nâ†’ âˆ n i=1 ](img/file2079.png)'
  id: totrans-642
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 âˆ‘n lim -- Xi = ğ”¼[X1 ] nâ†’ âˆ n i=1 ](img/file2079.png)'
- en: holds with probability 1\. In a sense, the law of large numbers allows you to
    glimpse into the future and see what happens if you make the same choice. In the
    case of poker, if you only make bets with a positive expected value, youâ€™ll win
    in the long run.
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥æ¦‚ç‡ 1 æˆç«‹ã€‚ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œå¤§æ•°æ³•åˆ™è®©ä½ èƒ½å¤Ÿç¥è§æœªæ¥ï¼Œçœ‹çœ‹å¦‚æœä½ åšå‡ºç›¸åŒçš„é€‰æ‹©ä¼šå‘ç”Ÿä»€ä¹ˆã€‚åœ¨æ‰‘å…‹æ¸¸æˆä¸­ï¼Œå¦‚æœä½ åªåšæœŸæœ›å€¼ä¸ºæ­£çš„ä¸‹æ³¨ï¼Œé•¿æœŸä¸‹æ¥ä½ å°†ä¼šèµ¢ã€‚
- en: In machine learning, the LLN also plays an essential role. Check out the mean-squared
    error
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼ŒLLN åŒæ ·èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚æŸ¥çœ‹å‡æ–¹è¯¯å·®
- en: '![ -1âˆ‘n 2 n MSE (x,y ) = n (f(xi)âˆ’ yi) , x,y âˆˆ â„ i=1 ](img/file2080.png)'
  id: totrans-645
  prefs: []
  type: TYPE_IMG
  zh: '![ -1âˆ‘n 2 n MSE (x,y ) = n (f(xi)âˆ’ yi) , x,y âˆˆ â„ i=1 ](img/file2080.png)'
- en: once more. If the number of samples (n) is in the millions, computing the gradient
    of this sum is not feasible. However, the mean-squared error is the sample average
    of the prediction errors; thus, itâ€™s enough to sample a smaller amount. This is
    the core principle behind stochastic gradients, an idea that makes machine learning
    on a large scale feasible.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒã€‚å¦‚æœæ ·æœ¬æ•°é‡ï¼ˆnï¼‰è¾¾åˆ°ç™¾ä¸‡çº§ï¼Œè®¡ç®—è¿™ä¸ªæ€»å’Œçš„æ¢¯åº¦å°±å˜å¾—ä¸å¯è¡Œã€‚ç„¶è€Œï¼Œå‡æ–¹è¯¯å·®æ˜¯é¢„æµ‹è¯¯å·®çš„æ ·æœ¬å¹³å‡å€¼ï¼›å› æ­¤ï¼Œé‡‡æ ·è¾ƒå°‘çš„æ ·æœ¬å°±è¶³å¤Ÿäº†ã€‚è¿™å°±æ˜¯éšæœºæ¢¯åº¦çš„æ ¸å¿ƒåŸç†ï¼Œå®ƒä½¿å¾—å¤§è§„æ¨¡æœºå™¨å­¦ä¹ å˜å¾—å¯è¡Œã€‚
- en: 'With this chapter, our journey comes to a close. Still, thereâ€™s so much to
    learn; I could probably write this book until the end of time. Sadly, we have
    to stop somewhere. Now, instead of giving a summary of all thatâ€™s in the book,
    letâ€™s talk about the most important message: learning never ends.'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« ç»“æŸäº†æˆ‘ä»¬çš„æ—…ç¨‹ã€‚ç„¶è€Œï¼Œè¿˜æœ‰å¾ˆå¤šä¸œè¥¿å¯ä»¥å­¦ä¹ ï¼›æˆ‘å¯èƒ½ä¼šä¸€ç›´å†™è¿™æœ¬ä¹¦ï¼Œç›´åˆ°æ—¶é—´çš„å°½å¤´ã€‚ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘ä»¬å¿…é¡»åœ¨æŸä¸ªåœ°æ–¹åœä¸‹ã€‚ç°åœ¨ï¼Œä¸å…¶æ€»ç»“ä¹¦ä¸­çš„æ‰€æœ‰å†…å®¹ï¼Œä¸å¦‚è°ˆè°ˆæœ€é‡è¦çš„ä¿¡æ¯ï¼šå­¦ä¹ æ°¸æ— æ­¢å¢ƒã€‚
- en: Itâ€™s a spiral that you continue to ascend, meeting familiar landscapes from
    higher and higher vantage points. If you keep going, youâ€™ll know what Iâ€™m talking
    about.
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªèºæ—‹å¼ä¸Šå‡çš„è¿‡ç¨‹ï¼Œä½ ä¸æ–­ä»æ›´é«˜çš„è§†è§’é‡è§ç†Ÿæ‚‰çš„æ™¯è±¡ã€‚å¦‚æœä½ ç»§ç»­å‰è¡Œï¼Œä½ ä¼šæ˜ç™½æˆ‘åœ¨è¯´ä»€ä¹ˆã€‚
- en: If you lead an intellectually challenging life, youâ€™ll also find that knowledge
    is like keeping a dozen leaky cups full of water. If your focus shifts from one,
    itâ€™ll empty faster than you think. In other words, youâ€™ll lose it if you donâ€™t
    use it. This is completely normal. The good news is, if you already have a good
    foundation, refilling the cup can be done quickly. Sometimes, simply glancing
    at a page from a book you read long ago can do the trick.
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¿‡ç€å……æ»¡æ™ºåŠ›æŒ‘æˆ˜çš„ç”Ÿæ´»ï¼Œä½ ä¹Ÿä¼šå‘ç°çŸ¥è¯†å°±åƒæ˜¯ä¿æŒä¸€æ‰“æ¼æ°´çš„æ¯å­æ»¡æ»¡çš„æ°´ã€‚å¦‚æœä½ çš„æ³¨æ„åŠ›ä»å…¶ä¸­ä¸€ä¸ªæ¯å­ç§»å¼€ï¼Œå®ƒä¼šæ¯”ä½ æƒ³è±¡çš„æ›´å¿«åœ°ç©ºæ‰ã€‚æ¢å¥è¯è¯´ï¼Œå¦‚æœä½ ä¸ä½¿ç”¨å®ƒï¼Œä½ ä¼šå¤±å»å®ƒã€‚è¿™æ˜¯å®Œå…¨æ­£å¸¸çš„ã€‚å¥½æ¶ˆæ¯æ˜¯ï¼Œå¦‚æœä½ å·²ç»æ‰“ä¸‹äº†åšå®çš„åŸºç¡€ï¼Œé‡æ–°å¡«å……æ¯å­æ˜¯å¾ˆå¿«å°±èƒ½åšåˆ°çš„ã€‚æœ‰æ—¶ï¼Œåªæ˜¯å¿«é€Ÿæµè§ˆä¸€ä¸‹ä½ å¾ˆä¹…ä»¥å‰è¯»è¿‡çš„ä¸€æœ¬ä¹¦çš„é¡µé¢å°±èƒ½è§£å†³é—®é¢˜ã€‚
- en: This is how I know that itâ€™s not goodbye. If you have found the book useful
    and continue down the rabbit hole that is machine learning, weâ€™ll meet again with
    probability one. You just have to keep going.
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘çŸ¥é“è¿™ä¸æ˜¯å‘Šåˆ«çš„åŸå› ã€‚å¦‚æœä½ è§‰å¾—è¿™æœ¬ä¹¦æœ‰ç”¨ï¼Œå¹¶ç»§ç»­æ·±å…¥æœºå™¨å­¦ä¹ çš„ä¸–ç•Œï¼Œæˆ‘ä»¬å°†ä»¥æ¦‚ç‡ 1 å†æ¬¡ç›¸é‡ã€‚ä½ åªéœ€è¦ç»§ç»­å‰è¡Œã€‚
- en: 20.9 Problems
  id: totrans-651
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.9 é—®é¢˜
- en: 'Problem 1\. Let X,Y : Î© â†’â„ be two random variables.'
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 'é—®é¢˜ 1\. è®¾ X,Y : Î© â†’â„ ä¸ºä¸¤ä¸ªéšæœºå˜é‡ã€‚'
- en: (a) Show that if X â‰¥ 0, then ğ”¼[X] â‰¥ 0.
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: (a) è¯æ˜å¦‚æœ X â‰¥ 0ï¼Œé‚£ä¹ˆ ğ”¼[X] â‰¥ 0ã€‚
- en: (b) Show that if X â‰¥Y , then ğ”¼[X] â‰¥ğ”¼[Y ].
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: (b) è¯æ˜å¦‚æœ X â‰¥ Yï¼Œé‚£ä¹ˆ ğ”¼[X] â‰¥ ğ”¼[Y]ã€‚
- en: 'Problem 2\. Let X : Î© â†’â„ be a random variable. Show that if Var[X] = 0, then
    X assumes only a single value. (That is, the set X(Î©) = {X(Ï‰) : Ï‰ âˆˆ Î©} has only
    a single element.)'
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 'é—®é¢˜ 2\. è®¾ X : Î© â†’â„ ä¸ºä¸€ä¸ªéšæœºå˜é‡ã€‚è¯æ˜å¦‚æœ Var[X] = 0ï¼Œé‚£ä¹ˆ X ä»…å–ä¸€ä¸ªå€¼ã€‚ï¼ˆå³ï¼ŒX(Î©) = {X(Ï‰) : Ï‰ âˆˆ
    Î©} åªæœ‰ä¸€ä¸ªå…ƒç´ ã€‚ï¼‰'
- en: Problem 3\. Let X âˆ¼ Geo(p) be a geometrically distributed (SectionÂ [19.2.3](ch031.xhtml#the-geometric-distribution))
    discrete random variable. Show that
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜ 3\. è®¾ X âˆ¼ Geo(p) ä¸ºä¸€ä¸ªå‡ ä½•åˆ†å¸ƒï¼ˆè§[19.2.3èŠ‚](ch031.xhtml#the-geometric-distribution)ï¼‰çš„ç¦»æ•£å‹éšæœºå˜é‡ã€‚è¯æ˜ï¼š
- en: '![H [X] = âˆ’ plogp-+-(1âˆ’-p)log(1âˆ’-p)-. p ](img/file2081.png)'
  id: totrans-657
  prefs: []
  type: TYPE_IMG
  zh: '![H [X] = âˆ’ plogp-+-(1âˆ’-p)log(1âˆ’-p)-. p ](img/file2081.png)'
- en: 'Hint: Use that for any q âˆˆ (0,1), âˆ‘ [k=1]^âˆkq^(kâˆ’1) = (1 âˆ’q)^(âˆ’2).'
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºï¼šå¯¹äºä»»æ„ q âˆˆ (0,1)ï¼Œâˆ‘ [k=1]^âˆ kq^(kâˆ’1) = (1 âˆ’ q)^(âˆ’2)ã€‚
- en: Problem 4\. Let X âˆ¼ exp(Î») be an exponentially distributed continuous random
    variable. Show that
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜ 4ï¼šè®¾ X âˆ¼ exp(Î») ä¸ºä¸€ä¸ªæŒ‡æ•°åˆ†å¸ƒçš„è¿ç»­éšæœºå˜é‡ã€‚è¯æ˜
- en: '![h [X ] = 1 âˆ’ logÎ». ](img/file2082.png)'
  id: totrans-660
  prefs: []
  type: TYPE_IMG
  zh: '![h [X ] = 1 âˆ’ logÎ». ](img/file2082.png)'
- en: Problem 5\. Find the maximum likelihood estimation for the Î» parameter of the
    exponential distribution.
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜ 5ï¼šæ±‚æŒ‡æ•°åˆ†å¸ƒçš„ Î» å‚æ•°çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡ã€‚
- en: Join our community on Discord
  id: totrans-662
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ å…¥æˆ‘ä»¬çš„ Discord ç¤¾åŒº
- en: Read this book alongside other users, Machine Learning experts, and the author
    himself. Ask questions, provide solutions to other readers, chat with the author
    via Ask Me Anything sessions, and much more. Scan the QR code or visit the link
    to join the community. [https://packt.link/math](https://packt.link/math)
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶ä»–ç”¨æˆ·ã€æœºå™¨å­¦ä¹ ä¸“å®¶ä»¥åŠä½œè€…æœ¬äººä¸€èµ·é˜…è¯»æœ¬ä¹¦ã€‚æå‡ºé—®é¢˜ï¼Œä¸ºå…¶ä»–è¯»è€…æä¾›è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡â€œé—®æˆ‘ä»»ä½•é—®é¢˜â€ç¯èŠ‚ä¸ä½œè€…èŠå¤©ï¼Œç­‰ç­‰ã€‚æ‰«æäºŒç»´ç æˆ–è®¿é—®é“¾æ¥åŠ å…¥ç¤¾åŒºã€‚[https://packt.link/math](https://packt.link/math)
- en: '![PIC](img/file1.png)'
  id: totrans-664
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1.png)'
