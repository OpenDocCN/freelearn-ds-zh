- en: Apache Spark GraphX
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark GraphX
- en: In this chapter, we want to examine the Apache Spark GraphX module and graph
    processing, in general. So, this chapter will cover the topic of implementing
    graph analysis workflows on top of GraphX. The *GraphX coding* section, written
    in Scala, will provide a series of graph coding examples. Before writing code
    in Scala to use the Spark GraphX module, we think it will be useful to provide
    an overview of what a graph actually is in terms of graph processing. The following
    section provides a brief introduction using a couple of simple graphs as examples.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们希望探讨Apache Spark GraphX模块和图处理的一般性。因此，本章将涵盖在GraphX之上实现图分析工作流程的主题。*GraphX编码*部分，用Scala编写，将提供一系列图编码示例。在用Scala编写代码以使用Spark
    GraphX模块之前，我们认为提供关于图处理中图实际是什么的概述将是有用的。以下部分使用几个简单图作为示例，提供了一个简短的介绍。
- en: 'In this chapter we will cover:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Creating a graph from raw data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从原始数据创建图
- en: Counting
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计数
- en: Filtering
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤
- en: PageRank
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PageRank
- en: Triangle count
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三角形计数
- en: Connected components
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连通组件
- en: Overview
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: A graph can be considered to be a data structure that consists of a group of
    vertices and edges connecting them. The vertices or nodes in the graph can be
    anything as long it is an object (so people for example), and the edges are the
    relationships between them. The edges can be un-directional or directional, meaning
    that the relationship operates from one node to another. For instance, node **A**
    is the parent of node **B**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图可以被视为一种数据结构，由一组顶点和连接它们的边组成。图中的顶点或节点可以是任何对象（例如人），而边则是它们之间的关系。边可以是无向的或有向的，意味着关系从一个节点操作到另一个节点。例如，节点**A**是节点**B**的父母。
- en: 'In the following diagram, the circles represent the vertices or nodes (**A**
    to **D**), while the thick lines represent the edges or relationships between
    them (**E1** to **E6**). Each node or edge may have properties, and these values
    are represented by the associated gray squares (**P1** to **P7**):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图中，圆圈代表顶点或节点（**A**至**D**），而粗线代表它们之间的边或关系（**E1**至**E6**）。每个节点或边可能具有属性，这些值由相关的灰色方块表示（**P1**至**P7**）：
- en: So, if a graph represents a physical ...
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果一个图代表了一个物理...
- en: Graph analytics/processing with GraphX
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GraphX进行图分析/处理
- en: This section will examine Apache Spark GraphX programming in Scala using the
    family relationship graph data sample shown in the last section. This data will
    be accessed as a list of vertices and edges. Although this data set is small,
    the graphs that you build in this way could be very large. For example, we've
    been able to analyze 30 TB of financial transaction data of a large bank using
    only four Apache Spark workers.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将探讨使用上一节中展示的家庭关系图数据样本，在Scala中进行Apache Spark GraphX编程。此数据将被访问为一组顶点和边。尽管此数据集较小，但通过这种方式构建的图可能非常庞大。例如，我们仅使用四个Apache
    Spark工作者就能够分析一家大型银行的30 TB金融交易数据。
- en: The raw data
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始数据
- en: 'We are working with two data files. They contain the data that will be used
    for this section in terms of the vertices and edges that make up a graph:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在处理两个数据文件。它们包含将用于本节的顶点和边数据，这些数据构成了一个图：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `vertex` file contains just six lines representing the graph used in the
    last section. Each `vertex` represents a person and has a vertex ID number, a
    name, and an age value:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`顶点`文件仅包含六行，代表上一节中使用的图。每个`顶点`代表一个人，并具有顶点ID号、姓名和年龄值：'
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `edge` file contains a set of directed `edge` values in the form source
    vertex ID, destination vertex ID, and relationship. So, record 1 forms a `Sister`
    relationship between `Flo` and `Mike`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`边`文件包含一组有向`边`值，形式为源顶点ID、目标顶点ID和关系。因此，记录1在`Flo`和`Mike`之间形成了一个`姐妹`关系：'
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Lets, examine some ...
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们，检查一些...
- en: Creating a graph
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建图
- en: This section will explain generic Scala code up to the point of creating a GraphX
    graph from data. This will save time as the same code is reused in each example.
    Once this is explained, we will concentrate on the actual graph-based manipulation
    in each code example.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释通用Scala代码，直到从数据创建GraphX图。这将节省时间，因为相同的代码在每个示例中都被重复使用。一旦解释完毕，我们将专注于每个代码示例中的实际基于图的操作。
- en: 'The generic code starts by importing Spark context, GraphX, and RDD functionality
    for use in the Scala code:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通用代码首先导入Spark上下文、GraphX和RDD功能，以便在Scala代码中使用：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then an application is defined, which `extends` the `App` class. The application
    name changes for each example from `graph1` to `graph5`. This application name
    will be used when running the application using `spark-submit`:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后定义一个应用程序，它`扩展`了`App`类。应用程序名称从`graph1`到`graph5`每个示例都会更改。运行应用程序时将使用此应用程序名称`spark-submit`：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As already mentioned, there are two data files that contain `vertex` and `edge`
    information:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，有两个数据文件包含`顶点`和`边`信息：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The **Spark Master URL** is defined as the application name, which will appear
    in the Spark user interface when the application runs. A new Spark configuration
    object is created, and the URL and name are assigned to it:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Spark主URL**定义为应用程序名称，该名称将在应用程序运行时出现在Spark用户界面中。创建一个新的Spark配置对象，并将URL和名称分配给它：'
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'A new Spark context is created using the configuration that was just defined:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用刚刚定义的配置创建一个新的Spark上下文：
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `vertex` information from the file is then loaded into an RDD-based structure
    called vertices using the `sparkCxt.textFile` method. The data is stored as a
    Long `VertexId` and strings to represent the person''s name and age. The data
    lines are split by commas as this is CSV-based data:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用`sparkCxt.textFile`方法将文件中的`顶点`信息加载到称为顶点的RDD基础结构中。数据存储为长`VertexId`和字符串，以表示人的姓名和年龄。数据行按逗号分割，因为这是基于CSV的数据：
- en: '[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Similarly, the `edge` data is loaded into an RDD-based data structure called
    edges. The CSV-based data is again split by comma values. The first two data values
    are converted to long values as they represent the source and destination vertex
    IDs. The final value representing the relationship of the edge is left as `String`.
    Note that each record in the RDD structure edges is actually now an `Edge` record:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，`边`数据加载到称为边的RDD基础数据结构中。基于CSV的数据再次按逗号值分割。前两个数据值转换为长值，因为它们表示源和目标顶点ID。最后代表边关系的值保持为`字符串`。请注意，RDD结构边中的每个记录实际上现在是一个`Edge`记录：
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'A default value is defined in case a connection or `vertex` is missing; the
    graph is then constructed from the RDD-based structures vertices and edges and
    the `default` record:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果缺少连接或`顶点`，则定义默认值；然后从基于RDD的结构顶点和边以及`默认`记录构建图：
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This creates a GraphX-based structure called `graph`, which can now be used
    for each of the examples. Remember that, although these data samples might be
    small, you could create extremely large graphs using this approach.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这创建了一个基于GraphX的结构，称为`图`，现在可以用于每个示例。请记住，尽管这些数据样本可能很小，但您可以使用这种方法创建非常大的图。
- en: Many of these algorithms are iterative applications, for instance, PageRank
    and triangle count. As a result, the programs will generate many iterative Spark
    jobs.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法中的许多都是迭代应用，例如PageRank和三角计数。因此，程序将生成许多迭代的Spark作业。
- en: Example 1 – counting
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例1 – 计数
- en: 'The graph has been loaded, and we know the data volumes in the data files.
    But what about the data content in terms of vertices and edges in the actual graph
    itself? It is very simple to extract this information using the vertices and edges
    `count` function shown as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图已加载，我们知道数据文件中的数据量。但在实际图中，顶点和边的数据内容是什么？使用以下所示的顶点和边`计数`函数提取此信息非常简单：
- en: '[PRE11]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Running the `graph1` example using the example name and the `.jar` file created
    earlier will provide the `count` information. The master URL is supplied to connect
    to the Spark cluster, and some default parameters are supplied for the executor
    memory and total executor cores:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`graph1`示例，使用先前创建的`.jar`文件和示例名称，将提供`计数`信息。主URL用于连接到Spark集群，并为执行器内存和总执行器核心提供一些默认参数：
- en: '[PRE12]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Example 2 – filtering
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例2 – 过滤
- en: 'What happens if we need to create a subgraph from the main graph and filter
    on person age or relationships? The example code from the second example Scala
    file `graph2` shows how this can be done:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要从主图中创建一个子图，并根据人物年龄或关系进行过滤，会发生什么？第二个示例Scala文件`graph2`中的示例代码展示了如何实现这一点：
- en: '[PRE13]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Two example counts have been created from the main graph: the first filters
    person-based vertices on age only, taking those people who are greater than forty
    years old. Notice that the `age` value, which was stored as a string, has been
    converted to a long for the comparison.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 已经从主图创建了两个示例计数：第一个仅根据年龄过滤基于人的顶点，选取那些年龄大于四十岁的人。请注意，存储为字符串的`年龄`值已转换为长整型以进行比较。
- en: 'The second example filters the edges on the relationship property of `Mother`
    or `Father`. Two count values `c1` and `c2` are created and printed as the Spark
    run output, shown as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个示例根据`Mother`或`Father`的关系属性过滤边。创建并打印了两个计数值`c1`和`c2`，作为Spark运行输出，如下所示：
- en: '[PRE14]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Example 3 – PageRank
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例3 – PageRank
- en: The PageRank algorithm provides a ranking value for each of the vertices in
    a graph. It makes the assumption that the vertices that are connected to the most
    edges are the most important.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: PageRank算法为图中的每个顶点提供一个排名值。它假设连接到最多边的顶点是最重要的。
- en: 'Search engines use PageRank to provide an ordering for page display during
    a web search as can be seen from the following code:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎使用PageRank为网页搜索期间的页面显示提供排序，如下面的代码所示：
- en: '[PRE15]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The example code creates a tolerance value and calls the graph `pageRank` method
    using it. The vertices are then ranked into a new value ranking. In order to make
    the ranking more meaningful, the ranking values are joined with the original ...
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 示例代码创建了一个容差值，并使用它调用图的`pageRank`方法。然后，顶点被排名到一个新的值排名中。为了使排名更有意义，排名值与原始值进行了连接...
- en: Example 4 – triangle counting
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例4 – 三角形计数
- en: The triangle count algorithm provides a vertex-based count of the number of
    triangles associated with that vertex. For instance, vertex `Mike` (1) is connected
    to `Kate` (5), who is connected to `Sarah` (2), `Sarah` is connected to `Mike`
    (1), and so a triangle is formed. This can be useful for route finding where triangle
    free minimum spanning tree graphs need to be generated for route planning.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 三角形计数算法提供了一个基于顶点的与该顶点相关的三角形数量的计数。例如，顶点`Mike` (1) 连接到`Kate` (5)，`Kate` 连接到`Sarah`
    (2)，`Sarah` 连接到`Mike` (1)，从而形成一个三角形。这在需要生成无三角形的最小生成树图进行路线规划时可能很有用。
- en: 'The code to execute a triangle count and print it is simple as shown next.
    The graph `triangleCount` method is executed for the graph vertices. The result
    is saved in the value `tCount` and printed:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 执行三角形计数并打印它的代码很简单，如下所示。对图的顶点执行`triangleCount`方法。结果保存在值`tCount`中并打印出来：
- en: '[PRE16]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The results of the application job show that vertices `Flo` (4) and `Jim` (6)
    have no triangles, while `Mike` (1) and `Sarah` (2) have the most as expected,
    as they have the most relationships:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序作业的结果显示，顶点`Flo` (4) 和`Jim` (6) 没有三角形，而`Mike` (1) 和`Sarah` (2) 如预期那样拥有最多，因为他们有最多的关系：
- en: '[PRE17]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Example 5 – connected components
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例5 – 连通组件
- en: When a large graph is created from data, it might contain unconnected subgraphs
    or subgraphs that are isolated from each other and might contain no bridging or
    connecting edges between them. These algorithms provide a measure of that connectivity.
    It might be important depending on your processing to know that all vertices are
    connected.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当从数据中创建一个大图时，它可能包含不相连的子图或彼此隔离的子图，并且可能不包含它们之间的桥接或连接边。这些算法提供了一种连接性的度量。根据你的处理需求，了解所有顶点是否连接可能很重要。
- en: 'The Scala code for this example calls two graph methods, `connectedComponents`
    and `stronglyConnectedComponents`. The `strong` method required a maximum iteration
    count, which has been set to `1000`. These counts are acting on the graph vertices:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的Scala代码调用了两个图方法，`connectedComponents`和`stronglyConnectedComponents`。`strong`方法需要一个最大迭代计数，已设置为`1000`。这些计数作用于图的顶点：
- en: '[PRE18]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Summary
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter showed by example how Scala-based code can be used to call GraphX
    algorithms in Apache Spark. Scala has been used because it requires less code
    to develop the examples than Java, which saves time. Note that GraphX is not available
    for Python or R. A Scala-based shell can be used, and the code can be compiled
    into Spark applications.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 本章通过示例展示了如何使用基于Scala的代码调用Apache Spark中的GraphX算法。使用Scala是因为它比Java需要更少的代码来开发示例，从而节省时间。请注意，GraphX不适用于Python或R。可以使用基于Scala的shell，并且代码可以编译成Spark应用程序。
- en: The most common graph algorithms have been covered and you should have an idea
    now on how to solve any graph problem with GraphX. Especially since you've understood
    that a Graph in GraphX is still represented and backed by RDDs, so you are already
    familiar with using them. The configuration and code examples from this chapter
    will also be available for download with the book.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 已经介绍了最常见的图算法，你现在应该知道如何使用GraphX解决任何图问题。特别是，既然你已经理解了GraphX中的图仍然由RDD表示和支持，那么你已经熟悉使用它们了。本章的配置和代码示例也将随书提供下载。
