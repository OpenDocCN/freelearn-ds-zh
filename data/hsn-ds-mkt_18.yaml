- en: What's Next?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接下来会是什么？
- en: We have come a long way. We started this book with the basics of data science
    and its applications in marketing and worked through numerous use cases of data
    science in marketing. Along the way, we have conducted descriptive analysis, where
    we used data science techniques to analyze and visualize data to identify patterns.
    We have also conducted explanatory analysis, where we used machine learning models
    to draw insights from data, such as finding the drivers behind certain customers'
    activities and the correlations between customer attributes and their actions.
    Lastly, we have also looked at predictive analytics, where we trained various
    machine learning algorithms to make forecasts on certain actions of customers.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经走了很长一段路。我们从数据科学的基础知识及其在营销中的应用开始，逐步探讨了数据科学在营销中的众多使用案例。在此过程中，我们进行了描述性分析，利用数据科学技术分析和可视化数据，以识别模式。我们还进行了解释性分析，使用机器学习模型从数据中得出洞察，例如找出某些客户活动背后的驱动因素，以及客户属性与其行为之间的关联。最后，我们还探讨了预测性分析，通过训练各种机器学习算法，预测客户的某些行为。
- en: The topics we have covered throughout this book are not trivial and were geared
    toward the practical usage of data science in marketing. Each chapter was meant
    to showcase how you can use data science and machine learning techniques in actual
    marketing use cases and guide you through how you might be able to apply the concepts
    discussed to your specific business cases. As the field of marketing analytics
    is growing and broadening its reach, we wanted to use this chapter to inform you
    of some potential challenges you might face and look at some other commonly used
    technologies, as well as review the topics that we have discussed in this book.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中所涉及的主题并非琐碎，它们都针对数据科学在营销中的实际应用而设计。每一章的目的都是展示如何在实际的营销用例中运用数据科学和机器学习技术，并指导你如何将讨论过的概念应用到你特定的商业案例中。随着营销分析领域的不断发展和拓展，我们希望通过这一章让你了解一些可能面临的挑战，并介绍一些常用的技术，同时回顾我们在本书中讨论的内容。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将涵盖以下主题：
- en: Recap of the topics covered in this book
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书所涵盖主题的回顾
- en: Real-life data science challenges
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现实生活中的数据科学挑战
- en: More machine learning models and packages
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多的机器学习模型和软件包
- en: Recap of the topics covered in this book
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书所涵盖主题的回顾
- en: We have covered a large amount of material from the beginning of this book,
    from discussing the trends in marketing and how data science and machine learning
    have become a crucial part in building marketing strategies, to building various
    predictive machine learning models for more efficient marketing. It is worth reviewing
    what we have covered so far and refreshing our memory before we close this book.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本书从一开始就涵盖了大量的内容，包括讨论营销趋势、数据科学和机器学习如何成为构建营销策略的关键组成部分，以及建立各种预测性机器学习模型以实现更高效的营销。在结束本书之前，回顾一下我们已经覆盖的内容并刷新记忆是很有价值的。
- en: Trends in marketing
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 营销趋势
- en: As you may recall, the first thing we discussed in [Chapter 1](c169428b-e0db-4624-896c-24316e9b29cc.xhtml),
    *Data Science and Marketing*, was the recent trends in marketing. It is important
    to try to understand and keep up with the trends that are occurring in the industry
    that you are working and specializing in. Especially in marketing, there is a
    lot of demand for more data-driven and quantitative marketing, and for the use
    of the latest and most intelligent technologies for developing more cost-effective
    marketing strategies.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能还记得的那样，我们在[第1章](c169428b-e0db-4624-896c-24316e9b29cc.xhtml)《数据科学与营销》中讨论的第一件事是营销的最新趋势。理解并跟上你所在行业中正在发生的趋势非常重要，尤其是在营销领域，对数据驱动的定量营销的需求非常大，而且还需要利用最新、最智能的技术来开发更具成本效益的营销策略。
- en: 'According to the February, 2018, CMO survey ([https://www.forbes.com/sites/christinemoorman/2018/02/27/marketing-analytics-and-marketing-technology-trends-to-watch/#4ec8a8431b8a](https://www.forbes.com/sites/christinemoorman/2018/02/27/marketing-analytics-and-marketing-technology-trends-to-watch/#4ec8a8431b8a)),
    reliance on marketing analytics has gone up from 30% to 42% in the past 5 years.
    The three main trends in marketing that can be easily observed are the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 根据2018年2月的首席营销官（CMO）调查（[https://www.forbes.com/sites/christinemoorman/2018/02/27/marketing-analytics-and-marketing-technology-trends-to-watch/#4ec8a8431b8a](https://www.forbes.com/sites/christinemoorman/2018/02/27/marketing-analytics-and-marketing-technology-trends-to-watch/#4ec8a8431b8a)），在过去的五年里，营销分析的依赖度从30%上升到了42%。可以很容易观察到的三个主要营销趋势如下：
- en: '**Rising importance of digital marketing**: Lots of marketing activities are
    now happening more heavily on digital channels, such as search engines, social
    media, email, and websites, rather than on more traditional mass media, such as
    TV, radio, and banners at bus stations. As various digital marketing channels
    are gaining popularity as the choice of marketing channel, it has become more
    important to have a good understanding of how audience targeting works on social
    networks, such as Facebook and Instagram, or how to place advertisements on search
    engines and video streaming services, such as Google and YouTube.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数字营销日益重要**：如今，许多营销活动更倾向于通过数字渠道进行，例如搜索引擎、社交媒体、电子邮件和网站，而不再局限于传统的大众媒体，如电视、广播和公交车站的广告牌。随着各种数字营销渠道作为营销选择越来越受欢迎，了解如何在社交网络上进行受众定向（例如Facebook和Instagram），或如何在搜索引擎和视频流媒体服务（如Google和YouTube）上投放广告变得尤为重要。'
- en: '**Marketing analytics**: Marketing analytics is a way of monitoring and quantifying
    the results and performances of past marketing efforts. In [Chapter 2](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml), *Key
    Performance Indicators and Visualizations*, we learned about various **key performance
    indicators** (**KPIs**) that we can use to track and quantify the returns from
    various marketing efforts. Marketing analytics does not just stop at analyzing
    KPIs. It can also be applied to product and customer analytics, which we discussed
    in [Chapter 5](73a716c6-6a84-4785-b04e-87651d0a29d1.xhtml), *Product Analytics*, and
    [Chapter 7](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml), *Exploratory Analysis
    for Customer Behavior*.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**营销分析**：营销分析是一种监控和量化过去营销活动结果和表现的方式。在[第2章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)，*关键绩效指标和可视化*中，我们了解了各种**关键绩效指标**（**KPI**），可以用来跟踪和量化不同营销活动的回报。营销分析不仅仅局限于分析KPI，它还可以应用于产品和客户分析，这些我们在[第5章](73a716c6-6a84-4785-b04e-87651d0a29d1.xhtml)，*产品分析*，和[第7章](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml)，*客户行为的探索性分析*中都有讨论。'
- en: '**Personalized and target marketing**: As the accessibility of data science
    and machine learning has become easier, another trend in marketing has arisen:
    individual-level targeted marketing. Using predictive analytics, we can now predict
    what types of products that individual customers would like, which we have discussed
    in [Chapter 6](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml), *Recommending the
    Right Products*. We have also seen how we can target those customers who are likely
    to churn by building predictive machine learning models in [Chapter 11](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml),
    *Retaining Customers*. As targeted marketing results in higher ROI, there are
    many **software-as-a-Service** (**SaaS**) companies, such as Sailthru and Oracle,
    that provide platforms for personalized and target marketing.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化和精准营销**：随着数据科学和机器学习的可访问性变得更加容易，另一个营销趋势应运而生：面向个人的精准营销。通过使用预测分析，我们现在可以预测出单个客户可能喜欢哪些类型的产品，这一点我们在[第6章](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml)，*推荐合适的产品*中已经讨论过。我们还看到，如何通过构建预测机器学习模型来针对那些可能流失的客户，这一点在[第11章](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml)，*留住客户*中有详细阐述。由于精准营销能够带来更高的投资回报率（ROI），因此有许多**软件即服务**（**SaaS**）公司，例如Sailthru和Oracle，提供个性化和精准营销的平台。'
- en: As new strategies and technologies are developed, trends are destined to change.
    The trends that we have discussed in this book might not be applicable in 20-30
    years, time. As a marketing professional, it is critical to follow and understand
    what others in the same industry do and what other approaches or technologies
    are being developed and used to achieve higher ROI.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着新策略和技术的发展，趋势注定会发生变化。我们在本书中讨论的趋势可能在20-30年后不再适用。作为一名营销专业人士，跟踪并了解同行的做法，以及正在开发和使用的其他方法或技术以实现更高的投资回报率（ROI）是至关重要的。
- en: Data science workflow
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学工作流
- en: 'As a marketing professional or an aspiring data scientist in marketing, it
    can be challenging to figure out where to start for a data science project. In
    [Chapter 1](c169428b-e0db-4624-896c-24316e9b29cc.xhtml), *Data Science and Marketing*,
    we have discussed a typical workflow for a data science project. It is worth reviewing
    the steps before you embark on your future marketing data science projects. You
    should be familiar with the following workflow diagram:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名营销专业人士或有志于成为营销领域数据科学家的你，可能会发现很难知道从哪里开始进行数据科学项目。在[第1章](c169428b-e0db-4624-896c-24316e9b29cc.xhtml)《数据科学与营销》中，我们讨论了一个典型的数据科学项目工作流。在开始未来的营销数据科学项目之前，回顾一下这些步骤是非常有意义的。你应该熟悉以下工作流图：
- en: '![](img/c76e5d08-c952-4db3-bd8a-7321b80ba75d.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c76e5d08-c952-4db3-bd8a-7321b80ba75d.png)'
- en: 'Let''s talk a bit more in detail about these six steps:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地讨论这六个步骤：
- en: '**Problem definition**: Any data science and machine learning project should
    have a clear problem definition. You will need to have an in-depth understanding
    of the problem itself, the scope of the project, and approaches to coming up with
    solutions. This is where you brainstorm what types of analyses and data science
    techniques to use.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**问题定义**：任何数据科学和机器学习项目都应该有一个明确的问题定义。你需要深入理解问题本身、项目的范围以及解决方案的思路。这时你需要集思广益，决定使用哪些分析方法和数据科学技术。'
- en: '**Data collection**: As it is for any data science project, having data is
    key for success. In this step, you will need to gather all the required data for
    your data science project. It is common that you will need to implement data collection
    processes for internal data, purchase third-party data, or scrape data from different
    websites. Depending on the cases, the data collection step can be trivial or it
    can also be tedious.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据收集**：对于任何数据科学项目来说，拥有数据是成功的关键。在这个步骤中，你需要收集所有所需的数据以供数据科学项目使用。通常，你可能需要为内部数据实现数据收集流程，购买第三方数据，或者从不同的网站抓取数据。根据情况的不同，数据收集步骤可能是简单的，也可能是繁琐的。'
- en: '**Data preparation**: With the data from the data collection step, the next
    step is to clean and prepare the data. As we have seen throughout this book, our
    programming exercises always started with data cleanup and preparation. In the
    data preparation step, we handled missing values, encoded categorical variables,
    or transformed other variables, so that this data can be understood by machine
    learning algorithms.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据准备**：在数据收集步骤获得数据后，下一步是清理和准备数据。正如我们在本书中所看到的，我们的编程练习总是从数据清理和准备开始。在数据准备步骤中，我们处理了缺失值、编码了类别变量，或者转换了其他变量，以便机器学习算法能够理解这些数据。'
- en: '**Data analysis**: As you may recall, we have discovered useful insights from
    this data analysis step in our programming exercises throughout the book. Through
    analyzing data, we gain a better understanding of the overall distributions of
    different variables, and it is often a good idea to visualize data with different
    plots to identify any noticeable patterns.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据分析**：正如你可能记得的那样，我们在本书的编程练习中通过数据分析步骤发现了有价值的见解。通过分析数据，我们更好地理解了不同变量的总体分布，通常来说，通过不同的图表可视化数据，有助于识别出明显的模式。'
- en: '**Feature engineering**: As we have seen and discussed throughout the book,
    there are many different ways to approach engineering the features for machine
    learning models. For monetary values, we have applied log transformations. In
    some cases, we have normalized the data so that the variables are on the same
    scale. We have also used one-hot encoding to encode categorical variables. Feature
    engineering is one of the most important steps in building machine learning models,
    as the algorithms are going to try to learn from these features to correctly predict
    the target.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征工程**：正如我们在整本书中看到并讨论过的那样，针对机器学习模型进行特征工程有许多不同的方式。对于货币值，我们应用了对数变换。在某些情况下，我们对数据进行了归一化，使得变量处于相同的尺度上。我们还使用了独热编码（one-hot
    encoding）来编码类别变量。特征工程是构建机器学习模型中最重要的步骤之一，因为算法将尝试从这些特征中学习，以正确预测目标。'
- en: '**Model building**: The final step in a typical data science workflow is, of
    course, model building. With the clean data and features that we have built from
    previous steps, this is where you train your machine learning models. Throughout
    this book, we have discussed how to evaluate the models. For classification models,
    we have often used accuracy, precision, recall, the ROC curve, and the AUC. For
    regression models, we have used MSE, *R*², or a scatterplot of predicted and actual
    values for model evaluations.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型构建**：典型数据科学工作流程中的最后一步，当然是模型构建。利用前面步骤中清理过的数据和构建的特征，这里是训练机器学习模型的地方。在本书中，我们讨论了如何评估模型。对于分类模型，我们通常使用准确率、精确率、召回率、ROC曲线和AUC。对于回归模型，我们使用了MSE、*R*²，或者是预测值与实际值的散点图来评估模型。'
- en: During our programming exercises, our workflow looked almost the same as the
    workflow that we have just discussed. When unsure about what to do next, we hope
    this workflow diagram gives you some hints on the next steps.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的编程练习中，我们的工作流程几乎与我们刚才讨论的工作流程相同。当不确定下一步该做什么时，我们希望这个工作流程图能为你提供下一步的一些提示。
- en: Machine learning models
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型
- en: 'As you may recall, we built a number of machine learning models in this book.
    For example, in [Chapter 8](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml), *Predicting
    the Likelihood of Marketing Engagement*, we trained a random forest model to predict
    how likely each customer is to engage with marketing calls. In [Chapter 11](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml),
    *Retaining Customers*, we used an **artificial neural network** (**ANN**) model
    to identify which customers are likely to churn from the business. In this section,
    we will review those machine learning models that we have used in this book:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所记得，我们在本书中构建了许多机器学习模型。例如，在[第8章](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml)，《预测营销参与的可能性》中，我们训练了一个随机森林模型来预测每个客户参与营销电话的可能性。在[第11章](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml)，《客户保留》中，我们使用了**人工神经网络**（**ANN**）模型来识别哪些客户可能会流失。在本节中，我们将回顾本书中使用过的机器学习模型：
- en: '**Logistic regression**: In [Chapter 3](ce2c2775-9817-4b18-972c-db8e8c629b74.xhtml),
    *Drivers behind Marketing Engagement*, we have used a logistic regression model
    to extract the insights on which factors make customers more likely to engage
    with marketing campaigns. In Python, we used the `statsmodels` package to build
    a logistic regression model, and the code to train a logistic regression model
    looked like the following:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逻辑回归**：在[第3章](ce2c2775-9817-4b18-972c-db8e8c629b74.xhtml)，《营销参与背后的驱动因素》中，我们使用了逻辑回归模型来提取哪些因素使客户更可能参与营销活动。在Python中，我们使用了`statsmodels`包来构建逻辑回归模型，训练逻辑回归模型的代码如下所示：'
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'From this trained model, we could look at the details and correlations between
    the features and the target variable by running `logit_fit.summary()`. On the
    other hand, in R, we used the following command to train a logistic regression
    model:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个训练好的模型中，我们可以通过运行`logit_fit.summary()`查看特征与目标变量之间的细节和相关性。另一方面，在R中，我们使用了以下命令来训练逻辑回归模型：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Similar to how we used the `summary` function in Python, we could run the `summary(logit.fit)`
    command to get the details of the logistic regression fit and the correlations
    between the features and the target variable.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们在Python中使用`summary`函数的方式，我们可以运行`summary(logit.fit)`命令来获取逻辑回归拟合的细节以及特征与目标变量之间的相关性。
- en: '**Random forest**: As you may recall, we used a random forest algorithm in
    [Chapter 8](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml), *Predicting the Likelihood
    of Marketing Engagement*, to predict which customers are likely to respond to
    marketing calls. In Python, we used the `scikit-learn` package to build random
    forest models. The code to train a random forest model looked like the following:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林**：如你所记得，我们在[第8章](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml)《预测营销参与的可能性》中使用了随机森林算法来预测哪些客户可能会响应营销电话。在Python中，我们使用了`scikit-learn`包来构建随机森林模型。训练随机森林模型的代码如下所示：'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As you may recall, there were numerous hyperparameters you could tune with
    the random forest algorithm. We have discussed how you can fine-tune the number
    of estimators in the forest, `n_estimators`, the maximum depth of the tree, `max_depth`,
    and the minimum of samples needed to be able to split into branches, `min_samples_split`.
    On the other hand, in R, we used the `randomForest` library to build random forest
    models. The code for training a random forest model in R looked like the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所记得，随机森林算法有许多超参数可以调整。我们已经讨论了如何微调森林中的估计器数量`n_estimators`，树的最大深度`max_depth`，以及分支分割所需的最小样本数`min_samples_split`。另一方面，在R中，我们使用了`randomForest`库来构建随机森林模型。训练随机森林模型的R代码如下所示：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: With the `randomForest` package, you could fine-tune the hyperparameters. You
    could use `ntree` to tune the number of trees in the forest, `sampsize` to tune
    the size of the sample to draw for training each tree, and `maxnodes` to define
    the maximum number of terminal nodes in the tree.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`randomForest`包，你可以微调超参数。你可以使用`ntree`来调整森林中树的数量，`sampsize`来调整训练每棵树时所需的样本大小，以及`maxnodes`来定义树中终端节点的最大数量。
- en: '**ANN**: As you may recall, in [Chapter 11](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml),
    *Retaining Customers*, we used an ANN model to predict the customers who are likely
    to churn from the business. In order to build an ANN model, we used the `keras`
    package for both Python and R. In Python, training an ANN model looked like the
    following:'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工神经网络（ANN）**：如你所记得，在[第11章](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml)《保持客户》中，我们使用了ANN模型来预测可能会流失的客户。为了构建ANN模型，我们在Python和R中都使用了`keras`包。在Python中，训练ANN模型的代码如下所示：'
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As you should know already, we first had to add input, hidden, and output layers
    to the model. Then, we could compile and train an ANN model. In R, the concept
    is the same, but the syntax looks a bit different. The R code to train an ANN
    model using the `keras` package looked like the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如你已经知道的，我们首先需要向模型中添加输入层、隐藏层和输出层。然后，我们可以编译并训练ANN模型。在R中，概念是相同的，但语法稍有不同。使用`keras`包训练ANN模型的R代码如下所示：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**k-means clustering**: In [Chapter 10](5955002d-2a75-4d5a-aa6a-86710a3bf00e.xhtml),
    *Data-Driven Customer Segmentation*, we used a k-means clustering algorithm to
    programmatically build different customer segments. We have seen how analyzing
    the attributes of these different customer segments can help us understand the
    different behaviors of the customers and find better ways to target different
    groups of customers. In Python, we could use the `scikit-learn` package to build
    a k-means clustering algorithm. The code looked like the following:'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**k-means聚类**：在[第10章](5955002d-2a75-4d5a-aa6a-86710a3bf00e.xhtml)《基于数据的客户细分》中，我们使用了k-means聚类算法来程序化地构建不同的客户细分群体。我们已经看到，分析这些不同客户细分群体的属性可以帮助我们理解客户的不同行为，并找到更好的方法来定位不同的客户群体。在Python中，我们可以使用`scikit-learn`包来构建k-means聚类算法。代码如下所示：'
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As you may recall, you needed to define the number of clusters you would like
    to build from the data, using the `n_clusters` parameter. In order to get the
    cluster labels for each record and cluster centroids, we could use `kmeans.labels_`
    and `kmeans.cluster_centers_`. Similarly, in R, we used the `kmeans` function
    to build a clustering model, as shown in the following code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所记得，你需要定义你希望从数据中构建的聚类数量，使用`n_clusters`参数。为了获取每条记录的聚类标签和聚类中心，我们可以使用`kmeans.labels_`和`kmeans.cluster_centers_`。同样，在R中，我们使用了`kmeans`函数来构建聚类模型，R代码如下所示：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In order to get the labels and cluster centroids, we could use `cluster$cluster`
    and `cluster$centers`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取标签和聚类中心，我们可以使用`cluster$cluster`和`cluster$centers`。
- en: With these algorithms, we were able to easily build various machine learning
    models for different use cases in marketing. We hope these brief reviews of the
    syntax of building these machine learning models helped to refresh your memory.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些算法，我们能够轻松地为营销中的不同使用场景构建各种机器学习模型。希望这些简短的机器学习模型构建语法回顾能帮助你刷新记忆。
- en: Real-life data science challenges
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现实生活中的数据科学挑战
- en: 'Applying data science and machine learning in marketing would be all glamorous
    and flawless if we were able to just build and use various machine learning models
    for different marketing use cases. However, that normally is not the case. Quite
    often, the end-to-end machine learning model building process can be tedious,
    with lots of barriers and bottlenecks on the way. We are going to discuss some
    of the most frequently appearing data science challenges in real life, including
    the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能够针对不同的营销场景构建并使用各种机器学习模型，那么应用数据科学和机器学习到营销中看起来会非常光鲜亮丽且完美无缺。然而，通常情况并非如此。实际上，端到端的机器学习模型构建过程往往是繁琐的，过程中会有许多障碍和瓶颈。接下来，我们将讨论一些在现实生活中最常见的数据科学挑战，包括以下内容：
- en: Challenges in data
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据方面的挑战
- en: Challenges in infrastructure
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施方面的挑战
- en: Challenges in choosing the right model
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择合适模型的挑战
- en: Challenges in data
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据方面的挑战
- en: One of the most challenging factors in using data science and machine learning
    for marketing is getting the right data. As may sound obvious to you, without
    data, there is no data science or machine learning. Moreover, if the quality of
    the data is not good, then the quality of your trained machine learning is also
    going to be bad.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在营销中使用数据科学和机器学习的一个最大挑战是获取正确的数据。虽然这听起来可能很显而易见，但没有数据，就没有数据科学或机器学习。而且，如果数据的质量不好，那么训练出来的机器学习模型质量也会很差。
- en: 'In this section, we are going to discuss some of the common challenges that
    many data scientists face in getting the right data:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将讨论一些许多数据科学家在获取正确数据时常遇到的挑战：
- en: '**Existence of data**: Sometimes you may come up with a great idea of applying
    data science techniques to solve one of the problems you have in marketing. However,
    the data you need might not even exist. For example, say your idea was to identify
    trending web content, such as which web pages are viewed the most and liked the
    most by your users. However, you might not have the page view data, if the web
    page tracking functionality was not implemented on your websites. In this case,
    you will need to implement tracking functionality in your websites to track which
    users viewed or liked which content. Then, it is only possible to work on your
    idea after some period of time, when you have gathered enough data for your analysis.
    This type of case happens relatively frequently, so it is critical to have a good
    understanding of how well you track user activities and which parts you are missing.
    If possible, obtaining third-party data is also an option, when the data does
    not exist internally. There are lots of data vendors who sell data that you might
    need. If using a third-party data vendor is an option, that can be a good solution
    when there is no data for your project. Also, there is a lot of publicly available
    data that you can use freely. It is always worthwhile to see whether the data
    you need is publicly available or not.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据的存在性**：有时候你可能会想出一个很好的点子，打算使用数据科学技术来解决你在营销中遇到的某个问题。然而，你需要的数据可能根本不存在。例如，假设你的点子是识别热门网页内容，比如哪些网页是用户浏览最多、点赞最多的。然而，如果没有在你的网站上实现网页浏览跟踪功能，那么你可能没有相关的页面浏览数据。在这种情况下，你需要在你的网站上实现跟踪功能，以便跟踪哪些用户浏览了或点赞了哪些内容。这样，你只能在一定时间之后，收集到足够的数据来进行分析，才能开展你的想法。类似的情况在现实中发生得比较频繁，因此，理解你如何追踪用户活动以及缺少了哪些部分是至关重要的。如果可能的话，当数据在内部不存在时，获取第三方数据也是一个选择。有很多数据供应商出售你可能需要的数据。如果使用第三方数据供应商是一个选择，那么当你的项目没有数据时，这可能是一个好的解决方案。另外，还有很多可以自由使用的公开数据。始终值得看看你需要的数据是否是公开的。'
- en: '**Accessibility of data**: Data accessibility can be a barrier for a data science
    project. Especially in big corporations, access to certain sets of data is strictly
    restricted to selected subgroups of teams. In this case, even if the required
    dataset exists, it can be difficult or even impossible for data scientists or
    marketing professionals to access and use the data. Where the data is being generated
    from can also cause data accessibility problems. For instance, if the data is
    streamed into other applications without being stored or archived, then this data
    can be lost after it has been streamed. The location of the data files can also
    be a barrier to accessing the data you need. If the data cannot be shared through
    a network or if you cannot reach the location that the data lives in, then that
    can also keep you from using this data. This is why the responsibility and importance
    of data engineering and data engineers is rising. Data engineers work with other
    data scientists or software developers to specifically work on building data pipelines
    through which data with accessibility issues can move to other parts of the business.
    If you are facing issues with data accessibility, it is crucial to first find
    out what the barrier is and consider working with data engineers to build data
    pipelines to make the data accessible for your future projects.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据的可访问性**：数据的可访问性可能会成为数据科学项目的障碍，尤其是在大型企业中，某些数据集的访问权限被严格限制，只开放给选定的小组。在这种情况下，即使所需的数据集存在，数据科学家或市场营销专业人士也可能很难甚至无法访问和使用这些数据。数据的来源也可能导致数据可访问性问题。例如，如果数据流入其他应用程序而没有被存储或归档，那么在数据流失之后，它可能会丢失。数据文件的位置也可能成为访问所需数据的障碍。如果数据无法通过网络共享，或者你无法访问数据存储的位置，那么这也可能妨碍你使用数据。这就是为什么数据工程和数据工程师的责任和重要性日益上升的原因。数据工程师与其他数据科学家或软件开发人员合作，专门构建数据管道，帮助有可访问性问题的数据流转到业务的其他部分。如果你遇到数据可访问性的问题，首先找出障碍所在并考虑与数据工程师合作，建立数据管道，以使数据在未来的项目中可访问，至关重要。'
- en: '**Messy data**: You can assume the majority of the data you will face in real-life
    data science projects will be messy. It may be in a format that you cannot easily
    understand. It may be segmented into smaller parts that cannot easily be joined
    to each other. Or, there may also be too many missing values or too many duplicate
    records in the data. The degree of messiness of datasets can significantly increase
    the amount of time you need to spend on cleaning up the raw data and making it
    usable. Conducting in-depth data analysis on this messy data is crucial in making
    the data usable for future steps. Sometimes, it may be worthwhile to work with
    data engineers to fix the source that causes the messiness in the data and make
    future data more clean.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**杂乱的数据**：你可以假设，在实际的数据科学项目中，你将面对的大部分数据都是杂乱无章的。数据可能是你无法轻易理解的格式，可能被分割成更小的部分，难以轻松地将它们连接在一起。或者，数据中也可能有太多缺失值或重复记录。数据集的杂乱程度会显著增加你需要花费的时间，以清理原始数据并使其可用。在这些杂乱的数据上进行深入的数据分析，对于使数据在未来步骤中可用至关重要。有时，与数据工程师合作修复数据源中的杂乱问题，进而使未来的数据更加清洁，可能是值得的。'
- en: Challenges in infrastructure
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础设施挑战
- en: When working with different datasets for applying data science techniques and
    using machine learning models for different projects in marketing, you may face
    some challenges in the system infrastructure that you use for developments. Quite often,
    datasets are too big to fit into your laptop or computer. As the size of data
    is grows bigger and bigger everyday, it becomes even more likely that sometime
    in the future, you will have issues with developing data science models on your
    laptop, even if you currently do not have this problem.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用数据科学技术并使用机器学习模型进行市场营销项目的过程中，使用的系统基础设施可能会遇到一些挑战。通常，数据集太大，无法容纳在你的笔记本电脑或计算机中。随着数据量的日益增长，将来你很可能会遇到在笔记本电脑上开发数据科学模型的问题，即使你现在没有这个问题。
- en: 'There are two main things that can slow you down when working on data science
    projects: shortage of CPU or processing power and shortage of RAM or memory. If
    you do not have enough processing power, your analysis could take long time. Especially
    when training machine learning models, it is not uncommon for model training to
    take days, weeks, or even months. On the other hand, if you do not have enough
    memory, you might end up getting `Out of Memory` errors while running your analysis.
    For example, tree-based models, such as decision trees or random forests, can
    take a large amount of memory, and training such models can fail after hours of
    training because of shortage of memory.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行数据科学项目时，有两件事可能会拖慢你的进度：CPU或处理能力不足，以及RAM或内存不足。如果没有足够的处理能力，你的分析可能会花费很长时间。尤其是在训练机器学习模型时，模型训练可能需要几天、几周甚至几个月。在另一方面，如果内存不足，你可能会在运行分析时遇到`Out
    of Memory`错误。例如，基于树的模型，如决策树或随机森林，可能需要大量内存，训练这些模型可能会因为内存不足而在几个小时的训练后失败。
- en: With the emerging popularity of and developments in cloud computing, there are
    solutions to these problems. Using one of the cloud computing service providers,
    such as AWS, Google, or Microsoft Azure, you can, theoretically, get an unlimited
    amount of computing power and memory. Of course, everything comes with a price.
    Running large data science jobs on these cloud platforms can cost a fortune, if
    you do not plan it right. When working with large datasets, it is wise to consider
    the amount of processing power and memory you would need to successfully run your
    tasks.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 随着云计算的兴起和发展，解决这些问题的方案也随之出现。通过使用如AWS、Google或Microsoft Azure等云计算服务提供商，你理论上可以获得无限的计算能力和内存。当然，一切都有代价。如果没有正确规划，在这些云平台上运行大型数据科学任务可能会花费一大笔钱。在处理大型数据集时，明智的做法是考虑你需要多少处理能力和内存，才能成功运行任务。
- en: Challenges in choosing the right model
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择合适模型的挑战
- en: Choosing a machine learning algorithm for a given data science project is more
    difficult than it sounds. Some algorithms work more like a black box, where you
    do not know how an algorithm makes predictions or decisions. For example, it is
    quite difficult to understand how a trained random forest model makes predictions
    on the output from the input. The decisions are made from hundreds of different
    decision trees, where each tree works differently with different decision-making
    criteria, and this makes it difficult for a data scientist to fully understand
    what happens in between the input and the output.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为某个数据科学项目选择机器学习算法比听起来更复杂。有些算法更像一个黑箱，你无法知道一个算法是如何做出预测或决策的。例如，理解一个训练好的随机森林模型是如何根据输入做出预测的非常困难。决策是由数百棵不同的决策树做出的，每棵树根据不同的决策标准进行工作，这使得数据科学家很难完全理解输入与输出之间发生了什么。
- en: On the other hand, linear models, such as logistic regression models, tell us
    exactly how they are making decisions. Once logistic regression models are trained,
    we know the coefficients given to each feature, and from these coefficients, we
    can deduce what the predicted output is going to be. Depending on your use cases,
    you might need to have this kind of explainability, where you need to be able
    to explain how each feature works and affects the prediction output to your business
    partners. Quite often, more advanced models work more like a black box, and you
    will need to make a trade-off between prediction accuracy and explainability.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，线性模型，如逻辑回归模型，能够准确地告诉我们它们是如何做出决策的。一旦逻辑回归模型被训练，我们就能知道每个特征的系数，并从这些系数中推断出预测的输出是什么。根据你的使用场景，你可能需要这种可解释性，你需要能够向业务合作伙伴解释每个特征如何作用以及如何影响预测输出。通常情况下，更高级的模型更像一个黑箱，你需要在预测准确性和可解释性之间做出权衡。
- en: More machine learning models and packages
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多的机器学习模型和包
- en: 'In this book, we have mainly used the following five machine learning algorithms
    that fit into and work the best for our marketing use cases: logistic regression,
    random forests, ANN, k-means clustering, and collaborative filtering. However,
    there are many more readily available machine learning algorithms that you may
    find useful for your future data science and machine learning projects. We will
    be covering some of the other frequently used machine learning algorithms, what
    packages to use in Python and R, and where to find more information on these algorithms.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们主要使用了以下五种最适合我们营销应用场景的机器学习算法：逻辑回归、随机森林、人工神经网络（ANN）、k-means 聚类和协同过滤。然而，还有许多其他现成的机器学习算法，您可能会在未来的数据科学和机器学习项目中找到它们的应用。我们将介绍一些其他常用的机器学习算法，以及在
    Python 和 R 中使用的包，另外，我们还会提供更多关于这些算法的资源链接。
- en: 'Some of the other machine learning algorithms to consider in your future projects
    are the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在您未来的项目中，您可能需要考虑的其他机器学习算法如下：
- en: '**Nearest neighbors**: This is a machine learning algorithm that finds the
    pre-defined number of closest samples to a new data point. Even though the concept
    of this algorithm sounds simple, the nearest neighbors algorithm has been used
    successfully in various areas, including image recognition. In the `scikit-learn`
    package of Python, you can use the `KNeighborsClassifier` class in the `neighbors`
    module to build classification models, or you can use the `KNeighborsRegressor`
    class to build regression models. For more details on the usage, we recommend
    you take a look at the following documentation page: [https://scikit-learn.org/stable/modules/neighbors.html](https://scikit-learn.org/stable/modules/neighbors.html).
    On the other hand, in R, you can use the `knn` function in the `class` library.
    For the documentation of this function in R, you can refer to this documentation
    page: [https://www.rdocumentation.org/packages/class/versions/7.3-15/topics/knn](https://www.rdocumentation.org/packages/class/versions/7.3-15/topics/knn).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最近邻**：这是一个机器学习算法，用于找到与新数据点最接近的预定义数量的样本。尽管这个算法的概念听起来很简单，但最近邻算法在包括图像识别在内的多个领域已被成功应用。在
    Python 的 `scikit-learn` 包中，您可以使用 `neighbors` 模块中的 `KNeighborsClassifier` 类来构建分类模型，或使用
    `KNeighborsRegressor` 类来构建回归模型。有关使用的详细信息，我们建议您查看以下文档页面：[https://scikit-learn.org/stable/modules/neighbors.html](https://scikit-learn.org/stable/modules/neighbors.html)。另一方面，在
    R 中，您可以使用 `class` 库中的 `knn` 函数。有关该函数的 R 文档，请参考此页面：[https://www.rdocumentation.org/packages/class/versions/7.3-15/topics/knn](https://www.rdocumentation.org/packages/class/versions/7.3-15/topics/knn)。'
- en: '**Support vector machine** (**SVM**): SVM is another machine learning algorithm
    that you may find useful. The SVM algorithm tries to find a hyperplane that best
    splits the data into classes or groups. It is especially effective in high-dimensional
    space. The `scikit-learn` package has the `SVC` and `SVR` classes implemented
    in Python for classification and regression models. The documentation page can
    be found at the following link: [https://scikit-learn.org/stable/modules/svm.html](https://scikit-learn.org/stable/modules/svm.html).
    In R, the `e1071` library has the `svm` function, which you can use to train SVM
    models. More documentation on its usage can be found here: [https://www.rdocumentation.org/packages/e1071/versions/1.7-0.1/topics/svm](https://www.rdocumentation.org/packages/e1071/versions/1.7-0.1/topics/svm).'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVM**）：SVM 是另一种您可能会用到的机器学习算法。SVM 算法试图找到一个超平面，将数据最佳地划分为不同的类别或组。它在高维空间中特别有效。在
    Python 的 `scikit-learn` 包中，您可以使用 `SVC` 和 `SVR` 类来实现分类和回归模型。有关文档页面，请访问以下链接：[https://scikit-learn.org/stable/modules/svm.html](https://scikit-learn.org/stable/modules/svm.html)。在
    R 中，`e1071` 库提供了 `svm` 函数，您可以用它来训练 SVM 模型。有关其用法的更多文档，请参考此页面：[https://www.rdocumentation.org/packages/e1071/versions/1.7-0.1/topics/svm](https://www.rdocumentation.org/packages/e1071/versions/1.7-0.1/topics/svm)。'
- en: '**Gradient-boosted trees** (**GBT**): GBT is one of the tree-based machine
    learning algorithms. Unlike the random forest algorithm, the GBT algorithm learns
    and trains each tree sequentially, and each tree learns from the mistakes that
    the previous trees made. It is well known and frequently used for its prediction
    accuracy and robustness. In Python, you can use the `GradientBoostingClassifier`
    class in the `scikit-learn` package''s `ensemble` module for classification problems
    and the `GradientBoostingRegressor` class for regression problems. More details
    about GBT in `scikit-learn` can be found here: [https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting).
    Similarly, in R, the `gbm` package has the GBT algorithm implemented for classification
    and regression problems. You can use the `gbm` function within the `gbm` package
    to train a GBT model. More information can be found at the following link: [https://www.rdocumentation.org/packages/gbm/versions/2.1.5/topics/gbm](https://www.rdocumentation.org/packages/gbm/versions/2.1.5/topics/gbm)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度提升树**（**GBT**）：GBT 是一种基于树的机器学习算法。与随机森林算法不同，GBT 算法按顺序学习和训练每一棵树，每棵树都从前一棵树的错误中学习。因其预测准确性和稳健性而广为人知并频繁使用。在
    Python 中，你可以使用 `scikit-learn` 包中的 `GradientBoostingClassifier` 类来解决分类问题，使用 `GradientBoostingRegressor`
    类来解决回归问题。关于 `scikit-learn` 中 GBT 的更多细节可以在这里找到：[https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting)。同样，在
    R 中，`gbm` 包实现了适用于分类和回归问题的 GBT 算法。你可以使用 `gbm` 包中的 `gbm` 函数来训练 GBT 模型。更多信息可以在以下链接中找到：[https://www.rdocumentation.org/packages/gbm/versions/2.1.5/topics/gbm](https://www.rdocumentation.org/packages/gbm/versions/2.1.5/topics/gbm)'
- en: Summary
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we reviewed the topics that we discussed in this book. We briefly
    went through the trends that are observable in the marketing industry and how
    data science and machine learning are becoming more and more important in marketing.
    Then, we reviewed a typical data science workflow, where you start with problem
    definition, then move onto data collection, preparation, and analysis, and finally
    move to feature engineering and model building. While working on future data science
    projects, it will be worthwhile to keep the workflow diagram we looked at in the
    back of your head and when stuck with what to do next, refer back to this diagram
    for ideas. We have also shared some of the challenges you might face when working
    with real-world datasets. The three main challenges we covered were data issues,
    infrastructure issues, and choosing the right model. More specifically, we discussed
    the trade-off between explainability and model accuracy. We have suggested some
    workarounds and solutions to these challenges, so we hope they help when you face
    similar challenges. Lastly, we have discussed some other frequently used machine
    learning models that you may find useful in your future projects. We have briefly
    showed which Python and R packages to use for each of these models and where you
    can find more information about the usage of those models.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了本书中讨论的主题。我们简要地概述了在营销行业中可以观察到的趋势，以及数据科学和机器学习在营销中的重要性日益增加。然后，我们回顾了一个典型的数据科学工作流，其中你从问题定义开始，然后进入数据收集、准备和分析，最后进行特征工程和模型构建。在未来的数据科学项目中，值得将我们所看到的工作流图放在脑海中，当你卡住不知道接下来做什么时，可以参考这个图来获取灵感。我们还分享了在处理真实世界数据集时可能遇到的一些挑战。我们讨论的三个主要挑战是数据问题、基础设施问题和选择合适的模型。更具体地说，我们讨论了可解释性与模型准确性之间的权衡。我们提出了一些解决这些挑战的替代方案和解决办法，希望它们能在你面对类似挑战时提供帮助。最后，我们讨论了在未来项目中可能有用的其他常用机器学习模型。我们简要展示了每个模型所需的
    Python 和 R 包，以及你可以在哪里找到有关这些模型使用的更多信息。
- en: Throughout the 13 chapters in this book, we have covered the various data science
    and machine learning techniques you can use in marketing, with a focus on practicality.
    As you have worked through numerous examples for different use cases in marketing
    throughout this book, we hope you have gained more confidence in applying data
    science techniques and building machine learning models for developing more intelligent
    and efficient marketing strategies. We hope your journey throughout this book
    was worthwhile and rewarding and that you have gained many new and useful skills.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的13章中，我们涵盖了可以应用于营销的各种数据科学和机器学习技术，重点强调实用性。通过本书中多个不同营销场景的示例，我们希望你已经对应用数据科学技术和构建机器学习模型以开发更智能、更高效的营销策略充满信心。我们希望你在本书的学习旅程中收获满满，获得了许多新的、有用的技能。
