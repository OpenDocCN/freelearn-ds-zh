- en: Classification Using K-Nearest Neighbors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用K-最近邻算法进行分类
- en: A nearest neighbor algorithm classifies a data instance based on its neighbors.
    The class of a data instance determined by the *k*-nearest neighbors algorithm
    is the class with the highest representation among the *k*-closest neighbors.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻算法根据邻居对数据实例进行分类。通过*k*-最近邻算法确定的数据实例的类别是*k*个最近邻居中出现次数最多的类别。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: How to implement the basics of the k-NN algorithm using the example of Mary
    and her temperature preferences
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何通过Mary及其温度偏好示例实现k-NN算法的基本原理
- en: How to choose a correct *k* value so that the algorithm can perform correctly
    and with the highest degree of accuracy using the example of a map of Italy
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何选择正确的*k*值，以便算法能够正确执行，并且在使用意大利地图示例时具有最高的准确度
- en: How to rescale values and prepare them for the k-NN algorithm using the example
    of house preferences
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何调整值的比例并为k-NN算法做准备，以房屋偏好为例
- en: How to choose a good metric to measure distances between data points
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何选择一个合适的度量标准来测量数据点之间的距离
- en: How to eliminate irrelevant dimensions in higher-dimensional space to ensure
    that the algorithm performs accurately using the text classification example
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在高维空间中消除不相关的维度，以确保算法在文本分类示例中能够准确执行
- en: Mary and her temperature preferences
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mary及其温度偏好
- en: As an example, if we know that our friend, Mary, feels cold when it is 10°C,
    but warm when it is 25°C, then in a room where it is 22°C, the nearest neighbor
    algorithm would guess that our friend would feel warm, because 22 is closer to
    25 than to 10.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们知道我们的朋友Mary在10°C时感觉冷，在25°C时感觉温暖，那么在一个温度为22°C的房间里，最近邻算法会猜测她会感觉温暖，因为22比10更接近25。
- en: 'Suppose that we would like to know when Mary feels warm and when she feels
    cold, as in the previous example, but in addition, wind speed data is also available
    when Mary is asked whether she feels warm or cold:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想知道Mary在何时感到温暖，何时感到寒冷，如前面的例子所示，但此外，风速数据在询问Mary是否感到温暖或寒冷时也可用：
- en: '| **Temperature in °C** | **Wind speed in km/h** | **Mary''s perception** |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| **温度（°C）** | **风速（km/h）** | **Mary的感知** |'
- en: '| 10 | 0 | Cold |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 0 | 冷 |'
- en: '| 25 | 0 | Warm |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 0 | 温暖 |'
- en: '| 15 | 5 | Cold |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 5 | 冷 |'
- en: '| 20 | 3 | Warm |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 3 | 温暖 |'
- en: '| 18 | 7 | Cold |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 18 | 7 | 冷 |'
- en: '| 20 | 10 | Cold |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 10 | 冷 |'
- en: '| 22 | 5 | Warm |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 22 | 5 | 温暖 |'
- en: '| 24 | 6 | Warm |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 24 | 6 | 温暖 |'
- en: 'We could represent the data in a graph, as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过图表来表示数据，如下所示：
- en: '![](img/32fcee24-5625-4abb-9ff4-48c0f241fca5.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32fcee24-5625-4abb-9ff4-48c0f241fca5.png)'
- en: 'Now, suppose we would like to find out how Mary feels when the temperature
    is 16°C with a wind speed of 3 km/h by using the *1*-NN algorithm:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们想通过使用*1*-NN算法来了解当温度为16°C、风速为3 km/h时，Mary的感受：
- en: '![](img/b1ef3a61-29f6-4395-9904-a8fd36dfcff9.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1ef3a61-29f6-4395-9904-a8fd36dfcff9.png)'
- en: For simplicity, we will use a Manhattan metric to measure the distance between
    the neighbors on the grid. The Manhattan distance *d[Man]* of the neighbor *N[1]=(x[1],y[1])*
    from the neighbor *N[2]=(x[2],y[2])* is defined as *d[Man]=|x[1]**-* *x[2]|+|y[1]**-*
    *y[2]|*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化起见，我们将使用曼哈顿距离度量法来测量网格上相邻点之间的距离。邻居*N[1]=(x[1],y[1])*到邻居*N[2]=(x[2],y[2])*的曼哈顿距离*d[Man]*定义为*d[Man]=|x[1]**-*
    *x[2]|+|y[1]**-* *y[2]|*。
- en: 'Let''s label the grid with distances around the neighbors to see which neighbor
    with a known class is closest to the point we would like to classify:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们给网格标上邻居的距离，看看哪个已知类别的邻居距离我们希望分类的点最近：
- en: '![](img/b41d305d-64c1-4f53-aa2e-2146b7586056.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b41d305d-64c1-4f53-aa2e-2146b7586056.png)'
- en: We can see that the closest neighbor with a known class is the one with a temperature
    of 15°C (blue) and a wind speed of 5 km/h. Its distance from the point in question
    is three units. Its class is blue (cold). The closest red (warm) neighbour is
    at a distance of four units from the point in question. Since we are using the
    1-nearest neighbor algorithm, we just look at the closest neighbor and, therefore,
    the class of the point in question should be blue (cold).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，距离该点最近的已知类别的邻居是温度为15°C（蓝色）且风速为5 km/h的邻居。它与该点的距离为三单位。它的类别是蓝色（冷）。最近的红色（温暖）邻居与该点的距离为四单位。由于我们使用的是1-最近邻算法，我们只需要查看最近的邻居，因此该点的类别应为蓝色（冷）。
- en: 'By applying this procedure to every data point, we can complete the graph,
    as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对每个数据点应用这个过程，我们可以完成图表，如下所示：
- en: '![](img/fadf736f-c76e-4d57-9868-ba3d12a30639.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fadf736f-c76e-4d57-9868-ba3d12a30639.png)'
- en: 'Note that, sometimes, a data point might be the same distance away from two
    known classes: for example, 20°C and 6 km/h. In such situations, we could prefer
    one class over the other, or ignore these boundary cases. The actual result depends
    on the specific implementation of an algorithm.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，有时数据点可能距离两个已知类别的距离相同：例如，20°C和6 km/h。在这种情况下，我们可以偏好一个类别，或者忽略这些边界情况。实际结果取决于算法的具体实现。
- en: Implementation of the k-nearest neighbors algorithm
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: k近邻算法的实现
- en: 'Now, we will implement the k-NN algorithm in Python to find Mary''s temperature
    preference. At the end of this section, we will also implement the visualization
    of the data produced in the previous section, that is, *Mary and her temperature
    preferences*. The full, compilable code, with the input files, can be found in
    the source code provided with this book. The most important parts have been extracted
    and presented here:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将在Python中实现k-NN算法来查找玛丽的温度偏好。在本节结束时，我们还将实现上一节中生成的数据的可视化，即*玛丽和她的温度偏好*。完整的可编译代码和输入文件可以在本书附带的源代码中找到。最重要的部分已提取并在此呈现：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Input**:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入**：'
- en: 'The preceding program will use the following file as the source of the input
    data. The file contains the table with the known data about Mary''s temperature
    preferences:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的程序将使用以下文件作为输入数据的来源。该文件包含了有关玛丽温度偏好的已知数据表：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Output**:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出**：'
- en: 'We run the preceding implementation on the `mary_and_temperature_preferences.data` input
    file by using the k-NN algorithm for `k=1` neighbors. The algorithm classifies
    all the points with integer coordinates in the rectangle with a size of `(30-5=25)
    by (10-0=10)`, hence, with a size of `(25+1) * (10+1) = 286` integer points (adding
    one to count points on boundaries). Using the `wc` command, we find out that the
    output file contains exactly 286 lines—one data item per point. Using the `head`
    command, we display the first 10 lines from the output file:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用k-NN算法（`k=1`邻居）在`mary_and_temperature_preferences.data`输入文件上运行前面的实现。该算法将所有具有整数坐标的点分类到大小为`(30-5=25)
    by (10-0=10)`的矩形区域内，因此，矩形的大小为`(25+1) * (10+1) = 286`个整数点（加一是为了计算边界上的点）。使用`wc`命令，我们发现输出文件确实包含286行——每个点对应一个数据项。通过使用`head`命令，我们显示输出文件中的前10行：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Visualization**:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**可视化**：'
- en: 'For the visualization depicted earlier in this chapter, the `matplotlib` library
    was used. A data file is loaded, and then displayed in a scatter diagram:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面描述的可视化中，使用了`matplotlib`库。数据文件被加载后，显示为散点图：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Map of Italy example – choosing the value of k
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 意大利地图示例 - 选择k值
- en: In our data, we are given some points (about 1 percent) from the map of Italy
    and its surroundings. The blue points represent water, and the green points represent
    land; the white points are unknown. From the partial information that we have
    been given, we would like to predict whether there is water or land in the white
    areas.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的数据中，我们获得了一些来自意大利及其周围地区地图的点（大约1%）。蓝色点代表水域，绿色点代表陆地；白色点是未知的。从我们所拥有的部分信息中，我们希望预测白色区域是水域还是陆地。
- en: 'Drawing only 1% of the map data in the picture would make it almost invisible.
    If we were given about 33 times more data from the map of Italy and its surroundings,
    and drew it in the picture instead, it would look as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 仅绘制地图数据的1%会使其几乎不可见。如果我们从意大利及其周围地区的地图中获取大约33倍的数据，并将其绘制在图中，结果将如下所示：
- en: '![](img/1d1458c9-b445-498b-81df-26d1aa0aed5a.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d1458c9-b445-498b-81df-26d1aa0aed5a.png)'
- en: Analysis
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析
- en: 'For this problem, we will use the k-NN algorithm—*k* here means that we will
    look at *k*-closest neighbors. Given a white point, it will be classified as an
    area of water if the majority of its *k*-closest neighbors are in an area of water
    and classified as land if the majority of its *k*-closest neighbors are an area
    of land. We will use the Euclidean metric for the distance: given two points, *X=[x[0],x[1]]*
    and *Y=[y[0],y[1]]*, their Euclidean distance is defined as *d[Euclidean] = sqrt((x[0]-y[0])²+(x[1]-y[1])²)*.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题，我们将使用k-NN算法——这里的*k*表示我们将查看*k*个最接近的邻居。给定一个白色点，如果它的*k*个最接近的邻居大多数位于水域区域，它将被分类为水域；如果它的*k*个最接近的邻居大多数位于陆地区域，它将被分类为陆地。我们将使用欧几里得度量来计算距离：给定两个点，*X=[x[0],x[1]]*和*Y=[y[0],y[1]]*，它们的欧几里得距离定义为*d[Euclidean]
    = sqrt((x[0]-y[0])²+(x[1]-y[1])²)*。
- en: 'The Euclidean distance is the most common metric. Given two points on a piece
    of paper, their Euclidean distance is just the length between the two points,
    as measured by a ruler, as shown in the following diagram:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得距离是最常用的度量。给定纸面上的两点，它们的欧几里得距离就是通过尺子量测得的两点之间的长度，如下图所示：
- en: '![](img/438d455d-c50a-4050-ad3c-8cc3c04594ae.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/438d455d-c50a-4050-ad3c-8cc3c04594ae.png)'
- en: To apply the k-NN algorithm to an incomplete map, we have to choose the value
    of *k*. Since the resulting class of a point is the class of the majority of the
    *k*-closest neighbors of that point, *k* should be odd. Let's apply this algorithm
    to the values of *k=1,3,5,7,9*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将k-NN算法应用到不完整的地图中，我们必须选择*k*值。由于一个点的最终分类是其*k*个最接近邻居的多数类别，因此*k*应为奇数。让我们将此算法应用于*k=1,3,5,7,9*的值。
- en: 'Applying this algorithm to every white point on the incomplete map will result
    in the following complete maps:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 将此算法应用到不完整地图上的每一个白点，将得到以下完整地图：
- en: '![](img/3e30176a-ac73-4bfc-bc22-ad4e9582f5c6.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3e30176a-ac73-4bfc-bc22-ad4e9582f5c6.png)'
- en: k=1
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: k=1
- en: '![](img/a3ba0c09-c93a-42c0-946d-008ef6dfa6fc.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a3ba0c09-c93a-42c0-946d-008ef6dfa6fc.png)'
- en: k=3
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: k=3
- en: '![](img/d2adcc17-bafc-4e20-aaa0-c43d020f6745.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d2adcc17-bafc-4e20-aaa0-c43d020f6745.png)'
- en: k=5
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: k=5
- en: '![](img/00da5203-291f-40de-906e-8f24897be3d2.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00da5203-291f-40de-906e-8f24897be3d2.png)'
- en: k=7
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: k=7
- en: '![](img/89bc78d7-4053-4586-83e2-49c105cf71bd.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/89bc78d7-4053-4586-83e2-49c105cf71bd.png)'
- en: k=9
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: k=9
- en: 'As you may have noticed, the highest value of *k* results in a complete map
    with smoother boundaries. An actual complete map of Italy is shown here:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所注意到的，*k*的最高值会导致一个边界更平滑的完整地图。这里展示了意大利的实际完整地图：
- en: '![](img/822d8fb1-cae0-4f08-8fce-a4ed19eb02a3.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/822d8fb1-cae0-4f08-8fce-a4ed19eb02a3.png)'
- en: 'We can use this real, complete map to calculate the percentage of incorrectly
    classified points for the various values of *k* to determine the accuracy of the
    k-NN algorithm for different values of *k*:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个实际的完整地图来计算不同*k*值下错误分类点的百分比，从而确定k-NN算法在不同*k*值下的准确性：
- en: '| **k** | **Precentage of incorrectly classified points** |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| **k** | **错误分类点的百分比** |'
- en: '| 1 | 2.97 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2.97 |'
- en: '| 3 | 3.24 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 3.24 |'
- en: '| 5 | 3.29 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 3.29 |'
- en: '| 7 | 3.40 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 3.40 |'
- en: '| 9 | 3.57 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 3.57 |'
- en: Thus, for this particular type of classification problem, the k-NN algorithm
    achieves the highest accuracy (least error rate) for *k=1*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于这种特定类型的分类问题，k-NN算法在*k=1*时达到了最高准确性（最小误差率）。
- en: However, in real life, the problem is that we wouldn't usually have complete
    data or a solution. In such scenarios, we need to choose a value of *k* that is
    appropriate to the data that is partially available. For this, consult *Problem
    4* at the end of this chapter.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在现实生活中，问题在于我们通常没有完整的数据或解决方案。在这种情况下，我们需要选择一个适合部分可用数据的*k*值。有关这一点，请参阅本章末尾的*问题4*。
- en: House ownership – data rescaling
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 房屋拥有情况 – 数据重缩放
- en: 'For each person, we are given their age, yearly income, and whether or not
    they own a house:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个人，我们都知道他们的年龄、年收入，以及是否拥有房屋：
- en: '| **Age** | **Annual income in USD** | **House ownership status** |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| **年龄** | **年收入（美元）** | **房屋拥有情况** |'
- en: '| 23 | 50,000 | Non-owner |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 23 | 50,000 | 非拥有者 |'
- en: '| 37 | 34,000 | Non-owner |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 37 | 34,000 | 非拥有者 |'
- en: '| 48 | 40,000 | Owner |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 48 | 40,000 | 拥有者 |'
- en: '| 52 | 30,000 | Non-owner |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 52 | 30,000 | 非拥有者 |'
- en: '| 28 | 95,000 | Owner |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 28 | 95,000 | 拥有者 |'
- en: '| 25 | 78,000 | Non-owner |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 78,000 | 非拥有者 |'
- en: '| 35 | 130,000 | Owner |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 35 | 130,000 | 拥有者 |'
- en: '| 32 | 105,000 | Owner |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 32 | 105,000 | 拥有者 |'
- en: '| 20 | 100,000 | Non-owner |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 100,000 | 非拥有者 |'
- en: '| 40 | 60,000 | Owner |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 40 | 60,000 | 拥有者 |'
- en: '| 50 | 80,000 | Peter |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 80,000 | 彼得 |'
- en: '![](img/dca3b7cb-d007-4325-8adc-6da7a4c97381.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dca3b7cb-d007-4325-8adc-6da7a4c97381.png)'
- en: House ownership and annual income
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 房屋拥有情况与年收入
- en: The aim is to predict whether Peter, aged 50, with an income of $80,000 per
    year, owns a house and could be a potential customer for our insurance company.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是预测50岁、年收入80,000美元的彼得是否拥有房屋，并可能成为我们保险公司的潜在客户。
- en: Analysis
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析
- en: 'In this case, we could try to apply the 1-NN algorithm. However, we should
    be careful about how we measure the distances between the data points, since the
    income range is much wider than the age range. Income levels of USD 115 k and
    USD 116 k are USD 1,000 apart. The two data points for these incomes would be
    very far apart. However, relative to each other, the difference between these
    data points isn''t actually that big. Because we consider both measures (age and
    yearly income) to be about as important as each other, we would scale both from
    0 to 1 according to the following formula:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以尝试应用 1-NN 算法。然而，我们需要小心如何衡量数据点之间的距离，因为收入范围远大于年龄范围。收入为 11.5 万美元和 11.6
    万美元之间相差 1,000 美元。这两个数据点在收入上差距很大。但相对而言，这些数据点之间的差异实际上并没有那么大。由于我们认为年龄和年收入这两个度量大致同等重要，我们将根据以下公式将它们都缩放到
    0 到 1 之间：
- en: '![](img/d7f80a4f-06bb-4927-95df-4173f07c1cf3.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d7f80a4f-06bb-4927-95df-4173f07c1cf3.png)'
- en: 'In our particular case, this reduces to the following:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们特定的案例中，这简化为以下内容：
- en: '![](img/ce5dc1b8-a7ce-4089-b54b-3974f5cf909a.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce5dc1b8-a7ce-4089-b54b-3974f5cf909a.png)'
- en: '![](img/1d4d1412-e788-4d98-8880-3ebf69fc1b26.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d4d1412-e788-4d98-8880-3ebf69fc1b26.png)'
- en: 'After scaling, we get the following data:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放后，我们得到以下数据：
- en: '| **Age** | **Scaled age** | **Annual income in USD** | **Scaled annual income**
    | **House ownership status** |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| **年龄** | **缩放后的年龄** | **年收入（美元）** | **缩放后的年收入** | **房屋所有权状态** |'
- en: '| 23 | 0.09375 | 50,000 | 0.2 | Non-owner |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 23 | 0.09375 | 50,000 | 0.2 | 非拥有者 |'
- en: '| 37 | 0.53125 | 34,000 | 0.04 | Non-owner |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 37 | 0.53125 | 34,000 | 0.04 | 非拥有者 |'
- en: '| 48 | 0.875 | 40,000 | 0.1 | Owner |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 48 | 0.875 | 40,000 | 0.1 | 拥有者 |'
- en: '| 52 | 1 | 30,000 | 0 | Non-owner |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 52 | 1 | 30,000 | 0 | 非拥有者 |'
- en: '| 28 | 0.25 | 95,000 | 0.65 | Owner |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 28 | 0.25 | 95,000 | 0.65 | 拥有者 |'
- en: '| 25 | 0.15625 | 78,000 | 0.48 | Non-owner |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 0.15625 | 78,000 | 0.48 | 非拥有者 |'
- en: '| 35 | 0.46875 | 130,000 | 1 | Owner |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 35 | 0.46875 | 130,000 | 1 | 拥有者 |'
- en: '| 32 | 0.375 | 105,000 | 0.75 | Owner |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 32 | 0.375 | 105,000 | 0.75 | 拥有者 |'
- en: '| 20 | 0 | 100,000 | 0.7 | Non-owner |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 0 | 100,000 | 0.7 | 非拥有者 |'
- en: '| 40 | 0.625 | 60,000 | 0.3 | Owner |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 40 | 0.625 | 60,000 | 0.3 | 拥有者 |'
- en: '| 50 | 0.9375 | 80,000 | 0.5 | ? |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 0.9375 | 80,000 | 0.5 | ? |'
- en: Now, if we apply the 1-NN algorithm with the Euclidean metric, we will find
    out that Peter more than likely owns a house. Note that, without rescaling, the
    algorithm would yield a different result. Refer to *Exercise 1.5* for more information.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们使用欧几里得度量应用 1-NN 算法，我们会发现 Peter 很可能拥有一套房子。请注意，如果不进行重新缩放，算法将得出不同的结果。有关更多信息，请参见*练习
    1.5*。
- en: Text classification – using non-Euclidean distances
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本分类 – 使用非欧几里得距离
- en: 'We are given the following word counts relating to the keywords **algorithm**
    and **computer**, for documents of the classes, in the informatics and mathematics
    subject classifications:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们给出以下与关键词**算法**和**计算机**相关的词频数据，适用于信息学和数学学科分类中的文档：
- en: '| **Algorithm words per 1,000** | **Computer words per 1,000** | **Subject
    classification** |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| **每千字算法词汇** | **每千字计算机词汇** | **学科分类** |'
- en: '| 153 | 150 | Informatics |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 153 | 150 | 信息学 |'
- en: '| 105 | 97 | Informatics |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 105 | 97 | 信息学 |'
- en: '| 75 | 125 | Informatics |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 125 | 信息学 |'
- en: '| 81 | 84 | Informatics |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 81 | 84 | 信息学 |'
- en: '| 73 | 77 | Informatics |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 73 | 77 | 信息学 |'
- en: '| 90 | 63 | Informatics |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 90 | 63 | 信息学 |'
- en: '| 20 | 0 | Mathematics |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 0 | 数学 |'
- en: '| 33 | 0 | Mathematics |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 33 | 0 | 数学 |'
- en: '| 105 | 10 | Mathematics |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 105 | 10 | 数学 |'
- en: '| 2 | 0 | Mathematics |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0 | 数学 |'
- en: '| 84 | 2 | Mathematics |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 84 | 2 | 数学 |'
- en: '| 12 | 0 | Mathematics |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 0 | 数学 |'
- en: '| 41 | 42 | ? |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 41 | 42 | ? |'
- en: Those documents having a high incidence of the words **algorithm** and **computer**
    are in the `informatics` class. The `mathematics` class happens to contain documents
    with a high incidence of the word **algorithm** in some cases, for example, a
    document concerned with the Euclidean algorithm from the field of number theory.
    But, since the `mathematics` class tends to be applied less than `informatics`
    in the area of algorithms, the word **computer** comes up less frequently in the
    documents.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 那些高频出现**算法**和**计算机**词汇的文档属于`信息学`类。`数学`类的文档偶尔也包含大量的**算法**词汇，例如涉及欧几里得算法的数论领域的文档。但由于`数学`类在算法领域的应用较少，**计算机**一词在这些文档中的出现频率较低。
- en: 'We would like to classify a document that has 41 instances of the word **algorithm**
    per 1,000 words, and 42 instances of the word **computer** per 1,000 words:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要分类一份文档，该文档中每千字出现 41 次**算法**，每千字出现 42 次**计算机**：
- en: '![](img/d58149ae-c5d9-458e-b369-b2c2249c17dc.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d58149ae-c5d9-458e-b369-b2c2249c17dc.png)'
- en: Analysis
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析
- en: Using, for example, the 1-NN algorithm and the Manhattan or Euclidean distance
    would result in the document in question being assigned to the `mathematics` class.
    However, intuitively, we should instead use a different metric to measure the
    distance, as the document in question has a much higher incidence of the word
    **computer** than other known documents in the class of `mathematics`.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用 1-NN 算法和曼哈顿距离或欧几里得距离，结果会将该文档归类为 `mathematics` 类别。然而，直观上我们应该使用不同的度量方法来衡量文档之间的距离，因为该文档中的
    **computer** 词汇出现频率远高于其他已知的 `mathematics` 类文档。
- en: Another candidate metric for this problem is a metric that would measure the
    proportion of the for the words or the angle between the instances in documents.
    Instead of the angle, you could take the cosine of the angle, *cos(θ)*, and then
    use the well-known dot product formula to calculate *cos(θ)*.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可选的度量方法是，测量文档实例之间词汇的比例或角度。你可以使用角度的余弦值，*cos(θ)*，然后使用著名的点积公式来计算 *cos(θ)*。
- en: 'Let''s use *a=(a[x],a[y]), b=(b[x],b[y])*. Use the following formula:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 设我们使用 *a=(a[x],a[y]), b=(b[x],b[y])*，使用以下公式：
- en: '![](img/ec9b933f-2f8c-4aaa-89f8-f8a64ddcbe2a.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec9b933f-2f8c-4aaa-89f8-f8a64ddcbe2a.png)'
- en: 'This will derive the following:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得出以下结果：
- en: '![](img/39906b59-4478-4f29-82d0-66365f6a52bf.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/39906b59-4478-4f29-82d0-66365f6a52bf.png)'
- en: 'Using the cosine distance metric, you could classify the document in question
    to the `informatics` class:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用余弦距离度量方法，你可以将该文档归类为 `informatics` 类：
- en: '![](img/7c0a52f7-1e42-4cff-8f2c-d1ebc92ae0ec.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7c0a52f7-1e42-4cff-8f2c-d1ebc92ae0ec.png)'
- en: Text classification – k-NN in higher dimensions
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本分类 – 高维空间中的 k-NN
- en: 'Suppose we are given documents and would like to classify other documents based
    on their word frequency counts. For example, the 120 most frequently occurring
    words found in the Project Gutenberg e-book of the King James Bible are as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一些文档，并希望基于它们的词频来分类其他文档。例如，出现在《金色圣经》项目古腾堡电子书中的120个最常出现的词汇如下：
- en: '![](img/e554f3ad-cab2-4a87-8abe-af4546dde5c2.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e554f3ad-cab2-4a87-8abe-af4546dde5c2.png)'
- en: The task is to design a metric that, given the word frequencies for each document,
    would accurately determine how semantically close those documents are. Consequently,
    such a metric could be used by the k-NN algorithm to classify the unknown instances
    in the new documents based on the existing documents.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 任务是设计一种度量方法，给定每个文档的词频，能够准确判断这些文档在语义上的相似度。因此，这样的度量方法可以被 k-NN 算法用来基于现有文档对新文档中的未知实例进行分类。
- en: Analysis
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析
- en: Suppose that we consider, for example, *N* most frequent words in our corpus
    of documents. Then, we count the word frequencies for each of the *N* words in
    a given document and put them in an *N*-dimensional vector that will represent
    that document. Then, we define a distance between two documents to be the distance
    (for example, Euclidean) between the two-word frequency vectors of those documents.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们考虑，例如，语料库中最常出现的 *N* 个词。然后，我们统计每个 *N* 个词在给定文档中的出现频率，并将它们放入一个 *N* 维向量中，代表该文档。接着，我们定义两个文档之间的距离为这两个文档的词频向量之间的距离（例如，欧几里得距离）。
- en: 'The problem with this solution is that only certain words represent the actual
    content of the book, and others need to be present in the text because of grammar
    rules or their general basic meaning. For example, out of the 120 most frequently
    encountered words in the Bible, each word is of different importance. In the following
    table, we have highlighted the words that have both a high frequency in the Bible
    and an important meaning:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的问题在于，只有某些词汇才代表书籍的实际内容，其他词汇之所以出现在文本中，是因为语法规则或它们的一般基础意义。例如，在《圣经》中，120个最常出现的词语中，每个词的意义不同。下表中，我们标出了那些在《圣经》中既频繁出现又具有重要意义的词语：
- en: '|'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: lord - used 1.00%
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: lord - 使用频率 1.00%
- en: god - 0.56%
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: god - 0.56%
- en: '|'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Israel - 0.32%
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Israel - 0.32%
- en: king - 0.32%
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: king - 0.32%
- en: '|'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: David - 0.13%
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: David - 0.13%
- en: Jesus - 0.12%
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Jesus - 0.12%
- en: '|'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: These words are less likely to be present in mathematical texts, for example,
    but more likely to be present in texts concerned with religion or Christianity.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这些词汇在数学文本中出现的可能性较低，但在宗教或基督教相关的文本中出现的可能性较高。
- en: 'However, if we just look at the six most frequent words in the Bible, they
    happen to be less useful with regard to detecting the meaning of the text:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们只看《圣经》中六个最常见的词，它们在检测文本意义方面其实没有什么用：
- en: '|'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: the - 8.07%
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: the - 8.07%
- en: and - 6.51%
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: and - 6.51%
- en: '|'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: of - 4.37%
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: of - 4.37%
- en: to - 1.72%
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: to - 1.72%
- en: '|'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: that - 1.63%
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: that - 1.63%
- en: in - 1.60%
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: in - 1.60%
- en: '|'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Texts concerned with mathematics, literature, and other subjects will have similar
    frequencies for these words. Differences may result mostly from the writing style.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 与数学、文学及其他学科相关的文本，在这些词汇的频率上会有类似的表现。差异主要可能来源于写作风格。
- en: Therefore, to determine a similarity distance between two documents, we only
    need to look at the frequency counts of the important words. Some words are less
    important—these dimensions are better reduced, as their inclusion can lead to
    misinterpretation of the results in the end. Thus, what we are left to do is choose
    the words (dimensions) that are important to classify the documents in our corpus.
    For this, consult *Problem 6*.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了确定两个文档之间的相似性距离，我们只需要查看重要词汇的频率统计。一些词汇不太重要——这些维度最好减少，因为它们的包含可能最终导致结果的误解。因此，我们需要做的就是选择那些对分类文档至关重要的词汇（维度）。为此，请参考*问题
    6*。
- en: Summary
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned that the *k*-nearest neighbor algorithm is a classification
    algorithm that assigns the majority class among the *k*-nearest neighbors to a
    given data point. The distance between two points is measured by a metric. We
    covered examples of distances, including the Euclidean distance, Manhattan distance,
    tangential distance, and cosine distance. We also discussed how experiments with
    various parameters and cross-validation can help to establish which parameter, *k*, and
    which metric should be used.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解到*k*-最近邻算法是一种分类算法，它将给定数据点的*k*-最近邻中多数类别分配给该数据点。两个点之间的距离是通过度量来衡量的。我们介绍了几种距离的例子，包括欧几里得距离、曼哈顿距离、切线距离和余弦距离。我们还讨论了如何通过不同参数的实验和交叉验证，帮助确定应使用哪个参数*k*以及哪个度量。
- en: We also learned that the dimensionality and position of a data point are determined
    by its qualities. A large number of dimensions can result in low accuracy of the
    k-NN algorithm. Reducing the dimensions of qualities of lesser importance can
    increase accuracy. Similarly, to increase accuracy further, distances for each
    dimension should be scaled according to the importance of the quality of that
    dimension.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还学到了数据点的维度和位置是由其特征决定的。大量的维度可能导致k-NN算法的准确性较低。减少重要性较小的特征维度可以提高准确性。同样，为了进一步提高准确性，每个维度的距离应该根据该维度特征的重要性进行缩放。
- en: In the next chapter, we will look at the Naive Bayes algorithm, which classifies
    an element based on probabilistic methods using Bayes' theorem.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将讨论朴素贝叶斯算法，该算法基于贝叶斯定理使用概率方法对元素进行分类。
- en: Problems
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'In this section, we will discuss the following problems:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论以下问题：
- en: Mary and her temperature preference problems
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 玛丽和她的温度偏好问题
- en: Map of Italy – choosing the value of *k*
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 意大利地图 – 选择*k*的值
- en: House ownership
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 房屋所有权
- en: In order to learn from the material from this chapter in the best way possible,
    please analyze these problems on your own first before looking at the *Analysis*
    section at the end of this chapter.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尽可能最佳地学习本章的内容，请先独立分析这些问题，然后再查看本章末尾的*分析*部分。
- en: Mary and her temperature preference problems
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 玛丽和她的温度偏好问题
- en: '**Problem 1**: Imagine that you know that your friend Mary feels cold when
    it is -50°C, but she feels warm when it is 20°C. What would the 1-NN algorithm
    say about Mary? Would she feel warm or cold at temperatures of 22, 15, and -10?
    Do you think that the algorithm predicted Mary''s body''s perception of the temperature
    correctly? If not, please give your reasons and suggest why the algorithm did
    not give appropriate results and what would need to be improved for the algorithm
    to make a better classification.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 1**：假设你知道你的朋友玛丽在-50°C时感到寒冷，而在20°C时感到温暖。那么1-NN算法会怎么判断玛丽的感受呢？在22°C、15°C和-10°C的温度下，她会感到温暖还是寒冷？你认为算法预测玛丽对温度的感知是正确的吗？如果不是，请给出你的理由，并指出为什么算法没有给出合适的结果，以及需要改进哪些方面，以便算法能够做出更好的分类。'
- en: '**Problem 2**: Do you think that the 1-NN algorithm would yield better results
    than using the *k*-NN algorithm for *k*>1?'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 2**：你认为1-NN算法会比使用*k*-NN算法（其中*k*>1）产生更好的结果吗？'
- en: '**Problem 3**: We collected more data and found out that Mary feels warm at 17°C,
    but cold at 18°C. Using our own common sense, Mary should feel warmer when the
    temperature is higher. Can you explain the possible cause of the discrepancies
    in the data? How could we improve the analysis of our data? Should we also collect some
    non-temperature data? Suppose that we have the only piece of temperature data
    available; do you think that the *1*-NN algorithm would still yield better results
    with data like this? How should we choose *k* for the *k*-NN algorithm to perform
    well?'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 3**：我们收集了更多数据，发现玛丽在17°C时感觉温暖，在18°C时却感觉寒冷。根据我们自己的常识，温度越高，玛丽应该越觉得温暖。你能解释数据中不一致的可能原因吗？我们如何改进数据分析？我们是否也应该收集一些非温度数据？假设我们只有一条温度数据，你认为仅用这些数据，*1*-NN算法是否仍然能够得出更好的结果？我们应该如何选择*k*值来让*k*-NN算法表现得更好？'
- en: Map of Italy – choosing the value of k
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 意大利地图 – 选择k值
- en: '**Problem 4**: We are given a partial map of Italy for the Map of Italy problem.
    However, suppose that the complete data is not available. Thus, we cannot calculate
    the error rate on all of the predicted points for different values of *k*. How
    should you choose the value of *k* for the *k*-NN algorithm, to complete the map
    of Italy with a view to maximizing its accuracy?'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 4**：我们得到意大利部分地图用于意大利地图问题。然而，假设完整数据不可用。因此，我们无法对不同*k*值的所有预测点计算误差率。你应如何选择*k*值，来使用*k*-NN算法，完成意大利地图并最大化其准确性？'
- en: House ownership
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 房屋所有权
- en: '**Problem 5**: Using the data from the section concerned with the problem of
    house ownership, find the closest neighbor to Peter by using the Euclidean metric:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 5**：使用与房屋所有权问题相关部分的数据，通过欧几里得度量找出离彼得最近的邻居：'
- en: a) Without rescaling the data
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: a) 不进行数据重新缩放
- en: b) By using the scaled data
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: b) 使用缩放后的数据
- en: 'Is the closest neighbor in:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的邻居是否在：
- en: a) The same as the neighbor in?
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: a) 与该邻居相同？
- en: b) Which of the neighbors owns the house?
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: b) 哪个邻居拥有房屋？
- en: '**Problem 6**: Suppose you would like to find books or documents in Gutenberg''s
    corpus ([www.gutenberg.org](http://www.gutenberg.org/)) that are similar to a
    selected book from the corpus (for example, the Bible) by using a certain metric
    and the 1-NN algorithm. How would you design a metric measuring the similarity
    distance between the two books?'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 6**：假设你想通过某种度量和1-NN算法，在古腾堡语料库（[www.gutenberg.org](http://www.gutenberg.org/)）中找到与某本选定书籍（例如《圣经》）相似的书籍或文档。你会如何设计一种度量来衡量这两本书的相似度？'
- en: Analysis
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析
- en: '**Problem 1**: 8°C is closer to 20°C than to -50°C. So, the algorithm would
    classify Mary as feeling warm at -8°C. But this is not likely to be true if we
    use our common sense and knowledge. In more complex examples, we may be deluded
    by the results of the analysis and make false conclusions due to our lack of expertise.
    But remember that data science makes use of substantive and expert knowledge,
    not only data analysis. In order to draw sound conclusions, we should have a good
    understanding of the problem and our data.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 1**：8°C比-50°C更接近20°C。因此，算法会将玛丽在-8°C时归类为感觉温暖。但如果我们运用常识和知识，这种判断不太可能成立。在更复杂的例子中，由于我们缺乏专业知识，可能会被分析结果误导，得出错误的结论。但请记住，数据科学不仅仅依赖数据分析，还需要实际的专业知识。为了得出合理的结论，我们应该对问题和数据有深刻的理解。'
- en: The algorithm further says that at 22°C, Mary should feel warm, and there is
    no doubt in that, as 22°C is higher than 20°C, and a human being feels warmer
    with a higher temperature; again, a trivial use of our knowledge. For 15°C, the
    algorithm would deem Mary to feel warm, but if we use our common sense, we may
    not be that certain of this statement.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 算法进一步指出，在22°C时，玛丽应该感觉温暖，这是毫无疑问的，因为22°C高于20°C，人类在较高的温度下会感觉更温暖；这再次是我们常识的一个简单应用。对于15°C，算法会认为玛丽感觉温暖，但如果我们使用常识，可能无法对这个结论完全确信。
- en: To be able to use our algorithm to yield better results, we should collect more
    data. For example, if we find out that Mary feels cold at 14°C, then we have a
    data instance that is very close to 15° and, thus, we can guess with a higher
    degree of certainty that Mary would feel cold at a temperature of 15°.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够使用我们的算法得到更好的结果，我们应该收集更多数据。例如，如果我们发现玛丽在14°C时感到寒冷，那么我们就有一个与15°C非常接近的数据实例，因此，我们可以更有信心地推测玛丽在15°C时也会觉得寒冷。
- en: '**Problem 2**: The data we are dealing with is just one-dimensional and is
    also partitioned into two parts, cold and warm, with the following property: the
    higher the temperature, the warmer a person feels. Also, even if we know how Mary
    feels at the temperatures -40, -39, …, 39, and 40, we still have a very limited
    amount of data instances – just one for around every degree Celsius. For these
    reasons, it is best to just look at one closest neighbor.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 2**：我们处理的数据只是单维的，并且也分为两部分，冷和暖，具有以下特性：温度越高，人感觉越暖。即使我们知道Mary在温度-40、-39、…、39和40时的感觉，我们的数据实例仍然非常有限——大约每摄氏度只有一个实例。因此，最好只查看一个最接近的邻居。'
- en: '**Problem 3**: Discrepancies in the data can be caused by inaccuracies in the
    tests carried out. This could be mitigated by performing more experiments.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 3**：数据中的差异可能是由于进行的测试不准确所致。这可以通过进行更多实验来缓解。'
- en: 'Apart from inaccuracy, there could be other factors that influence how Mary
    feels: for example, the wind speed, humidity, sunshine, how warmly Mary is dressed
    (whether she has a coat on with jeans, or just shorts with a sleeveless top, or
    even a swimming suit), and whether she is wet or dry. We could add these additional
    dimensions (wind speed and how she is dressed) into the vectors of our data points.
    This would provide more, and better quality, data for the algorithm and, consequently,
    better results could be expected.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 除了不准确性，还有其他因素可能会影响Mary的感觉：例如风速、湿度、阳光、Mary的穿着（她是穿着外套和牛仔裤，还是仅仅穿着短裤和无袖上衣，甚至是泳衣），以及她是湿的还是干的。我们可以将这些附加维度（风速和她的穿着）添加到数据点的向量中。这将为算法提供更多且更高质量的数据，因此可以期望得到更好的结果。
- en: If we have only temperature data, but more of it (for example, 10 instances
    of classification for every degree Celsius), then we could increase the *k* value
    and look at more neighbors to determine the temperature more accurately. But this
    purely relies on the availability of the data. We could adapt the algorithm to
    yield the classification based on all the neighbors within a certain distance,
    *d*, rather than classifying based on the *k*-closest neighbors. This would make
    the algorithm work well in both cases when we have a lot of data within a close
    distance, and when we have just one data instance close to the instance that we
    want to classify.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只有温度数据，但数据量更多（例如，每摄氏度有10个分类实例），那么我们可以增加*k*值，查看更多的邻居以更准确地确定温度。但这纯粹依赖于数据的可用性。我们可以调整算法，使其基于某个距离*d*内的所有邻居来进行分类，而不是仅仅基于*k*个最接近的邻居进行分类。这将使算法在数据量较大且距离较近时以及数据实例与我们想要分类的实例距离较近时都能有效工作。
- en: '**Problem 4**: For this purpose, you can use cross-validation (consult the
    *Cross-validation* section in *Appendix A – Statistics*) to determine the value
    of *k* with the highest accuracy. You could separate the available data from the
    partial map of Italy into learning and test data, for example, 80% of the classified
    pixels on the map would be given to a k-NN algorithm to complete the map. Then,
    the remaining 20% of the classified pixels from the partial map would be used
    to calculate the percentage of pixels with the correct classification according
    to the k-NN algorithm.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 4**：为此，你可以使用交叉验证（请参考*附录 A – 统计学*中的*交叉验证*部分）来确定具有最高准确性的*k*值。例如，你可以将来自意大利部分地图的可用数据分为学习数据和测试数据，80%的分类像素将交给k-NN算法来完成地图。然后，剩余的20%分类像素将用于根据k-NN算法计算正确分类的像素百分比。'
- en: '**Problem 5**:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 5**：'
- en: a) Without data rescaling, Peter's closest neighbor has an annual income of
    USD 78,000 and is aged 25\. This neighbor does not own a house.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: a) 在没有数据重缩放的情况下，Peter最近的邻居年收入为78,000美元，年龄为25岁。这个邻居没有房子。
- en: b) After data rescaling, Peter's closest neighbor has an annual income of USD
    60,000 and is aged 40\. This neighbor owns a house.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: b) 在数据重缩放之后，Peter最近的邻居年收入为60,000美元，年龄为40岁。这个邻居拥有房子。
- en: '**Problem 6**: To design a metric that accurately measures the similarity distance
    between the two documents, we need to select important words that will form the
    dimensions of the frequency vectors for the documents. Words that do not determine
    the semantic meaning of documents tend to have an approximately similar frequency
    count across all documents. Thus, instead, we could produce a list with the relative
    word frequency counts for a document. For example, we could use the following
    definition:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 6**：为了设计一个准确衡量两个文档相似度距离的度量，我们需要选择能够构成文档频率向量维度的重要单词。那些不能确定文档语义意义的单词，通常在所有文档中具有大致相同的词频。因此，我们可以创建一个包含文档相对词频的列表。例如，我们可以使用以下定义：'
- en: '![](img/53ecdce7-22e4-4db7-95d3-283325d8a832.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/53ecdce7-22e4-4db7-95d3-283325d8a832.png)'
- en: Then, the document could be represented by an *N*-dimensional vector consisting
    of the word frequencies for *N* words with the highest relative frequency count.
    Such a vector will tend to consist of more important words than a vector of *N*
    words with the highest frequency count.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，文档可以通过一个*N*维向量来表示，该向量由*相对频率最高的*N*个单词的词频组成。这样的向量通常会包含比由*频率最高的*N*个单词组成的向量更重要的单词。
