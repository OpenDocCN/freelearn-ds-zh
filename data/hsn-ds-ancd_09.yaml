- en: Supervised Learning in Anaconda
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Anaconda中的监督学习
- en: 'Since most of us understand the format of the function *y=f(x)*, it is a good
    idea to use it to explain supervised learning. When having both *y* and *x*, we
    could run various regressions to identify the correct function forms. This is
    the spirit of supervised learning. For supervised learning, we have two datasets:
    the **training data** and **test data**. Usually, the training set has a set of
    input variables, such as *x*, and a related output value such as *y* (that is,
    the supervisory signal). A supervised learning algorithm analyzes the training
    data and produces an inferred function form. Then, we apply this inferred function
    to map our test dataset.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们大多数人都理解函数*y=f(x)*的格式，因此使用它来解释监督学习是一个不错的主意。当有了* y *和* x *时，我们可以进行各种回归分析，以识别正确的函数形式。这就是监督学习的精髓。对于监督学习，我们有两个数据集：**训练数据**和**测试数据**。通常，训练集包含一组输入变量，如*
    x *，以及相关的输出值，如* y *（即监督信号）。监督学习算法分析训练数据并生成推断的函数形式。然后，我们将这个推断的函数应用于映射我们的测试数据集。
- en: 'In this chapter, the following topics will be covered:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: A glance at supervised learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习概览
- en: Classification
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类
- en: Implementation of supervised learning via R, Python, Julia, and Octave
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过R、Python、Julia和Octave实现监督学习
- en: Task view for machine learning in R
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R中的机器学习任务视图
- en: A glance at supervised learning
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习概览
- en: In the previous chapter, we discussed unsupervised learning where we have input
    data only. In terms of the function *y=f(x)*, for unsupervised learning we have
    only inputs *x*. Unlike unsupervised learning, we have both inputs *x* and the
    corresponding output *y* for supervised learning. Our task is to find the best
    function, linking *x* with *y*, based on our training dataset. In supervised learning,
    our training dataset consists of an input object, typically a vector, and a desired
    output value, where it could be either binary, categorical, discrete, or continuous.
    A supervised learning algorithm examines a given training dataset and produces
    an inferred best-fit function. To verify the accuracy of this inferred function,
    we use the second dataset, the test set.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了无监督学习，其中我们只有输入数据。就函数* y = f(x)*而言，对于无监督学习，我们只有输入* x *。与无监督学习不同，监督学习有输入*
    x *和相应的输出* y *。我们的任务是基于训练数据集找到最佳的函数，将* x *与* y *联系起来。在监督学习中，我们的训练数据集包含一个输入对象，通常是一个向量，以及一个期望的输出值，可以是二进制、分类、离散或连续的。监督学习算法检查给定的训练数据集，并生成推断的最佳拟合函数。为了验证这个推断的函数的准确性，我们使用第二个数据集——测试集。
- en: In an ideal world, we would want to have a large sample size. However, for many
    occasions, this is not true. In those cases, we could apply the bootstrap method
    for estimating statistical quantities from samples. The **Bootstrap Aggregation**
    algorithm is used to create multiple different models from a single training dataset.
    Actually, random forest is a sort of nickname for *decision tree ensemble through
    bagging*. Because of this, it ends up with a very powerful classifier.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想情况下，我们希望拥有一个大的样本量。然而，在很多情况下，情况并非如此。在这些情况下，我们可以应用自助法（bootstrap）来估计统计量。**自助聚合（Bootstrap
    Aggregation）**算法用于从单个训练数据集中创建多个不同的模型。实际上，随机森林就是通过*袋装法（bagging）*将多个决策树集成的一个别名。正因如此，它最终形成了一个非常强大的分类器。
- en: 'Let''s use the famous Titanic tragedy as an example. In 1912, on its maiden
    voyage, the Titanic sank after striking an iceberg. Of its passengers and crew,
    more than 1,500 died. First, let''s look at the simple dataset. The following
    R code can be downloaded from the author''s website at [http://canisius.edu/~yany/RData/titanic.RData](http://canisius.edu/~yany/RData/titanic.RData):'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以著名的“泰坦尼克号”悲剧为例。1912年，泰坦尼克号在处女航行中撞上冰山沉没，超过1500名乘客和船员丧生。首先，让我们看一下这个简单的数据集。以下的R代码可以从作者的网站下载：[http://canisius.edu/~yany/RData/titanic.RData](http://canisius.edu/~yany/RData/titanic.RData)：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'From the preceding output, it can be seen that the dataset has `2,201` observations
    with just `4` variables. The `CLASS` is for cabin or economic status, `GENDER`
    is for gender, and `SURVIVED` indicates whether the passenger survived or not.
    The `unique()` function can be used to show their unique values, shown here:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从之前的输出中可以看到，该数据集包含`2,201`条观测值，且仅有`4`个变量。`CLASS`表示舱位或经济状态，`GENDER`表示性别，`SURVIVED`表示乘客是否幸存。`unique()`函数可以显示它们的唯一值，如下所示：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Our task is to use the decision tree to find the contributions of those three
    input variables to the survival rate. Let''s use the R package called `Rattle`
    to run a simple decision tree model by using the embedded dataset. To launch the
    `Rattle` package, we have the following two lines:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的任务是使用决策树来找出这三个输入变量对生还率的贡献。让我们使用名为`Rattle`的R包，通过使用内置数据集来运行一个简单的决策树模型。要启动`Rattle`包，我们可以使用以下两行代码：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The next screenshot shows how to choose a library and a related dataset. Note
    that, depending on the version, the dataset might not be available. An alternative
    way is to download from the author''s web page at [http://canisius.edu/~yany/RData/titanic.RData](http://canisius.edu/~yany/RData/titanic.RData).
    The default setting for the partition is 70% (training), 15% (verification), and
    15% (testing):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个截图展示了如何选择一个库和相关数据集。请注意，根据版本的不同，数据集可能不可用。另一种方式是从作者的网页下载：[http://canisius.edu/~yany/RData/titanic.RData](http://canisius.edu/~yany/RData/titanic.RData)。默认的分割设置是70%（训练集）、15%（验证集）和15%（测试集）：
- en: '![](img/b1deab5c-fea1-4335-9897-2a648e7b756d.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1deab5c-fea1-4335-9897-2a648e7b756d.png)'
- en: 'If we choose Model | Tree, and then Execute in the upper left corner, we will
    get the following result:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择模型 | 树，然后在左上角点击执行，我们将得到以下结果：
- en: '![](img/7dcd68d4-ee7d-4ae0-8f2a-f9767065bfc6.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7dcd68d4-ee7d-4ae0-8f2a-f9767065bfc6.png)'
- en: The top ratio of **68%** is for the rate of those who did not survive while
    the **32%** is for the survival rate. The first question is whether the passenger
    is a male or not. If the answer is a yes, then the person would have a **21%**
    chance of survival, shown in the lower-left leaf. For a female passenger who booked
    a cabin of **Class 3**, she would have a **44%** chance of survival. For female
    passengers, when they occupy a first- or second-class cabin, she would have a
    **91%** chance of survival. Since the age does not appear in our final result,
    the model considers it useless.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**68%**的最高比例代表未生还者，而**32%**则代表幸存率。第一个问题是乘客是否为男性。如果答案是肯定的，那么这个人将有**21%**的生还机会，显示在左下叶子上。对于预定了**3级舱**的女性乘客，她将有**44%**的生还机会。对于女性乘客，当她们占据一等或二等舱时，她们的生还机会将高达**91%**。由于年龄没有出现在我们的最终结果中，模型认为它没有用。'
- en: 'Note that if you plan to use the loaded dataset called `.titanic`, you could
    use `x<-.titanic`, and then choose it by selecting R Dataset after Rattle is launched.
    For different associated datasets with more variables, it is not a surprise that
    users could reach different conclusions. You can save the log, that is, the code,
    for a later usage. The simplified code is given here. The log is on the Rattle
    menu bar:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果你打算使用名为`.titanic`的加载数据集，你可以使用`x<-.titanic`，然后在Rattle启动后选择R数据集。对于具有更多变量的不同相关数据集，用户得出不同结论并不奇怪。你可以保存日志，即代码，以供日后使用。简化的代码如下所示。日志位于Rattle菜单栏：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The second example is associated with the dataset called `iris`. This time,
    the language used is Python. First, let''s look at the data itself. The code and
    related output is shown here:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个示例与名为`iris`的数据集相关。这一次，使用的编程语言是Python。首先，让我们查看数据本身。代码和相关输出如下所示：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output would look like follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The dataset has five variables: sepal length, sepal width, petal length, petal
    width (all in cm), and class. The last one has three unique values for Setosa,
    Versicolour, or Virginica; see [https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris)
    for more information. The first several lines of the original dataset are shown
    here:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集有五个变量：花萼长度、花萼宽度、花瓣长度、花瓣宽度（均为厘米），以及类别。最后一个变量有三个唯一值，分别为Setosa、Versicolour和Virginica；更多信息请参见[https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris)。原始数据集的前几行如下所示：
- en: '![](img/a76421af-aa95-4003-8ab6-b768c25ef469.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a76421af-aa95-4003-8ab6-b768c25ef469.png)'
- en: 'The dataset can be downloaded from the UCI Machine Learning Repository: [https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data).
    First, let''s cut the dataset into a training and testing set. Then we use supervised
    learning to figure out the mapping function, that is, an inferred function:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以从UCI机器学习库下载：[https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data)。首先，我们将数据集切分为训练集和测试集。然后，使用监督学习来找出映射函数，即推断函数：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is shown here:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Classification
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类
- en: 'Supervised learning problems can be further divided into two groups: **classification**
    and **regression**. For the classification problem, the output variable, such
    as *y*, could be a binary variable, that is, 0 or 1, or several categories. For
    a regression, variables or values could be discrete or continuous. In the Titanic
    example, we have 1 for survived and 0 for not survived. For a regression problem,
    the output could be a value, such as, 2.5 or 0.234\. In the previous chapter,
    we discussed the concept of distance between group members within the same group
    and between groups.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习问题可以进一步分为两类：**分类**和**回归**。对于分类问题，输出变量（如*y*）可以是二元变量，即0或1，或多个类别。对于回归问题，变量或值可以是离散的或连续的。在泰坦尼克号的例子中，1表示生还，0表示未生还。对于回归问题，输出可能是一个值，例如2.5或0.234。在上一章中，我们讨论了同一组内成员之间的距离以及不同组之间的距离概念。
- en: 'The logic for classification is that the distance between (among) group members
    is shorter than the distance between different groups. Alternatively speaking,
    the similarity between (among) group members is higher than the similarity between
    (among) different groups or categories. Since categorical data cannot be ranked,
    we could use the following method to group them:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 分类的逻辑是，同组成员之间的距离比不同组之间的距离要短。换句话说，同组成员之间的相似度高于不同组或类别之间的相似度。由于类别数据无法排序，我们可以使用以下方法对其进行分组：
- en: '![](img/2adc625e-b24f-4b4c-a061-01ed4fb3e47d.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2adc625e-b24f-4b4c-a061-01ed4fb3e47d.png)'
- en: Here, *n[matched]* is the number of matched treatments and *n[total]* is the
    number of total treatments. When both categorical data and numeric data are available,
    we could estimate both types of distances first and then choose appropriate weights
    to combine them.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*n[matched]* 是匹配的治疗数，*n[total]* 是治疗总数。当同时有类别数据和数值数据时，我们可以首先估算两种类型的距离，然后选择适当的权重来将它们组合起来。
- en: 'Assume *d[num]* is for the distance based on the numerical data and *d[cat]*
    is for the distance based on the categorical data. Then, we have the following
    combined distance:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 假设*d[num]* 是基于数值数据的距离，*d[cat]* 是基于类别数据的距离。那么，我们得到以下的综合距离：
- en: '![](img/7ae7f744-791d-44da-b3e0-b20c7835aa9f.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7ae7f744-791d-44da-b3e0-b20c7835aa9f.png)'
- en: Here, *w[num]* is the weight for the numerical value.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*w[num]* 是数值的权重。
- en: The k-nearest neighbors algorithm
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: k-最近邻算法
- en: 'In pattern recognition or grouping, the **k-nearest neighbors** (**k-NN**) algorithm
    is a non-parametric method implemented for classification and regression. For
    those two cases, the input consists of the k-closest training examples in the
    feature space. The following four lines of R code tries to separate plants into
    k-groups by using a dataset called `iris`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在模式识别或分组中，**k-最近邻**（**k-NN**）算法是一种用于分类和回归的非参数方法。对于这两种情况，输入由特征空间中k个最接近的训练样本组成。以下四行R代码尝试通过使用名为`iris`的数据集将植物分成k组：
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The graph is shown here:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示如下：
- en: '![](img/d75fcb5b-c007-4b03-85cd-6df7336f2c57.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d75fcb5b-c007-4b03-85cd-6df7336f2c57.png)'
- en: 'The following diagram shows the five nearest neighbors:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了五个最近邻：
- en: '![](img/7650430a-6ca4-4ab8-90d7-009957e9c655.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7650430a-6ca4-4ab8-90d7-009957e9c655.png)'
- en: 'The code generated by the five nearest neighbors is given here. The code is
    slightly modified from the code offered by others at [https://stats.stackexchange.com/questions/21572/how-to-plot-decision-boundary-of-a-k-nearest-neighbor-classifier-from-elements-o/21602#21602](https://stats.stackexchange.com/questions/21572/how-to-plot-decision-boundary-of-a-k-nearest-neighbor-classifier-from-elements-o/21602#21602):'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里给出了由五个最近邻生成的代码。该代码稍微修改自其他人提供的代码，来源于[https://stats.stackexchange.com/questions/21572/how-to-plot-decision-boundary-of-a-k-nearest-neighbor-classifier-from-elements-o/21602#21602](https://stats.stackexchange.com/questions/21572/how-to-plot-decision-boundary-of-a-k-nearest-neighbor-classifier-from-elements-o/21602#21602)：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For more details about each function, readers can find the related manual regarding
    the `ElemStatLearn` package.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 关于每个函数的更多详细信息，读者可以查阅`ElemStatLearn`包的相关手册。
- en: Bayes classifiers
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯分类器
- en: 'This is a classification technique based on Bayes theorem with an assumption
    of independence among predictors. In layman''s terms, a naive Bayes classifier
    assumes that the presence of a particular feature in a class is unrelated to the
    presence of any other feature. First, let''s look at the `HouseVotes84` dataset:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种基于贝叶斯定理的分类技术，假设预测变量之间相互独立。通俗来说，朴素贝叶斯分类器假设某个特征在某一类别中的出现与该类别中其他特征的出现无关。首先，让我们来看一下`HouseVotes84`数据集：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output is shown in the following screenshot:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '![](img/221910c7-5292-48d0-88f0-3cc7cd0d0102.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/221910c7-5292-48d0-88f0-3cc7cd0d0102.png)'
- en: 'The first variable, `Class`, is a binary one: `republican` or `democrat`. In
    addition, we have 16 traits associated with each individual. The following program
    calls the `naiveBayes()` function which computes the conditional a-posterior probabilities
    of a categorical class variable given independent predictor variables using the
    Bayes rule:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个变量 `Class` 是二元的：`republican` 或 `democrat`。此外，我们有与每个个体相关的 16 个特征。以下程序调用了 `naiveBayes()`
    函数，利用贝叶斯规则计算给定独立预测变量时，分类类变量的条件后验概率：
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The final output is given here:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最终输出如下所示：
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The next example is to predict the survival rate by applying the naive Bayes
    methodology to the Titanic dataset:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例是通过应用朴素贝叶斯方法来预测泰坦尼克号数据集的生还率：
- en: '[PRE13]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is shown here:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE14]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: From the previous output, we could find the final prediction in terms of 32
    individuals.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中，我们可以找到关于 32 个个体的最终预测。
- en: Reinforcement learning
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习
- en: Reinforcement learning is a wonderful research area of machine learning. It
    has a root from behavioral psychology. The mechanism would maximize some notion
    of cumulative reward when certain actions were taken in a set of environments
    (that is, an agent tries to learn optimal behavior through trial-and-error interactions
    within a dynamic environment setting).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是机器学习的一个精彩研究领域，它起源于行为心理学。其机制是在一组环境中采取某些行动时，最大化某种累积奖励的概念（也就是说，智能体通过在动态环境设置中的反复试验与互动来学习最优行为）。
- en: 'Let''s use an R package called `ReinforcementLearning`. First, let''s look
    at the dataset, shown here:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用一个叫做 `ReinforcementLearning` 的 R 包。首先，查看如下数据集：
- en: '[PRE15]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The function called `sampleGridSequence()` is used to generate *n* observations.
    The `State` and `NextState` variables have four unique values: `s1`, `s2`, `s3`,
    and `s4`. The variable, `Action`, has four values: `left`, `right`, `down`, and
    `up`. The variable, `Award`, has two unique values of `-1` and `10`, and we could
    view `-1` as a punishment and `10` as a reward. For the first observation, if
    our current and next state is `s2` and our action is `left`, we would suffer a
    `-1` penalty. The following result shows that if the next status is the same as
    our current one, no matter what our action would take, we would always have a
    negative penalty:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 调用的函数 `sampleGridSequence()` 用于生成 *n* 个观测值。`State` 和 `NextState` 变量有四个独特的值：`s1`、`s2`、`s3`
    和 `s4`。变量 `Action` 有四个值：`left`、`right`、`down` 和 `up`。变量 `Award` 有两个独特的值 `-1` 和
    `10`，我们可以将 `-1` 视为惩罚，将 `10` 视为奖励。对于第一个观测，如果当前状态和下一个状态是 `s2`，我们的动作是 `left`，那么我们将遭受
    `-1` 的惩罚。以下结果显示，如果下一个状态与当前状态相同，不论我们的行动是什么，我们总会受到负面惩罚：
- en: '[PRE16]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The question is, when at a different state, what is the optimal action we should
    take? For example, at the `s1` state, should we move `left`, `right`, `up`, or
    `down`? Note that the `set.seed()` function is used to guarantee that every user
    would get the same result if they use the same random seed of `123`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，当处于不同的状态时，我们应该采取什么最优行动？例如，在 `s1` 状态下，我们应该选择 `left`、`right`、`up` 还是 `down`？请注意，`set.seed()`
    函数用于确保每个用户在使用相同随机种子 `123` 时得到相同的结果：
- en: '[PRE17]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is shown here:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE18]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Implementation of supervised learning via R
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 R 实现监督学习
- en: 'As we have discussed in the previous chapter, the best choice to conduct various
    tests for supervised learning is applying an R package called `Rattle`. Here,
    we show two more examples. Let''s first look at the `iris` dataset:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在上一章讨论的那样，进行各种监督学习测试的最佳选择是使用一个叫做 `Rattle` 的 R 包。这里，我们展示两个更多的例子。首先来看一下 `iris`
    数据集：
- en: '[PRE19]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The next example is using the `diabetes` dataset, shown in the screenshot here:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例是使用 `diabetes` 数据集，截图如下所示：
- en: '![](img/e3bc511f-0ba3-494d-82e6-28b475bc696f.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e3bc511f-0ba3-494d-82e6-28b475bc696f.png)'
- en: 'For example, we could choose the logistic model after clicking Model on the
    menu bar. After clicking on Execute, we would have the following output:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在菜单栏点击 Model 后，我们可以选择逻辑回归模型。点击 Execute 后，我们将得到以下输出：
- en: '![](img/b268ab90-54a9-4cca-a904-755a84f47845.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b268ab90-54a9-4cca-a904-755a84f47845.png)'
- en: Based on the significant level of p-values, we could see that in addition to
    the intercept, `x1`*,* `x2`*,* `x3`, and `x6` are statistically significant.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 p 值的显著性水平，我们可以看到，除了截距外，`x1`*，* `x2`*，* `x3` 和 `x6` 在统计上是显著的。
- en: 'The next example is from the R package called `LogicReg`. The code is given
    here:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例来自名为`LogicReg`的R包。代码如下：
- en: '[PRE20]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The related graph is shown here. Again, the `set.seed()` function is used for
    an easy replication. If the user omits the function or chooses a different seed,
    they would get quite a different result:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 相关图表如下。再次使用`set.seed()`函数便于复制。如果用户省略此函数或选择不同的种子值，则可能得到完全不同的结果：
- en: '![](img/4033da8d-3a63-4da6-a1c3-f4b6e0bdd52f.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4033da8d-3a63-4da6-a1c3-f4b6e0bdd52f.png)'
- en: Introduction to RTextTools
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RTextTools简介
- en: 'This R package is about *Automatic Text Classification via Supervised Learning*.
    It is a machine learning package for automatic text classification that makes
    it simple for novice users to get started with machine learning, while allowing
    experienced users to easily experiment with different settings and algorithm combinations.
    The package includes nine algorithms for ensemble classification (svm, slda, boosting,
    bagging, random forests, glmnet, decision trees, neural networks, and maximum
    entropy), comprehensive analytics, and thorough documentation. Here, we use the
    New York Times Times article as an example. First, let''s look at the data:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个R包是关于*自动文本分类通过监督学习*的。它是一个自动文本分类的机器学习包，简化了新手用户的入门，同时也允许经验丰富的用户轻松地尝试不同的设置和算法组合。该包包含九种集成分类算法（svm、slda、boosting、bagging、随机森林、glmnet、决策树、神经网络和最大熵），综合分析功能，以及全面的文档。这里，我们以《纽约时报》文章为例。首先，让我们查看数据：
- en: '[PRE21]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'When running the program, users should move this line. The output is shown
    here:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 运行程序时，用户应删除此行。输出如下：
- en: '![](img/7d443ffe-6d78-497b-b684-adca1173d118.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7d443ffe-6d78-497b-b684-adca1173d118.png)'
- en: 'Next, we could look at the types of existing algorithms by using the `print_algorithms()`
    function, shown in the code and output here:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用`print_algorithms()`函数查看现有算法的类型，以下是代码和输出：
- en: '[PRE22]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `BAGGING` is for zbc, `BOOSTING` is the bbb, `GLMNET` is for the general
    linear model, `MAXENT` is for maximum entropy model, `NNET` is for neural network,
    `RF` is for random forest, `SLDA` is for supervised machine learning algorithms,
    `SVM` is for support vector machine, and `TREE` is for decision trees. The code
    is shown here:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`BAGGING`用于zbc，`BOOSTING`用于bbb，`GLMNET`用于一般线性模型，`MAXENT`用于最大熵模型，`NNET`用于神经网络，`RF`用于随机森林，`SLDA`用于监督学习算法，`SVM`用于支持向量机，`TREE`用于决策树。代码如下：'
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Implementation via Python
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过Python实现
- en: 'In the previous chapter related to unsupervised learning, we have learnt about
    several Python packages. Fortunately, these packages can be applied to supervised
    learning algorithms as well. The following example is for a linear regression
    by using a few Python datasets. The Python dataset can be downloaded from the
    author''s website at [http://www.canisius.edu/~yany/python/ffcMonthly.pkl](http://www.canisius.edu/~yany/python/ffcMonthly.pkl).
    Assume that the data is saved under `c:/temp/`:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章有关无监督学习的内容中，我们已经学习了几种Python包。幸运的是，这些包也可以应用于监督学习算法。以下示例是使用一些Python数据集进行线性回归。Python数据集可以从作者的网站下载，地址为[http://www.canisius.edu/~yany/python/ffcMonthly.pkl](http://www.canisius.edu/~yany/python/ffcMonthly.pkl)。假设数据保存在`c:/temp/`目录下：
- en: '[PRE24]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is shown here:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/94d8d082-d81d-4027-9c23-f028ee1ad464.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/94d8d082-d81d-4027-9c23-f028ee1ad464.png)'
- en: 'We plan to run a linear regression; see the formula here:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计划运行线性回归；请参见公式：
- en: '![](img/8440dd65-eba0-4a2c-9086-19b30ad726e5.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8440dd65-eba0-4a2c-9086-19b30ad726e5.png)'
- en: 'Here, *R[i]* is stock i''s returns, *R[mkt]* is the *market returns*, *R[SMB]*
    is the *portfolio returns of small stocks* minus the *portfolio returns of big
    stocks*, *R[HML]* is the *portfolio returns with high book-to-market ratio* (of
    equity) minus the *portfolio returns of stocks with low book-to-market ratio*.
    The Python program is given next. Note that the Python dataset called `ffDaily.pkl`
    is downloadable at [http://canisius.edu/~yany/python/data/ffDaily.pkl](http://canisius.edu/~yany/python/data/ffDaily.pkl):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*R[i]* 是股票i的收益，*R[mkt]* 是*市场收益*，*R[SMB]* 是*小盘股投资组合收益*减去*大盘股投资组合收益*，*R[HML]*
    是*高账面市值比投资组合收益*（股票）减去*低账面市值比股票投资组合收益*。以下是给出的Python程序。请注意，名为`ffDaily.pkl`的Python数据集可以从[http://canisius.edu/~yany/python/data/ffDaily.pkl](http://canisius.edu/~yany/python/data/ffDaily.pkl)下载：
- en: '[PRE25]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output is shown here:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/e060f888-3d56-4194-8fc3-18ddbe658dd5.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e060f888-3d56-4194-8fc3-18ddbe658dd5.png)'
- en: 'The next example predicts `iris` categories. The code is given first:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例预测`iris`类别。首先给出代码：
- en: '[PRE26]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The nice output is shown here:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 美观的输出在此展示：
- en: '![](img/53ba7d27-ecb4-4f1e-a0a4-028bc4f77698.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/53ba7d27-ecb4-4f1e-a0a4-028bc4f77698.png)'
- en: Using the scikit-learn (sklearn) module
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用scikit-learn（sklearn）模块
- en: 'The following example is borrowed from [http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py](http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py).
    The program uses the `scikit-learn` module to recognize images of handwritten
    digits. The slightly modified code, for an easy presentation, is shown here:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下例子借鉴自[http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py](http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py)。该程序使用`scikit-learn`模块来识别手写数字的图像。为了便于展示，稍作修改后的代码如下所示：
- en: '[PRE27]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Part of the output is shown here:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 部分输出在此展示：
- en: '![](img/1bfeae7f-59b4-4887-8bf0-ab8655bc2bd6.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1bfeae7f-59b4-4887-8bf0-ab8655bc2bd6.png)'
- en: Implementation via Octave
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过Octave实现
- en: 'The next example of running a linear regression and the related datasets could
    be downloaded at [http://canisius.edu/~yany/data/c9_input.csv](http://canisius.edu/~yany/data/c9_input.csv).
    In the following program, the input data set is assumed to be under `c:/temp`:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个线性回归的例子及相关数据集可以在[http://canisius.edu/~yany/data/c9_input.csv](http://canisius.edu/~yany/data/c9_input.csv)下载。在以下程序中，假设输入数据集位于`c:/temp`：
- en: '[PRE28]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The first graph is shown here:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个图在此展示：
- en: '![](img/42a08750-02e4-427a-8b3b-581c3e0f3ab9.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/42a08750-02e4-427a-8b3b-581c3e0f3ab9.png)'
- en: 'To save space, the long program will not be shown here. Interested readers
    can use the previous link. However, its output graph is shown instead:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为节省空间，长程序将在此不显示。有兴趣的读者可以使用前面的链接。这里展示的是其输出图：
- en: '![](img/68d39b45-54a0-4a1c-b57f-a9aeefb5561f.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/68d39b45-54a0-4a1c-b57f-a9aeefb5561f.png)'
- en: 'For the next example, we download an Octave machine library at [https://github.com/partharamanujam/octave-ml](https://github.com/partharamanujam/octave-ml).
    Assume that the location of the directory is `C:\Octave\octave-ml-master` and
    the related `octavelib` is `C:\Octave\octave-ml-master\octavelib`. Then we add
    its path to our Octave program with the following one-liner:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于下一个例子，我们下载一个Octave机器库，地址为[https://github.com/partharamanujam/octave-ml](https://github.com/partharamanujam/octave-ml)。假设目录的位置是`C:\Octave\octave-ml-master`，相关的`octavelib`目录为`C:\Octave\octave-ml-master\octavelib`。然后，我们使用以下单行命令将其路径添加到Octave程序中：
- en: '[PRE29]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'There are many useful programs included under the subdirectory. Note that the
    `.m` extensions are all removed in the following table for brevity. Some useful
    programs included in the directory are presented in the table here:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 子目录下包含许多有用的程序。为了简便起见，以下表格中已移除`.m`扩展名。目录中包含的一些有用程序如下表所示：
- en: '| addBiasTerm | kMeansClosestCentroids |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| addBiasTerm | kMeansClosestCentroids |'
- en: '| choosePolynomialForLinearGradDesc | kMeansComputeCentroids |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| choosePolynomialForLinearGradDesc | kMeansComputeCentroids |'
- en: '| chooseRBFParamsForSVM | kMeansCostFunction |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| chooseRBFParamsForSVM | kMeansCostFunction |'
- en: '| chooseRegularizationForLinearGradDesc | kMeansInitCentroids |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| chooseRegularizationForLinearGradDesc | kMeansInitCentroids |'
- en: '| chooseRegularizationForLogisticGradDesc | linearRegressionCostFunction |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| chooseRegularizationForLogisticGradDesc | linearRegressionCostFunction |'
- en: '| collaborativeFilteringCostFunction | logisticRegressionCostFunction |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| collaborativeFilteringCostFunction | logisticRegressionCostFunction |'
- en: '| computeCoFiParamsByGradDescFmincg | logisticRegressionOneVsAllError |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| computeCoFiParamsByGradDescFmincg | logisticRegressionOneVsAllError |'
- en: '| computeGaussianParams | logisticRegressionOneVsAllTheta |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| computeGaussianParams | logisticRegressionOneVsAllTheta |'
- en: '| computeMultivarGaussianDistribution | normalizeRatings |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| computeMultivarGaussianDistribution | normalizeRatings |'
- en: '| computePCA | porterStemmer |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| computePCA | porterStemmer |'
- en: '| computeScalingParams | predictByLinearGradDesc |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| computeScalingParams | predictByLinearGradDesc |'
- en: '| computeThetaByLinearGradDescFminunc | predictByLogisticGradDescOneVsAll |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| computeThetaByLinearGradDescFminunc | predictByLogisticGradDescOneVsAll |'
- en: '| computeThetaByLogisticGradDescFminunc | predictByNormalEquation |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| computeThetaByLogisticGradDescFminunc | predictByNormalEquation |'
- en: '| computeThetaByNormalEquation | projectPCAData |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| computeThetaByNormalEquation | projectPCAData |'
- en: '| computeThresholdForMultivarGaussian | recoverPCAData |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| computeThresholdForMultivarGaussian | recoverPCAData |'
- en: '| fmincg | scaleFeatures |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| fmincg | scaleFeatures |'
- en: '| generateFeaturesPolynomial | sigmoid |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| generateFeaturesPolynomial | sigmoid |'
- en: '| generateKMeansClusters |  |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| generateKMeansClusters |  |'
- en: '| generateKMeansClustersMinCost |  |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| generateKMeansClustersMinCost |  |'
- en: Table 9.1 Supporting Octave programs under the octavelib directory
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.1 支持Octave程序位于octavelib目录下
- en: 'In addition, the sample programs and their related input datasets are included
    under the subdirectory called `examples` (see the following table):'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，示例程序及其相关输入数据集包含在名为`examples`的子目录下（见下表）：
- en: '| **Programs** | **Dataset(s)** |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| **程序** | **数据集** |'
- en: '| cofi.m | movieList.mat |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| cofi.m | movieList.mat |'
- en: '| extractEmailFeatures.m | email-sample-1.txtemail-sample-2.txtemail-sample-3.txt
    |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| extractEmailFeatures.m | email-sample-1.txtemail-sample-2.txtemail-sample-3.txt
    |'
- en: '| gaussian_m.m | anomaly.dat |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| gaussian_m.m | anomaly.dat |'
- en: '| initEnv.m | Note: setup program |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| initEnv.m | 注：设置程序 |'
- en: '| k_means.m | bird_small.png |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| k_means.m | bird_small.png |'
- en: '| linear_gd.m | damlevels.mat |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| linear_gd.m | damlevels.mat |'
- en: '| logistic_gd.m | numbers.mat |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| logistic_gd.m | numbers.mat |'
- en: '| normal_eq.m | prices.csv |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| normal_eq.m | prices.csv |'
- en: '| pca.m | faces.mat |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| pca.m | faces.mat |'
- en: '| svm.m | spam-vocab.txt |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| svm.m | spam-vocab.txt |'
- en: Table 9.2 Examples and their related datasets
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.2 示例及其相关数据集
- en: 'Let''s look at the following program for k-means. The original program is called
    `k_means.m` and its input photo is `bird_small.png`. The program tries to save
    space for a given picture by using the k-means method:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下以下的k-means程序。原始程序叫做`k_means.m`，它的输入图像是`bird_small.png`。该程序尝试通过使用k-means方法为给定的图片节省空间：
- en: '[PRE30]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The related two photos are shown here:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 相关的两张照片如下所示：
- en: '![](img/4ba844d4-d7ef-42c9-be45-be91b422ac59.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4ba844d4-d7ef-42c9-be45-be91b422ac59.png)'
- en: Implementation via Julia
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过Julia的实现
- en: 'The first example uses the familiar dataset called `iris` again. Using the
    `kmeans()` function, the program tries to group these plants:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个示例再次使用熟悉的数据集`iris`。通过使用`kmeans()`函数，程序尝试将这些植物进行分组：
- en: '[PRE31]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The related output is shown here:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 相关的输出如下所示：
- en: '![](img/0b5d7032-066f-46f9-b30c-f85d7123baa6.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0b5d7032-066f-46f9-b30c-f85d7123baa6.png)'
- en: 'For the next example, we try to sort a set of random numbers into `20` clusters.
    The code is shown here:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 对于下一个例子，我们尝试将一组随机数字分成`20`个簇。代码如下所示：
- en: '[PRE32]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'To show the value of `x` and `clusters`, we simply type them on the command
    line, shown here:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了显示`x`和`clusters`的值，我们只需在命令行中输入它们，如下所示：
- en: '![](img/ef6bb11b-21c2-42a0-a54d-0142c1756d00.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef6bb11b-21c2-42a0-a54d-0142c1756d00.png)'
- en: Task view for machine learning in R
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务视图：R中的机器学习
- en: 'From the previous chapters, we know that there are about three dozen task views
    for different topics. A task view is a set of R packages around a specific topic
    such as finance, econometrics, and the like. In the previous chapter, we briefly
    discussed the task view for clustering. There is no task view with a name of supervised
    learning. Instead, the closest one will be the machine learning task view; see
    the screenshot here for the top part:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的章节中，我们知道不同主题大约有三十多个任务视图。任务视图是围绕特定主题（如金融、计量经济学等）的一组R包。在上一章中，我们简要讨论了聚类任务视图。没有以“监督学习”为名的任务视图。相反，最接近的任务视图是机器学习任务视图；请参见这里的截图（上部）：
- en: '![](img/b14b3127-1f80-4d80-838c-34d07f1f0024.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b14b3127-1f80-4d80-838c-34d07f1f0024.png)'
- en: 'The URL is given in the preceding screenshot. Again, we could issue just three
    lines of R code to install the R packages included in the task view:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 上述截图给出了URL。再次强调，我们可以仅使用三行R代码来安装任务视图中包含的R包：
- en: '[PRE33]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: About 105 related R packages were installed as of April 3, 2018.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2018年4月3日，约105个相关的R包已被安装。
- en: Summary
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have discussed supervised learning, such as classification,
    the k-nearest neighbors algorithm, Bayes classifiers, reinforcement learning,
    and the `RTextTools` and `sklearn` modules in R. In addition, we discussed implementations
    of supervised learning via R, Python, Julia, and Octave.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了监督学习，如分类、k近邻算法、贝叶斯分类器、强化学习以及R中的`RTextTools`和`sklearn`模块。此外，我们还讨论了通过R、Python、Julia和Octave实现监督学习。
- en: For the next chapter, we will discuss predictive data analytics, modeling and
    validation, some useful datasets, time-series analytics, how to predict the future,
    seasonality, and how to visualize our data. For Python packages, we will mention `predictives-models-building`, `model-catwalk`,
    and `easyML`. For R packages, we will discuss `datarobot`, `LiblineaR`, `eclust`,
    and `AppliedPredictiveModeling`. For Julia packages, we will explain `EmpiricalRisks` and `ValidatedNumerics`.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论预测数据分析、建模与验证、一些有用的数据集、时间序列分析、如何预测未来、季节性以及如何可视化我们的数据。对于Python包，我们将提到`predictives-models-building`、`model-catwalk`和`easyML`。对于R包，我们将讨论`datarobot`、`LiblineaR`、`eclust`和`AppliedPredictiveModeling`。对于Julia包，我们将解释`EmpiricalRisks`和`ValidatedNumerics`。
- en: Review questions and exercises
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复习问题和练习
- en: What does *unsupervised learning* mean?
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*无监督学习*是什么意思？'
- en: What is the major difference between unsupervised learning and supervised learning?
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无监督学习和监督学习之间的主要区别是什么？
- en: How do we install the Python package `sklearn`?
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何安装Python包`sklearn`？
- en: Discuss the relationship between distance and clustering classification.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 讨论距离和聚类分类之间的关系。
- en: What does Bayes classification mean?
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 贝叶斯分类是什么意思？
- en: Find out the related functions for Bayes classification in R, Python, Octave,
    and Julia.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找R、Python、Octave和Julia中与贝叶斯分类相关的函数。
- en: How many R packages are installed after you run the following three lines of
    R code?
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在运行以下三行R代码后，安装了多少个R包？
- en: '[PRE34]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Download the IBM monthly data from Yahoo!Finance, [https://finance.yahoo.com](https://finance.yahoo.com) .
    Then run a Fama-French-Carhart four factor model by using Python. The 4-factor
    model is given here:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Yahoo!Finance下载IBM的月度数据，[https://finance.yahoo.com](https://finance.yahoo.com)。然后使用Python运行Fama-French-Carhart四因子模型。四因子模型在此给出：
- en: '![](img/c8c7fbb6-7041-4152-92a6-7229f522dc89.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c8c7fbb6-7041-4152-92a6-7229f522dc89.png)'
- en: The Python dataset related to those 4-factors can be downloaded from the author's
    website at [http://www.canisius.edu/~yany/python/ffcMonthly.pkl](http://www.canisius.edu/~yany/python/ffcMonthly.pkl).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 与这四个因子相关的Python数据集可以从作者的网站下载，[http://www.canisius.edu/~yany/python/ffcMonthly.pkl](http://www.canisius.edu/~yany/python/ffcMonthly.pkl)。
- en: 'Download the famous iris data set from the UCI Machine Learning Repository.
    The first several lines are given here:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从UCI机器学习库下载著名的鸢尾花数据集。以下是前几行数据：
- en: '![](img/276edafe-1193-447d-adbf-ea0e95089b47.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/276edafe-1193-447d-adbf-ea0e95089b47.png)'
- en: Then generate data sets for both R and Python.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 然后为R和Python生成数据集。
- en: To implement machine learning using Octave, how is the usage of the `octavelib` library
    introduced and used in the chapter? How many programs are under it?
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使用Octave实现机器学习，本章中如何引入并使用`octavelib`库？该库下有多少个程序？
- en: From the provided Octave programs discussed in this chapter, run the program
    called `logistic_gd.m` with an input Octave data set called `numbers.mat`. For
    more details, see Table 9.1 and 9.2 and the related explanations.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从本章提供的Octave程序中，运行名为`logistic_gd.m`的程序，并使用名为`numbers.mat`的输入Octave数据集。有关更多细节，请参见表9.1和9.2及相关解释。
- en: Discuss the `spa` R package and show a few related examples.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 讨论`spa` R包并展示一些相关示例。
- en: 'Download Fama-French-Carhart 4-factor model, see here:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载Fama-French-Carhart四因子模型，见此：
- en: '![](img/226dc7f5-afa8-4050-8ba8-404450076341.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/226dc7f5-afa8-4050-8ba8-404450076341.png)'
- en: 'where R[i] is stock *i*’s returns, R[mkt] is the market returns, R[SMB] is
    the portfolio returns of small stocks might the portfolio returns of big stocks,
    R[HML] is the portfolio returns with high book-to-market ratio (of equity) minus
    the portfolio returns of stocks with low book-to-market ratio, R[MOM] is the momentum
    factor. Write R/Python/Octave/Julia programs to run linear regressions for IBM
    stocks. Source of Data: 1) Prof. French’s Data Library, [http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html](http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html),
    and Yahoo!Finance, [https://finance.yahoo.com](https://finance.yahoo.com).'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 其中R[i]是股票*i*的收益率，R[mkt]是市场收益率，R[SMB]是小股票的组合收益率，可能是大股票的组合收益率，R[HML]是高账面市值比（股票）组合收益率减去低账面市值比股票的组合收益率，R[MOM]是动量因子。编写R/Python/Octave/Julia程序，对IBM股票进行线性回归分析。数据来源：1）法国教授的数据库，[http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html](http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html)
    和 Yahoo!Finance，[https://finance.yahoo.com](https://finance.yahoo.com)。
- en: Download the Bank Marketing Data Set from the UCI Machine Learning Repository, [https://archive.ics.uci.edu/ml/datasets/Bank+Marketing](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing).
    The data is related to direct marketing campaigns of a Portuguese banking institution.
    The marketing campaigns were based on phone calls. Often, more than one contact
    to the same client was required, in order to access if the product (bank term
    deposit) would be ('yes') or not ('no') subscribed. Use supervised learning to
    identify the most influential factors.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从UCI机器学习库下载银行营销数据集，[https://archive.ics.uci.edu/ml/datasets/Bank+Marketing](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)。该数据集与葡萄牙银行机构的直销营销活动相关。这些营销活动是通过电话进行的。通常，为了确定客户是否订购了产品（银行定期存款），需要与同一客户进行多次联系（结果为“是”或“否”）。使用监督学习来识别最具影响力的因素。
- en: Download a data set called *Census Income*, [https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/Census+Income)*. *Extraction
    was done by Barry Becker from the 1994 Census database. A set of reasonably clean
    records was extracted using the following conditions: `((AAGE>16) && (AGI>100)
    && (AFNLWGT>1) && (HRSWK>0))` . Write both R and Python programs to predict whether
    a person makes over $50,000 a year.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载名为*Census Income*的数据集，[https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/Census+Income)*。该数据集由Barry
    Becker从1994年人口普查数据库提取。使用以下条件提取了一组较为干净的记录：`((AAGE>16) && (AGI>100) && (AFNLWGT>1)
    && (HRSWK>0))`。编写R和Python程序预测一个人年收入是否超过$50,000。
- en: 'The utility function for an investor is shown here:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 投资者的效用函数如下所示：
- en: '![](img/02120cb7-b0a4-4dfc-aaac-5cf4806349ff.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02120cb7-b0a4-4dfc-aaac-5cf4806349ff.png)'
- en: where U is the utility function, E(R) is the expected portfolio return and we
    could use its mean to approximate, A is the risk-averse coefficient and σ² is
    the variance of the portfolio. Go to Professor French’s Data Library to download
    10 industry portfolio returns. Assume a risk-averse variable of A varies from
    1 to 100.  Use the k-means method to group investors based on E(R), A, and risk.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，U是效用函数，E(R)是预期投资组合回报，我们可以用其均值来近似，A是风险厌恶系数，σ²是投资组合的方差。前往French教授的数据库下载10个行业投资组合的回报数据。假设风险厌恶系数A的值从1到100不等。使用k-means方法根据E(R)、A和风险将投资者分组。
- en: Download a data set called Bike Sharing Data Set from the UCI Machine Learning
    Repository, [https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset). 
    The dataset contains the hourly and daily count of rental bikes between years
    2011 and 2012 in Capital bike share system with the corresponding weather and
    seasonal information. Write an R program to group individual riders into k-groups.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载名为“Bike Sharing Data Set”的数据集，来自UCI机器学习库，[https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)。该数据集包含2011年和2012年间Capital
    bike share系统的租赁自行车的小时和日租赁数量，以及相应的天气和季节信息。编写R程序将单独的骑行者分成k个组。
- en: Download a data set call Bag of Words, [https://archive.ics.uci.edu/ml/datasets/Bag+of+Words](https://archive.ics.uci.edu/ml/datasets/Bag+of+Words). 
    Write both R and Python to conduct a cluster analysis.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载名为“Bag of Words”的数据集，[https://archive.ics.uci.edu/ml/datasets/Bag+of+Words](https://archive.ics.uci.edu/ml/datasets/Bag+of+Words)。使用R和Python编写程序进行聚类分析。
- en: Download a data set called Sonar Dataset. The Sonar Dataset involves the prediction
    of whether or not an object is a mine or a rock given the strength of sonar returns
    at different angles.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载名为“Sonar Dataset”的数据集。Sonar数据集涉及根据不同角度的声呐回波强度预测一个物体是矿石还是岩石。
- en: 'Use the data set called Boston to run a regression (Python). The first several
    lines are shown here:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用名为Boston的数据集进行回归分析（Python）。前几行数据如下所示：
- en: '[PRE35]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
