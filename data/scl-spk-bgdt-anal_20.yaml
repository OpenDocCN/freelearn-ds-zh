- en: Accelerating Spark with Alluxio
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Alluxio加速Spark
- en: '"It has become appallingly obvious that our technology has exceeded our humanity."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “显而易见，我们的技术已经超越了人类的能力。”
- en: '- Albert Einstein'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- 阿尔伯特·爱因斯坦'
- en: Here, you will learn how to use Alluxio with Spark to accelerate the speed of
    processing. Alluxio is an open source distributed memory storage system, useful
    in accelerating the speed of many applications across platforms, including Apache
    Spark.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你将学习如何将Alluxio与Spark结合使用，以加速处理速度。Alluxio是一个开源的分布式内存存储系统，有助于加速跨平台的许多应用程序的速度，包括Apache
    Spark。
- en: 'In a nutshell, the following topics will be covered throughout this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本章将涵盖以下主题：
- en: The need for Alluxio
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alluxio的需求
- en: Getting started with Alluxio
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用Alluxio
- en: Integration with YARN
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与YARN的集成
- en: Using Alluxio in Spark
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark中使用Alluxio
- en: The need for Alluxio
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Alluxio的需求
- en: We have seen Apache Spark and the various functionalities around Spark core,
    Streaming, GraphX, Spark SQL, and Spark machine learning. We also looked at many
    use cases and operations surrounding data manipulations and processing. The key
    steps in any processing task are data input, data processing, and data output.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了Apache Spark及其围绕Spark核心的各种功能，包括Streaming、GraphX、Spark SQL和Spark机器学习。我们还讨论了许多围绕数据操作和处理的用例和操作。任何处理任务中的关键步骤是数据输入、数据处理和数据输出。
- en: 'Shown here is an illustration of a Spark job:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示的是一个Spark作业的示意图：
- en: '![](img/00323.jpeg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00323.jpeg)'
- en: As seen here, the input and output of a job are often dependent on slower storage
    options based on disk, while the processing usually is done using the memory/RAM.
    Since the memory is 100x faster than disk access, the performance of a job can
    clearly improve significantly if we can reduce the disk usage and use memory more.
    It is not necessary or even possible that we do not use any disk at all in any
    job; rather, we just intend to use memory as much as possible.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，一个作业的输入和输出通常依赖于基于磁盘的较慢存储选项，而处理通常是通过内存/RAM完成的。由于内存的访问速度是磁盘的100倍，如果我们能够减少磁盘使用并更多地使用内存，作业的性能就可以显著提升。并不是说在任何作业中都不使用磁盘是不必要的，甚至是不可行的；而是我们只是希望尽可能多地使用内存。
- en: As a start, we can try to cache as much data as possible in the memory in order
    to accelerate the processing using executors. While this might work for some jobs,
    it's not possible to have so much memory in GBs or TBs for large jobs running
    in a distributed cluster running Spark. Moreover, even if there is a big cluster
    for your usage, there will be many users in the environment, thus making it difficult
    to use so many resources for all jobs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以尽可能将数据缓存到内存中，以便通过执行器加速处理。虽然这对于一些作业可能有效，但对于在分布式集群中运行的大型作业来说，无法提供如此多的GB或TB内存。此外，即使你的环境中有一个大型集群，仍会有许多用户，因此很难为所有作业使用这么多资源。
- en: We know of distributed storage systems such as HDFS, S3, and NFS. Similarly,
    if we had a distributed memory system, we could use this as a storage system for
    all the jobs to reduce the I/O needed for a job or intermediate jobs in a pipeline.
    Alluxio provides exactly that by implementing a distributed in-memory filesystem
    that can be used by Spark for all input/output needs.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道有分布式存储系统，如HDFS、S3和NFS。类似地，如果我们有一个分布式内存系统，我们可以将其用作所有作业的存储系统，从而减少作业或管道中间作业所需的I/O。Alluxio正是通过实现一个分布式内存文件系统来提供这一功能，可以被Spark用于所有的输入/输出需求。
- en: Getting started with Alluxio
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用Alluxio
- en: 'Alluxio, formerly known as Tachyon, unifies data access and bridges computation
    frameworks and the underlying storage systems. Alluxio''s memory-centric architecture
    enables data access orders of magnitude faster than the existing solutions. Alluxio
    is also Hadoop compatible, thus providing seamless integration into the existing
    infrastructure. The existing data analytics applications, such as Spark and MapReduce
    programs, can run on top of Alluxio without any code change, which means that
    the transition time is insignificant with the benefit of better performance:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Alluxio，前身为Tachyon，统一了数据访问，连接了计算框架与底层存储系统。Alluxio的以内存为中心的架构使得数据访问比现有解决方案快了几个数量级。Alluxio还兼容Hadoop，从而实现了与现有基础设施的无缝集成。现有的数据分析应用程序，如Spark和MapReduce程序，可以在Alluxio之上运行，而无需任何代码更改，这意味着过渡时间几乎可以忽略不计，同时带来更好的性能：
- en: '![](img/00326.jpeg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00326.jpeg)'
- en: Downloading Alluxio
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载Alluxio
- en: 'You can download Alluxio by registering your name and email address using the
    [http://www.alluxio.org/download](http://www.alluxio.org/download) website:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过在[http://www.alluxio.org/download](http://www.alluxio.org/download)网站上注册姓名和电子邮件地址来下载Alluxio：
- en: '![](img/00207.jpeg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00207.jpeg)'
- en: 'Alternatively, you can also just go to [http://downloads.alluxio.org/downloads/files](http://downloads.alluxio.org/downloads/files)
    and download the latest version:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你也可以直接访问[http://downloads.alluxio.org/downloads/files](http://downloads.alluxio.org/downloads/files)并下载最新版本：
- en: '![](img/00216.jpeg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00216.jpeg)'
- en: Installing and running Alluxio locally
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在本地安装并运行Alluxio
- en: We will install and run 1.5.0 locally. You can do the same with any other version.
    If you downloaded version 1.5.0, you will see a file like `alluxio-1.5.0-hadoop2.7-bin.tar.gz`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将安装并在本地运行1.5.0版本。你也可以使用其他任何版本。如果你下载了1.5.0版本，你会看到一个类似`alluxio-1.5.0-hadoop2.7-bin.tar.gz`的文件。
- en: A prerequisite for Alluxio is to have JDK 7 or higher installed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Alluxio的前提条件是已安装JDK 7或更高版本。
- en: 'Unzip the downloaded `alluxio-1.5.0-hadoop2.7-bin.tar.gz` file:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 解压下载的`alluxio-1.5.0-hadoop2.7-bin.tar.gz`文件：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Also, if running locally, Alluxio will need an environment variable to properly
    bind to the host, so run the following command:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果在本地运行，Alluxio需要一个环境变量来正确绑定到主机，因此请运行以下命令：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Format the Alluxio filesystem using the `/bin/alluxio` command.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`/bin/alluxio`命令格式化Alluxio文件系统。
- en: This step is only required when you run Alluxio for the first time and, when
    run, all the previously stored data and metadata in the Alluxio filesystem will
    be erased.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步仅在第一次运行Alluxio时需要执行，执行时，Alluxio文件系统中之前存储的所有数据和元数据将被清除。
- en: 'Run the `/bin/alluxio` format command to format the filesystem:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`/bin/alluxio`格式化命令来格式化文件系统：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Start the Alluxio filesystem locally:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本地启动Alluxio文件系统：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can stop Alluxio by using a similar syntax.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用类似的语法来停止Alluxio。
- en: You can stop Alluxio by running `./bin/alluxio-stop.sh` local.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过运行`./bin/alluxio-stop.sh`来停止Alluxio本地实例。
- en: 'Verify that Alluxio is running by running the Alluxio script with the `runTests`
    argument:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`runTests`参数运行Alluxio脚本，验证Alluxio是否正在运行：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Refer to [http://www.alluxio.org/docs/master/en/Running-Alluxio-Locally.html](http://www.alluxio.org/docs/master/en/Running-Alluxio-Locally.html)
    for additional options and details.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 参见[http://www.alluxio.org/docs/master/en/Running-Alluxio-Locally.html](http://www.alluxio.org/docs/master/en/Running-Alluxio-Locally.html)了解更多选项和详细信息。
- en: You can also use the web UI to look at the Alluxio process by opening a browser
    and typing in `http://localhost:19999/`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以通过打开浏览器并输入`http://localhost:19999/`来使用Web UI查看Alluxio进程。
- en: Overview
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概览
- en: 'The Overview tab shows summary information, such as Master Address, Running
    Workers, Version, and Uptime of the cluster. Also shown is the cluster usage summary,
    which shows the workers capacity and filesystem UnderFS Capacity. Then, the storage
    usage summary is also seen, which shows the space capacity and the used space:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 概览标签页显示了集群的总结信息，例如主节点地址、运行中的工作节点、版本和集群的运行时间。还显示了集群使用情况总结，展示了工作节点的容量和文件系统的UnderFS容量。接着，存储使用情况总结也会显示，包括空间容量和已用空间：
- en: '![](img/00219.jpeg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00219.jpeg)'
- en: Browse
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 浏览
- en: 'The Browse tab allows you to look at the current content of the in-memory filesystem.
    This tab shows what is in the filesystem, the name of the file, size, and block
    size, whether we loaded the data into memory, and the ACLs and permissions on
    the file, specifying who can access it and perform operations such as read and
    write. You will see all the files managed in Alluxio in the Browse tab:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 浏览标签页允许你查看内存中文件系统的当前内容。此标签显示文件系统中的内容、文件名、大小和块大小、是否已将数据加载到内存中，以及文件的ACLs和权限，指定谁可以访问并执行读写等操作。你将看到所有在Alluxio中管理的文件都出现在浏览标签中：
- en: '![](img/00225.jpeg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00225.jpeg)'
- en: Configuration
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置
- en: 'The Configuration tab shows all the configuration parameters used. Some of
    the most important parameters are the configuration directory used, CPU resources,
    and memory resource allocations to the master as well as the workers. Also seen
    are the filesystem name, path, JDK settings, and so on. All these can be overridden
    to customize Alluxio for your use cases. Any changes here will also need a restart
    of the cluster:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 配置标签页显示了所有使用的配置参数。最重要的一些参数包括配置目录、CPU资源和分配给主节点及工作节点的内存资源。此外，还可以看到文件系统名称、路径、JDK设置等。这些都可以被重写，以根据你的使用案例定制Alluxio。任何在此处的更改都需要重新启动集群：
- en: '![](img/00231.jpeg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00231.jpeg)'
- en: Workers
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作节点
- en: 'The **Workers** tab simply shows the workers in the Alluxio cluster. This will
    just show the local machine in our case of local setup, but in a typical cluster
    of many workers, you will see all the worker nodes along with the state of the
    node, the worker''s capacity, the space used, and the last heartbeat received,
    which shows whether a worker is alive and participating in the cluster operations
    or not:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**Workers** 标签页简单地显示了 Alluxio 集群中的工作节点。在本地设置的情况下，它只会显示本地机器，但在典型的多个工作节点集群中，你将看到所有工作节点及其状态，工作节点的容量、已用空间以及最后接收到的心跳信息，后者可以告诉你一个工作节点是否存活并参与集群操作：'
- en: '![](img/00234.jpeg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00234.jpeg)'
- en: In-Memory Data
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存数据
- en: 'The In-Memory Data tab shows the current data in the memory of the Alluxio
    filesystem. This shows the content in the memory of the cluster memory. Typical
    information shown for each of the dataset in memory includes the permissions,
    ownership, creation, and modification times:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: “内存数据”标签页显示了 Alluxio 文件系统内存中的当前数据。这显示了集群内存中的内容。典型的每个数据集的信息包括权限、所有者、创建时间和修改时间：
- en: '![](img/00243.jpeg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00243.jpeg)'
- en: Logs
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志
- en: 'The Logs tab allows you to look at various log files for debugging and monitoring
    purpose. You will see the log file named `master.log` for the master node, the
    log file named `worker.log` for the worker nodes, `task.log`, `proxy.log`, and
    a user log too. Each of the log files grows independently and can be very useful
    in diagnosing problems or just monitoring the health of the cluster:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: “日志”标签页允许你查看各种日志文件以进行调试和监控。你将看到名为 `master.log` 的主节点日志文件，名为 `worker.log` 的工作节点日志文件，`task.log`，`proxy.log`，以及一个用户日志文件。每个日志文件独立增长，对于诊断问题或仅仅监控集群健康非常有用：
- en: '![](img/00252.jpeg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00252.jpeg)'
- en: Metrics
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指标
- en: 'The Metrics tab shows metrics useful to monitor the current state of the Alluxio
    filesystem. The main information here includes the capacity of the master node
    and the filesystem capacity. Also shown are the counters of various operations,
    such as logical operations of files created and deleted, and directories created
    and deleted. Another section shows the RPC invocations that you can use to monitor
    the CreateFile, DeleteFile, and GetFileBlockInfo operations, among others:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: “指标”标签页显示了监控 Alluxio 文件系统当前状态的有用指标。这里的主要信息包括主节点的容量和文件系统的容量。还展示了各种操作的计数器，如创建和删除的文件的逻辑操作，以及创建和删除的目录。另一个部分显示了你可以用来监控
    CreateFile、DeleteFile 和 GetFileBlockInfo 等操作的 RPC 调用：
- en: '![](img/00255.jpeg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00255.jpeg)'
- en: Current features
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当前功能
- en: 'As seen earlier, Alluxio provides a lot of functionalities to support a high-speed
    in-memory filesystem, significantly accelerating Spark or many other computing
    systems. The current release has many features, and some of the main features
    can be described as in the following list:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Alluxio 提供了许多功能来支持高速度的内存文件系统，从而显著加速 Spark 或其他许多计算系统。当前版本有许多功能，以下是一些主要功能的描述：
- en: '**Flexible file API** provides a Hadoop compatible filesystem, allowing Hadoop
    MapReduce and Spark to use Alluxio.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活的文件 API** 提供了一个兼容 Hadoop 的文件系统，使得 Hadoop MapReduce 和 Spark 可以使用 Alluxio。'
- en: '**Pluggable under storage** checkpoints in-memory data to the underlying storage
    system, which supports Amazon S3, Google Cloud Storage, OpenStack Swift, HDFS,
    and so on.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pluggable under storage** 将内存数据检查点存储到底层存储系统，支持 Amazon S3、Google Cloud Storage、OpenStack
    Swift、HDFS 等。'
- en: '**Tiered storage** can manage SSDs and HDDs in addition to memory, allowing
    for larger datasets to be stored in Alluxio.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分层存储** 除了内存外，还可以管理 SSD 和 HDD，从而允许更大的数据集存储在 Alluxio 中。'
- en: '**Unified namespace** enables effective data management across different storage
    systems through the mount feature. In addition, transparent naming ensures that
    filenames and the directory hierarchy for objects created in Alluxio are preserved
    when persisting these objects to the underlying storage system.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统一命名空间** 通过挂载功能实现跨不同存储系统的有效数据管理。此外，透明命名确保了在将 Alluxio 中创建的对象持久化到底层存储系统时，文件名和对象的目录层级得以保留。'
- en: '**Lineage** can achieve high throughput writes without compromising fault-tolerance
    using lineage, where lost output is recovered by reexecuting the jobs that created
    the output, just like the DAGs in Apache Spark.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Lineage** 可以通过使用血统（lineage）实现高吞吐量的写操作，而不影响容错性，丢失的输出可以通过重新执行创建输出的作业来恢复，就像
    Apache Spark 中的 DAG（有向无环图）一样。'
- en: '**Web UI and command line** allows users to browse the filesystem easily through
    the web UI. Under the debug mode, administrators can view detailed information
    of each file, including locations and checkpoint paths. Users can also use `./bin/alluxio
    fs` to interact with Alluxio, for example, copy data in and out of the filesystem.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Web UI 和命令行** 允许用户通过 Web UI 轻松浏览文件系统。在调试模式下，管理员可以查看每个文件的详细信息，包括位置和检查点路径。用户还可以使用
    `./bin/alluxio fs` 与 Alluxio 进行交互，例如，在文件系统中复制数据。'
- en: Refer to [http://www.alluxio.org/](http://www.alluxio.org/) for the latest features
    and more up-to-date information.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考 [http://www.alluxio.org/](http://www.alluxio.org/) 以获取最新的功能和更详细的信息。
- en: This is all good enough to get Alluxio started locally. Next, we will see how
    to integrate with a cluster manager, such as YARN.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这些设置足以让 Alluxio 本地启动。接下来，我们将看到如何与集群管理器（如 YARN）集成。
- en: Integration with YARN
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与 YARN 的集成
- en: YARN is one of the most used cluster managers, followed by Mesos. If you can
    recollect from [Chapter 5](part0148.html#4D4J81-21aec46d8593429cacea59dbdcd64e1c),
    *Tackle Big Data - Spark Comes to The Party*, YARN can manage the resources of
    a Hadoop cluster and allow hundreds of applications to share the cluster resources.
    We can run long-running Spark jobs to process real-time credit card transactions,
    for example, using YARN and Spark integration.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: YARN 是最常用的集群管理器之一，其次是 Mesos。如果你能回忆起 [第 5 章](part0148.html#4D4J81-21aec46d8593429cacea59dbdcd64e1c)，*解决大数据问题
    - Spark 携手登场*，YARN 可以管理 Hadoop 集群的资源，并允许数百个应用共享集群资源。例如，我们可以使用 YARN 和 Spark 集成运行长期运行的
    Spark 作业来处理实时信用卡交易。
- en: However, it is not recommended to try running Alluxio as a YARN application;
    rather, Alluxio should be run as a standalone cluster alongside YARN. Alluxio
    should be run alongside YARN so that all the YARN nodes have access to a local
    Alluxio worker. For YARN and Alluxio to coexist, we must inform YARN of the resources
    used by Alluxio. For instance, YARN needs to know how much memory and CPU to leave
    for Alluxio.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，不建议将 Alluxio 作为 YARN 应用程序运行；相反，Alluxio 应该作为独立集群与 YARN 一起运行。Alluxio 应与 YARN
    一起运行，这样所有 YARN 节点都可以访问本地的 Alluxio worker。为了使 YARN 和 Alluxio 共存，我们必须告知 YARN Alluxio
    使用的资源。例如，YARN 需要知道为 Alluxio 保留多少内存和 CPU。
- en: Alluxio worker memory
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Alluxio worker 内存
- en: The Alluxio worker requires some memory for its JVM process and some memory
    for its RAM disk; 1 GB is generally fine for the JVM memory since this memory
    is only used for buffering and metadata.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Alluxio worker 需要一些内存来支持其 JVM 进程，并为 RAM 磁盘提供一些内存；1 GB 通常足够用于 JVM 内存，因为这部分内存仅用于缓存和元数据。
- en: The RAM disk memory can be configured by setting `alluxio.worker.memory.size`.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过设置 `alluxio.worker.memory.size` 来配置 RAM 磁盘内存。
- en: Data stored in non-memory tiers, such as SSD or HDD, does not need to be included
    in the memory-size calculation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 存储在非内存层（如 SSD 或 HDD）中的数据无需包含在内存大小计算中。
- en: Alluxio master memory
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Alluxio master 内存
- en: The Alluxio master stores metadata about every file in Alluxio, so it should
    be at least 1 GB and up to 32 GB for larger cluster deployment.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Alluxio master 存储有关 Alluxio 中每个文件的元数据，因此它的内存应该至少为 1 GB，对于较大的集群部署，最多可达 32 GB。
- en: CPU vcores
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CPU vcores
- en: Each Alluxio worker should have one vcore as a minimum, and Alluxio master can
    use at least one and up to four vcores in production deployments.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 Alluxio worker 至少应分配一个 vcore，而 Alluxio master 在生产部署中可以使用至少一个并最多四个 vcores。
- en: To inform YARN of the resources to reserve for Alluxio on each node, modify
    the YARN configuration parameters in `yarn-site.xml`.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要告知 YARN 每个节点上 Alluxio 需要保留的资源，请修改 `yarn-site.xml` 中的 YARN 配置参数。
- en: Change `yarn.nodemanager.resource.memory-mb` to reserve some memory for the
    Alluxio worker.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 修改 `yarn.nodemanager.resource.memory-mb` 来为 Alluxio worker 保留一些内存。
- en: After determining how much memory to allocate to Alluxio on the node, subtract
    this from `yarn.nodemanager.resource.memory-mb` and update the parameter with
    the new value.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定要分配给 Alluxio 的内存量后，从 `yarn.nodemanager.resource.memory-mb` 中减去这一数值，并用新的值更新该参数。
- en: Change `yarn.nodemanager.resource.cpu-vcores` to reserve CPU vcores for the
    Alluxio worker.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 修改 `yarn.nodemanager.resource.cpu-vcores` 来为 Alluxio worker 保留 CPU vcores。
- en: After determining how much memory to allocate to Alluxio on the node, subtract
    this from `yarn.nodemanager.resource.cpu-vcores` and update the parameter with
    the new value.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定要分配给 Alluxio 的内存量后，从 `yarn.nodemanager.resource.cpu-vcores` 中减去这一数值，并用新的值更新该参数。
- en: After updating the YARN configuration, restart YARN so that it picks up the
    changes.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 更新 YARN 配置后，重启 YARN 以便它能加载新的配置更改。
- en: Using Alluxio with Spark
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Alluxio 与 Spark
- en: In order to use Alluxio with Spark, you will need a couple of dependency JARs.
    This is to enable Spark to connect to the Alluxio filesystem and to read/write
    data. Once we start Spark with Alluxio integration, most of the Spark code remains
    exactly the same, with changes only to the reading and writing portions of the
    code as now you have to use `alluxio://` to denote the Alluxio filesystem.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 Spark 中使用 Alluxio，你需要一些依赖的 JAR 文件。这是为了使 Spark 能够连接到 Alluxio 文件系统并进行数据读写。一旦启动了集成了
    Alluxio 的 Spark，大部分 Spark 代码保持不变，只有读取和写入部分需要修改，因为现在你必须使用 `alluxio://` 来表示 Alluxio
    文件系统。
- en: However, once the Alluxio cluster is set up, Spark jobs (executors) will connect
    to Alluxio master for metadata and the Alluxio workers for the actual data read/write
    operations.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一旦配置好 Alluxio 集群，Spark 任务（执行器）将连接到 Alluxio 主节点以获取元数据，并连接到 Alluxio 工作节点进行实际的数据读写操作。
- en: 'Shown here is an illustration of an Alluxio cluster used from a Spark job:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示的是一个 Spark 任务使用 Alluxio 集群的示意图：
- en: '![](img/00261.jpeg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00261.jpeg)'
- en: 'The following are the steps on how to start Spark-shell with Alluxio and run
    some code:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何使用 Alluxio 启动 Spark-shell 并运行一些代码的步骤：
- en: '**Step 1**, Change the directory into the directory where Spark was extracted:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 1 步**，切换到 Spark 解压目录：'
- en: '[PRE5]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Step 2**, Copy the JARs from Alluxio to Spark:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 2 步**，将 Alluxio 的 JAR 文件复制到 Spark 中：'
- en: '[PRE6]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Step 3**, Start Spark-shell with the Alluxio JARs:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 3 步**，使用 Alluxio JAR 启动 Spark-shell：'
- en: '[PRE7]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Step 4, Copy a sample dataset into the Alluxio filesystem:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 第 4 步，将一个示例数据集复制到 Alluxio 文件系统中：
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can verify the file in Alluxio using the Browse tab; it is the Sentiment_Analysis_Dataset10k.csv
    of size 801.29KB file:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过浏览标签查看 Alluxio 中的文件；它是大小为 801.29KB 的 Sentiment_Analysis_Dataset10k.csv
    文件：
- en: '![](img/00053.jpeg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00053.jpeg)'
- en: Step 4\. Access the file with and without Alluxio.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 第 4 步：分别通过 Alluxio 和不通过 Alluxio 访问文件。
- en: 'First, set the Alluxio filesystem configuration in the shell:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在 shell 中设置 Alluxio 文件系统配置：
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Load the text file from Alluxio:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Alluxio 加载文本文件：
- en: '[PRE10]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Load the same text file from the local filesystem:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 从本地文件系统加载相同的文本文件：
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If you can load Alluxio with a lot of data, Alluxio integration will provide
    greater performance without needing to cache the data. This yields several advantages,
    including removal of the need to cache large datasets by every user who is using
    the Spark cluster.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你可以加载大量数据到 Alluxio，Alluxio 集成将提供更好的性能，无需缓存数据。这带来了多个优点，包括无需每个使用 Spark 集群的用户缓存大型数据集。
- en: Summary
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this appendix, we explored the use of Alluxio as a way of accelerating Spark
    applications using the in-memory filesystem capabilities of Alluxio. This yields
    several advantages, including removal of the need to cache large datasets by every
    user who is using the Spark cluster.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在本附录中，我们探讨了如何利用 Alluxio 作为加速 Spark 应用程序的方式，利用 Alluxio 的内存文件系统功能。这带来了多个优点，包括无需每个使用
    Spark 集群的用户缓存大型数据集。
- en: In the next appendix, we will explore how to use Apache Zeppelin, a web-based
    notebook to perform interactive data analysis.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个附录中，我们将探讨如何使用 Apache Zeppelin，这是一种基于 Web 的笔记本工具，用于执行互动数据分析。
