- en: Chapter 2. Developing Applications with Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章：使用 Spark 开发应用程序
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍：
- en: Exploring the Spark shell
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 Spark 命令行
- en: Developing a Spark application in Eclipse with Maven
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Eclipse 中使用 Maven 开发 Spark 应用程序
- en: Developing Spark applications in Eclipse with SBT
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Eclipse 中使用 SBT 开发 Spark 应用程序
- en: Developing a Spark application in Intellij IDEA with Maven
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Intellij IDEA 中使用 Maven 开发 Spark 应用程序
- en: Developing a Spark application in Intellij IDEA with SBT
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Intellij IDEA 中使用 SBT 开发 Spark 应用程序
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: To create production quality Spark jobs/application, it is useful to use various
    **integrated development environments** (**IDEs**) and build tools. This chapter
    will cover various IDEs and build tools.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建生产质量的 Spark 作业/应用程序，使用各种**集成开发环境**（**IDEs**）和构建工具是有用的。本章将介绍各种 IDE 和构建工具。
- en: Exploring the Spark shell
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 Spark 命令行
- en: Spark comes bundled with a REPL shell, which is a wrapper around the Scala shell.
    Though the Spark shell looks like a command line for simple things, in reality
    a lot of complex queries can also be executed using it. This chapter explores
    different development environments in which Spark applications can be developed.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 随附了一个 REPL 命令行界面，它是 Scala 命令行的一个包装器。虽然 Spark 命令行看起来像是简单的命令行，但实际上，许多复杂的查询也可以用它来执行。本章将探讨不同的开发环境，在这些环境中可以开发
    Spark 应用程序。
- en: How to do it...
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Hadoop MapReduce''s word count becomes very simple with the Spark shell. In
    this recipe, we are going to create a simple 1-line text file, upload it to the
    **Hadoop distributed file system** (**HDFS**), and use Spark to count occurrences
    of words. Let''s see how:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Spark 命令行，Hadoop MapReduce 的词频统计变得非常简单。在这个菜谱中，我们将创建一个简单的单行文本文件，将其上传到**Hadoop
    分布式文件系统**（**HDFS**），并使用 Spark 来统计单词的出现次数。让我们看看如何：
- en: 'Create the `words` directory by using the following command:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建 `words` 目录：
- en: '[PRE0]'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Get into the `words` directory:'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 `words` 目录：
- en: '[PRE1]'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create a `sh.txt` text file and enter `"to be or not to be"` in it:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `sh.txt` 的文本文件，并在其中输入 `"to be or not to be"`：
- en: '[PRE2]'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Start the Spark shell:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 Spark 命令行：
- en: '[PRE3]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Load the `words` directory as RDD:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `words` 目录作为 RDD 加载：
- en: '[PRE4]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Count the number of lines ( result: 1):'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算行数（结果：1）：
- en: '[PRE5]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Divide the line (or lines) into multiple words:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将行（或行）分割成多个单词：
- en: '[PRE6]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Convert `word` to (word,1)—that is, output `1` as the value for each occurrence
    of `word` as a key:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `word` 转换为 (word,1)——即输出每个 `word` 出现作为键的值 `1`：
- en: '[PRE7]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Use the `reduceByKey` method to add the number of occurrences for each word
    as a key (the function works on two consecutive values at a time represented by
    `a` and `b`):'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `reduceByKey` 方法将每个单词的出现次数作为键（该函数一次处理两个连续的值，分别由 `a` 和 `b` 表示）：
- en: '[PRE8]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Sort the results:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对结果进行排序：
- en: '[PRE9]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Print the RDD:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印 RDD：
- en: '[PRE10]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Doing all of the preceding operations in one step is as follows:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有前面的操作一步完成如下：
- en: '[PRE11]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This gives us the following output:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们以下输出：
- en: '[PRE12]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now you understand the basics, load HDFS with a large amount of text—for example,
    stories—and see the magic.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了基础知识，加载 HDFS 中的大量文本——例如，故事——并看看魔法：
- en: If you have the files in a compressed format, you can load them as is in HDFS.
    Both Hadoop and Spark have codecs for unzipping, which they use based on file
    extensions.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有的文件是压缩格式，你可以在 HDFS 中直接加载它们。Hadoop 和 Spark 都有解压缩编解码器，它们根据文件扩展名使用它们。
- en: 'When `wordsFlatMap` was converted to `wordsMap` RDD, there was an implicit
    conversion. This converts RDD into `PairRDD`. This is an implicit conversion,
    which does not require anything to be done. If you are doing it in Scala code,
    please add the following `import` statement:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `wordsFlatMap` 转换为 `wordsMap` RDD 时，有一个隐式转换。这会将 RDD 转换为 `PairRDD`。这是一个隐式转换，不需要做任何事情。如果你在
    Scala 代码中这样做，请添加以下 `import` 语句：
- en: '[PRE13]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Developing Spark applications in Eclipse with Maven
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Eclipse 中使用 Maven 开发 Spark 应用程序
- en: 'Maven as a build tool has become the de-facto standard over the years. It''s
    not surprising if we look little deeper into the promise Maven brings. Maven has
    two primary features and they are:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Maven 作为构建工具，多年来已经成为事实上的标准。如果我们深入挖掘 Maven 带来的承诺，这并不令人惊讶。Maven 有两个主要特性，它们是：
- en: '**Convention over configuration**: Build tools prior to Maven gave developers
    freedom about where to put source files, where to put test files, where to put
    compiled files, and so on. Maven takes away that freedom. With this freedom, all
    the confusion about locations also goes. In Maven, there is a specific directory
    structure for everything. The following table shows a few of the most common locations:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**约定优于配置**：在Maven之前的构建工具允许开发者自由决定源文件、测试文件、编译文件等存放的位置。Maven剥夺了这种自由。有了这种自由，所有关于位置上的困惑也消失了。在Maven中，每个项目都有一个特定的目录结构。以下表格展示了其中一些最常见的位置：'
- en: '| `/src/main/scala` | Source code in Scala |'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| `/src/main/scala` | Scala源代码 |'
- en: '| `/src/main/java` | Source code in Java |'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| `/src/main/java` | Java源代码 |'
- en: '| `/src/main/resources` | Resources to be used by source code such as configuration
    files |'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| `/src/main/resources` | 源代码使用的资源，例如配置文件 |'
- en: '| `/src/test/scala` | Test code in Scala |'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| `/src/test/scala` | Scala测试代码 |'
- en: '| `/src/test/java` | Test code in Java |'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| `/src/test/java` | Java测试代码 |'
- en: '| `/src/test/resources` | Resources to be used by test code such as configuration
    files |'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| `/src/test/resources` | 测试代码使用的资源，例如配置文件 |'
- en: '**Declarative dependency management**: In Maven, every library is defined by
    following three coordinates:'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**声明式依赖管理**：在Maven中，每个库都通过以下三个坐标进行定义：'
- en: '| `groupId` | A logical way of grouping libraries similar to a package in Java/Scala,
    which has to be at least the domain name you own—for example, `org.apache.spark`
    |'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| `groupId` | 类似于Java/Scala中包的逻辑分组方式，必须至少包含你拥有的域名，例如 `org.apache.spark` |'
- en: '| `artifactId` | The name of the project and JAR |'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| `artifactId` | 项目和JAR的名称 |'
- en: '| `version` | Standard version numbers |'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| `version` | 标准版本号 |'
- en: 'In `pom.xml` (the configuration file that tells Maven all the information about
    a project), dependencies are declared in the form of these three coordinates.
    There is no need to search over the Internet and download, unpack, and copy libraries.
    All you need to do is to provide three coordinates of the dependency JAR you need
    and Maven will do the rest for you. The following is an example of using a JUnit
    dependency:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `pom.xml`（一个配置文件，它告诉Maven关于项目的所有信息）中，依赖项以以下三种坐标的形式声明。无需在互联网上搜索并下载、解压和复制库。你所需要做的就是提供所需依赖JAR的三种坐标，Maven会为你完成剩余的工作。以下是一个使用JUnit依赖项的示例：
- en: '[PRE14]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This makes dependency management including transitive dependencies very easy.
    Build tools that came after Maven such as SBT and Gradle also follow these two
    rules as-is and provide enhancements in other aspects.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得依赖项管理，包括传递依赖项，变得非常简单。在Maven之后出现的构建工具，如SBT和Gradle，也遵循这两条规则，并在其他方面提供增强。
- en: Getting ready
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: From this recipe onwards, this chapter assumes you have installed Eclipse. Please
    visit [http://www.eclipse.org](http://www.eclipse.org) for details.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从本食谱开始，本章假设你已经安装了Eclipse。请访问 [http://www.eclipse.org](http://www.eclipse.org)
    获取详细信息。
- en: How to do it...
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how to install the Maven plugin for Eclipse:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何安装Eclipse的Maven插件：
- en: Open Eclipse and navigate to **Help** | **Install New Software**.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Eclipse，导航到 **帮助** | **安装新软件**。
- en: Click on the **Work with** drop-down menu.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **操作** 下拉菜单。
- en: Select the <eclipse version> update site.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 <eclipse version> 更新站点。
- en: Click on **Collaboration tools**.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **协作工具**。
- en: Check Maven's integration with Eclipse, as in the following screenshot:![How
    to do it...](img/B03056_02_01.jpg)
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查Maven与Eclipse的集成，如下截图所示：![如何操作...](img/B03056_02_01.jpg)
- en: Click on **Next** and then click on **Finish**.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **下一步**，然后点击 **完成**。
- en: There will be a prompt to restart Eclipse and Maven will be installed after
    the restart.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将会有提示要求重启Eclipse，Maven将在重启后安装。
- en: 'Now let''s see how we can install the Scala plugin for Eclipse:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何安装Eclipse的Scala插件：
- en: Open Eclipse and navigate to **Help** | **Install New Software**.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Eclipse，导航到 **帮助** | **安装新软件**。
- en: Click on the **Work with** drop-down menu.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **操作** 下拉菜单。
- en: Select the <eclipse version> update site.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 <eclipse version> 更新站点。
- en: Type `http://download.scala-ide.org/sdk/helium/e38/scala210/stable/site`.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入 `http://download.scala-ide.org/sdk/helium/e38/scala210/stable/site`.
- en: Press *Enter*.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按 *Enter*。
- en: Select **Scala IDE for Eclipse**:![How to do it...](img/B03056_02_02.jpg)
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 **Scala IDE for Eclipse**：![如何操作...](img/B03056_02_02.jpg)
- en: Click on **Next** and then click on **Finish**. You will be prompted to restart
    Eclipse and Scala will be installed after the restart.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **下一步**，然后点击 **完成**。你将提示重启Eclipse，Scala将在重启后安装。
- en: Navigate to **Window** | **Open Perspective** | **Scala**.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 **窗口** | **打开透视图** | **Scala**。
- en: Eclipse is now ready for Scala development!
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 Eclipse 已经准备好进行 Scala 开发了！
- en: Developing Spark applications in Eclipse with SBT
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SBT 在 Eclipse 中开发 Spark 应用程序
- en: '**Simple Build Tool** (**SBT**) is a build tool made especially for Scala-based
    development. SBT follows Maven-based naming conventions and declarative dependency
    management.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**简单构建工具**（**SBT**）是一个专门为 Scala 开发制作的构建工具。SBT 遵循基于 Maven 的命名约定和声明式依赖管理。'
- en: 'SBT provides the following enhancements over Maven:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: SBT 相比 Maven 提供以下增强功能：
- en: Dependencies are in the form of key-value pairs in the `build.sbt` file as opposed
    to `pom.xml` in Maven
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依赖项以键值对的形式存在于 `build.sbt` 文件中，而不是 Maven 中的 `pom.xml` 文件。
- en: It provides a shell that makes it very handy to perform build operations
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了一个使执行构建操作变得非常方便的壳。
- en: For simple projects without dependencies, you do not even need the `build.sbt`
    file
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于没有依赖项的简单项目，甚至不需要 `build.sbt` 文件
- en: 'In `build.sbt`, the first line is the project definition:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `build.sbt` 中，第一行是项目定义：
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Each project has an immutable map of key-value pairs. This map is changed by
    settings in SBT like so:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 每个项目都有一个不可变的键值对映射。这个映射可以通过 SBT 中的设置进行更改，如下所示：
- en: '[PRE16]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Every change in the settings leads to a new map, as it's an immutable map.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 任何设置的改变都会导致一个新的映射，因为这是一个不可变的映射。
- en: How to do it...
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Here''s how we go about adding the `sbteclipse` plugin:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这是添加 `sbteclipse` 插件的方法：
- en: 'Add this to the global plugin file:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下内容添加到全局插件文件中：
- en: '[PRE17]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Alternatively, you can add the following to your project:'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者，您还可以添加以下内容到您的项目中：
- en: '[PRE18]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Start the `sbt` shell without any arguments:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在没有任何参数的情况下启动 `sbt` 命令行：
- en: '[PRE19]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Type `eclipse` and it will make an Eclipse-ready project:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入 `eclipse` 并将其转换为 Eclipse 兼容的项目：
- en: '[PRE20]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now you can navigate to **File** | **Import** | **Import existing project into
    workspace** to load the project into Eclipse.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您可以导航到 **文件** | **导入** | **将现有项目导入工作区** 来将项目加载到 Eclipse 中。
- en: Now you can develop the Spark application in Scala using Eclipse and SBT.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用 Eclipse 和 SBT 在 Scala 中开发 Spark 应用程序。
- en: Developing a Spark application in IntelliJ IDEA with Maven
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Maven 在 IntelliJ IDEA 中开发 Spark 应用程序
- en: IntelliJ IDEA comes bundled with support for Maven. We will see how to create
    a new Maven project in this recipe.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: IntelliJ IDEA 内置了对 Maven 的支持。我们将在这个菜谱中看到如何创建一个新的 Maven 项目。
- en: How to do it...
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to develop a Spark application on IntelliJ IDEA
    with Maven:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以在 IntelliJ IDEA 中使用 Maven 开发 Spark 应用程序：
- en: Select **Maven** in new project window and click on **Next**:![How to do it...](img/B03056_02_03.jpg)
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新项目窗口中选择 **Maven** 并点击 **下一步**：![如何操作...](img/B03056_02_03.jpg)
- en: Enter three dimensions of the project:![How to do it...](img/B03056_02_04.jpg)
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入项目的三个维度：![如何操作...](img/B03056_02_04.jpg)
- en: Enter the project's name and location:![How to do it...](img/B03056_02_05.jpg)
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入项目的名称和位置：![如何操作...](img/B03056_02_05.jpg)
- en: Click on **Finish** and the Maven project is ready.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **完成**，Maven 项目就准备好了。
- en: Developing a Spark application in IntelliJ IDEA with SBT
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SBT 在 IntelliJ IDEA 中开发 Spark 应用程序
- en: Before Eclipse became famous, IntelliJ IDEA was considered best of the breed
    in IDEs. IDEA has not shed its former glory yet and a lot of developers love IDEA.
    IDEA also has a community edition, which is free. IDEA provides native support
    for SBT, which makes it ideal for SBT and Scala development.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Eclipse 变得著名之前，IntelliJ IDEA 被认为是 IDE 中的佼佼者。IDEA 仍然保持着过去的辉煌，许多开发者都喜欢 IDEA。IDEA
    还有一个社区版，它是免费的。IDEA 为 SBT 和 Scala 开发提供了原生支持，使其成为 SBT 和 Scala 开发的理想选择。
- en: How to do it...
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to develop a Spark application on IntelliJ IDEA
    with SBT:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以在 IntelliJ IDEA 中使用 SBT 开发 Spark 应用程序：
- en: Add the `sbt-idea` plugin.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加 `sbt-idea` 插件。
- en: 'Add to the global plugin file:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下内容添加到全局插件文件中：
- en: '[PRE21]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Alternatively, you can add to your project as well:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者，您也可以添加到您的项目中：
- en: '[PRE22]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: IDEA is ready to use with SBT.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: IDEA 与 SBT 兼容并准备好使用。
- en: Now you can develop Spark code using Scala and build using SBT.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用 Scala 开发 Spark 代码，并使用 SBT 进行构建。
