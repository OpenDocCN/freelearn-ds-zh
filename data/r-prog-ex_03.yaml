- en: Predicting Votes with Linear Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线性模型预测投票
- en: This chapter shows how to work with statistical models using R. It shows how
    to check data assumptions, specify linear models, make predictions, and measure
    predictive accuracy. It also shows how to find good models programatically to
    avoid doing analysis by hand, which can potentially save a lot of time. By the
    end of this chapter, we will have worked with various quantitative tools that
    are used in many business and research areas nowadays. The packages used in this
    chapter are the same ones from the previous chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了如何使用R进行统计模型的工作。它展示了如何检查数据假设、指定线性模型、进行预测和测量预测准确性。它还展示了如何程序化地找到好的模型，以避免手动分析，这可能会节省大量时间。到本章结束时，我们将使用许多商业和研究领域现在使用的各种定量工具。本章使用的包与上一章相同。
- en: 'Just like in the previous chapter, the focus here will be on automating the
    analysis programatically rather than on deeply understanding the statistical techniques
    used in the chapter. Furthermore, since we have seen in [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes With Descriptive Statistics*, how to work efficiently with
    functions, we will use that approach directly in this chapter, meaning that when
    possible we''ll work directly with functions that will be used to automate our
    analysis. We will cover the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在前一章中一样，这里的重点将放在程序化地自动化分析程序上，而不是深入理解章节中使用的统计技术。此外，由于我们在[第二章](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730)，*使用描述性统计理解投票*中已经看到如何高效地使用函数，我们将在本章直接采用那种方法，这意味着当可能的时候，我们将直接使用用于自动化分析的函数。我们将涵盖以下内容：
- en: Splitting data into training and testing sets
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据分为训练集和测试集
- en: Creating linear regression models used for prediction
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建用于预测的线性回归模型
- en: Checking model assumptions with various techniques
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用各种技术检查模型假设
- en: Measuring predictive accuracy for numerical and categorical data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量数值和分类数据的预测准确性
- en: Programatically finding the best possible model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序化地寻找最佳模型
- en: Required packages
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 必需的包
- en: During this chapter we will make use of the following R packages, which were
    already used in the previous chapter, so you should be good to go.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下R包，这些包已经在上一章中使用过，所以你应该可以开始了。
- en: '| **Package** | **Reason** |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| **包** | **原因** |'
- en: '| `ggplot2` | High-quality graphs |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| `ggplot2` | 高质量图表 |'
- en: '| `corrplot` | Correlation plots |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| `corrplot` | 相关性图 |'
- en: '| `progress` | Show progress for Iteration |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| `progress` | 显示迭代进度 |'
- en: Setting up the data
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置数据
- en: As it's usual with data analysis, the first step is to understand the data we
    will be working with. In this case, the data is the same as in [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes with Descriptive Statistics*, and we have already understood
    some of its main characteristics. Mainly, we've understood that age, education,
    and race have considerable effects over the propensity to vote in favor of the
    UK leaving or remaining in the EU.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 就像数据分析通常那样，第一步是理解我们将要处理的数据。在这种情况下，数据与[第二章](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730)，*使用描述性统计理解投票*中相同，并且我们已经理解了它的一些主要特征。主要的是，我们已经理解了年龄、教育和种族对投票倾向有相当大的影响，即对英国离开或留在欧盟的投票倾向。
- en: The focus of this chapter will be on using linear models to predict the `Proportion`
    and `Vote` variables, which contain the percentage of votes in favor of leaving
    the EU and whether the ward had more votes for `"Leave"` or `"Remain"`, respectively.
    Both variables have similar information, the difference being that one is a numerical
    continuous variable with values between 0 and 1 (`Proportion`) and the other is
    a categorical variable with two categories (`Vote` with `Leave` and `Remain` categories).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点将放在使用线性模型来预测`比例`和`投票`变量上，这两个变量包含支持离开欧盟的投票百分比以及是否该地区有更多的“离开”或“留下”投票。这两个变量具有类似的信息，区别在于一个是介于0和1之间的数值连续变量（`比例`），另一个是具有两个类别（`投票`类别为“离开”和“留下”）的分类变量。
- en: 'We''ll keep observations that contain *complete cases* in the `data` object,
    and observations that have missing values for the `Proportion` and `Vote` variables
    in the `data_incomplete` object (we''ll make predictions over these in the latter
    part of this chapter). The functions `prepare_data()`, `adjust_data()`, and `get_numerical_variables()`
    come from [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes with Descriptive Statistics*, so you may want to take a look
    if you''re not clear about what they do. Basically, they load the data with the
    adjusted version that we created by compressing the data spread among various
    variables regarding age, education, and race:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在`data`对象中保留包含*完整案例*的观察结果，以及在`data_incomplete`对象中对于`比例`和`投票`变量有缺失值的观察结果（我们将在本章的后面部分对这些进行预测）。函数`prepare_data()`、`adjust_data()`和`get_numerical_variables()`来自[第2章](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730)，《使用描述性统计理解投票》，如果您不清楚它们的功能，可能需要查看。基本上，它们加载了通过压缩与年龄、教育和种族等变量相关的数据分布而创建的调整版本的数据：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Training and testing datasets
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和测试数据集
- en: 'For us to be able to measure the predictive accuracy of our models, we need
    to use some observations to validate our results. This means that our data will
    be split into three different groups:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够衡量我们模型的预测准确性，我们需要使用一些观察结果来验证我们的结果。这意味着我们的数据将被分为三个不同的组：
- en: Training data
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据
- en: Testing data
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试数据
- en: Predicting data
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测数据
- en: The predicting data is the data that we don't have complete cases for, specifically
    these are wards for which the `Vote` and `Proportion` variables have `NA` values.
    Our final objective is to provide predictions for these ward's `Proportion` and
    `Vote` variables using what we can learn from other wards for which we do have
    data for these variables, and it's something we'll do toward the end of the chapter.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 预测数据是我们没有完整案例的数据，具体来说，是那些`投票`和`比例`变量有`NA`值的地区。我们的最终目标是使用我们从其他地区学到的知识来预测这些地区的`比例`和`投票`变量，这是我们将在本章的末尾完成的事情。
- en: The data that has complete cases will be split into two parts, training, and
    testing data. Training data is used to extract knowledge and learn the relationship
    among variables. Testing is treated as if it had `NA` values for `Proportion`
    and `Vote`, and we produce predictions for them. These predictions are then compared
    to the real values in the corresponding observations, and this helps us understand
    how good our predictions are in a way that is objective since those observations
    are never seen by the trained models.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 完整案例的数据将被分为两部分，即训练数据和测试数据。训练数据用于提取知识和学习变量之间的关系。测试数据被视为对于“比例”和“投票”变量有`NA`值，我们对这些变量进行预测。然后，将这些预测值与对应观察中的实际值进行比较，这有助于我们以客观的方式了解我们的预测有多好，因为这些观察从未被训练模型看到。
- en: We created the predicting data in the previous section, and we called it `data_incomplete`.
    To create the training and testing data, we use the `sample()` function. It will
    take as input a list of numbers from which it will pick a certain number of values
    (`size`). The list of numbers will go from 1 to the total number of observations
    available in the data with complete cases. We specify the number of observations
    that will be picked for the training data as around 70% of the total number of
    observations available, and use the `replace = FALSE` argument to specify that
    the picked observations may not be duplicated (by avoiding a sample with replacement).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节创建了预测数据，并将其命名为`data_incomplete`。为了创建训练和测试数据，我们使用`sample()`函数。它将接受一个数字列表作为输入，从中选择一定数量的值（`size`）。数字列表将从1到具有完整案例的数据中的总观察数。我们指定用于训练数据的观察数约为总观察数的70%，并使用`replace
    = FALSE`参数指定选中的观察结果可能不会重复（通过避免使用替换的样本）。
- en: 'The testing data is composed of the remaining 30% of the observations. Since
    `sample` is a Boolean vector that contains a `TRUE` or `FALSE` value for each
    observation to specify whether or not it should be included, respectively, we
    can negate the vector to pick the other part of the data by prepending a minus
    sign (`-`) to the binary vector, effectively making every `TRUE` value a `FALSE`
    value, and vice versa. To understand this, let''s look at the following code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据由剩余的30%的观测值组成。由于`sample`是一个布尔向量，它包含每个观测值的`TRUE`或`FALSE`值，分别指定是否应该包含，我们可以通过在二进制向量前加上负号（`-`）来取数据的另一部分，有效地将每个`TRUE`值变为`FALSE`值，反之亦然。为了理解这一点，让我们看看以下代码：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If we did this process various times, we would find that every time we get different
    samples for the training and testing sets, and this may confuse us about our results.
    This is because the `sample()` function is stochastic, meaning that it will use
    *pseudo random number generator* to make the selection for us (computers can not
    generate real randomness, they simulate numbers that appear to be random even
    though they are not, that's why it's called **pseudo random**). If we want our
    process to be reproducible, meaning that, every time we run it the exact same
    samples are selected, then we must specify an initial seed before applying this
    process to precondition the pseudo random number generator. To do so, we need
    to pass an integer to the `set.seed()` function, as we do at the beginning of
    the code snippet. The seed argument must stay fixed to reproduce the same samples,
    and with it in place, every time we generate a random sample, we will get the
    same sample so that our results are reproducible.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们多次进行这个过程，我们会发现每次我们都会得到不同的训练和测试集样本，这可能会让我们对我们的结果感到困惑。这是因为`sample()`函数是随机的，这意味着它将使用*伪随机数生成器*为我们做出选择（计算机不能生成真正的随机数，它们模拟看起来是随机的数字，尽管它们不是，这就是为什么它被称为**伪随机**）。如果我们希望我们的过程是可重复的，也就是说，每次运行它时都会选择完全相同的样本，那么我们必须在应用此过程之前指定一个初始种子来预置伪随机数生成器。为此，我们需要将一个整数传递给`set.seed()`函数，就像我们在代码片段的开头所做的那样。种子参数必须保持固定，以便重现相同的样本，并且有了它，每次我们生成随机样本时，我们都会得到相同的样本，这样我们的结果就是可重复的。
- en: Predicting votes with linear models
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线性模型预测选票
- en: Before we can make any predictions, we need to specify a model and train it
    with our training data (`data_train`) so that it learns how to provide us with
    the predictions we're looking for. This means that we will solve an optimization
    problem that outputs certain numbers that will be used as parameters for our model's
    predictions. R makes it very easy for us to accomplish such a task.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够做出任何预测之前，我们需要指定一个模型，并使用我们的训练数据（`data_train`）对其进行训练，以便它学会如何提供我们想要的预测。这意味着我们将解决一个优化问题，输出某些数字，这些数字将被用作模型预测的参数。R使我们能够非常容易地完成这样的任务。
- en: 'The standard way of specifying a linear regression model in R is using the
    `lm()` function with the model we want to build expressed as a formula and the
    data that should be used, and save it into an object (in this case `fit`) that
    we can use to explore the results in detail. For example, the simplest model we
    can build is one with a single regressor (independent variable) as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中指定线性回归模型的标准方式是使用`lm()`函数，我们将要构建的模型以公式形式表达，并使用应该使用的数据，将其保存到对象（在这种情况下为`fit`）中，我们可以使用它来详细探索结果。例如，我们可以构建的最简单模型是只有一个回归变量（自变量）的模型，如下所示：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In this simple model, we would let R know that we want to run a regression
    where we try to explain the `Proportion` variable using only the `Students` variable
    in the data. This model is too simple, what happens if we want to include a second
    variable? Well, we can add it using the plus (`+`) sign after our other regressors.
    For example (keep in mind that this would override the previous `fit` object with
    the new results, so if you want to keep both of them, make sure that you give
    the resulting objects different names):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的模型中，我们将让R知道我们想要运行一个回归，我们试图仅使用数据中的`Students`变量来解释`Proportion`变量。这个模型太简单了，如果我们想要包含第二个变量会怎样呢？嗯，我们可以在其他回归变量后面使用加号（`+`）来添加它。例如（请注意，这将覆盖之前的`fit`对象，并使用新结果，所以如果你想保留它们两个，确保给结果对象不同的名字）：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This may be a better way of explaining the `Proportion` variable since we are
    working with more information. However, keep in mind the collinearity problem;
    it''s likely that the higher the students percentage is in a ward (`Students`),
    the higher the percentage of relatively young people (`Age_18to44`), meaning that
    we may not be adding independent information into the regression. Of course, in
    most situations, this is not a binary issue, it''s an issue of degree and the
    analyst must be able to handle such situations. We''ll touch more on this when
    checking the model''s assumptions in the next section. For now let''s get back
    to programming, shall we? What if we want to include all the variables in the
    data? Well, we have two options, include all variables manually or use R''s shortcut
    for doing so:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在处理更多信息，这可能是一种更好地解释`Proportion`变量的方法。然而，请记住共线性问题；学生百分比在街区（`Students`）中越高，相对较年轻的人的百分比（`Age_18to44`）也越高，这意味着我们可能没有向回归中添加独立信息。当然，在大多数情况下，这不是一个二元问题，而是一个程度问题，分析师必须能够处理这种情况。我们将在下一节检查模型假设时进一步讨论这个问题。现在，让我们回到编程，好吗？如果我们想包含数据中的所有变量怎么办？嗯，我们有两个选择，手动包含所有变量或使用R的快捷方式来做到这一点：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: These two models are exactly the same. However, there are a couple of subtle
    points we need to mention. First, when specifying the model manually, we had to
    leave the `Proportion` variable explicitly out of the regressors (variables after
    the `~` symbol) so that we don’t get an error when running the regressions (it
    would not make sense for R to allow us to try to explain the `Proportion` variable
    by using the same `Proportion` variable and other things). Second, if we make
    any typos while writing the variable names, we will get errors since those names
    will not be present in the variable names (if by coincidence your typo actually
    refers to another existing variable in the data it may be a hard mistake to diagnose).
    Third, in both cases the list of regressors includes variables that should not
    be there, like `ID`, `RegionName`, `NVotes`, `Leave`, and `Vote`. In the case
    `of`
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个模型完全相同。然而，有几个细微之处我们需要提及。首先，当手动指定模型时，我们必须明确地将`Proportion`变量排除在回归变量（`~`符号之后的变量）之外，这样在运行回归时就不会出现错误（对于R允许我们尝试使用相同的`Proportion`变量和其他事物来解释`Proportion`变量来说是没有意义的）。其次，如果我们输入变量名时出现任何拼写错误，我们会得到错误，因为这些名称将不会出现在变量名中（如果巧合下你的错误实际上指的是数据中另一个现有的变量，那么可能是一个难以诊断的错误）。第三，在这两种情况下，回归变量的列表中包含了不应该存在的变量，如`ID`、`RegionName`、`NVotes`、`Leave`和`Vote`。在`of`的情况下
- en: '`ID` it doesn’t make sense for that variable to be included in the analysis
    as it doesn’t have any information regarding the `Proportion`, it''s just an identifier.
    In the case of `RegionName` it''s a categorical variable so the regression would
    stop being a *Standard Multiple Linear Regression* and R would automatically make
    it work for us, but if we do not understand what we’re doing, it may produce confusing
    results. In this case we want to work only with numerical variables so we can
    remove it easily from the manual case, but we can’t do that in the shortcut case.
    Finally, in the case of `NVotes`, `Leave`, and `Vote`, those variables are expressing
    the same information in slightly the same way so they shouldn’t be included since
    we would have a multicollinearity problem.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`ID`这个变量包含在分析中是没有意义的，因为它没有任何关于`Proportion`的信息，它只是一个标识符。在`RegionName`的情况下，它是一个分类变量，所以回归将不再是*标准多元线性回归*，R会自动为我们处理，但如果我们不理解我们在做什么，它可能会产生令人困惑的结果。在这种情况下，我们只想处理数值变量，因此我们可以轻松地从手动情况中将其删除，但在快捷方式的情况下我们无法这样做。最后，在`NVotes`、`Leave`和`Vote`的情况下，这些变量以略微相同的方式表达相同的信息，因此它们不应该被包含，因为我们会有多重共线性问题。'
- en: 'Let''s say the final model we want to work with includes all the valid numerical
    variables:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要使用的最终模型包括所有有效的数值变量：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If we want to use the shortcut method, we can make sure that the data does not
    contain the problematic variables (using the selection techniques we looked at
    in [Chapter 1](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730), *Introduction
    to R*) and then using the shortcut.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想使用快捷方式，我们可以确保数据中不包含有问题的变量（使用我们在[第1章](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730)，*R语言简介*）中查看的筛选技术，然后使用快捷方式。
- en: 'To take a look at the results in detail, we use the `summary()` function on
    the `fit` object:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要详细查看结果，我们使用`fit`对象上的`summary()`函数：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: These results tell us which command was used to create our model, which is useful
    when you're creating various models and want to quickly know the model associated
    to the results you're looking at. It also shows some information about the distribution
    of the residuals. Next, it shows the regression's results for each variable used
    in the mode. We get the name of the variable (`(Intercept)` is the Standard Linear
    Regression intercept used in the model's specification), the coefficient estimate
    for the variable, the standard error, the *t statistic*, the *p-value*, and a
    visual representation of the *p-value* using asterisks for significance codes.
    At the end of the results, we see other results associated with the model, including
    the *R-squared* and the *F-statistic*. As mentioned earlier, we won't go into
    details about what each of these mean, and we will continue to focus on the programming
    techniques. If you're interested, you may look at Casella and Berger's, *Statistical
    Inference, 2002*, or Rice's, *Mathematical Statistics and Data Analysis, 1995*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果告诉我们用于创建我们模型的命令，这在创建各种模型并希望快速了解所查看结果的模型时很有用。它还显示了一些关于残差分布的信息。接下来，它显示了模型中使用的每个变量的回归结果。我们得到变量的名称（`（Intercept）`是模型规范中使用的标准线性回归截距），变量的系数估计，标准误差，*t
    统计量*，*p 值*，以及使用星号表示显著性代码的*p 值*的视觉表示。在结果末尾，我们看到与模型相关的其他结果，包括 *R 平方* 和 *F 统计量*。如前所述，我们不会深入探讨这些含义的细节，我们将继续关注编程技术。如果您感兴趣，可以查看
    Casella 和 Berger 的 *Statistical Inference, 2002* 或 Rice 的 *Mathematical Statistics
    and Data Analysis, 1995*。
- en: 'Now that we have a fitted model ready in the `fit` object, we can use it to
    make predictions. To do so, we use the `predict()` function with the `fit` object
    and the data we want to produce predictions for, `data_test` in our case. This
    returns a vector of predictions that we store in the `predictions` object. We
    will get one prediction for each observation in the `data_test` object:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了`fit`对象中的拟合模型，我们可以用它来进行预测。为此，我们使用`predict()`函数和`fit`对象以及我们想要对其产生预测的数据，在我们的例子中是`data_test`。这会返回一个预测值的向量，我们将其存储在`predictions`对象中。对于`data_test`对象中的每个观测值，我们都会得到一个预测：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: These predictions can be measured for accuracy as we will do in a later section
    in this chapter. For now, we know how to generate predictions easily with R.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在本章后面的某个部分测量这些预测的准确性。现在，我们知道如何用R轻松地生成预测。
- en: Checking model assumptions
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查模型假设
- en: Linear models, as with any kind of models, require that we check their assumptions
    to justify their application. The accuracy and interpretability of the results
    comes from adhering to a model's assumptions. Sometimes these will be rigorous
    assumptions in the sense that if they are not strictly met, then the model is
    not considered to be valid at all. Other times, we will be working with more flexible
    assumptions in which a degree of criteria from the analyst will come into play.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何类型的模型一样，线性模型要求我们检查其假设以证明其应用的合理性。结果的准确性和可解释性来自于遵守模型的假设。有时这些假设将是严格的，如果它们没有得到严格满足，那么模型就不被认为有效。其他时候，我们将与更灵活的假设一起工作，其中分析师的标准程度将发挥作用。
- en: For those of you interested, a great article about models' assumptions is David
    Robinson's, *K-means clust**ering is not free lunch, 2015* ([http://varianceexplained.org/r/kmeans-free-lunch/](http://varianceexplained.org/r/kmeans-free-lunch/)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有兴趣的人来说，一篇关于模型假设的精彩文章是 David Robinson 的 *K-means clustering is not free lunch,
    2015* ([http://varianceexplained.org/r/kmeans-free-lunch/](http://varianceexplained.org/r/kmeans-free-lunch/))。
- en: 'For linear models, the following are some of the core assumptions:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性模型，以下是一些核心假设：
- en: '**Linearity**: There is a linear relation among the variables'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性关系**：变量之间存在线性关系'
- en: '**Normality**: Residuals are normally distributed'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正态性**：残差呈正态分布'
- en: '**Homoscedasticity**: Residuals have constant variance'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**同方差性**：残差具有恒定的方差'
- en: '**No collinearity**: Variables are not linear combinations of each other'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无多重共线性**：变量之间不是彼此的线性组合'
- en: '**Independence**: Residuals are independent or at least not correlated'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**独立性**：残差是独立的，或者至少不相关'
- en: 'We will show how to briefly check four of the them: linearity, normality, homoscedasticity,
    and no collinearity. We should mention that the independence assumption is probably
    the most difficult assumption to test, and you can generally handle it with common
    sense and understanding how the data was collected. We will not get into that
    here as it''s more in the statistics side of things and we want to keep the book
    focused on programming techniques. For the statistically-interested reader, we
    recommend looking at Jeffrey M. Wooldridge''s, *Introductory Econometrics, 2013*
    and Joshua D. Angrist and Jorn-Steffen Pischke''s, *Mostly Harmless Econometrics,
    2008*.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将展示如何简要检查其中的四个：线性、正态性、同方差性和无多重共线性。我们应该提到，独立性假设可能是最难测试的假设，您通常可以用常识和对数据收集方式的理解来处理它。我们在这里不会深入探讨这一点，因为它更多地属于统计学的范畴，而我们希望这本书专注于编程技术。对于对统计学感兴趣的读者，我们推荐阅读Jeffrey
    M. Wooldridge的《2013年入门计量经济学》和Joshua D. Angrist以及Jorn-Steffen Pischke的《2008年无害计量经济学》。
- en: Checking linearity with scatter plots
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用散点图检查线性
- en: 'A basic way of checking the linearity assumption is to make a scatter plot
    with the dependent variable in the *y* axis and an independent variable in the
    *x* axis. If the relation appears to be linear, the assumption is validated. In
    any interesting problem it''s extremely hard to find a scatter plot that shows
    a very clear linear relation, and if it does happen we should be a little suspicious
    and careful with the data. To avoid reinventing the wheel, we will use the `plot_scatterlot()`
    function we created in [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes with Descriptive Statistics*:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 检查线性假设的基本方法是在*Y*轴上绘制因变量，在*x*轴上绘制自变量，制作一个散点图。如果关系看起来是线性的，那么假设就得到了验证。在任何有趣的问题中，找到一个非常清晰的线性关系的散点图都是非常困难的，如果确实发生了这种情况，我们应该稍微怀疑并小心对待数据。为了避免重复造轮子，我们将使用我们在[第2章](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730)，“使用描述性统计理解投票”中创建的`plot_scatterlot()`函数：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As we can see, the scatter plot on the left shows a clear linear relation, as
    the percentage of people between 18 and 44 years of age (`Age_18to44`) increases,
    the proportion of people in favor of leaving the EU (`Proportion`) decreases.
    On the right hand, we see that the relation among the percentage of students in
    a ward (`Students`) and `Proportion` is clearly linear in the initial area (where
    `Students` is between 0 and 20), after that the relation too seems to be linear,
    but it is polluted by observations with very high percentage of students. However,
    we can still assume a linear relation between `Students` and `Proportion`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，左边的散点图显示了明显的线性关系，因为18至44岁之间的人口比例（`Age_18to44`）增加，支持离开欧盟的人口比例（`Proportion`）减少。在右边，我们看到在初始区域（`Students`在0到20之间）中，学生比例（`Students`）和`Proportion`之间的关系是明显线性的，之后这种关系似乎也是线性的，但受到了具有非常高学生比例的观察值的污染。然而，我们仍然可以假设`Students`和`Proportion`之间存在线性关系。
- en: '![](img/00022.jpeg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00022.jpeg)'
- en: When we're doing a *Multiple Linear Regression* as we're doing here, the assumption
    should be checked for the rest of the variables, which we omit here to preserve
    space, but we encourage you to do so. Keep in mind that it's very hard to find
    a linear relation in all of them, and this assumption is mostly an indicator of
    the predictive power of the variable in the regression. As long as the relation
    appears to be slightly linear, we should be all set.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在这里进行**多重线性回归**时，应该检查除了我们这里省略的其余变量之外的所有假设，但我们鼓励您这样做。请记住，在所有这些变量中找到一个线性关系是非常困难的，而这个假设主要是变量在回归中的预测能力的指示。只要关系看起来稍微线性，我们就应该没问题。
- en: Checking normality with histograms and quantile-quantile plots
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用直方图和分位数-分位数图检查正态性
- en: We will check normality with two different techniques so that we can exemplify
    the usage of a technique known as the **strategy pattern**, which is part of a
    set of patterns from object-oriented programming. We will go deeper into these
    patterns in [Chapter 8](part0178.html#59O440-f494c932c729429fb734ce52cafce730),
    *Object-Oriented System **to Track Cryptocurrencies*.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用两种不同的技术来检查正态性，这样我们就可以举例说明一种称为**策略模式**的技术，它是面向对象编程中一系列模式的一部分。我们将在[第8章](part0178.html#59O440-f494c932c729429fb734ce52cafce730)，“面向对象系统**追踪加密货币**”中更深入地探讨这些模式。
- en: 'For now, you can think of the strategy pattern as a technique that will re-use
    code that would otherwise be duplicated and simply changes a way of doing things
    called the **strategy**. In the following code you can see that we create a function
    called `save_png()` which contains the code that would be duplicated (saving PNG
    files) and doesn''t need to be. We will have two strategies, in the form of functions,
    to check data normality—histograms and quantile-quantile plots. These will be
    sent through the argument conveniently named `functions_to_create_images`. As
    you can see, this code receives some data, a variable that will be used for the
    graph, the file name for the image, and a function that will be used to create
    the graphs. This last parameter, the function, should not be unfamiliar to the
    reader as we have seen in [Chapter 1](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730),
    *Introduction to R*, that we can send functions as arguments, and use them as
    we do in this code, by calling them through their *new name* inside the function,
    `function_to_create_image()` in this case:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，你可以将策略模式视为一种技术，它将重用那些否则会被重复的代码，并简单地改变一种称为**策略**的操作方式。在下面的代码中，你可以看到我们创建了一个名为`save_png()`的函数，它包含了将被重复的代码（保存PNG文件）且不需要重复。我们将有两种策略，以函数的形式呈现，用于检查数据正态性——直方图和分位数-分位数图。这些将通过名为`functions_to_create_images`的参数方便地传递。正如你所见，这段代码接收一些数据，一个用于图形的变量，图像的文件名，以及一个用于创建图形的函数。这个最后一个参数，即函数，对读者来说应该不会陌生，因为我们已经在[第1章](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730)，*R语言入门*中看到过，我们可以将函数作为参数传递，并像在这段代码中一样使用它们，通过在函数内部调用它们的*新名称*，在这个例子中是`function_to_create_image()`：
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now we show the code that will make use of this `save_png()` function and encapsulate
    the knowledge of the function that is used for each case. In the case of the histograms,
    the `histogram()` function shown in the following code simply wraps the `hist()`
    function used to create the graph with a common interface that will also be used
    by the other strategies (the `quantile_quantile()` function shown in the following
    code in this case). This common interface allows us to use these strategies as
    plugins that can be substituted easily as we do in the corresponding `variable_histogram()`
    and `variable_qqplot()` functions (they both do the same call, but use a different
    strategy in each case). As you can see, other details that are not part of the
    common interface (for example, `main` and `xlab`) are handled within each strategy''s
    code. We could add them as optional arguments if we wanted to, but it''s not necessary
    for this example:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们展示将利用这个`save_png()`函数并封装每个情况所使用的函数知识的代码。在直方图的例子中，下面代码中显示的`histogram()`函数简单地封装了用于创建图形的`hist()`函数，并使用了一个通用的接口，这个接口也将被其他策略使用（在这个例子中是下面代码中显示的`quantile_quantile()`函数）。这个通用接口允许我们将这些策略用作插件，可以像在相应的`variable_histogram()`和`variable_qqplot()`函数（它们都执行相同的调用，但在每种情况下使用不同的策略）中做的那样轻松替换。正如你所见，不属于通用接口的其他细节（例如，`main`和`xlab`）在每个策略的代码中处理。如果我们想，我们可以将它们作为可选参数添加，但在这个例子中不是必要的：
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following shows the graph for checking proportion normality:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码展示了用于检查比例正态性的图形：
- en: '![](img/00023.jpeg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00023.jpeg)'
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If we wanted to share the code used to create the PNG images with a third (or
    more) strategies, then we can simply add a strategy wrapper for each new case
    without worrying about duplicating the code that creates the PNG images. It may
    seem that this is not a big deal, but imagine that the code used to create the
    PNG files was complex and suddenly you found a bug. What would you need to fix
    that bug? Well, you'd have to go to every place where you duplicated the code
    and fix it there. Doesn't seem very efficient. Now, what happens if you no longer
    want to save PNG files and want to instead save JPG files? Well, again, you would
    have to go everywhere you have duplicated your code and change it. Again, not
    very efficient. As you can see, this way of programming requires a little investment
    upfront (creating the common interfaces and providing wrappers), but the benefit
    of doing so will pay for itself through the saved time, you do need to change
    the code, if only once, as well as more understandable and simpler code. This
    is a form of **dependency management** and is something you should learn how to
    do to become a more efficient programmer.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想与第三个（或更多）策略共享创建PNG图像的代码，那么我们可以简单地为每个新情况添加一个策略包装器，而不用担心重复创建PNG图像的代码。这看起来可能不是什么大问题，但想象一下，用于创建PNG文件的代码很复杂，你突然发现了一个错误。你需要修复什么错误？嗯，你将不得不去每个重复代码的地方进行修复。这看起来并不高效。现在，如果你不再想保存PNG文件，而想保存JPG文件会发生什么？嗯，同样，你将不得不去每个重复代码的地方进行更改。这同样效率不高。如您所见，这种编程方式需要前期进行一点投资（创建通用接口和提供包装器），但这样做的好处将通过节省的时间得到回报，即使你只需要更改一次代码，以及更易于理解和更简单的代码。这是一种**依赖管理**的形式，这是你应该学会如何做以成为一个更高效的程序员。
- en: You may have noticed that in the previous code, we could have avoided one function
    call by having the user call directly the `save_png()` function. However, doing
    so would require the user to have knowledge of two things, the `save_png()` function
    to save the image and the `quantile_quantile()` or `histogram()` functions to
    produce the plots, depending on what she was trying to plot. This extra burden
    in the user, although seemingly not problematic, could make things very confusing
    for her since not many users are used to sending functions as arguments, and they
    would have to know two function signatures, instead of one.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，在前面的代码中，我们可以通过让用户直接调用 `save_png()` 函数来避免一个函数调用。然而，这样做要求用户了解两件事，即 `save_png()`
    函数用于保存图像，以及 `quantile_quantile()` 或 `histogram()` 函数用于生成图表，具体取决于她试图绘制什么。这种额外的负担虽然看似不问题，但对于不习惯将函数作为参数传递的用户来说，可能会非常混乱，因为他们需要知道两个函数签名，而不是一个。
- en: Providing a wrapper whose signature is easily usable as we do with `variable_histogram()`
    and `variable_qqplot()` makes it easier on the user, and allows us to expand the
    way we want to show graphs in case we want to change that later without making
    the user learn a new function signature.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 提供一个签名易于使用的包装器，就像我们使用 `variable_histogram()` 和 `variable_qqplot()` 一样，这使用户更方便，并允许我们根据需要扩展显示图表的方式，如果我们以后想改变它而不需要用户学习新的函数签名。
- en: 'To actually produce the plots we''re looking for, we use the following code:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要实际生成我们想要的图表，我们使用以下代码：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As you can see, the histogram shows an approximate normal distribution slightly
    skewed towards the right, but we can easily accept it as being normal. The corresponding
    quantile-quantile plot shows the same information in a slightly different way.
    The line it shows corresponds to the quantiles of the normal distribution, and
    the dots show the actual distribution in the data. The closer these dots are to
    the line, the closer the variable's distribution is to being normally distributed.
    As we can see, for the most part, `Proportion` is normally distributed, and it's
    at the extremes that we can see a slight deviation, which probably comes from
    the fact that our `Proportion` variable actually has hard limits at 0 and 1\.
    However, we can also accept it as being normally distributed, and we can proceed
    to the next assumption safely.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，直方图显示了一个略微向右偏斜的近似正态分布，但我们很容易接受它为正态分布。相应的分位数-分位数图以略不同的方式显示了相同的信息。它显示的线对应于正态分布的分位数，而点显示了数据中的实际分布。这些点越接近线，变量的分布就越接近正态分布。如您所见，大部分情况下，“比例”是正态分布的，而在极端情况下我们可以看到轻微的偏差，这可能是由于我们的“比例”变量实际上在0和1处有硬限制。然而，我们也可以接受它为正态分布，并可以安全地继续到下一个假设。
- en: Checking homoscedasticity with residual plots
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用残差图检查同方差性
- en: '**Homoscedasticity** simply means that we need the data to have constant variance
    in our residuals. To check for it, we can use the `plot(fit)` function call. However,
    this will show one plot at a time asking you to hit *Enter* on your keyboard to
    show the next one. This kind of mechanism is not friendly to the automation processes
    we are creating. So we need a little adjustment. We will use the `par(mfrow =
    c(2, 2))` call to tell the `plot()` function to graph all four plots at the same
    time and show it in a single image. We wrap the command around our already familiar
    mechanism to save PNGs around the `fit_plot()` function, and we''re all set:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**同方差性**简单来说就是我们需要数据中的残差具有恒定的方差。为了检查它，我们可以使用`plot(fit)`函数调用。然而，这将一次显示一个图表，并要求你按键盘上的*Enter*键来显示下一个图表。这种机制对我们正在创建的自动化过程来说并不友好。因此，我们需要做一些调整。我们将使用`par(mfrow
    = c(2, 2))`调用告诉`plot()`函数同时绘制所有四个图表，并在一个图像中显示。我们将命令包裹在`fit_plot()`函数周围的我们已熟悉的机制中，以便在`fit_plot()`函数周围保存PNG图像，这样我们就设置好了：'
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'With the `fit_plot()` function in place, we can show the regressions graphical
    results with the following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在`fit_plot()`函数就位的情况下，我们可以使用以下方式展示回归的图形结果：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](img/00024.jpeg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00024.jpeg)'
- en: The information we're looking for is in the plots on the left-hand side, where
    we see fitted values in the x axis and residuals in the y axis. In these plots,
    we are looking for residuals to be randomly distributed in a tubular pattern,
    indicated by the dotted lines. We do not want residuals with a pattern that looks
    similar to a fan or funnel or in any way curvilinear. As we can see, the pattern
    we see does resemble a tubular pattern, so we can say the assumption of homoscedasticity
    holds for the data. As an extra, you can also see, in the top-right quantile-quantile
    plot, that the residuals follow a normal distribution which is also good. The
    plot on the lower-right shows a statistics concept, which we won't go into, called
    Cook's distance, which is used to find *influential* observations in a regression.
    To read more about it, you may look at John Fox's, *Regression Diagnostics, 1991*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要的信息在左侧的图表中，其中x轴上显示拟合值，y轴上显示残差。在这些图表中，我们寻找的是残差以随机分布的管状模式，由虚线所示。我们不希望残差呈现出类似扇形或漏斗形或任何形式的曲线模式。正如我们所见，我们看到的模式确实类似于管状模式，因此我们可以说同方差性的假设对于数据是成立的。作为额外信息，你还可以在右上角的分位数-分位数图中看到，残差遵循正态分布，这也是好的。右下角的图表展示了一个统计学概念，我们不会深入探讨，称为库克距离，它用于在回归中找到*有影响力的*观测值。要了解更多关于它的信息，你可以查看John
    Fox的*回归诊断，1991*。
- en: Checking no collinearity with correlations
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查无共线性与相关系数
- en: To check no collinearity, we could use a number of different techniques. For
    example, for those familiar with linear algebra, the condition number is a measure
    of how singular a matrix is, where singularity would imply perfect collinearity
    among the covariates. This number could provide a measure of this collinearity.
    Another technique is to use the *Variance Inflation Factor*, which is a more formal
    technique that provides a measure of how much a regression's variance is increased
    because of collinearity. Another, and a more common, way of checking this is with
    simple correlations. Are any variables strongly correlated among themselves in
    the sense that there could be a direct relation among them? If so, then we may
    have a multicollinearity problem. To get a sense of how correlated our variables
    are, we will use the correlations matrix techniques shown in [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes with Descriptive Statistics*.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查无共线性，我们可以使用多种不同的技术。例如，对于那些熟悉线性代数的人来说，条件数是衡量矩阵如何奇异的一个度量，其中奇异性意味着协变量之间有完美的共线性。这个数字可以提供这种共线性的度量。另一种技术是使用*方差膨胀因子*，这是一种更正式的技术，它提供了由于共线性而增加回归方差的程度。另一种，也是更常见的方法，是使用简单的相关系数。是否有任何变量在彼此之间有很强的相关性，以至于它们之间可能存在直接关系？如果是这样，那么我们可能有一个多重共线性问题。为了了解我们的变量之间是如何相关的，我们将使用[第2章](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730)中展示的相关系数矩阵技术，*使用描述性统计来理解投票*。
- en: 'The following code shows how correlations work in R:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了在R中相关系数是如何工作的：
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see, the strong correlations (either positive or negative) are occurring
    intra-groups not inter-groups, meaning that variables that measure the same thing
    in different ways appear to be highly correlated, while variables that measure
    different things don't appear to be highly correlated.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，强烈的关联（无论是正的还是负的）是在组内而不是组间发生的，这意味着以不同方式衡量同一事物的变量似乎高度相关，而衡量不同事物的变量则似乎不相关。
- en: '![](img/00025.jpeg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00025.jpeg)'
- en: For example, `Age_18to44` and `Age_45plus` are variables that measure age, and
    we expect them to have a negative relation since the higher the percentage of
    young people in a ward is, by necessity, the percentage of older people is lower.
    The same relation can be seen in the housing group (`Owned`, `OwnedOutright`,
    `SocialRent`, and `PrivateRent`), the employment group (`Unemp`, `UnempRate_EA`,
    and `HigherOccup`), the deprived group (`Deprived` and `MultiDepriv`), ethnic
    group (`White` and `NonWhite`), the residency group (`Residents` and `Households`),
    and the education group (`LowEducationLevel` and `HighEducationLevel`). If you
    pick variables belonging to different groups, the number of strong correlations
    is significantly lower, but it's there. For example, `HigherOccup` is strongly
    correlated to `HighEducationLevel` and `LowEducationLevel`, positively and negatively,
    respectively. Also, variables in the housing group seem to be correlated with
    variables in the age group. These kinds of relations are expected and natural
    since highly educated people will most probably have better jobs, and young people
    probably can't afford a house yet, so they rent. As analysts, we can assume that
    these variables are in fact measuring different aspects of society and continue
    on with our analysis. However, these are still things you may want to keep in
    mind when interpreting the results, and we may also want to only include one of
    the variables in each group to avoid inter-group collinearity, but we'll avoid
    these complexities and continue with our analysis for now.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`Age_18to44` 和 `Age_45plus` 是衡量年龄的变量，我们预计它们之间会有负相关关系，因为一个区域中年轻人的百分比越高，必然导致老年人的百分比越低。同样的关系也可以在住房群体（`Owned`、`OwnedOutright`、`SocialRent`
    和 `PrivateRent`）、就业群体（`Unemp`、`UnempRate_EA` 和 `HigherOccup`）、贫困群体（`Deprived`
    和 `MultiDepriv`）、种族群体（`White` 和 `NonWhite`）、居住群体（`Residents` 和 `Households`）和教育群体（`LowEducationLevel`
    和 `HighEducationLevel`）中看到。如果你选择属于不同群体的变量，强烈的关联数量会显著降低，但仍然存在。例如，`HigherOccup`
    与 `HighEducationLevel` 和 `LowEducationLevel` 强烈相关，分别呈正相关和负相关。此外，住房群体中的变量似乎与年龄群体中的变量相关。这些关系是预期和自然的，因为受过高等教育的人很可能有更好的工作，而年轻人可能还买不起房子，所以他们会租房。作为分析师，我们可以假设这些变量实际上是在衡量社会的不同方面，并继续我们的分析。然而，在解释结果时，你仍然可能想要记住这些事情，我们可能还只想在每个群体中包含一个变量，以避免组间共线性，但现在我们将避免这些复杂性，继续我们的分析。
- en: Linear regression is one of those types of models that require criteria from
    the analyst to be accepted or rejected. In our specific case, it seems that our
    model's assumptions are valid enough and we may safely use it to provide credible
    predictions as we will do in the following sections.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是那些需要分析师提供接受或拒绝标准的模型类型之一。在我们的具体案例中，似乎我们的模型假设是有效的，我们可以安全地使用它来提供可信的预测，正如我们将在以下章节中所做的那样。
- en: Measuring accuracy with score functions
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分数函数测量准确性
- en: Now that we have checked our model's assumptions, we turn toward measuring it's
    predictive power. To measure our predictive accuracy, we will use two methods,
    one for numerical data (`Proportion`) and the other for categorical data (`Vote`).
    We know that the `Vote` variable is a transformation from the `Proportion` variable,
    meaning that we are measuring the same information in two different ways. However,
    both numerical and categorical data are frequently encountered in data analysis,
    and thus we wanted to show both approaches here. Both functions, `score_proportions()`
    (numerical) and `score_votes()` (categorical) receive the data we use for testing
    and the predictions for each of the observations in the testing data, which come
    from the model we built in previous sections.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经检查了模型的假设，我们将转向测量其预测能力。为了测量我们的预测精度，我们将使用两种方法，一种用于数值数据（`Proportion`），另一种用于分类数据（`Vote`）。我们知道
    `Vote` 变量是 `Proportion` 变量的转换，这意味着我们以两种不同的方式测量相同的信息。然而，数值数据和分类数据在数据分析中经常遇到，因此我们想在这里展示两种方法。这两个函数，`score_proportions()`（数值）和
    `score_votes()`（分类），接收我们用于测试的数据以及测试数据中每个观测的预测，这些预测来自我们在前几节中构建的模型。
- en: 'In the numerical case, `score_proportions()` computes a score using the following
    expression:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在数值情况下，`score_proportions()` 函数使用以下表达式来计算分数：
- en: '![](img/00026.jpeg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00026.jpeg)'
- en: 'Here, `Y_i` is the *real response* variable value for the *i*th observation
    in the testing data, `Y''_i` is our prediction for that same observation, `SE`
    is our prediction''s standard error, and `n` is the number of observations in
    the testing data. This equation establishes that the score, which we want to minimize,
    is the average of *studentized residuals*. Studentized residuals, as you may know,
    are residuals divided by a measure of the standard errors. This formula gives
    us an average measure of how close we are to predicting an observation''s value
    correctly relative to the variance observed for that data range. If we have a
    high degree of variance (resulting in high standard errors), we don''t want to
    be too strict with the prediction, but if we are in a low-variance area, we want
    to make sure that our predictions are very accurate:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`Y_i` 是测试数据中第 *i* 个观测的 *真实响应* 变量值，`Y'_i` 是我们对该相同观测的预测，`SE` 是我们预测的标准误差，`n`
    是测试数据中的观测数。这个方程式建立了我们想要最小化的分数是 *学生化残差* 的平均值。你可能知道，学生化残差是将残差除以标准误差的度量。这个公式给我们提供了一个平均度量，即我们相对于观察到的数据范围方差预测观测值正确性的接近程度。如果我们有一个很高的方差（导致高标准误差），我们不想对预测过于严格，但如果我们处于低方差区域，我们想确保我们的预测非常准确：
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the categorical case, `score_votes()` computes a score by simply counting
    the number of times our predictions pointed toward the correct category, which
    we want to maximize. We do that by first using the same classification mechanism
    (if the predicted `Proportion` is larger than 0.5, then we classify it as a `"Leave"`
    vote and vice versa), and compare the categorical values. We know that the sum
    of Boolean vector will be equal to the number of `TRUE` values, and that''s what
    we''re using in the `sum(real == predicted)` expression:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类情况下，`score_votes()` 函数通过简单地计算我们的预测指向正确类别的次数来计算一个分数，这是我们想要最大化的。我们通过首先使用相同的分类机制（如果预测的
    `Proportion` 大于 0.5，则将其分类为 `"Leave"` 投票，反之亦然），并比较分类值来实现这一点。我们知道布尔向量的和将等于 `TRUE`
    值的数量，这正是我们在 `sum(real == predicted)` 表达式中使用的：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To test our model''s scores, we do the following:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的模型分数，我们执行以下操作：
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the case of the `score_votes()` function, the measure by itself tells us
    how well we are doing with our predictions since we can take the number of correct
    predictions (the output of the function call, which is 216), and divide it by
    the number of observations (rows) in the `data_test` object (which is 241). This
    gives us a precision of 89%. This means that if we are given the data from the
    regressors but we don't know how the ward actually voted, 89% of the time, we
    would provide a prediction for whether they wanted to leave or remain in the EU,
    which would be correct. This is pretty good if you ask me.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `score_votes()` 函数的情况下，这个度量本身告诉我们我们的预测做得如何，因为我们可以将正确预测的数量（函数调用的输出，即 216）除以
    `data_test` 对象中的观测数（行数，即 241）。这给我们带来了 89% 的精确度。这意味着如果我们得到了回归者的数据，但我们不知道沃德实际上是如何投票的，那么
    89% 的时间，我们会提供一个预测，即他们是否想要离开或留在欧盟，这个预测将是正确的。如果你问我，这相当不错。
- en: In the case of the `score_proportions()` function, since we're using a more
    abstract measure to be able to know how good we're doing, we would like to compare
    it against other model's scores and get a relative sense of the model's predictive
    power, and that's exactly what we'll do in the following sections.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在`score_proportions()`函数的情况下，由于我们使用更抽象的度量来了解我们做得如何，我们希望将其与其他模型的分数进行比较，并得到模型预测能力的相对感觉，这正是我们将在以下章节中做的。
- en: Programatically finding the best model
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编程寻找最佳模型
- en: Now that we have seen how to produce scores that represent how good or bad a
    model's predictive power is, you may go ahead and start specifying lots of models
    manually by changing the combinations of variables sent to the `lm()` function,
    compute each model's scores, and then choose the ones with the highest predictive
    power. This can potentially take a large amount of time, and you may want to delegate
    it to someone else since it's tedious work. However, fear not. There's a better
    way! Computers are good at repetitive and tedious tasks, and now we'll see how
    to tell the computer to find the best model for us with a little bit of programming.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了如何产生代表模型预测能力好坏的分数，你可以继续手动指定很多模型，通过改变发送给`lm()`函数的变量组合来改变，计算每个模型的分数，然后选择那些预测能力最高的模型。这可能会花费大量时间，你可能希望将其委托给其他人，因为这是一项繁琐的工作。然而，不用担心。有更好的方法！计算机擅长重复和繁琐的任务，现在我们将看到如何通过一点编程告诉计算机为我们找到最佳模型。
- en: The following sections will increase the programming level, but don't worry
    we'll explain the code in detail to make sure that everything is understood. If
    at any point you feel confused, you can always copy-paste small snippets of code
    into your R terminal and see what each of them are doing individually to gradually
    get a sense of the whole thing.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下章节将提高编程水平，但不用担心，我们会详细解释代码，确保一切都能理解。如果你在任何时候感到困惑，你总是可以将代码的小片段复制粘贴到你的R终端中，看看它们各自在做什么，从而逐渐对整个过程有一个整体的感觉。
- en: Generating model combinations
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型组合
- en: 'The first thing we need to do is develop a way of getting the combinations
    of regressors we want to test. Since this is a combinatorial problem, the number
    of combinations is exponential with the number of available options. In our case,
    with the 19 available variables, the number of possible models is the sum of the
    number of models we can create with one regressor plus the number of models we
    can create with two regressors, and so on, until we sum the number of models we
    can create with all 19 regressors. This is what the sum is:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要做的是开发一种获取我们想要测试的回归组合的方法。由于这是一个组合问题，组合的数量与可用选项的数量呈指数级增长。在我们的案例中，有19个可用变量，可能的模型数量是我们可以用一个回归器创建的模型数量加上我们可以用两个回归器创建的模型数量，以此类推，直到我们将我们可以用所有19个回归器创建的模型数量相加。这就是总和：
- en: '![](img/00027.jpeg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00027.jpeg)'
- en: Of course, computing so many models, although easy for a computer, may take
    a while, so we want to limit the minimum and maximum number of regressors allowed
    in the combinations. To do so, we specify the minimum and maximum percentage of
    regressors that will be included in the `min_percentage` and `max_percentage`
    parameters, respectively. In our case, if we specify `min_percentage = 0.9` and
    `max_percentage = 1.0`, we're asking for all combinations that contain between
    17 and 19 of the regressors, which adds up to 191 models. Imagine the time it
    would take you to generate 191 model specifications manually! Hopefully thinking
    about that will make you realize the power of this technique.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，计算这么多模型，虽然对计算机来说很容易，但可能需要一段时间，所以我们希望限制组合中允许的最小和最大回归器数量。为此，我们指定了将包含在`min_percentage`和`max_percentage`参数中的回归器的最小和最大百分比。在我们的案例中，如果我们指定`min_percentage
    = 0.9`和`max_percentage = 1.0`，我们要求包含17到19个回归器的所有组合，这总共是191个模型。想象一下手动生成191个模型规范需要多长时间！希望考虑这一点会让你意识到这种技术的强大。
- en: To start, we create the `generate_combinations_unvectorized()` function that
    will output the a list with all the possible combinations given the `variables`
    and the `min_percentage` and `max_percentage` parameters mentioned earlier. The
    first thing we do is remove the `Proportion` variable by specifying it as `FALSE`
    in the `variables` vector (the `variables` object here corresponds to the `numerical_variables`
    object, but we have adjusted its name within this function to make it more readable).
    The other unwanted variables (`NVotes`, `Leave`, `Vote`, and `RegionName`) were
    removed in the `get_numerical_variable_names()` function at the beginning of the
    chapter. Next, we get the actual names of the variables with `TRUE` values so
    that we can work with string and not Boolean. After that, we compute the total
    number of variables as `n`, and the actual number of variables we will include
    in the combinations by taking the percentage parameters, multiplying them by the
    number of variables, and getting either the *floor* or *ceiling* for that number
    to make sure that we include the extremes. After that, we initialize the `all_combinations`
    object that will contain the list of combinations we want. The next part is the
    progress bar object that we won't explain as we have used it before.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建`generate_combinations_unvectorized()`函数，该函数将输出一个列表，包含所有可能的组合，这些组合由前面提到的`variables`、`min_percentage`和`max_percentage`参数给出。我们首先做的是通过在`variables`向量中将`Proportion`指定为`FALSE`来删除`Proportion`变量（这里的`variables`对象对应于`numerical_variables`对象，但我们已经在这个函数中调整了其名称，使其更易于阅读）。其他不想要的变量（`NVotes`、`Leave`、`Vote`和`RegionName`）在章节开头的`get_numerical_variable_names()`函数中被删除。接下来，我们通过使用`TRUE`值来获取变量的实际名称，这样我们就可以使用字符串而不是布尔值进行操作。然后，我们计算变量的总数`n`，以及我们将包括在组合中的实际变量数量，通过取百分比参数，将它们乘以变量数量，并获取该数字的*floor*或*ceiling*，以确保包括极端值。之后，我们初始化`all_combinations`对象，该对象将包含我们想要的组合列表。接下来是进度条对象，我们不会对其进行解释，因为我们之前已经使用过它。
- en: The actual work is done inside the `for` loop. Notice that it goes from the
    minimum to the maximum number of variables we want inside our combinations. In
    each iteration, we compute the number of combinations which is returned to us
    as a matrix where each column represents a different combination and each row
    contains the index of the variables for that particular combination. This means
    that we need to add each of those columns to our total list of combinations (`all_combinations`),
    which is what we do inside the nested `for` loop. Finally, since we have nested
    lists, we want to use the `unlist()` function to bring them to the *same level*,
    but we don't want to do it recursively because we would just end with a single
    long list and we wouldn't be able to differentiate one combination from another.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 实际工作是在`for`循环内部完成的。请注意，它从我们想要的组合中的最小变量数到最大变量数。在每次迭代中，我们计算组合的数量，它返回给我们一个矩阵，其中每一列代表一个不同的组合，每一行包含该特定组合的变量索引。这意味着我们需要将每一列添加到我们的总组合列表（`all_combinations`）中，这就是我们在嵌套`for`循环内部所做的事情。最后，由于我们有嵌套列表，我们想要使用`unlist()`函数将它们带到*同一级别*，但我们不想递归地这样做，因为我们最终只会得到一个长的列表，我们无法区分一个组合与另一个组合。
- en: I encourage you to change the return statement to avoid using the `recursive
    = FALSE` parameter, as well as avoiding the use of the `unlist()` function at
    all. Doing so will quickly show you what effect they have on the function's output,
    and why we need them.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励您将返回语句更改为避免使用`recursive = FALSE`参数，以及完全避免使用`unlist()`函数。这样做将迅速显示它们对函数输出的影响，以及为什么我们需要它们。
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'A sample output of the object that the `generate_combinations_unvectorized()`
    function does is shown next. As you can see, it''s a list where each element is
    a vector or type `character`. The first combination created contains only 17 variables,
    which is the minimum number of variables used when the total number of variables
    is 19 and the minimum percentage requested is 90%. The last combination (combination
    number 191), contains all 19 variables and corresponds to the model we built manually
    earlier in this chapter:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例显示了`generate_combinations_unvectorized()`函数生成的对象。如您所见，它是一个列表，其中每个元素都是一个向量或类型`character`。创建的第一个组合只包含17个变量，这是当变量总数为19且请求的最小百分比为90%时使用的最小变量数。最后一个组合（组合编号191）包含所有19个变量，对应于我们在本章前面手动构建的模型：
- en: '[PRE20]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Getting only those combinations that contain between 90% and 100% of the variables
    may seem a bit restrictive. What if we want to generate all possible combinations?
    In that case, we would change the first parameter to be 0, but it may not finish
    in a practical amount of time. The reason is that our `generate_combinations_unvectorized()`
    function, as the name implies, is not vectorized, and even worse, has nested `for`
    loops. This is a huge bottleneck in this particular case, and it's something you
    want to look out for in your own code. One possible solution is to make a *vectorized*
    version of the function. For those of you interested, we have included a file
    named `vectorized_vs_unvectorized.R` in this book's code repository ([https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example)),
    that shows the said implementation. We also include some tests that will show
    you just how much faster the vectorized implementation is. Just to give you a
    spoiler, it can be hundreds of times faster! For those cases where vectorizing
    and other approaches that only depend on R itself are not good enough, you can
    try delegating the task to a faster (compiled) language. We will see how to do
    that in [Chapter 9](part0229.html#6QCGQ0-f494c932c729429fb734ce52cafce730), *Implementing
    an Efficient Simple Moving Average.*
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 只获取包含90%至100%变量的组合可能显得有些限制。如果我们想生成所有可能的组合呢？在这种情况下，我们需要将第一个参数更改为0，但可能不会在合理的时间内完成。原因是我们的`generate_combinations_unvectorized()`函数，正如其名称所暗示的，并没有进行向量化，而且更糟糕的是，它包含了嵌套的`for`循环。这在特定情况下是一个巨大的瓶颈，这也是你在自己的代码中需要留意的地方。一个可能的解决方案是制作函数的*向量化*版本。对于那些感兴趣的人，我们在本书的代码仓库中包含了一个名为`vectorized_vs_unvectorized.R`的文件（[https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example)），展示了上述实现。我们还包含了一些测试，将展示向量化实现有多快。仅提前透露一下，它可能快数百倍！对于那些向量化和仅依赖于R本身的其他方法不够好的情况，你可以尝试将任务委托给一个更快的（编译）语言。我们将在第9章中看到如何做到这一点，*实现高效的简单移动平均*。
- en: 'Going back to our example, the next thing to do is to create the `find_best_fit()`
    function, which will go through each of the combinations generated, use the `data_train`
    data to train a model with the corresponding combination, test it''s accuracy
    with the `measure` selection (either `Proportion` (numerical) or `Vote` (categorical))
    and will save the corresponding score in a `scores` vector. Then, it will find
    the index of the optimal score by either finding the minimum or maximum score,
    depending on the `measure` selection we''re using (`Proportion` requires us to
    minimize while `Vote` requires us to maximize), and finally it will recreate the
    optimal model, print it''s information, and return the model to the user. The
    `compute_model_and_fit()`, `compute_score()`, and `print_best_model_info()` functions
    will be developed next as we''re following a top-down approach:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的例子，接下来要做的事情是创建`find_best_fit()`函数，它将遍历生成的每个组合，使用`data_train`数据训练一个具有相应组合的模型，使用`measure`选择（无论是数值的`Proportion`还是分类的`Vote`）来测试其准确性，并将相应的分数保存到`scores`向量中。然后，它将根据我们使用的`measure`选择（`Proportion`要求我们最小化，而`Vote`要求我们最大化）找到最优分数的索引，最后它将重新创建最优模型，打印其信息，并将模型返回给用户。`compute_model_and_fit()`、`compute_score()`和`print_best_model_info()`函数将在我们采用自顶向下的方法时开发：
- en: '[PRE21]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, we create the `compute_model_and_fit()` function, which simply generates
    the formula for the selected combination and uses it within the `lm()` function.
    As you can see in the `combinations` object, we returned previously from the `generate_combinations_unvectorized()`
    function, it''s a list with character vectors, it''s not a formula we can pass
    to the `lm()` function; this is why we need the `generate_model()` function, which
    will take on of these vectors, and concatenate its elements into a single string
    with the plus (`+`) sign between them by using the `paste()` function with the
    `collapse = " + "` argument, and it will prepend the `Proportion ~` string to
    it. This gives us back a formula object specified by a string like `Proportion
    ~ Residents + ... + NonWhite`, which contains, instead of the dots, all the variables
    in the first combination shown in the preceding code. This string is then used
    inside the `lm()` function to execute our regression, and both `model` and `fit`
    are returned within a list to be used in the following steps:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建 `compute_model_and_fit()` 函数，该函数简单地生成所选组合的公式，并在 `lm()` 函数中使用它。正如您在
    `combinations` 对象中看到的，我们之前从 `generate_combinations_unvectorized()` 函数返回的它是一个包含字符向量的列表，它不是一个可以传递给
    `lm()` 函数的公式；这就是为什么我们需要 `generate_model()` 函数，它将接受这些向量之一，并使用 `paste()` 函数和 `collapse
    = " + "` 参数将它们连接成一个由加号（`+`）分隔的单个字符串，并在其前面添加 `Proportion ~` 字符串。这给我们返回一个由字符串指定的公式对象，如
    `Proportion ~ Residents + ... + NonWhite`，其中包含的不是省略号，而是前面代码中显示的第一个组合中的所有变量。然后，我们使用这个字符串在
    `lm()` 函数中执行回归，并将 `model` 和 `fit` 都返回在一个列表中，以便在后续步骤中使用：
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As can be seen by the `score <- compute_score(measure, results[["fit"]], data_test)`
    line, the `compute_score()` function receives a `measure` object, a `fit` object
    (which comes from the `results` list), and the data used for testing. It computes
    the score using the *strategy* pattern mentioned earlier for the plots used to
    check the normality assumption. Basically, depending on the value of the `measure`
    string (the chosen strategy), it will choose one of the two functions that share
    the same signature, and that function will be used to compute the final predictions.
    We send the `se.fit = TRUE` parameter to the `predict()` function we had seen
    before because we want the standard errors to also be sent in case we use the
    numerical score which requires them. The `score_proportions()` and `score_votes()`
    functions were defined previously in this chapter:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如 `score <- compute_score(measure, results[["fit"]], data_test)` 行所示，`compute_score()`
    函数接收一个 `measure` 对象、一个 `fit` 对象（来自 `results` 列表），以及用于测试的数据。它使用之前提到的 *策略模式* 来计算用于检查正态性假设的图表的得分。基本上，根据
    `measure` 字符串（选择的策略）的值，它将选择两个具有相同签名的函数之一，并使用该函数来计算最终的预测。我们向之前看到的 `predict()` 函数发送
    `se.fit = TRUE` 参数，因为我们希望标准误差也一起发送，以防我们使用需要它们的数值得分。`score_proportions()` 和 `score_votes()`
    函数在本章中之前已定义：
- en: '[PRE23]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, we create a little convenience function called `print_best_model_info()`
    that will print results about the best model found. It simply takes the index
    of the best model, the model formula, its score, and the measure type, and prints
    all of that for the user. As you can see, since the `model` object is not a simple
    string but a *formula* object, we need to work a little with it to get the results
    we want by converting it into a string and splitting it using the plus sign (`+`)
    we know is included; otherwise, it would be a very long string:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们创建了一个名为 `print_best_model_info()` 的小型便利函数，该函数将打印找到的最佳模型的结果。它简单地接受最佳模型的索引、模型公式、其得分和度量类型，并将所有这些信息打印给用户。正如您所看到的，由于
    `model` 对象不是一个简单的字符串，而是一个 *公式* 对象，我们需要稍微处理一下它，通过将其转换为字符串并使用我们知道的包含加号（`+`）来分割它，以获取我们想要的结果；否则，它将是一个非常长的字符串：
- en: '[PRE24]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We can find the best model, according to the `Proportion` measure by calling
    the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过调用以下命令来根据 `Proportion` 度量找到最佳模型：
- en: '[PRE25]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As we can see, the best model was the third one out of the 191 models, and it
    had a score of 10.23\. We can also see the regressors used in the model. As you
    can see, `NonWhite` and `HighEducationLevel` were left out by the optimization
    method, probably due to their counterparts containing all the information necessary
    for their respective groups. It's no coincidence that those are among the most
    representative variables in the data.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，最佳模型是191个模型中的第三个，得分为10.23。我们还可以看到模型中使用的回归变量。如您所见，`NonWhite`和`HighEducationLevel`被优化方法排除在外，这可能是由于它们的对应变量包含了它们各自组所需的所有信息。这不是巧合，这些是数据中最具代表性的变量之一。
- en: 'To find the best model according to the `Vote` measure, we use the following
    code. Note that given the good techniques we used to create this function, all
    we have to do is change the value of the `measure` parameter to optimize our search
    using a different approach:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 要根据`Vote`度量找到最佳模型，我们使用以下代码。请注意，鉴于我们创建此函数时使用的良好技术，我们只需更改`measure`参数的值，就可以使用不同的方法来优化我们的搜索：
- en: '[PRE26]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In this case, the best model was the seventh one out of the 191 models, with
    220 out of 241 correct predictions, which gives us an accuracy of 91%, an improvement
    given the accuracy we had computed earlier in the chapter. In this case, `LowEducationLevel`
    and `Age_18to44` were left out. Again, no coincidence that these are part of the
    most important variables in the data.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，最佳模型是191个模型中的第七个，有241个正确预测中的220个，这给我们带来了91%的准确性，这是一个相对于我们在本章早期计算的准确性的改进。在这种情况下，`LowEducationLevel`和`Age_18to44`被排除在外。再次强调，这不是巧合，这些是数据中最重要变量的一部分。
- en: Predicting votes from wards with unknown data
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从未知数据的选区预测投票
- en: 'Now that we know how to train our models and find the best one possible, we
    will provide predictions for those wards for which we don''t have voting data
    using the best models we found using the `Vote` measure. To do so, we simply execute
    the following line:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了如何训练我们的模型并找到最佳的可能模型，我们将使用使用`Vote`度量找到的最佳模型来预测那些我们没有投票数据的选区的预测。为此，我们只需执行以下行：
- en: '[PRE27]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This will take the best model we found earlier using the `Votes` measure and
    use it to generate predictions for the `Proportion` variable in the `data_incomplete`
    data, which contains those observations for which we don't have any voting data.
    These are the best predictions we can provide with what we have done so far and
    we can expect them to have a 91% accuracy when used to categorize the `Proportion`
    variable into the `Vote` variable.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使用我们之前使用`Votes`度量找到的最佳模型，并利用它来生成对`data_incomplete`数据中`Proportion`变量的预测，这些数据包含我们没有任何投票数据的观测值。这是我们目前所能提供的最佳预测，并且我们预计当用于将`Proportion`变量分类到`Vote`变量时，它们将有91%的准确性。
- en: Summary
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter showed how to use multiple linear regression models, one of the
    most commonly used family of models, to predict numerical and categorical data.
    Our focus was on showing programming techniques that allow analysts to be more
    efficient in the projects while keeping their code quality high. We did so by
    showing how to create different model combinations programatically, measuring
    the predictive accuracy, and selecting the best one. The techniques used can easily
    be used with other, more advanced, types of models, and we encourage you to try
    to improve on the predictive accuracy by using other families of models. In the
    code that accompanies this book ([https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example)),
    you can find an implementation that also uses generalized linear models to produce
    predictions.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了如何使用多重线性回归模型，这是最常用的模型家族之一，来预测数值和分类数据。我们的重点是展示编程技术，这些技术允许分析师在保持代码质量高的同时提高项目效率。我们通过展示如何程序化地创建不同的模型组合、测量预测准确性和选择最佳模型来实现这一点。所使用的技巧可以很容易地用于其他更高级的模型类型，我们鼓励您尝试使用其他模型家族来提高预测准确性。在本书附带的代码（[https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example)）中，您可以找到一个实现，它还使用了广义线性模型来生成预测。
- en: In the following chapter, we will start working with a different and slightly
    less technical example that uses product data from a hypothetical company to show
    how to work with manipulative data in a variety of ways and use it with many kinds
    of visualizations, including 3D, interactive, and geospatial graphs.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始使用一个不同且技术性略低的示例，该示例使用一家假设公司的产品数据来展示如何以多种方式处理操纵性数据，并将其用于多种可视化，包括3D、交互式和地理空间图。
