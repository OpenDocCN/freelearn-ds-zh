- en: '*Chapter 5*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第五章*'
- en: Handling Missing Values and Correlation Analysis
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理缺失值和相关性分析
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Detect and handle missing values in data using PySpark
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PySpark检测和处理数据中的缺失值
- en: Describe correlations between variables
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述变量之间的相关性
- en: Compute correlations between two or more variables in PySpark
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算PySpark中两个或多个变量之间的相关性
- en: Create a correlation matrix using PySpark
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PySpark创建相关矩阵
- en: In this chapter, we will be using the Iris dataset to handle missing data and
    find correlations between data values.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Iris数据集处理缺失数据并找到数据值之间的相关性。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapter, we learned the basic concepts of Spark DataFrames and
    saw how to leverage them for big data analysis.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了Spark DataFrame的基本概念，并了解了如何利用它们进行大数据分析。
- en: In this chapter, we will go a step further and learn about handling missing
    values in data and correlation analysis with Spark DataFrames—concepts that will
    help us with data preparation for machine learning and exploratory data analysis.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将进一步学习如何处理数据中的缺失值和进行相关性分析，这些概念将帮助我们为机器学习和探索性数据分析准备数据。
- en: We will briefly cover these concepts to provide the reader with some context,
    but our focus is on their implementation with Spark DataFrames. We will use the
    same Iris dataset that we used in the previous chapter for the exercises in this
    chapter as well. But the Iris dataset has no missing values, so we have randomly
    removed two entries from the `Sepallength` column and one entry from the `Petallength`
    column from the original dataset. So, now we have a dataset with missing values,
    and we will learn how to handle these missing values using PySpark.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将简要介绍这些概念，以便为读者提供一些背景，但我们将重点介绍如何在Spark DataFrame中实现它们。我们将使用上一章中使用的相同Iris数据集进行本章的练习。但由于Iris数据集没有缺失值，我们随机从原始数据集中删除了`Sepallength`列中的两个条目和`Petallength`列中的一个条目。因此，现在我们有了一个包含缺失值的数据集，我们将学习如何使用PySpark处理这些缺失值。
- en: We will also look at the correlation between the variables in the Iris dataset
    by computing their correlation coefficients and correlation matrix.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将通过计算相关系数和相关矩阵来查看Iris数据集中变量之间的相关性。
- en: Setting up the Jupyter Notebook
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置Jupyter Notebook
- en: 'The following steps are required before getting started with the exercises:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 开始练习之前，需要执行以下步骤：
- en: 'Import all the required modules and packages in the Jupyter notebook:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Jupyter Notebook中导入所有必要的模块和包：
- en: '[PRE0]'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, use the following command to set up `SparkContext`:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令设置`SparkContext`：
- en: '[PRE1]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Similarly, use the following command to set up `SQLContext` in the Jupyter
    notebook:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，使用以下命令在Jupyter Notebook中设置`SQLContext`：
- en: '[PRE2]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'Make sure you have the PySpark CSV reader package from the Databricks website
    ([https://databricks.com/](https://databricks.com/)) installed and ready before
    executing the next command. If not, then download it using the following command:'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在执行下一个命令之前，确保已经从Databricks网站（[https://databricks.com/](https://databricks.com/)）安装并准备好PySpark
    CSV读取器包。如果没有，请使用以下命令下载：
- en: '`pyspark –packages com.databricks:spark-csv_2.10:1.4.0`'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`pyspark –packages com.databricks:spark-csv_2.10:1.4.0`'
- en: 'Read the Iris dataset from the CSV file into a Spark DataFrame:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将Iris数据集从CSV文件读取到Spark DataFrame中：
- en: '[PRE3]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述命令的输出如下：
- en: '[PRE4]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Figure 5.1: Iris DataFrame](img/C12913_05_01.jpg)'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图5.1：Iris DataFrame](img/C12913_05_01.jpg)'
- en: 'Figure 5.1: Iris DataFrame'
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.1：Iris DataFrame
- en: Missing Values
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失值
- en: The data entries with no value assigned to them are called **missing values**.
    In the real world, encountering missing values in data is common. Values may be
    missing for a wide variety of reasons, such as non-responsiveness of the system/responder,
    data corruption, and partial deletion.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 没有分配值的数据项称为**缺失值**。在实际应用中，数据中遇到缺失值是很常见的。缺失值可能由多种原因造成，例如系统/响应者无响应、数据损坏或部分删除。
- en: Some fields are more likely than other fields to contain missing values. For
    example, income data collected from surveys is likely to contain missing values,
    because of people not wanting to disclose their income.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 某些字段比其他字段更容易包含缺失值。例如，来自调查的收入数据可能包含缺失值，因为人们不愿透露自己的收入。
- en: Nevertheless, it is one of the major problems plaguing the data analytics world.
    Depending on the percentage of missing data, missing values may prove to be a
    significant challenge in data preparation and exploratory analysis. So, it's important
    to calculate the missing data percentage before getting started with data analysis.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这仍然是困扰数据分析领域的主要问题之一。根据缺失数据的比例，缺失值可能会成为数据准备和探索性分析中的重大挑战。因此，在开始数据分析之前，计算缺失数据的百分比是非常重要的。
- en: In the following exercise, we will learn how to detect and calculate the number
    of missing value entries in PySpark DataFrames.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的练习中，我们将学习如何检测并计算 PySpark DataFrame 中缺失值的数量。
- en: 'Exercise 38: Counting Missing Values in a DataFrame'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 38：统计 DataFrame 中的缺失值
- en: 'In this exercise, we will learn how to count the missing values from the PySpark
    DataFrame column:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将学习如何统计 PySpark DataFrame 列中的缺失值：
- en: 'Use the following command to check whether the Spark DataFrame has missing
    values or not:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令检查 Spark DataFrame 是否存在缺失值：
- en: '[PRE5]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we will count the missing values in the `Sepallength` column of the Iris
    dataset loaded in the PySpark DataFrame `df` object:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将统计加载到 PySpark DataFrame `df` 对象中的鸢尾花数据集 `Sepallength` 列中的缺失值：
- en: '[PRE6]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE7]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Exercise 39: Counting Missing Values in All DataFrame Columns'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 39：统计 DataFrame 所有列中的缺失值
- en: 'In this exercise, we will count the missing values present in all the columns
    of a PySpark DataFrame:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将统计 PySpark DataFrame 所有列中的缺失值：
- en: 'First, import all the required modules, as illustrated here:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导入所有必需的模块，如下所示：
- en: '[PRE8]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now let''s show the data using the following command:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令显示数据：
- en: '[PRE9]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is as follows:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![](img/C12913_05_02.jpg)'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C12913_05_02.jpg)'
- en: 'Figure 5.2: Iris DataFrame, counting missing values'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.2：鸢尾花 DataFrame，统计缺失值
- en: The output shows we have `2` missing entries in the `Seapllength` column and
    `1` missing entry in the `Petallength` column in the PySpark DataFrame.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果显示，`Seapllength` 列中有 `2` 个缺失值，而 `Petallength` 列中有 `1` 个缺失值，出现在 PySpark DataFrame
    中。
- en: 'A simple way is to just use the `describe()` function, which gives the count
    of non-missing values for each column, along with a bunch of other summary statistics.
    Let''s execute the following command in the notebook:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种简单的方法是使用 `describe()` 函数，它提供每一列非缺失值的数量，并给出一些其他汇总统计数据。我们在笔记本中执行以下命令：
- en: '[PRE10]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Figure 5.3: Iris DataFrame, counting the missing values using different approach](img/C12913_05_03.jpg)'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 5.3：鸢尾花 DataFrame，使用不同方法统计缺失值](img/C12913_05_03.jpg)'
- en: 'Figure 5.3: Iris DataFrame, counting the missing values using different approach'
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.3：鸢尾花 DataFrame，使用不同方法统计缺失值
- en: As we can see, there are `148` non-missing values in the `Sepallength` column,
    indicating `2` missing entries and `149` non-missing values in the `Petallength`
    column, indicating `1` missing entry.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，`Sepallength` 列中有 `148` 个非缺失值，表示有 `2` 个缺失值，而 `Petallength` 列中有 `149` 个非缺失值，表示有
    `1` 个缺失值。
- en: In the following section, we will explore how to find the missing values from
    the DataFrame.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将探讨如何从 DataFrame 中查找缺失值。
- en: Fetching Missing Value Records from the DataFrame
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从 DataFrame 中获取缺失值记录
- en: 'We can also filter out the records containing the missing value entries from
    the PySpark DataFrame using the following code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用以下代码过滤掉 PySpark DataFrame 中包含缺失值记录的行：
- en: '[PRE11]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](img/C12913_05_04.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12913_05_04.jpg)'
- en: 'Figure 5.4: Iris DataFrame, fetching the missing value'
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.4：鸢尾花 DataFrame，获取缺失值
- en: The `show` function displays the first 20 records of a PySpark DataFrame. We
    only get two here as the `Sepallength` column only has two records with missing
    entries.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`show` 函数显示 PySpark DataFrame 中的前 20 条记录。由于 `Sepallength` 列只有两条缺失值记录，所以我们这里只看到两条。'
- en: Handling Missing Values in Spark DataFrames
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理 Spark DataFrame 中的缺失值
- en: Missing value handling is one of the complex areas of data science. There are
    a variety of techniques that are used to handle missing values depending on the
    type of missing data and the business use case at hand.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失值是数据科学中一个复杂的领域。根据缺失数据的类型和具体业务场景，存在多种技术用于处理缺失值。
- en: 'These methods range from simple logic-based methods to advanced statistical
    methods such as regression and KNN. However, irrespective of the method used to
    tackle the missing values, we will end up performing one of the following two
    operations on the missing value data:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法包括从基于简单逻辑的方法到先进的统计方法，如回归和 KNN。然而，无论采用何种方法来处理缺失值，最终我们都会对缺失值数据执行以下两种操作之一：
- en: Removing the records with missing values from the data
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据中删除包含缺失值的记录
- en: Imputing the missing value entries with some constant value
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用某个常数值填充缺失的条目
- en: In this section, we will explore how to do both these operations with PySpark
    DataFrames.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探索如何使用 PySpark DataFrame 执行这两个操作。
- en: 'Exercise 40: Removing Records with Missing Values from a DataFrame'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 40：从 DataFrame 中删除包含缺失值的记录
- en: 'In this exercise, we will remove the records containing missing value entries
    for the PySpark DataFrame. Let''s perform the following steps:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将删除包含缺失值条目的 PySpark DataFrame 记录。请执行以下步骤：
- en: 'To remove the missing values from a particular column, use the following command:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从特定列中删除缺失值，可以使用以下命令：
- en: '[PRE12]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The previous code will return `148` as the output as the two records containing
    missing entries for the `Sepallength` column have been removed from the PySpark
    DataFrame.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码将返回 `148` 作为输出，因为包含缺失值条目的两条 `Sepallength` 列记录已经从 PySpark DataFrame 中删除。
- en: 'To remove all the records containing any missing value entry for any column
    from the PySpark DataFrame, use the following command:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要删除 PySpark DataFrame 中包含任何列的缺失值条目的所有记录，请使用以下命令：
- en: '[PRE13]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The DataFrame had `3` records with missing values, as we saw in *Exercise 2:
    Counting Missing Values in all DataFrame Columns*—two records with missing entries
    for the `Sepallength` column and one with a missing entry for the `Petallength`
    column.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 中有 `3` 条记录缺失了值，正如我们在 *练习 2：计算所有 DataFrame 列中缺失的值* 中看到的那样——其中有两条记录在
    `Sepallength` 列中缺失值，另外一条记录在 `Petallength` 列中缺失值。
- en: The previous code removes all three records, thereby returning 147 complete
    records in the PySpark DataFrame.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码删除了所有三条记录，从而在 PySpark DataFrame 中返回了 147 条完整的记录。
- en: 'Exercise 41: Filling Missing Values with a Constant in a DataFrame Column'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 41：用常数填充 DataFrame 列中的缺失值
- en: In this exercise, we will replace the missing value entries of the PySpark DataFrame
    column with a constant numeric value.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将把 PySpark DataFrame 列的缺失值条目替换为常数数值。
- en: 'Our DataFrame has missing values in two columns—`Sepallength` and `Petallength`:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 DataFrame 中有两个列包含缺失值——`Sepallength` 和 `Petallength`：
- en: 'Now, let''s replace the missing value entries in both these columns with a
    constant numeric value of `1`:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将这两列中的缺失值条目都替换为常数数值 `1`：
- en: '[PRE14]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, let''s count the missing values in the new DataFrame, `y`, that we just
    created. The new DataFrame should have no missing values:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们统计刚刚创建的新 DataFrame `y` 中的缺失值。这个新 DataFrame 应该没有缺失值：
- en: '[PRE15]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output is as follows:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 5.5: Iris DataFrame, finding the missing value](img/Image43351.jpg)'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 5.5：Iris DataFrame，查找缺失值](img/Image43351.jpg)'
- en: 'Figure 5.5: Iris DataFrame, finding the missing value'
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.5：Iris DataFrame，查找缺失值
- en: Sometimes, we want to replace all the missing values in the DataFrame with a
    single constant value.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有时，我们希望用单一的常数值替换 DataFrame 中所有的缺失值。
- en: 'Use the following command to replace all the missing values in the PySpark
    DataFrame with a constant numeric value of 1:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将 PySpark DataFrame 中所有缺失的值替换为常数数值 1：
- en: '[PRE16]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, let''s count the missing values in the new DataFrame `z` that we just
    created. The new DataFrame should have no missing values:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们统计刚刚创建的新 DataFrame `z` 中的缺失值。这个新 DataFrame 应该没有缺失值：
- en: '[PRE17]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is as follows:'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 5.6: Iris DataFrame, printing the missing value](img/Image43362.jpg)'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 5.6：Iris DataFrame，打印缺失值](img/Image43362.jpg)'
- en: 'Figure 5.6: Iris DataFrame, printing the missing value'
  id: totrans-98
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.6：Iris DataFrame，打印缺失值
- en: Correlation
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关性
- en: Correlation is a statistical measure of the level of association between two
    numerical variables. It gives us an idea of how closely two variables are related
    with each other. For example, age and income are quite closely related variables.
    It has been observed that the average income grows with age within a threshold.
    Thus, we can assume that age and income are positively correlated with each other.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性是衡量两个数值变量之间关联程度的统计量。它给我们一个关于两个变量彼此关系密切程度的概念。例如，年龄和收入是非常相关的变量。观察发现，在一定的阈值范围内，平均收入会随着年龄的增长而增加。因此，我们可以假设年龄和收入之间是正相关的。
- en: Note
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: However, correlation does not establish a **cause-effect relationship**. A cause-effect
    relationship means that one variable is causing a change in another variable.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，相关性并不建立**因果关系**。因果关系意味着一个变量正在引起另一个变量的变化。
- en: The most common metric used to compute this association is the **Pearson Product-Moment
    Correlation**, commonly known as **Pearson correlation coefficient** or simply
    as the **correlation coefficient**. It is named after its inventor, *Karl Pearson*.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 用来计算这种关联的最常见指标是**皮尔逊积矩相关系数**，通常称为**皮尔逊相关系数**或简写为**相关系数**。它以其发明者*卡尔·皮尔逊*的名字命名。
- en: The Pearson correlation coefficient is computed by dividing the covariance of
    the two variables by the product of their standard deviations. The correlation
    value lies between *-1* and *+1* with values close to *1* or *-1* signifying strong
    association and values close to *0*, signifying weak association. The sign (`+`,
    `-`) of the coefficient tells us whether the association is positive (both variables
    increase/decrease together) or negative (vice-versa).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 皮尔逊相关系数通过将两个变量的协方差除以它们标准差的乘积来计算。相关值介于*-1*和*+1*之间，接近*1*或*-1*的值表示强关联，接近*0*的值表示弱关联。系数的符号（`+`，`-`）告诉我们关联是正相关（两个变量一起增加/减少）还是负相关（反之亦然）。
- en: Note
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Correlation only captures the linear association between variables. So, if the
    association is non-linear, the correlation coefficient won't capture it. Two disassociated
    variables will have a low or zero correlation coefficient, but variables with
    zero/low correlation values are not necessarily disassociated.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性仅捕捉变量之间的线性关联。因此，如果关联是非线性的，相关系数将无法捕捉到它。两个不相关的变量将具有较低或零的相关系数，但零/低相关值的变量不一定是完全不相关的。
- en: Correlation is of great importance in statistical analysis, as it helps explain
    the data and sometimes highlights predictive relationships between variables.
    In this section, we will learn how to compute correlation between variables and
    compute a correlation matrix in PySpark.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性在统计分析中具有重要意义，因为它帮助解释数据，有时还突出变量之间的预测关系。在这一部分，我们将学习如何计算变量之间的相关性，并在 PySpark
    中计算相关矩阵。
- en: 'Exercise 42: Computing Correlation'
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 42：计算相关性
- en: 'In this exercise, we will compute the value of the Pearson correlation coefficient
    between two numerical variables and a correlation matrix for all the numerical
    columns of our PySpark DataFrame. The correlation matrix helps us visualize the
    correlation of all the numerical columns with each other:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将计算两个数值变量之间的皮尔逊相关系数以及我们 PySpark DataFrame 中所有数值列的相关矩阵。相关矩阵帮助我们可视化所有数值列之间的相关性：
- en: 'Perform the following steps to calculate the correlation between two variables:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下步骤计算两个变量之间的相关性：
- en: '[PRE18]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The previous code outputs the Pearson correlation coefficient of `-0.1122503554120474`
    between the two variables mentioned.
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码输出了这两个变量之间的皮尔逊相关系数`-0.1122503554120474`。
- en: 'Import the relevant modules, as illustrated here:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如下所示，导入相关模块：
- en: '[PRE19]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Remove any missing values from the data with the following command:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令删除数据中的任何缺失值：
- en: '[PRE20]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To remove any non-numerical columns before computing the correlation matrix,
    use the following command:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在计算相关矩阵之前，使用以下命令去除任何非数值列：
- en: '[PRE21]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, let''s compute the correlation matrix with the help of the following command:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用以下命令计算相关矩阵：
- en: '[PRE22]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To convert the matrix into a pandas DataFrame for easy visualization, execute
    the following command:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将矩阵转换为 pandas DataFrame 以便于可视化，执行以下命令：
- en: '[PRE23]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Rename the indexes of the pandas DataFrame with the name of the columns from
    the original PySpark DataFrame:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用原始 PySpark DataFrame 中列的名称重命名 pandas DataFrame 的索引：
- en: '[PRE24]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, visualize the pandas DataFrame with the following command:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令可视化 pandas DataFrame：
- en: '[PRE25]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![Figure 5.7: Iris DataFrame, computing correlation](img/C12913_05_07.jpg)'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 5.7：鸢尾花数据框，计算相关性](img/C12913_05_07.jpg)'
- en: 'Figure 5.7: Iris DataFrame, computing correlation'
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.7：鸢尾花数据框，计算相关性
- en: 'Activity 12: Missing Value Handling and Correlation Analysis with PySpark DataFrames'
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 12：缺失值处理和使用PySpark数据框的相关性分析
- en: 'In this activity, we will detect and handle missing values in the Iris dataset.
    We will also compute the correlation matrix and verify the variables showing strong
    correlations by plotting them with each other and fitting a linear line on the
    plot:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，我们将检测和处理鸢尾花数据集中的缺失值。我们还将计算相关矩阵，并通过将变量绘制在一起并在图表上拟合一条线性线来验证显示强相关性的变量：
- en: Perform the initial procedure of importing packages and libraries in the Jupyter
    notebook.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Jupyter笔记本中执行导入包和库的初始程序。
- en: Set up `SparkContext` and `SQLContext`.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置`SparkContext`和`SQLContext`。
- en: 'Read the data from the CSV file into a Spark object:![Figure 5.8: Iris DataFrame,
    reading data from the DataFrame](img/C12913_05_08.jpg)'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从CSV文件读取数据到Spark对象中：![图 5.8：鸢尾花数据框，读取数据](img/C12913_05_08.jpg)
- en: 'Figure 5.8: Iris DataFrame, reading data from the DataFrame'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.8：鸢尾花数据框，读取数据
- en: Fill in the missing values in the `Sepallength` column with its column mean.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用`Sepallength`列的列均值填充缺失值。
- en: Compute the correlation matrix for the dataset. Make sure to import the required
    modules.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算数据集的相关矩阵。确保导入所需的模块。
- en: Remove the `String` columns from the PySpark DataFrame and compute the correlation
    matrix in the Spark DataFrame.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从PySpark数据框中移除`String`列，并计算Spark数据框中的相关矩阵。
- en: 'Convert the correlation matrix into a pandas DataFrame:![Figure 5.9: Iris DataFrame,
    converting the correlation matrix into a pandas DataFrame](img/C12913_05_09.jpg)'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将相关矩阵转换为pandas数据框：![图 5.9：鸢尾花数据框，将相关矩阵转换为pandas数据框](img/C12913_05_09.jpg)
- en: 'Figure 5.9: Iris DataFrame, converting the correlation matrix into a pandas
    DataFrame'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.9：鸢尾花数据框，将相关矩阵转换为pandas数据框
- en: Load the required modules and plotting data to plot the variable pairs showing
    strong positive correlation and fit a linear line on them.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载所需的模块并绘制数据，绘制显示强正相关的变量对，并在其上拟合一条线性线。
- en: 'This is the graph for `x = "Sepallength", y = "Petalwidth"`:'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是`x = "Sepallength", y = "Petalwidth"`的图表：
- en: '![Figure 5.10: Iris DataFrame, plotting graph as x = “Sepallength”, y = “Petalwidth”](img/C12913_05_10.jpg)'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 5.10：鸢尾花数据框，绘制图表，x = “Sepallength”，y = “Petalwidth”](img/C12913_05_10.jpg)'
- en: 'Figure 5.10: Iris DataFrame, plotting graph as x = "Sepallength", y = "Petalwidth"'
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.10：鸢尾花数据框，绘制图表，x = "Sepallength"，y = "Petalwidth"
- en: 'This is the graph for `x = "Sepallength", y = "Petalwidth"`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`x = "Sepallength", y = "Petalwidth"`的图表：
- en: '![Figure 5.11: Iris DataFrame, plotting graph as x = “Sepallength”, y = “Petalwidth”](img/C12913_05_11.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.11：鸢尾花数据框，绘制图表，x = “Sepallength”，y = “Petalwidth”](img/C12913_05_11.jpg)'
- en: 'Figure 5.11: Iris DataFrame, plotting graph as x = "Sepallength", y = "Petalwidth"'
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.11：鸢尾花数据框，绘制图表，x = "Sepallength"，y = "Petalwidth"
- en: 'This is the graph for `x = "Petallength", y = "Petalwidth"`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`x = "Petallength", y = "Petalwidth"`的图表：
- en: '![Figure 5.12: Iris DataFrame, plotting graph as x = “Petallength”, y = “Petalwidth”](img/C12913_05_12.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.12：鸢尾花数据框，绘制图表，x = “Petallength”，y = “Petalwidth”](img/C12913_05_12.jpg)'
- en: 'Figure 5.12: Iris DataFrame, plotting graph as x = "Petallength", y = "Petalwidth"'
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.12：鸢尾花数据框，绘制图表，x = "Petallength"，y = "Petalwidth"
- en: Note
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Alternatively, you can use any dataset for this activity.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以使用任何数据集进行此活动。
- en: The solution for this activity can be found on page 229.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以在第229页找到。
- en: Summary
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned how to detect and handle the missing values in PySpark
    DataFrames. We looked at how to perform correlation and a metric to quantify the
    Pearson correlation coefficient. Later, we computed Pearson correlation coefficients
    for different numerical variable pairs and learned how to compute the correlation
    matrix for all the variables in the PySpark DataFrame.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们学习了如何在PySpark数据框中检测和处理缺失值。我们研究了如何进行相关性分析，并量化皮尔逊相关系数的指标。随后，我们计算了不同数值变量对的皮尔逊相关系数，并学习了如何计算PySpark数据框中所有变量的相关矩阵。
- en: In the next chapter, we will learn what problem definition is, and understand
    how to perform KPI generation. We will also use the data aggregation and data
    merge operations (learned about in previous chapters) and analyze data using graphs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习什么是问题定义，并理解如何进行KPI生成。我们还将使用数据聚合和数据合并操作（在前面的章节中学习过）并使用图表分析数据。
