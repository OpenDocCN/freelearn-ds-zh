- en: Restructuring Data into a Tidy Form
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据重构为整洁形式
- en: All the datasets used in the preceding chapters have not had much or any work
    done to change their structure. We immediately began processing the datasets in
    their original shape. Many datasets in the wild will need a significant amount
    of restructuring before commencing a more detailed analysis. In some cases, an
    entire project might only be concerned with formatting the data in such a way
    that it can be easily processed by someone else.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 前几章中使用的所有数据集都没有经过太多或任何结构变化的处理。我们直接开始在原始形态下处理这些数据集。许多实际中的数据集在开始更详细分析之前需要进行大量的重构。在某些情况下，整个项目可能仅仅是为了将数据格式化成某种方式，以便其他人能够轻松处理。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Tidying variable values as column names with `stack`
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`stack`将变量值整洁化为列名
- en: Tidying variable values as column names with `melt`
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`melt`将变量值整洁化为列名
- en: Stacking multiple groups of variables simultaneously
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时堆叠多个变量组
- en: Inverting stacked data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反转堆叠数据
- en: Unstacking after a `groupby` aggregation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`groupby`聚合后进行反向堆叠
- en: Replicating `pivot_table` with a `groupby` aggregation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`groupby`聚合实现`pivot_table`的功能
- en: Renaming axis levels for easy reshaping
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了方便重构而重命名轴级
- en: Tidying when multiple variables are stored as column names
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当多个变量作为列名存储时的整洁化
- en: Tidying when multiple variables are stored as column values
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当多个变量存储为列值时的整洁化
- en: Tidying when two or more values are stored in the same cell
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当两个或多个值存储在同一单元格中时的整洁化
- en: Tidying when variables are stored in column names and values
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当变量存储在列名和列值中时的整洁化
- en: Tidying when multiple observational units are stored in the same table
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当多个观察单元存储在同一张表格中时进行整洁化
- en: There are many terms that are used to describe the process of data restructuring,
    with **tidy data** being the most common to data scientists. Tidy data is a term
    coined by Hadley Wickham to describe a form of data that makes analysis easy to
    do. This chapter will cover many ideas formulated by Hadley and how to accomplish
    them with pandas. To learn a great deal more about tidy data, read Hadley's paper
    ([http://vita.had.co.nz/papers/tidy-data.pdf](http://vita.had.co.nz/papers/tidy-data.pdf)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 用于描述数据重构过程的术语有很多，其中**整洁数据**是数据科学家最常用的术语。整洁数据是Hadley Wickham创造的术语，用来描述一种便于分析的数据形式。本章将讨论Hadley提出的许多想法以及如何通过pandas实现这些想法。要深入了解整洁数据，请阅读Hadley的论文（[http://vita.had.co.nz/papers/tidy-data.pdf](http://vita.had.co.nz/papers/tidy-data.pdf)）。
- en: 'What is tidy data? Hadley puts forth three simple guiding principles that determine
    whether a dataset is tidy or not:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是整洁数据？Hadley提出了三个简单的指导原则来决定一个数据集是否整洁：
- en: Each variable forms a column
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个变量形成一列
- en: Each observation forms a row
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个观察形成一行
- en: Each type of observational unit forms a table
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每种类型的观察单元形成一个表格
- en: Any dataset that does not meet these guidelines is considered messy. This definition
    will make more sense once we start restructuring our data into tidy form, but
    for now, we'll need to know what variables, observations, and observational units
    are.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 任何不符合这些指南的数据集都被认为是杂乱的。这个定义在我们开始将数据重构为整洁形式后会更有意义，但现在我们需要知道什么是变量、观察和观察单元。
- en: To gain intuition about what a variable actually is, it is good to think about
    the distinction between a variable name and the variable value. The variable names
    are labels, such as gender, race, salary, and position. The variable values are
    those things liable to change for every observation, such as male/female for gender
    or white/black for race. A single observation is the collection of all variable
    values for a single observational unit. To help understand what an observational
    unit might be, consider a retail store, which has data for each transaction, employee,
    customer, item, and the store itself. Each of these can be considered an observational
    unit and would require its own table. Combining employee information (like the
    number of hours worked) with customer information (like amount spent) in the same
    table would break this tidy principle.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解变量究竟是什么，考虑一下变量名与变量值的区别是非常有帮助的。变量名是标签，如性别、种族、薪资和职位；变量值则是那些在每次观察中可能变化的内容，如性别的“男/女”或种族的“白人/黑人”。一个单独的观察就是一个观察单元所有变量值的集合。为了帮助理解观察单元的概念，假设有一家零售店，它有每个交易、员工、顾客、商品和店铺本身的数据。每个都可以被认为是一个观察单元，需要自己独立的表格。将员工信息（如工作时长）与顾客信息（如消费金额）放在同一张表格中会破坏整洁化原则。
- en: 'The first step to resolving messy data is to recognize it when it exists, and
    there are boundless possibilities. Hadley explicitly mentions five of the most
    common types of messy data:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 解决杂乱数据的第一步是识别它的存在，而杂乱数据的种类有无穷多种。Hadley明确提到五种最常见的杂乱数据类型：
- en: Column names are values, not variable names
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列名是值，而不是变量名
- en: Multiple variables are stored in column names
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个变量存储在列名中
- en: Variables are stored in both rows and columns
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量同时存储在行和列中
- en: Multiple types of observational units are stored in the same table
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同类型的观察单元存储在同一个表格中
- en: A single observational unit is stored in multiple tables
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单一观察单元存储在多个表格中
- en: It is important to understand that tidying data does not typically involve changing
    the values of your dataset, filling in missing values, or doing any sort of analysis.
    Tidying data involves changing the shape or structure of the data to meet the
    tidy principles. Tidy data is akin to having all your tools in the toolbox instead
    of scattered randomly throughout your house. Having the tools properly in the
    toolbox allows all other tasks to be completed easily. Once the data is in the
    correct form, it becomes much easier to perform further analysis.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 需要理解的是，整理数据通常不涉及更改数据集的值、填补缺失值或进行任何类型的分析。整理数据涉及改变数据的形状或结构，以符合整洁原则。整洁数据类似于将所有工具放在工具箱里，而不是散乱地放在房子各处。将工具正确地放入工具箱，可以让所有其他任务更容易完成。一旦数据以正确的形式存在，进行进一步分析就变得更加容易。
- en: Once you have spotted messy data, you will use the pandas tools to restructure
    the data, so that it is tidy. The main tidy tools that pandas has available for
    you are the DataFrame methods `stack`, `melt`, `unstack`, and `pivot`. More complex
    tidying involves ripping apart text, which necessitates the `str` accessor. Other
    helper methods, such as `rename`, `rename_axis`, `reset_index`, and `set_index`
    will help with applying the final touches to tidy data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你发现了杂乱数据，就可以使用pandas工具来重构数据，使其变得整洁。pandas提供的主要整洁工具包括DataFrame方法`stack`、`melt`、`unstack`和`pivot`。更复杂的整理需要拆解文本，这就需要使用`str`访问器。其他辅助方法，如`rename`、`rename_axis`、`reset_index`和`set_index`，有助于在整洁数据上做最后的修饰。
- en: Tidying variable values as column names with stack
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用stack将变量值作为列名整理
- en: 'To help understand the differences between tidy and messy data, let''s take
    a look at a simple table that may or may not be in tidy form:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助理解整洁数据和杂乱数据之间的区别，让我们看一下一个简单的表格，它可能是整洁形式，也可能不是：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](img/0c3550a4-3074-402c-8c02-ba272547bde2.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0c3550a4-3074-402c-8c02-ba272547bde2.png)'
- en: There does not appear to be anything messy about this table, and the information
    is easily consumable. However, according to the tidy principles, it isn't actually
    tidy. Each column name is actually the value of a variable. In fact, none of the
    variable names are even present in the DataFrame. One of the first steps to transform
    a messy dataset into tidy data is to identify all of the variables. In this particular
    dataset, we have variables for **state** and **fruit**. There's also the numeric
    data that wasn't identified anywhere in the context of the problem. We can label
    this variable as **weight** or any other sensible name.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表格似乎没有什么杂乱，信息也很容易读取。然而，根据整洁原则，它实际上并不整洁。每个列名实际上是一个变量的值。事实上，数据框中甚至没有出现任何变量名。将杂乱数据集转换为整洁数据的第一步是识别所有变量。在这个数据集中，我们有**state**和**fruit**两个变量。还有数字数据，它在问题的上下文中并没有被明确识别。我们可以将这个变量标记为**weight**或任何其他合理的名称。
- en: Getting ready
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: This particular messy dataset contains variable values as column names. We will
    need to transpose these column names into column values. In this recipe, we use
    the `stack` method to restructure our DataFrame into tidy form.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特别的杂乱数据集将变量值作为列名存储。我们需要将这些列名转换为列值。在这个示例中，我们使用`stack`方法将DataFrame重构为整洁形式。
- en: How to do it...
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'First, take note that the state names are in the index of the DataFrame. These
    states are correctly placed vertically and do not need to be restructured. It
    is the column names that are the problem. The `stack` method takes all of the
    column names and reshapes them to be vertical as a single index level:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，注意到州名在DataFrame的索引中。这些州名正确地垂直排列，不需要重新结构化。问题出在列名上。`stack`方法将所有列名转换为垂直排列，作为一个单独的索引层级：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Notice that we now have a Series with a MultiIndex. There are now two levels
    in the index. The original index has been pushed to the left to make room for
    the old column names. With this one command, we now essentially have tidy data.
    Each variable, state, fruit, and weight is vertical. Let''s use the `reset_index`
    method to turn the result into a DataFrame:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，我们现在有一个带有MultiIndex的Series。索引现在有两个级别。原始的索引被推到左侧，为旧的列名腾出空间。通过这一条命令，我们现在基本上得到了整洁的数据。每个变量、状态、水果和重量都是垂直排列的。我们可以使用`reset_index`方法将结果转换为DataFrame：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](img/85efcd7a-edc3-44b9-8578-696dafb6a1bd.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/85efcd7a-edc3-44b9-8578-696dafb6a1bd.png)'
- en: 'Our structure is now correct, but the column names are meaningless. Let''s
    replace them with proper identifiers:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们的结构已经正确，但列名没有意义。让我们用适当的标识符替换它们：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](img/9e607e7b-2dd2-4c90-94c3-4e5f7f659dc7.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9e607e7b-2dd2-4c90-94c3-4e5f7f659dc7.png)'
- en: 'Instead of directly changing the columns attribute, it''s possible to use the
    lesser-known Series method `rename_axis` to set the names of the index levels
    before using `reset_index`:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了直接改变`columns`属性，还可以使用不太为人所知的Series方法`rename_axis`在使用`reset_index`之前设置索引级别的名称：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'From here, we can simply chain the `reset_index` method with the `name` parameter
    to reproduce the output from step 3:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这里，我们可以简单地将`reset_index`方法与`name`参数链式调用，以再现第三步的输出：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: How it works...
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `stack` method is powerful and it takes time to understand and appreciate
    fully. It takes all the column names and transposes them, so they become the new
    innermost index level. Notice how each old column name still labels its original
    value by being paired with each state. There were nine original values in a 3
    x 3 DataFrame, which got transformed into a single Series with the same number
    of values. The original first row of data became the first three values in the
    resulting Series.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`stack`方法非常强大，需要一定时间才能完全理解和掌握。它将所有列名转置，使它们成为新的最内层索引级别。注意，每个旧的列名仍然通过与每个状态配对来标记其原始值。在一个3
    x 3的DataFrame中有九个原始值，它们被转化成一个包含相同数量值的单列Series。原来的第一行数据变成了结果Series中的前三个值。'
- en: After resetting the index in step 2, pandas defaults our DataFrame columns to
    `level_0`, `level_1`, and `0`. This is because the Series calling this method
    has two index levels that were formally unnamed. Pandas also refers to indexes
    by integer beginning from zero from the outside.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二步重置索引后，pandas会默认将我们的DataFrame列命名为`level_0`、`level_1`和`0`。这是因为调用此方法的Series有两个未命名的索引级别。Pandas还会将索引从外部按从零开始的整数进行引用。
- en: Step 3 shows a simple and intuitive way to rename the columns. You can simply
    set new columns for the entire DataFrame by setting the columns attribute equal
    to a list.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 第三步展示了一种简单直观的方式来重命名列。你可以通过将`columns`属性设置为一个列表，直接为整个DataFrame设置新的列名。
- en: Alternatively, it is possible to set the column names in a single step by chaining
    the `rename_axis` method that, when passing a list as the first argument, uses
    those values as the index level names. Pandas uses these index level names as
    the new column names when the index is reset. Additionally, the `reset_index`
    method has a `name` parameter corresponding to the new column name of the Series
    values.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，可以通过链式调用`rename_axis`方法一步设置列名。当传递一个列表作为第一个参数时，Pandas使用这些值作为索引级别名称。Pandas在重置索引时，会将这些索引级别名称作为新的列名。此外，`reset_index`方法有一个`name`参数，对应Series值的新列名。
- en: All Series have a `name` attribute that can be set directly or with the `rename`
    method. It is this attribute that becomes the column name when using `reset_index`.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所有Series都有一个`name`属性，可以直接设置或通过`rename`方法设置。正是这个属性在使用`reset_index`时成为列名。
- en: There's more...
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'One of the keys to using `stack` is to place all of the columns that you do
    not wish to transform in the index. The dataset in this recipe was initially read
    with the states in the index. Let''s take a look at what would have happened if
    we did not read the states into the index:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`stack`的一个关键点是将所有不希望转换的列放在索引中。本例中的数据集最初是将状态作为索引读取的。我们来看一下如果没有将状态读入索引会发生什么：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](img/825e195b-4117-4d76-a0a6-9c475c9f493f.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/825e195b-4117-4d76-a0a6-9c475c9f493f.png)'
- en: 'As the state names are not in the index, using `stack` on this DataFrame reshapes
    all values into one long Series of values:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于状态名称不在索引中，在这个DataFrame上使用`stack`会将所有值重塑为一个长Series：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This command reshapes all the columns, this time including the states, and
    is not at all what we need. In order to reshape this data correctly, you will
    need to put all the non-reshaped columns into the index first with the `set_index`
    method, and then use `stack`. The following code gives a similar result to step
    1:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令重新整形了所有列，这次包括状态，并且完全不符合我们的需求。为了正确地重塑这些数据，您需要首先使用`set_index`方法将所有非重塑的列放入索引中，然后使用`stack`。以下代码提供了与步骤1类似的结果：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: See also
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Pandas official documentation on *Reshaping and Pivot Tables* ([http://bit.ly/2xbnNms](http://pandas.pydata.org/pandas-docs/stable/reshaping.html))
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas官方文档关于*重塑和透视表* ([http://bit.ly/2xbnNms](http://pandas.pydata.org/pandas-docs/stable/reshaping.html))
- en: Pandas official documentation on the `stack` method ([http://bit.ly/2vWZhH1](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.stack.html))
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas官方文档关于`stack`方法 ([http://bit.ly/2vWZhH1](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.stack.html))
- en: Tidying variable values as column names with melt
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用melt方法整理变量值作为列名
- en: Like most large Python libraries, pandas has many different ways to accomplish
    the same task--the differences usually being readability and performance. Pandas
    contains a DataFrame method named `melt` that works similarly to the `stack` method
    described in the previous recipe but gives a bit more flexibility.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 像大多数大型Python库一样，pandas有许多完成相同任务的不同方法--区别通常在于可读性和性能。Pandas包含一个名为`melt`的DataFrame方法，其工作方式与前面示例中描述的`stack`方法类似，但提供了更多灵活性。
- en: Before pandas version 0.20, `melt` was only provided as a function that had
    to be accessed with `pd.melt`. Pandas is still an evolving library and you need
    to expect changes with each new version. Pandas has been making a push to move
    all functions that only operate on DataFrames to methods, such as they did with
    `melt`. This is the preferred way to use `melt` and the way this recipe uses it.
    Check the *What's New* part of the pandas documentation to stay up to date with
    all the changes ([http://bit.ly/2xzXIhG](http://bit.ly/2xzXIhG)).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在pandas版本0.20之前，`melt`仅作为一个函数提供，需要通过`pd.melt`访问。Pandas仍然是一个不断发展的库，您需要预期每个新版本都会带来变化。Pandas一直在推动将所有仅对DataFrame操作的函数移动到方法中，就像他们对`melt`所做的那样。这是使用`melt`的首选方式，也是本示例使用的方式。查看pandas文档中的*新内容*部分，以了解所有更改
    ([http://bit.ly/2xzXIhG](http://bit.ly/2xzXIhG))。
- en: Getting ready
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we use the `melt` method to tidy a simple DataFrame with variable
    values as column names.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们使用`melt`方法来整理一个包含变量值作为列名的简单DataFrame。
- en: How to do it...
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Read in the `state_fruit2` dataset and identify which columns need to be transformed
    and which ones do not:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取`state_fruit2`数据集并确定哪些列需要转换，哪些不需要：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](img/a8e3bd31-0e35-437c-93e2-b78b1c43a731.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a8e3bd31-0e35-437c-93e2-b78b1c43a731.png)'
- en: 'Use the `melt` method by passing the appropriate columns to the `id_vars` and
    `value_vars` parameters:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将适当的列传递给`id_vars`和`value_vars`参数来使用`melt`方法：
- en: '[PRE10]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](img/21219e55-bc00-472e-a99c-e85328927350.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/21219e55-bc00-472e-a99c-e85328927350.png)'
- en: 'This one step creates tidy data for us. By default, `melt` refers to the transformed
    former column names as *variable* and the corresponding values as *value*. Conveniently,
    `melt` has two additional parameters, `var_name` and `value_name`, that give you
    the ability to rename these two columns:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这一步为我们创建了整洁的数据。默认情况下，`melt`将转换前的列名称为*variable*，相应的值称为*value*。方便地，`melt`还有两个额外的参数，`var_name`和`value_name`，允许您重新命名这两列：
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](img/8622f3dc-f2f8-4598-90f2-9a2e72e9cd64.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8622f3dc-f2f8-4598-90f2-9a2e72e9cd64.png)'
- en: How it works...
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'The `melt` method is powerful and dramatically reshapes your DataFrame. It
    takes up to five parameters, with two of them being crucial to understanding how
    to reshape your data correctly:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`melt`方法功能强大，可以显著重塑您的DataFrame。它最多接受五个参数，其中两个对于理解如何正确重塑数据至关重要：'
- en: '`id_vars` is a list of column names that you want to preserve as columns and
    not reshape'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id_vars`是您想要保留为列而不重塑的列名列表'
- en: '`value_vars` is a list of column names that you want to reshape into a single
    column'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value_vars`是您想要重塑为单列的列名列表'
- en: The `id_vars`, or the identification variables, remain in the same column but
    repeat for each of the columns passed to `value_vars`. One crucial aspect of `melt`
    is that it ignores values in the index, and, in fact, it silently drops your index
    and replaces it with a default `RangeIndex`. This means that if you do have values
    in your index that you would like to keep, you will need to reset the index first
    before using `melt`.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`id_vars`，或者称为标识变量，将保留在同一列中，但对于传递给 `value_vars` 的每一列都会重复。一项关键的 `melt` 特性是它会忽略索引中的值，实际上它会默默地丢弃你的索引，并用默认的
    `RangeIndex` 代替。这意味着，如果你的索引中有你希望保留的值，你需要先重置索引，然后再使用 `melt`。'
- en: It is somewhat common terminology to refer to the transformation of horizontal
    column names into vertical column values as **melting**, **stacking**, or **unpivoting**.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 将水平列名转换为垂直列值的过程通常称为 **melt**、**stacking** 或 **unpivoting**。
- en: There's more...
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'All the parameters for the `melt` method are optional, and if you desire all
    your values to be in a single column and their old column labels to be in the
    other, you may call `melt` with just its defaults:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`melt` 方法的所有参数都是可选的，如果你希望所有的值都在一列中，而它们原来的列标签在另一列中，你可以只使用 `melt` 的默认值来调用它：'
- en: '[PRE12]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](img/98b9e58c-f2d0-4210-92dd-e2d5dac1e42d.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/98b9e58c-f2d0-4210-92dd-e2d5dac1e42d.png)'
- en: 'More realistically, you might have lots of variables that need melting and
    would like to specify only the identification variables. In that case, calling
    `melt` in the following manner will yield the same result as in step 2\. You actually
    don''t even need a list when melting a single column and can simply pass its string
    value:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 更实际的情况是，你可能有许多需要“融化”的变量，并且只想指定标识变量。在这种情况下，以以下方式调用 `melt` 将得到与步骤 2 相同的结果。实际上，当只融化单列时，你甚至不需要列表，可以直接传递它的字符串值：
- en: '[PRE13]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: See also
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: Pandas official documentation on the `melt` method ([http://bit.ly/2vcuZNJ](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.melt.html))
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas 官方文档中的 `melt` 方法（[http://bit.ly/2vcuZNJ](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.melt.html)）
- en: Pandas developers discussion of `melt` and other similar functions being converted
    to methods ([http://bit.ly/2iqIQhI](https://github.com/pandas-dev/pandas/issues/12640))
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas 开发者讨论将 `melt` 和其他类似函数转换为方法的内容（[http://bit.ly/2iqIQhI](https://github.com/pandas-dev/pandas/issues/12640)）
- en: Stacking multiple groups of variables simultaneously
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同时堆叠多个变量组
- en: 'Some datasets contain multiple groups of variables as column names that need
    to be stacked simultaneously into their own columns. An example of the `movie`
    dataset can help clarify this. Let''s begin by selecting all columns containing
    the actor names and their corresponding Facebook likes:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据集包含多个作为列名的变量组，这些变量需要同时堆叠到它们自己的列中。以下是 `movie` 数据集的一个例子，可以帮助澄清这一点。我们首先选择所有包含演员姓名及其对应
    Facebook 点赞数的列：
- en: '[PRE14]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](img/28f8a2eb-d81b-475d-a563-3d82da61a598.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/28f8a2eb-d81b-475d-a563-3d82da61a598.png)'
- en: If we define our variables as the title of the movie, the actor name, and the
    number of Facebook likes, then we will need to stack independently two sets of
    columns, which is not possible using a single call to `stack` or `melt`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将变量定义为电影标题、演员姓名和 Facebook 点赞数，那么我们将需要独立堆叠两组列，这在使用单次调用 `stack` 或 `melt` 时是不可能实现的。
- en: Getting ready
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备开始
- en: In this recipe, we will tidy our `actor` DataFrame by simultaneously stacking
    the actor names and their corresponding Facebook likes with the `wide_to_long`
    function.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用 `wide_to_long` 函数同时堆叠演员姓名和对应的 Facebook 点赞数，从而整理我们的 `actor` 数据框。
- en: How to do it...
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We will be using the versatile `wide_to_long` function to reshape our data
    into tidy form. To use this function, we will need to change the column names
    that we are stacking, so that they end with a digit. We first create a user-defined
    function to change the column names:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用多功能的 `wide_to_long` 函数将数据重塑为整洁的格式。为了使用此函数，我们需要更改要堆叠的列名，使其以数字结尾。我们首先创建一个用户定义的函数来更改列名：
- en: '[PRE15]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Pass this function to the `rename` method to transform all the column names:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此函数传递给 `rename` 方法来转换所有列名：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](img/7ef188f2-f6c0-4325-a78d-8c0bcd1e752f.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7ef188f2-f6c0-4325-a78d-8c0bcd1e752f.png)'
- en: 'Use the `wide_to_long` function to stack the actor and Facebook sets of columns
    simultaneously:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `wide_to_long` 函数同时堆叠演员和 Facebook 列集：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](img/24a5560f-de6c-4b7f-a913-6a9650921b6e.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/24a5560f-de6c-4b7f-a913-6a9650921b6e.png)'
- en: How it works...
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `wide_to_long` function works in a fairly specific manner. Its main parameter
    is `stubnames`, which is a list of strings. Each string represents a single column
    grouping. All columns that begin with this string will be stacked into a single
    column. In this recipe, there are two groups of columns: *actor*, and *actor_facebook_likes*.
    By default, each of these groups of columns will need to end in a digit. This
    digit will subsequently be used to label the reshaped data. Each of these column
    groups has an underscore character separating the `stubname` from the ending digit.
    To account for this, you must use the `sep` parameter.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`wide_to_long`函数的工作方式相当具体。它的主要参数是`stubnames`，这是一个字符串列表。每个字符串代表一个单独的列分组。所有以此字符串开头的列将被堆叠到一个单独的列中。在这个例子中，有两组列：*actor*和*actor_facebook_likes*。默认情况下，每一组列需要以数字结尾。这个数字随后将用于标记重新塑形的数据。每个列组的列名中都有一个下划线字符，将`stubname`与结尾的数字分开。为了考虑到这一点，您必须使用`sep`参数。'
- en: The original column names do not match the pattern needed for `wide_to_long`
    to work. The column names could have been changed manually by exactly specifying
    their values with a list. This could quickly become a lot of typing so instead,
    we define a function that automatically converts our columns to a format that
    works. The `change_col_name` function removes **_name** from the actor columns
    and rearranges the Facebook columns so that now they both end in digits.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 原始列名与`wide_to_long`所需的模式不匹配。列名可以通过手动精确指定其值的列表来更改。这样可能会需要大量的输入，因此，我们定义了一个函数，自动将列转换为有效的格式。`change_col_name`函数从演员列中删除**_name**，并重新排列Facebook列，使它们都以数字结尾。
- en: To actually accomplish the column renaming, we use the `rename` method in step
    2\. It accepts many different types of arguments, one of which is a function.
    When passing it to a function, every column name gets implicitly passed to it
    one at a time.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实际完成列重命名，我们在第二步中使用了`rename`方法。它接受多种不同类型的参数，其中之一是一个函数。当将其传递给一个函数时，每个列名会逐一隐式地传递给该函数。
- en: We have now correctly created two independent groups of columns, those beginning
    with **actor** and **actor_facebook_likes** that will be stacked**.** In addition
    to this, `wide_to_long` requires a unique column, parameter `i`, to act as an
    identification variable that will not be stacked. Also required is the parameter
    `j`, which simply renames the identifying digit stripped from the end of the original
    column names. By default, the prefix parameter contains the **regular expression**,
    **\d+** that searches for one more or more digits. The **\d** is a special token
    that matches the digits 0-9\. The plus sign, **+**, makes the expression match
    for one or more of these digits.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经正确创建了两组独立的列，这些列分别以**actor**和**actor_facebook_likes**开头，将被堆叠**。**除此之外，`wide_to_long`需要一个独特的列，参数`i`，作为标识变量，该变量不会被堆叠。另一个必需的参数是`j`，它仅仅是将原始列名末尾的标识数字重命名。默认情况下，前缀参数包含**正则表达式**，**\d+**，它用于搜索一个或多个数字。**\d**是一个特殊的标记，表示匹配数字0-9。加号**+**使表达式匹配一个或多个数字。
- en: To become a powerful user of the `str` methods, you will need to be familiar
    with regular expressions, which are a sequence of characters that match a particular
    pattern within some text. They consist of **metacharacters**, which have a special
    meaning, and **literal** characters. To make yourself useful with regular expressions
    check this short tutorial from *Regular-Expressions.info* ([http://bit.ly/2wiWPbz](http://bit.ly/2wiWPbz)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要成为`str`方法的强大用户，您需要熟悉正则表达式，正则表达式是一系列字符，用于匹配文本中的特定模式。它们由**元字符**组成，这些字符具有特殊含义，以及**字面**字符。为了让自己更好地使用正则表达式，您可以查看*Regular-Expressions.info*的这个简短教程（[http://bit.ly/2wiWPbz](http://bit.ly/2wiWPbz)）。
- en: There's more...
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The function `wide_to_long` works when all groupings of variables have the
    same numeric ending as they did in this recipe. When your variables do not have
    the same ending or don''t end in a digit, you can still use `wide_to_long` to
    do simultaneous column stacking. For instance, let''s take a look at the following
    dataset:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`wide_to_long`函数适用于所有变量分组具有相同数字结尾的情况，就像这个例子中一样。当您的变量没有相同的结尾，或者没有以数字结尾时，您仍然可以使用`wide_to_long`进行列堆叠。例如，来看一下以下数据集：'
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](img/ab29bdc4-c4a2-4f3a-a9bb-217ce9330c2d.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ab29bdc4-c4a2-4f3a-a9bb-217ce9330c2d.png)'
- en: 'Let''s say we wanted columns `a1` and `b1` stacked together, as well as columns
    `d` and `e`. Additionally, we wanted to use `a1` and `b1` as labels for the rows.
    To accomplish this task, we would need to rename the columns so that they ended
    in the label we desired:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想将列 `a1` 和 `b1` 堆叠在一起，同时将列 `d` 和 `e` 也堆叠在一起。除此之外，我们还希望使用 `a1` 和 `b1` 作为行标签。为此，我们需要重新命名列，使其以所需的标签结尾：
- en: '[PRE19]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](img/44caf11d-1056-4f5f-99a6-c155b4979a95.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/44caf11d-1056-4f5f-99a6-c155b4979a95.png)'
- en: 'We would then need to modify the suffix parameter, which normally defaults
    to a regular expression that selects digits. Here, we simply tell it to find any
    number of characters:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要修改后缀参数，默认情况下该参数是一个正则表达式，用来选择数字。这里，我们只需告诉它查找任意数量的字符：
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](img/dd943f25-9112-4778-8006-b0fccb810901.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dd943f25-9112-4778-8006-b0fccb810901.png)'
- en: See also
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Pandas official documentation for `wide_to_long` ([http://bit.ly/2xb8NVP](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.wide_to_long.html))
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas 官方文档关于 `wide_to_long`（[http://bit.ly/2xb8NVP](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.wide_to_long.html))
- en: Inverting stacked data
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反转堆叠数据
- en: DataFrames have two similar methods, `stack` and `melt`, to convert horizontal
    column names into vertical column values. DataFrames have the ability to invert
    these two operations directly with the `unstack` and `pivot` methods respectively. 
    `stack`/`unstack` are simpler methods that allow control over only the column/row
    indexes, while `melt`/`pivot` gives more flexibility to choose which columns are
    reshaped.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 有两个相似的方法，`stack` 和 `melt`，可以将水平的列名转换为垂直的列值。DataFrame 还可以通过 `unstack`
    和 `pivot` 方法分别直接反转这两个操作。`stack`/`unstack` 是较简单的方法，只能控制列/行索引，而 `melt`/`pivot` 提供了更多的灵活性，可以选择哪些列需要被重塑。
- en: Getting ready
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will `stack`/`melt` a dataset and promptly invert the operation
    with `unstack`/`pivot` back to its original form.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用 `stack`/`melt` 处理数据集，并通过 `unstack`/`pivot` 迅速将其恢复到原始形式。
- en: How to do it...
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Read in the `college` dataset with the institution name as the index, and with
    only the undergraduate race columns:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取 `college` 数据集，并将机构名称作为索引，仅包括本科种族列：
- en: '[PRE21]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](img/efc80119-761f-4d14-b1a5-3f42839c8892.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/efc80119-761f-4d14-b1a5-3f42839c8892.png)'
- en: 'Use the `stack` method to convert each horizontal column name into a vertical
    index level:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `stack` 方法将每个水平列名转换为垂直索引级别：
- en: '[PRE22]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Invert this stacked data back to its original form with the `unstack` Series
    method:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `unstack` Series 方法将堆叠的数据恢复为其原始形式：
- en: '[PRE23]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'A similar sequence of operations can be done with `melt` followed by `pivot`.
    First, read in the data without putting the institution name in the index:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以通过 `melt` 然后 `pivot` 进行类似的操作。首先，读取数据时不将机构名称放入索引：
- en: '[PRE24]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](img/b634368b-df19-474a-97bf-39d015e36450.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b634368b-df19-474a-97bf-39d015e36450.png)'
- en: 'Use the `melt` method to transpose all the race columns into a single column:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`melt`方法将所有的种族列转换为单一列：
- en: '[PRE25]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](img/d3043e3c-0590-402f-ba89-581207ade0bc.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3043e3c-0590-402f-ba89-581207ade0bc.png)'
- en: 'Use the `pivot` method to invert this previous result:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pivot` 方法反转之前的结果：
- en: '[PRE26]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](img/99990148-2b85-45ac-a1d6-1a00c08d9940.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99990148-2b85-45ac-a1d6-1a00c08d9940.png)'
- en: 'Notice that the institution names are now shuttled over into the index and
    are not in their original order. The column names are not in their original order.
    To get an exact replication of our starting DataFrame from step 4, use the `.loc`
    indexing operator to select rows and columns simultaneously and then reset the
    index:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，机构名称现在已经被移到索引中，并且顺序发生了变化。列名也不再是原始顺序。要完全恢复步骤 4 中的原始 DataFrame，可以使用 `.loc`
    索引操作符同时选择行和列，然后重置索引：
- en: '[PRE27]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: How it works...
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: There are multiple ways to accomplish the same thing in step 1\. Here, we show
    the versatility of the `read_csv` function. The `usecols` parameter accepts either
    a list of the columns that we would like to import or a function that dynamically
    determines them. We use an anonymous function that checks whether the column name
    contains `UGDS_` or is equal to `INSTNM`. The function is passed each column name
    as a string and must return a boolean. A huge amount of memory can be saved in
    this manner.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 1 中有多种方法可以实现相同的结果。这里，我们展示了 `read_csv` 函数的多样性。`usecols` 参数接受我们想要导入的列的列表，也可以是一个动态确定列的函数。我们使用了一个匿名函数来检查列名是否包含
    `UGDS_` 或等于 `INSTNM`。该函数将列名作为字符串传入，必须返回布尔值。这样可以节省大量内存。
- en: The `stack` method in step 2 puts all column names into the innermost index
    level and returns a Series. In step 3, the `unstack` method inverts this operation
    by taking all the values in the innermost index level converting them to column
    names.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 第2步中的`stack`方法将所有列名放入最内层的索引级别，并返回一个Series。在第3步中，`unstack`方法通过将最内层索引级别中的所有值转换为列名，反转了这一操作。
- en: The result from step 3 isn't quite an exact replication of step 1\. There are
    entire rows of missing values, and by default, the `stack` method drops these
    during step 2\. To keep these missing values and create an exact replication,
    use `dropna=False` in the `stack` method.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 第3步的结果并不是第1步的完全复制。存在整行缺失值，默认情况下，`stack`方法会在第2步时丢弃这些值。要保留这些缺失值并实现精确复制，可以在`stack`方法中使用`dropna=False`。
- en: Step 4 reads in the same dataset as in step 1 but does not put the institution
    name in the index because the `melt` method isn't able to access it. Step 5 uses
    the `melt` method to transpose all the **Race** columns. It does this by leaving
    the `value_vars` parameter as its default value `None`. When not specified, all
    the columns not present in the `id_vars` parameter get transposed.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 第4步读取与第1步相同的数据集，但由于`melt`方法无法访问，机构名称没有被放入索引中。第5步使用`melt`方法转置所有的**Race**列。通过将`value_vars`参数保持为默认值`None`来实现这一点。未指定时，所有不在`id_vars`参数中的列都会被转置。
- en: Step 6 inverts the operation from step 5 with the `pivot` method, which accepts
    three parameters. Each parameter takes a single column as a string. The column
    referenced by the `index` parameter remains vertical and becomes the new index.
    The values of the column referenced by the `columns` parameter become the column
    names. The values referenced by the `values` parameter become tiled to correspond
    with the intersection of their former index and columns label.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 第6步使用`pivot`方法反转第5步的操作，`pivot`方法接受三个参数。每个参数都作为字符串引用单独的列。`index`参数引用的列保持垂直，并成为新的索引。`columns`参数引用的列的值变为新的列名。`values`参数引用的列的值会在其原始索引和列标签交叉处进行排列。
- en: To make an exact replication with `pivot`, we need to sort the rows and columns
    in the exact order from the original. As the institution name is in the index,
    we use the `.loc` indexing operator as a way to sort the DataFrame by its original
    index.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了用`pivot`实现精确复制，我们需要按照原始数据集中的顺序对行和列进行排序。由于机构名称在索引中，我们使用`.loc`索引运算符作为排序DataFrame的方式，以便按照原始索引顺序排列。
- en: There's more...
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: To help further understand `stack`/`unstack`, let's use them to **transpose**
    the `college` DataFrame.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解`stack`/`unstack`，我们将它们用于**转置**`college`数据集。
- en: In this context, we are using the precise mathematical definition of the transposing
    of a matrix, where the new rows are the old columns of the original data matrix.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个上下文中，我们使用的是矩阵转置的精确定义，其中新的行是原始数据矩阵中的旧列。
- en: 'If you take a look at the output from step 2, you''ll notice that there are
    two index levels. By default, the `unstack` method uses the innermost index level
    as the new column values. Index levels are numbered beginning from zero from the
    outside. Pandas defaults the `level` parameter of the `unstack` method to -1,
    which refers to the innermost index. We can instead `unstack` the outermost column
    using `level=0`:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果查看第2步的输出，你会注意到有两个索引级别。默认情况下，`unstack`方法使用最内层的索引级别作为新的列值。索引级别从外到内编号，从0开始。Pandas将`unstack`方法的`level`参数默认为-1，表示最内层索引。我们可以使用`level=0`来`unstack`最外层的列：
- en: '[PRE28]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![](img/23f980c3-580e-470f-94c9-476146342f49.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/23f980c3-580e-470f-94c9-476146342f49.png)'
- en: 'There is actually a very simple way to transpose a DataFrame that don''t require
    `stack` or `unstack` by using the `transpose` method or the `T` attribute like
    this:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 其实，有一种非常简单的方法可以转置DataFrame，无需使用`stack`或`unstack`，只需使用`transpose`方法或`T`属性，如下所示：
- en: '[PRE29]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: See also
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: Refer to the *Selecting DataFrame rows and columns simultaneously* recipe from
    [Chapter 10](3b938362-1f65-406c-ba9d-3bf735543ca8.xhtml), *Selecting Subsets of
    Data*
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅[第10章](3b938362-1f65-406c-ba9d-3bf735543ca8.xhtml)中的*同时选择DataFrame行和列*部分，*选择数据子集*。
- en: Pandas official documentation of the `unstack` ([http://bit.ly/2xIyFvr](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html))
    and `pivot` ([http://bit.ly/2f3qAWP](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot.html))
    methods
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas官方文档中的`unstack`（[http://bit.ly/2xIyFvr](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html)）和`pivot`（[http://bit.ly/2f3qAWP](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot.html)）方法
- en: Unstacking after a groupby aggregation
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在`groupby`聚合后进行unstack操作
- en: Grouping data by a single column and performing an aggregation on a single column
    returns a simple and straightforward result that is easy to consume. When grouping
    by more than one column, a resulting aggregation might not be structured in a
    manner that makes consumption easy. Since `groupby` operations by default put
    the unique grouping columns in the index, the `unstack` method can be extremely
    useful to rearrange the data so that it is presented in a manner that is more
    useful for interpretation.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 按单个列对数据进行分组并对单列进行聚合，返回的结果简单直观，易于使用。当按多个列分组时，聚合结果可能不会以易于理解的方式结构化。由于`groupby`操作默认将唯一的分组列放入索引中，`unstack`方法可以非常有用，用于重新排列数据，以便以更有利于解读的方式呈现数据。
- en: Getting ready
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we use the `employee` dataset to perform an aggregation, grouping
    by multiple columns. We then use the `unstack` method to reshape the result into
    a format that makes for easier comparisons of different groups.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用`employee`数据集进行聚合，按多个列分组。然后使用`unstack`方法重新调整结果的格式，使不同组的比较变得更加容易。
- en: How to do it...
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'Read in the employee dataset and find the mean salary by race:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取员工数据集并按种族计算平均薪资：
- en: '[PRE30]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This is a very simple `groupby` operation that results in a Series that is
    easy to read and has no need to reshape. Let''s now find the average salary for
    all races by gender:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个非常简单的`groupby`操作，返回一个易于读取且无需重塑的Series。现在让我们通过性别计算所有种族的平均薪资：
- en: '[PRE31]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This aggregation is more complex and can be reshaped to make different comparisons
    easier. For instance, it would be easier to compare male versus female salaries
    for each race if they were side by side and not vertical as they are now. Let''s
    unstack the gender index level:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个聚合更复杂，可以重新调整形状，使不同的比较变得更容易。例如，如果男性与女性在每个种族中的薪资并排显示，而不是像现在这样垂直显示，那么比较将会更加容易。让我们对性别索引级别进行unstack操作：
- en: '[PRE32]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![](img/d0f45d1b-2ade-4b1d-afdd-1a734cd20390.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d0f45d1b-2ade-4b1d-afdd-1a734cd20390.png)'
- en: 'Similarly, we can `unstack` the race index level:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，我们也可以对种族索引级别进行`unstack`操作：
- en: '[PRE33]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![](img/ecc8127d-acf5-46df-9220-f3d95d9fb67a.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ecc8127d-acf5-46df-9220-f3d95d9fb67a.png)'
- en: How it works...
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Step 1 has the simplest possible aggregation with a single grouping column (`RACE`),
    a single aggregating column (`BASE_SALARY`), and a single aggregating function
    (`mean`). This result is easy to consume and doesn't require any more processing
    to evaluate. Step 2 slightly increases the complexity by grouping by both race
    and gender together. The resulting MultiIndex Series contains all the values in
    a single dimension, which makes comparisons more difficult. To make the information
    easier to consume, we use the `unstack` method to convert the values in one (or
    more) of the levels to columns.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是最简单的聚合操作，只有一个分组列（`RACE`）、一个聚合列（`BASE_SALARY`）和一个聚合函数（`mean`）。这个结果易于消费，不需要进一步处理。第二步稍微增加了复杂性，按种族和性别一起分组。结果是一个MultiIndex
    Series，所有值都在一个维度中，这使得比较变得更困难。为了使信息更容易消费，我们使用`unstack`方法将某一（或多个）级别的值转换为列。
- en: By default, `unstack` uses the innermost index level as the new columns. You
    can specify the exact level you would like to unstack with the `level` parameter,
    which accepts either the level name as a string or the level integer location.
    It is preferable to use the level name over the integer location to avoid ambiguity.
    Steps 3 and 4 unstack each level, which results in a DataFrame with a single-level
    index. It is now much easier to compare salaries from each race by gender.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`unstack`使用最内层的索引级别作为新的列。你可以通过`level`参数指定你想要进行unstack的确切级别，`level`参数接受级别名称（作为字符串）或级别的整数位置。为了避免歧义，最好使用级别名称而非整数位置。步骤3和步骤4对每个级别执行unstack操作，结果是一个具有单级索引的DataFrame。现在，通过性别比较每个种族的薪资就容易得多。
- en: There's more...
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'If there are multiple grouping and aggregating columns, then the immediate
    result will be a DataFrame and not a Series. For instance, let''s calculate more
    aggregations than just the mean, as was done in step 2:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有多个分组和聚合列，那么立即得到的将是一个DataFrame，而不是Series。例如，让我们计算多个聚合，而不仅仅是第一步中的均值：
- en: '[PRE34]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![](img/e38c7d48-cec8-4d77-a314-b241e25607e3.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e38c7d48-cec8-4d77-a314-b241e25607e3.png)'
- en: 'Unstacking the **Gender** column will result in MultiIndex columns. From here,
    you can keep swapping row and column levels with both the `unstack` and `stack`
    methods until you achieve the structure of data you desire:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对**Gender**列进行unstack操作将导致MultiIndex列。从这里开始，你可以使用`unstack`和`stack`方法交换行列层级，直到达到你想要的数据结构：
- en: '[PRE35]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![](img/ba0f9ae2-4f39-4fa4-beaa-12eb750daafa.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba0f9ae2-4f39-4fa4-beaa-12eb750daafa.png)'
- en: See also
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: Refer to the *Grouping and aggregating with multiple columns* recipe and functions
    from [Chapter 13](b50e0294-740b-45fc-9c4e-284ecfda8b7d.xhtml), *Grouping for Aggregation,
    Filtration, and Transformation*
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考*使用多个列进行分组和聚合*的食谱以及[第13章](b50e0294-740b-45fc-9c4e-284ecfda8b7d.xhtml)中的函数，*用于聚合、过滤和转换的分组*
- en: Replicating pivot_table with a groupby aggregation
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用groupby聚合复制pivot_table
- en: At first glance, it may seem that the `pivot_table` method provides a unique
    way to analyze data. However, after a little massaging, it is possible to replicate
    its functionality exactly with a `groupby` aggregation. Knowing this equivalence
    can help shrink the universe of pandas functionality.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，`pivot_table`方法似乎提供了一种独特的数据分析方式。然而，经过稍微处理后，完全可以通过`groupby`聚合来复制其功能。了解这种等价性可以帮助缩小pandas功能的范围。
- en: Getting ready
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we use the `flights` dataset to create a pivot table and then
    recreate it using `groupby` operations.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用`flights`数据集创建一个透视表，然后通过`groupby`操作重新创建它。
- en: How to do it...
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Read in the flights dataset, and use the `pivot_table` method to find the total
    number of canceled flights per origin airport for each airline:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取航班数据集，并使用`pivot_table`方法查找每个航空公司从每个起飞机场出发的取消航班总数：
- en: '[PRE36]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![](img/563d0c11-0a75-4dc2-962d-a70ff0a70e91.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/563d0c11-0a75-4dc2-962d-a70ff0a70e91.png)'
- en: 'A `groupby` aggregation cannot directly replicate this table. The trick is
    to group by all the columns in the `index` and `columns` parameters first:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`groupby`聚合不能直接复制此表。诀窍是先根据`index`和`columns`参数中的所有列进行分组：'
- en: '[PRE37]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Use the `unstack` method to pivot the `ORG_AIR` index level to column names:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`unstack`方法将`ORG_AIR`索引层级透视为列名：
- en: '[PRE38]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: How it works...
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `pivot_table` method is very versatile and flexible but performs a rather
    similar operation to a `groupby` aggregation with step 1 showing a simple example.
    The `index` parameter takes a column (or columns) that will not be pivoted and
    whose unique values will be placed in the index. The `columns` parameter takes
    a column (or columns) that will be pivoted and whose unique values will be made
    into column names. The `values` parameter takes a column (or columns) that will
    be aggregated.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`pivot_table`方法非常灵活且多功能，但执行的操作与`groupby`聚合非常相似，第一步展示了一个简单的例子。`index`参数接受一个（或多个）不会被透视的列，并将这些列的唯一值放置在索引中。`columns`参数接受一个（或多个）将被透视的列，并将这些列的唯一值转换为列名。`values`参数接受一个（或多个）将被聚合的列。'
- en: There also exists an `aggfunc` parameter that takes an aggregating function
    (or functions) that determines how the columns in the `values` parameter get aggregated.
    It defaults to the mean, and, in this example, we change it to calculate the sum.
    Additionally, some unique combinations of `AIRLINE` and `ORG_AIR` do not exist.
    These missing combinations will default to missing values in the resulting DataFrame.
    Here, we use the `fill_value` parameter to change them to zero.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个`aggfunc`参数，它接受一个聚合函数（或多个函数），决定如何对`values`参数中的列进行聚合。默认情况下为均值，在这个例子中，我们将其更改为计算总和。此外，某些`AIRLINE`和`ORG_AIR`的唯一组合并不存在。这些缺失的组合将在结果DataFrame中默认显示为缺失值。在这里，我们使用`fill_value`参数将它们更改为零。
- en: Step 2 begins the replication process using all the columns in the `index` and
    `columns` parameter as the grouping columns. This is the key to making this recipe
    work. A pivot table is simply an intersection of all the unique combinations of
    the grouping columns. Step 3 finishes the replication by pivoting the innermost
    index level into column names with the `unstack` method. Just like with `pivot_table`,
    not all combinations of `AIRLINE` and `ORG_AIR` exist; we again use the `fill_value`
    parameter to force these missing intersections to zero.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 第 2 步开始复制过程，使用 `index` 和 `columns` 参数中的所有列作为分组列。这是使此方法有效的关键。透视表实际上是所有分组列唯一组合的交集。第
    3 步通过使用 `unstack` 方法将最内层的索引级别转换为列名，完成了复制过程。就像使用 `pivot_table` 一样，并不是所有 `AIRLINE`
    和 `ORG_AIR` 的组合都存在；我们再次使用 `fill_value` 参数将这些缺失的交集强制为零。
- en: There's more...
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'It is possible to replicate much more complex pivot tables with `groupby` aggregations.
    For instance, take the following result from `pivot_table`:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 `groupby` 聚合，可以复制更复杂的透视表。例如，取 `pivot_table` 的以下结果：
- en: '[PRE39]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '![](img/ee0f83c3-f7e7-4cd0-ac93-2be6b3bd0e52.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee0f83c3-f7e7-4cd0-ac93-2be6b3bd0e52.png)'
- en: 'To replicate this with a `groupby` aggregation, simply follow the same pattern
    from the recipe and place all the columns from the `index` and `columns` parameters
    into the `groupby` method and then `unstack` the columns:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 若要通过 `groupby` 聚合复制此操作，只需按照食谱中的相同模式，将 `index` 和 `columns` 参数中的所有列放入 `groupby`
    方法中，然后使用 `unstack` 处理列：
- en: '[PRE40]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: There are a few differences. The `pivot_table` method does not accept aggregation
    functions as strings when passed as a list like the `agg` groupby method. Instead,
    you must use NumPy functions. The order of the column levels also differs, with
    `pivot_table` putting the aggregation functions at a level preceding the columns
    in the `values` parameter. This is equalized with the `swaplevel` method that,
    in this instance, switches the order of the top two levels.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些区别。`pivot_table` 方法在作为列表传递时，不像 `agg` 的 groupby 方法那样接受作为字符串的聚合函数。相反，您必须使用
    NumPy 函数。列级别的顺序也有所不同，`pivot_table` 将聚合函数放在 `values` 参数中的列之前的一个级别。这可以通过 `swaplevel`
    方法来统一，在此实例中，它交换了前两个级别的顺序。
- en: As of the time of writing this book, there is a bug when unstacking more than
    one column. The `fill_value` parameter is ignored ([http://bit.ly/2jCPnWZ](https://github.com/pandas-dev/pandas/issues/13971)).
    To work around this bug, chain `.fillna(0)` to the end of the code.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 截至本书撰写时，当堆叠多个列时，存在一个 bug。`fill_value` 参数会被忽略（[http://bit.ly/2jCPnWZ](https://github.com/pandas-dev/pandas/issues/13971)）。为了解决这个
    bug，可以在代码末尾链接 `.fillna(0)`。
- en: Renaming axis levels for easy reshaping
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重命名轴级别以便于重新塑形
- en: Reshaping with the `stack`/`unstack` methods is far easier when each axis (index/column)
    level has a name. Pandas allows users to reference each axis level by integer
    location or by name. Since integer location is implicit and not explicit, you
    should consider using level names whenever possible. This advice follows from
    *The* *Zen of Python* ([http://bit.ly/2xE83uC](http://bit.ly/2xE83uC)), a short
    list of guiding principles for Python of which the second one is *Explicit is
    better than implicit*.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 当每个轴（索引/列）级别都有名称时，使用 `stack`/`unstack` 方法进行重新塑形要容易得多。Pandas 允许用户通过整数位置或名称引用每个轴级别。由于整数位置是隐式的而非显式的，因此建议尽可能使用级别名称。这个建议来自于
    *The* *Zen of Python*（[http://bit.ly/2xE83uC](http://bit.ly/2xE83uC)），它是 Python
    的一组指导原则，其中第二条是 *显式优于隐式*。
- en: Getting ready
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: When grouping or aggregating with multiple columns, the resulting pandas object
    will have multiple levels in one or both of the axes. In this recipe, we will
    name each level of each axis and then use the methods `stack`/`unstack` to dramatically
    reshape the data to the desired form.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 当按多个列进行分组或聚合时，结果的 pandas 对象将在一个或两个轴上具有多个级别。在这个示例中，我们将为每个轴的每个级别命名，然后使用 `stack`/`unstack`
    方法大幅度地重新塑形数据，直到得到所需的形式。
- en: How to do it...
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Read in the college dataset, and find a few basic summary statistics on the
    undergraduate population and SAT math scores by institution and religious affiliation:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取大学数据集，并根据院校和宗教背景，找到一些本科生人口和 SAT 数学成绩的基本统计数据：
- en: '[PRE41]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![](img/6ec7dfb9-fb3b-439d-9693-dea41616d025.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6ec7dfb9-fb3b-439d-9693-dea41616d025.png)'
- en: 'Notice that both index levels have names and are the old column names. The
    column levels, on the other hand, do not have names. Use the `rename_axis` method
    to supply level names to them:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，两个索引级别都有名称，并且是旧的列名。另一方面，列级别没有名称。使用 `rename_axis` 方法为它们提供级别名称：
- en: '[PRE42]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![](img/d68168ab-e11d-4f74-ac6e-e567fae7f7dd.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d68168ab-e11d-4f74-ac6e-e567fae7f7dd.png)'
- en: 'Now that each axis level has a name, reshaping is a breeze. Use the `stack`
    method to move the `AGG_FUNCS` column to an index level:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在每个轴级别都有了名称，重塑变得轻而易举。使用 `stack` 方法将 `AGG_FUNCS` 列移动到索引级别：
- en: '[PRE43]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![](img/2651e1eb-49ec-4de9-a8c3-1c5ba20e8bb4.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2651e1eb-49ec-4de9-a8c3-1c5ba20e8bb4.png)'
- en: 'By default, stacking places the new column level in the innermost position.
    Use the `swaplevel` method to switch the placement of the levels:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，堆叠将新的列级别放在最内层的位置。使用 `swaplevel` 方法可以交换级别的位置：
- en: '[PRE44]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![](img/77c9ed9a-de64-4f3f-89ce-eb0ef47617a3.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77c9ed9a-de64-4f3f-89ce-eb0ef47617a3.png)'
- en: 'We can continue to make use of the axis level names by sorting levels with
    the `sort_index` method:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以继续通过使用 `sort_index` 方法根据轴级别的名称对级别进行排序：
- en: '[PRE45]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![](img/f83a1be9-1118-4ce7-9b80-e374e3d0c29e.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f83a1be9-1118-4ce7-9b80-e374e3d0c29e.png)'
- en: 'To completely reshape your data, you might need to stack some columns while
    unstacking others. Chain the two methods together in a single command:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了完全重塑数据，您可能需要在堆叠某些列的同时取消堆叠其他列。将这两个方法链式结合在一个命令中：
- en: '[PRE46]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![](img/d3d07ca2-2a5f-4b03-a969-7dc29d04e458.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3d07ca2-2a5f-4b03-a969-7dc29d04e458.png)'
- en: 'Stack all the columns at once to return a Series:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一次性堆叠所有列以返回一个 Series：
- en: '[PRE47]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: How it works...
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: It is common for the result of a `groupby` aggregation to produce a DataFrame
    or Series with multiple axis levels. The resulting DataFrame from the `groupby`
    operation in step 1 has multiple levels for each axis. The column levels are not
    named, which would require us to reference them only by their integer location.
    To greatly ease our ability to reference the column levels, we rename them with
    the `rename_axis` method.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '`groupby` 聚合的结果通常会产生具有多个轴级别的 DataFrame 或 Series。在步骤 1 中的 `groupby` 操作产生的 DataFrame
    对每个轴都有多个级别。列级别没有命名，这意味着我们只能通过其整数位置来引用它们。为了大大简化引用列级别的操作，我们使用 `rename_axis` 方法对其进行重命名。'
- en: The `rename_axis` method is a bit strange in that it can modify both the level
    names and the level values based on the type of the first argument passed to it.
    Passing it a list (or a scalar if there is only one level) changes the names of
    the levels. Passing it a dictionary or a function changes the values of the levels.
    In step 2, we pass the `rename_axis` method a list and are returned a DataFrame
    with all axis levels named.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '`rename_axis` 方法有些奇怪，因为它可以根据传入的第一个参数的类型修改级别名称和级别值。传入一个列表（如果只有一个级别，则传入标量）会改变级别的名称。传入字典或函数会改变级别的值。在步骤
    2 中，我们传递给 `rename_axis` 方法一个列表，并返回一个所有轴级别都有名称的 DataFrame。'
- en: Once all the axis levels have names, we can easily and explicitly control the
    structure of data. Step 3 stacks the `AGG_FUNCS` column into the innermost index
    level. The `swaplevel` method in step 4 accepts the name or position of the levels
    that you want to swap as the first two arguments. The `sort_index` method is called
    twice and sorts the actual values of each level. Notice that the values of the
    column level are the column names `SATMTMID` and `UGDS`.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有轴级别都有了名称，我们就可以轻松明确地控制数据结构。步骤 3 将 `AGG_FUNCS` 列堆叠到最内层的索引级别。步骤 4 中的 `swaplevel`
    方法接受您希望交换的级别的名称或位置作为前两个参数。`sort_index` 方法被调用两次，对每个级别的实际值进行排序。注意，列级别的值是列名 `SATMTMID`
    和 `UGDS`。
- en: We can get vastly different output by both stacking and unstacking, as done
    in step 6\. It is also possible to stack every single column level into the index
    to produce a Series.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 通过堆叠和取消堆叠（如步骤 6 中所做的），我们可以得到截然不同的输出。还可以将每个列级别堆叠到索引中，从而生成一个 Series。
- en: There's more...
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'If you wish to dispose of the level values altogether, you may set them to
    `None`. A case for this can be made when there is a need to reduce clutter in
    the visual output of a DataFrame or when it is obvious what the column levels
    represent and no further processing will take place:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望完全删除级别值，可以将其设置为 `None`。这种做法适用于需要减少 DataFrame 可视化输出中的杂乱，或当列级别显然表示的内容已足够清晰，且不再进行其他处理时：
- en: '[PRE48]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '![](img/b1ad2bd3-f4b8-4c58-ad05-3372f30ef470.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1ad2bd3-f4b8-4c58-ad05-3372f30ef470.png)'
- en: Tidying when multiple variables are stored as column names
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当多个变量作为列名存储时进行整理
- en: One particular flavor of messy data appears whenever the column names contain
    multiple different variables themselves. A common example of this scenario occurs
    when age and sex are concatenated together. To tidy datasets like this, we must
    manipulate the columns with the pandas `str` accessor, an attribute that contains
    additional methods for string processing.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 一种特定类型的混乱数据出现在列名本身包含多个不同变量的情况。一个常见的例子是性别和年龄被合并在一起。要整理这样的数据集，我们必须使用pandas的`str`访问器操作列，这个访问器包含了额外的字符串处理方法。
- en: Getting ready...
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪...
- en: In this recipe, we will first identify all the variables of which some will
    be concatenated together as column names. We then reshape the data and parse the
    text to extract the correct variable values.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程里，我们首先会识别所有的变量，其中一些会作为列名被合并在一起。然后我们会重塑数据并解析文本以提取正确的变量值。
- en: How to do it...
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Read in the men''s `weightlifting` dataset, and identify the variables:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取男性的`weightlifting`数据集，并识别变量：
- en: '[PRE49]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '![](img/edd05ae0-84ad-445b-9253-a47df0bfc41c.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](img/edd05ae0-84ad-445b-9253-a47df0bfc41c.png)'
- en: 'The variables are the weight category, sex/age category, and the qualifying
    total. The age and sex variables have been concatenated together into a single
    cell. Before we can separate them, let''s use the `melt` method to transpose the
    age and sex column names into a single vertical column:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 变量包括体重类别、性别/年龄类别和资格总分。性别和年龄的变量已经合并到一个单元格中。在我们将它们分离之前，先使用`melt`方法将年龄和性别列名转置为一个单一的垂直列：
- en: '[PRE50]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '![](img/339c92ee-9050-4902-be9e-956b2a6dcc9d.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![](img/339c92ee-9050-4902-be9e-956b2a6dcc9d.png)'
- en: 'Select the `sex_age` column, and use the `split` method available from the
    `str` accessor to split the column into two different columns:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`sex_age`列，并使用`str`访问器提供的`split`方法将该列分割成两列：
- en: '[PRE51]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![](img/fafd813e-d36e-43cf-8c2b-1a150aacc052.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fafd813e-d36e-43cf-8c2b-1a150aacc052.png)'
- en: 'This operation returned a completely separate DataFrame with meaningless column
    names. Let''s rename the columns so that we can explicitly access them:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个操作返回了一个完全独立的DataFrame，列名没有意义。我们需要重命名这些列，以便能够明确地访问它们：
- en: '[PRE52]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '![](img/4dffbd4f-2739-4cff-9b78-28b679065e88.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4dffbd4f-2739-4cff-9b78-28b679065e88.png)'
- en: 'Use the indexing operator directly after the `str` accessor to select the first
    character from the `Sex` column:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接在`str`访问器后使用索引操作符，从`Sex`列中选择第一个字符：
- en: '[PRE53]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '![](img/d243cb22-19e7-43dc-a3cc-96fb06022077.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d243cb22-19e7-43dc-a3cc-96fb06022077.png)'
- en: 'Use the `pd.concat` function to concatenate this DataFrame with `wl_melt` to
    produce a tidy dataset:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pd.concat`函数将此DataFrame与`wl_melt`连接，以生成一个整理好的数据集：
- en: '[PRE54]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '![](img/cb920c05-8091-49c8-b933-746cafedeef4.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cb920c05-8091-49c8-b933-746cafedeef4.png)'
- en: 'This same result could have been created with the following:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个相同的结果也可以通过以下方法实现：
- en: '[PRE55]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: How it works...
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: The `weightlifting` dataset, like many datasets, has easily digestible information
    in its raw form, but technically, it is messy, as all but one of the column names
    contain information for sex and age. Once the variables are identified, we can
    begin to tidy the dataset. Whenever column names contain variables, you will need
    to use the `melt` (or `stack`) method. The `Weight Category` variable is already
    in the correct position so we keep it as an identifying variable by passing it
    to the `id_vars` parameter. Note that we don't explicitly need to name all the
    columns that we are melting with `value_vars`. By default, all the columns not
    present in `id_vars` get melted.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '`weightlifting` 数据集像许多数据集一样，在其原始形式下包含易于理解的信息，但从技术角度来看，它是混乱的，因为除了一个列名，其他列名都包含性别和年龄信息。一旦识别出这些变量，我们就可以开始整理数据集。当列名包含变量时，你需要使用`melt`（或`stack`）方法。`Weight
    Category`变量已经在正确的位置，因此我们通过将其传递给`id_vars`参数，将其作为标识变量保留。注意，我们不需要显式列出所有被“融化”的列，默认情况下，所有未出现在`id_vars`中的列都会被融化。'
- en: The `sex_age` column needs to be parsed, and split into two variables. For this,
    we turn to the extra functionality provided by the `str` accessor, only available
    to Series (a single DataFrame column). The `split` method is one of the more common
    methods in this situation, as it can separate different parts of the string into
    their own column. By default, it splits on an empty space, but you may also specify
    a string or regular expression with the `pat` parameter. When the `expand` parameter
    is set to `True`, a new column forms for each independent split character segment.
    When `False`, a single column is returned, containing a list of all the segments.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '`sex_age` 列需要解析，并分割为两个变量。为此，我们利用了`str`访问器提供的额外功能，这仅适用于 Series（单个数据框列）。`split`
    方法在这种情况下是更常见的方法之一，它可以将字符串的不同部分分割为自己的列。默认情况下，它在空格上分割，但您也可以使用 `pat` 参数指定字符串或正则表达式。当
    `expand` 参数设置为 `True` 时，为每个独立分割字符段形成新列。当为 `False` 时，返回一个包含所有段列表的单列。'
- en: After renaming the columns in step 4, we need to use the `str` accessor again.
    Interestingly enough, the indexing operator is available to select or slice segments
    of a string. Here, we select the first character, which is the variable for sex.
    We could go further and split the ages into two separate columns for minimum and
    maximum age, but it is common to refer to the entire age group in this manner,
    so we leave it as is.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 4 中重新命名列后，我们需要再次使用 `str` 访问器。有趣的是，索引运算符可用于选择或切片字符串的段。在这里，我们选择第一个字符，即性别的变量。我们可以进一步将年龄分为两个单独的列，最小年龄和最大年龄，但通常以这种方式引用整个年龄组。
- en: Step 6 shows one of two different methods to join all the data together. The
    `concat` function accepts a collection of DataFrames and either concatenates them
    vertically (`axis='index'`) or horizontally (`axis='columns'`). Because the two
    DataFrames are indexed identically, it is possible to assign the values of one
    DataFrame to new columns in the other as done in step 7.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 第 6 步展示了连接所有数据的两种不同方法之一。`concat` 函数接受一组数据框，并且可以垂直 (`axis='index'`) 或水平 (`axis='columns'`)
    连接它们。由于两个数据框的索引相同，在第 7 步中将一个数据框的值分配给另一个数据框的新列是可能的。
- en: There's more...
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Another way to complete this recipe, beginning after step 2, is by directly
    assigning new columns from the `sex_age` column without using the `split` method.
    The `assign` method may be used to add these new columns dynamically:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种在步骤 2 之后完成此操作的方法是直接从 `sex_age` 列中分配新列，而无需使用 `split` 方法。可以使用 `assign` 方法动态添加这些新列：
- en: '[PRE56]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The `Sex` column is found in the exact same manner as done in step 5\. Because
    we are not using `split`, the `Age Group` column must be extracted in a different
    manner. The `extract` method uses a complex regular expression to extract very
    specific portions of the string. To use `extract` correctly, your pattern must
    contain capture groups. A capture group is formed by enclosing parentheses around
    a portion of the pattern. In this example, the entire expression is one large
    capture group. It begins with `\d{2}`, which searches for exactly two digits,
    followed by either a literal plus or minus, optionally followed by two more digits.
    Although the last part of the expression, `(?:\d{2})?`, is surrounded by parentheses,
    the `?:`  denotes that it is not actually a capture group. It is technically a
    non-capturing group used to express two digits together as optional. The `sex_age`
    column is no longer needed and is dropped. Finally, the two tidy DataFrames are
    compared against one another and are found to be equivalent.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '`Sex` 列的查找方式与第 5 步完全相同。因为我们没有使用 `split`，所以必须以不同的方式提取 `Age Group` 列。`extract`
    方法使用复杂的正则表达式提取字符串的特定部分。要正确使用 `extract`，您的模式必须包含捕获组。捕获组通过在模式的一部分周围加括号形成。在这个例子中，整个表达式是一个大的捕获组。它以
    `\d{2}` 开始，搜索精确两位数字，接着是一个字面上的加号或减号，后面可以跟着两位数字。虽然表达式的最后部分 `(?:\d{2})?` 周围有括号，但
    `?:` 表示它实际上不是捕获组。这在技术上是一个非捕获组，用于表达两位数字一起作为可选项。`sex_age` 列现在不再需要并被丢弃。最后，这两个整洁的数据框相互比较，并且发现它们是等价的。'
- en: See also
  id: totrans-291
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Refer to the site *Regular-Expressions.info* for more on non-capturing groups
    ([http://bit.ly/2f60KSd](http://www.regular-expressions.info/brackets.html))
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅 *Regular-Expressions.info* 网站以了解更多关于非捕获组的信息 ([http://bit.ly/2f60KSd](http://www.regular-expressions.info/brackets.html))
- en: Tidying when multiple variables are stored as column values
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当多个变量存储为列值时进行整理
- en: 'Tidy datasets must have a single column for each variable. Occasionally, multiple
    variable names are placed in a single column with their corresponding value placed
    in another. The general format for this kind of messy data is as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 整洁的数据集必须为每个变量设置单独的列。偶尔，多个变量名被放置在一个列中，并且它们对应的值放在另一个列中。这种混乱数据的通用格式如下：
- en: '![](img/42ccf8cc-1772-41ed-978d-baeb3c6042db.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![](img/42ccf8cc-1772-41ed-978d-baeb3c6042db.png)'
- en: 'In this example, the first and last three rows represent two distinct observations
    that should each be rows. The data needs to be pivoted such that it ends up like
    this:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，前后三行表示两组不同的观测数据，它们本应分别作为单独的行。需要对数据进行透视，使其变成如下所示：
- en: '![](img/8bbcb829-f145-419a-b236-d56c301bed4b.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8bbcb829-f145-419a-b236-d56c301bed4b.png)'
- en: Getting ready
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we identify the column containing the improperly structured
    variables and pivot it to create tidy data.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例中，我们找出包含结构不正确的变量的列，并将其进行透视以创建整洁的数据。
- en: How to do it...
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Read in the restaurant `inspections` dataset, and convert the `Date` column
    data type to `datetime64`:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取餐厅`inspections`数据集，并将`Date`列的数据类型转换为`datetime64`：
- en: '[PRE57]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '![](img/c0cb0612-2512-4bf6-b4c7-fe701add7627.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c0cb0612-2512-4bf6-b4c7-fe701add7627.png)'
- en: 'This dataset has two variables, `Name` and `Date`, that are each correctly
    contained in a single column. The `Info` column itself has five different variables: `Borough`,
    `Cuisine`, `Description`, `Grade`, and `Score`. Let''s attempt to use the `pivot`
    method to keep the `Name` and `Date` columns vertical, create new columns out
    of all the values in the `Info` column, and use the `Value` column as their intersection:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个数据集包含两个变量，`Name`和`Date`，它们分别正确地包含在单独的列中。`Info`列本身包含五个不同的变量：`Borough`、`Cuisine`、`Description`、`Grade`和`Score`。我们尝试使用`pivot`方法，将`Name`和`Date`列保持为竖直排列，将`Info`列中的所有值转换为新的列，并将`Value`列作为它们的交集：
- en: '[PRE58]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Unfortunately, pandas developers have not implemented this functionality for
    us. There is a good chance that in the future, this line of code is going to work.
    Thankfully, for the most part, pandas has multiple ways of accomplishing the same
    task. Let''s put `Name`, `Date`, and `Info` into the index:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不幸的是，pandas开发者尚未为我们实现这一功能。未来很可能这行代码会生效。幸运的是，pandas大多数情况下有多种方式实现同一任务。我们将`Name`、`Date`和`Info`放入索引中：
- en: '[PRE59]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '![](img/8cc902d7-4f90-45e4-9e77-c46bb9f9bad2.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8cc902d7-4f90-45e4-9e77-c46bb9f9bad2.png)'
- en: 'Use the `unstack` method to pivot all the values in the `Info` column:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`unstack`方法将`Info`列中的所有值进行透视：
- en: '[PRE60]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '![](img/1d9dc70a-4ba4-4c52-baaa-0885be04978e.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d9dc70a-4ba4-4c52-baaa-0885be04978e.png)'
- en: 'Make the index levels into columns with the `reset_index` method:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`reset_index`方法将索引级别转化为列：
- en: '[PRE61]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '![](img/43f33846-bc71-4616-8bef-0479a9369591.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![](img/43f33846-bc71-4616-8bef-0479a9369591.png)'
- en: 'The dataset is tidy, but there is some annoying leftover pandas debris that
    needs to be removed. Let''s use the MultiIndex method `droplevel` to remove the
    top column level and then rename the index level to `None`:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集已经整洁，但仍然有一些令人讨厌的pandas残留物需要清理。我们使用MultiIndex方法`droplevel`来删除顶部的列级别，然后将索引级别重命名为`None`：
- en: '[PRE62]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '![](img/03216f24-010c-4470-996c-1d5f4f3f575c.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![](img/03216f24-010c-4470-996c-1d5f4f3f575c.png)'
- en: 'The creation of the column MultiIndex in step 4 could have been avoided by
    converting that one column DataFrame into a Series with the `squeeze` method.
    The following code produces the same result as the previous step:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第4步中创建的列MultiIndex本可以通过将该单列DataFrame转换为Series并使用`squeeze`方法避免。以下代码产生与上一步相同的结果：
- en: '[PRE63]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: How it works...
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其工作原理...
- en: In step 1, we notice that there are five variables placed vertically in the
    `Info` column with their corresponding value in the `Value` column. Because we
    need to pivot each of these five variables as horizontal column names, it would
    seem that the `pivot` method would work. Unfortunately, pandas developers have
    yet to implement this special case when there is more than one non-pivoted column.
    We are forced to use a different method.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1步中，我们注意到`Info`列中垂直排列了五个变量及其对应的`Value`列中的值。由于我们需要将这五个变量作为横向列名，因此看起来`pivot`方法应该可以工作。不幸的是，pandas开发者尚未实现当存在多个非透视列时的这种特殊情况，我们只能使用其他方法。
- en: The `unstack` method also pivots vertical data, but only for data in the index.
    Step 3 begins this process by moving both the columns that will and will not be
    pivoted into the index with the `set_index` method. Once these columns are in
    the index, `unstack` can be put to work as done in step 3.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '`unstack`方法也可以对垂直数据进行透视，但仅对索引中的数据有效。第3步通过`set_index`方法将需要透视和不需要透视的列都移动到索引中，开始了这一过程。将这些列放入索引后，`unstack`就可以像第3步那样使用了。'
- en: Notice that as we are unstacking a DataFrame, pandas keeps the original column
    names (here, it is just a single column, `Value`) and creates a MultiIndex with
    the old column names as the upper level. The dataset is now essentially tidy but
    we go ahead and make our non-pivoted columns normal columns with the `reset_index`
    method. Because we have MultiIndex columns, we can choose which level the new
    column names will belong to with the `col_level` parameter. By default, the names
    are inserted into the uppermost level (level 0). We use `-1` to indicate the bottommost
    level.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在我们对DataFrame进行unstack操作时，pandas会保留原来的列名（这里只有一列，`Value`），并用旧的列名作为上层级创建一个MultiIndex。现在数据集基本上已经是整洁的，但我们继续使用`reset_index`方法，将非透视列变成常规列。因为我们有MultiIndex列，我们可以使用`col_level`参数来选择新列名属于哪个层级。默认情况下，名称会被插入到最上层（层级0）。我们使用`-1`来指示最底层。
- en: After all this, we have some excess DataFrame names and indexes that need to
    be discarded. Unfortunately, there isn't a DataFrame method that can remove levels,
    so we must drop down into the index and use its `droplevel` method. Here, we overwrite
    the old MultiIndex columns with single-level columns. These columns still have
    a useless name attribute, `Info`, which is renamed to `None`.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这些操作后，我们有一些多余的DataFrame名称和索引需要被丢弃。不幸的是，没有DataFrame方法可以删除层级，所以我们必须深入到索引中，使用其`droplevel`方法。在这里，我们用单级列覆盖了旧的MultiIndex列。这些列仍然有一个无用的名称属性`Info`，我们将其重命名为`None`。
- en: Cleaning up the MultiIndex columns could have been avoided by forcing the resulting
    DataFrame from step 3 to a Series. The `squeeze` method works only on single-column
    DataFrames and turns them into Series.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将第3步的结果强制转换为Series，可以避免清理MultiIndex列。`squeeze`方法只适用于单列DataFrame，并将其转换为Series。
- en: There's more...
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'It is actually possible to use the `pivot_table` method, which has no restrictions
    on how many non-pivoted columns are allowed. The `pivot_table` method differs
    from `pivot` by performing an aggregation for all the values that correspond to
    the intersection between the columns in the `index` and `columns` parameters.
    Because it is possible that there are multiple values in this intersection, `pivot_table`
    requires the user to pass it an aggregating function, in order to output a single
    value. We use the `first` aggregating function, which takes the first of the values
    of the group. In this particular example, there is exactly one value for each
    intersection, so there is nothing to be aggregated. The default aggregation function
    is the mean, which will produce an error here since some of the values are strings:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上可以使用`pivot_table`方法，该方法对非透视列的数量没有限制。`pivot_table`方法与`pivot`的不同之处在于，它对位于`index`和`columns`参数交集中的所有值执行聚合操作。由于可能存在多个值在这个交集里，`pivot_table`要求用户传递一个聚合函数，以便输出一个单一值。我们使用`first`聚合函数，它取组中第一个值。在这个特定的例子中，每个交集位置只有一个值，因此不需要进行聚合。默认的聚合函数是均值，但这里会产生错误，因为其中一些值是字符串类型：
- en: '[PRE64]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: See also
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: Pandas official documentation of the `droplevel` ([http://bit.ly/2yo5BXf](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.MultiIndex.droplevel.html))
    and `squeeze` ([http://bit.ly/2yo5TgN](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.squeeze.html))
    methods
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas官方文档中的`droplevel`方法（[http://bit.ly/2yo5BXf](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.MultiIndex.droplevel.html)）和`squeeze`方法（[http://bit.ly/2yo5TgN](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.squeeze.html)）
- en: Tidying when two or more values are stored in the same cell
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当两个或更多的值存储在同一个单元格中时的整理
- en: Tabular data, by nature, is two-dimensional, and thus, there is a limited amount
    of information that can be presented in a single cell. As a workaround, you will
    occasionally see datasets with more than a single value stored in the same cell.
    Tidy data allows for exactly a single value for each cell. To rectify these situations,
    you will typically need to parse the string data into multiple columns with the
    methods from the `str` Series accessor.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 表格数据天生是二维的，因此每个单元格中可以展示的信息是有限的。为了解决这个问题，您有时会看到数据集中一个单元格中存储了多个值。整洁的数据要求每个单元格恰好包含一个值。要解决这些情况，通常需要使用`str`系列访问器中的方法将字符串数据解析成多个列。
- en: Getting ready...
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作...
- en: In this recipe, we examine a dataset that has a column containing multiple different
    variables in each cell. We use the `str` accessor to parse these strings into
    separate columns to tidy the data.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们查看了一个数据集，其中有一列包含每个单元格中多个不同的变量。我们使用`str`访问器将这些字符串解析成单独的列，以整理数据。
- en: How to do it...
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Read in the Texas `cities` dataset, and identify the variables:'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取德克萨斯州的`cities`数据集，并识别变量：
- en: '[PRE65]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '![](img/31a2b314-702f-4cca-b436-cd0d8fdc701c.png)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![](img/31a2b314-702f-4cca-b436-cd0d8fdc701c.png)'
- en: 'The `City` column looks good and contains exactly one value. The `Geolocation`
    column, on the other hand, contains four variables: `latitude`, `latitude direction`,
    `longitude`, and `longitude direction`. Let''s split the `Geolocation` column
    into four separate columns:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`City`列看起来没问题，且仅包含一个值。另一方面，`Geolocation`列包含四个变量：`latitude`、`latitude direction`、`longitude`和`longitude
    direction`。我们将`Geolocation`列拆分为四个单独的列：'
- en: '[PRE66]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '![](img/5264d585-9f44-4741-9b3e-c87b9bd36cb9.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5264d585-9f44-4741-9b3e-c87b9bd36cb9.png)'
- en: 'Because the original data type for the `Geolocation` was an object, all the
    new columns are also objects. Let''s change `latitude` and `longitude` into floats:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于`Geolocation`的原始数据类型是对象，因此所有新列的类型也都是对象。现在，我们将`latitude`和`longitude`转换为浮动类型：
- en: '[PRE67]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Concatenate these new columns with the `City` column from the original:'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些新列与原始的`City`列连接起来：
- en: '[PRE68]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '![](img/d64eada2-828f-45a4-bf44-27938354fa58.png)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d64eada2-828f-45a4-bf44-27938354fa58.png)'
- en: How it works...
  id: totrans-347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原理...
- en: After reading the data, we decide how many variables there are in the dataset.
    Here, we chose to split the `Geolocation` column into four variables, but we could
    have just chosen two for latitude and longitude and used a negative sign to differentiate
    between west/east and south/north.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在读取数据之后，我们决定数据集中有多少个变量。在这里，我们选择将`Geolocation`列拆分为四个变量，但我们也可以选择仅拆分为两个变量，分别表示纬度和经度，并使用负号区分东西经和南北纬。
- en: There are a few ways to parse the `Geolocation` column with the methods from
    the `str` accessor. The easiest way is to use the `split` method. We pass it a
    simple regular expression defined by any character (the period) and a space. When
    a space follows any character, a split is made, and a new column is formed. The
    first occurrence of this pattern takes place at the end of the latitude. A space
    follows the degree character, and a split is formed. The splitting characters
    are discarded and not kept in the resulting columns. The next split matches the
    comma and space following directly after the latitude direction.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以通过`str`访问器的方法来解析`Geolocation`列。最简单的方式是使用`split`方法。我们传入一个简单的正则表达式，定义任意字符（即句点）和空格。当一个空格出现在任何字符后面时，就会进行拆分并形成一个新列。此模式第一次出现在纬度的末尾，度数符号后有一个空格，从而形成拆分。拆分符号会被丢弃，不会出现在结果列中。下一个拆分匹配紧跟在纬度方向后的逗号和空格。
- en: A total of three splits are made, resulting in four columns. The second line
    in step 2 provides them with meaningful names. Even though the resulting `latitude`
    and `longitude` columns appear to be floats, they are not. They were originally
    parsed from an object column and therefore remain object data types. Step 3 uses
    a dictionary to map the column names to their new types.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 总共进行了三次拆分，生成了四个列。步骤2中的第二行为它们提供了有意义的名称。尽管生成的`latitude`和`longitude`列看起来像是浮动类型，但它们实际上不是。它们最初是从对象列中解析出来的，因此仍然是对象数据类型。步骤3使用字典将列名映射到新的数据类型。
- en: 'Instead of using a dictionary, which would require a lot of typing if you had
    many column names, you can use the function `to_numeric` to attempt to convert
    each column to either integer or float. To apply this function iteratively over
    each column, use the `apply` method with the following:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 与其使用字典（如果列名很多，打字量会很大），不如使用`to_numeric`函数，尝试将每个列转换为整数或浮动类型。为了在每一列上迭代应用此函数，可以使用`apply`方法，如下所示：
- en: '[PRE69]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Step 4 concatenates the city to the front of this new DataFrame to complete
    the process of making tidy data.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 第4步将城市名称附加到这个新DataFrame的前面，以完成整洁数据的制作过程。
- en: There's more...
  id: totrans-354
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The `split` method worked exceptionally well in this example with a simple
    regular expression. For other examples, some columns might require you to create
    splits on several different patterns. To search for multiple regular expressions,
    use the pipe character `|`. For instance, if we wanted to split only the degree
    symbol and comma, each followed by a space, we would do the following:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，`split`方法与简单的正则表达式配合得非常好。对于其他例子，某些列可能需要你创建多个不同模式的拆分。要搜索多个正则表达式，可以使用管道字符`|`。例如，如果我们只想拆分度符号和逗号，并且每个符号后面都有一个空格，我们将这样做：
- en: '[PRE70]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: This returns the same DataFrame from step 2\. Any number of additional split
    patterns may be appended to the preceding string pattern with the pipe character.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回与第2步相同的DataFrame。任何数量的额外拆分模式可以通过管道字符追加到前面的字符串模式中。
- en: 'The `extract` method is another excellent method which allows you to extract
    specific groups within each cell. These capture groups must be enclosed in parentheses.
    Anything that matches outside the parentheses is not present in the result. The
    following line produces the same output as step 2:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '`extract`方法是另一个非常优秀的方法，它允许你提取每个单元格内的特定组。这些捕获组必须用括号括起来。括号外匹配的任何内容都不会出现在结果中。以下这一行的输出与第2步相同：'
- en: '[PRE71]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: This regular expression has four capture groups. The first and third groups
    search for at least one or more consecutive digits with decimals. The second and
    fourth groups search for a single character (the direction). The first and third
    capture groups are separated by any character followed by a space. The second
    capture group is separated by a comma and then a space.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 这个正则表达式有四个捕获组。第一个和第三个组用于搜索至少一个或多个连续的带小数的数字。第二个和第四个组用于搜索单个字符（方向）。第一个和第三个捕获组由任何字符和一个空格分隔。第二个捕获组由逗号和空格分隔。
- en: Tidying when variables are stored in column names and values
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当变量存储在列名和列值中时的整洁化
- en: One particularly difficult form of messy data to diagnose appears whenever variables
    are stored both horizontally across the column names and vertically down column
    values. You will typically encounter this type of dataset, not in a database,
    but from a summarized report that someone else has already generated.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 一种特别难以诊断的凌乱数据形式出现在变量同时存储在列名横向和列值纵向时。你通常会在数据库中遇不到这种数据集，而是在某个已经生成的汇总报告中遇到。
- en: Getting ready
  id: totrans-363
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, variables are identified both vertically and horizontally and
    reshaped into tidy data with the `melt` and `pivot_table` methods.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，变量既在垂直方向上又在水平方向上被识别，并通过`melt`和`pivot_table`方法重塑成整洁数据。
- en: How to do it...
  id: totrans-365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Read in the `sensors` dataset and identify the variables:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取`sensors`数据集并识别变量：
- en: '[PRE72]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '![](img/282dc5ee-23e7-4efb-aaa3-f0dc2d4a047f.png)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![](img/282dc5ee-23e7-4efb-aaa3-f0dc2d4a047f.png)'
- en: 'The only variable placed correctly in a vertical column is `Group`. The `Property`
    column appears to have three unique variables, `Pressure`, `Temperature`, and
    `Flow`. The rest of the columns `2012` to `2016` are themselves a single variable,
    which we can sensibly name `Year`. It isn''t possible to restructure this kind
    of messy data with a single DataFrame method. Let''s begin with the `melt` method
    to pivot the years into their own column:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 唯一正确放置在垂直列中的变量是`Group`。`Property`列似乎有三个独特的变量，分别是`Pressure`、`Temperature`和`Flow`。其余的列`2012`到`2016`本身是单个变量，我们可以合理地将其命名为`Year`。这种凌乱的数据无法通过单一的DataFrame方法重构。让我们先使用`melt`方法，将年份转置到各自的列中：
- en: '[PRE73]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '![](img/0d2b310a-19e4-4cb7-87c8-d0c052a7e68a.png)'
  id: totrans-371
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0d2b310a-19e4-4cb7-87c8-d0c052a7e68a.png)'
- en: 'This takes care of one of our issues. Let''s use the `pivot_table` method to
    pivot the `Property` column into new column names:'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这解决了我们的问题之一。我们使用`pivot_table`方法将`Property`列转置为新的列名：
- en: '[PRE74]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '![](img/10329c01-746c-4fdd-8402-a4fa284c0286.png)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10329c01-746c-4fdd-8402-a4fa284c0286.png)'
- en: How it works...
  id: totrans-375
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Once we have identified the variables in step 1, we can begin our restructuring.
    Pandas does not have a method to pivot columns simultaneously, so we must take
    on this task one step at a time. We correct the years by keeping the `Property`
    column vertical by passing it to the `id_vars` parameter in the `melt` method.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们在第一步中识别出了变量，我们就可以开始进行重构。Pandas没有一个方法可以同时旋转多个列，因此我们必须一步步地处理。我们通过将`Property`列传递给`melt`方法中的`id_vars`参数来保持其竖直排列，从而纠正年份数据。
- en: The result is now precisely the pattern of messy data found in the preceding
    recipe, *Tidying when multiple variables are stored as column values.* As explained
    in the *There's more* section of that recipe, we must use `pivot_table` to pivot
    a DataFrame when using more than one column in the `index` parameter. After pivoting,
    the `Group` and `Year` variables are stuck in the index. We push them back out
    as columns. The `pivot_table` method preserves the column name used in the `columns`
    parameter as the name of the column index. After resetting the index, this name
    is meaningless, and we remove it with `rename_axis`.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 结果现在正是前面“*当多个变量作为列值存储时进行整洁化*”章节中的混乱数据模式。如该章节中的“*还有更多...*”部分所述，当`index`参数中使用多个列时，我们必须使用`pivot_table`来旋转DataFrame。在旋转之后，`Group`和`Year`变量被固定在索引中。我们将它们作为列重新提取出来。`pivot_table`方法会将`columns`参数中使用的列名保留为列索引名。重设索引后，这个名称已不再有意义，我们使用`rename_axis`将其删除。
- en: There's more...
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Whenever a solution involves `melt`, `pivot_table`, or `pivot`, you can be
    sure that there is an alternative method using `stack` and `unstack`. The trick
    is first to move the columns that are not currently being pivoted into the index:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 每当解决方案涉及到`melt`、`pivot_table`或`pivot`时，你可以确信有一种使用`stack`和`unstack`的替代方法。诀窍是首先将当前没有被旋转的列移到索引中：
- en: '[PRE75]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Tidying when multiple observational units are stored in the same table
  id: totrans-381
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当多个观察单元存储在同一表格中
- en: It is generally easier to maintain data when each table contains information
    from a single observational unit. On the other hand, it can be easier to find
    insights when all data is in a single table, and in the case of machine learning,
    all data must be in a single table. The focus of tidy data is not on directly
    performing analysis. Rather, it is structuring the data so that analysis is easier
    further down the line, and when there are multiple observational units in one
    table, they may need to get separated into their own tables.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 当每个表格仅包含来自单一观察单元的信息时，通常更容易维护数据。另一方面，当所有数据都在一个表格中时，查找见解可能更为容易，在机器学习的情况下，所有数据必须在一个表格中。整洁数据的重点不在于直接进行分析，而是对数据进行结构化处理，以便后续分析更加简便。如果一个表格中包含多个观察单元，它们可能需要被分离成各自的表格。
- en: Getting ready
  id: totrans-383
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we use the `movie` dataset to identify the three observational
    units (movies, actors, and directors) and create separate tables for each. One
    of the keys to this recipe is understanding that the actor and director Facebook
    likes are independent of the movie. Each actor and director is mapped to a single
    value representing their number of Facebook likes. Due to this independence, we
    can separate the data for the movies, directors, and actors into their own tables.
    Database folks call this process normalization, which increases data integrity
    and reduces redundancy.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用`movie`数据集来识别三种观察单元（电影、演员和导演），并为每个单独创建表格。本章的一个关键点是理解演员和导演的Facebook点赞数与电影是独立的。每个演员和导演都有一个与之对应的值，表示他们的Facebook点赞数。由于这种独立性，我们可以将电影、导演和演员的数据分离到各自的表格中。数据库领域的人称这一过程为规范化，它提高了数据的完整性并减少了冗余。
- en: How to do it...
  id: totrans-385
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Read in the altered `movie` dataset, and output the first five rows:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取修改后的`movie`数据集，并输出前五行：
- en: '[PRE76]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '![](img/b97a1df3-edb5-4e9c-8a1d-56e74387c59c.png)'
  id: totrans-388
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b97a1df3-edb5-4e9c-8a1d-56e74387c59c.png)'
- en: 'This dataset contains information on the movie itself, the director, and actors.
    These three entities can be considered observational units. Before we start, let''s
    use the `insert` method to create a column to uniquely identify each movie:'
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该数据集包含电影本身、导演和演员的信息。这三种实体可以视为观察单元。在开始之前，让我们使用`insert`方法创建一列，唯一标识每部电影：
- en: '[PRE77]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '![](img/764642b0-57b7-450a-aa3d-ec0fb80d040f.png)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
  zh: '![](img/764642b0-57b7-450a-aa3d-ec0fb80d040f.png)'
- en: 'Let''s attempt to tidy this dataset with the `wide_to_long` function to put
    all the actors in one column and their corresponding Facebook likes in another,
    and do the same for the director, even though there is only one per movie:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们尝试使用`wide_to_long`函数来整理这个数据集，将所有演员放在一列，将他们对应的Facebook点赞数放在另一列，同样对导演进行处理，尽管每部电影只有一个导演：
- en: '[PRE78]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '![](img/db2fb0dd-88b9-4ca5-8d58-a1a47e5fcd3a.png)'
  id: totrans-394
  prefs: []
  type: TYPE_IMG
  zh: '![](img/db2fb0dd-88b9-4ca5-8d58-a1a47e5fcd3a.png)'
- en: 'The dataset is now ready to be split into multiple smaller tables:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集现在已准备好被拆分成多个较小的表格：
- en: '[PRE79]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '![](img/5ea1387e-c719-46d4-91ab-dddbda8d76b3.png)  ![](img/fc4648c2-7958-4413-8d1c-71a644b02675.png) 
    ![](img/393e3f43-5347-419b-89f6-e5b2cdebdf0c.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ea1387e-c719-46d4-91ab-dddbda8d76b3.png)  ![](img/fc4648c2-7958-4413-8d1c-71a644b02675.png)  ![](img/393e3f43-5347-419b-89f6-e5b2cdebdf0c.png)'
- en: 'There are still several issues with these tables. The `movie` table duplicates
    each movie three times, the director table has two missing rows for each ID, and
    a few movies have missing values for some of the actors. Let''s take care of these
    issues:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些表格仍然存在几个问题。`movie`表格每部电影重复了三次，导演表格每个ID有两行缺失，另外一些电影的演员数据也缺失。让我们解决这些问题：
- en: '[PRE80]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '![](img/5fff55d4-6424-4a23-a31e-9b3811062ec7.png)    ![](img/f2c340d0-bc16-4d3f-9b3e-e985172fe4d6.png)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5fff55d4-6424-4a23-a31e-9b3811062ec7.png)    ![](img/f2c340d0-bc16-4d3f-9b3e-e985172fe4d6.png)'
- en: 'Now that we have separated the observational units into their own tables, let''s
    compare the memory of the original dataset with these three tables:'
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经将观察单元分开到各自的表格中，让我们将原始数据集的内存与这三个表格进行对比：
- en: '[PRE81]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Our new tidier data actually takes up a little more memory. This is to be expected,
    as all the data in the original columns are simply spread out into the new tables.
    The new tables also each have an index, and two of them have an extra `num` column,
    which accounts for the extra memory. We can, however, take advantage of the fact
    that the count of Facebook likes is independent of the movie, meaning that each
    actor and director has exactly one count of Facebook likes for all movies. Before
    we can do this, we need to create another table mapping each movie to each actor/director.
    Let''s first create `id` columns specific to the actor and director tables, uniquely
    identifying each actor/director:'
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们整理后的数据实际上占用了更多的内存。这是可以预期的，因为原始列中的所有数据只是被分散到了新的表格中。新的表格每个都有一个索引，并且其中两个表格有一个额外的`num`列，这就是额外内存的原因。然而，我们可以利用Facebook点赞数与电影无关这一事实，即每个演员和导演对所有电影的Facebook点赞数是相同的。在我们进行这个操作之前，我们需要创建一个新的表格，将每部电影映射到每个演员/导演。首先，让我们为演员和导演表格创建`id`列，唯一标识每个演员/导演：
- en: '[PRE82]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '![](img/daf3c29d-7671-482c-8238-fba2bbcbf5aa.png)   ![](img/216498c9-7f00-499c-8364-15e4062a925e.png)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![](img/daf3c29d-7671-482c-8238-fba2bbcbf5aa.png)   ![](img/216498c9-7f00-499c-8364-15e4062a925e.png)'
- en: 'We can use these tables to form our intermediate tables and unique `actor`/`director`
    tables. Let''s first do this with the `director` tables:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以利用这些表格来形成我们的中间表格和唯一的`actor`/`director`表格。我们首先用`director`表格来处理：
- en: '[PRE83]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '![](img/70bc3432-dfb3-4c38-8d3f-70bc9c0be26a.png)     ![](img/820a26f7-83b9-4d2c-b109-513beb3c607a.png)'
  id: totrans-408
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70bc3432-dfb3-4c38-8d3f-70bc9c0be26a.png)     ![](img/820a26f7-83b9-4d2c-b109-513beb3c607a.png)'
- en: 'Let''s do the same thing with the `actor` table:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们用`actor`表格做同样的操作：
- en: '[PRE84]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '![](img/0a2222e9-0cb6-4351-922d-21aab964aee2.png)    ![](img/e577a0e7-455c-4a7d-8abf-6863ea069432.png)'
  id: totrans-411
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0a2222e9-0cb6-4351-922d-21aab964aee2.png)    ![](img/e577a0e7-455c-4a7d-8abf-6863ea069432.png)'
- en: 'Let''s find out how much memory our new tables consume:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来看看这些新表格消耗了多少内存：
- en: '[PRE85]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Now that we have normalized our tables, we can build an entity-relationship
    diagram showing all the tables (entities), columns, and relationships. This diagram
    was created with the easy to use ERDPlus ([https://erdplus.com](https://erdplus.com/#/)):![](img/272f2599-5e7a-4001-94e9-90eb430ba6d7.png)
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经规范化了我们的表格，我们可以构建一个实体-关系图，展示所有表格（实体）、列以及它们之间的关系。这个图是通过易于使用的ERDPlus工具创建的（[https://erdplus.com](https://erdplus.com/#/)）：![](img/272f2599-5e7a-4001-94e9-90eb430ba6d7.png)
- en: How it works...
  id: totrans-415
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: After importing the data and identifying the three entities, we must create
    a unique identifier for each observation so that we can link to the movies, actors
    and directors together once they have been separated into different tables. In
    step 2, we simply set the ID column as the row number beginning from zero. In
    step 3, we use the `wide_to_long` function to simultaneously `melt` the `actor`
    and `director` columns. It uses the integer suffix of the columns to align the
    data vertically and places this integer suffix in the index. The parameter `j`
    is used to control its name. The values in the columns not in the `stubnames`
    list repeat to align with the columns that were melted.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入数据并识别出三个实体之后，我们必须为每个观察值创建一个唯一标识符，这样一来，当它们被分隔到不同的表格时，我们就能将电影、演员和导演关联在一起。在步骤2中，我们简单地将ID列设置为从零开始的行号。在步骤3中，我们使用`wide_to_long`函数同时`melt`（熔化）`actor`和`director`列。它使用列的整数后缀来将数据垂直对齐，并将此整数后缀放置在索引中。参数`j`用于控制其名称。列中不在`stubnames`列表中的值会重复，以便与已熔化的列对齐。
- en: In step 4, we create our three new tables, keeping the `id` column in each.
    We also keep the `num` column to identify the exact `director`/`actor` column
    from which it was derived. Step 5 condenses each table by removing duplicates
    and missing values.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤4中，我们创建了三个新的表格，每个表格都保留了`id`列。我们还保留了`num`列，用于标识它所衍生的具体`director`/`actor`列。步骤5通过去除重复项和缺失值来压缩每个表格。
- en: After step 5, the three observational units are in their own tables, but they
    still contain the same amount of data as the original (and a bit more), as seen
    in step 6\. To return the correct number of bytes from the `memory_usage` method
    for `object` data type columns, you must set the `deep` parameter to `True`.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤5之后，三个观察单元已经各自放入了独立的表格中，但它们仍然包含与原始表格相同的数据量（甚至更多），如步骤6所示。为了从`memory_usage`方法返回正确的字节数，针对`object`数据类型的列，必须将`deep`参数设置为`True`。
- en: Each actor/director needs only one entry in his or her respective tables. We
    can't simply make a table of just actor name and Facebook likes, as there would
    be no way to link the actors back to the original movie. The relationship between
    movies and actors is called a **many-to-many relationship**. Each movie is associated
    with multiple actors, and each actor can appear in multiple movies. To resolve
    this relationship, an intermediate or associative table is created, which contains
    the unique identifiers (**primary keys**) of both the movie and actor.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 每个演员/导演在其相应的表格中只需要一个条目。我们不能简单地创建一个仅包含演员名字和Facebook点赞数的表格，因为那样就无法将演员与原始电影关联起来。电影与演员之间的关系被称为**多对多关系**。每部电影与多个演员相关联，每个演员也可以出现在多部电影中。为了解决这个关系，创建了一个中间或关联表，它包含电影和演员的唯一标识符（**主键**）。
- en: To create associative tables, we must uniquely identify each actor/director.
    One trick is to create a categorical data type out of each actor/director name
    with `pd.Categorical`. Categorical data types have an internal map from each value
    to an integer. This integer is found in the `codes` attribute, which is used as
    the unique ID. To set up the creation of the associative table, we add this unique
    ID to the `actor`/`director` tables.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建关联表，我们必须唯一标识每个演员/导演。一个技巧是使用`pd.Categorical`从每个演员/导演的名字创建一个分类数据类型。分类数据类型有一个内部映射，将每个值映射到一个整数。这个整数可以在`codes`属性中找到，它被用作唯一ID。为了设置关联表的创建，我们将这个唯一ID添加到`actor`/`director`表中。
- en: Step 8 and step 9 create the associative tables by selecting both of the unique
    identifiers. Now, we can reduce the `actor` and `director` tables to just the
    unique names and Facebook likes. This new arrangement of tables uses 20% less
    memory than the original. Formal relational databases have entity-relationship
    diagrams to visualize the tables. In step 10, we use the simple ERDPlus tool to
    make the visualization, which greatly eases the understanding of the relationships
    between the tables.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤8和步骤9通过选择两个唯一标识符来创建关联表。现在，我们可以将`actor`和`director`表减少到仅包含唯一名称和Facebook点赞数。这个新表格的布局比原始布局节省了20%的内存。正式的关系数据库有实体关系图（ERD）来可视化表格。在步骤10中，我们使用简单的ERDPlus工具来进行可视化，这大大帮助了理解表格之间的关系。
- en: There's more...
  id: totrans-422
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'It is possible to recreate the original `movie` table by joining all the tables
    back together. First, join the associative tables to the `actor`/`director` tables.
    Then pivot the num column, and add the column prefixes back:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过将所有表格重新连接起来，重新创建原始的`movie`表。首先，将关联表连接到`actor`/`director`表。然后对`num`列进行透视，并将列前缀重新添加：
- en: '[PRE86]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '![](img/ba4a5426-19e4-4531-b181-647f0192e0df.png)![](img/c3b43d8b-89fd-4066-8431-9f8ded3783f7.png)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba4a5426-19e4-4531-b181-647f0192e0df.png)![](img/c3b43d8b-89fd-4066-8431-9f8ded3783f7.png)'
- en: 'These tables can now be joined together with `movie_table`:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这些表可以通过`movie_table`连接在一起：
- en: '[PRE87]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: See also
  id: totrans-428
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: More on database normalization ([http://bit.ly/2w8wahQ](https://en.wikipedia.org/wiki/Database_normalization)),
    associative tables ([http://bit.ly/2yqE4oh](https://en.wikipedia.org/wiki/Associative_entity)),
    and primary and foreign keys ([http://bit.ly/2xgIvEb](https://en.wikipedia.org/wiki/Unique_key))
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于数据库规范化的更多信息（[http://bit.ly/2w8wahQ](https://en.wikipedia.org/wiki/Database_normalization)）、关联表（[http://bit.ly/2yqE4oh](https://en.wikipedia.org/wiki/Associative_entity)）以及主键和外键（[http://bit.ly/2xgIvEb](https://en.wikipedia.org/wiki/Unique_key)）
- en: Refer to the *Stacking multiple groups of variables simultaneously* recipe in
    this chapter for more information on the `wide_to_long` function
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参考本章中的*同时堆叠多个变量组*配方，了解有关`wide_to_long`函数的更多信息。
