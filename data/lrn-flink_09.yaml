- en: Chapter 9. Deploying Flink on Cloud
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章 在云上部署Flink
- en: In the recent times, more and more companies have been investing in Cloud-based
    solutions and which is justified looking at the cost and efficiency we achieve
    through the Cloud. **Amazon Web Services** (**AWS**), **Google Cloud Platform**
    (**GCP**) and Microsoft Azure are the clear leaders so far in this business. Almost
    all of them provide big data solutions which are quite handy to use. The cloud
    provides efficient solutions in a timely manner where people don't need to worry
    about hardware purchases, networking, and so on.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，越来越多的公司投资于基于云的解决方案，这是有道理的，考虑到我们通过云实现的成本和效率。**亚马逊网络服务**（**AWS**）、**Google
    Cloud平台**（**GCP**）和微软Azure目前在这一业务中是明显的领导者。几乎所有这些公司都提供了相当方便使用的大数据解决方案。云提供了及时高效的解决方案，人们不需要担心硬件购买、网络等问题。
- en: In this chapter, we are going to see how we can deploy Flink on cloud. We will
    see a detailed approach to installing and deploying applications on AWS and Google
    Cloud. So let's get started.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看到如何在云上部署Flink。我们将详细介绍在AWS和Google Cloud上安装和部署应用程序的方法。所以让我们开始吧。
- en: Flink on Google Cloud
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Google Cloud上的Flink
- en: Flink can be deployed on Google Cloud using one utility called BDUtil. It is
    an open source utility available for everyone to use [https://cloud.google.com/hadoop/bdutil](https://cloud.google.com/hadoop/bdutil).
    The very first step we need to do is to install **Google Cloud SDK**.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Flink可以使用一个名为BDUtil的实用程序在Google Cloud上部署。这是一个开源实用程序，供所有人使用 [https://cloud.google.com/hadoop/bdutil](https://cloud.google.com/hadoop/bdutil)。我们需要做的第一步是安装**Google
    Cloud SDK**。
- en: Installing Google Cloud SDK
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装Google Cloud SDK
- en: Google Cloud SDK is an executable utility that can be installed on the Windows,
    Mac, or UNIX operating systems. You can choose the mode of installation based
    on your operating system. Here is a link that directs users about detailed installations
    at [https://cloud.google.com/sdk/downloads](https://cloud.google.com/sdk/downloads).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud SDK是一个可执行实用程序，可以安装在Windows、Mac或UNIX操作系统上。您可以根据您的操作系统选择安装模式。以下是一个链接，指导用户了解详细的安装过程 [https://cloud.google.com/sdk/downloads](https://cloud.google.com/sdk/downloads)。
- en: Here I assume that you are already familiar with Google Cloud concepts and the
    terminologies; if not I would recommend reading [https://cloud.google.com/docs/](https://cloud.google.com/docs/).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我假设您已经熟悉Google Cloud的概念和术语；如果没有，我建议阅读 [https://cloud.google.com/docs/](https://cloud.google.com/docs/)。
- en: In my case, I will be using UNIX machine to launch a Flink-Hadoop cluster. So
    let's get started with the installation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的情况下，我将使用UNIX机器启动一个Flink-Hadoop集群。所以让我们开始安装。
- en: First, we need to download the installer for the Cloud SDK.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要下载Cloud SDK的安装程序。
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next we un-tar the files by the following command:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过以下命令解压文件：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once done, we need to initialize the SDK:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们需要初始化SDK：
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will start an interactive installation process and will require you to
    provide input as and when needed. The following screenshot shows the process:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动一个交互式安装过程，并需要您根据需要提供输入。下面的截图显示了这个过程：
- en: '![Installing Google Cloud SDK](img/image_09_001.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![安装Google Cloud SDK](img/image_09_001.jpg)'
- en: 'It is also recommended to get authenticated by executing the following command:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 还建议通过执行以下命令进行身份验证：
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This will give you a URL to be opened in your machine's browser. On hitting
    that URL, you will a get code which will be used for authentication.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为您提供一个URL，可以在您的机器浏览器中打开。点击该URL，您将获得一个用于身份验证的代码。
- en: Once the authentication is done, we are all set for the BDUtil installation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 身份验证完成后，我们就可以开始BDUtil安装了。
- en: Installing BDUtil
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装BDUtil
- en: 'As we said earlier, BDUtil is a utility developed by Google to facilitate hiccup-free
    big data installations on Google Cloud. You can install the following services:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所说，BDUtil是Google开发的一个实用程序，旨在在Google Cloud上实现无故障的大数据安装。您可以安装以下服务：
- en: Hadoop - HDP and CDH
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop - HDP和CDH
- en: Flink
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flink
- en: Hama
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hama
- en: Hbase
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hbase
- en: Spark
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark
- en: Storm
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storm
- en: Tajo
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tajo
- en: 'The following steps are required to install BDUtil. First of all, we need to
    download the source code:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 安装BDUtil需要以下步骤。首先，我们需要下载源代码：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Unzip the code by the following command:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下命令解压代码：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It is recommended to use a **non-root account** for BDUtil operations if you
    are using it on one the Google Compute machine. Generally root logins are by default
    disabled on all compute engine machines.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在Google Compute机器上使用BDUtil操作，建议使用**非root帐户**。通常情况下，所有计算引擎机器默认禁用root登录。
- en: Now we are all set with the BDUtil installation and ready for deployment.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了BDUtil的安装，并准备好部署了。
- en: Launching a Flink cluster
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动Flink集群
- en: 'BDUtil needs at least one project in which we will do our installations and
    a bucket where temporary files can be kept. To create a bucket, you can go to
    the **Cloud Storage** sections and choose to create a bucket as shown in the following
    screenshot:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: BDUtil至少需要一个项目，我们将在其中进行安装，并且需要一个存放临时文件的存储桶。要创建一个存储桶，您可以转到**Cloud Storage**部分，并选择创建一个存储桶，如下截图所示：
- en: '![Launching a Flink cluster](img/image_09_002.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![启动Flink集群](img/image_09_002.jpg)'
- en: 'We have named this bucket at **bdutil-flink-bucket**. Next we need to edit
    the `bdutil_env.sh` file to configure information about the project name, bucket
    name and Google Cloud zone to be used. We can also set other things such as the
    machine type and Operating System. `bdutil_env.sh` looks as shown in the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将这个存储桶命名为**bdutil-flink-bucket**。接下来，我们需要编辑`bdutil_env.sh`文件，配置有关项目名称、存储桶名称和要使用的Google
    Cloud区域的信息。我们还可以设置其他内容，如机器类型和操作系统。`bdutil_env.sh`如下所示：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: By default, the configuration launches three node, Hadoop/Flink cluster with
    one master and two worker nodes.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，配置启动三个节点，Hadoop/Flink集群，一个主节点和两个工作节点。
- en: Note
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you are using the trial version of GCP, then it is recommended to use machine
    type as **n1-standard-2**. This will restrict the CPU and storage of the node
    type.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用GCP的试用版，则建议使用机器类型为**n1-standard-2**。这将限制节点类型的CPU和存储。
- en: 'Now we are all set to launch the cluster, with the following command:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好启动集群，使用以下命令：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This will start creating machines and will deploy required software on it. It
    generally takes 10-20 minutes of time to get the cluster up and running if everything
    works well. Before starting the executing, you should review what the screen shot
    tell us.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这将开始创建机器并在其上部署所需的软件。如果一切顺利，通常需要10-20分钟的时间来启动和运行集群。在开始执行之前，您应该查看屏幕截图告诉我们什么。
- en: '![Launching a Flink cluster](img/image_09_003.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![启动Flink集群](img/image_09_003.jpg)'
- en: 'Once complete, you will see some messages as shown in the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您将看到以下消息：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In case of any failures in between, please check what logs say. You can visit
    the Google Cloud Compute Engine Console to get the exact IPs of the master and
    slave machines.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果中途出现任何故障，请查看日志。您可以访问Google云计算引擎控制台以获取主机和从机的确切IP地址。
- en: 'Now if you check the Job Manager UI, you should have two task managers and
    four task slots available for the use. You can hit URL `http://<master-node-ip>:8081`
    . The following is sample screenshot for the same:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果您检查作业管理器UI，您应该有两个任务管理器和四个任务插槽可供使用。您可以访问URL `http://<master-node-ip>:8081`。以下是相同的示例屏幕截图：
- en: '![Launching a Flink cluster](img/image_09_004.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![启动Flink集群](img/image_09_004.jpg)'
- en: Executing a sample job
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行示例作业
- en: You can check if everything is working fine by launching a sample word count
    program. In order to do so, we first need to log in to Flink Master node. The
    following command starts a sample word count program provided by Flink installation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过启动一个示例词频统计程序来检查一切是否正常运行。为此，我们首先需要登录到Flink主节点。以下命令启动了Flink安装提供的一个示例词频统计程序。
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following screenshot shows the execution map of the job:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了作业的执行地图：
- en: '![Executing a sample job](img/image_09_005.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![执行示例作业](img/image_09_005.jpg)'
- en: 'Here is another screenshot of the timeline with which all tasks got executed:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个时间轴的屏幕截图，显示了所有任务的执行情况：
- en: '![Executing a sample job](img/image_09_006.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![执行示例作业](img/image_09_006.jpg)'
- en: Shutting down the cluster
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关闭集群
- en: Once we are done with all our executions and if we no longer wish to do any
    further use of the cluster then it is better to shut it down.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们完成了所有的执行，如果我们不再希望进一步使用集群，最好关闭它。
- en: 'The following is a command, we need to execute to shut down the cluster we
    started:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个命令，我们需要执行以关闭我们启动的集群：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Please make sure to confirm the configurations before deleting the cluster.
    The following is a screenshot which shows what it is going to delete and the complete
    process:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在删除集群之前，请务必确认配置。以下是一个屏幕截图，显示了将要删除的内容和完整的过程：
- en: '![Shutting down the cluster](img/image_09_007.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![关闭集群](img/image_09_007.jpg)'
- en: Flink on AWS
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在AWS上使用Flink
- en: Now let's look at how we can use Flink on **Amazon Web Services** (**AWS**).
    Amazon provides a hosted Hadoop service called **Elastic Map Reduce** (**EMR**).
    We can use and Flink in combination. We can do reading on EMR at [https://aws.amazon.com/documentation/elastic-mapreduce/](https://aws.amazon.com/documentation/elastic-mapreduce/).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何在亚马逊网络服务（AWS）上使用Flink。亚马逊提供了一个托管的Hadoop服务，称为弹性Map Reduce（EMR）。我们可以结合使用Flink。我们可以在EMR上进行阅读[https://aws.amazon.com/documentation/elastic-mapreduce/](https://aws.amazon.com/documentation/elastic-mapreduce/)。
- en: Here I assume that you already have AWS account and knows basics of AWS.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我假设您已经有AWS帐户并了解AWS的基础知识。
- en: Launching an EMR cluster
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动EMR集群
- en: 'The very first thing we need to do is launch EMR cluster. We first need to
    log in to AWS account and choose **EMR** service from the console as shown in
    the following screenshot:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事就是启动EMR集群。我们首先需要登录到AWS帐户，并从控制台中选择EMR服务，如下图所示：
- en: '![Launching an EMR cluster](img/image_09_008.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![启动EMR集群](img/image_09_008.jpg)'
- en: 'Next we go to EMR console and launch a three-node cluster with one master and
    two slave nodes. Here we choose minimum cluster size to avoid surprise billing.
    The following screenshot shows the EMR cluster creation screen:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们转到EMR控制台，并启动一个包含一个主节点和两个从节点的三节点集群。在这里，我们选择最小的集群大小以避免意外计费。以下屏幕截图显示了EMR集群创建屏幕：
- en: '![Launching an EMR cluster](img/image_09_009.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![启动EMR集群](img/image_09_009.jpg)'
- en: 'Generally it takes 10-15 minutes for cluster to be up and running. Once the
    cluster is ready, we can do SSH to the cluster. For that we first need to click
    on **Create Security Group** section and add rule to add SSH port 22 rule. The
    following screen shows the security group section in which we need to edit **In
    Bound** traffic rule for SSH:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通常需要10-15分钟才能启动和运行集群。一旦集群准备就绪，我们可以通过SSH连接到集群。为此，我们首先需要单击“创建安全组”部分，并添加规则以添加SSH端口22规则。以下屏幕显示了安全组部分，在其中我们需要编辑SSH的“入站”流量规则：
- en: '![Launching an EMR cluster](img/image_09_010.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![启动EMR集群](img/image_09_010.jpg)'
- en: 'Now we are all set to login to the master node using SSH with the private key.
    You will see the following screen once you login with user name Hadoop:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好使用SSH和私钥登录到主节点。一旦使用Hadoop用户名登录，您将看到以下屏幕：
- en: '![Launching an EMR cluster](img/image_09_011.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![启动EMR集群](img/image_09_011.jpg)'
- en: Installing Flink on EMR
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在EMR上安装Flink
- en: 'Installing Flink is very easy once we have our EMR cluster ready. We need to
    do the following steps:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的EMR集群准备就绪，安装Flink就非常容易。我们需要执行以下步骤：
- en: 'Download the Flink compatible to right Hadoop Version from link - [http://flink.apache.org/downloads.html](http://flink.apache.org/downloads.html).
    I am downloading Flink compatible with Hadoop 2.7 version:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从链接[http://flink.apache.org/downloads.html](http://flink.apache.org/downloads.html)下载与正确的Hadoop版本兼容的Flink。我正在下载与Hadoop
    2.7版本兼容的Flink：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, we need to un-tar the installer:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要解压安装程序：
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And that is it, just go the un-tarred folder and set following environment
    variables and we are all set:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就是这样，只需进入解压后的文件夹并设置以下环境变量，我们就准备好了：
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Executing Flink on EMR-YARN
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在EMR-YARN上执行Flink
- en: 'Executing Flink on YARN is very easy. We have already learnt the details on
    Flink on YARN in the previous chapter. The following steps shows a sample job
    execution. This would submit a single Flink job to YARN:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在YARN上执行Flink非常容易。我们已经在上一章中学习了有关YARN上的Flink的详细信息。以下步骤显示了一个示例作业执行。这将向YARN提交一个单个的Flink作业：
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You will see immediately Flink executing will start and on completion, you
    will see the word count results:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 您将立即看到Flink的执行开始，并在完成后，您将看到词频统计结果：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can also look at YARN cluster UI as shown in the following screenshot:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看YARN集群UI，如下面的屏幕截图所示：
- en: '![Executing Flink on EMR-YARN](img/image_09_012.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![在EMR-YARN上执行Flink](img/image_09_012.jpg)'
- en: Starting a Flink YARN session
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动Flink YARN会话
- en: Alternatively we can also start a YARN session by blocking the resources which
    we have already seen in the previous chapter. A Flink YARN session will create
    a continuously running YARN session which can be used to execute multiple Flink
    jobs. This session keeps on running until we stop it.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们也可以通过阻止我们在上一章中已经看到的资源来启动YARN会话。Flink YARN会话将创建一个持续运行的YARN会话，可用于执行多个Flink作业。此会话将持续运行，直到我们停止它。
- en: 'To start the Flink YARN session, we need to execute the following command:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动Flink YARN会话，我们需要执行以下命令：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here we start two Task Managers with 768 MB memory each and 4 slots. You will
    see the YARN session ready as shown in the console logs:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们启动了两个具有每个768 MB内存和4个插槽的任务管理器。您将在控制台日志中看到YARN会话已准备就绪的情况：
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here is a screenshot of the Flink Job Manager UI, where we can see two Task
    Managers and eight task slots:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Flink作业管理器UI的屏幕截图，我们可以看到两个任务管理器和八个任务插槽：
- en: '![Starting a Flink YARN session](img/image_09_013.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![启动Flink YARN会话](img/image_09_013.jpg)'
- en: Executing Flink job on YARN session
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在YARN会话上执行Flink作业
- en: 'Now we can use this YARN session to submit Flink Jobs by executing the following
    command:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用这个YARN会话来提交Flink作业，执行以下命令：
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You will see word count job getting executed as shown in the following code:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到如下代码所示的词频统计作业的执行：
- en: '[PRE19]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here is a screenshot of the job execution details and task breakup:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是作业执行详细信息和任务分解的屏幕截图：
- en: '![Executing Flink job on YARN session](img/image_09_014.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![在YARN会话上执行Flink作业](img/image_09_014.jpg)'
- en: 'We can also see the timeline details on which all task were executed in parallel
    and which are in sequential manner. Here is screenshot of the same:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到时间轴详细信息，显示了所有并行执行的任务以及按顺序执行的任务。以下是同样的屏幕截图：
- en: '![Executing Flink job on YARN session](img/image_09_015.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![在YARN会话上执行Flink作业](img/image_09_015.jpg)'
- en: Shutting down the cluster
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关闭集群
- en: Once all our work is done, it is important to shut down the cluster. To do this,
    we again need to go to AWS console and click on the **Terminate** button.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有工作后，关闭集群非常重要。为此，我们需要再次转到AWS控制台，然后点击**终止**按钮。
- en: Flink on EMR 5.3+
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EMR 5.3+上的Flink
- en: AWS has now started supporting Flink by default in its EMR cluster. In order
    to get that we have to follow these instructions.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: AWS现在默认支持其EMR集群中的Flink。为了获得这一点，我们必须遵循这些说明。
- en: 'First of all, we have to go to AWS EMR create cluster screen and then click
    on **Go to advanced options link** as heighted in the following screenshot:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须转到AWS EMR创建集群屏幕，然后点击**转到高级选项链接**，如下面的屏幕截图中所示：
- en: '![Flink on EMR 5.3+](img/image_09_016.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![EMR 5.3+上的Flink](img/image_09_016.jpg)'
- en: 'Next you will have a screen which will all you to choose additional services
    you wish to have. There you need to check Flink 1.1.4:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将看到一个屏幕，让您选择您希望拥有的其他服务。在那里，您需要勾选Flink 1.1.4：
- en: '![Flink on EMR 5.3+](img/image_09_017.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![EMR 5.3+上的Flink](img/image_09_017.jpg)'
- en: And then click on the **Next** button to continue the rest of the setup. The
    remaining steps would be same as we saw in the previous sections. Once the cluster
    is up and running, you are all set to use Flink directly.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 然后点击**下一步**按钮，继续进行其余的设置。其余步骤与我们在前几节中看到的相同。一旦集群启动并运行，您就可以直接使用Flink。
- en: Using S3 in Flink applications
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Flink应用程序中使用S3
- en: '**Amazon Simple Storage Service** (**S3**) is a Software-as-a-Service provided
    by AWS to store in the AWS Cloud. Many companies use S3 for cheap data storage.
    It is a hosted filesystem as a service. S3 can be used as alternative to the HDFS.
    One can think of using S3 over HDFS if he/she does not want to invest in complete
    Hadoop cluster. Flink provides you API to allow reading data stored on S3.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**亚马逊简单存储服务**（**S3**）是AWS提供的一种软件即服务，用于在AWS云中存储数据。许多公司使用S3进行廉价的数据存储。它是作为服务的托管文件系统。S3可以用作HDFS的替代方案。如果某人不想投资于完整的Hadoop集群，可以考虑使用S3而不是HDFS。Flink为您提供API，允许读取存储在S3上的数据。'
- en: 'We can use S3 objects like simple files. The following code snippet shows how
    to use S3 object in Flink:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像简单文件一样使用S3对象。以下代码片段显示了如何在Flink中使用S3对象：
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: S3 is treated like any other filesystem by Flink. It uses S3 client for Hadoop.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Flink将S3视为任何其他文件系统。它使用Hadoop的S3客户端。
- en: To access S3 objects, Flink needs authentication. This can be provided by using
    AWS IAM service. This method helps maintaining the security as we don't need to
    distribute the access and secret keys.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问S3对象，Flink需要进行身份验证。这可以通过使用AWS IAM服务来提供。这种方法有助于保持安全性，因为我们不需要分发访问密钥和秘密密钥。
- en: Summary
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learnt how we can deploy Flink on AWS and GCP. This is very
    handy for faster deployments and installations. We can spawn and delete Flink
    cluster with minimum efforts.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何在AWS和GCP上部署Flink。这对于更快的部署和安装非常方便。我们可以用最少的工作量生成和删除Flink集群。
- en: In the next chapter, we are going to learn about the best practice one should
    follow in order to efficiently use Flink.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何有效地使用Flink的最佳实践。
