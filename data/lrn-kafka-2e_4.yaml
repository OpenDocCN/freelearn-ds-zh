- en: Chapter 4. Writing Producers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章。编写生产者
- en: Producers are applications that create messages and publish them to the Kafka
    broker for further consumption. These producers can be different in nature; for
    example, frontend applications, backend services, proxy applications, adapters
    to legacy systems, and producers for Hadoop. These producers can also be implemented
    in different languages such as Java, C, and Python.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者是创建消息并将其发布到Kafka代理以供进一步消费的应用程序。这些生产者可以是不同的性质；例如，前端应用程序、后端服务、代理应用程序、适配器到传统系统以及用于Hadoop的生产者。这些生产者也可以用不同的语言实现，比如Java、C和Python。
- en: 'In this chapter, we will be focusing on the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注以下主题：
- en: The Kafka API for message producers
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息生产者的Kafka API
- en: Java-based Kafka producers
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于Java的Kafka生产者
- en: Java-based producers using custom message partitioning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自定义消息分区的基于Java的生产者
- en: At the end of the chapter, we will also explore a few important configurations
    required for the Kafka producer.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后，我们还将探讨Kafka生产者所需的一些重要配置。
- en: 'Let''s begin. The following diagram explains the high-level working of Kafka
    producers in producing the messages:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始。以下图解释了Kafka生产者在生成消息时的高级工作原理：
- en: '![Writing Producers](img/3090OS_04_01.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![编写生产者](img/3090OS_04_01.jpg)'
- en: The producer connects to any of the alive nodes and requests metadata about
    the leaders for the partitions of a topic. This allows the producer to put the
    message directly to the lead broker for the partition.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者连接到任何存活的节点，并请求有关主题分区的领导者的元数据。这允许生产者直接将消息放到分区的领导代理中。
- en: The Kafka producer API exposes the interface for semantic partitioning by allowing
    the producer to specify a key to partition by and using this to hash to a partition.
    Thus, the producer can completely control which partition it publishes messages
    to; for example, if customer ID is selected as a key, then all data for a given
    customer will be sent to the same partition. This also allows data consumers to
    make locality assumptions about customer data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka生产者API通过允许生产者指定一个键进行语义分区来公开接口，并使用此键进行哈希分区。因此，生产者可以完全控制将消息发布到哪个分区；例如，如果选择客户ID作为键，则给定客户的所有数据将被发送到同一个分区。这也允许数据消费者对客户数据进行局部性假设。
- en: For high efficiency in Kafka, producers can also publish the messages in batches
    that work in asynchronous mode only. In asynchronous mode, the producer works
    either with a fixed number of messages or fixed latency defined by producer configuration,
    `queue.time` or `batch.size`, respectively for example, 10 seconds or 50 messages.
    Data is accumulated in memory at the producer's end and published in batches in
    a single request. Asynchronous mode also brings the risk of losing the data in
    the case of a producer crash with accumulated non-published, in-memory data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在Kafka中实现高效，生产者还可以以批处理方式发布消息，只能在异步模式下工作。在异步模式下，生产者可以使用生产者配置中定义的固定消息数量或固定延迟（例如10秒或50条消息）工作。数据在生产者端在内存中累积，并以批处理方式在单个请求中发布。异步模式还会带来风险，即在生产者崩溃时会丢失未发布的内存中的数据。
- en: Note
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For asynchronous producers, callback method functionality is proposed for future
    release; this would be used for registering handlers to catch sent errors.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于异步生产者，提议将回调方法功能用于将来的发布；这将用于注册处理程序以捕获发送的错误。
- en: In the next few sections, we will discuss the API provided by Kafka for writing
    Java-based custom producers.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将讨论Kafka为编写基于Java的自定义生产者提供的API。
- en: The Java producer API
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java生产者API
- en: 'Let us first understand the important classes that are imported to write Java-based
    basic producers for a Kafka cluster:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先了解导入的重要类，以便为Kafka集群编写基本的基于Java的生产者：
- en: '`Producer`: Kafka provides the `kafka.javaapi.producer.Producer` class (`class
    Producer<K, V>`) for creating messages for single or multiple topics with message
    partition as an optional feature. The default message partitioner is based on
    the hash of the key. Here, `Producer` is a type of Java generic ([http://en.wikipedia.org/wiki/Generics_in_Java](http://en.wikipedia.org/wiki/Generics_in_Java))
    written in Scala where we need to specify the type of parameters; `K` and `V`
    specify the types for the partition key and message value, respectively. The following
    is the class diagram and its explanation:![The Java producer API](img/3090OS_04_02.jpg)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Producer`：Kafka提供了`kafka.javaapi.producer.Producer`类（`class Producer<K, V>`）用于为单个或多个主题创建消息，消息分区是一个可选功能。默认的消息分区器是基于键的哈希值。在这里，`Producer`是一种在Scala中编写的Java泛型（[http://en.wikipedia.org/wiki/Generics_in_Java](http://en.wikipedia.org/wiki/Generics_in_Java)），我们需要指定参数的类型；`K`和`V`分别指定分区键和消息值的类型。以下是类图及其解释：![Java生产者API](img/3090OS_04_02.jpg)'
- en: '`KeyedMessage`: The `kafka.producer.KeyedMessage` class takes the topic name,
    partition key, and the message value that need to be passed from the producer
    as follows:'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`KeyedMessage`：`kafka.producer.KeyedMessage`类接受需要从生产者传递的主题名称、分区键和消息值。'
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, `KeyedMessage` is a type of Java generic written in Scala where we need
    to specify the type of the parameters; `K` and `V` specify the type for the partition
    key and message value, respectively, and the topic is always of type `String`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`KeyedMessage`是一种在Scala中编写的Java泛型，我们需要指定参数的类型；`K`和`V`分别指定分区键和消息值的类型，而主题始终是`String`类型。
- en: '`ProducerConfig`: The `kafka.producer.ProducerConfig` class encapsulates the
    values required for establishing the connection with the brokers such as the broker
    list, message partition class, serializer class for the message, and partition
    key.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProducerConfig`：`kafka.producer.ProducerConfig`类封装了与代理建立连接所需的值，例如代理列表、消息分区类、消息的序列化器类和分区键。'
- en: The Producer API wraps the low-level producer implementations for synchronous
    (default behavior) and asynchronous producers that are picked up based on the
    producer configuration `producer.type`. For example, in the case of asynchronous
    producers the `kafka.producer.Producer` class handles the buffering of the producer's
    data before the data is serialized and dispatched to the appropriate Kafka broker
    partition. Internally, the `kafka.producer.async.ProducerSendThread` instance
    dequeues the batch of messages and `kafka.producer.EventHandler` serializes and
    dispatches the data. The Kafka producer configuration `event.handler` also provides
    the ability to define custom event handlers.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者API包装了同步（默认行为）和异步生产者的低级生产者实现，这些实现是基于生产者配置`producer.type`选择的。例如，在异步生产者的情况下，`kafka.producer.Producer`类处理生产者数据的缓冲，然后将数据序列化并分派到适当的Kafka经纪人分区。在内部，`kafka.producer.async.ProducerSendThread`实例出列消息批次，`kafka.producer.EventHandler`序列化并分派数据。Kafka生产者配置`event.handler`还提供了定义自定义事件处理程序的能力。
- en: Note
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: All the examples are developed and tested for a multi-broker cluster (either
    single or multiple nodes). For more information on how to set up a single node
    - multi-broker cluster, refer to [Chapter 2](ch02.html "Chapter 2. Setting Up
    a Kafka Cluster"), *Setting Up a Kafka Cluster*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 所有示例都是为多经纪人集群（单个或多个节点）开发和测试的。有关如何设置单节点 - 多经纪人集群的更多信息，请参阅[第2章](ch02.html "第2章。设置Kafka集群")，“设置Kafka集群”。
- en: Simple Java producers
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单的Java生产者
- en: Now we will start writing a simple Java-based producer to transmit the message
    to the broker. This `SimpleProducer` class is used to create a message for a specific
    topic and transmit it using the default message partitioning.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将开始编写一个简单的基于Java的生产者，将消息传输到经纪人。这个`SimpleProducer`类用于为特定主题创建消息，并使用默认的消息分区传输它。
- en: Importing classes
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入类
- en: 'As the first step, we need to import the following classes:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们需要导入以下类：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Defining properties
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义属性
- en: 'As the next step in writing the producer, we need to define properties for
    making a connection with the Kafka broker and pass these properties to the Kafka
    producer:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写生产者的下一步中，我们需要定义用于与Kafka经纪人建立连接的属性，并将这些属性传递给Kafka生产者：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now let us see the major properties mentioned in the code:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看代码中提到的主要属性：
- en: '`metadata.broker.list`: This property specifies the list of brokers (in the
    `[<node:port>, <node:port>]` format) that the producer needs to connect to. Kafka
    producers automatically determine the lead broker for the topic, partition it
    by raising a request for the metadata, and connect to the correct broker before
    it publishes any message.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata.broker.list`：此属性指定生产者需要连接的经纪人列表（以`[<node:port>, <node:port>]`格式）。Kafka生产者会自动确定主题的主要经纪人，通过提出元数据请求对其进行分区，并在发布任何消息之前连接到正确的经纪人。'
- en: '`serializer.class`: This property specifies the `serializer` class that needs
    to be used while preparing the message for transmission from the producer to the
    broker. In this example, we will be using the string encoder provided by Kafka.
    By default, the `serializer` class for the key and message is the same, but we
    can also implement the custom `serializer` class by extending the Scala-based
    `kafka.serializer.Encoder` implementation. Producer configuration `key.serializer.class`
    is used to set the custom encoder.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`serializer.class`：此属性指定在从生产者到经纪人传输消息时需要使用的`serializer`类。在本例中，我们将使用Kafka提供的字符串编码器。默认情况下，密钥和消息的`serializer`类相同，但我们也可以通过扩展基于Scala的`kafka.serializer.Encoder`实现来实现自定义`serializer`类。生产者配置`key.serializer.class`用于设置自定义编码器。'
- en: '`request.required.acks`: This property instructs the Kafka broker to send an
    acknowledgment to the producer when a message is received. The value `1` means
    the producer receives an acknowledgment once the lead replica has received the
    data. This option provides better durability as the producer waits until the broker
    acknowledges the request as successful. By default, the producer works in the
    "fire and forget" mode and is not informed in the case of message loss.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`request.required.acks`：此属性指示Kafka经纪人在接收到消息时向生产者发送确认。值`1`表示一旦主副本接收到数据，生产者就会收到确认。此选项提供更好的耐久性，因为生产者会等到经纪人确认请求成功。默认情况下，生产者以“发送并忘记”的模式工作，在消息丢失的情况下不会收到通知。'
- en: Building the message and sending it
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建消息并发送
- en: 'As the final step, we need to build the message and send it to the broker as
    shown in the following code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们需要构建消息并将其发送到经纪人，如下所示的代码：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The complete program will look as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的程序如下所示：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Before running this, make sure you have created the topic `kafkatopic` either
    using the API or from the command line, as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行之前，请确保您已经创建了主题`kafkatopic`，可以使用API或命令行创建，如下所示：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Before compiling and running the Java-based Kafka program in the console, make
    sure you download the `slf4j-1.7.7.tar.gz` file from [http://www.slf4j.org/download.html](http://www.slf4j.org/download.html)
    and copy `slf4j-log4j12-1.7.7.jar` contained within `slf4j-1.7.7.tar.gz` to the
    `/opt/kafka_2.9.2-0.8.1.1/libs` directory. Add the `KAFKA_LIB` environment variable
    and also add all the libraries available in `/opt/kafka_2.9.2-0.8.1.1/libs` to
    the classpath using the following commands:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在控制台中编译和运行基于Java的Kafka程序之前，请确保您从[http://www.slf4j.org/download.html](http://www.slf4j.org/download.html)下载`slf4j-1.7.7.tar.gz`文件，并将其中包含的`slf4j-log4j12-1.7.7.jar`复制到`/opt/kafka_2.9.2-0.8.1.1/libs`目录。添加`KAFKA_LIB`环境变量，并使用以下命令将`/opt/kafka_2.9.2-0.8.1.1/libs`中的所有库添加到类路径中：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Compile the preceding program using the following command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令编译上述程序：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Run the simple producer using the following command:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令运行简单的生产者：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `SimpleProducer` class takes two arguments; first, the topic name and second,
    the number of messages to be published. Once the producer is successfully executed
    and begins publishing the messages to the broker, run the command line consumer
    for consuming the messages as it subscribes to the topic created in the Kafka
    broker as:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: “SimpleProducer”类需要两个参数；首先是主题名称，其次是要发布的消息数量。一旦生产者成功执行并开始将消息发布到代理程序，就运行命令行消费者来消费消息，因为它订阅了在Kafka代理程序中创建的主题：
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Creating a Java producer with custom partitioning
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自定义分区创建Java生产者
- en: 'The previous example is a very basic example of a `Producer` class running
    on a single-node, multi-broker cluster with no explicit partitioning of messages.
    Jumping to the next level, let''s write another program that uses customized message
    partitioning. In this example, a log message for a website visit from any IP address
    is captured and published. This log message has three parts:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的示例是一个在单节点、多代理程序集群上运行的基本“Producer”类的非常基本的示例，没有明确对消息进行分区。跳到下一个级别，让我们编写另一个程序，该程序使用自定义消息分区。在这个例子中，捕获并发布了来自任何IP地址的网站访问的日志消息。这条日志消息有三个部分：
- en: The timestamp of the website hit
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网站点击的时间戳
- en: The name of website itself
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网站的名称本身
- en: The IP address from where the website is being accessed
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正在访问网站的IP地址
- en: Let's begin with the coding.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从编码开始。
- en: Importing classes
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入类
- en: 'First import the following classes:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 首先导入以下类：
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Defining properties
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义属性
- en: 'As the next step, we need to define properties for making a connection with
    the Kafka broker, as shown in the following code, and pass these properties to
    the Kafka producer:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 作为下一步，我们需要定义用于与Kafka代理程序建立连接的属性，如下面的代码所示，并将这些属性传递给Kafka生产者：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The only change in the previous property list is the addition of the `partitioner.class`
    configuration.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前的属性列表中唯一的更改是添加了“partitioner.class”配置。
- en: The `partitioner.class` property defines the class to be used for determining
    the partition in the topic where the message needs to be sent. If the key is null,
    Kafka uses the hash value of the key.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: “partitioner.class”属性定义了用于确定消息需要发送到的主题中的分区的类。如果键为空，Kafka将使用键的哈希值。
- en: Implementing the Partitioner class
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现Partitioner类
- en: 'Next, we need to develop a custom partitioner class `SimplePartitioner` by
    implementing the `Partitioner` class (an abstract class written in Scala) that
    takes the key, which in this example is the IP address. It then finds the last
    octet and does a modulo operation on the number of partitions defined within Kafka
    for the topic. The following is the code for the `SimplePartitioner` class:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要通过实现“Partitioner”类（Scala中编写的一个抽象类）来开发自定义分区类“SimplePartitioner”，该类需要接受在本例中是IP地址的键。然后找到最后一个八位并对Kafka为主题定义的分区数量进行模运算。以下是“SimplePartitioner”类的代码：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Building the message and sending it
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建消息并发送
- en: 'As the final step, we need to build the message and send it to the broker.
    The following is the complete listing of the program:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们需要构建消息并将其发送到代理程序。以下是程序的完整列表：
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Before running this, make sure you have created the topic `website-hits` from
    the command line:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行此之前，请确保您已从命令行创建了主题“website-hits”：
- en: '[PRE14]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Also, as specified in the beginning of the previous example, do the classpath
    settings if not already done. Now compile the partitioner class and the preceding
    producer program using the following command:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 还有，如前面的示例中所指定的，如果尚未完成，请进行类路径设置。现在使用以下命令编译分区器类和前面的生产者程序：
- en: '[PRE15]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Run the custom partition producer using the following command:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令运行自定义分区生产者：
- en: '[PRE16]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `CustomPartitionProducer` program takes two arguments; first, the topic
    name and second, the number of log messages to be published. Once the producer
    is successfully executed and begins publishing the messages to the broker, run
    the command line consumer for consuming the messages as it subscribes to the topic
    created in the Kafka broker:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: “CustomPartitionProducer”程序需要两个参数；首先是主题名称，其次是要发布的日志消息数量。一旦生产者成功执行并开始将消息发布到代理程序，就运行命令行消费者来消费消息，因为它订阅了在Kafka代理程序中创建的主题：
- en: '[PRE17]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the preceding example, the benefit of using custom partitioning logic is
    that all the log messages that are generated for the same client IP address will
    end up going to the same partition. Also, the same partition may have batch log
    messages for different IP addresses.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，使用自定义分区逻辑的好处是，为同一客户端IP地址生成的所有日志消息最终都将进入同一个分区。此外，同一个分区可能具有不同IP地址的批量日志消息。
- en: Note
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The partitioning logic also needs to be known to the consumer so that the consumer
    can consume the messages published for the desired IPs. This part is covered in
    [Chapter 5](ch05.html "Chapter 5. Writing Consumers"), *Writing Consumers*.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 分区逻辑也需要为消费者所知，以便消费者可以消费为所需IP地址发布的消息。这部分在[第5章](ch05.html "第5章。编写消费者")*编写消费者*中有所涵盖。
- en: The Kafka producer property list
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kafka生产者属性列表
- en: The following table shows a list of a few important properties that can be configured
    for Kafka producer. The Scala class `kafka.producer.ProducerConfig` provides implementation-level
    details for producer configurations. For the complete list, visit [http://kafka.apache.org/documentation.html#producerconfigs](http://kafka.apache.org/documentation.html#producerconfigs).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了可以为Kafka生产者配置的一些重要属性列表。Scala类“kafka.producer.ProducerConfig”提供了生产者配置的实现级别细节。有关完整列表，请访问[http://kafka.apache.org/documentation.html#producerconfigs](http://kafka.apache.org/documentation.html#producerconfigs)。
- en: '| Property name | Description | Default value |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 属性名称 | 描述 | 默认值 |'
- en: '| --- | --- | --- |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `metadata.broker.list` | The producer uses this property to get metadata
    (topics, partitions, and replicas). The socket connections for sending the actual
    data will be established based on the broker information returned in the metadata.
    The format is `host1:port1,host2:port2`. |   |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `metadata.broker.list` | 生产者使用此属性来获取元数据（主题、分区和副本）。根据元数据返回的代理信息，将建立用于发送实际数据的套接字连接。格式为
    `host1:port1,host2:port2`。 |   |'
- en: '| `serializer.class` | This specifies the `serializer` class for the messages.
    The default encoder accepts a byte and returns the same byte. | `kafka.serializer.DefaultEncoder`
    |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `serializer.class` | 这指定了消息的 `serializer` 类。默认编码器接受一个字节并返回相同的字节。 | `kafka.serializer.DefaultEncoder`
    |'
- en: '| `producer.type` | This property specifies how the messages will be sent:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`producer.type` | 此属性指定消息将如何发送：'
- en: '`async` for asynchronous sending (used with message batching)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`async` 用于异步发送（与消息批处理一起使用）'
- en: '`sync` for synchronous sending'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sync` 用于同步发送'
- en: '| `sync` |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `sync` |'
- en: '| `request.required.acks` | This value controls when the producer request is
    considered complete and whether the producer receives an acknowledgment from the
    broker:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '| `request.required.acks` | 此值控制生产者请求何时被视为完成以及生产者是否从代理接收确认：'
- en: '`0` means the producer will never wait for an acknowledgment from the broker.
    This is used for the lowest latency, but with the weakest durability.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0` 表示生产者永远不会等待来自代理的确认。这用于最低延迟，但耐久性最弱。'
- en: '`1` means the producer receives an acknowledgment once the lead replica has
    received the data. This option provides better durability as the client waits
    until the server acknowledges the request as successful.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1` 表示一旦主副本接收到数据，生产者将收到确认。此选项提供更好的耐久性，因为客户端会等待服务器确认请求成功。'
- en: '`-1` means the producer will receive an acknowledgment once all the in-sync
    replicas have received the data. This option provides the best durability.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-1` 表示一旦所有同步副本接收到数据，生产者将收到确认。此选项提供了最佳的耐久性。'
- en: '| `0` |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `0` |'
- en: '| `key.serializer.class` | This specifies the serializer class for keys. |
    `${serializer.class}` |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `key.serializer.class` | 这指定了键的序列化程序类。 | `${serializer.class}` |'
- en: '| `partitioner.class` | This is the partitioner class for partitioning messages
    among subtopics. The default partitioner is based on the hash value of the key.
    | `kafka.producer.DefaultPartitioner` |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| `partitioner.class` | 这是用于在子主题之间分区消息的分区器类。默认的分区器基于键的哈希值。 | `kafka.producer.DefaultPartitioner`
    |'
- en: '| `compression.codec` | This parameter specifies the compression codec for
    all data generated by this producer. Valid values are `none`, `gzip`, and `snappy`.
    | `none` |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| `compression.codec` | 此参数指定此生产者生成的所有数据的压缩编解码器。有效值为 `none`、`gzip` 和 `snappy`。
    | `none` |'
- en: '| `batch.num.messages` | This specifies the number of messages to be sent in
    one batch when using async mode. The producer will wait until this quantity of
    messages is ready to be sent or `queue.buffer.max.ms` is reached. | `200` |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| `batch.num.messages` | 当使用异步模式时，此属性指定要在一批中发送的消息数量。生产者将等待，直到准备发送此数量的消息或达到
    `queue.buffer.max.ms`。 | `200` |'
- en: Summary
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter we have learned how to write basic producers and some advanced
    Java producers that use message partitioning. We have also covered the details
    of properties for Kafka producers.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何编写基本的生产者和一些使用消息分区的高级Java生产者。我们还介绍了Kafka生产者的属性细节。
- en: In the next chapter, we will learn how to write Java-based consumers for message
    consumption.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何编写基于Java的消费者来消费消息。
