- en: Integrating Data Visualization into the Workflow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据可视化集成到工作流中
- en: We have now come to the concluding chapter of this book. Throughout the course
    of this book, you have mastered the techniques to create and customize static
    and animated plots using real-world data in different formats scraped from the
    web. To wrap up, we will start a mini-project in this chapter to combine the skills
    of data analytics with the visualization techniques you've learned. We will demonstrate
    how to integrate visualization techniques in your current workflow.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在来到了本书的最后一章。在本书的整个过程中，你已经掌握了如何使用来自网络的不同格式的真实世界数据，创建和定制静态与动态图表的技巧。作为总结，我们将在本章开始一个迷你项目，将数据分析技能与您学到的可视化技术结合起来。我们将演示如何将可视化技术整合到当前的工作流中。
- en: In the era of big data, machine learning becomes fundamental to ease analytic
    work by replacing huge amounts of manual curation with automatic prediction. Yet,
    before we enter model building, **Exploratory Data Analysis** (**EDA**) is always
    essential to get a good grasp of what the data is like. Constant review during
    the optimization process also helps improve our training strategy and results.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在大数据时代，机器学习成为简化分析工作的重要工具，通过用自动预测替代大量的手动整理。尽管如此，在我们进入模型构建之前，**探索性数据分析**（**EDA**）始终是获取数据基本情况的关键。优化过程中的不断回顾也有助于改进我们的训练策略和结果。
- en: High-dimensional data typically requires special processing techniques to be
    visualized intuitively. Statistical methods such as **Principle Component Analysis**
    (**PCA**) and **t-Distributed Stochastic Neighbor Embedding** (**t-SNE**) are
    important skills in reducing the dimension of data for effective visualization.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 高维数据通常需要特殊的处理技术才能直观地进行可视化。统计方法，如**主成分分析**（**PCA**）和**t-分布随机邻居嵌入**（**t-SNE**），是将数据降维以便有效可视化的重要技能。
- en: As a showcase, we will demonstrate the use of various visualization techniques
    in a workflow involving recognizing handwritten digits using a **Convolutional
    Neural Network** (**CNN**).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 作为展示，我们将演示在一个涉及使用**卷积神经网络**（**CNN**）识别手写数字的工作流中使用各种可视化技术。
- en: One important note is that we do not intend to illustrate all the mathematics
    and machine learning approaches in detail in this chapter. Our goal is to visualize
    some of the processes in between. Hopefully, readers will appreciate the importance
    of exploring processes such as the `loss` function when training a CNN, or visualizing
    the dimension reduction results with different parameters.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的注意点是，我们并不打算在本章详细说明所有的数学和机器学习方法。我们的目标是可视化其中的一些过程。希望读者能意识到探索如`损失`函数在训练CNN时的作用，或使用不同参数可视化降维结果等过程的重要性。
- en: Getting started
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始
- en: Recall the MNIST dataset we briefly touched upon in [Chapter 04](456b0dc2-84d5-40f9-bf63-1ab4635cbac8.xhtml), *Advanced
    Matplotlib*. It contains 70,000 images of handwritten digits, often used in data
    mining tutorials as *Machine Learning 101*. We will continue using a similar image
    dataset of handwritten digits for our project in this chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾我们在[第04章](456b0dc2-84d5-40f9-bf63-1ab4635cbac8.xhtml)《高级 Matplotlib》中简要提到的MNIST数据集。它包含了70,000张手写数字的图像，通常用于数据挖掘教程中作为*机器学习基础*。在本章的项目中，我们将继续使用类似的手写数字图像数据集。
- en: We are almost certain that you had already heard about the popular keywords—deep
    learning or machine learning in general—before starting with this course. That's
    why we are choosing it as our showcase. As detailed concepts in machine learning,
    such as **hyperparameter tuning** to optimize performance, are beyond the scope
    of this book, we will not go into them. But we will cover the model training part
    in a cookbook style. We will focus on how visualization helps our workflow. For
    those of you interested in the details of machine learning, we recommend exploring
    further resources that are largely available online.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎可以确定，在开始本课程之前，你已经听说过一些热门关键词——深度学习或机器学习。正因为如此，我们将它作为展示案例。由于机器学习中的一些详细概念，如**超参数调优**来优化性能，超出了本书的范围，我们不会深入探讨。但是，我们将以食谱式的方式讲解模型训练部分。我们将重点讲解可视化如何帮助我们的工作流。对于那些对机器学习细节感兴趣的读者，我们建议进一步探索大量在线资源。
- en: Visualizing sample images from the dataset
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化数据集中的样本图像
- en: Data cleaning and EDA are indispensable components of data science. Before we
    begin analyzing our data, it is important to understand some basic properties
    of what we have input. The dataset we are using comprises standardized images
    with regular shapes and normalized pixel values. The features are simple, thin
    lines. Our goal is straightforward as well, to recognize digits from images. Yet,
    in many cases of real-world practice, the problems can be more complicated; the
    data we collect is going to be raw and often much more heterogeneous. Before tackling
    the problem, it is usually worth the time to sample a small amount of input data
    for inspection. Imagine training a model to recognize Ramen just to get you drooling
    ;). You will probably take a look at some images to decide what features make
    a good input sample to exemplify the presence of the bowl. Besides the initial
    preparatory phase, during model building taking out some of the mislabeled samples
    to examine may also help us devise strategies for optimization.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清洗和探索性数据分析（EDA）是数据科学中不可或缺的组成部分。在我们开始分析数据之前，理解输入数据的一些基本特性是很重要的。我们使用的数据集包含标准化的图像，形状规则且像素值已归一化。特征简单，主要是细线条。我们的目标也很直接，就是从图像中识别数字。然而，在许多实际应用的案例中，问题可能更复杂；我们收集的数据往往是原始的，且异质性较强。在解决问题之前，通常值得花时间抽取少量数据进行检查。试想训练一个模型来识别拉面，只是为了让你垂涎三尺；）。你可能会查看一些图像，以决定哪些特征可以作为一个好的输入样本，来展示碗的存在。除了初步的准备阶段，在模型构建过程中，剔除一些标签错误的样本进行检查，也有助于我们制定优化策略。
- en: In case you wonder where the Ramen idea comes from, a data scientist named Kenji
    Doi created a model to recognize in which restaurant branch a bowl of Ramen was made.
    You may read more on the Google Cloud Big Data and Machine Learning Blog post
    on [https://cloud.google.com/blog/big-data/2018/03/automl-vision-in-action-from-ramen-to-branded-goods](https://cloud.google.com/blog/big-data/2018/03/automl-vision-in-action-from-ramen-to-branded-goods).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道拉面这个想法是从哪里来的，一个名为Kenji Doi的数据科学家创建了一个模型，用来识别一碗拉面是在哪家餐厅分店制作的。你可以在Google
    Cloud大数据与机器学习博客中阅读更多内容，链接在此：[https://cloud.google.com/blog/big-data/2018/03/automl-vision-in-action-from-ramen-to-branded-goods](https://cloud.google.com/blog/big-data/2018/03/automl-vision-in-action-from-ramen-to-branded-goods)。
- en: Importing the UCI ML handwritten digits dataset
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入UCI ML手写数字数据集
- en: While we will be using the MNIST dataset as in [Chapter 04](https://cdp.packtpub.com/matplotlib_for_python_developers__second_edition/wp-admin/post.php?post=338&action=edit#post_73), *Advanced
    Matplotlib* (since we will be demonstrating visualization along with model building
    in machine learning), we will take a shortcut to speed up the training process.
    Instead of using the 60,000 images with 28x28 pixels each, we will import another
    similar dataset of 8x8-pixel images from the scikit-learn package.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们将使用MNIST数据集，正如在[第04章](https://cdp.packtpub.com/matplotlib_for_python_developers__second_edition/wp-admin/post.php?post=338&action=edit#post_73)中所示的*高级Matplotlib*（因为我们将展示机器学习中的可视化和模型构建），但是我们将采取捷径以加速训练过程。我们不会使用包含60,000张28x28像素图像的MNIST数据集，而是从scikit-learn包中导入另一个类似的8x8像素图像数据集。
- en: This dataset is obtained from the University of California, Irvine Machine Learning
    Repository, found at [http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits](http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits).
    It is a preprocessed version of images of digits written by 43 people, with 30
    and 13 contributing to the training and testing set respectively. The preprocessing
    method is described in M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick,
    J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based Handprint
    Recognition System, NISTIR 5469, 1994.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集来自加利福尼亚大学欧文分校机器学习资源库，地址为[http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits](http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits)。它是43个人手写数字图像的预处理版本，其中30人用于训练集，13人用于测试集。预处理方法在M.
    D. Garris、J. L. Blue、G. T. Candela、D. L. Dimmick、J. Geist、P. J. Grother、S. A.
    Janet和C. L. Wilson的论文《NIST表单式手写识别系统》，NISTIR 5469，1994中有详细描述。
- en: 'The code to import the dataset is as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 导入数据集的代码如下：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To begin, let''s store our dataset into a variable. We will call it `digits`
    and reuse it throughout the chapter:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们将数据集存储到一个变量中。我们将其命名为`digits`，并在本章中多次使用它：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s see what is loaded by the `load_digits()` function by printing out the
    variable `digits`:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过打印出变量`digits`来查看`load_digits()`函数加载了什么内容：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The type of `digits` is `<class 'sklearn.utils.Bunch'>`, which is specific to
    loading sample dataset.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`digits` 的类型是 `<class ''sklearn.utils.Bunch''>`，这是专门用于加载示例数据集的。'
- en: 'As the output for `print(digits)` is somewhat long, we will show its beginning
    and end in two screenshots:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `print(digits)` 的输出比较长，我们将在两张截图中展示它的开头和结尾：
- en: '![](img/913f538a-09d1-4fb8-99c3-78856b08da5a.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/913f538a-09d1-4fb8-99c3-78856b08da5a.png)'
- en: 'The following screenshot shows the tail of the output:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了输出的尾部：
- en: '![](img/60f31ffd-78ae-406b-837e-c8148acb223c.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/60f31ffd-78ae-406b-837e-c8148acb223c.png)'
- en: 'We can see that there are five members within the class `digits`:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，`digits` 类中有五个成员：
- en: '`''data''`: Pixel values flattened into 1D NumPy arrays'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''data''`：像素值压平为一维 NumPy 数组'
- en: '`''target''`: A NumPy array of identity labels of each element in the dataset'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''target''`：数据集中每个元素的身份标签的 NumPy 数组'
- en: '`''target_names''`: A list of unique labels existing in the dataset—integers
    0-9 in this case'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''target_names''`：数据集中存在的唯一标签的列表—在这里是整数 0-9'
- en: '`''images''`: Pixel values reshaped into 2D NumPy arrays in the dimension of
    images'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''images''`：像素值重新排列成二维 NumPy 数组，表示图像的维度'
- en: '`''DESCR''`: Description of the dataset'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''DESCR''`：数据集的描述'
- en: 'Besides having smaller image dimensions than MNIST, this dataset also has far
    fewer images. So, how many are there in total? We get the dimensions of a NumPy
    array in a tuple of dimensions by `nd.shape`, where `nd` is the array. Hence,
    to inquire about the shape of `digits.image`, we call:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 除了图像尺寸比 MNIST 更小外，这个数据集的图像数量也少得多。那么，究竟有多少张图像呢？我们可以通过 `nd.shape` 获取 NumPy 数组的维度元组，其中
    `nd` 是数组。因此，要查询 `digits.image` 的形状，我们调用：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We get `(1797, 8, 8)` as result.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的结果是 `(1797, 8, 8)`。
- en: You may wonder why the number is so peculiar. If you have particularly sharp
    eyes, you might have seen that there are 5,620 instances in the description. In
    fact, the description is retrieved from the archive web page. The data we have
    loaded is actually the testing portion of the full dataset. You may also download
    the plain text equivalent from [http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes](http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，为什么这个数字如此特别。如果你眼尖的话，可能已经注意到描述中有 5,620 个实例。事实上，这些描述是从归档网页中检索到的。我们加载的数据实际上是完整数据集中的测试部分。你也可以从
    [http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes](http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes)
    下载其纯文本版本。
- en: 'If you are interested in getting the full MNIST dataset, scikit-learn also
    offers an API to fetch it:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣获取完整的 MNIST 数据集，scikit-learn 也提供了一个 API 来获取它：
- en: '`from sklearn.datasets import fetch_mldata mnist = fetch_mldata(''MNIST original'',
    data_home=custom_data_home)`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`from sklearn.datasets import fetch_mldata mnist = fetch_mldata(''MNIST original'',
    data_home=custom_data_home)`'
- en: Plotting sample images
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制样本图像
- en: Now that we know more about the background of our input data, let's plot out
    some sample images.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们更了解输入数据的背景了，让我们绘制一些样本图像。
- en: Extracting one sample each of digits 0-9
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取每个数字 0-9 的一个样本
- en: 'To get a feel for what the images look like, we want to extract one image of
    each digit for inspection. For this, we need to find out where the digits are.
    We can do so by tracking down the right indices (the data labels) with `digits.target` then
    we write a few lines of code to call `10` images:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解图像的样子，我们希望提取每个数字的一个图像进行检查。为此，我们需要找出数字的位置。我们可以通过跟踪正确的索引（即数据标签）来完成这一任务，使用
    `digits.target`，然后写几行代码来调用 `10` 张图像：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Interestingly, `[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]` is returned as output, which
    means the first `10` samples happen to be in numerical order. Is it by chance
    or is the data ordered? We need to check as the sample distribution can impact
    our training performance.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，`[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]` 被作为输出返回，这意味着前 `10` 个样本恰好按数字顺序排列。这是偶然发生的，还是数据是有序的？我们需要检查，因为样本分布可能会影响我们的训练表现。
- en: Examining the randomness of the dataset
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查数据集的随机性
- en: 'Because showing all 1,797 data points will make the plot too dense for any
    meaningful interpretation, we will plot the first `200` data points to check:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 由于显示所有 1,797 个数据点会使得图像过于密集，无法进行有意义的解释，我们将绘制前 `200` 个数据点来检查：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here we get a scatter plot of the sample distribution. Not quite random, is
    it? The 0-9 digits are ordered and repeated three times. We also see a repetition
    of patterns from around the *125^(th)* sample. The structure of the data hints
    at randomization before our training of machine learning model later. For now,
    we will first take it as-is and continue with our image inspection:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们得到了一张样本分布的散点图。看起来并不完全随机，对吧？数字0到9按顺序排列并重复了三次。我们还可以看到从*第125个*样本开始，模式有了重复。数据的结构暗示着在后续机器学习模型训练之前可能进行了随机化处理。现在，我们将按原样继续，继续检查这些图像：
- en: '![](img/276c26f9-b086-4787-b2b8-ea51b1116162.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/276c26f9-b086-4787-b2b8-ea51b1116162.png)'
- en: Plotting the 10 digits in subplots
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在子图中绘制10个数字
- en: 'We will align the images in a grid of two rows and five columns. We first set
    the rectangular canvas by `plt.figure()`. For each sample image of a digit, we
    define the axes with the `plt.subplot()` function, and then call `imshow()` to
    show the arrays of color values as images. Recall that the colormap `''gray_r''`
    plots values in grayscale from white to black with values from zero to maximum.
    As there is no need for *x* and *y* tick labels to show the scales, we will remove
    them by passing an empty list to `plt.xticks()` and `plt.yticks()` to remove the
    clutter. Here is the code snippet to do so:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将图像排列在一个两行五列的网格中。首先通过`plt.figure()`设置矩形画布。对于每个数字的样本图像，我们通过`plt.subplot()`函数定义坐标轴，然后调用`imshow()`显示颜色值数组作为图像。回想一下，颜色映射`'gray_r'`会将值从零到最大值以灰度形式从白色到黑色进行绘制。由于不需要显示*x*和*y*的刻度标签，我们将通过传递一个空列表给`plt.xticks()`和`plt.yticks()`来移除这些多余的内容。以下是实现这一操作的代码片段：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As you can see from the following figure, the images are a bit blurry to human
    eyes. But, believe it or not, there are enough details for the algorithm to extract
    features and differentiate between each digit. We will observe this together along
    with our workflow:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示，图像对人眼来说有些模糊。但信不信由你，算法足够提取出特征并区分每个数字。我们将在我们的工作流程中一起观察这一点：
- en: '![](img/d98d2ebf-0141-4136-b077-9844f371e7b9.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d98d2ebf-0141-4136-b077-9844f371e7b9.png)'
- en: Exploring the data nature by the t-SNE method
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用t-SNE方法探索数据的性质
- en: After visualizing a few images and glimpsing of how the samples are distributed,
    we will go deeper into our EDA.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在可视化了几个图像并略微了解样本的分布后，我们将深入进行数据探索分析（EDA）。
- en: Each pixel comes with an intensity value, which makes 64 variables for each
    8x8 image. The human brain is not good at intuitively perceiving dimensions higher
    than three. For high-dimensional data, we need more effective visual aids.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 每个像素都有一个强度值，这样每个8x8的图像就有64个变量。人类大脑不擅长直观感知超过三维的空间。对于高维数据，我们需要更有效的视觉辅助工具。
- en: Dimensionality reduction methods, such as the commonly used PCA and t-SNE, reduce
    the number of input variables under consideration, while retaining most of the
    useful information. As a result, the visualization of data becomes more intuitive.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 降维方法，例如常用的PCA和t-SNE，通过减少考虑的输入变量的数量，同时保留大部分有用的信息，从而使数据的可视化变得更加直观。
- en: In the following section, we will focus our discussion on the t-SNE method by
    using the scikit-learn library in Python.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将重点讨论使用Python中的scikit-learn库进行t-SNE方法的应用。
- en: Understanding t-Distributed stochastic neighbor embedding
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解t-分布随机邻域嵌入
- en: The t-SNE method was proposed by van der Maaten and Hinton in 2008 in the publication
    *Visualizing Data using t-SNE*. It is a nonlinear dimension reduction method that
    aims to effectively visualize high-dimensional data. t-SNE is based on probability
    distributions with random walk on neighborhood graphs to find the structure within
    the data. The mathematical details of t-SNE are beyond the scope of this book,
    and readers are advised to read the paper for more details.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: t-SNE方法由van der Maaten和Hinton于2008年在论文《使用t-SNE可视化数据》中提出。它是一种非线性降维方法，旨在有效地可视化高维数据。t-SNE基于概率分布，通过在邻域图上进行随机游走来发掘数据中的结构。t-SNE的数学细节超出了本书的范围，建议读者阅读原论文以了解更多细节。
- en: In short, t-SNE is a way to capture non-linear relationships in a high-dimensional
    data. This is particularly useful when we are trying to extract features from
    a high-dimensional matrix such as image processing, biological data, and network
    information. It enables us to reduce high-dimensional data to two or three dimensions;
    one interesting feature of t-SNE is that it is stochastic, indicating that the
    final results it shows each time will be different, but still they are all equally
    correct. Therefore, in order to get the best performance in t-SNE dimension reduction,
    it is advisable to first perform PCA dimension reduction on the big dataset, and
    then incorporate the PCA dimensions into t-SNE for subsequent dimension reduction.
    Thus, you get more consistent and replicable results.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，t-SNE是一种捕捉高维数据中非线性关系的方法。当我们试图从高维矩阵中提取特征时，例如图像处理、生物数据和网络信息，它特别有用。它使我们能够将高维数据降维到二维或三维；t-SNE的一个有趣特点是它是随机的，这意味着它每次显示的最终结果都会不同，但它们都是同样正确的。因此，为了在t-SNE降维中获得最佳表现，建议先对大数据集执行PCA降维，然后将PCA维度引入t-SNE进行后续降维。这样，你会得到更一致且可复制的结果。
- en: Importing the t-SNE method from scikit-learn
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从scikit-learn导入t-SNE方法
- en: 'We will implement the t-SNE method by loading the `TSNE` function from scikit-learn,
    as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过加载scikit-learn中的`TSNE`函数来实现t-SNE方法，如下所示：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'There are a few hypervariables that the user has to set upon running t-SNE,
    which include:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 用户在运行t-SNE时需要设置一些超参数，包括：
- en: '`''init''` : Initialization of embedding'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''init''`：嵌入初始化'
- en: '`''method''`: `barnes_hut` or exact'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''method''`：`barnes_hut`或精确方法'
- en: '`''perplexity''`: Default `30`'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''perplexity''`：默认值`30`'
- en: '`''n_iter''`: Default `1000`'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''n_iter''`：默认值`1000`'
- en: '`''n_components''`: Default `2`'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''n_components''`：默认值`2`'
- en: Going into the mathematical details of individual hypervariables would be a
    chapter on its own, but we do have suggestions on what the parameters should be
    in general. For `init`, it is recommended to use `'pca'` with the reason given
    before. For method, `barnes_hut` will be faster and gives very similar results
    if the provided dataset is not highly similar intrinsically. For perplexity, it
    reflects on the focus in teasing out local and global substructures of the data.
    `n_iter` indicates the number of iterations that you will run through the algorithm,
    and `n_components = 2` indicates that the final outcome is a two-dimensional space.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 进入单个超参数的数学细节会是一个单独的章节，但我们确实有一些关于参数设置的一般建议。对于`init`，推荐使用`'pca'`，原因之前已说明。对于方法，`barnes_hut`会更快，并且如果提供的数据集本身没有高度相似性，结果非常相似。对于困惑度，它反映了对数据局部和全局子结构的关注。`n_iter`表示你将运行算法的迭代次数，而`n_components
    = 2`表示最终的结果是二维空间。
- en: To track the time use for rounds of experiments, we can use the cell magic `%%timeit`
    in the Jupyter notebook to track the time needed for a cell to run.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了追踪实验轮次的时间，我们可以在Jupyter Notebook中使用单元魔法`%%timeit`来跟踪单元运行所需的时间。
- en: Drawing a t-SNE plot for our data
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制t-SNE图来展示我们的数据
- en: 'Let''s first reorder the data points according to the handwritten numbers:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先按手写数字的顺序重新排列数据点：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`y` will become `array([0, 0, 0, ..., 9, 9, 9])`.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`y`将变成`array([0, 0, 0, ..., 9, 9, 9])`。'
- en: 'Note that the t-SNE transformation can take minutes to compute on a regular
    laptop, and the `tSNE` command can be simply run as follows. We will first try
    running t-SNE with `250` iterations:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，t-SNE变换在普通笔记本电脑上可能需要几分钟的计算时间，`tSNE`命令可以像下面这样简单地运行。我们首先尝试使用`250`次迭代来运行t-SNE：
- en: '[PRE9]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s draw a scatter plot to see how the data cluster:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制一个散点图，看看数据是如何聚集的：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can see that the clusters are not well separated at `250` iterations:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在`250`次迭代后，聚类并没有很好地分开：
- en: '![](img/0d7d2b79-8a06-4de2-b6ac-6eb559ade1c1.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0d7d2b79-8a06-4de2-b6ac-6eb559ade1c1.png)'
- en: 'Let''s now try running with `2000` iterations:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试使用`2000`次迭代来运行：
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As seen from the following screenshot, the samples appear as `10` distinct
    blots of clusters. By running `2000` iterations, we have obtained far more satisfying
    results:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如下截图所示，样本呈现为`10`个不同的聚类斑点。通过运行`2000`次迭代，我们得到了更加满意的结果：
- en: '![](img/d5ae44f2-a6cf-4e9f-ad15-0c5598b077d7.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d5ae44f2-a6cf-4e9f-ad15-0c5598b077d7.png)'
- en: Creating a CNN to recognize digits
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个CNN来识别数字
- en: In the following section, we will use Keras. Keras is a Python library for neural
    networks and provides a high-level interface to TensorFlow libraries. We do not
    intend to give a complete tutorial on Keras or CNN, but we want to show how we
    can use Matplotlib to visualize the `loss` function, `accuracy`, and outliers
    of the results.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将使用 Keras。Keras 是一个用于神经网络的 Python 库，提供了一个高级接口来调用 TensorFlow 库。我们不打算对
    Keras 或 CNN 进行完整的教程讲解，但我们希望展示如何使用 Matplotlib 可视化`损失`函数、`准确率`以及结果中的异常值。
- en: Readers who are not familiar with machine learning should be able to go through
    the logic of the remaining chapter and hopefully understand why visualizing the
    `loss` function, `accuracy`, and outliers of the results is important in fine-tuning
    the CNN model.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不熟悉机器学习的读者，他们应该能够理解剩余章节的逻辑，并希望能够理解为什么可视化`损失`函数、`准确率`和结果中的异常值对于微调 CNN 模型非常重要。
- en: Here is a snippet of code for the CNN; the most important part is the evaluation
    section after this!
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是 CNN 代码的一段，最重要的部分是在这一部分之后的评估环节！
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Evaluating prediction results with visualizations
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用可视化评估预测结果
- en: 'We have specified the callbacks that store the loss and accuracy information
    for each epoch to be saved as the variable `history`. We can retrieve this data
    from the dictionary `history.history`. Let''s check out the dictionary `keys`:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经指定了回调函数，保存每个训练轮次的损失和准确率信息，作为变量`history`进行保存。我们可以从字典`history.history`中提取这些数据。让我们查看一下字典的`keys`：
- en: '[PRE13]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This will output `dict_keys(['loss', 'acc'])`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出`dict_keys(['loss', 'acc'])`。
- en: 'Next, we will plot out the `loss` function and `accuracy` along epochs in line
    graphs:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在折线图中绘制`损失`函数和`准确率`随训练轮次变化的情况：
- en: '[PRE14]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Upon training, we can say the `loss` function is decreasing, accompanied by
    an increase in accuracy, which is something we are delighted to see. Here is the
    first graph showing the `loss` function:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们可以看到`损失`函数正在减少，准确率也在增加，这是我们很高兴看到的现象。以下是展示`损失`函数的第一张图：
- en: '![](img/9f14a248-9cf2-47c6-ae6f-b4077351bcbb.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9f14a248-9cf2-47c6-ae6f-b4077351bcbb.png)'
- en: 'The next graph shows the changes in **Accuracy** across **Epoch**:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 下一张图展示了**准确率**在**训练轮次**中的变化：
- en: '![](img/65bc06af-bb45-435a-a020-0dfaca639b24.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/65bc06af-bb45-435a-a020-0dfaca639b24.png)'
- en: From these screenshots, we can observe a general trend for decreasing loss and
    increasing accuracy with each epoch along the training process, with alternating
    ups and downs. We can observe whether the final accuracy or the learning rate
    is desirable and optimize the model where necessary.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些截图中，我们可以观察到随着每个训练轮次的进行，损失逐渐减少，准确率逐渐增加，期间有时会上下波动。我们可以观察到最终的准确率是否令人满意，学习率是否合适，并在必要时优化模型。
- en: Examining the prediction performance for each digit
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查每个数字的预测性能
- en: 'We first revert the labels from one-hot format back to lists of integers:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将标签从 one-hot 格式还原为整数列表：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We will extract the indices of mislabeled images, and use them to retrieve
    the corresponding true and predicted labels:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将提取错误标记图像的索引，并用它们来获取相应的真实标签和预测标签：
- en: '[PRE16]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output is as follows, with NumPy arrays of the indices, true and predicted
    labels of the array of mislabeled images:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下，包含了错误标记图像的索引、真实标签和预测标签的 NumPy 数组：
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let''s count how many samples are mislabeled for each digit. We will store
    the counts into a list:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们统计每个数字被错误标记的样本数量。我们将把计数结果存储到一个列表中：
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, we will plot a bar chart of the ratio of mislabeled samples for each digit:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将绘制一个条形图，显示每个数字的错误标记样本比例：
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This code creates a bar chart showing the ratio of each digit mislabeled by
    our model:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成一个条形图，显示我们模型错误标记每个数字的比例：
- en: '![](img/4337625d-7d76-4b64-98f2-9a661335fe80.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4337625d-7d76-4b64-98f2-9a661335fe80.png)'
- en: From the preceding figure, we see that the digit 8 is the most easily mis-recognized
    digit by our model. Let's find out why.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图中，我们看到数字 8 是模型最容易误识别的数字。我们来看看为什么。
- en: Extracting falsely predicted images
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取错误预测的图像
- en: 'Similar to what we did at the beginning of this chapter, we will draw the digit
    images out. This time, we pick out the mislabeled ones because they are the ones
    we''re concerned about. We will again pick 10 images and put them in a grid of
    subplots. We write the true label in green at the bottom as `xlabel` and the false
    label predicted in `red` as the `title` at the top for each image in a subplot:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在本章开头所做的类似，我们将提取出数字图像。这次，我们挑选出被错误标记的图像，因为这些才是我们关注的对象。我们将再次挑选出10张图像，并将它们放入子图网格中。我们将真实标签用绿色写在底部作为`xlabel`，并将预测的错误标签用`红色`写在顶部作为`title`，对于每个子图中的图像：
- en: '[PRE20]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Let's see how the images look. Does the handwriting look more like the true
    or falsely predicted label to you?
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些图像的效果。你认为这些手写数字更像真实标签还是错误预测的标签呢？
- en: '![](img/15efdaaa-3fc6-484a-8780-8f1cd93f3501.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/15efdaaa-3fc6-484a-8780-8f1cd93f3501.png)'
- en: We can observe that, for some images, it is quite difficult to identify the
    true label at the 8x8 resolution even with the naked eye, such as the number **4**
    in the middle of the bottom row. However, the leftmost number **4** on the same
    row should be legible enough for humans to recognize. From here, we can estimate
    the maximum possible improvement in accuracy by additional training and optimizing
    the model. This will guide our decision on whether it is worth while to expend
    further effort to improve our model, or what kind of training data to get or generate
    next to obtain better results.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到，对于某些图像，即使用肉眼看，8x8分辨率下也很难识别真实标签，比如底部行中间的数字**4**。然而，同一行最左侧的数字**4**应该足够清晰，便于人类识别。从这里我们可以估算出通过额外训练和优化模型，准确度最大可能的提升。这将指导我们是否值得投入更多精力去改进模型，或者下一步应该获取或生成哪种训练数据，以获得更好的结果。
- en: Meanwhile, notice that the training and testing datasets generally contain samples
    from different distributions. It is left for an exercise for you to repeat the
    process by downloading the actual training dataset from UCI ML, using the larger
    MNIST dataset (by downloading it via Keras, or even scraping or creating your
    own).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，请注意，训练和测试数据集通常包含来自不同分布的样本。你可以通过下载UCI ML的实际训练数据集，使用更大的MNIST数据集（通过Keras下载，甚至是抓取或自己生成数据）来重复这一过程，作为练习。
- en: Summary
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Congratulations! You have now completed this chapter as well as the whole book.
    In this chapter, we integrated various data visualization techniques along with
    an analytic project workflow, from the initial inspection and exploratory analysis
    of data, to model building and evaluation. Give yourself a huge round of applause,
    and get ready to leap forward into the journey of data science!
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！你已经完成了这一章以及整本书。在这一章中，我们整合了各种数据可视化技术，并结合了一个分析项目工作流程，从数据的初步检查和探索性分析，到模型构建和评估。给自己热烈的掌声，准备好跃进数据科学之旅吧！
