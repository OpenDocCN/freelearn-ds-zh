- en: Chapter 6. Machine Learning Using FlinkML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。使用FlinkML进行机器学习
- en: In the previous chapter, we talked about how to solve complex event-processing
    problems using the Flink CEP library. In this chapter, we are going to see how
    to do machine learning using Flink's machine learning library, called FlinkML.
    FlinkML consists of a set of supported algorithms, which can be used to solve
    real-life use cases. Throughout this chapter, we will look at what algorithms
    are available in FlinkML and how to apply them.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了如何使用Flink CEP库解决复杂的事件处理问题。在本章中，我们将看到如何使用Flink的机器学习库FlinkML进行机器学习。FlinkML包括一组支持的算法，可用于解决现实生活中的用例。在本章中，我们将看看FlinkML中有哪些算法以及如何应用它们。
- en: Before diving deep into FlinkML, let us first try to understand basic machine
    learning principles.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究FlinkML之前，让我们首先尝试理解基本的机器学习原理。
- en: What is machine learning?
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: Machine learning is a stream of engineering which uses mathematics to allow
    machines to make classifications, predictions, recommendations, and so on, based
    on the data provided to them. This area is vast, and we could spend years discussing
    it. But in order to keep our discussion focused, we will discuss only what is
    required for the scope of this book.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一种利用数学让机器根据提供给它们的数据进行分类、预测、推荐等的工程流。这个领域非常广阔，我们可以花费数年来讨论它。但为了保持我们的讨论集中，我们只讨论本书范围内所需的内容。
- en: 'Very broadly, machine learning can be divided into three big categories:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 非常广泛地，机器学习可以分为三大类：
- en: Supervised learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习
- en: Unsupervised learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Semi supervised learning![What is machine learning?](img/image_06_001.jpg)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半监督学习！[什么是机器学习？](img/image_06_001.jpg)
- en: The preceding diagram shows a broad classification of machine learning algorithms.
    Now let's discuss these in detail.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表显示了机器学习算法的广泛分类。现在让我们详细讨论这些。
- en: Supervised learning
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习
- en: In supervised learning, we are generally given an input dataset, which is a
    historical record of actual events. We are also given what the expected output
    should look like. Using the historical data, we choose which factors contributed
    to the results. Such attributes are called features. Using the historical data,
    we understand how the previous results were calculated and apply that same understanding
    to the data on which we want to make predictions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，我们通常会得到一个输入数据集，这是实际事件的历史记录。我们还知道预期的输出应该是什么样子。使用历史数据，我们选择了哪些因素导致了结果。这些属性被称为特征。使用历史数据，我们了解了以前的结果是如何计算的，并将相同的理解应用于我们想要进行预测的数据。
- en: 'Supervised learning can be again subdivided into:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习可以再次细分为：
- en: Regression
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归
- en: Classification
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类
- en: Regression
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回归
- en: In regression problems, we try to predict results using inputs from a continuous
    function. Regression means predicting the score of one variable based on the scores
    of another variable. The variable we will be predicting is called the criterion
    variable, and the variable from which we will be doing our predictions is called
    the predictor variable. There can be more than one predictor variable; in this
    case, we need to find the best fitting line, called the regression line.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归问题中，我们试图使用连续函数的输入来预测结果。回归意味着基于另一个变量的分数来预测一个变量的分数。我们将要预测的变量称为标准变量，我们将进行预测的变量称为预测变量。可能会有多个预测变量；在这种情况下，我们需要找到最佳拟合线，称为回归线。
- en: Note
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You can read more about regression at [https://en.wikipedia.org/wiki/Regression_analysis](https://en.wikipedia.org/wiki/Regression_analysis).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://en.wikipedia.org/wiki/Regression_analysis](https://en.wikipedia.org/wiki/Regression_analysis)上了解更多关于回归的信息。
- en: 'Some very common algorithms used for solving regression problem are as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 用于解决回归问题的一些常见算法如下：
- en: Logistic regression
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Decision trees
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: Support Vector Machine (SVM)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）
- en: Naive Bayes
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴素贝叶斯
- en: Random forest
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Linear regression
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归
- en: Polynomial regression
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式回归
- en: Classification
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类
- en: In classification, we predict the output in discrete results. Classification,
    being a part of supervised learning, also needs the input data and sample output
    to be given. Here, based on the features, we try to classify the results into
    sets of defined categories. For instance, based on the features given, classify
    records of people into male or female. Or, based on customer behavior, predict
    if he/she would buy a product or not. Or based on the e-mail content and sender,
    predict if the e-mail is spam or not. Refer to [https://en.wikipedia.org/wiki/Statistical_classification](https://en.wikipedia.org/wiki/Statistical_classification).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类中，我们预测离散结果的输出。分类作为监督学习的一部分，也需要提供输入数据和样本输出。在这里，基于特征，我们试图将结果分类为一组定义好的类别。例如，根据给定的特征，将人员记录分类为男性或女性。或者，根据客户行为，预测他/她是否会购买产品。或者根据电子邮件内容和发件人，预测电子邮件是否是垃圾邮件。参考[https://en.wikipedia.org/wiki/Statistical_classification](https://en.wikipedia.org/wiki/Statistical_classification)。
- en: In order to understand the difference between regression and classification,
    consider the example of stock data. Regression algorithms can help to predict
    the value of stock in upcoming days, while classification algorithms can help
    decide whether to buy the stock or not.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解回归和分类之间的区别，考虑股票数据的例子。回归算法可以帮助预测未来几天股票的价值，而分类算法可以帮助决定是否购买股票。
- en: Unsupervised learning
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Unsupervised learning does not give us any idea about how our results should
    look. Instead, it allows us to group data based on the features of the attributes.
    We derive the clustering based on the relationships among the records.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习并不给我们任何关于结果应该如何的想法。相反，它允许我们根据属性的特征对数据进行分组。我们根据记录之间的关系推导出聚类。
- en: Unlike supervised learning, there is no validation we can do to verify our results,
    which means there is no feedback method to teach us whether we did right or wrong.
    Unsupervised learning is primarily based on clustering algorithms.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 与监督学习不同，我们无法验证结果，这意味着没有反馈方法来告诉我们是否做对了还是错了。无监督学习主要基于聚类算法。
- en: Clustering
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚类
- en: In order to understand clustering more easily, let's consider an example; let's
    say we have 20,000 news articles on various topics and we have to group them based
    on their content . In this case, we can use clustering algorithms, which would
    group set of articles into small groups.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易理解聚类，让我们考虑一个例子；假设我们有2万篇关于各种主题的新闻文章，我们需要根据它们的内容对它们进行分组。在这种情况下，我们可以使用聚类算法，将一组文章分成小组。
- en: 'We can also consider the basic example of fruits. Let''s say we have apples,
    bananas, lemons, and cherries in a fruit basket and we need to classify them into
    groups. If we look at their colors, we can classify them into two groups:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以考虑水果的基本例子。假设我们有苹果、香蕉、柠檬和樱桃在一个水果篮子里，我们需要将它们分类成组。如果我们看它们的颜色，我们可以将它们分成两组：
- en: '**Red color group**: Apples and cherries'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**红色组**：苹果和樱桃'
- en: '**Yellow color group**: Bananas and lemons'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黄色组**：香蕉和柠檬'
- en: 'Now we can do more grouping based on another feature, its size:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以根据另一个特征，它的大小，进行更多的分组：
- en: '**Red color and large size**: Apples'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**红色和大尺寸**：苹果'
- en: '**Red color and small size**: Cherries'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**红色和小尺寸**：樱桃'
- en: '**Yellow color and large size**: Banana'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黄色和大尺寸**：香蕉'
- en: '**Yellow color and small size**: Lemons'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黄色和小尺寸**：柠檬'
- en: 'The following diagram shows a representation of clustering:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了聚类的表示：
- en: '![Clustering](img/image_06_002.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![聚类](img/image_06_002.jpg)'
- en: This way, by looking at more features, we can also do more clustering. Here,
    we don't have any training data and a variable to be predicted, unlike in supervised
    learning. Our only task is to learn more about the features and cluster the records
    based on inputs.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看更多特征，我们也可以进行更多的聚类。在这里，我们没有任何训练数据和要预测的变量，不像在监督学习中。我们的唯一任务是学习更多关于特征，并根据输入对记录进行聚类。
- en: 'The following are some of the algorithms commonly used for clustering:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些常用于聚类的算法：
- en: K-means clustering
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K均值聚类
- en: Hierarchical clustering
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层次聚类
- en: Hidden Markov models
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐马尔可夫模型
- en: Association
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关联
- en: Association problems are more about learning, and making recommendations by
    defining association rules. Association rules could, for example, refer to the
    assumption that people who bought an iPhone are more likely to buy an iPhone case.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 关联问题更多是关于学习和通过定义关联规则进行推荐。例如，关联规则可能指的是购买iPhone的人更有可能购买iPhone手机壳的假设。
- en: These days, many retail companies use these algorithms to make personalized
    recommendations. For instance, on [www.amazon.com](http://www.amazon.com), if
    I tend to purchase product *X* and then Amazon recommends me product *Y* as well,
    there must be some association between the two.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，许多零售公司使用这些算法进行个性化推荐。例如，在[www.amazon.com](http://www.amazon.com)，如果我倾向于购买产品*X*，然后亚马逊也向我推荐产品*Y*，那么这两者之间一定存在一些关联。
- en: 'Some of the algorithms based on these principles are as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些原则的一些算法如下：
- en: Apriori algorithm
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apriori算法
- en: Eclat algorithm
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eclat算法
- en: FDP growth algorithm
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FDP增长算法
- en: Semi-supervised learning
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 半监督学习
- en: Semi-supervised learning is a sub-class of supervised learning that considers
    unlabeled data for training. Generally, while training, it has a good amount of
    unlabeled data and only a very small amount of labeled data. Many researchers
    and machine learning practitioners have found that, when labeled data is used
    in conjunction with unlabeled data, the results are likely to be more accurate.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习是监督学习的一个子类，它考虑了用于训练的未标记数据。通常，在训练过程中，有大量未标记数据，只有很少量的标记数据。许多研究人员和机器学习实践者发现，当标记数据与未标记数据一起使用时，结果很可能更准确。
- en: Note
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: More details on semi-supervised learning can be found at [https://en.wikipedia.org/wiki/Semi-supervised_learning](https://en.wikipedia.org/wiki/Semi-supervised_learning).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 有关半监督学习的更多细节，请参阅[https://en.wikipedia.org/wiki/Semi-supervised_learning](https://en.wikipedia.org/wiki/Semi-supervised_learning)。
- en: FlinkML
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FlinkML
- en: FlinkML is a library of sets of algorithms supported by Flink that can be used
    to solve real-life use cases. The algorithms are built so that they can use the
    distributed computing power of Flink and make predictions or do clustering and
    so on with ease. Right now, there are only a few sets of algorithms supported,
    but the list is growing.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: FlinkML是由Flink支持的一组算法库，可用于解决现实生活中的用例。这些算法被构建成可以利用Flink的分布式计算能力，并且可以轻松进行预测、聚类等。目前，只支持了少量算法集，但列表正在增长。
- en: FlinkML is being built with the focus on ML developers needing to write minimal
    glue code. Glue code is code that helps bind various components together. Another
    goal of FlinkML is to keep the use of algorithms simple.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: FlinkML的重点是ML开发人员需要编写最少的粘合代码。粘合代码是帮助将各种组件绑定在一起的代码。FlinkML的另一个目标是保持算法的使用简单。
- en: Flink exploits in-memory data streaming and executes iterative data processing
    natively. FlinkML allows data scientists to test their models locally, with a
    subset of data, and then execute them in cluster mode on bigger data.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Flink利用内存数据流和本地执行迭代数据处理。FlinkML允许数据科学家在本地测试他们的模型，使用数据子集，然后在更大的数据上以集群模式执行它们。
- en: FlinkML is inspired by scikit-learn and Spark's MLlib, which allows you to define
    data pipelines cleanly and solve machine learning problems in a distributed manner.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: FlinkML受scikit-learn和Spark的MLlib启发，允许您清晰地定义数据管道，并以分布式方式解决机器学习问题。
- en: 'The following is the road map Flink''s development team is aiming to build:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Flink开发团队的路线图如下：
- en: Pipelines of transformers and learners
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换器和学习者的管道
- en: 'Data pre-processing:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据预处理：
- en: Feature scaling
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征缩放
- en: Polynomial feature base mapper
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式特征基映射
- en: Feature hashing
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征哈希
- en: Feature extraction for text
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本特征提取
- en: Dimensionality reduction
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降维
- en: 'Model selection and performance evaluation:'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型选择和性能评估：
- en: Model evaluation using a variety of scoring functions
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用各种评分函数进行模型评估
- en: Cross-validation for model selection and evaluation
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于模型选择和评估的交叉验证
- en: Hyper-parameter optimization
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数优化
- en: 'Supervised learning:'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习：
- en: Optimization framework
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化框架
- en: Stochastic Gradient Descent
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机梯度下降
- en: L-BFGS
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L-BFGS
- en: Generalized Linear Models
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广义线性模型
- en: Multiple linear regression
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多元线性回归
- en: LASSO, Ridge regression
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LASSO，岭回归
- en: Multi-class Logistic regression
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多类逻辑回归
- en: Random forests
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Support Vector Machines
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Decision trees
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: 'Unsupervised learning:'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习：
- en: Clustering
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类
- en: K-means clustering
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K均值聚类
- en: Principal Components Analysis
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主成分分析
- en: 'Recommendation:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐：
- en: ALS
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ALS
- en: 'Text analytics:'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本分析：
- en: LDA
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LDA
- en: Statistical estimation tools
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计估计工具
- en: Distributed linear algebra
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式线性代数
- en: Streaming ML
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流式机器学习
- en: The algorithms highlighted are already part of the existing Flink source code.
    In the following section, we will look at how we can use those in practice.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 突出显示的算法已经是现有的Flink源代码的一部分。在接下来的部分中，我们将看看如何在实践中使用它们。
- en: Supported algorithms
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持的算法
- en: 'To get started with FlinkML, we first need to add the following Maven dependency:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用FlinkML，我们首先需要添加以下Maven依赖项：
- en: '[PRE0]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now let's try to understand the supported algorithms and how to use those.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们试着了解支持的算法以及如何使用它们。
- en: Supervised learning
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习
- en: 'Flink supports three algorithms in the supervised-learning category. They are
    as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Flink支持监督学习类别中的三种算法。它们如下：
- en: Support Vector Machine (SVM)
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）
- en: Multiple linear regression
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多元线性回归
- en: Optimization framework
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化框架
- en: Let's get started learning about them one at a time.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一次学习一个开始。
- en: Support Vector Machine
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 支持向量机
- en: '**Support Vector Machines** (**SVMs**) are supervised learning models, which
    analyze the data solving classification and regression problems. It helps classify
    objects into one category or another. It is non-probabilistic linear classification.
    There are various examples in which SVM can be used, such as the following:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVMs**）是监督学习模型，用于解决分类和回归问题。它有助于将对象分类到一个类别或另一个类别。它是非概率线性分类。SVM可以用在各种例子中，例如以下情况：'
- en: Regular data classification problems
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常规数据分类问题
- en: Text and hypertext classification problems
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本和超文本分类问题
- en: Image classification problems
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像分类问题
- en: Biological and other science problems
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生物学和其他科学问题
- en: Flink supports SVM based on a soft-margin using a communication-efficient distributed
    dual-coordinate ascent algorithm.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Flink支持基于软间隔的SVM，使用高效的通信分布式双坐标上升算法。
- en: Details on this algorithm are available at [https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/svm.html#description](https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/svm.html#description).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 有关该算法的详细信息可在[https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/svm.html#description](https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/svm.html#description)找到。
- en: Flink uses **Stochastic Dual Coordinate Ascent** (**SDCA**) to solve the minimization
    problem. To make this algorithm efficient in a distributed environment, Flink
    uses the CoCoA algorithm, which calculates the SDCA on a local data block and
    then merges it into global state.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Flink使用**随机双坐标上升**（**SDCA**）来解决最小化问题。为了使该算法在分布式环境中高效，Flink使用CoCoA算法，该算法在本地数据块上计算SDCA，然后将其合并到全局状态中。
- en: Note
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The implementation of this algorithm is based on the following paper: [https://arxiv.org/pdf/1409.1458v2.pdf](https://arxiv.org/pdf/1409.1458v2.pdf).'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法的实现基于以下论文：[https://arxiv.org/pdf/1409.1458v2.pdf](https://arxiv.org/pdf/1409.1458v2.pdf)。
- en: 'Now let''s look at how we can solve a real-life problem using this algorithm.
    We will take the example of the Iris dataset ([https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set)),
    consisting of four attributes which decide the species of Iris. The following
    is some sample data:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用该算法解决实际问题。我们将以鸢尾花数据集（[https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set)）为例，该数据集由四个属性组成，决定了鸢尾花的种类。以下是一些示例数据：
- en: '| **Sepal length** | **Sepal width** | **Petal length** | **Petal width** |
    **Species** |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| **萼片长度** | **萼片宽度** | **花瓣长度** | **花瓣宽度** | **种类** |'
- en: '| 5.1 | 3.5 | 1.4 | 0.2 | 1 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 5.1 | 3.5 | 1.4 | 0.2 | 1 |'
- en: '| 5.6 | 2.9 | 3.6 | 1.3 | 2 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 5.6 | 2.9 | 3.6 | 1.3 | 2 |'
- en: '| 5.8 | 2.7 | 5.1 | 1.9 | 3 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 5.8 | 2.7 | 5.1 | 1.9 | 3 |'
- en: 'Here, it is important to use categories in number format to be used as input
    to SVM:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，使用数字格式的类别作为SVM的输入非常重要：
- en: '| **Species code** | **Species name** |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| **种类代码** | **种类名称** |'
- en: '| 1 | Iris Setosa |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 鸢尾花山鸢尾 |'
- en: '| 2 | Iris Versicolor |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 鸢尾花变色鸢尾 |'
- en: '| 3 | Iris Virginica |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 鸢尾花维吉尼亚 |'
- en: One more thing we need to do before using data for Flink's SVM algorithm is
    to convert this CSV data into LibSVM data.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Flink的SVM算法之前，我们需要做的另一件事是将CSV数据转换为LibSVM数据。
- en: Note
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: LibSVM data is a special format used for specifying SVM datasets. More information
    on LibSVM is available at [https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: LibSVM数据是一种用于指定SVM数据集的特殊格式。有关LibSVM的更多信息，请访问[https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/)。
- en: To convert CSV data to LibSVM data, we will use some open-source Python code
    available at [https://github.com/zygmuntz/phraug/blob/master/csv2libsvm.py](https://github.com/zygmuntz/phraug/blob/master/csv2libsvm.py).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要将CSV数据转换为LibSVM数据，我们将使用[https://github.com/zygmuntz/phraug/blob/master/csv2libsvm.py](https://github.com/zygmuntz/phraug/blob/master/csv2libsvm.py)上提供的一些开源Python代码。
- en: 'To convert CSV to LibSVM, we need to execute the following command:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要将CSV转换为LibSVM，我们需要执行以下命令：
- en: '[PRE1]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now let''s get started with writing the program:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们开始编写程序：
- en: '[PRE2]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: So, now we are all set to run the program, and you will the see the predicted
    output in the output folder.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在我们已经准备好运行程序了，您将在输出文件夹中看到预测的输出。
- en: 'The following is the code:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是代码：
- en: '[PRE3]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can also fine-tune the results by setting various parameters:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过设置各种参数来微调结果：
- en: '| **Parameter** | **Description** |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| **参数** | **描述** |'
- en: '| `Blocks` | Sets the number of blocks into which the input data will be split.
    It is ideal to set this number equal to the parallelism you want to achieve. On
    each block, local stochastic dual-coordinate ascent is performed. The default
    value is `None`. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| `Blocks` | 设置输入数据将被分成的块数。最好将这个数字设置为你想要实现的并行度。在每个块上，执行本地随机对偶坐标上升。默认值为`None`。
    |'
- en: '| `Iterations` | Sets the number of iterations of the outer loop method, for
    example, the amount of time the SDCA method should applied on blocked data. The
    default value is `10`. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| `Iterations` | 设置外部循环方法的迭代次数，例如，SDCA方法在分块数据上应用的次数。默认值为`10`。 |'
- en: '| `LocalIterations` | Defines the maximum number of SDCA iterations that need
    to be executed locally. The default value is `10`. |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| `LocalIterations` | 定义需要在本地执行的SDCA迭代的最大次数。默认值为`10`。 |'
- en: '| `Regularization` | Sets the regularization constant of the algorithm. The
    higher you set the value, the smaller the 2 norm of the weighted vector be. The
    default value is `1`. |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| `Regularization` | 设置算法的正则化常数。您设置的值越高，加权向量的2范数就越小。默认值为`1`。 |'
- en: '| `StepSize` | Defines the initial step size for the updates of weight vector.
    This value needs to be set up in case the algorithm becomes unstable. The default
    value is `1.0`. |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| `StepSize` | 定义了权重向量更新的初始步长。在算法变得不稳定的情况下，需要设置这个值。默认值为`1.0`。 |'
- en: '| `ThresholdValue` | Defines the limiting value for the decision function.
    The default value is `0.0`. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| `ThresholdValue` | 定义决策函数的限制值。默认值为`0.0`。 |'
- en: '| `OutputDecisionFunction` | Setting this to true will return the hyperplane
    distance for each example. Setting it to false will return the binary label. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| `OutputDecisionFunction` | 将其设置为true将返回每个示例的超平面距离。将其设置为false将返回二进制标签。 |'
- en: '| `Seed` | Sets the random long integer. This will be used to initialize the
    random number generator. |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| `Seed` | 设置随机长整数。这将用于初始化随机数生成器。 |'
- en: Multiple Linear Regression
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多元线性回归
- en: '**Multiple Linear Regression** (**MLR**) is an extension of simple linear regression
    where more than one independent variable (*X*) is used to determine the single
    independent variable (*Y*). The predicted value is a linear transformation of
    input variables such that the sum of squared deviations of the observed and predicted
    is minimum.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**多元线性回归**（**MLR**）是简单线性回归的扩展，其中使用多个自变量（*X*）来确定单个自变量（*Y*）。预测值是输入变量的线性变换，使得观察值和预测值的平方偏差之和最小。'
- en: MLR tries to model the relationship between multiple explanatory variables and
    response variables by fitting a linear equation.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: MLR试图通过拟合线性方程来建模多个解释变量和响应变量之间的关系。
- en: Note
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A more detailed explanation of MLR can be found on this link [http://www.stat.yale.edu/Courses/1997-98/101/linmult.htm](http://www.stat.yale.edu/Courses/1997-98/101/linmult.htm).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 关于MLR的更详细的解释可以在此链接找到[http://www.stat.yale.edu/Courses/1997-98/101/linmult.htm](http://www.stat.yale.edu/Courses/1997-98/101/linmult.htm)。
- en: Let's try solving the same classification problem of Iris dataset using MLR
    now. First we need the training dataset on which we can train our mode.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试使用MLR解决鸢尾花数据集的相同分类问题。首先，我们需要训练数据集来训练我们的模型。
- en: Here we will be using the same data files we used in previous section on SVM.
    So now we have `iris-train.txt` and `iris-test.txt` which are converted into LibSVM
    format.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用在SVM上一节中使用的相同的数据文件。现在我们有`iris-train.txt`和`iris-test.txt`，它们已经转换成了LibSVM格式。
- en: 'The following code snippet shows how MLR can be used:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了如何使用MLR：
- en: '[PRE4]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The complete code and the data files are available for download on [https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06](https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06). We
    can also fine-tune the results by setting various parameters:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码和数据文件可以在[https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06](https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06)上下载。我们还可以通过设置各种参数来微调结果：
- en: '| **Parameter** | **Description** |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| **参数** | **描述** |'
- en: '| `Iterations` | Sets the maximum number of iterations. The default value is
    `10`. |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| `Iterations` | 设置最大迭代次数。默认值为`10`。 |'
- en: '| `Stepsize` | The step size of the gradient descent method. This value controls
    how far the gradient descent method can move in the opposite direction. Tuning
    this parameter is very important to get better results. The default value is `0.1`.
    |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| `Stepsize` | 梯度下降方法的步长。这个值控制了梯度下降方法在相反方向上可以移动多远。调整这个参数非常重要，以获得更好的结果。默认值为`0.1`。
    |'
- en: '| `Convergencethreshold` | The threshold for the relative change of the sum
    of squared residuals until the iteration is stopped. The default value is `None`.
    |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| `Convergencethreshold` | 直到迭代停止的平方残差的相对变化的阈值。默认值为`None`。 |'
- en: '| `Learningratemethod` |  `Learningratemethod` is used to calculate the learning
    rate of each iteration. |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| `Learningratemethod` | `Learningratemethod` 用于计算每次迭代的学习率。 |'
- en: Optimization framework
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化框架
- en: Optimization framework in Flink is a developer-friendly package which can be
    used to solve optimization problems. This is not a specific algorithm to solve
    exact problems, but it is the basis of every machine learning problem.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Flink中的优化框架是一个开发者友好的包，可以用来解决优化问题。这不是一个解决确切问题的特定算法，而是每个机器学习问题的基础。
- en: 'Generally, it is about finding the model, with a set of parameters, with a
    minimization function. FlinkML supports **Stochastic Gradient Descent** (**SGD**),
    with the following types of regularizations:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，它是关于找到一个模型，带有一组参数，通过最小化函数。FlinkML支持**随机梯度下降**（**SGD**），并具有以下类型的正则化：
- en: '| **Regularization function** | **Class name** |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| **正则化函数** | **类名** |'
- en: '| L1 regularization | `GradientDescentL1` |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| L1正则化 | `GradientDescentL1` |'
- en: '| L2 regularization | `GradientDescentL2` |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| L2正则化 | `GradientDescentL2` |'
- en: '| No regularization | `SimpleGradient` |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 无正则化 | `SimpleGradient` |'
- en: 'The following code snippet shows how to use SGD using FlinkML:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了如何使用FlinkML使用SGD：
- en: '[PRE5]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can also use parameters to fine-tune the algorithm:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用参数来微调算法：
- en: '| **Parameter** | **Description** |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| **参数** | **描述** |'
- en: '| `LossFunction` | Flink supports the following loss functions:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '| `LossFunction` | Flink支持以下损失函数：'
- en: Squared Loss
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平方损失
- en: Hinged Loss
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 铰链损失
- en: Logistic Loss
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑损失
- en: The default is `None`
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认值为`None`
- en: '|'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| `RegularizationConstant` | The weight of regularization to be applied. The
    default value is `0.1`. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| `RegularizationConstant` | 要应用的正则化权重。默认值为`0.1`。 |'
- en: '| `Iterations` | The maximum number of iterations to be performed. The default
    is `10`. |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| `Iterations` | 要执行的最大迭代次数。默认值为`10`。 |'
- en: '| `ConvergenceThreshold` | The threshold for relative change of the sum of
    squared residuals until the iteration is stopped. The default value is `None`.
    |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| `ConvergenceThreshold` | 直到迭代停止的残差平方和的相对变化阈值。默认值为`None`。 |'
- en: '| `LearningRateMethod` | This method is used to calculate the learning rate
    of each iteration. |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| `LearningRateMethod` | 用于计算每次迭代的学习率的方法。 |'
- en: '| `LearningRate` | This is the initial learning rate for the gradient descent
    method. |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| `LearningRate` | 这是梯度下降方法的初始学习率。 |'
- en: '| `Decay` | The default value is `0.0`. |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| `Decay` | 默认值为`0.0`。 |'
- en: Recommendations
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐
- en: Recommendation engines are one of the most interesting and heavily used machine
    learning techniques to provide user-based and item-based recommendations. E-commerce
    companies such as Amazon use recommendation engines to personalize recommendations
    based on the purchasing patterns and review ratings of its customers.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎是最有趣和最常用的机器学习技术之一，用于提供基于用户和基于项目的推荐。亚马逊等电子商务公司使用推荐引擎根据客户的购买模式和评论评分来个性化推荐。
- en: Flink also supports ALS-based recommendations. Let's look at ALS in more detail.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Flink还支持基于ALS的推荐。让我们更详细地了解ALS。
- en: Alternating Least Squares
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交替最小二乘法
- en: The **Alternating Least Squares** (**ALS**) algorithm factorizes a given matrix,
    *R*, into two factors, *U* and *V*, such that  ![Alternating Least Squares](img/image_06_003.jpg)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**交替最小二乘法**（**ALS**）算法将给定的矩阵*R*分解为两个因子*U*和*V*，使得 ![交替最小二乘法](img/image_06_003.jpg)'
- en: In order to better understand the application of this algorithm, let's assume
    that we have a dataset which contains the rating, *r*, provided by user *u* for
    book *b*.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解该算法的应用，让我们假设我们有一个包含用户*u*对书籍*b*提供的评分*r*的数据集。
- en: 'Here is a sample data format (`user_id`, `book_id`, `rating)`:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个样本数据格式（`user_id`，`book_id`，`rating)`：
- en: '[PRE6]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now we can feed this information to the ALS algorithm and start getting recommendations
    from it. The following is a code snippet for using ALS:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将这些信息提供给ALS算法，并开始从中获得推荐。以下是使用ALS的代码片段：
- en: '[PRE7]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Once you execute the application, you''ll get the results as recommendations.
    Like with other algorithms, you can fine-tune the parameters to get better results:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您执行应用程序，您将获得推荐结果。与其他算法一样，您可以微调参数以获得更好的结果：
- en: '| **Parameter** | **Description** |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| **参数** | **描述** |'
- en: '| `NumFactors` | The number of latent factors to use for the underlying model.
    The default value is `10`. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| `NumFactors` | 用于基础模型的潜在因子的数量。默认值为`10`。 |'
- en: '| `Lambda` | This is a regularization factor; we can tune this parameter for
    better results. The default is `1`. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| `Lambda` | 这是一个正则化因子；我们可以调整此参数以获得更好的结果。默认值为`1`。 |'
- en: '| `Iterations` | The maximum number of iterations to be performed. The default
    is `10`. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| `Iterations` | 要执行的最大迭代次数。默认值为`10`。 |'
- en: '| `Blocks` | The number of blocks in which user and item matrix are grouped.
    The fewer the blocks, the less data is sent redundantly. The default value is
    `None`. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| `Blocks` | 用户和项目矩阵分组的块数。块越少，发送的冗余数据就越少。默认值为`None`。 |'
- en: '| `Seed` | The seed value to initiate the item matrix generator. The default
    is `0`. |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| `Seed` | 用于初始化项目矩阵生成器的种子值。默认值为`0`。 |'
- en: '| `TemporaryPath` | This is a path to be used for storing intermediate results.
    |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| `TemporaryPath` | 这是用于存储中间结果的路径。 |'
- en: Unsupervised learning
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Now let's try to understand what FinkML offers for unsupervised learning. For
    now, it supports only one algorithm, called the k Nearest Neighbor join algorithm.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们试着了解FinkML为无监督学习提供了什么。目前，它只支持一种算法，称为k最近邻接算法。
- en: k Nearest Neighbour join
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: k最近邻接
- en: The **k Nearest Neighbor** (**kNN**) algorithm is designed to find the k Nearest
    Neighbour from a dataset for every object in another dataset. It is one of the
    most widely used solutions in many data-mining algorithms. The kNN is an expensive
    operation, as it is a combination of finding the k nearest neighbor and performing
    a join. Considering the volume of the data, it is very difficult to perform this
    operation on a centralized single machine, hence it is always good to have solutions
    that can work on distributed architecture. The FlinkML algorithm provides kNN
    on a distributed environment.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '**k最近邻接**（**kNN**）算法旨在为另一个数据集中的每个对象找到k个最近邻居。它是许多数据挖掘算法中最常用的解决方案之一。kNN是一项昂贵的操作，因为它是找到k个最近邻居并执行连接的组合。考虑到数据的量，很难在集中的单台机器上执行此操作，因此总是很好地拥有可以在分布式架构上工作的解决方案。FlinkML算法提供了分布式环境下的kNN。'
- en: Note
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'A research paper describing the implementation of kNN on a distributed environment
    can be found here: [https://arxiv.org/pdf/1207.0141v1.pdf](https://arxiv.org/pdf/1207.0141v1.pdf).'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在这里找到一篇描述在分布式环境中实现kNN的研究论文：[https://arxiv.org/pdf/1207.0141v1.pdf](https://arxiv.org/pdf/1207.0141v1.pdf)。
- en: Here, the idea is to compute the distance between every training and testing
    point and then find the nearest points for a given point. Computing the distance
    between each point is a time-consuming activity, which is eased out in Flink by
    implementing quad trees.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，想法是计算每个训练和测试点之间的距离，然后找到给定点的最近点。计算每个点之间的距离是一项耗时的活动，在Flink中通过实现四叉树来简化。
- en: 'Using quad trees reduces the computation by partitioning the dataset. This
    reduces the computation to the subset of data only. The following diagram shows
    computation with and without quad trees:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 使用四叉树通过对数据集进行分区来减少计算。这将计算减少到仅对数据子集进行。以下图表显示了使用四叉树和不使用四叉树的计算：
- en: '![k Nearest Neighbour join](img/image_06_004.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![k最近邻连接](img/image_06_004.jpg)'
- en: 'You can find a detailed discussion on using quad trees to calculate the nearest
    neighbors here: [http://danielblazevski.github.io/assets/player/KeynoteDHTMLPlayer.html](http://danielblazevski.github.io/assets/player/KeynoteDHTMLPlayer.html).'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这里找到有关使用四叉树计算最近邻居的详细讨论：[http://danielblazevski.github.io/assets/player/KeynoteDHTMLPlayer.html](http://danielblazevski.github.io/assets/player/KeynoteDHTMLPlayer.html)。
- en: It's not always the case that quad trees will perform better. If the data is
    spatial, the quad trees might be the worst choice. But as a developer, we don't
    need to worry about it as FlinkML takes care of deciding whether to use quad tree
    or not based on the data available.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 四叉树并不总是表现得更好。如果数据是空间的，四叉树可能是最糟糕的选择。但作为开发人员，我们不需要担心这一点，因为FlinkML会根据可用的数据来决定是否使用四叉树。
- en: 'The following code snippet shows how to use kNN join in FlinkML:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了如何在FlinkML中使用kNN连接：
- en: '[PRE8]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following are some parameters we can use to fine-tune the results:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些我们可以用来微调结果的参数：
- en: '| **Parameter** | **Description** |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| **参数** | **描述** |'
- en: '| `K` | The number of nearest neighbours to search for. The default is `5`.
    |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| `K` | 要搜索的最近邻居的数量。默认值为`5`。'
- en: '| `DistanceMetric` | Sets the distance metric to be used to calculate the distance
    between two points. By default, Euclidian Distance Metric is used. |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| `DistanceMetric` | 设置用于计算两点之间距离的距离度量。默认情况下，使用欧几里德距离度量。'
- en: '| `Blocks` | The number of blocks into which the input data should be split.
    It is ideal to set this number equal to the degree of parallelism. |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| `Blocks` | 输入数据应该分成的块数。将此数字设置为并行度的理想值。'
- en: '| `UseQuadTree` | Sets whether to use quad tree for processing or not. The
    default value is `None`. If nothing is specified, the algorithm decides on its
    own. |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| `UseQuadTree` | 设置是否使用四叉树进行处理。默认值为`None`。如果未指定任何内容，算法会自行决定。'
- en: Utilities
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实用程序
- en: 'FlinkML supports various extensible utilities, which can be handy while doing
    data analysis and predictions. One such utility is distance metrics. Flink supports
    a set of distance metrics which can be used. The following link shows Flink-supported
    distance metrics: [https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/distance_metrics.html](https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/distance_metrics.html).'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: FlinkML支持各种可扩展的实用程序，在进行数据分析和预测时非常方便。其中一个实用程序是距离度量。Flink支持一组可以使用的距离度量。以下链接显示了Flink支持的距离度量：[https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/distance_metrics.html](https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/distance_metrics.html)。
- en: 'If any of the previously mentioned algorithms do not satisfy your needs, you
    can think about writing your own custom distance algorithm. The following code
    snippet shows how to do so:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前面提到的算法都不能满足您的需求，您可以考虑编写自己的自定义距离算法。以下代码片段显示了如何实现：
- en: '[PRE9]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: A good application of using distance metrics is the kNN join algorithm, where
    you can set the distance metric to use.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 使用距离度量的一个很好的应用是kNN连接算法，您可以设置要使用的距离度量。
- en: Another important utility is `Splitter`, which can be used for cross validation.
    In some cases, we may not have a test dataset to validate our results. In such
    cases, we can split the training dataset using `Splitter`.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的实用程序是`Splitter`，它可以用于交叉验证。在某些情况下，我们可能没有测试数据集来验证我们的结果。在这种情况下，我们可以使用`Splitter`来拆分训练数据集。
- en: 'The following is an example:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例：
- en: '[PRE10]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the preceding example, we are splitting the training dataset into portions
    of 60% and 40% of the actual data.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们将训练数据集分成了实际数据的60%和40%的部分。
- en: 'There is another method to fetch better results, called `TrainTestHoldout`
    split. Here, we use some portion of the data for training, some for testing, and
    another set for final result validations. The following snippet shows how to do
    it:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一种获取更好结果的方法，称为`TrainTestHoldout`拆分。在这里，我们使用一部分数据进行训练，一部分进行测试，另一部分用于最终结果验证。以下代码片段显示了如何实现：
- en: '[PRE11]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can use another strategy, called K fold splits. In this method, the training
    set is split into *k* equal size folds. Here, an algorithm is created for each
    fold and then validated against its testing set. The following code shows how
    to do k-fold splits:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用另一种策略，称为K折拆分。在这种方法中，训练集被分成*k*个相等大小的折叠。在这里，为每个折叠创建一个算法，然后针对其测试集进行验证。以下代码显示了如何进行K折拆分：
- en: '[PRE12]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can also use **Multi Random Splits**; here we can specify how many datasets
    to create and of what portion of the original:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用**多随机拆分**；在这里，我们可以指定要创建多少个数据集以及原始数据的什么部分：
- en: '[PRE13]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Data pre processing and pipelines
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理和管道
- en: Flink supports Python scikit-learn style pipeline. A pipeline in FlinkML is
    feature to chain multiple transformers and predictors in one go. In general, many
    data scientists would like to see and build the flow of machine learning application
    with ease. Flink allows them to do so using the concept of pipelines.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: Flink支持Python scikit-learn风格的管道。FlinkML中的管道是将多个转换器和预测器链接在一起的特性。一般来说，许多数据科学家希望轻松地查看和构建机器学习应用的流程。Flink允许他们使用管道的概念来实现这一点。
- en: 'In general, there are three building blocks of ML pipelines:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，ML管道有三个构建块：
- en: '**Estimator:** Estimator performs the actual training of a model using a `fit`
    method. For example, finding correct weights in a linear regression model.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**估计器：** 估计器使用`fit`方法对模型进行实际训练。例如，在线性回归模型中找到正确的权重。'
- en: '**Transformer:** Transformer as the name suggests have a `transform` method
    which can help in scaling the input.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转换器：** 转换器正如其名称所示，具有一个`transform`方法，可以帮助进行输入缩放。'
- en: '**Predictor:** Predictors have the `predict` method which applies the algorithm
    for generating predictions, for example, SVM or MLR.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测器：** 预测器具有`predict`方法，该方法应用算法生成预测，例如，SVM或MLR。'
- en: A pipeline is a chain of estimator, transformers and predictor. The predictor
    is the end of a pipeline and nothing can be chained after that.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 管道是一系列估计器、转换器和预测器。预测器是管道的末端，在此之后不能再链接任何内容。
- en: Flink supports various data pre-processing tools which would help us advance
    the results. Let's start understanding the details.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: Flink支持各种数据预处理工具，这将有助于我们提高结果。让我们开始了解细节。
- en: Polynomial features
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多项式特征
- en: 'The polynomial feature is a transformer which maps a vector into the polynomial
    feature space of degree *d*. Polynomial feature helps in solving classification
    problems by changing the graph of the function. Let''s try to understand this
    by an example:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式特征是一种将向量映射到* d *次多项式特征空间的转换器。多项式特征有助于通过改变函数的图形来解决分类问题。让我们通过一个例子来理解这一点：
- en: Consider a linear formula: *F(x,y) = 1*x + 2*y;*
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑一个线性公式：*F(x,y) = 1*x + 2*y;*
- en: 'Imagine we have two observations:'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想象我们有两个观察结果：
- en: '*x=12* and *y=2*'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x=12* 和 *y=2*'
- en: '*x=5* and *y =5.5*'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x=5* 和 *y =5.5*'
- en: In both cases, we get *f() = 16*. If these observations belong to two different
    classes then we cannot differentiate between the two. Now if we add one more feature
    called *z* which is combination of previous two features *z = x+y*.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，我们得到 *f() = 16*。如果这些观察结果属于两个不同的类别，那么我们无法区分这两个类别。现在，如果我们添加一个称为*z*的新特征，该特征是前两个特征的组合*z
    = x+y*。
- en: So now *f(x,y,z) = 1*x + 2*y + 3*z*
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 *f(x,y,z) = 1*x + 2*y + 3*z*
- en: Now the same observations would be
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 现在相同的观察结果将是
- en: '*(1*12)+ (2*2) + (3*24) = 88*'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*(1*12)+ (2*2) + (3*24) = 88*'
- en: '*(1*5)+ (2*5.5) + (3*27.5) = 98.5*'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*(1*5)+ (2*5.5) + (3*27.5) = 98.5*'
- en: This way adding a new feature using existing features can help us get better
    results. Flink polynomial features allows us to do the same with pre-build functions.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用现有特征添加新特征的方式可以帮助我们获得更好的结果。Flink多项式特征允许我们使用预构建函数做同样的事情。
- en: 'In order to use polynomial features in Flink, we have the following code:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在Flink中使用多项式特征，我们有以下代码：
- en: '[PRE14]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Standard scaler
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标准缩放器
- en: Standard scaler helps scale the input data using the user-specified mean and
    variance. If the user does not specify any values then default mean is `0` and
    standard deviation would be `1`. Standard scaler is a transformer which has `fit`
    and `transform` method.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 标准缩放器通过使用用户指定的均值和方差来缩放输入数据。如果用户没有指定任何值，则默认均值为`0`，标准差为`1`。标准缩放器是一个具有`fit`和`transform`方法的转换器。
- en: 'First we need to define the values for mean and standard deviation as shown
    in the following code snippet:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要像下面的代码片段中所示定义均值和标准差的值：
- en: '[PRE15]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next we need to let it learn about mean and standard deviation of training
    dataset as shown in the following code snippet:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要让它了解训练数据集的均值和标准差，如下面的代码片段所示：
- en: '[PRE16]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'And finally we scale the provided data using the user-defined mean and standard
    deviation as shown in the following code snippet:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用用户定义的均值和标准差来缩放提供的数据，如下面的代码片段所示：
- en: '[PRE17]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now we can use this scaled input data to do further transformation and analysis.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用这些缩放后的输入数据进行进一步的转换和分析。
- en: MinMax scaler
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最小-最大缩放器
- en: MinMax scaler is like standard scaler but the only difference is it makes sure
    that scaling of each feature lies between user-defined `min` and `max` values.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 最小-最大缩放器类似于标准缩放器，但唯一的区别是它确保每个特征的缩放位于用户定义的`min`和`max`值之间。
- en: 'The following code snippet shows how to use this:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了如何使用它：
- en: '[PRE18]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Thus, we can use these data pre-processing operations to enhance the results.
    These can also be combined in pipelines to create the workflow.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以使用这些数据预处理操作来增强结果。这些还可以组合在管道中创建工作流程。
- en: 'The following code snippet shows how to use these data pre-processing operations
    in pipeline:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了如何在管道中使用这些数据预处理操作：
- en: '[PRE19]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The complete code is available on GitHub at [https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06](https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06).
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码可在GitHub上找到[https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06](https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06)。
- en: Summary
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the different types of machine learning algorithm.
    We looked at various supervised and unsupervised algorithms, and their respective
    examples. We also looked at various utilities provided by FlinkML, which can be
    very handy during data analysis. Later we looked at data pre-processing operations
    and how to use them in pipelines.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了不同类型的机器学习算法。我们看了各种监督和无监督算法，以及它们各自的示例。我们还看了FlinkML提供的各种实用工具，在数据分析过程中非常方便。后来我们看了数据预处理操作以及如何在管道中使用它们。
- en: In the following chapter, we will look at the graph-processing capabilities
    of Flink.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将看一下Flink的图处理能力。
