- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Enhancing Machine Learning Models Using Feature Selection
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用特征选择增强机器学习模型
- en: This chapter describes how genetic algorithms can be used to improve the performance
    of **supervised machine learning** models by selecting the best subset of features
    from the provided input data. We will start with a brief introduction to machine
    learning and then describe the two main types of supervised machine learning tasks
    – **regression** and **classification**. We will then discuss the potential benefits
    of **feature selection** when it comes to the performance of these models. Next,
    we will demonstrate how genetic algorithms can be utilized to pinpoint the genuine
    features that are generated by the **Friedman-1 Test** regression problem. Then,
    we will use the real-life **Zoo dataset** to create a classification model and
    improve its accuracy – again by applying genetic algorithms to isolate the best
    features for the task.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了如何通过遗传算法选择提供输入数据中的最佳特征，从而提高 **有监督机器学习** 模型的性能。我们将首先简要介绍机器学习，然后描述两种主要的有监督学习任务——**回归**
    和 **分类**。接着，我们将讨论在这些模型的性能方面，**特征选择**的潜在好处。随后，我们将演示如何利用遗传算法确定由 **Friedman-1 测试**
    回归问题生成的真正特征。然后，我们将使用真实的 **Zoo 数据集** 创建一个分类模型，并通过遗传算法来隔离任务的最佳特征，从而提高其准确性。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: Understand the basic concepts of supervised machine learning, as well as regression
    and classification tasks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解有监督机器学习的基本概念，以及回归和分类任务
- en: Understand the benefits of feature selection on the performance of supervised
    learning models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解特征选择对有监督学习模型性能的影响
- en: Enhance the performance of a regression model for the Friedman-1 Test regression
    problem, using feature selection carried out by a genetic algorithm coded with
    the DEAP framework
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用通过 DEAP 框架编码的遗传算法进行特征选择，增强 Friedman-1 测试回归问题的回归模型性能
- en: Enhance the performance of a classification model for the Zoo dataset classification
    problem, using feature selection carried out by a genetic algorithm coded with
    the DEAP framework
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用通过 DEAP 框架编码的遗传算法进行特征选择，增强 Zoo 数据集分类问题的分类模型性能
- en: We will start this chapter with a quick review of supervised machine learning.
    If you are a seasoned data scientist, feel free to skip the introductory sections.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从对有监督机器学习的快速回顾开始本章内容。如果你是经验丰富的数据科学家，可以跳过这些入门部分。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will be using Python 3 with the following supporting libraries:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用 Python 3 和以下支持库：
- en: '**deap**'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**deap**'
- en: '**numpy**'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**numpy**'
- en: '**pandas**'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pandas**'
- en: '**matplotlib**'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**matplotlib**'
- en: '**seaborn**'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**seaborn**'
- en: '**scikit-learn** – introduced in this chapter'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**scikit-learn** – 本章介绍'
- en: Important Note
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you use the **requirements.txt** file we provide (see [*Chapter 3*](B20851_03.xhtml#_idTextAnchor091)),
    these libraries are already included in your environment.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用我们提供的 **requirements.txt** 文件（参见 [*第 3 章*](B20851_03.xhtml#_idTextAnchor091)），这些库已经包含在你的环境中。
- en: In addition, we will be using the *UCI Zoo* *Dataset* ([https://archive.ics.uci.edu/ml/datasets/zoo](https://archive.ics.uci.edu/ml/datasets/zoo)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将使用 *UCI Zoo* *数据集*（[https://archive.ics.uci.edu/ml/datasets/zoo](https://archive.ics.uci.edu/ml/datasets/zoo)）。
- en: The programs that will be used in this chapter can be found in this book’s GitHub
    repository at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/tree/main/chapter_07](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/tree/main/chapter_07).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的程序可以在本书的 GitHub 仓库中找到，地址为 [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/tree/main/chapter_07](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/tree/main/chapter_07)。
- en: 'Check out the following video to see the code in action:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，看看代码是如何运行的：
- en: '[https://packt.link/OEBOd](https://packt.link/OEBOd).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/OEBOd](https://packt.link/OEBOd)。'
- en: Supervised machine learning
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有监督的机器学习
- en: The term **machine learning** typically refers to a computer program that receives
    input and produces output. Our goal is to train this program, also known as the
    **model**, to produce the correct output for the given input *without explicitly*
    *programming it*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习** 这个术语通常指的是一个接收输入并生成输出的计算机程序。我们的目标是训练这个程序，也称为 **模型**，使其能够对给定的输入生成正确的输出，*而无需明确*
    *编程*。'
- en: During this training process, the model learns the mapping between the inputs
    and the outputs by adjusting its internal parameters. One common way to train
    the model is by providing it with a set of inputs for which the correct output
    is known. For each of these inputs, we tell the model what the correct output
    is so that it can adjust, or tune itself, aiming to eventually produce the desired
    output for each of the given inputs. This tuning is at the heart of the learning
    process.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在此训练过程中，模型通过调整其内部参数来学习输入与输出之间的映射。训练模型的一种常见方法是为它提供一组已知正确输出的输入。对于这些输入，我们告诉模型正确的输出是什么，以便它可以调整或调优自己，最终为每个给定输入产生期望的输出。这种调优是学习过程的核心。
- en: 'Over the years, many types of machine learning models have been developed.
    Each model has its own particular internal parameters that can affect the mapping
    between the input and the output, and the values of these parameters can be tuned,
    as illustrated in the following diagram:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，已经开发出许多类型的机器学习模型。每种模型都有其独特的内部参数，这些参数可以影响输入与输出之间的映射，并且这些参数的值可以进行调整，如下图所示：
- en: '![Figure 7.1: Parameter tuning of a machine learning model](img/B20851_07_001.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图7.1：机器学习模型的参数调整](img/B20851_07_001.jpg)'
- en: 'Figure 7.1: Parameter tuning of a machine learning model'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：机器学习模型的参数调整
- en: 'For example, if the model was implementing a *decision tree*, it could contain
    several `IF- THEN` statements, which can be formulated as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果模型正在实现一个*决策树*，它可能包含几个`IF-THEN`语句，可以按如下方式表示：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this case, both the threshold value and the identity of the target branch
    are parameters that can be adjusted, or tuned, during the learning process.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，阈值和目标分支的身份都是可以在学习过程中调整或调优的参数。
- en: To tune the internal parameters, each type of model has an accompanying *learning
    algorithm* that iterates over the given input and output values and seeks to match
    the given output for each of the given inputs. To accomplish this goal, a typical
    learning algorithm will measure the difference (also called *error*, or more generally
    *loss*) between the actual output and the desired output; the algorithm will then
    attempt to minimize this error by adjusting the model’s internal parameters.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了调整内部参数，每种类型的模型都有一个相应的*学习算法*，该算法会遍历给定的输入和输出值，并尝试使每个输入的输出与给定的输出相匹配。为了实现这一目标，典型的学习算法会衡量实际输出与期望输出之间的差异（也称为*误差*，或更广义的*损失*）；然后，算法会通过调整模型的内部参数来最小化这个误差。
- en: The two main types of supervised machine learning are **classification** and
    **regression**, and will be described in the following subsections.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的两种主要类型是**分类**和**回归**，将在以下小节中进行描述。
- en: Classification
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类
- en: 'When carrying out a classification task, the model needs to decide which *category*
    a certain input belongs to. Each category is represented by a single output (called
    a **label**), while the inputs are called **features**:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行分类任务时，模型需要决定某个输入属于哪个*类别*。每个类别由一个单独的输出（称为**标签**）表示，而输入被称为**特征**：
- en: '![Figure 7.2: Machine learning classification model](img/B20851_07_002.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图7.2：机器学习分类模型](img/B20851_07_002.jpg)'
- en: 'Figure 7.2: Machine learning classification model'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：机器学习分类模型
- en: 'For example, in the well-known *Iris dataset* ([https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris)),
    there are four features: **Petal length**, **Petal width**, **Sepal length**,
    and **Sepal width**. These represent the measurements that have been manually
    taken of actual Iris flowers.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在著名的*鸢尾花数据集*（[https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris)）中，有四个特征：**花瓣长度**、**花瓣宽度**、**萼片长度**和**萼片宽度**。这些代表了实际鸢尾花的手动测量值。
- en: 'In terms of the output, there are three labels: **Iris setosa**, **Iris virginica**,
    and **Iris versicolor**. These represent the three different types of Iris in
    the dataset.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在输出方面，有三个标签：**鸢尾花Setosa**、**鸢尾花Virginica**和**鸢尾花Versicolor**。这些代表了数据集中三种不同类型的鸢尾花。
- en: 'When input values, which represent the measurements that were taken from a
    given Iris flower, are present we expect the output of the correct label to go
    high and the other two to go low:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入值代表从某个鸢尾花中获取的测量值时，我们期望正确标签的输出值变高，而其他两个标签的输出值变低：
- en: '![Figure 7.3: Iris Flower classifier illustrated](img/B20851_07_003.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图7.3：鸢尾花分类器示意图](img/B20851_07_003.jpg)'
- en: 'Figure 7.3: Iris Flower classifier illustrated'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：鸢尾花分类器示意图
- en: Classification tasks have a multitude of real-life applications, such as approval
    of bank loans and credit cards, email spam detection, handwritten digit recognition,
    and face recognition. Later in this chapter, we will be demonstrating the classification
    of animal types using the *Zoo dataset*.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 分类任务有许多现实生活中的应用，例如银行贷款和信用卡审批、电子邮件垃圾邮件检测、手写数字识别和人脸识别。本章后面将演示使用*动物园数据集*进行动物类型分类。
- en: The second main type of supervised machine learning, **regression**, will be
    described in the next subsection.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的第二种主要类型，**回归**，将在下一个子节中描述。
- en: Regression
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归
- en: 'In contrast to classification tasks, models for regression tasks map the input
    values into a **single output** to provide a continuous value, as illustrated
    in the following diagram:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 与分类任务相比，回归任务的模型将输入值映射为**单一输出**，以提供一个连续值，如下图所示：
- en: '![Figure 7.4: Machine learning regression model](img/B20851_07_004.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4：机器学习回归模型](img/B20851_07_004.jpg)'
- en: 'Figure 7.4: Machine learning regression model'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4：机器学习回归模型
- en: Given the input values, the model is expected to predict the correct value of
    the output.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 给定输入值，模型预计会预测输出的正确值。
- en: 'Real-life examples of regression include predicting the value of stocks, the
    quality of wine, or the market price of a house, as depicted in the following
    diagram:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 回归的实际应用实例包括预测股票价值、葡萄酒质量或房屋市场价格，如下图所示：
- en: '![Figure 7.5: House pricing regressor](img/B20851_07_005.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.5：房价回归模型](img/B20851_07_005.jpg)'
- en: 'Figure 7.5: House pricing regressor'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5：房价回归模型
- en: In the preceding image, the inputs are features that provide information that
    describes a given house, while the output is the predicted value of the house.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图像中，输入是描述给定房屋信息的特征，而输出是预测的房屋价值。
- en: Many types of models exist for carrying out classification and regression tasks
    – some of them are described in the following subsection.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多类型的模型用于执行分类和回归任务——其中一些将在下一个子节中描述。
- en: Supervised learning algorithms
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习算法
- en: As we mentioned previously, each supervised learning model consists of a set
    of internal tunable parameters and an algorithm that tunes these parameters in
    an attempt to achieve the required result.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，每个监督学习模型由一组内部可调参数和一个调整这些参数的算法组成，旨在实现所需结果。
- en: 'Some common supervised learning models/algorithms are as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的监督学习模型/算法如下：
- en: '**Support Vector Machines** (**SVMs**): Algorithms that map the given inputs
    as points in space so that the inputs that belong to separate categories are divided
    by the largest possible gap.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVMs**）：将给定输入映射为空间中的点，使得属于不同类别的输入通过尽可能大的间隔被分开。'
- en: '**Decision Trees**: A family of algorithms that utilize a tree-like graph,
    where branching points represent decisions and the branches represent their consequences.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树**：一类利用树状图的算法，其中分支点代表决策，分支代表其后果。'
- en: '**Random Forests**: Algorithms that create a large number of decision trees
    during the training phase and use a combination of their outputs.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林**：在训练阶段创建大量决策树，并使用它们输出的组合。'
- en: '**Artificial Neural Networks**: Models that consist of multiple simple nodes,
    or neurons, which can be interconnected in various ways. Each connection can have
    a weight that controls the level of the signal that’s carried from one neuron
    to the next.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工神经网络**：由多个简单节点或神经元组成的模型，这些神经元可以以不同方式互联。每个连接可以有一个权重，控制从一个神经元到下一个神经元的信号强度。'
- en: There are certain techniques that can be used to improve and enhance the performance
    of such models. One interesting technique – **feature selection** – will be discussed
    in the next section.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些技术可以用来提高和增强这些模型的性能。一种有趣的技术——**特征选择**——将在下一节中讨论。
- en: Feature selection in supervised learning
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习中的特征选择
- en: As we saw in the previous section, a supervised learning model receives a set
    of inputs, called **features**, and maps them to a set of outputs. The assumption
    is that the information described by the features is useful for determining the
    value of the corresponding outputs. At first glance, it may seem that the more
    information we can use as input, the better our chances of predicting the output(s)
    correctly. However, in many cases, the opposite holds true; if some of the features
    we use are irrelevant or redundant, the consequence could be a (sometimes significant)
    decrease in the accuracy of the models.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节所看到的，监督学习模型接收一组输入，称为**特征**，并将它们映射到一组输出。假设特征所描述的信息对于确定相应输出的值是有用的。乍一看，似乎我们使用的输入信息越多，正确预测输出的机会就越大。然而，在许多情况下，事实恰恰相反；如果我们使用的一些特征无关紧要或是冗余的，结果可能是模型准确性的（有时是显著的）下降。
- en: 'Feature selection is the process of selecting the most beneficial and essential
    set of features out of the entire given set of features. Besides increasing the
    accuracy of the model, a successful feature selection can provide the following
    advantages:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择是从给定的所有特征集中选择最有益和最重要的特征的过程。除了提高模型的准确性外，成功的特征选择还可以带来以下优势：
- en: The training times of the models are shorter.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的训练时间较短。
- en: The resulting trained models are simpler and easier to interpret.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果训练得到的模型更简单，更易于解释。
- en: The resulting models are likely to provide better generalization, that is, they
    perform better with new input data that is dissimilar to the data that was used
    for training.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果模型可能提供更好的泛化能力，也就是说，它们在处理与训练数据不同的新输入数据时表现更好。
- en: When looking at methods to carry out feature selection, genetic algorithms are
    a natural candidate. We will demonstrate how they can be applied to find the best
    features out of an artificially generated dataset in the next section.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看执行特征选择的方法时，遗传算法是一个自然的候选方法。我们将在下一节中演示如何将它们应用于从人工生成的数据集中找到最佳特征。
- en: Selecting the features for the Friedman-1 regression problem
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为Friedman-1回归问题选择特征
- en: 'The *Friedman-1* regression problem, which was created by Friedman and Breiman,
    describes a single output value, y , which is a function of five input values,
    x 0, x 1, x 2, x 3, x 4, and randomly generated noise, according to the following
    formula:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*Friedman-1*回归问题由Friedman和Breiman创建，描述了一个单一的输出值y，该值是五个输入值x 0、x 1、x 2、x 3、x
    4和随机生成噪声的函数，按照以下公式：'
- en: y(x 0, x 1, x 2, x 3, x 4)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: y(x 0, x 1, x 2, x 3, x 4)
- en: = 10 ∙ sin(π ∙ x 0 ∙ x 1) + 20 (x 2 − 0.5) 2 + 10 x 3 + 5 x 4 + noise
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: = 10 ∙ sin(π ∙ x 0 ∙ x 1) + 20 (x 2 − 0.5) 2 + 10 x 3 + 5 x 4 + 噪声
- en: ∙ N(0, 1)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ∙ N(0, 1)
- en: The input variables, x 0 . .x 4, are independent, and uniformly distributed
    over the interval [0, 1]. The last component in the formula is the randomly generated
    noise. The noise is **normally distributed** and multiplied by the constant *noise*,
    which determines its level.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 输入变量x 0 . .x 4是独立的，且在区间[0, 1]内均匀分布。公式中的最后一个组成部分是随机生成的噪声。噪声是**正态分布**的，并与常数*噪声*相乘，后者决定了噪声的水平。
- en: In Python, the `scikit-learn` (`sklearn`) library provides us with the `make_friedman1()`
    function, which can be used to generate a dataset containing the desired number
    of samples. Each of the samples consists of randomly generated x 0 . .x 4 values
    and their corresponding calculated y value. The interesting part, however, is
    that we can tell the function to add an arbitrary number of irrelevant input variables
    to the five original ones by setting the `n_features` parameter of the function
    to a value larger than five. If, for example, we set the value of `n_features`
    to 15, we will get a dataset containing the original five input variables (or
    features) that were used to generate the *y* values according to the preceding
    formula and an additional 10 features that are completely irrelevant to the output.
    This can be used, for example, to test the resilience of various regression models
    to noise and the presence of irrelevant features in the dataset.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，`scikit-learn`（`sklearn`）库提供了`make_friedman1()`函数，我们可以使用它来生成包含所需样本数量的数据集。每个样本由随机生成的x0...x4值及其对应的计算y值组成。然而，值得注意的是，我们可以通过将`n_features`参数设置为大于五的值，告诉函数向原来的五个特征中添加任意数量的无关输入变量。例如，如果我们将`n_features`的值设置为15，我们将得到一个包含原始五个输入变量（或特征）的数据集，这些特征根据前面的公式生成了*y*值，并且还有另外10个与输出完全无关的特征。这可以用于测试各种回归模型对噪声和数据集中无关特征存在的抗干扰能力。
- en: We can take advantage of this function to test the effectiveness of genetic
    algorithms as a feature selection mechanism. In our test, we will use the `make_friedman1()`
    function to create a dataset with 15 features and use the genetic algorithm to
    search for the subset of features that provides the best performance. As a result,
    we expect the genetic algorithm to pick the first five features and drop the rest,
    assuming that the model’s accuracy is better when only the relevant features are
    used as input. The fitness function of the genetic algorithm will utilize a regression
    model that, for each potential solution a subset of the original features will
    be trained using the dataset containing only the selected features.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用这个功能来测试遗传算法作为特征选择机制的有效性。在我们的测试中，我们将使用`make_friedman1()`函数创建一个包含15个特征的数据集，并使用遗传算法搜索提供最佳性能的特征子集。因此，我们预计遗传算法会选择前五个特征，并去除其余的特征，假设当仅使用相关特征作为输入时，模型的准确性会更好。遗传算法的适应度函数将使用回归模型，对于每一个潜在解，都会使用仅包含选择特征的数据集训练原始特征的子集。
- en: As usual, we will start by choosing an appropriate representation for the solution,
    as described in the next subsection.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们将从选择合适的解决方案表示开始，如下一小节所述。
- en: Solution representation
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案表示
- en: The objective of our algorithm is to find a subset of features that yield the
    best performance. Therefore, a solution needs to indicate which features are chosen
    and which are dropped. One obvious way to go about this is to represent each individual
    using a **list of binary values**. Every entry in that list corresponds to one
    of the features in the dataset. A value of 1 represents selecting the corresponding
    feature, while a value of 0 means that the feature has not been selected. This
    is very similar to the approach we used in the **knapsack 0-1 problem** we described
    in [*Chapter 4*](B20851_04.xhtml#_idTextAnchor155)*,* *Combinatorial Optimization*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们算法的目标是找到一个能够提供最佳性能的特征子集。因此，一个解决方案需要指示哪些特征被选择，哪些被丢弃。一个明显的方法是使用**二进制值列表**来表示每个个体。列表中的每一项对应数据集中的一个特征。值为1表示选择相应的特征，而值为0表示该特征未被选择。这与我们在[
    *第4章*](B20851_04.xhtml#_idTextAnchor155)*,* *组合优化*中描述的**背包0-1问题**方法非常相似。
- en: The presence of each 0 in the solution will be translated into dropping the
    corresponding feature’s data column from the dataset, as we will see in the next
    subsection.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案中每个0的存在将被转换为从数据集中删除相应特征的数据列，正如我们在下一小节中所看到的那样。
- en: Python problem representation
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python 问题表示
- en: To encapsulate the Friedman-1 feature selection problem, we’ve created a Python
    class called `Friedman1Test`. This class can be found in the `friedman.py` file,
    which is located at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/friedman.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/friedman.py).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了封装 Friedman-1 特征选择问题，我们创建了一个名为 `Friedman1Test` 的 Python 类。该类可以在 `friedman.py`
    文件中找到，文件位置在 [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/friedman.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/friedman.py)。
- en: 'The main parts of this class are as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 该类的主要部分如下：
- en: 'The **__init__()** method of the class creates the dataset, as follows:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类的 **__init__()** 方法创建了数据集，具体如下：
- en: '[PRE1]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, it divides the data into two subsets—a training set and a validation
    set—using the **scikit-learn** **model_selection.train_test_split()** method:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用 **scikit-learn** **model_selection.train_test_split()** 方法将数据划分为两个子集——训练集和验证集：
- en: '[PRE2]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Dividing the data into a **train set** and a **validation set** allows us to
    train the regression model on the train set, where the correct prediction is given
    to the model for training purposes, and then test it with the separate validation
    set, where the correct predictions are not given to the model and are, instead,
    compared to the predictions it produces. This way, we can test how well the model
    is able to generalize, rather than memorize, the training data.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将数据分为 **训练集** 和 **验证集**，使我们能够在训练集上训练回归模型，其中为训练提供正确的预测，然后在单独的验证集上测试模型，在验证集中不提供正确的预测，而是将其与模型产生的预测进行比较。通过这种方式，我们可以测试模型是否能够泛化，而不是仅仅记住训练数据。
- en: 'Next, we create the regression model, for which we chose the **Gradient Boosting
    Regressor** (**GBR**) type. This model creates an **ensemble** (or aggregation)
    of decision trees during the training phase:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建回归模型，并选择了 **梯度提升回归器** (**GBR**) 类型。该模型在训练阶段创建了一个 **集成**（或聚合）决策树：
- en: '[PRE3]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Important Note
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In our example, we are passing the random seed along so that it can be used
    internally by the regressor. This way, we can make sure the results that we obtain
    are repeatable.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们传递了随机种子，以便回归器可以在内部使用它。通过这种方式，我们可以确保得到的结果是可重复的。
- en: 'The **getMSE()** method of the class is used to determine the performance of
    our gradient-boosting regression model for a set of selected features. It accepts
    a list of binary values corresponding to the features in the dataset—a value of
    1 represents selecting the corresponding feature, while a value of 0 means that
    the feature is dropped. The method then deletes the columns in the training and
    validation sets that correspond to the unselected features:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类的 **getMSE()** 方法用于确定我们为一组选定特征训练的梯度提升回归模型的性能。它接受一个对应于数据集中各特征的二进制值列表——值为 1
    表示选择相应特征，值为 0 则表示该特征被丢弃。然后该方法删除训练集和验证集中与未选择特征对应的列：
- en: '[PRE4]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The modified train set—containing only the selected features—is then used to
    train the regressor, while the modified validation set is used to evaluate its
    predictions:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改后的训练集——仅包含所选特征——用于训练回归器，而修改后的验证集用于评估回归器的预测：
- en: '[PRE5]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The metric used here to evaluate the regressor is called the **mean square error**
    (**MSE**), which finds the average squared difference between the model’s predicted
    values and the actual values. A *lower* value of this measurement indicates *better*
    performance of the regressor.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里用于评估回归器的度量叫做 **均方误差** (**MSE**)，它计算模型预测值与实际值之间的平均平方差。该度量的 *较低* 值表示回归器的 *更好*
    性能。
- en: 'The **main()** method of the class creates an instance of the **Friedman1Test**
    class with 15 features. Then, it repeatedly uses the **getMSE()** method to evaluate
    the performance of the regressor with the first *n* features, while *n* is incremented
    from 1 to 15:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类的 **main()** 方法创建了一个包含 15 个特征的 **Friedman1Test** 类的实例。然后，它反复使用 **getMSE()**
    方法评估回归器在前 *n* 个特征上的性能，*n* 从 1 递增到 15：
- en: '[PRE6]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'When running the main method, the results show that, as we add the first five
    features one by one, the performance improves. However, afterward, each additional
    feature degrades the performance of the regressor:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行 main 方法时，结果显示，当我们逐一添加前五个特征时，性能有所提高。然而，之后每增加一个特征都会降低回归器的性能：
- en: '[PRE7]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This is further illustrated by the generated plot, showing the minimum MSE
    value where the first five features are used:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点通过生成的图表进一步说明，图中显示了使用前五个特征时的最小MSE值：
- en: '![Figure 7.6: Plot of error values for the Friedman-1 regression problem](img/B20851_07_006.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图7.6：Friedman-1回归问题的误差值图](img/B20851_07_006.jpg)'
- en: 'Figure 7.6: Plot of error values for the Friedman-1 regression problem'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：Friedman-1回归问题的误差值图
- en: In the next subsection, we will find out if a genetic algorithm can successfully
    identify these first five features.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们将探讨遗传算法是否能够成功识别这五个特征。
- en: Genetic algorithms solution
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 遗传算法解决方案
- en: To identify the best set of features to be used for our regression test using
    a genetic algorithm, we’ve created the Python program, `01_solve_friedman.py`,
    which is located at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/01_solve_friedman.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/01_solve_friedman.py).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用遗传算法识别回归测试中最优的特征集，我们创建了Python程序`01_solve_friedman.py`，可以在[https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/01_solve_friedman.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/01_solve_friedman.py)找到。
- en: As a reminder, the chromosome representation that’s being used here is a list
    of integers with values of 0 or 1, denoting whether a feature should be used or
    dropped. This makes our problem, from the point of view of the genetic algorithm,
    similar to the *OneMax* problem, or the *knapsack 0-1* problem we solved previously.
    The difference is in the fitness function returning the regression model’s MSE,
    which is calculated within the `Friedman1Test` class.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，这里使用的染色体表示是一个整数列表，值为0或1，表示某个特征是否应被使用或舍弃。从遗传算法的角度来看，这使得我们的任务类似于*OneMax*问题，或我们之前解决过的*背包0-1*问题。不同之处在于适应度函数返回的是回归模型的MSE，该值是在`Friedman1Test`类中计算的。
- en: 'The following steps describe the main parts of our solution:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤描述了我们解决方案的主要部分：
- en: 'First, we need to create an instance of the **Friedman1Test** class with the
    desired parameters:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个**Friedman1Test**类的实例，并设置所需的参数：
- en: '[PRE8]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Since our goal is to minimize the MSE of the regression model, we define a
    single objective, minimizing the fitness strategy:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们的目标是最小化回归模型的MSE，因此我们定义了一个单一目标，即最小化适应度策略：
- en: '[PRE9]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Since the solution is represented by a list of 0 or 1 integer values, we use
    the following toolbox definitions to create the initial population:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于解是通过一个0或1的整数值列表来表示的，因此我们使用以下工具箱定义来创建初始种群：
- en: '[PRE10]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, we instruct the genetic algorithm to use the **getMSE()** method of the
    **Friedman1Test** instance for fitness evaluation:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们指示遗传算法使用**Friedman1Test**实例的**getMSE()**方法来进行适应度评估：
- en: '[PRE11]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As for the genetic operators, we use *tournament selection* with a tournament
    size of 2 and *crossover* and *mutation* operators that are specialized for binary
    list chromosomes:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 至于遗传操作符，我们使用*锦标赛选择*（锦标赛规模为2），以及专门为二进制列表染色体设计的*交叉*和*变异*操作符：
- en: '[PRE12]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In addition, we continue to use the *elitist approach*, where the **hall of
    fame** (**HOF**) members – the current best individuals – are always passed untouched
    to the next generation:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，我们继续使用*精英主义方法*，即**名人堂**（**HOF**）成员——当前最优秀的个体——始终不变地传递到下一代：
- en: '[PRE13]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'By running the algorithm for 30 generations with a population size of 30, we
    get the following outcome:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行30代，种群大小为30，我们得到以下结果：
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This indicates that the first five features have been selected to provide the
    best MSE (about 6.7) for our test. Note that the genetic algorithm makes no assumptions
    about the set of features that it was looking for, meaning it did not know that
    we were looking for a subset of the first *n* features. It simply searched for
    the best possible subset of features.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明前五个特征被选择出来，以提供我们测试的最佳MSE（大约为6.7）。请注意，遗传算法并不假设它要找的特征集是什么，这意味着它并不知道我们在寻找前*n*个特征的子集。它仅仅是寻找最优的特征子集。
- en: In the next section, we will advance from using artificially generated data
    to an actual dataset, and utilize the genetic algorithm to select the best features
    for a classification problem.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将从使用人工生成的数据转向实际数据集，并利用遗传算法为分类问题选择最佳特征。
- en: Selecting the features for classifying the Zoo dataset
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为分类Zoo数据集选择特征
- en: The UCI Machine Learning Repository ([https://archive.ics.uci.edu/](https://archive.ics.uci.edu/))
    maintains over 600 datasets as a service to the machine learning community. These
    datasets can be used for experimentation with various models and algorithms. A
    typical dataset contains a number of features (inputs) and the desired output,
    in theform of columns, with a description of their meaning.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: UCI 机器学习库（[https://archive.ics.uci.edu/](https://archive.ics.uci.edu/)）为机器学习社区提供了超过
    600 个数据集。这些数据集可以用于不同模型和算法的实验。一个典型的数据集包含若干个特征（输入）和期望的输出，通常以列的形式呈现，并且会附有描述这些特征的含义。
- en: 'In this section, we will use the UCI Zoo dataset ([https://archive.ics.uci.edu/dataset/111/zoo](https://archive.ics.uci.edu/dataset/111/zoo)).
    This dataset describes 101 different animals using the following 18 features:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 UCI 动物园数据集（[https://archive.ics.uci.edu/dataset/111/zoo](https://archive.ics.uci.edu/dataset/111/zoo)）。此数据集描述了
    101 种不同的动物，使用以下 18 个特征：
- en: '| **No.** | **Feature Name** | **Data Type** |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| **编号** | **特征名称** | **数据类型** |'
- en: '| 1 | animal name | unique for each instance |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 动物名称 | 每个实例唯一 |'
- en: '| 2 | hair | boolean |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 毛发 | 布尔值 |'
- en: '| 3 | feathers | boolean |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 羽毛 | 布尔值 |'
- en: '| 4 | eggs | boolean |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 鸡蛋 | 布尔值 |'
- en: '| 5 | milk | boolean |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 牛奶 | 布尔值 |'
- en: '| 6 | airborne | boolean |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 空中 | 布尔值 |'
- en: '| 7 | aquatic | boolean |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 水生 | 布尔值 |'
- en: '| 8 | predator | boolean |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 捕食者 | 布尔值 |'
- en: '| 9 | toothed | boolean |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 有齿 | 布尔值 |'
- en: '| 10 | backbone | boolean |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 脊椎 | 布尔值 |'
- en: '| 11 | breathes | boolean |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 呼吸 | 布尔值 |'
- en: '| 12 | venomous | boolean |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 有毒 | 布尔值 |'
- en: '| 13 | fins | boolean |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 鳍 | 布尔值 |'
- en: '| 14 | legs | Numeric (set of values {0,2,4,5,6,8}) |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 腿数 | 数值型（值集合 {0,2,4,5,6,8}） |'
- en: '| 15 | tail | boolean |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 尾巴 | 布尔值 |'
- en: '| 16 | domestic | boolean |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 16 | 驯养 | 布尔值 |'
- en: '| 17 | catsize | boolean |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 17 | 猫大小 | 布尔值 |'
- en: '| 18 | type | numeric (integer values in the range [1..7]) |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 18 | 类型 | 数值型（整数值范围 [1..7]） |'
- en: 'Table 7.1: Feature list for the Zoo dataset'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7.1：动物园数据集的特征列表
- en: Most features are `Boolean` (value of 1 or 0), indicating the presence or absence
    of a certain attribute, such as `hair`, `fins`, and so on. The first feature,
    `animal name`, is just to provide us with added information and does not participate
    in the learning process.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数特征是 `布尔值`（1 或 0），表示某种属性的存在或不存在，如 `毛发`、`鳍` 等。第一个特征，`动物名称`，仅提供附加信息，不参与学习过程。
- en: This dataset is used for testing classification tasks, where the input features
    need to be mapped into two or more categories/labels. In this dataset, the last
    feature, called `type`, represents the category and is used as the `type` value
    of `5`, for instance, represents the animal category that includes frog, newt,
    and toad.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集用于测试分类任务，其中输入特征需要映射到两个或更多的类别/标签。在这个数据集中，最后一个特征，称为 `类型`，表示类别，例如，`类型` 值为 `5`
    表示包括青蛙、蝾螈和蟾蜍在内的动物类别。
- en: To sum this up, a classification model trained with this dataset will use features
    2–17 (`hair`, `feathers`, `fins`, and so on) to predict the value of feature 18
    (animal `type`).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，使用此数据集训练的分类模型将使用特征 2-17（`毛发`、`羽毛`、`鳍` 等）来预测特征 18（动物 `类型`）的值。
- en: Once again, we want to use a genetic algorithm to select the features that will
    give us the best predictions. Let’s start by creating a Python class that represents
    a classifier that’s been trained with this dataset.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次希望使用遗传算法来选择能够给出最佳预测的特征。我们从创建一个代表分类器的 Python 类开始，该分类器已通过此数据集进行训练。
- en: Python problem representation
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python 问题表示
- en: 'To encapsulate the feature selection process for the Zoo dataset classification
    task, we’ve created a Python class called `Zoo`. This class is contained in the
    `zoo.py` file, which is located at:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了封装动物园数据集分类任务中的特征选择过程，我们创建了一个名为 `Zoo` 的 Python 类。这个类位于 `zoo.py` 文件中，文件路径为：
- en: '[https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/zoo.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/zoo.py)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/zoo.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/zoo.py)'
- en: 'The main parts of this class are highlighted as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类的主要部分如下所示：
- en: 'The **__init__()** method of the class loads the Zoo dataset from the web while
    skipping the first feature—**animal** **name**—as follows:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类的 **__init__()** 方法从网络加载动物园数据集，同时跳过第一个特征——**动物名称**，具体如下：
- en: '[PRE15]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, it separates the data to input features (first remaining 16 columns)
    and the resulting category (last column):'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它将数据分离为输入特征（前16列）和结果类别（最后一列）：
- en: '[PRE16]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Instead of just separating the data into a training set and a test set, like
    we did in the previous section, we’re using **k-fold cross-validation**. This
    means that the data is split into *k* equal parts and the model is evaluated *k*
    times, each time using *(k-1)* parts for training and the remaining part for testing
    (or *validation*). This is easy to do in Python using the **scikit-learn** library’s
    **model_selection.KFold()** method:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们不再像上一节那样仅将数据分割为训练集和测试集，而是使用**k折交叉验证**。这意味着数据被分割成**k**个相等的部分，每次评估时，使用**(k-1)**部分作为训练集，剩余部分作为测试集（或**验证集**）。在Python中，可以使用**scikit-learn**库的**model_selection.KFold()**方法轻松实现：
- en: '[PRE17]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, we create a classification model based on a **decision tree**. This type
    of classifier creates a tree structure during the training phase that splits the
    dataset into smaller subsets, eventually resulting in a prediction:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们基于**决策树**创建一个分类模型。这种类型的分类器在训练阶段创建一个树形结构，将数据集分割成更小的子集，最终生成一个预测：
- en: '[PRE18]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Important Note
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We are passing a random seed so that it can be used internally by the classifier.
    This way, we can make sure the results that are obtained are repeatable.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传递一个随机种子，以便它可以被分类器内部使用。这样，我们可以确保获得的结果是可重复的。
- en: 'The **getMeanAccuracy()** method of the class is used to evaluate the performance
    of the classifier for a set of selected features. Similar to the **getMSE()**
    method in the **Friedman1Test** class, this method accepts a list of binary values
    corresponding to the features in the dataset—a value of **1** represents selecting
    the corresponding feature, while a value of **0** means that the feature is dropped.
    The method then drops the columns in the dataset that correspond to the unselected
    features:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类的**getMeanAccuracy()**方法用于评估分类器在一组选定特征下的性能。类似于**Friedman1Test**类中的**getMSE()**方法，该方法接受一个与数据集中的特征对应的二进制值列表——值为**1**表示选择了对应的特征，而值为**0**表示丢弃该特征。该方法随后丢弃数据集中与未选择特征对应的列：
- en: '[PRE19]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This modified dataset—containing only the selected features—is then used to
    perform the **k-fold cross-validation** process and determine the classifier’s
    performance over the data partitions. The value of **k** in our class is set to
    **5**, so five evaluations take place each time:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个修改后的数据集——仅包含选定的特征——随后用于执行**k折交叉验证**过程，并确定分类器在数据分区上的表现。我们类中的**k**值设置为**5**，因此每次进行五次评估：
- en: '[PRE20]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The metric that’s being used here to evaluate the classifier is accuracy—the
    portion of the cases that were classified correctly. An accuracy of 0.85, for
    example, means that 85% of the cases were classified correctly. Since, in our
    case, we train and evaluate the classifier *k* times, we use the average (mean)
    accuracy value that was obtained over these evaluations.
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里用来评估分类器的指标是准确度——即分类正确的案例所占的比例。例如，准确度为0.85，意味着85%的案例被正确分类。由于在我们的情况下，我们训练并评估分类器**k**次，因此我们使用在这些评估中获得的平均（均值）准确度值。
- en: 'The main method of the class creates an instance of the **Zoo** class and evaluates
    the classifier with all 16 features that are present using the all-one solution
    representation:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类的主方法创建了一个**Zoo**类的实例，并使用全一解决方案表示法评估所有16个特征的分类器：
- en: '[PRE21]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'When running the main method of the class, the printout shows that, after testing
    our classifier with 5-fold cross-validation using all 16 features, the classification
    accuracy that’s achieved is about 91%:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行类的主方法时，输出显示，在使用所有16个特征进行5折交叉验证测试我们的分类器后，获得的分类准确度大约为91%：
- en: '[PRE22]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In the next subsection, we will attempt to improve the accuracy of the classifier
    by selecting a subset of features from the dataset, instead of using all the features.
    We will use—you guessed it—a genetic algorithm to select these features for us.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个小节中，我们将尝试通过从数据集中选择一个特征子集来提高分类器的准确性，而不是使用所有特征。我们将使用——你猜对了——遗传算法来为我们选择这些特征。
- en: Genetic algorithms solution
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 遗传算法解决方案
- en: To identify the best set of features to be used for our Zoo classification task
    using a genetic algorithm, we’ve created the Python program `02_solve_zoo.py`,
    which is located at [https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/02_solve_zoo.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/02_solve_zoo.py).
    As in the previous section, the chromosome representation that’s being used here
    is a list of integers with the values of `0` or `1`, denoting whether a feature
    should be used or dropped.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用遗传算法确定用于Zoo分类任务的最佳特征集，我们创建了Python程序`02_solve_zoo.py`，该程序位于[https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/02_solve_zoo.py](https://github.com/PacktPublishing/Hands-On-Genetic-Algorithms-with-Python-Second-Edition/blob/main/chapter_07/02_solve_zoo.py)。与前一节一样，这里使用的染色体表示是一个整数列表，值为`0`或`1`，表示某个特征是否应被使用或丢弃。
- en: 'The following steps highlight the main parts of the program:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤突出了程序的主要部分：
- en: 'First, we need to create an instance of the **Zoo** class and pass our random
    seed along for the sake of producing repeatable results:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个**Zoo**类的实例，并传递我们的随机种子，以确保结果可重复：
- en: '[PRE23]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Since our goal is to maximize the accuracy of the classifier model, we define
    a single objective, maximizing the fitness strategy:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们的目标是最大化分类器模型的准确性，我们定义了一个单一目标，即最大化适应度策略：
- en: '[PRE24]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Just like in the previous section, we use the following toolbox definitions
    to create the initial population of individuals, each constructed as a list of
    **0** or **1** integer values:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就像在前一节中一样，我们使用以下工具箱定义来创建初始种群，每个个体由**0**或**1**整数值组成：
- en: '[PRE25]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Then, we instruct the genetic algorithm to use the **getMeanAccuracy()** method
    of the **Zoo** instance for fitness evaluation. To do this, we have to make two
    modifications:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们指示遗传算法使用**Zoo**实例的**getMeanAccuracy()**方法进行适应度评估。为此，我们需要进行两个修改：
- en: We eliminate the possibility of no features being selected (all-zeros individual)
    since our classifier will throw an exception in such a case.
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们排除了未选择任何特征（全零个体）的可能性，因为在这种情况下我们的分类器将抛出异常。
- en: 'We add a small *penalty* for each feature being used to encourage the selection
    of fewer features. The penalty value is very small (0.001), so it only comes into
    play as a tie-breaker between two equally performing classifiers, leading the
    algorithm to prefer the one that uses fewer features:'
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们对每个被使用的特征添加一个小的*惩罚*，以鼓励选择较少的特征。惩罚值非常小（0.001），因此它仅在两个表现相同的分类器之间起到决胜作用，导致算法偏好使用较少特征的分类器：
- en: '[PRE26]'
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'For the genetic operators, we again use **tournament selection** with a tournament
    size of **2** and **crossover** and **mutation** operators that are specialized
    for binary list chromosomes:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于遗传算子，我们再次使用**锦标赛选择**，锦标赛大小为**2**，并且使用专门针对二进制列表染色体的**交叉**和**变异**算子：
- en: '[PRE27]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'And once again, we continue to use the **elitist approach**, where HOF members—the
    current best individuals—are always passed untouched to the next generation:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，我们继续使用**精英主义方法**，即HOF成员——当前最佳个体——总是被直接传递到下一代，而不做改变：
- en: '[PRE28]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'At the end of the run, we print out all the members of the HOF so that we can
    see the top results that were found by the algorithm. We print both the fitness
    value, which includes the penalty for the number of features, and the actual accuracy
    value:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在运行结束时，我们打印出HOF的所有成员，以便查看算法找到的最佳结果。我们打印出适应度值（包括特征数量的惩罚）和实际的准确度值：
- en: '[PRE29]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'By running the algorithm for 50 generations with a population size of 50 and
    HOF size of 5, we get the following outcome:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行该算法50代，种群大小为50，HOF大小为5，我们得到了以下结果：
- en: '[PRE30]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'These results indicate that all five top solutions achieved an accuracy value
    of 97%, using either six or seven features out of the available 16\. Thanks to
    the penalty factor on a number of features, the top solution is the set of six
    features, which are as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果表明，所有五个最佳解的准确率值均达到了97%，使用的是从可用的16个特征中选择的六个或七个特征。由于对特征数量的惩罚因素，最佳解是由六个特征组成，具体如下：
- en: '**feathers**'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**羽毛**'
- en: '**milk**'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**牛奶**'
- en: '**airborne**'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空中**'
- en: '**backbone**'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**脊柱**'
- en: '**fins**'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**鳍**'
- en: '**tail**'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尾巴**'
- en: In conclusion, by selecting these particular features out of the 16 given in
    the dataset, not only did we reduce the dimensionality of the problem, but we
    were also able to improve our model’s accuracy from 91% to 97%. If this does not
    seem like a large enhancement at first glance, think of it as reducing the error
    rate from 9% to 3% – a very significant improvement in terms of classification
    performance.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 总结而言，通过从数据集中选择这16个特定特征，我们不仅减少了问题的维度，还成功地将模型的准确率从91%提高到了97%。如果乍一看这似乎不是一个巨大的提升，那么可以把它看作是将错误率从9%降低到3%——在分类性能方面，这是一个非常显著的改进。
- en: Summary
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you were introduced to machine learning and the two main types
    of supervised machine learning tasks – *regression* and *classification*. Then,
    you were presented with the potential benefits of *feature selection* on the performance
    of the models carrying out these tasks. At the heart of this chapter were two
    demonstrations of how genetic algorithms can be utilized to enhance the performance
    of such models via feature selection. In the first case, we pinpointed the genuine
    features that were generated by the *Friedman-1 Test* regression problem, while,
    in the other case, we selected the most beneficial features of the *Zoo* *classification
    dataset*.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，您将了解到机器学习以及两种主要的有监督机器学习任务——*回归*和*分类*。然后，您将了解到*特征选择*在执行这些任务的模型性能中的潜在好处。本章的核心内容是通过遗传算法如何利用特征选择来提升模型性能的两个演示。在第一个案例中，我们确定了由*Friedman-1测试*回归问题生成的真实特征，而在另一个案例中，我们选择了*Zoo*
    *分类数据集*中最有益的特征。
- en: In the next chapter, we will look at another possible way of enhancing the performance
    of supervised machine learning models, namely **hyperparameter tuning**.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨另一种可能的方式来提升有监督机器学习模型的性能，即**超参数调优**。
- en: Further reading
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'For more information about the topics that were covered in this chapter, please
    refer to the following resources:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解本章所涉及的更多内容，请参考以下资源：
- en: '*Applied Supervised Learning with Python*, Benjamin Johnston and Ishita Mathur,
    April 26, 2019'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Python应用监督学习*，Benjamin Johnston 和 Ishita Mathur，2019年4月26日'
- en: '*Feature Engineering Made Easy*, Sinan Ozdemir and Divya Susarla, January 22,
    2018'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征工程简明指南*，Sinan Ozdemir 和 Divya Susarla，2018年1月22日'
- en: '*Feature selection for classification*, M.Dash and H.Liu, 1997: [https://doi.org/10.1016/S1088-467X(97)00008-5](https://www.sciencedirect.com/science/article/abs/pii/S1088467X97000085?via%3Dihub)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分类特征选择*，M.Dash 和 H.Liu，1997年：[https://doi.org/10.1016/S1088-467X(97)00008-5](https://www.sciencedirect.com/science/article/abs/pii/S1088467X97000085?via%3Dihub)'
- en: '*UCI Machine Learning* *Repository*: [https://archive.ics.uci.edu/](https://archive.ics.uci.edu/)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*UCI机器学习* *数据集库*：[https://archive.ics.uci.edu/](https://archive.ics.uci.edu/)'
