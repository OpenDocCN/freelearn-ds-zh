- en: Chapter 5. Introducing MLlib
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。介绍MLlib
- en: In the previous chapter, we learned how to prepare the data for modeling. In
    this chapter, we will actually use some of that learning to build a classification
    model using the MLlib package of PySpark.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何为建模准备数据。在本章中，我们将实际使用这些知识来构建一个使用PySpark的MLlib包的分类模型。
- en: MLlib stands for Machine Learning Library. Even though MLlib is now in a maintenance
    mode, that is, it is not actively being developed (and will most likely be deprecated
    later), it is warranted that we cover at least some of the features of the library.
    In addition, MLlib is currently the only library that supports training models
    for streaming.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib代表机器学习库。尽管MLlib目前处于维护模式，即它不再积极开发（并且很可能会被弃用），但我们仍然有必要介绍该库的一些功能。此外，MLlib是目前唯一支持训练流模型（streaming）的库。
- en: Note
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Starting with Spark 2.0, ML is the main machine learning library that operates
    on DataFrames instead of RDDs as is the case for MLlib.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 从Spark 2.0开始，ML是主要的机器学习库，它操作的是DataFrame而不是RDD，这与MLlib的情况不同。
- en: 'The documentation for `MLlib` can be found here: [http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html).'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '`MLlib`的文档可以在这里找到：[http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html)。'
- en: 'In this chapter, you will learn how to do the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习以下内容：
- en: Prepare the data for modeling with MLlib
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MLlib准备建模数据
- en: Perform statistical testing
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行统计测试
- en: Predict survival chances of infants using logistic regression
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用逻辑回归预测婴儿的生存机会
- en: Select the most predictable features and train a random forest model
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择最可预测的特征并训练随机森林模型
- en: Overview of the package
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 包含概述
- en: 'At the high level, MLlib exposes three core machine learning functionalities:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，MLlib暴露了三个核心机器学习功能：
- en: '**Data preparation**: Feature extraction, transformation, selection, hashing
    of categorical features, and some natural language processing methods'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据准备**：特征提取、转换、选择、分类特征的哈希以及一些自然语言处理方法'
- en: '**Machine learning algorithms**: Some popular and advanced regression, classification,
    and clustering algorithms are implemented'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习算法**：实现了某些流行的和高级的回归、分类和聚类算法'
- en: '**Utilities**: Statistical methods such as descriptive statistics, chi-square
    testing, linear algebra (sparse and dense matrices and vectors), and model evaluation
    methods'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实用工具**：描述性统计、卡方检验、线性代数（稀疏和密集矩阵和向量）以及模型评估方法'
- en: As you can see, the palette of available functionalities allows you to perform
    almost all of the fundamental data science tasks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，可用的功能调色板允许您执行几乎所有基本的数据科学任务。
- en: 'In this chapter, we will build two classification models: a linear regression
    and a random forest. We will use a portion of the US 2014 and 2015 birth data
    we downloaded from [http://www.cdc.gov/nchs/data_access/vitalstatsonline.htm](http://www.cdc.gov/nchs/data_access/vitalstatsonline.htm);
    from the total of 300 variables we selected 85 features that we will use to build
    our models. Also, out of the total of almost 7.99 million records, we selected
    a balanced sample of 45,429 records: 22,080 records where infants were reported
    dead and 23,349 records with infants alive.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将构建两个分类模型：线性回归和随机森林。我们将使用我们从[http://www.cdc.gov/nchs/data_access/vitalstatsonline.htm](http://www.cdc.gov/nchs/data_access/vitalstatsonline.htm)下载的美国2014年和2015年出生数据的一部分；从总共300个变量中我们选择了85个特征来构建我们的模型。此外，从近799万条记录中，我们选择了45,429条平衡样本：22,080条记录报告婴儿死亡，23,349条记录婴儿存活。
- en: Tip
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: The dataset we will use in this chapter can be downloaded from [http://www.tomdrabas.com/data/LearningPySpark/births_train.csv.gz](http://www.tomdrabas.com/data/LearningPySpark/births_train.csv.gz).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将使用的数据集可以从[http://www.tomdrabas.com/data/LearningPySpark/births_train.csv.gz](http://www.tomdrabas.com/data/LearningPySpark/births_train.csv.gz)下载。
- en: Loading and transforming the data
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据和转换数据
- en: Even though MLlib is designed with RDDs and DStreams in focus, for ease of transforming
    the data we will read the data and convert it to a DataFrame.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管MLlib的设计重点是RDD和DStreams，为了便于转换数据，我们将读取数据并将其转换为DataFrame。
- en: Note
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The DStreams are the basic data abstraction for Spark Streaming (see [http://bit.ly/2jIDT2A](http://bit.ly/2jIDT2A))
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: DStreams是Spark Streaming的基本数据抽象（见[http://bit.ly/2jIDT2A](http://bit.ly/2jIDT2A)）
- en: Just like in the previous chapter, we first specify the schema of our dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在前一章中一样，我们首先指定数据集的模式。
- en: Note
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Note that here (for brevity), we only present a handful of features. You should
    always check our GitHub account for this book for the latest version of the code:
    [https://github.com/drabastomek/learningPySpark](https://github.com/drabastomek/learningPySpark).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这里（为了简洁），我们只展示了少量特征。你应该始终检查我们GitHub账户上这本书的最新代码版本：[https://github.com/drabastomek/learningPySpark](https://github.com/drabastomek/learningPySpark)。
- en: 'Here''s the code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we load the data. The `.read.csv(...)` method can read either uncompressed
    or (as in our case) GZipped comma-separated values. The `header` parameter set
    to `True` indicates that the first row contains the header, and we use the `schema`
    to specify the correct data types:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们加载数据。`.read.csv(...)`方法可以读取未压缩的或（如我们的情况）GZipped逗号分隔值。`header`参数设置为`True`表示第一行包含标题，我们使用`schema`来指定正确的数据类型：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: There are plenty of features in our dataset that are strings. These are mostly
    categorical variables that we need to somehow convert to a numeric form.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集中有很多字符串类型的特点。这些大多是类别变量，我们需要以某种方式将它们转换为数值形式。
- en: Tip
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'You can glimpse over the original file schema specification here: [ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Dataset_Documentation/DVS/natality/UserGuide2015.pdf](ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Dataset_Documentation/DVS/natality/UserGuide2015.pdf).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里查看原始文件的模式规范：[ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Dataset_Documentation/DVS/natality/UserGuide2015.pdf](ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Dataset_Documentation/DVS/natality/UserGuide2015.pdf)。
- en: 'We will first specify our recode dictionary:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将指定我们的重编码字典：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Our goal in this chapter is to predict whether the `''INFANT_ALIVE_AT_REPORT''`
    is either `1` or `0`. Thus, we will drop all of the features that relate to the
    infant and will try to predict the infant''s chances of surviving only based on
    the features related to its mother, father, and the place of birth:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是预测`'INFANT_ALIVE_AT_REPORT'`是`1`还是`0`。因此，我们将删除所有与婴儿相关的特征，并尝试仅基于与母亲、父亲和出生地相关的特征来预测婴儿的生存机会：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In our dataset, there are plenty of features with Yes/No/Unknown values; we
    will only code `Yes` to `1`; everything else will be set to `0`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的数据集中，有很多具有是/否/未知值的特征；我们只将“是”编码为`1`；其他所有内容都将设置为`0`。
- en: 'There is also a small problem with how the number of cigarettes smoked by the
    mother was coded: as 0 means the mother smoked no cigarettes before or during
    the pregnancy, between 1-97 states the actual number of cigarette smoked, 98 indicates
    either 98 or more, whereas 99 identifies the unknown; we will assume the unknown
    is 0 and recode accordingly.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 关于母亲吸烟数量编码的小问题：0表示母亲在怀孕前或怀孕期间没有吸烟，1-97表示实际吸烟的数量，98表示98或更多，而99表示未知；我们将假设未知为0，并相应地进行重编码。
- en: 'So next we will specify our recoding methods:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，接下来我们将指定我们的重编码方法：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `recode` method looks up the correct key from the `recode_dictionary` (given
    the `key`) and returns the corrected value. The `correct_cig` method checks when
    the value of the feature `feat` is not equal to 99 and (for that situation) returns
    the value of the feature; if the value is equal to 99, we get 0 otherwise.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`recode`方法从`recode_dictionary`（给定`key`）中查找正确的键并返回修正后的值。`correct_cig`方法检查特征`feat`的值是否不等于99，并且（对于这种情况）返回特征的值；如果值等于99，则返回0，否则返回。'
- en: 'We cannot use the `recode` function directly on a `DataFrame`; it needs to
    be converted to a UDF that Spark will understand. The `rec_integer` is such a
    function: by passing our specified `recode` function and specifying the return
    value data type, we can use it then to encode our Yes/No/Unknown features.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能直接在`DataFrame`上使用`recode`函数；它需要转换为Spark可以理解的UDF。`rec_integer`就是这样一种函数：通过传递我们指定的重编码函数并指定返回值数据类型，我们可以使用它来编码我们的是/否/未知特征。
- en: 'So, let''s get to it. First, we''ll correct the features related to the number
    of cigarettes smoked:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们开始吧。首先，我们将纠正与吸烟数量相关的特征：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `.withColumn(...)` method takes the name of the column as its first parameter
    and the transformation as the second one. In the previous cases, we do not create
    new columns, but reuse the same ones instead.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`.withColumn(...)`方法将其第一个参数作为列名，第二个参数作为转换。在前面的例子中，我们没有创建新列，而是重用了相同的列。'
- en: 'Now we will focus on correcting the Yes/No/Unknown features. First, we will
    figure out which these are with the following snippet:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将专注于纠正 Yes/No/Unknown 特征。首先，我们将通过以下片段来确定这些特征：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: First, we created a list of tuples (`cols`) that hold column names and corresponding
    data types. Next, we loop through all of these and calculate distinct values of
    all string columns; if a `'Y'` is within the returned list, we append the column
    name to the `YNU_cols` list.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建了一个包含列名和对应数据类型的元组列表（`cols`）。接下来，我们遍历所有这些，计算所有字符串列的唯一值；如果返回列表中包含 `'Y'`，我们将列名追加到
    `YNU_cols` 列表中。
- en: 'DataFrames can transform the features in bulk while selecting features. To
    present the idea, consider the following example:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrames 可以在选择特征的同时批量转换特征。为了说明这个概念，考虑以下示例：
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here''s what we get in return:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的返回结果：
- en: '![Loading and transforming the data](img/B05793_05_01.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![加载和转换数据](img/B05793_05_01.jpg)'
- en: We select the `'INFANT_NICU_ADMISSION'` column and we pass the name of the feature
    to the `rec_integer` method. We also alias the newly transformed column as `'INFANT_NICU_ADMISSION_RECODE'`.
    This way we will also confirm that our UDF works as intended.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择 `'INFANT_NICU_ADMISSION'` 列，并将特征的名称传递给 `rec_integer` 方法。我们还把新转换的列别名为 `'INFANT_NICU_ADMISSION_RECODE'`。这样我们也将确认我们的
    UDF 是按预期工作的。
- en: 'So, to transform all the `YNU_cols` in one go, we will create a list of such
    transformations, as shown here:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了一次性转换所有的 `YNU_cols`，我们将创建一个这样的转换列表，如下所示：
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s check if we got it correctly:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查我们是否正确理解了：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here''s what we get:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的结果：
- en: '![Loading and transforming the data](img/B05793_05_02.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![加载和转换数据](img/B05793_05_02.jpg)'
- en: Looks like everything worked as we wanted it to work, so let's get to know our
    data better.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来一切如我们所愿地工作，所以让我们更好地了解我们的数据。
- en: Getting to know your data
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解你的数据
- en: In order to build a statistical model in an informed way, an intimate knowledge
    of the dataset is necessary. Without knowing the data it is possible to build
    a successful model, but it is then a much more arduous task, or it would require
    more technical resources to test all the possible combinations of features. Therefore,
    after spending the required 80% of the time cleaning the data, we spend the next
    15% getting to know it!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了以有信息的方式构建统计模型，需要对数据集有深入了解。不知道数据，你仍然可以构建一个成功的模型，但这将是一个更加艰巨的任务，或者需要更多的技术资源来测试所有可能的特征组合。因此，在花费了所需
    80% 的时间清理数据之后，我们接下来花费 15% 的时间来了解它！
- en: Descriptive statistics
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述性统计
- en: I normally start with descriptive statistics. Even though the DataFrames expose
    the `.describe()` method, since we are working with `MLlib`, we will use the `.colStats(...)`
    method.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常从描述性统计开始。尽管 DataFrames 提供了 `.describe()` 方法，但由于我们正在使用 `MLlib`，我们将使用 `.colStats(...)`
    方法。
- en: Note
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: 'A word of warning: the `.colStats(...)` calculates the descriptive statistics
    based on a sample. For real world datasets this should not really matter but if
    your dataset has less than 100 observations you might get some strange results.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一个警告：`.colStats(...)` 是基于样本计算描述性统计的。对于现实世界的数据集，这实际上不应该很重要，但如果你的数据集观察值少于 100，你可能会得到一些奇怪的结果。
- en: 'The method takes an `RDD` of data to calculate the descriptive statistics of
    and return a `MultivariateStatisticalSummary` object that contains the following
    descriptive statistics:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法接受一个用于计算描述性统计的 `RDD` 数据，并返回一个包含以下描述性统计的 `MultivariateStatisticalSummary`
    对象：
- en: '`count()`: This holds a row count'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`count()`: 这包含行数'
- en: '`max()`: This holds maximum value in the column'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max()`: 这包含列中的最大值'
- en: '`mean():` This holds the value of the mean for the values in the column'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mean()`: 这包含列中值的平均值'
- en: '`min()`: This holds the minimum value in the column'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min()`: 这包含列中的最小值'
- en: '`normL1()`: This holds the value of the L1-Norm for the values in the column'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normL1()`: 这包含列中值的 L1-Norm 值'
- en: '`normL2()`: This holds the value of the L2-Norm for the values in the column'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normL2()`: 这包含列中值的 L2-Norm 值'
- en: '`numNonzeros()`: This holds the number of nonzero values in the column'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numNonzeros()`: 这包含列中非零值的数量'
- en: '`variance()`: This holds the value of the variance for the values in the column'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variance()`: 这包含列中值的方差'
- en: Note
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: You can read more about the L1- and L2-norms here [http://bit.ly/2jJJPJ0](http://bit.ly/2jJJPJ0)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里了解更多关于 L1-和 L2-范数的知识 [http://bit.ly/2jJJPJ0](http://bit.ly/2jJJPJ0)
- en: 'We recommend checking the documentation of Spark to learn more about these.
    The following is a snippet that calculates the descriptive statistics of the numeric
    features:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议检查 Spark 的文档以了解更多信息。以下是一个计算数值特征描述性统计的代码片段：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding code produces the following result:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下结果：
- en: '![Descriptive statistics](img/B05793_05_03.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![描述性统计](img/B05793_05_03.jpg)'
- en: 'As you can see, mothers, compared to fathers, are younger: the average age
    of mothers was 28 versus over 44 for fathers. A good indication (at least for
    some of the infants) was that many mothers quit smoking while being pregnant;
    it is horrifying, though, that there still were some that continued smoking.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，与父亲相比，母亲更年轻：母亲的平均年龄为 28 岁，而父亲的平均年龄超过 44 岁。一个很好的迹象（至少对于一些婴儿来说）是许多母亲在怀孕期间戒烟；尽管如此，仍然有一些人继续吸烟，这令人震惊。
- en: 'For the categorical variables, we will calculate the frequencies of their values:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类变量，我们将计算其值的频率：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here is what the results look like:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果看起来像什么：
- en: '![Descriptive statistics](img/B05793_05_04.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![描述性统计](img/B05793_05_04.jpg)'
- en: 'Most of the deliveries happened in hospital (`BIRTH_PLACE` equal to `1`). Around
    550 deliveries happened at home: some intentionally (`''BIRTH_PLACE''` equal to
    `3`), and some not (`''BIRTH_PLACE''` equal to `4`).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数分娩发生在医院（`BIRTH_PLACE` 等于 `1`）。大约有 550 次分娩发生在家里：一些是故意发生的（`'BIRTH_PLACE'` 等于
    `3`），一些则不是（`'BIRTH_PLACE'` 等于 `4`）。
- en: Correlations
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关系数
- en: 'Correlations help to identify collinear numeric features and handle them appropriately.
    Let''s check the correlations between our features:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 相关系数有助于识别共线性数值特征并适当处理它们。让我们检查特征之间的相关性：
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding code will calculate the correlation matrix and will print only
    those features that have a correlation coefficient greater than `0.5`: the `corrs
    > 0.5` part takes care of that.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码将计算相关矩阵，并且只打印出那些相关系数大于 `0.5` 的特征：`corrs > 0.5` 这一部分负责这个。
- en: 'Here''s what we get:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的结果：
- en: '![Correlations](img/B05793_05_05.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![相关性](img/B05793_05_05.jpg)'
- en: 'As you can see, the `''CIG_...''` features are highly correlated, so we can
    drop most of them. Since we want to predict the survival chances of an infant
    as soon as possible, we will keep only the `''CIG_1_TRI''`. Also, as expected,
    the weight features are also highly correlated and we will only keep the `''MOTHER_PRE_WEIGHT''`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`'CIG_...'` 特征高度相关，因此我们可以删除大部分。由于我们希望尽快预测婴儿的存活机会，我们将只保留 `'CIG_1_TRI'`。此外，正如预期的那样，权重特征也高度相关，我们将只保留
    `'MOTHER_PRE_WEIGHT'`：
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Statistical testing
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统计测试
- en: We cannot calculate correlations for the categorical features. However, we can
    run a Chi-square test to determine if there are significant differences.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能对分类特征计算相关性。然而，我们可以运行卡方测试来确定是否存在显著差异。
- en: 'Here''s how you can do it using the `.chiSqTest(...)` method of `MLlib`:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您可以使用 `MLlib` 的 `.chiSqTest(...)` 方法来完成的方法：
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We loop through all the categorical variables and pivot them by the `'INFANT_ALIVE_AT_REPORT'`
    feature to get the counts. Next, we transform them into an RDD, so we can then
    convert them into a matrix using the `pyspark.mllib.linalg` module. The first
    parameter to the `.Matrices.dense(...)` method specifies the number of rows in
    the matrix; in our case, it is the length of distinct values of the categorical
    feature.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历所有分类变量，并通过 `'INFANT_ALIVE_AT_REPORT'` 特征进行转置以获取计数。接下来，我们将它们转换成一个 RDD，然后我们可以使用
    `pyspark.mllib.linalg` 模块将它们转换成一个矩阵。`.Matrices.dense(...)` 方法的第一个参数指定了矩阵中的行数；在我们的情况下，它是分类特征的唯一值的长度。
- en: 'The second parameter specifies the number of columns: we have two as our `''INFANT_ALIVE_AT_REPORT''`
    target variable has only two values.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数指定了列数：我们有两个，因为我们的 `'INFANT_ALIVE_AT_REPORT'` 目标变量只有两个值。
- en: The last parameter is a list of values to be transformed into a matrix.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个参数是要转换成矩阵的值列表。
- en: 'Here''s an example that shows this more clearly:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个更清楚地展示这个的例子：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The preceding code produces the following matrix:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下矩阵：
- en: '![Statistical testing](img/B05793_05_06.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![统计测试](img/B05793_05_06.jpg)'
- en: Once we have our counts in a matrix form, we can use the `.chiSqTest(...)` to
    calculate our test.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将计数以矩阵形式表示，我们就可以使用 `.chiSqTest(...)` 来计算我们的测试。
- en: 'Here''s what we get in return:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这是返回的结果：
- en: '![Statistical testing](img/B05793_05_07.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![统计测试](img/B05793_05_07.jpg)'
- en: Our tests reveal that all the features should be significantly different and
    should help us predict the chance of survival of an infant.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的测试表明，所有特征都应该有显著差异，并有助于我们预测婴儿存活的概率。
- en: Creating the final dataset
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建最终数据集
- en: Therefore, it is time to create our final dataset that we will use to build
    our models. We will convert our DataFrame into an RDD of `LabeledPoints`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在是时候创建我们的最终数据集了，我们将使用它来构建我们的模型。我们将我们的DataFrame转换为`LabeledPoints`的RDD。
- en: 'A `LabeledPoint` is a MLlib structure that is used to train the machine learning
    models. It consists of two attributes: `label` and `features`.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`LabeledPoint`是MLlib结构，用于训练机器学习模型。它由两个属性组成：`label`和`features`。'
- en: The `label` is our target variable and `features` can be a NumPy `array`, `list`,
    `pyspark.mllib.linalg.SparseVector`, `pyspark.mllib.linalg.DenseVector`, or `scipy.sparse`
    column matrix.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`label`是我们的目标变量，`features`可以是NumPy `array`、`list`、`pyspark.mllib.linalg.SparseVector`、`pyspark.mllib.linalg.DenseVector`或`scipy.sparse`列矩阵。'
- en: Creating an RDD of LabeledPoints
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建LabeledPoints的RDD
- en: 'Before we build our final dataset, we first need to deal with one final obstacle:
    our `''BIRTH_PLACE''` feature is still a string. While any of the other categorical
    variables can be used as is (as they are now dummy variables), we will use a hashing
    trick to encode the `''BIRTH_PLACE''` feature:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们构建最终数据集之前，我们首先需要解决一个最后的障碍：我们的`'BIRTH_PLACE'`特征仍然是一个字符串。虽然其他任何分类变量都可以直接使用（因为它们现在是虚拟变量），但我们将使用哈希技巧来编码`'BIRTH_PLACE'`特征：
- en: '[PRE16]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: First, we create the hashing model. Our feature has seven levels, so we use
    as many features as that for the hashing trick. Next, we actually use the model
    to convert our `'BIRTH_PLACE'` feature into a `SparseVector`; such a data structure
    is preferred if your dataset has many columns but in a row only a few of them
    have non-zero values. We then combine all the features together and finally create
    a `LabeledPoint`.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建哈希模型。我们的特征有七个级别，所以我们使用与哈希技巧相同数量的特征。接下来，我们实际上使用模型将我们的`'BIRTH_PLACE'`特征转换为`SparseVector`；如果您的数据集有很多列但只有少数几列具有非零值，则这种数据结构是首选的。然后我们将所有特征组合在一起，最后创建一个`LabeledPoint`。
- en: Splitting into training and testing
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 划分为训练集和测试集
- en: 'Before we move to the modeling stage, we need to split our dataset into two
    sets: one we''ll use for training and the other for testing. Luckily, RDDs have
    a handy method to do just that: `.randomSplit(...)`. The method takes a list of
    proportions that are to be used to randomly split the dataset.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入建模阶段之前，我们需要将我们的数据集分为两个集合：一个用于训练，另一个用于测试。幸运的是，RDD有一个方便的方法来做这件事：`.randomSplit(...)`。该方法接受一个比例列表，用于随机划分数据集。
- en: 'Here is how it is done:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何操作的：
- en: '[PRE17]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: That's it! Nothing more needs to be done.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！不需要做更多的事情了。
- en: Predicting infant survival
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测婴儿存活
- en: 'Finally, we can move to predicting the infants'' survival chances. In this
    section, we will build two models: a linear classifier—the logistic regression,
    and a non-linear one—a random forest. For the former one, we will use all the
    features at our disposal, whereas for the latter one, we will employ a `ChiSqSelector(...)`
    method to select the top four features.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以转向预测婴儿的存活机会。在本节中，我们将构建两个模型：一个线性分类器——逻辑回归，以及一个非线性模型——随机森林。对于前者，我们将使用我们所有的特征，而对于后者，我们将使用`ChiSqSelector(...)`方法选择前四个特征。
- en: Logistic regression in MLlib
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLlib中的逻辑回归
- en: Logistic regression is somewhat a benchmark to build any classification model.
    MLlib used to provide a logistic regression model estimated using a **stochastic
    gradient descent** (**SGD**) algorithm. This model has been deprecated in Spark
    2.0 in favor of the `LogisticRegressionWithLBFGS` model.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归在构建任何分类模型方面某种程度上是一个基准。MLlib曾经提供使用**随机梯度下降**（**SGD**）算法估计的逻辑回归模型。在Spark 2.0中，这个模型已被弃用，转而使用`LogisticRegressionWithLBFGS`模型。
- en: The `LogisticRegressionWithLBFGS` model uses the **Limited-memory Broyden–Fletcher–Goldfarb–Shanno**
    (**BFGS**) optimization algorithm. It is a quasi-Newton method that approximates
    the BFGS algorithm.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`LogisticRegressionWithLBFGS`模型使用**有限记忆Broyden-Fletcher-Goldfarb-Shanno**（**BFGS**）优化算法。它是一种拟牛顿方法，近似BFGS算法。'
- en: Note
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'For those of you who are mathematically adept and interested in this, we suggest
    perusing this blog post that is a nice walk-through of the optimization algorithms:
    [http://aria42.com/blog/2014/12/understanding-lbfgs](http://aria42.com/blog/2014/12/understanding-lbfgs).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些数学能力强且对此感兴趣的人，我们建议阅读这篇博客文章，它是对优化算法的精彩概述：[http://aria42.com/blog/2014/12/understanding-lbfgs](http://aria42.com/blog/2014/12/understanding-lbfgs)。
- en: 'First, we train the model on our data:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们在我们的数据上训练模型：
- en: '[PRE18]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Training the model is very simple: we just need to call the `.train(...)` method.
    The required parameters are the RDD with `LabeledPoints`; we also specified the
    number of `iterations` so it does not take too long to run.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型非常简单：我们只需要调用`.train(...)`方法。所需的参数是带有`LabeledPoints`的RDD；我们还指定了`iterations`的数量，这样它不会运行得太久。
- en: 'Having trained the model using the `births_train` dataset, let''s use the model
    to predict the classes for our testing set:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`births_train`数据集训练模型后，让我们使用该模型来预测测试集的类别：
- en: '[PRE19]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The preceding snippet creates an RDD where each element is a tuple, with the
    first element being the actual label and the second one, the model's prediction.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段创建了一个RDD，其中每个元素都是一个元组，第一个元素是实际标签，第二个元素是模型的预测。
- en: 'MLlib provides an evaluation metric for classification and regression. Let''s
    check how well or how bad our model performed:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib为分类和回归提供了评估指标。让我们检查一下我们的模型表现如何：
- en: '[PRE20]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here''s what we got:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们的结果：
- en: '![Logistic regression in MLlib](img/B05793_05_08.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![MLlib中的逻辑回归](img/B05793_05_08.jpg)'
- en: The model performed reasonably well! The 85% area under the Precision-Recall
    curve indicates a good fit. In this case, we might be getting slightly more predicted
    deaths (true and false positives). In this case, this is actually a good thing
    as it would allow doctors to put the expectant mother and the infant under special
    care.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的表现相当不错！精确-召回曲线下的85%区域表示拟合良好。在这种情况下，我们可能会得到稍微更多的预测死亡（真实和假阳性）。在这种情况下，这实际上是一件好事，因为它可以让医生对预期母亲和婴儿进行特殊护理。
- en: The area under **Receiver-Operating Characteristic** (**ROC**) can be understood
    as a probability of the model ranking higher than a randomly chosen positive instance
    compared to a randomly chosen negative one. A 63% value can be thought of as acceptable.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**接收者操作特征**（ROC）曲线下的面积可以理解为模型将随机选择的正实例排名高于随机选择的负实例的概率。63%的值可以被认为是可接受的。'
- en: Note
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more on these metrics, we point interested readers to [http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves](http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves)
    and [http://gim.unmc.edu/dxtests/roc3.htm](http://gim.unmc.edu/dxtests/roc3.htm).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于这些指标的信息，我们建议感兴趣的读者参考[http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves](http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves)和[http://gim.unmc.edu/dxtests/roc3.htm](http://gim.unmc.edu/dxtests/roc3.htm)。
- en: Selecting only the most predictable features
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仅选择最可预测的特征
- en: Any model that uses less features to predict a class accurately should always
    be preferred to a more complex one. MLlib allows us to select the most predictable
    features using a Chi-Square selector.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 任何使用更少特征准确预测类别的模型都应该优先于更复杂的模型。MLlib允许我们使用卡方选择器选择最可预测的特征。
- en: 'Here''s how you do it:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何做到这一点的步骤：
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We asked the selector to return the four most predictive features from the dataset
    and train the selector using the `births_train` dataset. We then used the model
    to extract only those features from our training and testing datasets.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要求选择器从数据集中返回四个最可预测的特征，并使用`births_train`数据集来训练选择器。然后我们使用模型从我们的训练和测试数据集中提取仅这些特征。
- en: The `.ChiSqSelector(...)` method can only be used for numerical features; categorical
    variables need to be either hashed or dummy coded before the selector can be used.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`.ChiSqSelector(...)`方法只能用于数值特征；分类变量在使用选择器之前需要被哈希化或转换为虚拟变量。'
- en: Random forest in MLlib
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLlib中的随机森林
- en: We are now ready to build the random forest model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好构建随机森林模型。
- en: 'The following code shows you how to do it:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何实现：
- en: '[PRE22]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The first parameter to the `.trainClassifier(...)` method specifies the training
    dataset. The `numClasses` one indicates how many classes our target variable has.
    As the third parameter, you can pass a dictionary where the key is the index of
    a categorical feature in our RDD and the value for the key indicates the number
    of levels that the categorical feature has. The `numTrees` specifies the number
    of trees to be in the forest. The next parameter tells the model to use all the
    features in our dataset instead of keeping only the most descriptive ones, while
    the last one specifies the seed for the stochastic part of the model.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`.trainClassifier(...)` 方法的第一个参数指定了训练数据集。`numClasses` 参数表示我们的目标变量有多少个类别。作为第三个参数，您可以传递一个字典，其中键是我们RDD中分类特征的索引，而键的值表示分类特征有多少个级别。`numTrees`
    指定了森林中的树的数量。下一个参数告诉模型使用我们数据集中的所有特征，而不是只保留最具描述性的特征，而最后一个参数指定了模型随机部分的种子。'
- en: 'Let''s see how well our model did:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的模型表现如何：
- en: '[PRE23]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here are the results:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '![Random forest in MLlib](img/B05793_05_09.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![MLlib中的随机森林](img/B05793_05_09.jpg)'
- en: 'As you can see, the Random Forest model with fewer features performed even
    better than the logistic regression model. Let''s see how the logistic regression
    would perform with a reduced number of features:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，具有较少特征的随机森林模型甚至比逻辑回归模型表现更好。让我们看看逻辑回归在特征数量减少的情况下会如何表现：
- en: '[PRE24]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The results might surprise you:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可能会让您感到惊讶：
- en: '![Random forest in MLlib](img/B05793_05_10.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![MLlib中的随机森林](img/B05793_05_10.jpg)'
- en: As you can see, both models can be simplified and still attain the same level
    of accuracy. Having said that, you should always opt for a model with fewer variables.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这两个模型可以简化，同时仍然达到相同的准确度水平。话虽如此，您应该始终选择具有较少变量的模型。
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked at the capabilities of the `MLlib` package of PySpark.
    Even though the package is currently in a maintenance mode and is not actively
    being worked on, it is still good to know how to use it. Also, for now it is the
    only package available to train models while streaming data. We used `MLlib` to
    clean up, transform, and get familiar with the dataset of infant deaths. Using
    that knowledge we then successfully built two models that aimed at predicting
    the chance of infant survival given the information about its mother, father,
    and place of birth.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了PySpark的`MLlib`包的功能。尽管该包目前处于维护模式，并且没有积极开发，但了解如何使用它仍然是有益的。此外，目前它是唯一可用于在流数据时训练模型的包。我们使用`MLlib`清理、转换并熟悉婴儿死亡数据集。利用这些知识，我们成功构建了两个模型，旨在根据母亲、父亲和出生地信息预测婴儿存活的机会。
- en: In the next chapter, we will revisit the same problem, but using the newer package
    that is currently the Spark recommended package for machine learning.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将重新审视相同的问题，但使用目前Spark推荐的机器学习新包。
