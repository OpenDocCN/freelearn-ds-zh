- en: Optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化
- en: Optimization is a branch of applied mathematics that has applications in a multitude
    of fields, such as physics, engineering, economics, and so on, and is of vital
    importance in developing and training of deep neural networks. In this chapter,
    a lot of what we covered in previous chapters will be very relevant, particularly
    linear algebra and calculus.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 优化是应用数学的一个分支，广泛应用于物理学、工程学、经济学等多个领域，在深度神经网络的开发和训练中具有至关重要的作用。在本章中，我们之前章节所涉及的很多内容将非常相关，特别是线性代数和微积分。
- en: As we know, deep neural networks are developed on computers and are, therefore,
    expressed mathematically. More often than not, training deep learning models comes
    down to finding the correct (or as close to the correct) set of parameters. We
    will learn more about this as we progress further through this book.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所知，深度神经网络是在计算机上开发的，因此可以用数学表达式表示。通常，训练深度学习模型归结为找到正确（或者尽可能接近正确的）参数集。我们将在本书的进一步学习中了解更多内容。
- en: In this chapter, we'll mainly learn about two types of continuous optimization—constrained
    and unconstrained. However, we will also briefly touch on other forms of optimization,
    such as genetic algorithms, particle swarm optimization, and simulated annealing.
    Along the way, we will also learn when and how to use each of these techniques.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们主要将学习两种类型的连续优化——约束优化和无约束优化。然而，我们还将简要介绍其他形式的优化，如遗传算法、粒子群优化和模拟退火。在这个过程中，我们还将学习何时以及如何使用这些技术。
- en: 'This chapter will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding optimization and it's different types
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解优化及其不同类型
- en: Exploring the various optimization methods
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索各种优化方法
- en: Exploring population methods
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索种群方法
- en: Understanding optimization and it's different types
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解优化及其不同类型
- en: In optimization, our goal is to either minimize or maximize a function. For
    example, a business wants to minimize its costs while maximizing its profits or
    a shopper might want to get as much as possible while spending as little as possible.
    Therefore, the goal of optimization is to find the best case of ![](img/3e222295-5f36-49fc-b8e7-f78d7cbb5e36.png),
    which is denoted by *x^** (where *x* is a set of points), that satisfies certain
    criteria. These criteria are, for our purposes, mathematical functions known as
    **objective functions**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化中，我们的目标是要么最小化，要么最大化一个函数。例如，企业希望在最大化利润的同时最小化成本，或者购物者可能希望在尽可能少花费的情况下得到尽可能多的东西。因此，优化的目标是找到满足特定标准的最佳情况 ![](img/3e222295-5f36-49fc-b8e7-f78d7cbb5e36.png)，表示为
    *x^** （其中 *x* 是一组点），这些标准是对我们来说的数学函数，称为 **目标函数**。
- en: 'For example, let''s suppose we have the [![](img/a43eb391-efdc-4743-86c1-4440f7b229fb.png)] equation. If
    we plot it, we get the following graph:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有[![](img/a43eb391-efdc-4743-86c1-4440f7b229fb.png)] 方程。如果我们绘制它，我们将得到如下图表：
- en: '![](img/f8646f12-1773-48b4-9095-f1e923f17847.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f8646f12-1773-48b4-9095-f1e923f17847.png)'
- en: 'You will recall from [Chapter 1](3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml),
    *Vector Calculus*, that we can find the gradient of a function by taking its derivative,
    equating it to 0, and solving for *x*. We can find the point(s) at which the function
    has a minimum or maximum, as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你会从[第1章](3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml)，*向量微积分*中回忆起，我们可以通过求取函数的导数，将其等于0，并解出
    *x* 来找到函数的梯度。我们可以找到函数具有最小值或最大值的点，如下所示：
- en: '![](img/5961dece-f3e3-42d3-b35e-ee3c05da7850.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5961dece-f3e3-42d3-b35e-ee3c05da7850.png)'
- en: After solving this equation, we find that it has three distinct solutions (that
    is, three points where the minima and maxima occur).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 解这个方程后，我们发现它有三个不同的解（即，三个函数的最小值和最大值出现的点）。
- en: To find which of these three solutions are the minima and maxima, we find the
    second derivative, [![](img/bcfe75c6-d2ba-4c56-a73e-782316ce5048.png)], and check
    whether our stationary points are positive or negative.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到这三个解中哪些是最小值和最大值，我们求出二阶导数，[![](img/bcfe75c6-d2ba-4c56-a73e-782316ce5048.png)]，并检查我们的驻点是正值还是负值。
- en: Visually, when we see the graph, we can identify the local and global minima,
    but it isn't as simple as this when we calculate it computationally. So, instead,
    we start at a value and follow the gradient until we get to the minima (hopefully,
    the global minima).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从图形上看，当我们看到图表时，可以识别局部和全局最小值，但在计算时并不像这样简单。所以，我们从一个值开始，沿着梯度前进，直到到达最小值（希望是全局最小值）。
- en: Say we start from the right side at *x *= *2*. The gradient is negative, which
    means we move to the left incrementally (these increments are called **step size**)
    and we get to the local minima, which isn't the one we want to find. However,
    if we start at *x *= -*2*, then we end up at the global minima.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们从右侧开始，*x* = *2*。梯度是负的，这意味着我们逐渐向左移动（这些增量叫做**步长**），然后我们到达局部最小值，但这不是我们想找到的最小值。然而，如果我们从*x*
    = -*2*开始，我们最终会到达全局最小值。
- en: Constrained optimization
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有约束优化
- en: 'Constrained optimization, in general, has certain rules or constraints attached
    that must be followed. In general, the problem is defined in the following form:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 有约束优化，通常有一些规则或约束必须遵循。一般来说，问题的定义形式如下：
- en: '![](img/38e4bb82-504f-4304-850e-df6ab4043796.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38e4bb82-504f-4304-850e-df6ab4043796.png)'
- en: In the preceding equation, ![](img/b0caee31-eba0-4c04-8308-d6b60e0d03f1.png) contains
    the decision variables, [![](img/7164aca9-e847-46ab-82bf-c274593ccdbc.png)] is
    our objective function, [![](img/a4ddd95d-2b71-4e99-a2d0-fe0128fd0037.png)] and ![](img/20549c15-3f7f-4667-bff1-48cfaa6f6524.png) are
    the functional constraints, while [![](img/2a7b4195-d394-418c-8833-04f5cc1b3f89.png)] is
    the regional constraint.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，![](img/b0caee31-eba0-4c04-8308-d6b60e0d03f1.png)包含了决策变量，[![](img/7164aca9-e847-46ab-82bf-c274593ccdbc.png)]是我们的目标函数，[![](img/a4ddd95d-2b71-4e99-a2d0-fe0128fd0037.png)]和![](img/20549c15-3f7f-4667-bff1-48cfaa6f6524.png)是功能约束，而[![](img/2a7b4195-d394-418c-8833-04f5cc1b3f89.png)]是区域约束。
- en: All of these variables are vectors; in fact, all of the variables in this chapter
    will be vectors, so for simplification, we will not be writing them in boldface
    as we did previously, in [Chapter 1](3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml),
    *Vector Calculus*, and [Chapter 2](6a34798f-db83-4a32-9222-06ba717fc809.xhtml),
    *Linear Algebra*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些变量都是向量；实际上，本章中的所有变量都是向量，因此为了简化，我们不会像在[第一章](3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml)、《*向量微积分*》和[第二章](6a34798f-db83-4a32-9222-06ba717fc809.xhtml)、《*线性代数*》中那样将它们写成粗体。
- en: Sometimes, our constraints could be in the form of an inequality, such as [![](img/89e125d8-972e-47cf-b9b7-d5f9c1185efb.png)],
    and we can add in a slack variable, *z*, which now makes our functional constraint [![](img/9fa2fd6e-7f91-49b9-974a-7325fd386946.png)] and
    the regional constraint *z ≥ 0*.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，我们的约束可能是以不等式的形式出现，例如[![](img/89e125d8-972e-47cf-b9b7-d5f9c1185efb.png)]，我们可以加入一个松弛变量*z*，这使得我们的函数约束变为[![](img/9fa2fd6e-7f91-49b9-974a-7325fd386946.png)]，并且区域约束变为*z
    ≥ 0*。
- en: 'We could simply write out all the constraints explicitly, but that''s just
    too messy. We generally write them as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接列出所有约束，但那样太乱了。我们通常将它们写作如下形式：
- en: '![](img/c1b8e2a7-df9f-4a15-9c9c-ecf39eb04931.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c1b8e2a7-df9f-4a15-9c9c-ecf39eb04931.png)'
- en: 'This is the general form of a linear program. The standard form, however, is
    written as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是线性规划的一般形式。然而，标准形式通常写作如下：
- en: '![](img/3353ae3b-19be-47df-8c80-ee53bdee815c.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3353ae3b-19be-47df-8c80-ee53bdee815c.png)'
- en: I know this may all seem very unclear right now, but don't fear—we will make
    sense of all of it soon.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道现在这一切可能看起来非常不清楚，但别担心——我们很快就能弄清楚所有这些内容。
- en: Unconstrained optimization
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无约束优化
- en: 'The goal of optimization problems is to minimize *f(x)*, and we will primarily
    be dealing with functions that are twice differentiable and where [![](img/6e2c031b-260a-449e-9a05-67bdbcf4f6b5.png)].
    A rather important property to be aware of is that since *f* is differentiable
    and convex, we have the following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 优化问题的目标是最小化*f(x)*，我们主要处理的是二次可微的函数，并且满足[![](img/6e2c031b-260a-449e-9a05-67bdbcf4f6b5.png)]。一个非常重要的属性是，由于*f*是可微且凸的，我们有如下结论：
- en: '![](img/96c4a8d2-9ed0-4c87-884d-c3be361f804e.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96c4a8d2-9ed0-4c87-884d-c3be361f804e.png)'
- en: This should be apparent if you remember what we learned in [Chapter 1](3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml),
    *Vector Calculus*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记得我们在[第一章](3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml)、《*向量微积分*》中学到的内容，这应该是显而易见的。
- en: Unconstrained optimization, as you can probably tell, is the case in which we
    do not have any constraints whatsoever and any point could be a minimum, maximum,
    or a saddle point, which doesn't make the problem easy.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 无约束优化，正如你可能已经能看出来的那样，就是没有任何约束的情况，任何点都可能是最小值、最大值或鞍点，这使得问题变得不容易。
- en: Let's suppose we have a problem with *n* equations and *n* variables. Solving
    this and finding the optimal solution isn't simple, and we generally solve the
    problem iteratively. Think of this as computing a set sequence of points in the
    domain of *f*, which gradually gets us to the optima.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个含有*n*个方程和*n*个变量的问题。求解这个问题并找到最优解并不简单，通常我们是通过迭代方式来解决问题。可以把它看作是在*f*的定义域内计算一个有序的点集，逐步接近最优解。
- en: 'Now, say we have a function, [![](img/e887acf6-10cc-4770-9a52-873c549bcd9f.png)],
    and ![](img/90e72e61-e77d-4137-94f1-a437b66d7e5b.png), such that [![](img/0daaddad-4c1a-4c3a-910e-0daead88e939.png)]. The
    problem now looks as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们有一个函数，[![](img/e887acf6-10cc-4770-9a52-873c549bcd9f.png)]，并且 ![](img/90e72e61-e77d-4137-94f1-a437b66d7e5b.png)，使得
    [![](img/0daaddad-4c1a-4c3a-910e-0daead88e939.png)]。现在的问题如下所示：
- en: '![](img/b4b1bdff-8536-4309-9df1-7a2ba6231b56.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b4b1bdff-8536-4309-9df1-7a2ba6231b56.png)'
- en: Here, we have [![](img/b733309e-a4ba-4ba7-acfc-1eaefa417be5.png)], which we
    know from previous chapters is the gradient of *f*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们有[![](img/b733309e-a4ba-4ba7-acfc-1eaefa417be5.png)]，根据前面的章节我们知道它是*f*的梯度。
- en: Naturally, to start computing these points, we need a starting point, which
    we call the initial point, and it must lie within the domain of *f*. Then, we
    iterate and find better points from there until we find the optimal one.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，为了开始计算这些点，我们需要一个起始点，我们称之为初始点，并且它必须位于*f*的定义域内。然后，我们通过迭代从那里找到更好的点，直到找到最优点。
- en: Convex optimization
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 凸优化
- en: 'Convex optimization concerns minimizing a convex function over a convex set.
    In general, it takes the following form:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 凸优化问题关注的是在凸集上最小化一个凸函数。一般来说，它的形式如下：
- en: '![](img/617cc53f-c166-49c0-9b8e-109f5bc45d2c.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/617cc53f-c166-49c0-9b8e-109f5bc45d2c.png)'
- en: 'Here, [![](img/e285ab0c-4a1f-4104-b887-f43bc22d062b.png)] are convex functions
    and so they satisfy the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，[![](img/e285ab0c-4a1f-4104-b887-f43bc22d062b.png)]是凸函数，因此它们满足以下条件：
- en: '![](img/e7d109ff-18d8-4688-a0d2-b9a736723a84.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7d109ff-18d8-4688-a0d2-b9a736723a84.png)'
- en: This is the case when [![](img/b8989821-4430-4087-a36d-82b6d05599b9.png)] and
    [![](img/f61e1754-4fb8-4ff7-b900-e8b5763f9cf1.png)] are non-negative and [![](img/46b6fb29-b1a3-472a-8a1c-2ef169b59a8e.png)].
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是当[![](img/b8989821-4430-4087-a36d-82b6d05599b9.png)]和[![](img/f61e1754-4fb8-4ff7-b900-e8b5763f9cf1.png)]为非负数且[![](img/46b6fb29-b1a3-472a-8a1c-2ef169b59a8e.png)]时的情况。
- en: Convex sets
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 凸集
- en: In optimization, we come across the terms convex and non-convex fairly often.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化中，我们常常遇到凸和非凸这两个术语。
- en: We define a convex set as one where if we were to take any two random points
    and draw a line to join them, the line would lie completely within the boundaries
    of the set.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义一个凸集为：如果我们选取任意两个点并画一条线连接它们，那么这条线将完全位于该集的边界内。
- en: We label our convex set [![](img/c05c4837-b88a-47ae-bc8f-1edb1666dc1d.png)] and
    if we have two points, [![](img/720e4010-3faa-4d96-ab3e-5ca967ab0170.png)] and
    some scalar [![](img/24646c89-6d96-4680-b027-57ffd9dff50e.png)] value, then ![](img/9f6936b2-a543-41f8-8ac4-1474b4f24bd0.png).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们标记我们的凸集为[![](img/c05c4837-b88a-47ae-bc8f-1edb1666dc1d.png)]，如果我们有两个点，[![](img/720e4010-3faa-4d96-ab3e-5ca967ab0170.png)]和某个标量[![](img/24646c89-6d96-4680-b027-57ffd9dff50e.png)]值，那么[![](img/9f6936b2-a543-41f8-8ac4-1474b4f24bd0.png)]。
- en: Now, let's suppose we have the [![](img/0ba6e809-a9d9-4dce-8573-5c971f3ecbc7.png)] function. Then,
    if *θ *= *0*, *f *= *y*; but if *θ *= *1*, then *f *= *x*. From this, we can tell
    that as *θ* increases, *f* moves gradually from *y* to *x*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们有[![](img/0ba6e809-a9d9-4dce-8573-5c971f3ecbc7.png)]函数。如果*θ*=*0*，*f*=*y*；但如果*θ*=*1*，那么*f*=*x*。从这个可以看出，随着*θ*的增加，*f*会逐渐从*y*变到*x*。
- en: A function, [![](img/261c3458-9094-4653-81fe-5fe00504816b.png)], is convex if
    *S* is convex for all cases of [![](img/c7694f92-3edf-4144-996a-6c64ae1115e0.png)] and [![](img/9722a716-64e8-40d7-a81a-55c40946ab15.png)].
    We then have [![](img/32d46d71-f9c5-4ee5-a028-193b68162e8b.png)].
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一个函数，[![](img/261c3458-9094-4653-81fe-5fe00504816b.png)]，如果* S *对于所有[![](img/c7694f92-3edf-4144-996a-6c64ae1115e0.png)]和[![](img/9722a716-64e8-40d7-a81a-55c40946ab15.png)]的情况都是凸的，那么它就是凸函数。然后我们得到[![](img/32d46d71-f9c5-4ee5-a028-193b68162e8b.png)]。
- en: Additionally, if we have [![](img/3b24f04a-6e8e-465a-89d2-07fd53de064b.png)],
    where the domain of the function is the convex set for all cases of [![](img/58611348-d5eb-43d7-ba78-0ce672ed94bc.png)],
    then [![](img/5e1fa71b-5172-4f67-84b8-a31c0e534867.png)].
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果我们有[![](img/3b24f04a-6e8e-465a-89d2-07fd53de064b.png)]，其中该函数的定义域是对于所有[![](img/58611348-d5eb-43d7-ba78-0ce672ed94bc.png)]的凸集，那么[![](img/5e1fa71b-5172-4f67-84b8-a31c0e534867.png)]。
- en: 'To aid us in visualizing a convex function, we have the following diagram,
    where we can see that it looks almost like a bowl and that all the points within
    the bowl are points in the convex set:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们可视化一个凸函数，我们有以下图示，其中可以看到它几乎像一个碗，碗内的所有点都是凸集合中的点：
- en: '![](img/243305a4-c4ad-4527-b159-3bcd670269e2.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/243305a4-c4ad-4527-b159-3bcd670269e2.png)'
- en: 'Now, let''s suppose our function can be differentiated twice. Then, *f* is
    convex on a convex region and we can define our Hessian matrix as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们的函数可以进行二次微分。那么，*f*在凸区域上是凸的，我们可以将我们的Hessian矩阵定义如下：
- en: '![](img/5ced4b33-92ff-45fd-81eb-d5eed913a677.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ced4b33-92ff-45fd-81eb-d5eed913a677.png)'
- en: This is positive semi-definite for all cases of ![](img/f6c1440a-9f9a-4854-b629-be27ec7ce8b2.png).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有![](img/f6c1440a-9f9a-4854-b629-be27ec7ce8b2.png)的情况，这是半正定的。
- en: Affine sets
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 仿射集合
- en: If we have a ![](img/b31ca2d7-8a28-440d-a9dd-d1d189695d74.png)  set, it is affine
    if the line connecting our two points in ![](img/e6d29ef2-3f6b-4c6e-a821-41cd646e7e42.png) lies
    in ![](img/09f97db9-7438-435c-9976-3fde21d6206c.png); that is, this space contains
    a linear combination of the points in ![](img/24bfae59-46ca-44b6-8775-2484de5530cb.png),
    but only if the sum of the coefficients is equal to 1 so that [![](img/87aab3a5-ac23-4def-85cc-a35fe03adfed.png)], [![](img/f1ef638a-aabb-4381-b785-0e921798d34f.png)] and [![](img/81958148-fc61-442a-955f-d4dfc247302b.png)].
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个![](img/b31ca2d7-8a28-440d-a9dd-d1d189695d74.png)集合，当连接我们在![](img/e6d29ef2-3f6b-4c6e-a821-41cd646e7e42.png)中的两点的直线位于![](img/09f97db9-7438-435c-9976-3fde21d6206c.png)中时，它是仿射的；也就是说，这个空间包含了![](img/24bfae59-46ca-44b6-8775-2484de5530cb.png)中点的线性组合，但只有当系数之和等于1时，[![](img/87aab3a5-ac23-4def-85cc-a35fe03adfed.png)]、[![](img/f1ef638a-aabb-4381-b785-0e921798d34f.png)]和[![](img/81958148-fc61-442a-955f-d4dfc247302b.png)]。
- en: 'Additionally, if we have more than two points, then [![](img/2ed96c4c-ac66-404c-95b7-c965ac5e6b39.png)] is
    an affine combination of *n* points, given the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果我们有超过两个点，那么[![](img/2ed96c4c-ac66-404c-95b7-c965ac5e6b39.png)]是*n*个点的仿射组合，给定以下条件：
- en: '![](img/ac09bd0f-5404-4c97-9bd8-300eadd416f4.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ac09bd0f-5404-4c97-9bd8-300eadd416f4.png)'
- en: 'Also, if ![](img/a9aa04b3-8235-4e3e-9936-54cd8be900b1.png) is an affine set
    and we have a [![](img/fbd3ad9e-84df-4a47-b00e-344e0d5ef1e5.png)] point, then
    we have the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果![](img/a9aa04b3-8235-4e3e-9936-54cd8be900b1.png)是一个仿射集合，并且我们有一个[![](img/fbd3ad9e-84df-4a47-b00e-344e0d5ef1e5.png)]点，那么我们可以得到以下结论：
- en: '![](img/55b11d6f-1111-4527-bee5-190ffa236178.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/55b11d6f-1111-4527-bee5-190ffa236178.png)'
- en: This is a subspace of ![](img/57233124-1946-43aa-bf30-833d46b3f50a.png).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这是![](img/57233124-1946-43aa-bf30-833d46b3f50a.png)的一个子空间。
- en: 'Now, suppose we have some [![](img/87659a7a-26e2-41cb-8f44-7d4840932b71.png)] and
    [![](img/f60e07cc-3406-487b-b656-702c03a4f656.png)] points. From earlier, we know
    that [![](img/ae1e1af3-b81a-481d-a4bb-e94eabd8e448.png)] and [![](img/846c0c58-4bcd-4f33-9c6f-e1670545499d.png)].
    Therefore, we can express ![](img/6e005216-d152-4fe0-a3f8-f400cd4270b9.png) as
    follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们有一些[![](img/87659a7a-26e2-41cb-8f44-7d4840932b71.png)]和[![](img/f60e07cc-3406-487b-b656-702c03a4f656.png)]点。从前面我们知道[![](img/ae1e1af3-b81a-481d-a4bb-e94eabd8e448.png)]和[![](img/846c0c58-4bcd-4f33-9c6f-e1670545499d.png)]。因此，我们可以将![](img/6e005216-d152-4fe0-a3f8-f400cd4270b9.png)表示如下：
- en: '![](img/1bc5e4e9-61b1-4c8b-b472-05b32def8259.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1bc5e4e9-61b1-4c8b-b472-05b32def8259.png)'
- en: In general, we call the set of all combinations of points in ![](img/f1f48a0e-0b60-47e5-957b-47c7410033b1.png) the
    affine hull of ![](img/e010d8ad-0ccb-429f-ab9f-872760dd2dfe.png).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，我们称![](img/f1f48a0e-0b60-47e5-957b-47c7410033b1.png)中所有点组合的集合为![](img/e010d8ad-0ccb-429f-ab9f-872760dd2dfe.png)的仿射外壳。
- en: Let's now assume that we have a unit sphere in ![](img/f30c5049-69a7-46cb-b0fd-26cb7afc2596.png) where
    *x* is its center, *r* is the radius, and [![](img/99bf9568-e1db-4d77-9445-2ff2e226de01.png)]. The
    relative interior of ![](img/0f0f2afd-e435-4dcc-9370-1e99a49d0b73.png), where
    the dimension of ![](img/9989f0fb-45e6-4430-a025-d2151797ee4b.png) is less than
    *n*, is defined as the [![](img/ea052682-bc68-430b-8caa-4ca4f5f610b6.png)] set, where
    [![](img/71050a5c-018e-4d4a-a1c8-d4281b973023.png)].
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们有一个单位球体在![](img/f30c5049-69a7-46cb-b0fd-26cb7afc2596.png)中，其中*x*是其中心，*r*是半径，且[![](img/99bf9568-e1db-4d77-9445-2ff2e226de01.png)]。![](img/0f0f2afd-e435-4dcc-9370-1e99a49d0b73.png)的相对内部，其中![](img/9989f0fb-45e6-4430-a025-d2151797ee4b.png)的维度小于*n*，定义为[![](img/ea052682-bc68-430b-8caa-4ca4f5f610b6.png)]集合，其中[![](img/71050a5c-018e-4d4a-a1c8-d4281b973023.png)]。
- en: Then, the relative boundary of  ![](img/8e3cf85d-faf0-4087-a762-109bd22884f7.png) is
    defined as the difference between the closure of  ![](img/807b275e-06ac-4d8e-8c26-e5e04667539b.png) and
    the relative interior of ![](img/8b6f6e29-c46b-415e-a937-66e9a5a0e092.png).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，定义相对边界为[![](img/8e3cf85d-faf0-4087-a762-109bd22884f7.png)]的闭包与[![](img/807b275e-06ac-4d8e-8c26-e5e04667539b.png)]的相对内部之间的差。
- en: Convex functions
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 凸函数
- en: 'A convex function is defined as a [![](img/e4cab5f6-ec5d-4fc6-973e-7501ad655009.png)]  function if
    its domain is a convex set and if for *x*, [![](img/0b82b4e6-3472-4b2a-b235-5f743677a3c7.png)] and
    [![](img/414d8821-0649-4d8e-8527-0961307cf686.png)], which gives us the following:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个函数的定义域是一个凸集，并且对于*x*，[![](img/0b82b4e6-3472-4b2a-b235-5f743677a3c7.png)]和[![](img/414d8821-0649-4d8e-8527-0961307cf686.png)]满足条件，那么该函数被定义为一个[![](img/e4cab5f6-ec5d-4fc6-973e-7501ad655009.png)]函数，如下所示：
- en: '![](img/12fb8fb7-308e-4a5b-9ebe-c6e65acb5737.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/12fb8fb7-308e-4a5b-9ebe-c6e65acb5737.png)'
- en: 'Let''s visualize this inequality with the following graph:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用以下图形可视化这个不等式：
- en: '![](img/955b131d-f913-4f5a-a023-6200b5504c0e.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/955b131d-f913-4f5a-a023-6200b5504c0e.png)'
- en: The line that connects the two points is above the function, which tells us
    that it is convex. However, the function is concave when it is -*f* and is convex
    otherwise.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 连接两点的直线在函数之上，这告诉我们该函数是凸的。然而，当函数是-*f*时，它是凹的，否则是凸的。
- en: Affine functions, on the other hand, have equality and are, therefore, concave
    and convex.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，仿射函数具有等式，因此既是凹函数又是凸函数。
- en: Optimization problems
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化问题
- en: 'We can recall from earlier in this chapter that the optimization problem can
    be defined as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从本章前面回顾到，优化问题可以定义如下：
- en: '![](img/f9575709-0e71-440d-8bdd-e280e15f04fb.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9575709-0e71-440d-8bdd-e280e15f04fb.png)'
- en: 'The optimal value of our problem is defined as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们问题的最优值定义如下：
- en: '![](img/24ec5f1d-f26b-44ec-a17e-b10ea4ec05e3.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/24ec5f1d-f26b-44ec-a17e-b10ea4ec05e3.png)'
- en: 'We call *x^** an optimal point (or solution to our problem) if [![](img/03a1b1d2-66b1-41df-ae4d-e9fea8dc1a6e.png)].
    Therefore, the optimal set containing all the optimal points is as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称*x^**为一个最优点（或者是我们问题的解），如果[![](img/03a1b1d2-66b1-41df-ae4d-e9fea8dc1a6e.png)]。因此，包含所有最优点的最优集如下所示：
- en: '![](img/66cceb19-535a-46b5-9390-0debe5346716.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/66cceb19-535a-46b5-9390-0debe5346716.png)'
- en: In convex optimization, there is a rather major property that states that any
    point that is locally optimal is also globally optimal.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在凸优化中，有一个相当重要的性质，指出任何局部最优点也是全局最优点。
- en: Non-convex optimization
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非凸优化
- en: In convex optimization, we deal with having to find a local optimum, which also
    happens to be the global minimum. However, in non-convex optimization, we have
    to find the global minimum, which isn't the local minimum; in fact, there could
    be more than one local minimum, as well as saddle points.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在凸优化中，我们需要找到一个局部最优解，这也恰好是全局最小值。然而，在非凸优化中，我们需要找到全局最小值，这并不是局部最小值；事实上，可能会有多个局部最小值以及鞍点。
- en: This makes non-convex optimization far more challenging than convex optimization.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得非凸优化比凸优化更具挑战性。
- en: Exploring the various optimization methods
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索各种优化方法
- en: Now that you know what optimization is, it's time to explore some of the methods
    used in practice. We will not be covering the entire field of optimization because
    that would require an entire book to cover. We will only cover the essential optimization
    methods that are applicable to deep learning.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了优化是什么，是时候探索一些实际应用中使用的方法了。我们不会覆盖整个优化领域，因为这需要一本书来讲解。我们只会涵盖适用于深度学习的基本优化方法。
- en: Least squares
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小二乘法
- en: 'Least squares is a subclass of convex optimization. It is classified as having
    no constraints and takes the following form:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法是凸优化的一个子集。它被归类为无约束优化，形式如下：
- en: '![](img/57b89537-b10b-4e6f-a183-8647707b2a4d.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57b89537-b10b-4e6f-a183-8647707b2a4d.png)'
- en: Here, [![](img/1b466f43-d90e-4adf-bfa1-6acf5f829700.png)], [![](img/7960cb35-6307-40bc-ae94-aa999d68919f.png)] are
    rows of *A*, and ![](img/1de284b2-be3b-4bd6-902d-82a40c284be0.png) is our optimization
    variable.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，[![](img/1b466f43-d90e-4adf-bfa1-6acf5f829700.png)]，[![](img/7960cb35-6307-40bc-ae94-aa999d68919f.png)]是*A*的行，而[![](img/1de284b2-be3b-4bd6-902d-82a40c284be0.png)]是我们的优化变量。
- en: We can also express this as a set of linear equations of the [![](img/bb9c9ef7-5180-402c-a58a-0c247a009c2b.png)] form. Therefore, [![](img/49cc707f-9547-48ff-bb62-a5171fa45bc8.png)].
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将其表示为[![](img/bb9c9ef7-5180-402c-a58a-0c247a009c2b.png)]形式的线性方程组。因此，[![](img/49cc707f-9547-48ff-bb62-a5171fa45bc8.png)]。
- en: The problem of least squares is very similar to that of maximum likelihood estimation.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘问题与最大似然估计问题非常相似。
- en: Lagrange multipliers
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拉格朗日乘子
- en: When solving constrained optimization problems, it is best to include the constraints
    in the objective function. This way, anything that is not included in the constraints
    is not considered a minimum.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在求解约束优化问题时，最好将约束条件包含在目标函数中。这样，任何不包含在约束中的部分就不会被认为是最小值。
- en: 'Let''s revisit our earlier problem:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下之前的问题：
- en: '![](img/0faa4e4d-5404-42d7-8216-82fc036851f5.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0faa4e4d-5404-42d7-8216-82fc036851f5.png)'
- en: We'll call our constraint *C*.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们的约束称为 *C*。
- en: 'So, we define the Lagrangian of *C* as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们定义 *C* 的拉格朗日函数如下：
- en: '![](img/7fe1b202-2d3b-4b99-b823-674b2f436e5d.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7fe1b202-2d3b-4b99-b823-674b2f436e5d.png)'
- en: Here, ![](img/34b89d9d-e947-45fe-8630-6aa56c043a58.png) and is known as the
    **Lagrange multiplier**.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/34b89d9d-e947-45fe-8630-6aa56c043a58.png) 被称为 **拉格朗日乘子**。
- en: When our constraint is satisfied, then [![](img/56663a20-d766-4a44-ac7c-c2b1e9cfcb87.png)] and [![](img/9fabb59b-5ee3-4f50-b7e7-22731db68787.png)].
    By minimizing *L* over *x* and λ, we find the solution with respect to the constraints.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的约束条件得到满足时，[![](img/56663a20-d766-4a44-ac7c-c2b1e9cfcb87.png)] 和 [![](img/9fabb59b-5ee3-4f50-b7e7-22731db68787.png)]。通过对
    *L* 在 *x* 和 λ 上进行最小化，我们得到了关于约束条件的解。
- en: 'Suppose we have ![](img/ed341058-10d3-4606-b545-264057b205c1.png) and ![](img/345f1fab-16c7-45fc-8990-5590ed98da77.png),
    such that we have the following:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有 ![](img/ed341058-10d3-4606-b545-264057b205c1.png) 和 ![](img/345f1fab-16c7-45fc-8990-5590ed98da77.png)，这样我们得到如下式子：
- en: '![](img/824e9d0e-0a0d-4c09-8ebb-5969fc5e7d86.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/824e9d0e-0a0d-4c09-8ebb-5969fc5e7d86.png)'
- en: Then, *x^** is optimal for *C*; that is, it minimizes *f*. This is called **Lagrangian
    sufficiency**.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，*x^** 对 *C* 是最优的；也就是说，它最小化了 *f*。这被称为 **拉格朗日充分性**。
- en: 'To find λ^* and *x^**, we must solve the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到 λ^* 和 *x^**，我们必须解如下方程：
- en: '![](img/e1582730-9cd5-48bf-bec8-9c7f433eaac5.png) and ![](img/2ab61b4a-8c1d-44f1-afcb-4c9dd4c35449.png).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/e1582730-9cd5-48bf-bec8-9c7f433eaac5.png) 和 ![](img/2ab61b4a-8c1d-44f1-afcb-4c9dd4c35449.png)。'
- en: For example, say we want to minimize [![](img/32c59e92-7e79-465b-bee9-4c0572d92de2.png)] subject
    to [![](img/e4564403-bee3-40be-82f6-544ec526a501.png)] and [![](img/bedccddf-8b17-4a29-bf49-6068e6e551f1.png)].
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想要最小化 [![](img/32c59e92-7e79-465b-bee9-4c0572d92de2.png)]，并满足 [![](img/e4564403-bee3-40be-82f6-544ec526a501.png)]
    和 [![](img/bedccddf-8b17-4a29-bf49-6068e6e551f1.png)]。
- en: 'So, the equation for Lagrangian sufficiency is as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，拉格朗日充分性方程如下：
- en: '![](img/db3a1b74-5ec6-4886-b403-e4a95aeb2b19.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/db3a1b74-5ec6-4886-b403-e4a95aeb2b19.png)'
- en: 'We can rewrite this as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其改写为如下形式：
- en: '![](img/894ee79f-0ded-4dc2-b569-82bd916e1a52.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/894ee79f-0ded-4dc2-b569-82bd916e1a52.png)'
- en: We also need to pick a λ^(* )and *x^** value so that *L*(*x^*, λ^**) is minimal.
    So, for λ^*, *L*(*x,λ^**) must have a finite minimum.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要选择一个 λ^(*) 和 *x^** 的值，使得 *L*(*x^*, λ^**) 最小。所以，对于 λ^*，*L*(*x, λ^**) 必须有一个有限的最小值。
- en: From the preceding equation, we know that [![](img/d1973200-084f-4928-9b04-92f9e34424e2.png)] has
    a finite minimum at [![](img/5a174002-c832-4387-8ac7-db2d09fcf31f.png)] and the
    *x[1]* and *x[2]* terms only have a finite minimum when [![](img/cd7c0978-9bc3-4f73-b521-a66a73654af1.png)].
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的方程中，我们知道 [![](img/d1973200-084f-4928-9b04-92f9e34424e2.png)] 在 [![](img/5a174002-c832-4387-8ac7-db2d09fcf31f.png)]
    处有一个有限的最小值，并且 *x[1]* 和 *x[2]* 项只有在 [![](img/cd7c0978-9bc3-4f73-b521-a66a73654af1.png)]
    时才有有限的最小值。
- en: 'Now, to find a minimum, we take the first derivatives and make them equal to
    0, as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了找到最小值，我们求导并令其等于 0，如下所示：
- en: '![](img/20881f89-fd82-44c0-a246-251bc64ab52f.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/20881f89-fd82-44c0-a246-251bc64ab52f.png)'
- en: 'Since the first derivatives must be equal to 0, we have the following:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 由于一阶导数必须等于 0，我们得到了如下式子：
- en: '![](img/88197c13-42da-4a6d-a305-02ec24699398.png), ![](img/8f9290ee-6789-4557-9288-b71779b1baa3.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/88197c13-42da-4a6d-a305-02ec24699398.png)， ![](img/8f9290ee-6789-4557-9288-b71779b1baa3.png)'
- en: 'To confirm that these are the minimum, we find the Hessian matrix:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确认这些是最小值，我们求解 Hessian 矩阵：
- en: '![](img/78d527db-a928-4d06-a744-897d300de4d1.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/78d527db-a928-4d06-a744-897d300de4d1.png)'
- en: As we would expect, this is positive semi-definite when [![](img/34972cc9-724b-4970-9156-0df5942666d5.png)].
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们预期的那样，当 [![](img/34972cc9-724b-4970-9156-0df5942666d5.png)] 时，这个矩阵是正半定的。
- en: 'The values of λ that we want are in the [![](img/82c94aa8-0ad8-4630-9137-f0ed7c6a0a62.png)] set, which
    tells us that the unique minimum of [![](img/0c6a8ebe-d447-4da8-b8be-4f52a16c4fd7.png)] is
    as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要的 λ 值在 [![](img/82c94aa8-0ad8-4630-9137-f0ed7c6a0a62.png)] 集合中，这告诉我们 [![](img/0c6a8ebe-d447-4da8-b8be-4f52a16c4fd7.png)]
    的唯一最小值如下：
- en: '![](img/c75077b2-748a-4d36-a3f9-0816a559e6e5.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c75077b2-748a-4d36-a3f9-0816a559e6e5.png)'
- en: All we have to do now is find the values of *λ* and *x* for *x*(λ) that satisfy
    the constraints.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们要做的就是找到 *λ* 和 *x* 对应的 *x*(λ) 的值，以满足约束条件。
- en: Newton's method
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 牛顿法
- en: Newton's method is a second-order optimization method that rescales the gradients
    in all directions using the inverse of the corresponding eigenvalues of the Hessian.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 牛顿法是一种二阶优化方法，它通过使用海森矩阵对应特征值的逆来重新缩放各个方向上的梯度。
- en: As we know, we are trying to find the value of *x^** that minimizes *f(x)* and
    satisfies [![](img/e9bcb20c-1acb-4c37-8ef7-6bb613d393ed.png)]. Imagine that we
    are currently at a point, *x[k]*, and we move to *x[k+1]*, which is closer to
    *x^**. We can write this step as [![](img/dc2066c6-c7ce-47e2-bed8-0489d0086ef7.png)] (or
    [![](img/403534da-227e-48b6-9e54-e31c5b5751a6.png)]).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，我们试图找到最小化 *f(x)* 且满足 [![](img/e9bcb20c-1acb-4c37-8ef7-6bb613d393ed.png)]
    的 *x^** 的值。假设我们当前位于 *x[k]* 处，并且我们移动到更接近 *x^** 的 *x[k+1]* 处。我们可以将这一步表示为 [![](img/dc2066c6-c7ce-47e2-bed8-0489d0086ef7.png)]（或
    [![](img/403534da-227e-48b6-9e54-e31c5b5751a6.png)]）。
- en: The reason why Newton step works well is because it behaves well when *x* is
    near *x^** since it takes the steepest descent direction at *x*. However, its
    performance is slow when we are at *x[0]* because the second derivative at *x[0]* does
    not give us reliable information about which direction we need to move in to reach
    *x^**.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 牛顿法之所以有效，是因为当 *x* 接近 *x^** 时，它能表现得很好，因为它在 *x* 处取的是最速下降方向。然而，当我们位于 *x[0]* 时，它的表现较慢，因为在
    *x[0]* 处的二阶导数不能为我们提供关于需要朝哪个方向移动才能到达 *x^** 的可靠信息。
- en: 'Now, let''s suppose that [![](img/9d926883-fa35-47f7-9aa2-32745227cf4b.png)].
    Then, we have the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设 [![](img/9d926883-fa35-47f7-9aa2-32745227cf4b.png)]。那么，我们得到以下结果：
- en: '![](img/cc2b9e7d-eb1a-4ac4-b4af-33877ae3ea93.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cc2b9e7d-eb1a-4ac4-b4af-33877ae3ea93.png)'
- en: Here, [![](img/c9f7842e-6b1d-4883-87db-19f7d4da7519.png)].
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，[![](img/c9f7842e-6b1d-4883-87db-19f7d4da7519.png)]。
- en: 'We can rewrite this as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其重写如下：
- en: '![](img/057d4594-ac8a-4f9e-8f85-be59d57effb5.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/057d4594-ac8a-4f9e-8f85-be59d57effb5.png)'
- en: 'This is known as the Newton step. Therefore, at *x[k]*, *x[k+1]* minimizes
    the following quadratic function:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为牛顿步。因此，在 *x[k]* 处，*x[k+1]* 最小化以下二次函数：
- en: '![](img/1bd96824-6494-4a48-aa93-097152d97363.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1bd96824-6494-4a48-aa93-097152d97363.png)'
- en: We also know that *Hf(x)* is positive definite, which tells us [![](img/9634901f-8c85-41cb-b723-ae9033d24dcd.png)],
    unless [![](img/48d6bf17-bc1e-4f52-ac5d-4a4c5301a129.png)].
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还知道 *Hf(x)* 是正定的，这告诉我们 [![](img/9634901f-8c85-41cb-b723-ae9033d24dcd.png)]，除非
    [![](img/48d6bf17-bc1e-4f52-ac5d-4a4c5301a129.png)]。
- en: 'When we receive our new value, *x[k+1]*, we can expect an error in it. This
    error is proportional to the square of the error in *x[k]*. We can see this as
    follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们接收到新的值 *x[k+1]* 时，可以预期其中会有误差。这个误差与 *x[k]* 中的误差的平方成正比。我们可以如下观察这一点：
- en: '![](img/d326693a-4c49-4758-a31a-4ac942cccdb5.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d326693a-4c49-4758-a31a-4ac942cccdb5.png)'
- en: This leads to this method converging quadratically (speedily, but only as long
    as *x[k]* is close to the optimal value).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得该方法以二次收敛的速度收敛（快速，但仅当 *x[k]* 接近最优值时）。
- en: The secant method
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 割线法
- en: In Newton's method, we calculated the first and second derivatives, but calculating
    the Hessian in a large problem is not ideal.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在牛顿法中，我们计算了一阶和二阶导数，但在一个大问题中计算海森矩阵并不理想。
- en: Suppose we have a function, [![](img/485f8af8-d2f3-4953-a916-803ce127c619.png)],
    and *n = 50*. If we take the first derivative of *f*, with respect to each case
    of *x[i]*, we get 50 equations. Now, if we calculate the second derivative, we
    have 2,500 equations, with respect to *x[i]* and *x[j]*, in a matrix. However,
    because Hessians are symmetric, we only really have to calculate 1,275 second
    derivatives. This is still a considerably large amount.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个函数，[![](img/485f8af8-d2f3-4953-a916-803ce127c619.png)]，并且 *n = 50*。如果我们分别对每个
    *x[i]* 求 *f* 的一阶导数，我们得到 50 个方程。现在，如果我们计算二阶导数，我们将得到 2,500 个关于 *x[i]* 和 *x[j]* 的方程，这些方程组成一个矩阵。然而，由于海森矩阵是对称的，我们实际上只需要计算
    1,275 个二阶导数。这仍然是一个相当庞大的数量。
- en: The secant method uses the Newton method, but instead of computing the second
    derivative, it estimates them using the first derivative, which makes it better
    suited to practice.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 割线法利用了牛顿法，但它不是计算二阶导数，而是使用一阶导数来估计，这使得它在实际应用中更加适用。
- en: 'It approximates the second derivative as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 它通过如下方式近似二阶导数：
- en: '![](img/f5ad01f4-7760-40ad-98ea-0e6847f36272.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f5ad01f4-7760-40ad-98ea-0e6847f36272.png)'
- en: 'We take this approximation and plug it into the Newton method, which gives
    us the following:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这个近似值代入牛顿法，得到以下结果：
- en: '![](img/5f6c1680-7f83-432a-9da9-34094fedb65c.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f6c1680-7f83-432a-9da9-34094fedb65c.png)'
- en: While this does reduce the computational complexity, it suffers the same fate
    as Newton's method because it requires additional iterations to converge.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这样可以减少计算复杂度，但它和牛顿法有相同的缺点，因为它需要额外的迭代才能收敛。
- en: The quasi-Newton method
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准牛顿法
- en: 'The secant method approximated the second derivative, but the quasi-Newton
    method approximates the inverse of the Hessian. The steps are computed as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 割线法近似第二导数，而准牛顿法近似Hessian矩阵的逆。步骤如下：
- en: '![](img/798eb06b-3128-450d-aa8a-0fbda4134281.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/798eb06b-3128-450d-aa8a-0fbda4134281.png)'
- en: Here, *Q[k]* is the approximated inverse of the Hessian at *x[k]*.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*Q[k]* 是 *x[k]* 处的Hessian矩阵的近似逆。
- en: 'We start by letting *Q[1 ]*= 1 and use two terms, α and β, to update the matrix
    at each iteration to aid in improving our estimation. They are defined as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从让*Q[1]* = 1开始，并使用两个项，α和β，在每次迭代中更新矩阵，以帮助改进我们的估计。它们的定义如下：
- en: '![](img/ac775e6d-394a-44f9-bdcc-2b9387227238.png) and ![](img/a391149e-cbe9-4f5d-8b41-1294270c4579.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ac775e6d-394a-44f9-bdcc-2b9387227238.png) 和 ![](img/a391149e-cbe9-4f5d-8b41-1294270c4579.png)'
- en: 'To update the matrix at each iteration, we make use of the **Broyden-Fletcher-Goldfarb-Shanno**
    (**BFGS**) method, which works as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在每次迭代中更新矩阵，我们使用**Broyden-Fletcher-Goldfarb-Shanno**（**BFGS**）方法，具体过程如下：
- en: '![](img/a1a73000-b5cf-4aa5-ba36-89eb6ec6c039.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1a73000-b5cf-4aa5-ba36-89eb6ec6c039.png)'
- en: For minimization to work, *Q* must be positive definite.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使最小化有效，*Q* 必须是正定的。
- en: Game theory
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 博弈论
- en: Let's diverge to game theory for a bit. Games that consist of three or more
    players tend to be very challenging to solve, but two-player games are much simpler
    and are what we will focus on here.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微偏离一下，谈谈博弈论。包含三个或更多玩家的游戏通常很难解决，但双人游戏要简单得多，我们将在这里集中讨论。
- en: 'Let''s suppose we have two players that are represented by [![](img/c8555aa8-778c-4d41-8771-c7ef3a9830f4.png)],
    respectively, and they are playing rock paper scissors. As we know, in this game
    we tend to make decisions without any information about what the other player
    will choose. Each player naturally wants to win, so each player has the following
    payoff matrices:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个玩家，分别由[![](img/c8555aa8-778c-4d41-8771-c7ef3a9830f4.png)]表示，他们正在进行剪刀石头布游戏。正如我们所知道的，在这个游戏中，我们通常在没有任何关于对方选择的信息的情况下做出决定。每个玩家自然都希望获胜，因此每个玩家都有以下的收益矩阵：
- en: '![](img/becec948-a8a0-4fe5-af6c-2c270422a7f0.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/becec948-a8a0-4fe5-af6c-2c270422a7f0.png)'
- en: 'Personally, I am not the biggest fan of showing the payoff in this way because
    you have to write two matrices and look up the individual payoff each time. I
    prefer to write it in the following way:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 就我个人而言，我不是最喜欢以这种方式展示收益，因为你需要写两个矩阵并每次查找单个收益。我更喜欢以下方式：
- en: '|  | **R** | **P** | **S** |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  | **R** | **P** | **S** |'
- en: '| **R** | (0, 0) | (-1, 1) | (1, -1) |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| **R** | (0, 0) | (-1, 1) | (1, -1) |'
- en: '| **P** | (1, -1) | (0, 0) | (-1, 1) |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| **P** | (1, -1) | (0, 0) | (-1, 1) |'
- en: '| **S** | (-1, 1) | (1, -1) | (0, 0) |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| **S** | (-1, 1) | (1, -1) | (0, 0) |'
- en: In the preceding table, player 1 chooses a row, [![](img/0c17fab6-9577-4fa6-a7c1-ab626bb152ed.png)],
    and player 2 chooses a column, [![](img/b0c5dc57-d3cb-4651-9476-f889b8d51c8e.png)].
    So, if we look at the preceding table, (-1, 1) tells us that player 1 lost and
    player 2 won.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的表格中，玩家1选择一行，[![](img/0c17fab6-9577-4fa6-a7c1-ab626bb152ed.png)]，玩家2选择一列，[![](img/b0c5dc57-d3cb-4651-9476-f889b8d51c8e.png)]。因此，如果我们查看前面的表格，(-1,
    1) 表示玩家1输了，玩家2赢了。
- en: In game theory, players have strategies that determine how they act or what
    actions they can take.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在博弈论中，玩家有一组策略来决定他们的行为或可以采取的行动。
- en: 'Player *X*, in our case, has the following set of strategies:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 玩家*X*，在我们的案例中，拥有以下一组策略：
- en: '![](img/c9655716-a652-4f63-8f49-d9b4f20e0ea2.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9655716-a652-4f63-8f49-d9b4f20e0ea2.png)'
- en: 'Player *Y* has the following set of strategies:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 玩家*Y*拥有以下一组策略：
- en: '![](img/4c72aed7-05cd-456a-91da-f7802562d01a.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4c72aed7-05cd-456a-91da-f7802562d01a.png)'
- en: Here, each vector represents the probability of choosing each column or row.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，每个向量代表选择每一列或每一行的概率。
- en: Each case of [![](img/de1ec537-a985-405b-a59c-98f31802a8bd.png)] represents
    a strategy profile, and we calculate the expected payoff for player *X* as [![](img/4223e048-5b89-402e-b7fe-5c46e7d742a8.png)].
    If, for some case of *i*, *x[i ]*= 1, then we always choose *i* and call *x* a
    **pure strategy**.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 每个[![](img/de1ec537-a985-405b-a59c-98f31802a8bd.png)]的情况表示一个策略配置，我们计算玩家*X*的期望收益为[![](img/4223e048-5b89-402e-b7fe-5c46e7d742a8.png)]。如果对于某个*i*的情况，*x[i]*
    = 1，那么我们总是选择*i*，并称*x*为**纯策略**。
- en: Let's move on to another well-known example—the **prisoner's dilemma**. Here,
    we have two people who commit a crime and are caught. They each have two choices
    that they can make—testify (*T*) or stay quiet (*Q*).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论另一个著名的例子——**囚徒困境**。这里有两个人，他们犯了罪并被抓住。他们每个人有两个选择可以做——作证（*T*）或保持沉默（*Q*）。
- en: 'The following are the outcomes of the choices they can make:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是他们可以做出的选择结果：
- en: If they both keep quiet, they both end up in jail serving a 2-year sentence.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果他们俩都保持沉默，他们两个人都会被判刑两年，关进监狱。
- en: If one testifies and the other stays quiet, then the one who stays quiet ends
    up serving a 3-year sentence and the testifier is freed for cooperating with the
    police.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个人作证而另一个人保持沉默，那么保持沉默的人将被判刑三年，而作证的人因为配合警方而被释放。
- en: If they both testify, then they both serve a 5-year sentence.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果他们俩都作证，他们两个人都会被判刑五年。
- en: 'Our payoff table looks as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的支付表格如下所示：
- en: '|  | **S** | **T** |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  | **S** | **T** |'
- en: '| **S** | (2, 2) | (0, 3) |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| **S** | (2, 2) | (0, 3) |'
- en: '| **T** | (3, 0) | (1, 1) |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| **T** | (3, 0) | (1, 1) |'
- en: Naturally, each person wants to maximize their own payoff; note that neither
    of the two has the opportunity to know or discuss what the other is going to do,
    so colluding is not an option. Therefore, each person would prefer to testify
    since this option is strictly better. We call *T* a dominant strategy and (1,
    1) is Pareto, dominated by (2, 2).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，每个人都希望最大化自己的回报；请注意，这两个人都没有机会知道或讨论对方将做什么，所以合谋并不是一个选项。因此，每个人都会更倾向于作证，因为这个选择显然更好。我们称
    *T* 为占优策略，而 (1, 1) 是帕累托最优，且被 (2, 2) 所支配。
- en: 'Let''s suppose we have a game and a strategy profile (*x, y*), such that they
    are in equilibrium (where *x* is the best response to *y* and vice versa). Then,
    we define ![](img/007884d9-2905-481e-aea0-3ad51a954c68.png) as having the best
    response to [![](img/cc93028a-aedc-4603-98c4-578efdfe4db3.png)], if for all cases
    of ![](img/e9ab4434-9dcc-4bf3-bab7-6f7491422d39.png) we have the following:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个游戏和一个策略组合 (*x, y*)，使得它们处于均衡状态（即 *x* 是 *y* 的最佳回应，反之亦然）。那么，我们定义 ![](img/007884d9-2905-481e-aea0-3ad51a954c68.png)
    为对 [![](img/cc93028a-aedc-4603-98c4-578efdfe4db3.png)] 的最佳回应，如果对于所有情况 ![](img/e9ab4434-9dcc-4bf3-bab7-6f7491422d39.png)，我们有以下内容：
- en: '![](img/539b5840-f024-428c-ae93-9215e848e352.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/539b5840-f024-428c-ae93-9215e848e352.png)'
- en: Many of you will likely have heard the term zero-sum before, but for those of
    you haven't, it is a special game where the total payoff is 0, such that [![](img/bbceec62-804a-44a1-a40c-ebd28cfbcd87.png)].
    The earlier example of rock-paper-scissor is a good demonstration of this.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 你们中的许多人可能听说过零和游戏这个术语，但对于那些没有听说过的人来说，它是指总回报为0的特殊游戏，因此 [![](img/bbceec62-804a-44a1-a40c-ebd28cfbcd87.png)]。早前的石头剪刀布示例很好地展示了这一点。
- en: 'A very important solution to the two-player matrix game is the minimax theorem.
    Suppose we have a [![](img/94e995ea-4eb6-43f1-bde6-ae17cc74b5a6.png)] payoff matrix. Then,
    we have the following:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个二人博弈的矩阵游戏，一个非常重要的解法是极小极大定理。假设我们有一个 [![](img/94e995ea-4eb6-43f1-bde6-ae17cc74b5a6.png)] 支付矩阵。然后，我们得到以下内容：
- en: '![](img/ed611ad9-a52e-475c-b137-9da12ede3f24.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed611ad9-a52e-475c-b137-9da12ede3f24.png)'
- en: This states that if both players use the minimax strategy, then they are in
    equilibrium since this results in both player 1 and player 2 getting the worst
    payoff, which satisfies the criteria. This is quite similar to finding the optimal
    value of [![](img/39a0c42c-e60a-480f-bfbe-5fe47a0475b2.png)], subject to constraints,
    as in a linear program.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这表示如果两个玩家都使用极小极大策略，那么它们处于均衡状态，因为这导致玩家1和玩家2都得到最差的回报，从而满足均衡条件。这与在约束条件下找到 [![](img/39a0c42c-e60a-480f-bfbe-5fe47a0475b2.png)]
    的最优值非常相似，就像线性规划中的问题一样。
- en: Descent methods
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下降方法
- en: 'Generally, descent methods take the following form:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，下降方法的形式如下：
- en: '![](img/bd6e953e-c815-4c3a-83c9-2695c27a1ccf.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd6e953e-c815-4c3a-83c9-2695c27a1ccf.png)'
- en: Here, [![](img/fdc594cc-721b-47af-9249-1641bb64234a.png)], and [![](img/71014de6-e392-4e10-89cc-c2c7af122bbc.png)].
    In the preceding algorithm, *k* is a sequence of steps, *x[k]* is the optimal
    point, and ![](img/7357c2be-114d-4c06-ba07-dbff575f048b.png) is a step. The scalar
    value, *c[k]*, is the size of the step at the *k^(th)* iteration.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，[![](img/fdc594cc-721b-47af-9249-1641bb64234a.png)]，以及 [![](img/71014de6-e392-4e10-89cc-c2c7af122bbc.png)]。在之前的算法中，*k*
    是步骤的序列，*x[k]* 是最优点，而 ![](img/7357c2be-114d-4c06-ba07-dbff575f048b.png) 是一步。标量值，*c[k]*，是第
    *k^(th)* 次迭代中的步长。
- en: In descent methods, [![](img/65830918-0eeb-42f0-83cd-8bc5a5e472ea.png)], except
    in the case where *x[k]* is the optimal value, which tells us that [![](img/ccfa74c5-0839-4bd7-b331-cf5756775f01.png)] for
    all cases of *k*.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在下降法中，[![](img/65830918-0eeb-42f0-83cd-8bc5a5e472ea.png)]，除非 *x[k]* 是最优值，这告诉我们
    [![](img/ccfa74c5-0839-4bd7-b331-cf5756775f01.png)] 对所有 *k* 的情况都适用。
- en: Gradient descent
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度下降
- en: Gradient descent is a widely used first-order optimization problem, and it takes
    steps in the direction of the negative of the gradient of the function from the
    point it is currently at until it eventually terminates at the optimal solution.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一种广泛使用的第一阶优化问题，它从当前所在的点出发，沿着函数的负梯度方向逐步前进，直到最终停在最优解处。
- en: Imagine you're at a skateboarding park and you have a tennis ball in your hand.
    You bend down and place the ball on the surface of a ramp and let it go; gravity
    does its thing and the ball follows the ramp's curvature, finding its way to the
    bottom. This is the concept behind gradient descent.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你在滑板公园，手里拿着一个网球。你弯下腰，将球放在一个坡道的表面上并放开；重力起作用，球沿坡道的曲率滑动，最终到达底部。这就是梯度下降的概念。
- en: 'In this case, the natural choice for the step is the negative gradient; that
    is, [![](img/2cb191ce-de37-4a7d-8213-3516637fd748.png)]. This is known as **gradient
    descent**, which takes the following form:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，步长的自然选择是负梯度；即，[![](img/2cb191ce-de37-4a7d-8213-3516637fd748.png)]。这就是**梯度下降**，其形式如下：
- en: '![](img/29d1d41f-0ca4-4fd3-b214-30914dea5118.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/29d1d41f-0ca4-4fd3-b214-30914dea5118.png)'
- en: 'In optimization, we generally define the stopping criteria as a condition that,
    when satisfied, should stop our algorithm from continuing to optimize. It usually
    takes the following form:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化中，我们通常定义停止标准为一个条件，当满足时，应该停止我们的算法继续优化。它通常呈现如下形式：
- en: '![](img/7735d23d-1601-4df8-9331-58d0064b89d8.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7735d23d-1601-4df8-9331-58d0064b89d8.png)'
- en: Here, η is a small positive number.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，η 是一个小的正数。
- en: 'We should remember, from the previous chapter, that if we have a function, *f*(*x,
    y*), then its gradient is [![](img/beb5c523-0bd6-4196-b675-22768cf354d5.png)].
    Therefore, we can compute the magnitude (or steepness) of the function at (*x,
    y*) as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该记得，在前一章中，如果我们有一个函数 *f*(*x, y*)，则它的梯度为 [![](img/beb5c523-0bd6-4196-b675-22768cf354d5.png)]。因此，我们可以按如下方式计算在
    (*x, y*) 处的函数的幅度（或陡峭度）：
- en: '![](img/ed63a23a-902f-411d-83ef-60baeda060e5.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed63a23a-902f-411d-83ef-60baeda060e5.png)'
- en: This acts as a guide and tells us the direction that we should move at each
    step (since the curvature changes as we move downwards) to get to the minima.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这起到了指导作用，告诉我们在每一步应该朝哪个方向移动（因为随着我们向下移动，曲率会变化），以达到最小值。
- en: However, gradient descent isn't perfect. It can be quite slow if the step size, *c^((k))*,
    is too small, and if the step size is too large, we may not reach the optimal
    point due to overshooting, which would result in our algorithm failing to converge,
    thus diverging instead.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，梯度下降并不完美。如果步长 *c^((k))* 太小，可能会非常慢；如果步长太大，则可能由于过度跳跃而无法到达最优点，这样会导致算法无法收敛，反而会发散。
- en: 'To understand this better, let''s take a look at the following two diagrams.
    The first diagram has a small step size and looks as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这一点，让我们看一下以下两个图示。第一个图示有一个较小的步长，图示如下：
- en: '![](img/d0232347-0f57-44bb-a724-638332817422.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d0232347-0f57-44bb-a724-638332817422.png)'
- en: 'The second diagram shows a large step size:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个图示展示了较大的步长：
- en: '![](img/be9d6a16-bcf1-4514-80da-51bce1372770.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be9d6a16-bcf1-4514-80da-51bce1372770.png)'
- en: 'As you can see, a good step size is important, and picking it isn''t always
    an easy task. Luckily, there is a method known as **adaptive step size** that
    adjusts the step size after each iteration. It follows two rules:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，选择一个合适的步长非常重要，而选择它并不总是容易的。幸运的是，有一种叫做 **自适应步长** 的方法，它会在每次迭代后调整步长。它遵循两个规则：
- en: If the value of the function increases after a step—which means the step size
    was too large—then undo the step and decrease the step size.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果步长后函数值增加——这意味着步长过大——那么就撤销这个步骤并减小步长。
- en: If the value of the function decreases the size of the step, then increase the
    step size.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果函数的值在减小步长时下降，那么就增加步长。
- en: Still, this isn't perfect either. As you can tell from the diagram, the optimization
    is somewhat erratic, and when we encounter more flat surfaces, our algorithm tends
    to slow down.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这也并不完美。从图示中可以看出，优化过程有些不稳定，当我们遇到更平坦的表面时，算法的速度往往会减慢。
- en: Stochastic gradient descent
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机梯度下降
- en: By now, you should be able to tell that computing the gradient and getting to
    the optima isn't easy and is time-consuming.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该能察觉到，计算梯度并达到最优解并不容易，而且非常耗时。
- en: This is why computing an approximation that points us in the same general direction instead is
    useful. We call this method **stochastic Gradient Descent** (**SGD**), and it
    is a very important algorithm that theoretically guarantees convergence. The word
    **stochastic** comes from the fact that we do not know the precise value of the
    gradient, only an approximation of it.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么计算一个能指引我们朝着大致方向前进的近似值是有用的。我们称这种方法为**随机梯度下降**（**SGD**），它是一个非常重要的算法，从理论上保证收敛。**随机**这个词来源于我们并不清楚梯度的精确值，只能得到一个近似值。
- en: 'Let''s suppose we have *M* points [![](img/f6ad3959-1bb7-4bef-ac6b-f52f1431d3dc.png)],
    where *M* is very large. This becomes a big optimization problem. So, we take
    an objective function, *L*(*x*), which is a sum of the losses over the points.
    We write this as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有*M*个点[![](img/f6ad3959-1bb7-4bef-ac6b-f52f1431d3dc.png)]，其中*M*非常大。这变成了一个巨大的优化问题。所以，我们采取一个目标函数，*L*(*x*)，它是所有点的损失之和。我们将其表示如下：
- en: '![](img/b7ea1f74-f73b-4d95-8aa8-99617aca1070.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7ea1f74-f73b-4d95-8aa8-99617aca1070.png)'
- en: Here, our goal is to minimize the loss as much as possible so that our model best
    fits the true function, *y*, as in regression. By minimizing the loss, we reduce
    the distance between our model's calculated point and the true point.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们的目标是尽可能地最小化损失，以使我们的模型最贴合真实函数*y*，就像回归问题中一样。通过最小化损失，我们减少了模型计算点与真实点之间的距离。
- en: The reason we use this method is that when we have a lot of points or a large
    optimization problem, it can be very computationally infeasible to calculate the
    gradient at each point, even more so if we were to calculate the Hessian. This
    method is, on the other hand, a lot more computationally feasible.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这种方法的原因是，当我们有大量点或较大的优化问题时，计算每个点的梯度是非常不切实际的，尤其是如果我们还要计算海森矩阵的话。而这种方法，另一方面，在计算上更为可行。
- en: Loss functions
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 损失函数
- en: 'We know that we are trying to approximate a function and we are trying to get
    as close as possible to the true function. To do this, we need to define a loss
    function—we have many to choose from. The following are the main ones that are
    used in practice:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，我们正在尝试逼近一个函数，并且尽可能地接近真实函数。为此，我们需要定义一个损失函数——我们有很多选择。以下是实践中常用的主要损失函数：
- en: '[![](img/18e3c4af-4e08-462b-9487-fdbc47868572.png)], known as **mean squared
    error**'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/18e3c4af-4e08-462b-9487-fdbc47868572.png)]，也称为**均方误差**。'
- en: '[![](img/92ae23a0-4a80-41bc-b62b-096e4074bfee.png)], known as **mean absolute
    error**'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/92ae23a0-4a80-41bc-b62b-096e4074bfee.png)]，也称为**均值绝对误差**。'
- en: '[![](img/2740f6ba-8d21-4a6a-927e-4a039f373f43.png)], known as **square loss**'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/2740f6ba-8d21-4a6a-927e-4a039f373f43.png)]，也称为**平方损失**。'
- en: '[![](img/700d1816-3736-4e8a-91f4-556a2ac823ca.png)], known as **hinge loss**'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/700d1816-3736-4e8a-91f4-556a2ac823ca.png)]，也称为**铰链损失**。'
- en: '[![](img/2ce94877-0693-48c6-a7f1-da2ea1b42a0f.png)], known as **cross-entropy
    loss**'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/2ce94877-0693-48c6-a7f1-da2ea1b42a0f.png)]，也称为**交叉熵损失**。'
- en: '[![](img/6efd84a2-e6d4-4c2d-b783-970bff2d0585.png)], known as **Huber loss**'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/6efd84a2-e6d4-4c2d-b783-970bff2d0585.png)]，也称为**Huber损失**。'
- en: We will revisit them later on and understand when it is best to use each one.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在稍后重新审视这些内容，并理解何时最好使用每一种方法。
- en: Gradient descent with momentum
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带动量的梯度下降
- en: 'As we have seen, gradient descent takes some time to find its way to a relatively
    flat surface. An improvement to the preceding example is gradient descent with
    momentum, which smoothes the gradient updates so that it is less erratic. Consider
    a tennis ball and a boulder both rolling down a mountain. The tennis ball would
    bounce around more and likely get stuck, but the boulder would gain momentum as
    it goes and maintain a relatively straight path toward the bottom. That is the
    key idea behind this improvement. It does so by remembering the previous updates
    and each update is a combination of the previous and current gradients, as follows:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，梯度下降需要一些时间才能找到相对平坦的区域。对前一个例子的改进是带动量的梯度下降，它通过平滑梯度更新来减少波动性。考虑一颗网球和一块巨石同时从山上滚下。网球会四处弹跳，可能会被卡住，但巨石会随着时间的推移获得动量，并保持相对笔直的路径向下滚动。这就是这个改进的核心思想。它通过记住以前的更新，将每次更新作为前一次和当前梯度的结合，表示如下：
- en: '![](img/6572ae6c-8ee4-49a3-a5d7-6853320b02cd.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6572ae6c-8ee4-49a3-a5d7-6853320b02cd.png)'
- en: Here, [![](img/e3e4f1a1-8a9f-4fb9-bf41-76cef419bd4a.png)] and [![](img/6880e464-a804-4b46-852c-649fb51be543.png)].
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这里， [![](img/e3e4f1a1-8a9f-4fb9-bf41-76cef419bd4a.png)] 和 [![](img/6880e464-a804-4b46-852c-649fb51be543.png)]。
- en: In this method, as you will notice, we not only have to choose the step size, *c[k]*,
    but also the momentum coefficient, *α*.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，正如你所注意到的，我们不仅需要选择步长 *c[k]*，还需要选择动量系数 *α*。
- en: The Nesterov's accelerated gradient
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Nesterov 加速梯度
- en: While momentum dampens the oscillations of gradient descent, Nesterov's method
    allows the ball traveling down the slope to look ahead and calculate the gradient
    with respect to the future position.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 动量能够抑制梯度下降的振荡，而 Nesterov 方法则允许小球在下坡时向前看，并计算出未来位置的梯度。
- en: 'In essence, instead of calculating the gradient at *x[k]*, we use [![](img/e8029e10-cbab-44a0-a572-293b3453bb0f.png)] (where
    [![](img/f18fca39-e776-49de-aaf8-93486da448d1.png)]), which is close to where
    we would be after the next step. So, we have the following:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，我们不是在 *x[k]* 计算梯度，而是使用 [![](img/e8029e10-cbab-44a0-a572-293b3453bb0f.png)] （其中
    [![](img/f18fca39-e776-49de-aaf8-93486da448d1.png)]），它接近我们在下一步之后的位置。因此，我们有以下表达式：
- en: '![](img/666cbfa9-a992-4ac2-9356-88af667666ac.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/666cbfa9-a992-4ac2-9356-88af667666ac.png)'
- en: We could also combine the momentum update with Nesterov's accelerated gradient
    by making *γ* = *α*, which would give us [![](img/fbecbba8-da6b-4671-9008-a5c47e4b7317.png)] and [![](img/4cae029d-44ac-4a8e-82c8-1670ed5e8899.png)].
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过将 *γ* = *α* 来结合动量更新与 Nesterov 加速梯度，这样就得到了 [![](img/fbecbba8-da6b-4671-9008-a5c47e4b7317.png)]
    和 [![](img/4cae029d-44ac-4a8e-82c8-1670ed5e8899.png)]。
- en: Here, as you will notice, we now have three parameters (*c*, *α*, and *γ*) instead
    of the two that we had in momentum.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你会注意到，我们现在有三个参数（*c*、*α* 和 *γ*），而不是动量法中的两个。
- en: Adaptive gradient descent
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自适应梯度下降
- en: We briefly touched on adaptive step sizes earlier. These methods generally use
    the gradients from previous steps to guide the search direction and the step size
    to get us to convergence faster. The two main ones that we will look at are **adaptive
    gradient** (**Adagrad**) and **adaptive moment estimation** (**Adam**).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前简要提到过自适应步长。这些方法通常使用前一步的梯度来指导搜索方向和步长，从而帮助我们更快地收敛。我们将要重点讲解的两种方法是 **自适应梯度**
    (**Adagrad**) 和 **自适应矩估计** (**Adam**)。
- en: As before, our goal is to find *x^**, which minimizes the loss function.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们的目标是找到 *x^**，使得损失函数最小化。
- en: These gradient descent methods take the form of [![](img/23762e3b-c12e-43bd-accd-e1c492f78c1f.png)],
    where *G[k]* is the gradient at the *k^(th)* step.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这些梯度下降方法的形式是 [![](img/23762e3b-c12e-43bd-accd-e1c492f78c1f.png)]，其中 *G[k]* 是第
    *k* 步的梯度。
- en: 'In the case of Adagrad, we have [![](img/35f9a6ac-b612-47c6-97e3-5b24640f7fcb.png)] and
    [![](img/ddde34a3-f360-4682-a1e1-9136ab371742.png)], which, if we plug into the
    preceding equation, gives us the following:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Adagrad 的情况下，我们有 [![](img/35f9a6ac-b612-47c6-97e3-5b24640f7fcb.png)] 和 [![](img/ddde34a3-f360-4682-a1e1-9136ab371742.png)]，将其代入前面的方程后，得到以下结果：
- en: '![](img/f9f741ed-9707-4162-9eb5-0a79fa5910ac.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9f741ed-9707-4162-9eb5-0a79fa5910ac.png)'
- en: As you can see, we use the square root of the sum of the squares of the losses
    to update the step size at each step, which eliminates the need to do this ourselves.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们使用损失平方和的平方根来更新每一步的步长，这样就不需要我们自己手动计算了。
- en: Adam also keeps a history of the previous gradients, but it differs from Adagrad
    in that it stores an exponentially moving average of both the squared gradients
    and the gradients.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Adam 也会保留前几步的梯度历史，但与 Adagrad 不同的是，它保存了梯度平方和梯度的指数加权平均值。
- en: We write this as [![](img/9e4e7164-1d00-4652-b66c-9f3187bd4ee4.png)] and [![](img/e9002cf3-1a66-4b95-a06d-0076f242de72.png)].
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将其写作 [![](img/9e4e7164-1d00-4652-b66c-9f3187bd4ee4.png)] 和 [![](img/e9002cf3-1a66-4b95-a06d-0076f242de72.png)]。
- en: Simulated annealing
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟退火
- en: Simulated annealing is inspired by the field of metallurgy, where we use heat
    to alter the properties of a material. The applied heat increases the energy of
    ions and moves more freely. As the material starts to cool, it takes on a different
    shape upon reaching its equilibrium state. The heat needs to be slowly and gradually
    reduced to avoid the material getting stuck in a metastable state, which represents
    a local minimum.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟退火的灵感来源于冶金学领域，我们通过加热来改变材料的属性。施加的热量增加了离子的能量，使其更加自由地移动。当材料开始冷却时，它会在达到平衡状态时呈现出不同的形状。热量需要缓慢而逐渐地减少，以避免材料陷入亚稳态，这代表了一个局部最小值。
- en: In our case, to optimize a problem, we use temperature to control stochasticity.
    When the temperature is high, this means the process is freely and randomly exploring
    the space with the hope that it comes across a good convex region with a more
    favorable minimum. By reducing the temperature, we reduce the stochasticity and
    make the algorithm converge to a minimum.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，为了优化问题，我们使用温度来控制随机性。当温度较高时，意味着该过程在自由和随机地探索空间，希望能够找到一个有更有利最小值的良好凸区域。通过降低温度，我们减少随机性，使得算法逐渐收敛到一个最小值。
- en: Simulated annealing is a non-convex optimization algorithm and is effective
    because of its ability to escape local minima.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟退火是一种非凸优化算法，其有效性来自于它能够逃脱局部最小值。
- en: 'At each iteration, we sample a possible step from a transition distribution, *T*,
    which is accepted according to the following probability:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次迭代中，我们从转移分布*T*中抽取一个可能的步长，根据以下概率接受它：
- en: '![](img/733ba40e-94f4-43d2-9329-dc715154237e.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![](img/733ba40e-94f4-43d2-9329-dc715154237e.png)'
- en: Here, [![](img/91d15cb8-96fb-498c-bf70-b531e9718a19.png)] and ![](img/f28daa64-d175-458c-a51d-3fa71f73d7e5.png) is
    the temperature. This probability is known as the **Metropolis criterion** and
    is what gives simulated annealing the ability to escape local minima when we have
    a high temperature.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，[![](img/91d15cb8-96fb-498c-bf70-b531e9718a19.png)]和![](img/f28daa64-d175-458c-a51d-3fa71f73d7e5.png)是温度。这个概率被称为**Metropolis准则**，它使模拟退火能够在温度较高时逃离局部最小值。
- en: 'To gradually bring the temperature down, we use a decay factor, [![](img/e35b2138-1090-4143-86dd-fe192b6727e2.png)],
    which looks as follows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 为了逐渐降低温度，我们使用一个衰减因子，[![](img/e35b2138-1090-4143-86dd-fe192b6727e2.png)]，其形式如下：
- en: '![](img/2006443d-0556-4f37-9a8c-6e8a18371a3a.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2006443d-0556-4f37-9a8c-6e8a18371a3a.png)'
- en: The process continues until it meets the stopping criteria; that is, the temperature
    drops to the point where we see no improvements from *n[k]* to *n[k+1]*.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程会持续进行，直到满足停止准则；也就是说，温度降低到一个程度，以至于我们从*n[k]*到*n[k+1]*没有看到任何改进。
- en: Natural evolution
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然进化
- en: 'Natural evolution is a method that makes use of gradient descent, and our goal
    is to minimize [![](img/205c481b-b412-4d16-b476-874df8b803c8.png)]. We estimate
    the gradient from the samples, as follows:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 自然进化是一种利用梯度下降的方法，我们的目标是最小化[![](img/205c481b-b412-4d16-b476-874df8b803c8.png)]。我们从样本中估计梯度，具体如下：
- en: '![](img/adaa8636-4694-4348-bf58-875a7753d43a.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![](img/adaa8636-4694-4348-bf58-875a7753d43a.png)'
- en: Earlier, when looking at gradient descent, we needed to calculate the gradient
    of the objective function; but here, we work with the log likelihood, [![](img/b8303fc2-f8ea-467a-b043-69483e92f205.png)],
    and we can use this estimation of the gradient in any of the gradient descent
    methods we covered earlier to improve *θ*.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，在讨论梯度下降时，我们需要计算目标函数的梯度；但是在这里，我们处理的是对数似然[![](img/b8303fc2-f8ea-467a-b043-69483e92f205.png)]，并且可以使用这种梯度估计来改进*θ*，并应用于我们之前介绍的任何梯度下降方法。
- en: Exploring population methods
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索群体方法
- en: So far, we have dealt with optimization problems where we have a *ball* or *particle* that
    we edge along the curved space gradually and move toward the minima using gradient
    descent or Newton's method. Now, however, we will take a look at another class
    of optimization, where we use a population of individuals.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们处理的优化问题中，我们有一个*球体*或*粒子*，通过沿着曲面逐渐移动，并使用梯度下降或牛顿法朝着最小值前进。然而，现在我们将观察另一类优化问题，在这种问题中，我们使用一个个体群体。
- en: We spread these individuals across the optimization space, which prevents the
    optimization algorithm from getting stuck at local minima or a saddle point. These
    individuals can share information with each other about the local area they're
    in and use this to find an optimal solution that minimizes our function.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些个体分布在优化空间中，这可以防止优化算法在局部最小值或鞍点处卡住。这些个体可以互相分享它们所在局部区域的信息，并利用这些信息找到一个最优解，从而最小化我们的函数。
- en: With these algorithms, we have an initial population and we would like to distribute
    them so that we cover as much ground as we can to give us the best chance of finding
    a globally optimal region.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些算法时，我们有一个初始的个体群体，我们希望将其分布开来，以便尽可能覆盖更多区域，从而增加找到全局最优区域的最佳机会。
- en: We can sample our population from a multivariate normal distribution that is
    entered over a region that we are interested in, or uniformly distribute the population
    under some constraints; however, these two distributions are only recommended
    if you want to limit the space your population covers. Alternatively, we can use
    **Cauchy distribution**, which allows us to cover a larger space.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从一个多变量正态分布中抽样我们的种群，这个分布被输入到我们感兴趣的区域，或者在某些约束条件下均匀地分布种群；然而，只有当你想限制种群覆盖的空间时，才建议使用这两种分布。或者，我们可以使用**柯西分布**，它允许我们覆盖更大的空间。
- en: Genetic algorithms
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遗传算法
- en: Genetic algorithms are inspired by Darwinism, where a fitter individual passes
    on certain heritable characteristics to the next generation. The objective function,
    in this case, has an inverse relationship with the individual's fitness or ability
    to reproduce. The chromosomes from the fitter individuals in each generation are
    passed on to the subsequent generation after having been subjected to crossover
    and mutation.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 遗传算法的灵感来源于达尔文主义，即适应性更强的个体将某些可遗传的特征传递给下一代。在这种情况下，目标函数与个体的适应度或繁殖能力呈反比关系。每一代中适应性更强的个体的染色体将在经过交叉和突变后传递给下一代。
- en: The simplest way for us to represent a chromosome is by using a binary string,
    similar to how DNA is encoded. However, a better method is writing each chromosome
    as a vector in ![](img/af6ea1fb-0cd0-400b-b83b-6198660a5911.png) that represents
    a point in the optimization space. This allows us to express crossover and mutation
    with greater ease.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们表示染色体的最简单方式是使用二进制字符串，类似于DNA编码的方式。然而，更好的方法是将每个染色体写成一个表示优化空间中一个点的向量，![](img/af6ea1fb-0cd0-400b-b83b-6198660a5911.png)。这样，我们可以更轻松地表示交叉和突变。
- en: We start with a random population, and from it, we choose a set of chromosomes
    that will be the parents for the subsequent generation. If we have a population
    of *n* chromosomes, then we will select *n* parental pairs that will produce *n* children
    in the subsequent generation.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个随机种群开始，然后从中选择一组染色体作为下一代的父代。如果我们有 *n* 个染色体，那么我们将选择 *n* 对父代，它们将生成 *n* 个孩子，形成下一代。
- en: Our goal is to minimize the objective function. So, we sample *k* random individuals
    from the population and pick the top-performing individuals from each of the samples
    or with the probability of their performance relative to the population. The fitness,
    then, of each individual has an inverse relation to [![](img/d16b37b4-541c-4aad-9d1b-d56db8d563fa.png)],
    and we can calculate it using [![](img/98fa3db9-37d1-4156-a26b-c875e9ac6018.png)].
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是最小化目标函数。因此，我们从种群中抽取 *k* 个随机个体，并从每个样本中选出表现最好的个体，或者根据它们相对于种群的表现概率来选择。然后，每个个体的适应度与[![](img/d16b37b4-541c-4aad-9d1b-d56db8d563fa.png)]成反比，我们可以通过[![](img/98fa3db9-37d1-4156-a26b-c875e9ac6018.png)]来计算它。
- en: Crossover, on the other hand, is a combination of the chromosomes of the parents,
    which results in the children. There are a number of ways that this combination
    can occur, such as single-point crossover, two-point crossover, or uniform crossover,
    or we can use one of our own making.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，交叉是父代染色体的组合，结果生成孩子。这个组合可以通过多种方式发生，比如单点交叉、两点交叉或均匀交叉，或者我们可以使用自定义的交叉方式。
- en: In fitness and crossover, there are only so many traits that can be passed on
    from the initial population to subsequent generations. However, if only the best
    traits are passed on, we will end up with a saturated population, which isn't
    what we want. This is where mutations are useful. They allow new traits to be
    created and passed on, which enables individuals to explore more of the optimization
    space. After each crossover, each child in the population experiences some mutation,
    subject to a probability.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在适应度和交叉中，只有有限的特征能够从初代种群传递到后代。然而，如果只传递最佳的特征，我们最终会得到一个饱和的种群，这不是我们想要的。这时，突变就变得非常有用。突变允许产生新的特征并传递下去，从而使个体能够探索更多的优化空间。在每次交叉后，种群中的每个孩子都会经历一些突变，突变的发生有一定的概率。
- en: Particle swarm optimization
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 粒子群优化
- en: This algorithm uses the concept of swarm intelligence, where you have a school
    of fish or a flock of birds. Let's suppose they are trying to find some food.
    They arrive at an area and spread out a bit, starting to look for food individually.
    When one of them finds food, it lets the others know so that they can join in.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法利用了群体智能的概念，就像一群鱼或一群鸟。假设它们正在寻找食物。它们到达一个区域后稍微分开，开始各自寻找食物。当其中一只发现了食物时，它会告诉其他个体，以便大家一起参与。
- en: Each individual in the population knows its current position and velocity and only keeps
    track of the previous best positions it has visited. The velocity vector determines
    the direction of the search, and if the individual has a high velocity, then it
    has a more explorative character, whereas if it has a low velocity, it has a more
    exploitative character.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 种群中的每个个体都知道其当前的位置和速度，并且只记录它所访问过的最佳位置。速度向量决定了搜索的方向，如果个体具有较高的速度，则表现出更强的探索性；而如果速度较低，则表现出更多的利用性。
- en: 'At the start of each iteration, the whole population is accelerated to the
    best position that any individual has come across so far. The updates are computed
    as follows:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次迭代的开始，整个种群都会被加速到任何个体迄今为止遇到的最佳位置。更新过程如下所示：
- en: '![](img/dc39b971-d525-47fe-aa0b-8e35460d6988.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dc39b971-d525-47fe-aa0b-8e35460d6988.png)'
- en: Here, *x[best]* is the best position found by the group as a whole, [![](img/53046c2c-9631-4b82-8d0a-2e128da57c7f.png)] is
    the best position that an individual has found, *w*, *α[1]*, and *α[2]* are parameters,
    and [![](img/50b9c5eb-fd86-4247-a994-3f2c34ee65ee.png)].
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*x[best]* 是整个群体所找到的最佳位置，[![](img/53046c2c-9631-4b82-8d0a-2e128da57c7f.png)]
    是个体所找到的最佳位置，*w*、*α[1]* 和 *α[2]* 是参数，[![](img/50b9c5eb-fd86-4247-a994-3f2c34ee65ee.png)]。
- en: The values of *c[1]* and *c[2]* heavily influence the rate at which they converge.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '*c[1]* 和 *c[2]* 的值在它们收敛的速度上有着重要的影响。'
- en: Summary
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered a number of different kinds of optimization, such
    as convex and non-convex optimization, as well as what makes optimization such
    a challenging problem. We also had a look at how to define an optimization problem
    and explored a variety of methods, including population methods, simulated annealing,
    and gradient descent-based methods. In later chapters, we'll come to understand
    how optimization is used in deep learning and why it is such an important field
    for us to understand.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了几种不同的优化方法，如凸优化和非凸优化，以及使优化成为一个具有挑战性问题的原因。我们还学习了如何定义优化问题，并探索了包括种群方法、模拟退火法和基于梯度下降的方法在内的多种方法。在后续的章节中，我们将进一步了解优化在深度学习中的应用，以及为何它是我们必须理解的一个重要领域。
- en: In the next chapter, we will learn about graph theory and its uses in the field
    to solve various problems.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习图论及其在该领域中的应用，解决各种问题。
