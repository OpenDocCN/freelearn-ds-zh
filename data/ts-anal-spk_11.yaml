- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Recent Developments in Time Series Analysis
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列分析的最新发展
- en: As we reach the last chapter of this book, let’s do a brief recap of the journey
    we have been through. Starting with an introduction to time series and its components
    in [*Chapter 1*](B18568_01.xhtml#_idTextAnchor016), we looked at the different
    use cases for time series analysis in [*Chapter 2*](B18568_02.xhtml#_idTextAnchor044).
    We were then introduced to Apache Spark, its architecture, and how it works in
    [*Chapter 3*](B18568_03.xhtml#_idTextAnchor063). Before delving into the details
    of how Apache Spark is used for time series analysis, we stepped back, in [*Chapter
    4*](B18568_04.xhtml#_idTextAnchor087), to look at the big picture of an end-to-end
    time series project. We then turned our focus to each of the main stages of a
    project from [*Chapter 5*](B18568_05.xhtml#_idTextAnchor103) to [*Chapter 9*](B18568_09.xhtml#_idTextAnchor169),
    covering data preparation, exploratory data analysis, model development, testing,
    scaling, and going to production. In [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190),
    we covered ways to go further with Apache Spark by using a managed data and AI
    platform such as Databricks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们走到本书的最后一章时，让我们简要回顾一下我们走过的历程。从在[*第1章*](B18568_01.xhtml#_idTextAnchor016)中介绍时间序列及其组成开始，我们在[*第2章*](B18568_02.xhtml#_idTextAnchor044)中查看了时间序列分析的不同应用场景。接着，我们在[*第3章*](B18568_03.xhtml#_idTextAnchor063)中介绍了Apache
    Spark及其架构，以及它是如何工作的。在深入探讨Apache Spark如何用于时间序列分析之前，我们在[*第4章*](B18568_04.xhtml#_idTextAnchor087)中回顾了一个端到端的时间序列项目的整体框架。随后，我们将焦点转向项目的主要阶段，从[*第5章*](B18568_05.xhtml#_idTextAnchor103)到[*第9章*](B18568_09.xhtml#_idTextAnchor169)，涵盖了数据准备、探索性数据分析、模型开发、测试、扩展和生产部署。在[*第10章*](B18568_10.xhtml#_idTextAnchor190)中，我们讨论了通过使用如Databricks这样的托管数据和AI平台，如何进一步利用Apache
    Spark。
- en: In this concluding chapter, we will explore recent developments in the field
    of time series analysis, covering emerging methodologies, tools, and trends. We
    will cover an approach from the exciting field of generative AI applied to time
    series forecasting. Having a forecasting mechanism in place is great but not enough.
    Another area of interesting development is how forecasting is served and made
    available on demand to data analysts and applications. End users can also benefit
    from new approaches to making the outcome of time series analysis accessible to
    them in non-technical ways.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的结尾，我们将探讨时间序列分析领域的最新发展，涵盖新兴的方法论、工具和趋势。我们将介绍一种来自生成式AI领域的时间序列预测方法。拥有一个预测机制固然很棒，但还不够。另一个有趣的发展方向是如何通过API向数据分析师和应用程序提供并按需提供预测结果。最终用户也可以通过新的方法受益，使时间序列分析的结果以非技术性的方式对他们可访问。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主要内容：
- en: Generative AI for time series
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列的生成式AI
- en: Serving forecasts via API
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过API提供预测
- en: Democratizing access to time series analysis
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 民主化时间序列分析的访问
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: We will be using a Databricks environment for the platform infrastructure. To
    set up the environment, follow the instructions in the *Environment setup* section
    of [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Databricks环境作为平台基础设施。要设置环境，请按照[*第10章*](B18568_10.xhtml#_idTextAnchor190)中*环境设置*部分的说明进行操作。
- en: 'The code for this chapter can be found at this URL:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在此URL找到：
- en: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch11](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch11)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch11](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch11)'
- en: Generative AI for time series analysis
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列分析中的生成式AI
- en: While effective, traditional time series models have limitations in performance
    and accuracy, especially with large-scale data or complex patterns.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管传统的时间序列模型有效，但在大规模数据或复杂模式下，它们在性能和准确性上存在局限性。
- en: Generative AI, and particularly **time series transformers** (**TSTs**), offers
    a solution to these challenges. Similar to the transformer models in **natural
    language processing** (**NLP**), TSTs are adept at capturing complex, non-linear
    dependencies over long sequences. This capability makes them suitable for real-world
    data that includes missing values, seasonality, and irregular patterns. TSTs use
    a self-attention mechanism to analyze time series data and identify seasonal patterns.
    These models are pre-trained on vast datasets to create foundation models, which
    can then be fine-tuned for specific time series applications.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能，特别是**时间序列变换器**（**TSTs**），为这些挑战提供了解决方案。类似于**自然语言处理**（**NLP**）中的transformer模型，TSTs擅长捕捉长序列上的复杂、非线性依赖关系。这种能力使它们适用于包含缺失值、季节性和不规则模式的真实世界数据。TSTs使用自注意机制分析时间序列数据并识别季节性模式。这些模型在庞大数据集上进行预训练以创建基础模型，然后可以针对特定时间序列应用进行微调。
- en: Recently, several pre-built TSTs have been released enabling us to leverage
    their capabilities without requiring effort to engineer such solutions. Examples
    include Chronos, Moira, TimesFM, and TimeGPT, among others.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，已发布了几个预构建的TST，使我们能够利用它们的功能，而无需努力工程化这些解决方案。示例包括Chronos、Moira、TimesFM和TimeGPT等。
- en: In the next section, we will examine the practicalities of using one of these
    with TimesFM.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将研究如何使用其中之一与TimesFM。
- en: Introduction to TimesFM
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TimesFM简介
- en: '**TimesFM**, short for **Time Series Foundation Model**, is an open source
    forecasting model developed by Google Research, designed specifically for time
    series data. Built on a transformer-based architecture, TimesFM is versatile,
    handling a wide range of forecasting tasks from short-term to long-term predictions.
    Unlike models such as Chronos, which treat time series similarly to natural language,
    TimesFM includes specialized mechanisms for time series data, such as seasonality
    handling, support for missing values, and capturing multivariate dependencies.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**TimesFM**，简称**时间序列基础模型**，是由谷歌研究开发的开源预测模型，专门设计用于时间序列数据。TimesFM建立在基于transformer的架构上，具有多功能性，可以处理从短期到长期预测的各种任务。与Chronos等将时间序列类似于自然语言处理的模型不同，TimesFM包括针对时间序列数据的专门机制，如季节性处理、支持缺失值和捕捉多变量依赖关系。'
- en: Pre-trained on over 100 billion real-world time series points, TimesFM generalizes
    effectively to new datasets, often providing accurate zero-shot predictions without
    additional training. This extensive pre-training allows TimesFM to recognize both
    short- and long-term dependencies in time series data, making it highly useful
    for applications requiring an understanding of seasonal patterns and trends.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在超过1000亿真实世界时间序列点上进行预训练，TimesFM有效地推广到新数据集，通常在没有额外训练的情况下提供准确的零-shot预测。这种广泛的预训练使TimesFM能够识别时间序列数据中的短期和长期依赖关系，使其非常适用于需要了解季节模式和趋势的应用程序。
- en: 'For an overview of the TimesFM architecture and a detailed explanation, we
    recommend consulting the original research paper, *A decoder-only foundation model
    for time-series* *forecasting*, here:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解TimesFM架构的概述和详细解释，我们建议查阅原始研究论文，*一种仅解码器的时间序列基础模型* *预测*，请点击这里：
- en: '[https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/](https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/](https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/)'
- en: We will see TimesFM in action with a forecasting example in the next section.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中通过一个预测示例看到TimesFM的实际应用。
- en: Forecasting
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测
- en: 'For the time series forecasting example in this section, we will be using the
    Databricks environment as set up in the *Technical requirements* section. The
    code for this section can be uploaded into the Databricks workspace from the following
    URL:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的时间序列预测示例中，我们将使用在*技术要求*部分设置的Databricks环境。本节的代码可以从以下URL上传到Databricks工作区：
- en: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_timesFM.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_timesFM.dbc)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_timesFM.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_timesFM.dbc)'
- en: You can use the Databricks serverless compute to execute the code, as we did
    in [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190). Alternatively, you can use
    the Databricks Runtime for ML. Version 14.3 is required for compatibility with
    the version of Python supported by TimesFM at the time of writing.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用Databricks无服务器计算来执行代码，正如我们在[*第10章*](B18568_10.xhtml#_idTextAnchor190)中所做的那样。或者，你可以使用Databricks
    Runtime for ML。由于TimesFM在撰写时支持的Python版本要求，必须使用14.3版本。
- en: 'We will go through the steps to install and use TimesFM here, with code extracts.
    Refer to the notebook for the full code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里通过代码示例逐步讲解如何安装和使用TimesFM。完整代码请参见笔记本：
- en: 'Install the following necessary libraries: `timesfm[torch]`, `torch`, and `sktime`.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装以下必要的库：`timesfm[torch]`、`torch`和`sktime`。
- en: 'Specify the hyperparameters (`hparams`) and load the TimesFM model from a checkpoint
    in Hugging Face (`huggingface_repos_id`). Note that `500m` refers to the 500 million
    parameters supported by the model, and we will use the `pytorch` version due to
    compatibility with Databricks:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定超参数（`hparams`），并从Hugging Face的检查点加载TimesFM模型（`huggingface_repos_id`）。请注意，`500m`指的是模型支持的5亿个参数，由于与Databricks的兼容性，我们将使用`pytorch`版本：
- en: '[PRE0]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: While we have used the default values for the hyperparameters, you will need
    to experiment to find the best ones to use depending on your forecasting requirement.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虽然我们使用了超参数的默认值，但你需要进行实验，根据你的预测需求找到最佳的超参数。
- en: With the TimesFM model loaded, we can bring in the dataset for forecasting.
    We will reuse the energy consumption dataset from [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190).
    Before proceeding with the next step, you must execute the code example, including
    the feature engineering pipeline from the previous chapter.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 加载TimesFM模型后，我们可以引入用于预测的数据集。我们将重新使用来自[*第10章*](B18568_10.xhtml#_idTextAnchor190)的能源消耗数据集。在进行下一步之前，你必须执行代码示例，包括上一章中的特征工程管道。
- en: 'We will read from the `features_aggr_power_consumption` table and convert the
    Spark DataFrame into a pandas DataFrame, which is required by TimesFM. The `Date`
    column is renamed to `date` and converted to the `datetime` format, as expected
    by the model:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从`features_aggr_power_consumption`表中读取数据，并将Spark DataFrame转换为pandas DataFrame，这是TimesFM所需要的。`Date`列重命名为`date`，并转换为模型所期望的`datetime`格式：
- en: '[PRE1]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Function to create a data pipeline for batching time series
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建批量时间序列数据管道的函数
- en: data
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: def get_batched_data_fn(
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: def get_batched_data_fn(
- en: …
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: …
- en: examples["inputs"].append(
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: examples["inputs"].append(
- en: sub_df["hourly_Global_active_power"][
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: sub_df["hourly_Global_active_power"][
- en: start:(context_end := start + context_len)
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: start:(context_end := start + context_len)
- en: '].tolist())'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '].tolist())'
- en: …
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: …
- en: examples["outputs"].append(
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: examples["outputs"].append(
- en: sub_df["hourly_Global_active_power"][
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: sub_df["hourly_Global_active_power"][
- en: context_end:(context_end + horizon_len)
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: context_end:(context_end + horizon_len)
- en: '].tolist())'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '].tolist())'
- en: …
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: …
- en: '[PRE2]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can then iterate over the batches of input data to generate the forecast
    using the `forecast` function, as in the following code extract:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以遍历输入数据的批次，使用`forecast`函数生成预测，代码示例如下：
- en: '[PRE3]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We evaluate the forecast using the `mdape` metric, as we have done in the previous
    chapters. This is comparable to [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190):'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`mdape`指标来评估预测效果，正如我们在前几章所做的那样。这与[*第10章*](B18568_10.xhtml#_idTextAnchor190)类似：
- en: '[PRE4]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This gives the following result:'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将得到以下结果：
- en: '[PRE5]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As we have seen in this section, using a pre-trained transformer-based foundation
    model such as TimesFM, with default hyperparameters, gives us comparable accuracy
    to the different approaches we have used in the previous chapters. With hyperparameter
    tuning and the use of covariates, which will be discussed next, we can seek to
    further improve accuracy.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本节中所看到的，使用基于预训练的Transformer模型（如TimesFM），并且使用默认的超参数，能够提供与我们在前几章中使用的不同方法相当的准确性。通过超参数调优和协变量的使用（下文将讨论），我们可以进一步提高准确性。
- en: Support for covariates
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协变量支持
- en: An important feature of TimesFM is its support for external **covariates**,
    as time series rarely occur in isolation. Various factors, such as economic indicators
    or weather conditions, can correlate with a time series, and incorporating these
    into the analysis can improve prediction accuracy. Put simply, a covariate is
    a separate variable that can help us forecast a time series.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: TimesFM的一个重要特性是它支持外部**协变量**，因为时间序列很少是孤立出现的。经济指标或天气条件等多种因素可能与时间序列相关联，将这些因素纳入分析可以提高预测的准确性。简单来说，协变量是一个独立的变量，可以帮助我们预测时间序列。
- en: TimesFM accommodates both univariate and multivariate forecasting with covariates,
    enabling it to capture correlations between the target series and these external
    variables. By inputting covariates as parallel sequences, the model learns how
    they relate to future values over time, enhancing its adaptability to real-world
    scenarios where external factors significantly impact outcomes. For example, we
    can investigate using the estimation of road traffic to forecast pollution levels.
    This capability to support covariates gives TimesFM a predictive edge over traditional
    time series models and other foundational models that do not incorporate these
    variables.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: TimesFM 支持单变量和多变量预测，包含协变量，使其能够捕捉目标序列与这些外部变量之间的相关性。通过将协变量作为并行序列输入，模型可以学习它们与未来值之间的关系，从而增强其在外部因素对结果产生显著影响的实际场景中的适应性。例如，我们可以通过估算道路交通来预测污染水平。这一支持协变量的能力使得
    TimesFM 在预测上相较于传统时间序列模型和其他不包含这些变量的基础模型具有优势。
- en: 'You can find more information on covariates support with an example here:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这里找到有关协变量支持的更多信息和示例：
- en: '[https://community.databricks.com/t5/technical-blog/genai-for-time-series-analysis-with-timesfm/ba-p/95507](https://community.databricks.com/t5/technical-blog/genai-for-time-series-analysis-with-timesfm/ba-p/95507)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://community.databricks.com/t5/technical-blog/genai-for-time-series-analysis-with-timesfm/ba-p/95507](https://community.databricks.com/t5/technical-blog/genai-for-time-series-analysis-with-timesfm/ba-p/95507)'
- en: Other generative AI models and Many Model Forecasting
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他生成式 AI 模型和多模型预测
- en: You can test other generative models to find the best one for your use case.
    One way to do this is with the **Many Model Forecasting** (**MMF**) Solution Accelerator
    by Databricks. This offers a solution for organizations needing to create forecasts
    across numerous time series, such as for sales, demand, or inventory predictions.
    The repository provides a scalable approach using Databricks to deploy and manage
    many forecasting models simultaneously. It includes resources such as notebooks,
    model templates, and data pipelines that streamline the process of training, evaluating,
    and deploying time series models on a large scale.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以测试其他生成式模型，以找到最适合您用例的模型。一种方法是使用 Databricks 的 **多模型预测**（**MMF**）解决方案加速器。该加速器为需要在多个时间序列上创建预测的组织提供了解决方案，例如销售、需求或库存预测。该仓库提供了一个可扩展的方法，使用
    Databricks 同时部署和管理多个预测模型。它包括笔记本、模型模板和数据管道等资源，简化了在大规模上训练、评估和部署时间序列模型的过程。
- en: 'You can find more information here:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此找到更多信息：
- en: '[https://github.com/databricks-industry-solutions/many-model-forecasting](https://github.com/databricks-industry-solutions/many-model-forecasting)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/databricks-industry-solutions/many-model-forecasting](https://github.com/databricks-industry-solutions/many-model-forecasting)'
- en: With generative AI and MMF now part of our time series analysis toolkit, let's
    explore how we can enhance the availability of forecasts for applications and
    data analysts.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式 AI 和 MMF 成为我们时间序列分析工具包的一部分，让我们探索如何增强预测结果对应用和数据分析师的可用性。
- en: Serving forecasts via API
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 API 提供预测
- en: The main part of this book has focused on preparing and analyzing a time series
    dataset. We also covered presenting the analysis’s outcomes in tables and graphs
    in notebooks and reporting dashboards. However, in many cases, forecasts must
    be served on-demand to data analysts and applications. We will now explore ways
    to achieve this.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的主要部分集中在准备和分析时间序列数据集上。我们还涵盖了如何在笔记本和报告仪表板中以表格和图形的形式呈现分析结果。然而，在许多情况下，预测必须按需提供给数据分析师和应用程序。我们现在将探讨如何实现这一目标。
- en: Forecasting simplified with ai_forecast
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过 ai_forecast 简化预测
- en: In this situation, the data analyst has access to time series data and wants
    to provide this as input to get a forecast without first having to develop a model.
    By abstracting the forecast behind a function such as the `ai_forecast` function
    on the Databricks platform, the ability to forecast can be greatly simplified
    for someone without knowledge of forecasting models and algorithms.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，数据分析师可以访问时间序列数据，并希望将其作为输入来获取预测，而无需首先开发一个模型。通过将预测功能抽象为 Databricks 平台上的
    `ai_forecast` 函数，可以大大简化没有预测模型和算法知识的用户进行预测的过程。
- en: 'You can see this action with a simple example at the following URL:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下 URL 查看一个简单示例：
- en: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_aiforecast.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_aiforecast.dbc)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_aiforecast.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_aiforecast.dbc)'
- en: 'This code is based on the example in the documentation, the link to which is
    provided at the end of this section:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码基于文档中的示例，链接在本节末尾提供：
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The output of running this example is shown in *Figure 11**.1*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此示例的输出如*图11.1*所示。
- en: '![](img/B18568_11_1.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_11_1.jpg)'
- en: 'Figure 11.1: Example output of ai_forecast'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1：ai_forecast示例输出
- en: 'You can find and zoom in on a digital version of *Figure* *11**.1* here:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处找到并放大*图11.1*的数字版本：
- en: https://packt.link/vg87q
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: https://packt.link/vg87q
- en: Note that this feature is in public preview at the time of this writing, so
    you may need to request access from Databricks to try it.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在撰写本文时，此功能仍处于公开预览阶段，因此您可能需要向Databricks请求访问权限才能试用它。
- en: 'You can find more information here:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处找到更多信息：
- en: '[https://docs.databricks.com/en/sql/language-manual/functions/ai_forecast.html](https://docs.databricks.com/en/sql/language-manual/functions/ai_forecast.html)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.databricks.com/en/sql/language-manual/functions/ai_forecast.html](https://docs.databricks.com/en/sql/language-manual/functions/ai_forecast.html)'
- en: While a simplified and predefined function such as `ai_function` is a great
    way to quickly generate a forecast, we may want to make our own custom-developed
    forecasting model accessible easily to other applications, as we will cover next.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然像`ai_function`这样简化且预定义的函数是快速生成预测的好方法，但我们可能希望使我们自己定制开发的预测模型能够轻松供其他应用访问，接下来我们将介绍如何做到这一点。
- en: Model Serving
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型服务
- en: In some cases, we need to programmatically get a forecast from our model from
    another application. For such application-to-application integration, the use
    of a REST API is a common practice. One way to provide a REST API interface to
    our model is by using Databricks’ **Model Serving**.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，我们需要从另一个应用程序中以编程方式获取模型的预测。对于这种应用间集成，使用REST API是一种常见做法。提供REST API接口的一种方式是使用Databricks的**模型服务**。
- en: Databricks’ Model Serving provides the functionality for deploying, governing,
    and querying ML and AI models, for both real-time and batch inference. The deployed
    model is accessible via a REST API, which enables integration into web or client
    applications. Various model types are supported, including custom Python models
    packaged in the MLflow format and open foundation models provided. This service
    is designed for high availability and low latency, automatically scaling to changing
    demand.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks的模型服务提供了部署、管理和查询ML和AI模型的功能，支持实时推理和批量推理。已部署的模型可以通过REST API访问，从而集成到Web或客户端应用程序中。支持多种模型类型，包括以MLflow格式打包的自定义Python模型和提供的开放基础模型。该服务旨在高可用性和低延迟，并能自动扩展以应对需求变化。
- en: 'Here’s an overview of the steps to serve a model. Note that this is not a working
    example. The screenshots shown here are to illustrate the steps only:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是提供模型服务的步骤概览。请注意，这不是一个实际的示例。此处展示的截图仅用于说明步骤：
- en: Access the model in Unity Catalog as per *Figure 11**.2* and click the **Serve
    this model** button at the top right.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照*图11.2*中的步骤访问Unity Catalog中的模型，并点击右上角的**服务此模型**按钮。
- en: '![](img/B18568_11_2.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_11_2.jpg)'
- en: 'Figure 11.2: Model in Unity Catalog'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2：Unity Catalog中的模型
- en: Create a serving endpoint as per *Figure 11**.3*. This will show the URL to
    use to access the REST API to invoke the model.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照*图11.3*中的步骤创建服务端点。此时将显示访问REST API以调用模型的URL。
- en: '![](img/B18568_11_3.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_11_3.jpg)'
- en: 'Figure 11.3: Create serving endpoint'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3：创建服务端点
- en: When creating the serving endpoint, we can enable an inference table, as per
    *Figure 11**.4*, to store all the input and output of interactions with the model
    REST API.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建服务端点时，我们可以启用推理表，如*图11.4*所示，以存储与模型REST API交互的所有输入和输出。
- en: '![](img/B18568_11_4.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_11_4.jpg)'
- en: 'Figure 11.4: Inference tables'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4：推理表
- en: Once created, the serving endpoint will be shown with the status of **Ready**,
    as per *Figure 11**.5*, and can be used.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建后，服务端点将显示为**准备就绪**状态，如*图11.5*所示，并可以使用。
- en: '![](img/B18568_11_5.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_11_5.jpg)'
- en: 'Figure 11.5: Serving endpoint is ready'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5：服务端点已准备就绪
- en: As the serving endpoint is used, its metrics can be monitored, as per *Figure
    11**.6*.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当使用服务端点时，可以根据*图11.6*来监控其指标。
- en: '![](img/B18568_11_6.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_11_6.jpg)'
- en: 'Figure 11.6: Service endpoint metrics'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6：服务端点指标
- en: 'You can find more information on Model Serving here:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在此找到有关模型服务的更多信息：
- en: '[https://docs.databricks.com/en/machine-learning/serve-models.html](https://docs.databricks.com/en/machine-learning/serve-models.html)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.databricks.com/en/machine-learning/serve-models.html](https://docs.databricks.com/en/machine-learning/serve-models.html)'
- en: As we have seen in this section, exposing our time series analysis model via
    a REST API makes it easier to integrate the analysis with other applications.
    Continuing on the accessibility of time series analysis, we will look next at
    how to facilitate this for end users as well.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本节中看到的，通过 REST API 暴露我们的时间序列分析模型，使得将分析与其他应用程序集成变得更加容易。继续讨论时间序列分析的可访问性，接下来我们将探讨如何为最终用户简化这一过程。
- en: Democratizing access to time series analysis
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 普及时间序列分析的访问
- en: In this section, we will explore how innovative approaches to accessing the
    outcome of time series can benefit non-technical users. This allows us to democratize
    time series analysis for the benefit of an even broader audience.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探索访问时间序列结果的创新方法如何使非技术用户受益。这使得我们能够将时间序列分析普及化，惠及更广泛的受众。
- en: Genie spaces
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Genie 空间
- en: In the first approach, we will be using a natural language chatbot-like interface
    on Databricks called **Genie spaces**.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种方法中，我们将使用 Databricks 上类似自然语言聊天机器人的界面，称为 **Genie 空间**。
- en: The Databricks Genie spaces is a conversational UI enabling business users to
    ask questions in natural language and receive analytical insights without requiring
    technical expertise. This works by configuring Genie spaces with relevant datasets,
    sample queries, and instructions. Users can then interact in natural language,
    asking questions and visualizations about the data. Genie uses annotated table
    and column metadata to translate the user queries into SQL statements. These are
    used to query the data so that Genie can provide responses to users.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks Genie 空间是一个对话式 UI，使业务用户能够用自然语言提问并获得分析见解，而无需技术专长。这通过配置 Genie 空间与相关数据集、示例查询和说明来实现。然后，用户可以用自然语言与系统互动，提出关于数据的问题和可视化需求。Genie
    使用带注释的表格和列元数据将用户查询转化为 SQL 语句。这些语句用于查询数据，以便 Genie 可以向用户提供响应。
- en: To see this in practice, we will use the dashboard that we created in [*Chapter
    10*](B18568_10.xhtml#_idTextAnchor190), as shown in *Figure 11**.7*. This is one
    way to access Genie – from the dashboard, we can click on the top-left **Ask Genie**
    button. This opens a chatbot-like interface at the bottom right, where we can
    start typing questions in natural language. Alternatively, we can choose to open
    the Genie space in a full screen.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实践这一点，我们将使用在 [*第 10 章*](B18568_10.xhtml#_idTextAnchor190) 中创建的仪表板，如 *图 11.7*
    所示。这是访问 Genie 的一种方式——在仪表板上，我们可以点击左上角的 **询问 Genie** 按钮。这将打开右下角的聊天机器人界面，我们可以开始用自然语言输入问题。或者，我们可以选择将
    Genie 空间打开为全屏模式。
- en: '![](img/B18568_11_7.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_11_7.jpg)'
- en: 'Figure 11.7: Access to Genie space from the dashboard'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7：从仪表板访问 Genie 空间
- en: In *Figure 11**.8*, we can see the complete Genie space with a query, the results,
    and the generated SQL used to get the results.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 11.8* 中，我们可以看到完整的 Genie 空间，包括查询、结果和用于获取结果的生成 SQL。
- en: '![](img/B18568_11_8.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_11_8.jpg)'
- en: 'Figure 11.8: Genie spaces query and results'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.8：Genie 空间查询和结果
- en: The query in this example is to show **Forecasted vs. Actual**, which can also
    be requested as a visualization, as shown in *Figure 11**.9*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例中的查询是显示 **预测与实际**，这也可以作为可视化请求，如 *图 11.9* 所示。
- en: '![](img/B18568_11_9.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_11_9.jpg)'
- en: 'Figure 11.9: Genie spaces visualization'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.9：Genie 空间可视化
- en: 'You can find more information on Databricks Genie spaces here: [https://docs.databricks.com/en/genie/index.html](https://docs.databricks.com/en/genie/index.html)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在此找到有关 Databricks Genie 空间的更多信息：[https://docs.databricks.com/en/genie/index.html](https://docs.databricks.com/en/genie/index.html)
- en: Apps
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用
- en: In cases where more application-like interactivity is required, a dashboard
    or chatbot interface is not sufficient to meet the users’ needs. Databricks Apps
    provides a platform to build and deploy applications directly within the Databricks
    environment. Currently in public preview, Databricks Apps supports development
    frameworks such as Dash, Shiny, Gradio, Streamlit, and Flask, for the creation
    of data visualizations, AI applications, self-service analytics, and other data
    applications.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要更多应用式交互性的情况下，仪表盘或聊天机器人界面不足以满足用户需求。Databricks 应用提供了一个平台，可以在 Databricks 环境中直接构建和部署应用。目前处于公开预览阶段，Databricks
    应用支持如 Dash、Shiny、Gradio、Streamlit 和 Flask 等开发框架，用于创建数据可视化、AI 应用、自助分析和其他数据应用。
- en: 'You can find more information on Databricks Apps here: [https://www.databricks.com/blog/introducing-databricks-apps](https://www.databricks.com/blog/introducing-databricks-apps)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到更多关于 Databricks 应用的信息：[https://www.databricks.com/blog/introducing-databricks-apps](https://www.databricks.com/blog/introducing-databricks-apps)
- en: Summary
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this final chapter, we delved into recent advancements in time series analysis,
    focusing on emerging methodologies, tools, and trends. We tried the innovative
    approach from the dynamic field of generative AI applied to time series forecasting.
    To answer the growing requirement for forecasts via API, we explored ways to provide
    on-demand forecasting to data analysts and applications. We concluded with the
    use of an AI chatbot and Databricks Apps to democratize access to time series
    analysis for non-technical users.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后，我们深入探讨了时间序列分析的最新进展，重点关注新兴的方法论、工具和趋势。我们尝试了将生成式 AI 这一创新方法应用于时间序列预测的前沿领域。为了响应对通过
    API 进行预测的需求增长，我们探索了如何为数据分析师和应用提供按需预测服务。最后，我们使用了 AI 聊天机器人和 Databricks 应用，旨在使非技术用户也能便捷地进行时间序列分析。
- en: As we arrive at the end of the book, looking back at our journey and the skills
    we acquired, we have built a solid foundation on the multiple stages of time series
    analysis projects with Apache Spark and other components. Armed with the multiple
    use cases discussed in [*Chapter 2*](B18568_02.xhtml#_idTextAnchor044), the practical
    skills gained throughout the book, and the recent advancements in this chapter,
    we have the necessary ingredients to succeed in production-ready, scalable, and
    future-proofed time series analysis projects across industries.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们到达本书的尾声，回顾我们的旅程和所获得的技能时，我们已经在使用 Apache Spark 和其他组件进行时间序列分析项目的多个阶段上打下了坚实的基础。凭借[*第二章*](B18568_02.xhtml#_idTextAnchor044)中讨论的多个应用场景、本书中获得的实践技能，以及本章中的最新进展，我们已经具备了成功实施可生产、可扩展并具备未来适应性的时间序列分析项目所需的所有要素。
- en: We began this book with Pericles' wise counsel on the importance of time—now,
    at the end of this book, we have the ability to uncover the valuable insights
    hidden in time series and use them to our benefit. May this knowledge empower
    you to tackle challenges with new ideas and confidence. Wishing you happy learning
    and success on your journey with time series analysis and Apache Spark!
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以 Pericles 关于时间重要性的智慧建议开始了这本书——现在，在本书的结尾，我们具备了揭示时间序列中隐藏的宝贵洞察并将其运用到实际中的能力。愿这些知识使你能够以新的思路和信心应对挑战。祝你在时间序列分析和
    Apache Spark 的学习旅程中取得成功！
- en: Join our community on Discord
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们在 Discord 的社区
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者讨论：
- en: '[https://packt.link/ds](https://packt.link/ds)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/ds](https://packt.link/ds)'
- en: '![Join our community on Discord ](img/ds_(1).jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![加入我们在 Discord 的社区](img/ds_(1).jpg)'
