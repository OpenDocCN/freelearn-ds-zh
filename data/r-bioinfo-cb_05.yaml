- en: Metagenomics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 宏基因组学
- en: The use of high throughput sequencing has turbocharged metagenomics from a field
    focused on studying variation in single sequences such as the 16S **ribosomal
    RNA** (**rRNA**) sequence to studying entire genomes of the many species that
    may be present in a sample. The task of identifying species or taxa and their
    abundances in a sample is computationally challenging and requires the bioinformatician
    to deal with the preparation of sequences, assignment to taxa, comparisons of
    taxa, and quantifications. Packages for this have been developed by a wide range
    of specialist laboratories that have created new tools and new visualizations
    specific to working with sequences in metagenomics.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 高通量测序技术已经大大推动了宏基因组学的发展，从一个专注于研究单一序列变异的领域（例如16S **核糖体RNA** (**rRNA**) 序列）发展到研究样本中可能存在的多个物种的整个基因组。识别物种或分类单元及其在样本中的丰度是一项计算挑战，要求生物信息学家处理序列准备、分类分配、分类比较以及定量分析。为此，许多专业实验室已经开发出相关的包，这些包创造了特定于宏基因组学中序列处理的新工具和新可视化。
- en: 'In this chapter, we''ll look at recipes to carry out some complex analyses
    in metagenomics with R:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将查看一些在R中进行宏基因组学复杂分析的配方：
- en: Loading in hierarchical taxonomic data using `phyloseq`
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`phyloseq`加载层级分类数据
- en: Rarefying counts to correct for sample differences using `metacoder`
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`metacoder`进行计数稀疏化以纠正样本差异
- en: Reading amplicon data from raw reads with `dada2`
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`dada2`从原始读取中读取扩增子数据
- en: Visualizing taxonomic abundances with heat trees in `metacoder`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`metacoder`中的热图树可视化分类丰度
- en: Computing sample diversity with `vegan`
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`vegan`计算样本多样性
- en: Splitting sequence files into operational taxonomic units
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将序列文件拆分为操作性分类单元
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The sample data you'll need is available from this book's GitHub repository
    at [https://github.com/PacktPublishing/R-Bioinformatics-Cookbook](https://github.com/PacktPublishing/R-Bioinformatics-Cookbook)[.](https://github.com/danmaclean/R_Bioinformatics_Cookbook) If
    you want to use the code examples as they are written, then you will need to make
    sure that this data is in a sub-directory of whatever your working directory is.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要的示例数据可以从本书的GitHub库获取：[https://github.com/PacktPublishing/R-Bioinformatics-Cookbook](https://github.com/PacktPublishing/R-Bioinformatics-Cookbook)[.](https://github.com/danmaclean/R_Bioinformatics_Cookbook)
    如果你想按原样使用代码示例，你需要确保这些数据位于你的工作目录的子目录中。
- en: 'Here are the R packages that you''ll need. Most of these will install with
    `install.packages()`*;* others are a little more complicated:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是你需要的R包。大多数包可以通过`install.packages()`安装*；*其他一些包安装起来稍微复杂一些：
- en: '`ape`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ape`'
- en: '`Bioconductor`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Bioconductor`'
- en: '`dada2`'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dada2`'
- en: '`phyloseq`'
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`phyloseq`'
- en: '`corrplot`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`corrplot`'
- en: '`cowplot`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cowplot`'
- en: '`dplyr`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dplyr`'
- en: '`kmer`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kmer`'
- en: '`magrittr`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`magrittr`'
- en: '`metacoder`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metacoder`'
- en: '`RColorBrewer`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RColorBrewer`'
- en: '`vegan`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vegan`'
- en: 'Bioconductor is huge and has its own installation manager. You can install
    it with the following code:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Bioconductor非常庞大，并且拥有自己的安装管理器。你可以通过以下代码安装它：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Further information is available at the following link: [https://www.bioconductor.org/install/](https://www.bioconductor.org/install/).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步的信息可以通过以下链接获取：[https://www.bioconductor.org/install/](https://www.bioconductor.org/install/)。
- en: Normally, in R, a user will load a library and use the functions directly by
    name. This is great in interactive sessions but it can cause confusion when many
    packages are loaded. To clarify which package and function I'm using at a given
    moment, I will occasionally use the `packageName::functionName()` convention.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在R中，用户会加载一个库并直接按名称使用函数。这在交互式会话中非常方便，但在加载多个包时可能会造成混乱。为了明确我在某一时刻使用的是哪个包和函数，我偶尔会使用`packageName::functionName()`的约定。
- en: 'Sometimes, in the middle of a recipe, I''ll interrupt the code so you can see
    some intermediate output or the structure of an object that''s important to understand.
    Whenever that happens, you''ll see a code block where each line begins with `##` (double
    hash) symbols. Consider the following command:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，在一个配方的中间，我会中断代码，方便你查看一些中间输出或对象结构，这对于理解非常重要。每当这种情况发生时，你会看到一个代码块，其中每一行都以`##`（双井号）符号开头。请看下面的命令：
- en: '`letters[1:5]`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`letters[1:5]`'
- en: 'This will give us the following output:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们以下输出：
- en: '`## a b c d e`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`## a b c d e`'
- en: Note that the output lines are prefixed with `##`.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，输出行前面有`##`的前缀。
- en: Loading in hierarchical taxonomic data using phyloseq
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用phyloseq加载层级分类数据
- en: Metagenomics pipelines often start with large sequencing datasets that are processed
    in powerful and fully featured programs such as QIIME and `mothur`. In these cases,
    it is the results from these tools that we wish to prepare into reports or further
    specific analysis with R. In this recipe, we'll look at how we can get the output
    from QIIME and `mothur` into R.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 元基因组学管道通常从大型测序数据集开始，这些数据集会在强大且功能齐全的程序中处理，如QIIME和`mothur`。在这些情况下，我们希望将这些工具的结果整理成报告或进一步进行特定分析。在这个步骤中，我们将展示如何将QIIME和`mothur`的输出导入R中。
- en: Getting ready
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this short recipe, we need the `phyloseq` package from `Bioconductor` and
    files in the `datasets/ch5` folder of this book's data repository.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个简短的步骤，我们需要从`Bioconductor`安装`phyloseq`包，并从本书数据仓库的`datasets/ch5`文件夹中获取文件。
- en: How to do it...
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Loading in hierarchical taxonomic data using `phyloseq` can be done using the
    following steps:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`phyloseq`加载层次分类数据可以通过以下步骤完成：
- en: 'Load the library:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Import the QIIME `.biom` file:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入QIIME的`.biom`文件：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Access different parts of the `phyloseq` object:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问`phyloseq`对象的不同部分：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Import the `mothur` data files:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`mothur`数据文件：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Access the `otu` object in the `phyloseq` object:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问`phyloseq`对象中的`otu`对象：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: How it works...
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this straightforward recipe, we create objects and use accessor functions.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的步骤中，我们创建对象并使用访问器函数。
- en: In *Step 1*, we load the `phyloseq` library as is customary.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第1步*中，我们按惯例加载`phyloseq`库。
- en: Then, in *Step 2*, we define a file and use it as the first argument to the
    `import_biom()` function. This function can read the modern `biom` format output
    from QIIME in uncompressed JSON and compressed HDF5 forms. The type is detected
    automatically. We get back a fully populated `phyloseq` object.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在*第2步*中，我们定义一个文件，并将其作为`import_biom()`函数的第一个参数。该函数可以读取来自QIIME的现代`biom`格式输出，支持未压缩的JSON和压缩的HDF5格式。类型会自动检测。我们将得到一个完全填充的`phyloseq`对象。
- en: In *Step 3*, we use the accessor functions to get the subsections of the object,
    the taxonomies with `tax_table()`, the OTU with `otu_table()`, and the sample
    data with `sample_data()`; these can all be used downstream easily as they are
    matrix-like objects.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第3步*中，我们使用访问器函数获取对象的子部分，使用`tax_table()`获取分类数据，使用`otu_table()`获取OTU，使用`sample_data()`获取样本数据；这些都可以作为类似矩阵的对象在后续处理中轻松使用。
- en: We change track in *Step 4* and work with the `mothur` output. We need a list
    file and group file at least, which we specify as file paths in the `mothur_list_file`
    and `mothur_group_file` arguments. Here, we also specify a Newick format tree
    with the `mothur_tree_file` argument.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第4步*中，我们改变方向，使用`mothur`的输出数据。我们至少需要一个列表文件和一个分组文件，这些文件路径通过`mothur_list_file`和`mothur_group_file`参数指定。这里，我们还通过`mothur_tree_file`参数指定一个Newick格式的树。
- en: Again, we can use the `phyloseq accessor` function, `otu_table()`, to get the
    OTU. With the minimal `mothur` data, we specify here that we can't get the sample
    data or taxonomy table.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以使用`phyloseq`的访问器函数`otu_table()`来获取OTU。对于最小的`mothur`数据，我们在此指定不能获取样本数据或分类学表。
- en: There's more...
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: If you have data generated from an older version of QIIME in the proprietary
    format, you can use the `import_qiime()` function. There is also an accessor function
    for the tree object if you attach one—`phy_tree()`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有来自旧版QIIME的专有格式数据，可以使用`import_qiime()`函数。若你附加了树对象，也有一个访问器函数——`phy_tree()`。
- en: See also
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: The websites and wiki pages of the QIIME and `mothur` programs do a great job
    of showing how to work with the data from their pipelines in R, particularly `mothur`.
    If you'd like analysis ideas for this data, try them out.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: QIIME和`mothur`程序的官网和wiki页面非常出色地展示了如何在R中处理它们管道输出的数据，尤其是`mothur`。如果你想要一些数据分析的思路，可以试试它们。
- en: Rarefying counts and correcting for sample differences using metacoder
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用metacoder稀释计数并校正样本差异。
- en: In metagenomics, a common question is to ask which species are present in a
    sample and what is the difference between two or more samples. Since samples can
    be made up of different amounts of observations—which, in a metagenomic sense,
    means the different amounts of reads that were generated—then the taxonomic richness
    of the sample will increase with the depth of sequencing. To assess the diversity
    of different taxa represented in samples fairly, metagenomicists will often perform
    rarefaction on the counts to ensure the samples all have constant depths. Essentially,
    this means reducing the sample depth down to whatever the lowest sample depth
    is. We'll perform rarefaction on OTU counts from a `biom` file in this recipe.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在宏基因组学中，一个常见的问题是询问某个样本中存在哪些物种，以及两个或多个样本之间的差异。由于样本可能由不同数量的观察值组成——在宏基因组学中，这意味着生成的不同数量的读取——因此样本的分类丰富度会随着测序深度的增加而增加。为了公平地评估样本中不同类群的多样性，宏基因组学家通常会对计数进行稀释，以确保样本的测序深度相同。本质上，这意味着将样本深度减少到最小的样本深度。在这个步骤中，我们将对来自
    `biom` 文件的 OTU 计数进行稀释。
- en: Getting ready
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this recipe, you'll need the `metacoder` package and `datasets/ch5/rich_high_count_otu.biom`, which
    is an example `biom` file with six samples (labeled `Sample1`–`Sample6`) and five
    OTUs. This is, of course, a very small file, useful only to learn how the code
    works. Real metagenomic datasets are much larger.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个步骤，你将需要 `metacoder` 包和 `datasets/ch5/rich_high_count_otu.biom`，这是一个包含六个样本（标记为
    `Sample1`–`Sample6`）和五个 OTU 的示例 `biom` 文件。当然，这是一个非常小的文件，只用于学习代码的工作原理。真实的宏基因组数据集要大得多。
- en: How to do it...
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Rarefying counts and correcting for sample differences using `metacoder` can
    be done using the following steps:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `metacoder` 对计数进行稀释并修正样本差异可以通过以下步骤完成：
- en: 'Load the library and files:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库和文件：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create a histogram of counts in the samples:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建样本中计数的直方图：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Call the rarefaction function and filter out low OTUs that may be created:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用稀释函数并过滤掉可能生成的低 OTU：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works...
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The overall pattern here is to get the file loaded, check the distribution of
    sample OTU counts, and apply rarefaction.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的总体模式是加载文件，检查样本 OTU 计数的分布，并应用稀释法。
- en: The first step is to get the library loaded and the example file imported. We
    do this by preparing the `rich_high_count_otu.biom` file, which we pass to the
    `parse_qiime()` function. This `metacoder` function simply reads in biome files
    and returns a `taxmap` object (another type of object for holding taxonomic data)
    that we can use in the `metacoder` functions.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是加载库并导入示例文件。我们通过准备 `rich_high_count_otu.biom` 文件来完成此操作，并将其传递给 `parse_qiime()`
    函数。这个 `metacoder` 函数只是读取生物群落文件并返回一个 `taxmap` 对象（另一种用于保存分类数据的对象），我们可以在 `metacoder`
    函数中使用它。
- en: 'Next, we wish to inspect the distribution of sample OTU counts, which we do
    by preparing a histogram. We make a character vector of sample names with the
    `paste()` function and use that to extract by named index the counts containing
    columns from within `otu_table`. This subset of columns is passed into the `colSums()`
    function, which gets the total counts for each sample in the `hist_data` vector.
    We can now create a histogram of those counts with `hist()` and add the density
    curve with `lines()` and the `density()` function on `hist_data`. Note that the
    resulting plot (in the following histogram) looks sparse because of the small
    number of samples in the small example file. The lowest numbers here give us an
    idea of the lowest sequenced sample. If there are stand-out low samples, it may
    be wise to remove those columns first:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们希望检查样本 OTU 计数的分布，这可以通过准备一个直方图来完成。我们使用 `paste()` 函数创建一个包含样本名称的字符向量，并用它来通过命名索引提取
    `otu_table` 中的计数列。这些列的子集被传递给 `colSums()` 函数，后者会获取 `hist_data` 向量中每个样本的总计数。现在，我们可以使用
    `hist()` 创建这些计数的直方图，并通过 `lines()` 和 `density()` 函数在 `hist_data` 上添加密度曲线。请注意，结果图（在以下直方图中）看起来较为稀疏，因为示例文件中的样本数量较少。这里的最低计数为我们提供了最低测序样本的概念。如果存在明显较低的样本，最好先去除这些列：
- en: '![](img/bf69048e-291b-494e-8d88-a2f0db900a49.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bf69048e-291b-494e-8d88-a2f0db900a49.png)'
- en: Now, we can perform rarefaction. We use the `rarefy_obs()` function on `taxdata`;
    the second argument (with the `"otu_table"` value) is the name of the slot in
    the `taxdata` object that contains the OTU counts. As rarefaction reduces counts,
    we now need to remove any that have fallen too far across all samples. Hence,
    we use the `rowSums()` function and indexing by sample name on the `taxdata$data$rarefied_otus`
    object to get a logical vector indicating which OTUs have a total count lower
    than 20\. Finally, we use the `filter_obs()` function on `taxdata`; the second
    argument (with the `"rarefied_otus"` value) is the name of the slot in the `taxdata`
    object that contains the rarefied OTU counts. The `!` character is used to invert
    the logical vector of low OTUs because `filter_obs()` keeps the rows that pass
    and we wish to remove them. The final output from this is a rarefied set of OTU
    counts.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以进行稀释分析。我们在 `taxdata` 上使用 `rarefy_obs()` 函数；第二个参数（值为 `"otu_table"`）是 `taxdata`
    对象中包含 OTU 计数的槽位名称。由于稀释会减少计数，因此我们现在需要去除在所有样本中已经减少过多的计数。因此，我们使用 `rowSums()` 函数，并通过样本名称索引
    `taxdata$data$rarefied_otus` 对象，得到一个逻辑向量，表示哪些 OTU 的总计数低于 20。最后，我们在 `taxdata` 上使用
    `filter_obs()` 函数；第二个参数（值为 `"rarefied_otus"`）是 `taxdata` 对象中包含稀释 OTU 计数的槽位名称。`!`
    字符用于反转低计数 OTU 的逻辑向量，因为 `filter_obs()` 会保留通过的行，而我们希望移除这些行。最终输出的是一个稀释后的 OTU 计数集。
- en: 'Note how, in the following output, OTU row 3 has been removed through low counts:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在以下输出中，OTU 行 3 已通过低计数被移除：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: There's more...
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'We can estimate a useful count level with rarefaction curves. With these, the
    counts are randomly sampled at varying sample sizes and the number of species
    in the OTUs is counted. The point at which the number of species stops increasing
    lets us know we have enough reads and aren''t getting any more value from dealing
    with extra counts. The `rarecurve()` function in the `vegan` package will do this
    for us. We provide an OTU table (note that this function needs the samples in
    rows so we must rotate our `taxdata` OTU table with the `t()` function). Then,
    we pass the minimum sample size for the `sample` argument. We use the `colSums()`
    and `min()` functions to get the lowest sample OTU count for this. The output
    looks like the following diagram:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过稀释曲线估算一个有用的计数水平。通过这些曲线，计数会在不同的样本大小下随机抽取，并计算 OTU 中的物种数。当物种数量停止增加时，我们就知道我们已经有足够的读取数据，并且不会从处理额外的计数中获得更多价值。`rarecurve()`
    函数在 `vegan` 包中可以帮助我们完成这一任务。我们提供一个 OTU 表（请注意，该函数需要样本按行排列，因此我们必须使用 `t()` 函数旋转我们的
    `taxdata` OTU 表）。然后，我们为 `sample` 参数传入最小样本大小。我们使用 `colSums()` 和 `min()` 函数来获取该最小样本
    OTU 计数。输出结果如下图所示：
- en: '![](img/c1c83f1c-0ad4-4d48-9de7-319c2dc02658.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c1c83f1c-0ad4-4d48-9de7-319c2dc02658.png)'
- en: Here, we can clearly see that samples over 20,000 do not increase the richness
    of species.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以清楚地看到，超过 20,000 的样本并没有增加物种的丰富度。
- en: Reading amplicon data from raw reads with dada2
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 dada2 从原始读取数据中读取扩增子数据
- en: A long-standing technique in metagenomics, particularly for those interested
    in bacterial microbiome studies, uses the sequencing of cloned copies (amplicons)
    of the 16S or 18S rRNA genes to create species profiles. These approaches can
    take advantage of lower throughput sequencing and the knowledge of the target
    sequence to classify each cloned sequence, simplifying the tricky task of assigning
    taxa to reads. In this recipe, we'll make use of the `dada2` package to run an
    amplicon analysis from raw `fastq` sequence reads. We'll perform quality control
    and OTU assignment steps and use an interesting machine learning method to classify
    sequences.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 作为元基因组学中的一项长期技术，特别是对于有兴趣进行细菌微生物组研究的人，使用 16S 或 18S rRNA 基因的克隆拷贝（扩增子）测序来创建物种谱图。这些方法可以利用低通量测序以及目标序列的知识来对每个克隆序列进行分类，从而简化了将分类单元分配到读取序列的复杂任务。在这个方案中，我们将使用
    `dada2` 包从原始 `fastq` 序列读取中运行扩增子分析。我们将执行质量控制和 OTU 分配步骤，并使用一种有趣的机器学习方法来对序列进行分类。
- en: Getting ready
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this recipe, we need the Bioconductor `dada2` package and the CRAN `cowplot`
    package. We'll use some metagenomic sequence reads from the Short Read Archive
    experiment *SRR9040914*, in which the water from a tidal marine lake at a tourist
    center was examined for species composition because people were tossing coins
    into it and making wishes. We will use twenty `fastq` files of 2,500 files each,
    each compressed and available in this book's repository at `datasets/ch5/fq`.
    This is a small subset of the full set of Illumina reads. We'll also need the
    `datasets/ch5/rdp_train_set_14.fa` file, which is one of the sets of 16S sequences
    maintained as training sets by the `dada` team. See more training sets at [http://benjjneb.github.io/dada2/training.html](http://benjjneb.github.io/dada2/training.html)*. *
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个食谱，我们需要Bioconductor的`dada2`包和CRAN的`cowplot`包。我们将使用来自短读档案实验*SRR9040914*的某些宏基因组序列数据，其中检测了一个旅游中心潮汐海湖水中的物种组成，因为游客向湖里投掷硬币并许愿。我们将使用二十个`fastq`文件，每个文件包含2500条数据，每个文件经过压缩，且可以在本书的仓库`datasets/ch5/fq`中找到。这是Illumina读取的一个小子集。我们还需要`datasets/ch5/rdp_train_set_14.fa`文件，它是由`dada`团队维护的16S序列训练集之一。更多训练集请参见[http://benjjneb.github.io/dada2/training.html](http://benjjneb.github.io/dada2/training.html)*。*
- en: How to do it...
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何进行...
- en: 'Reading amplicon data from raw reads with `dada2` can be done using the following
    steps:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`dada2`从原始读取数据中读取扩增子数据，可以按照以下步骤进行：
- en: 'Load the libraries and prepare a plot for each `fastq` file:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库并为每个`fastq`文件准备绘图：
- en: '[PRE10]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Quality trimming and dereplicating the files:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对文件进行质量修剪和去重复：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Estimate the `dada2` model from a subset of samples:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从样本子集估算`dada2`模型：
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Infer the sequence composition of the samples using the parameters estimated
    in *Step 3*:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*第3步*中估算的参数推测样本的序列组成：
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Assign taxonomy to the sequences:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给序列分配分类：
- en: '[PRE14]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: How it works...
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We first make a vector of file paths to all of the `fastq` files we wish to
    use by passing the `fq_dir` variable containing the `fastq` directory to the `list.files()`
    function. Then, we use the looping function, `lapply()`, to iterate over each
    `fastq` file path and run the `dada` function, `plotQualityProfile()`, with each
    file in turn. Each resulting plot object is saved into the list object, `quality_plots`.
    The `cowplot` function, `plot_grid()`, will plot all these in a grid when a list
    of plots is passed to the `plotlist` argument.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过将包含`fastq`目录的`fq_dir`变量传递给`list.files()`函数，创建一个所有`fastq`文件路径的向量。然后，我们使用循环函数`lapply()`，遍历每个`fastq`文件路径，并依次运行`dada`函数`plotQualityProfile()`。每个结果绘图对象都会保存到列表对象`quality_plots`中。当将绘图列表传递给`plotlist`参数时，`cowplot`函数`plot_grid()`将把这些绘图以网格形式显示出来。
- en: 'We get the plot in the following diagram. Note how the `fastq` quality scores
    are poor in the first 10 or so nucleotides and after about 260 nucleotides in.
    These will be the trimming points for the next step:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到下图所示的绘图。请注意，`fastq`质量分数在前10个核苷酸左右较差，且在大约260个核苷酸后出现问题。这些将是下一步的修剪点：
- en: '![](img/2dd7cd9b-9132-4592-bb02-73eec82e7e6c.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2dd7cd9b-9132-4592-bb02-73eec82e7e6c.png)'
- en: To carry out trimming, we run a loop over the `fastq` files in `read_files`.
    In each iteration of the loop, we create an output `fastq` filename, `out_fq`,
    by pasting the text `"trimmed.filtered"` onto the filename (since we will save
    the trimmed reads to a new file, rather than memory), then run the `fastqFilter()` trimming
    function, passing it the input filename, `fq`; the `out_fq` filename; and the
    trim parameters. At the end of this loop, we have a folder full of trimmed read
    files. The names of these are loaded into a vector with the `list.files()` function
    again—this time, matching only files with the `"trimmed.filtered"` pattern. All
    of these files are loaded into memory and dereplicated using the `derepFaistq()`
    function. We then calculate the parameters for the compositional inference step
    using the `dada()` function on a proportion of the files. We pass the first five
    sets of dereplicated files using indexing on the `derep_reads` object. By setting
    `err` to `NULL` and `selfConsist` to `TRUE`, we force `dada()` to estimate parameters
    from the data, saving the results in the `dd_model` variable.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行修剪，我们对 `read_files` 中的 `fastq` 文件运行一个循环。在每次循环迭代中，我们通过将文本 `"trimmed.filtered"`
    附加到文件名上来创建一个输出的 `fastq` 文件名 `out_fq`（因为我们将修剪后的读取结果保存到新文件中，而不是内存中），然后运行 `fastqFilter()`
    修剪函数，传递输入文件名 `fq`、输出文件名 `out_fq` 和修剪参数。循环结束后，我们将得到一个包含修剪过的读取文件的文件夹。通过再次使用 `list.files()`
    函数加载这些文件的名称，这次只匹配文件名中带有 `"trimmed.filtered"` 模式的文件。所有这些文件都被加载到内存中，并使用 `derepFaistq()`
    函数进行去重。接着，我们通过对部分文件使用 `dada()` 函数，计算组成推断步骤的参数。我们通过索引 `derep_reads` 对象，传递前五组去重后的文件。通过将
    `err` 设置为 `NULL` 和 `selfConsist` 设置为 `TRUE`，我们强制 `dada()` 从数据中估算参数，并将结果保存在 `dd_model`
    变量中。
- en: We next run the `dada()` function on all of the data, setting the `err` parameter
    to that estimated previously and stored in `dd_model`. This step calculates the
    final sequence composition for the whole data.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们对所有数据运行 `dada()` 函数，将 `err` 参数设置为先前估算并存储在 `dd_model` 中的值。此步骤计算整个数据集的最终序列组成。
- en: 'Finally, we can make the sequence table with the results of the `dada()` function
    and use that to find OTUs using `assignTaxonomy()`. This function uses a naive
    Bayes classifier to assign sequences to taxa, based on the classification in the
    training set provided in the `rdp_train_set_14.fa` file*.* The output of this
    function is the classification of each sequence. A single row of the resulting
    table, `taxonomy_tb`, looks like this:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用 `dada()` 函数的结果创建序列表，并利用该表通过 `assignTaxonomy()` 查找 OTU。此函数使用朴素贝叶斯分类器将序列分配到分类群中，基于提供的
    `rdp_train_set_14.fa` 文件中的训练集分类。该函数的输出是每个序列的分类。结果表格 `taxonomy_tb` 中的一行如下所示：
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: See also
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: The functions used in this recipe, `fastqFilter()` and `derepFastQ()`, also
    have variants for paired reads.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 本配方中使用的函数 `fastqFilter()` 和 `derepFastQ()` 也有用于配对读取的变体。
- en: Visualizing taxonomic abundances with heat trees in metacoder
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 `metacoder` 可视化分类丰度的热树
- en: However we arrive at estimates of taxonomic abundance, it is usually helpful
    to create a visualization that summarizes the broad trends in the data in a single
    figure. One expressive and easy to interpret visualization is a heat tree. These
    are renderings of phylogenetic trees of the taxons of interest with data mapped
    onto visual elements of the render. For example, the number of times a taxon is
    seen may be expressed by changing the color or thickness of a tree branch. Different
    datasets can be easily compared by examining trees of each for differences. In
    this recipe, we'll construct a heat tree and customize it.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们如何估算分类丰度，通常都需要创建一种可视化方法，以便在单一图形中总结数据的广泛趋势。一个表达力强且易于解读的可视化方式是热树。这些是对感兴趣的分类群的系统发育树的呈现，其中数据被映射到图形的视觉元素上。例如，一个分类群被观察到的次数可能通过改变树枝的颜色或粗细来表示。不同的数据集可以通过比较每个数据集的树形图来轻松发现差异。在本配方中，我们将构建一棵热树并进行自定义。
- en: Getting ready
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We need the input `.biom` file in `datasets/ch5/rich_high_count_otu.biom` and
    the `metacoder` and `RColorBrewer` packages.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要输入 `.biom` 文件 `datasets/ch5/rich_high_count_otu.biom` 和 `metacoder`、`RColorBrewer`
    包。
- en: How to do it...
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Visualizing taxonomic abundances with heat trees in `metacoder` can be done
    using the following steps:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `metacoder` 可视化分类丰度的热树可以通过以下步骤完成：
- en: 'Load the libraries and input files:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库和输入文件：
- en: '[PRE16]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Pass customization options to the tree-drawing function:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将自定义选项传递给树绘制函数：
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: How it works...
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Initially, we load the libraries and use the `parse_qiime_biom()` function to
    get a `metacoder taxmap` object from the `biom` file.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们加载库并使用`parse_qiime_biom()`函数从`biom`文件获取一个`metacoder taxmap`对象。
- en: 'We then use the `heat_tree()` function to render the tree. It''s enough to
    pass just the `taxdata taxmap` object—this will give a default tree—all of the
    other arguments specify customizations of the tree. `node_label` specifies the
    column in the `taxdata` object to use for the node labels; here, we use `taxon_names`,
    notably without enclosing quotes since the function uses non-standard evaluation
    in the same way that you may be familiar with from the `tidyverse` and `ggplot`
    functions. `node_size` controls node size based on the column given. Here, `n_obs`
    and `node_color` give the parameter that affects the variation of the color of
    the nodes (note that this isn''t the set of colors—it''s the things that should
    be colored the same/differently). Next, the `layout` argument tells the function
    how to spread the branches of the tree in the render. Of the next three argument
    titles, `node_color_axis` and `node_size_axis_label` are simply labels for the
    plot. Finally, `node_color_range` gets a vector of color identifiers that are
    used to draw with. Here, we use the `RColorBrewer` package function, `brewer.pal()`,
    which returns such things. Its first parameter is the number of colors to return,
    and the second the name of the palette to choose from. With all of these set,
    we get the following plot from our small input file:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用`heat_tree()`函数来渲染树。只需要传递`taxdata taxmap`对象——这将生成默认的树——其他的参数则是用来定制树的。`node_label`指定在`taxdata`对象中用于节点标签的列；在这里，我们使用`taxon_names`，特别注意这里没有加引号，因为该函数使用非标准评估方式，类似于你在`tidyverse`和`ggplot`函数中可能已经熟悉的方式。`node_size`根据给定的列控制节点大小。在这里，`n_obs`和`node_color`提供了影响节点颜色变化的参数（注意，这不是颜色的集合——而是应该被相同/不同颜色标记的内容）。接下来，`layout`参数告诉函数如何在渲染中展开树的分支。在接下来的三个参数标题中，`node_color_axis`和`node_size_axis_label`仅仅是图形的标签。最后，`node_color_range`获取一个颜色标识符向量，用来绘制图形。这里，我们使用`RColorBrewer`包的函数`brewer.pal()`，它返回这样的内容。它的第一个参数是要返回的颜色数量，第二个参数是要选择的调色板名称。设置好所有这些后，我们从我们的输入小文件中得到如下图：
- en: '![](img/e5c0ea89-48c3-4989-965e-33a3ae341008.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e5c0ea89-48c3-4989-965e-33a3ae341008.png)'
- en: Computing sample diversity with vegan
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用vegan计算样本多样性
- en: A common task in ecological and metagenomics studies is to estimate the species
    (or taxonomical) diversity within a sample or between samples to see which has
    more or less. There are multiple measures for both within and between sample diversity,
    including the Simpson and Bray indices. In this recipe, we'll look at functions
    that can go from the common OTU table and return measures of diversity.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在生态学和宏基因组学研究中，一个常见的任务是估算样本内或样本之间的物种（或分类学）多样性，以查看哪些样本多样性较高或较低。有多种度量方法可以衡量样本内外的多样性，包括辛普森指数和布雷指数。在这个示例中，我们将查看能够从常见的OTU表格中返回多样性度量的函数。
- en: Getting ready
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We'll need the sample `.biom` input file, `datasets/ch5/rich_high_count_otu.biom`,
    and the `vegan` package.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要样本的`.biom`输入文件，`datasets/ch5/rich_high_count_otu.biom`，以及`vegan`包。
- en: How to do it...
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现……
- en: 'Computing sample diversity with `vegan` can be done using the following steps:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`vegan`计算样本多样性可以通过以下步骤完成：
- en: 'Load in the libraries and prepare an OTU table from the sample file:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库并从样本文件准备OTU表格：
- en: '[PRE18]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Calculate the alpha diversity:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算α多样性：
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Calculate the beta diversity:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算β多样性：
- en: '[PRE20]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How it works...
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The first step is very straightforward. Here, we use the `metacoder parse_qiime_biom()`
    function to load in our `biom` file and then use subsetting on the resulting `taxdata$data$otu_table`
    slot to extract a simple OTU table into `otu_table`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步非常简单。在这里，我们使用`metacoder parse_qiime_biom()`函数加载我们的`biom`文件，然后对生成的`taxdata$data$otu_table`插槽进行子集化，提取一个简单的OTU表格到`otu_table`中。
- en: 'We can now call the `diversity()` function from `vegan`. The `index` argument
    is set to `"simpson"`, so the function will use the Simpson index for within-sample
    diversity. The `MARGIN` argument tells the function whether the samples are in
    rows or columns: 1 for rows and 2 for columns. The `diversity()` function returns
    a named vector that is easy to visualize with the `barplot()` function, giving
    us this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以调用`vegan`包中的`diversity()`函数。`index`参数设置为`"simpson"`，所以函数将使用辛普森指数来计算样本内的多样性。`MARGIN`参数告诉函数样本是按行还是按列排列：1表示按行，2表示按列。`diversity()`函数返回一个命名的向量，便于使用`barplot()`函数进行可视化，生成如下图：
- en: '![](img/48f8dc6b-3b3f-41a3-a48e-935484d9100e.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/48f8dc6b-3b3f-41a3-a48e-935484d9100e.png)'
- en: We can now run the between-sample diversity measure using the `vegdist()` function;
    again, the `index` argument sets the index to use, and here, we choose the Bray
    index. `vegdist()` expects the sample data to be rows, so we use the `t()` function
    to rotate `otu_table`. The resulting object is stored in `between_sample`— it's
    a pairwise correlation table and we can visualize it in `corrplot`. To do this,
    we need to convert it into a matrix with `as.matrix()`; the `ncol` argument should
    match the number of samples so that you get a column for each sample. The returned
    matrix, `between_sample_m`, can be passed to the `corrplot()` function to render
    it. By setting `method` to `circle`, `type` to `upper`, and `diag` to `false`,
    we get a plot with only the upper diagonal of the matrix, without the self-versus-self
    comparisons reducing redundancy in the plot.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用`vegdist()`函数运行样本间的多样性度量；同样，`index`参数设置要使用的指数，这里我们选择Bray指数。`vegdist()`期望样本数据是按行排列的，所以我们使用`t()`函数来旋转`otu_table`。生成的对象存储在`between_sample`中——它是一个成对相关性表格，我们可以在`corrplot`中可视化它。为了做到这一点，我们需要通过`as.matrix()`将其转换为矩阵；`ncol`参数应与样本的数量匹配，以便为每个样本生成一列。返回的矩阵`between_sample_m`可以传递给`corrplot()`函数进行渲染。通过将`method`设置为`circle`，`type`设置为`upper`，并将`diag`设置为`false`，我们可以得到一个只显示矩阵上三角部分的图，而没有自我与自我的比较，从而减少图中的冗余。
- en: 'The output looks like this:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![](img/3789c397-ec25-4c32-b3e1-778e1a903158.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3789c397-ec25-4c32-b3e1-778e1a903158.png)'
- en: See also...
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见...
- en: The correlation plot in this recipe explicitly shows correlations for a few
    samples but can become unwieldy on very large experiments. At this stage, you
    may want to consider PCA or some other multidimensional scaling approach.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 本示例中的相关性图明确显示了几个样本的相关性，但在非常大的实验中可能变得不易处理。在此阶段，您可能需要考虑PCA或其他某种多维尺度方法。
- en: Splitting sequence files into OTUs
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将序列文件拆分为OTU
- en: Perhaps the most common task with cleaned trimmed reads for a metagenomic shotgun
    experiment is to divide the sequences into OTUs. This can be achieved in many
    ways; in this recipe, we'll look at a method that splits sequences into subsequences
    of a given length and performs a type of hierarchical clustering on them to create
    groups.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于经过清理和修剪的测序数据，最常见的任务之一是将序列划分为OTU。在这方面有很多方法；在本示例中，我们将探讨一种将序列拆分为指定长度的子序列并对其执行某种层次聚类的方式，以创建组。
- en: Getting ready
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The key package here is the `kmer` package and we'll use one of the sample `fastq`
    sequence files in the `datasets/ch5/fq` folder. We'll also make use of the `dplyr`
    and `magrittr` packages for convenience.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键包是`kmer`包，我们将使用`datasets/ch5/fq`文件夹中的一个示例`fastq`序列文件。我们还将使用`dplyr`和`magrittr`包以提高便利性。
- en: How to do it...
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Splitting sequence files into OTUs can be done using the following steps:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 将序列文件拆分为OTU可以通过以下步骤完成：
- en: 'Load the data and compute the OTUs:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据并计算OTU：
- en: '[PRE21]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Count the frequency of each OTU cluster:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个OTU簇的频率：
- en: '[PRE22]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How it works...
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: After loading the libraries, we use the `read.fastq()` function from `ape` to
    get a `DNAbin` object representing the sequences. The key function, `otu()`, from
    the `kmer` package can use the `DNAbin seqs` object directly to create k-mers
    of the length, `k`, and perform hierarchical clustering on them. The threshold
    argument sets the OTU identity cut-off. This function returns a named vector in
    which the names are the sequence IDs and the value for each is the ID of the cluster
    it belongs to.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 加载库后，我们使用`ape`包中的`read.fastq()`函数获取表示序列的`DNAbin`对象。`kmer`包中的关键函数`otu()`可以直接使用`DNAbin
    seqs`对象创建长度为`k`的k-mer，并对其执行层次聚类。`threshold`参数设置OTU的身份阈值。该函数返回一个命名向量，其中名称为序列ID，每个值为该序列所属簇的ID。
- en: We can then use `otu_vec` to build an intermediate data frame with `data.frame`,
    using the names attribute to set a `seqid` column and putting the cluster membership
    into a column called `cluster`. We drop row names by setting `row.names` to `NULL`.
    We then use `magrittr` piping with the `%>%` operator to group the data frame
    on clusters with `dplyr::group()` and create a summary data frame with `dplyr::summarize()`.
    By setting the count to the result of the `dplyr::n()` function, we get the number
    of times each cluster appeared in the named vector—or, how many reads were assigned
    into each cluster.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用`otu_vec`通过`data.frame`构建一个中间数据框，使用`names`属性设置一个`seqid`列，并将聚类成员信息放入一个名为`cluster`的列中。通过将`row.names`设置为`NULL`，我们去掉行名称。接着，我们使用`magrittr`管道符号`%>%`，通过`dplyr::group()`按聚类对数据框进行分组，并通过`dplyr::summarize()`创建一个汇总数据框。通过将计数设置为`dplyr::n()`函数的结果，我们可以得到每个聚类在命名向量中出现的次数——即每个聚类中分配到的读取次数。
