- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Identifying and Fixing Missing Values
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别并修复缺失值
- en: I think I speak for many data analysts and scientists when I write, rarely is
    there something so seemingly small and trivial that is of as much consequence
    as a missing value. We spend a good deal of our time worrying about missing values
    because they can have a dramatic, and surprising, effect on our analysis. This
    is most likely to happen when missing values are not random, but are correlated
    with a dependent variable. For example, if we are doing a longitudinal study of
    earnings, but individuals with lower education are more likely to skip the earnings
    question each year, there is a decent chance that this will bias our parameter
    estimate for education.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我想我可以代表许多数据分析师和科学家来说，鲜少有什么看似微小而琐碎的事情能像缺失值那样对我们的分析产生如此大的影响。我们花费大量时间担心缺失值，因为它们可能对我们的分析产生戏剧性的、令人惊讶的影响。尤其是当缺失值不是随机的，而是与因变量相关时，情况尤其如此。例如，如果我们正在做一个收入的纵向研究，但教育水平较低的个体每年更可能跳过收入问题，那么很可能会对我们关于教育水平的参数估计产生偏差。
- en: Of course, identifying missing values is not even half of the battle. We then
    need to decide how to handle them. Do we remove any observation with a missing
    value for one or more variables? Do we impute a value based on a sample-wide statistic
    like the mean? Or assign a value based on a more targeted statistic, like the
    mean for those in a certain class? Do we think of this differently for time series
    or longitudinal data where the nearest temporal value might make the most sense?
    Or should we use a more complex multivariate technique for imputing values, perhaps
    based on regression or *k*-nearest neighbors?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，识别缺失值只解决了问题的一部分。我们还需要决定如何处理它们。我们是删除任何包含缺失值的观测值，还是基于像均值这样的样本统计量插补一个值？或者，基于更有针对性的统计量，例如某个类别的均值，来插补？对于时间序列或纵向数据，我们是否应该考虑用最接近的时间值来填补？或者，是否应该使用更复杂的多变量技术进行插补，可能是基于回归或
    *k*-最近邻方法？
- en: The answer to all of the preceding questions is, “yes.” At some point we will
    want to use each of these techniques. We will want to be able to answer why or
    why not to all of these possibilities when making a final choice about missing
    value imputation. Each will make sense depending on the situation.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前面所有的问题，答案是“是的”。在某个阶段，我们会希望使用这些技术中的每一个。我们希望在做出最终缺失值插补选择时，能够回答为什么或为什么不使用这些可能性。每种方法都将根据情况有其合理性。
- en: We will go over techniques in this chapter for identifying the missing values
    for each variable, and for observations where values for a large number of the
    variables are absent. We will then explore strategies for imputing values, such
    as setting values to the overall mean, to the mean for a given category, and forward
    filling. We also examine multivariate techniques for imputing values and discuss
    when they are appropriate.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍识别每个变量的缺失值以及识别缺失值较多的观测值的技术。接着，我们将探讨一些插补策略，例如将缺失值设置为整体均值、某个特定类别的均值或前向填充。我们还将研究多变量插补技术，并讨论它们在何种情况下是合适的。
- en: 'Specifically, we will explore the following recipes in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，本章将探讨以下几种方法：
- en: Identifying missing values
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别缺失值
- en: Cleaning missing values
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理缺失值
- en: Imputing values with regression
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用回归进行插补
- en: Using *k*-nearest neighbors for imputation
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 *k*-最近邻方法进行插补
- en: Using random forest for imputation
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用随机森林进行插补
- en: Using PandasAI for imputation
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 PandasAI 进行插补
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need pandas, NumPy, and Matplotlib to complete the recipes in this
    chapter. I used pandas 2.1.4, but the code will run on pandas 1.5.3 or later.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你将需要 pandas、NumPy 和 Matplotlib 来完成本章中的示例。我使用的是 pandas 2.1.4，但代码同样适用于 pandas
    1.5.3 或更高版本。
- en: The code in this chapter can be downloaded from the book’s GitHub repository,
    [https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码可以从本书的 GitHub 仓库下载：[https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition)。
- en: Identifying missing values
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别缺失值
- en: Since identifying missing values is such an important part of the workflow of
    analysts, any tool we use needs to make it easy to regularly check for such values.
    Fortunately, pandas makes it quite simple to identify missing values.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于识别缺失值是分析师工作流程中的重要部分，我们使用的任何工具都需要使定期检查缺失值变得容易。幸运的是，pandas 使得识别缺失值变得非常简单。
- en: Getting ready
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: We will work with the **National Longitudinal Survey** (**NLS**) data in this
    chapter. The NLS data has one observation per survey respondent. Data for employment,
    earnings, and college enrollment for each year are stored in columns with suffixes
    representing the year, such as `weeksworked21` and `weeksworked22` for weeks worked
    in `2021` and `2022` respectively.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将使用 **国家纵向调查**（**NLS**）数据。NLS 数据每个调查响应者有一条观察记录。每年的就业、收入和大学入学数据都存储在带有后缀的列中，后缀表示年份，如
    `weeksworked21` 和 `weeksworked22` 分别代表 2021 年和 2022 年的工作周数。
- en: We will also work with the COVID-19 data again. This dataset has one observation
    for each country with total COVID-19 cases and deaths, as well as some demographic
    data for each country.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将再次使用 COVID-19 数据。该数据集包含每个国家的观察值，记录了总 COVID-19 病例和死亡人数，以及每个国家的人口统计数据。
- en: '**Data note**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据说明**'
- en: The National Longitudinal Survey of Youth is conducted by the United States
    Bureau of Labor Statistics. This survey started with a cohort of individuals in
    1997 who were born between 1980 and 1985, with annual follow-ups each year through
    2023\. For this recipe, I pulled 104 variables on grades, employment, income,
    and attitudes toward the government from the hundreds of data items on the survey.
    NLS data can be downloaded from [nlsinfo.org/](https://nlsinfo.org).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 青年国家纵向调查由美国劳工统计局进行。此调查始于 1997 年，针对的是 1980 至 1985 年出生的群体，每年进行一次跟踪，直到 2023 年。对于此项工作，我从调查的数百个数据项中提取了关于年级、就业、收入和对政府态度的
    104 个变量。NLS 数据可以从 [nlsinfo.org/](https://nlsinfo.org) 下载。
- en: '*Our World in Data* provides COVID-19 data for public use at [https://ourworldindata.org/covid-cases](https://ourworldindata.org/covid-cases).
    The dataset includes total cases and deaths, tests administered, hospital beds,
    and demographic data such as median age, gross domestic product, and life expectancy.
    The dataset used in this recipe was downloaded on March 3, 2024.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*Our World in Data* 提供了用于公共使用的 COVID-19 数据，网址为 [https://ourworldindata.org/covid-cases](https://ourworldindata.org/covid-cases)。该数据集包括总病例和死亡人数、已做测试数量、医院床位数以及人口统计数据，如中位年龄、国内生产总值和预期寿命。此处使用的数据集是在
    2024 年 3 月 3 日下载的。'
- en: How to do it...
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: We will use pandas functions to identify both missing values and logical missing
    values (non-missing values that nonetheless connote missing values).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 pandas 函数来识别缺失值和逻辑缺失值（即尽管数据本身不缺失，但却代表缺失的非缺失值）。
- en: 'Let’s start by loading the NLS and COVID-19 data:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从加载 NLS 和 COVID-19 数据开始：
- en: '[PRE0]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we count the number of missing values for each variable. We can use the
    `isnull` method to test if each value is missing. It will return True if the value
    is missing and False if not. We can then use `sum` to count the number of True
    values, since `sum` will treat each True value as 1 and False value as 0\. We
    indicate `axis=0` to sum over columns rather than across rows:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们统计每个变量的缺失值数量。我们可以使用 `isnull` 方法来测试每个值是否缺失。如果值缺失，它将返回 True，否则返回 False。然后，我们可以使用
    `sum` 来统计 True 值的数量，因为 `sum` 会将每个 True 值视为 1，False 值视为 0。我们指定 `axis=0` 来对列进行求和，而不是对行进行求和：
- en: '[PRE1]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 43 of the 231 countries have null values for `aged_65_older`. We have `life_expectancy`
    for almost all countries.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 231 个国家中有 43 个国家的 `aged_65_older` 变量存在空值。几乎所有国家都有 `life_expectancy` 数据。
- en: 'If we want the number of missing values for each row, we can specify `axis=1`
    when summing. The following code creates a Series, `demovarsmisscnt`, with the
    number of missing values for the demographic variables for each country. 178 countries
    have values for all of the variables, but 16 are missing values for 4 of the 5
    variables, and 4 are missing values for all of the variables:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们想要了解每一行的缺失值数量，可以在求和时指定 `axis=1`。以下代码创建了一个 Series，`demovarsmisscnt`，它记录了每个国家人口统计变量的缺失值数量。178
    个国家的所有变量都有值，但 16 个国家缺少 5 个变量中的 4 个值，4 个国家所有变量都缺少值：
- en: '[PRE5]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let’s take a look at a few of the countries with 4 or more missing values.
    There is very little demographic data available for these countries:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看一看一些缺失值超过 4 的国家。这些国家几乎没有人口统计数据：
- en: '[PRE7]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s also check the missing values for total cases and deaths. There is one
    missing value for cases per million of the population and one missing value for
    deaths per million:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还将检查总病例和死亡人数的缺失值。每百万人的病例和每百万人的死亡人数分别有一个缺失值：
- en: '[PRE9]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can easily check if one country is missing both cases per million and deaths
    per million. We see that `230` countries are not missing either, and just one
    country is missing both:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以轻松检查某个国家是否同时缺失每百万的病例数和每百万的死亡人数。我们看到有`230`个国家两者都没有缺失，而仅有一个国家同时缺失这两项数据：
- en: '[PRE11]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Sometimes we have logical missing values that we need to transform into actual
    missing values. This happens when the dataset designers use valid values as codes
    for missing values. These are often values like 9, 99, or 999, based on the allowable
    number of digits for the variable. Or it might be a more complicated coding scheme
    where there are codes for different reasons for there being missing values. For
    example, on the NLS dataset the codes reveal why the respondent did not provide
    an answer for a question: -3 is an invalid skip, -4 is a valid skip, and -5 is
    a non-interview.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们会遇到需要转换为实际缺失值的逻辑缺失值。这发生在数据集设计者使用有效值作为缺失值的代码时。这些通常是像 9、99 或 999 这样的值，取决于变量允许的数字位数。或者它可能是一个更复杂的编码方案，其中有不同的代码表示缺失值的不同原因。例如，在
    NLS 数据集中，代码揭示了受访者未回答问题的原因：-3 是无效跳过，-4 是有效跳过，-5 是非访谈。
- en: The last 4 columns on the NLS DataFrame have data on the highest grade completed
    for the respondent’s mother and father, parental income, and the mother’s age
    when the respondent was born. Let’s examine logical missing values for those columns,
    starting with `motherhighgrade`.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NLS 数据框的最后 4 列包含了关于受访者母亲和父亲完成的最高学位、父母收入以及受访者出生时母亲年龄的数据。我们将从 `motherhighgrade`
    列开始，检查这些列的逻辑缺失值。
- en: '[PRE13]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There are 523 invalid skips and 165 valid skips. Let’s look at a few individuals
    that have at least one of these non-response values for these four variables:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有 523 个无效跳过值和 165 个有效跳过值。我们来看几个至少在这四个变量中有一个非响应值的个体：
- en: '[PRE15]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'For our analysis, the reason why there is a non-response is not important.
    Let’s just count the number of non-responses for each of the columns, regardless
    of the reason for the non-response:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们的分析，非响应的原因并不重要。我们只需要统计每列的非响应数量，无论非响应的原因是什么：
- en: '[PRE17]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We should set these values to missing before using these columns in our analysis.
    We can use `replace` to set all values between -5 and -1 to missing. When we check
    for actual missing values we get the expected counts:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们进行分析之前，应该将这些值设置为缺失值。我们可以使用 `replace` 将所有介于 -5 和 -1 之间的值设置为缺失值。当我们检查实际缺失值时，我们得到预期的计数：
- en: '[PRE19]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How it works...
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We made good use of lambda functions and `transform` in *step 8* and *step 9*
    to search for values in a specified range across multiple columns. `transform`
    works in much the same way as `apply`. Both are methods of DataFrames or of Series,
    allowing us to pass one or more columns of data to a function. In this case, we
    use a lambda function, but we could have also used a named function, as we did
    in the *Changing Series values conditionally* recipe in *Chapter 6*, *Cleaning
    and Exploring Data with Series Operations*.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 8*和*步骤 9*中，我们充分利用了 lambda 函数和 `transform` 来跨多个列搜索指定范围的值。`transform` 的工作方式与
    `apply` 类似。两者都是 DataFrame 或 Series 的方法，允许我们将一个或多个数据列传递给一个函数。在这种情况下，我们使用了 lambda
    函数，但我们也可以使用命名函数，就像我们在*第 6 章*《使用 Series 操作清理和探索数据》中的*条件性更改 Series 值*教程中所做的那样。
- en: This recipe demonstrated some very handy pandas techniques to identify the number
    of missing values for each variable, and observations with a large number of missing
    values. We also examined how to find logical missing values and convert them to
    actual missing values. Next, we will take our first look at cleaning missing values.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个教程展示了一些非常实用的 pandas 技巧，用于识别每个变量的缺失值数量以及具有大量缺失值的观测数据。我们还研究了如何找到逻辑缺失值并将其转换为实际缺失值。接下来，我们将首次探索如何清理缺失值。
- en: Cleaning missing values
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清理缺失值
- en: We go over some of the most straightforward approaches for handling missing
    values in this recipe. This includes dropping observations where there are missing
    values; assigning a sample-wide summary statistic, such as the mean, to the missing
    values; and assigning values based on the mean value for an appropriate subset
    of the data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们介绍了一些最直接处理缺失值的方法。这包括删除缺失值的观测数据；为缺失值分配样本范围内的统计量（如均值）；以及基于数据的适当子集的均值为缺失值分配值。
- en: How to do it...
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'We will find and then remove observations from the NLS data that have mainly
    missing data for key variables. We will also use pandas methods to assign alternative
    values to missing values, such as the variable mean:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将查找并移除来自 NLS 数据中那些主要缺失关键变量数据的观测值。我们还将使用 pandas 方法为缺失值分配替代值，例如使用变量均值：
- en: Let’s load the NLS data and select some of the educational data.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载 NLS 数据并选择一些教育数据。
- en: '[PRE21]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We can use the techniques we explored in the previous recipe to identify missing
    values. `schoolrecord.isnull().sum(axis=0)` gives us the number of missing values
    for each column. The overwhelming majority of observations have missing values
    for `satverbal`, 7,578 out of 8,984\. Only 31 observations have missing values
    for `highestdegree`:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用前面章节中探讨的技术来识别缺失值。`schoolrecord.isnull().sum(axis=0)` 会给出每列的缺失值数量。绝大多数观测值在
    `satverbal` 上存在缺失值，共7,578个缺失值（总共8,984个观测值）。只有31个观测值在 `highestdegree` 上有缺失值：
- en: '[PRE23]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We can create a Series, `misscnt`, with the number of missing variables for
    each observation with `misscnt = schoolrecord.isnull().sum(axis=1)`. 949 observations
    have 7 missing values for the educational data, and 10 are missing values for
    all 8 columns. In the following code we also take a look at a few observations
    with 7 or more missing values. It looks like `highestdegree` is often the one
    variable that is present, which is not surprising given that we have already discovered
    that `highestdegree` is rarely missing:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以创建一个 Series `misscnt`，它记录每个观测值的缺失变量数量，方法是 `misscnt = schoolrecord.isnull().sum(axis=1)`。949个观测值的教育数据中有7个缺失值，10个观测值的所有8个列都有缺失值。在以下代码中，我们还查看了一些具有7个或更多缺失值的观测值。看起来
    `highestdegree` 通常是唯一一个存在的变量，这并不奇怪，因为我们已经发现 `highestdegree` 很少缺失：
- en: '[PRE25]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let’s drop observations that have missing values for 7 or more variables, out
    of 8\. We can accomplish this by setting the `thresh` parameter of `dropna` to
    `2`. This will drop observations that have fewer than 2 non-missing values. We
    get the expected number of observations after the `dropna`; `8984`-`949`-`10`
    = `8025`:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将删除那些在8个变量中有7个或更多缺失值的观测值。我们可以通过将 `dropna` 的 `thresh` 参数设置为 `2` 来实现。这样会删除那些非缺失值少于2个的观测值。删除缺失值后，我们得到了预期的观测数：`8984`
    - `949` - `10` = `8025`：
- en: '[PRE29]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: There are a fair number of missing values for `gpaoverall`, 2,980, though we
    have valid values for two-thirds of the observations `((8984-2980)/8984)`. We
    might be able to salvage this as a variable if we do a good job of imputing missing
    values. This is likely more desirable than just removing these observations. We
    do not want to lose that data if we can avoid it, particularly if individuals
    with a missing `gpaoverall` are different from others in ways that will matter
    for our predictions.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`gpaoverall` 存在相当多的缺失值，共计2,980个，虽然我们有三分之二的有效观测值 `((8984-2980)/8984)`。如果我们能够很好地填补缺失值，这个变量可能是可以保留的。相比于直接删除这些观测值，这样做可能更可取。如果我们能避免丢失这些数据，尤其是如果缺失
    `gpaoverall` 的个体与其他个体在一些重要预测变量上有所不同，我们不希望失去这些数据。'
- en: 'The most straightforward approach is to assign the overall mean for `gpaoverall`
    to the missing values. The following code uses the pandas Series `fillna` method
    to assign all missing values of `gpaoverall` to the Series mean value. The first
    argument to `fillna` is the value you want for all missing values, in this case,
    `schoolrecord.gpaoverall.mean()`. Note that we need to remember to set the `inplace`
    parameter to True to actually overwrite the existing values:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最直接的方法是将`gpaoverall`的总体均值分配给缺失值。以下代码使用 pandas Series 的 `fillna` 方法将所有缺失的 `gpaoverall`
    值替换为 Series 的均值。`fillna` 的第一个参数是你想要填充所有缺失值的值，在本例中是 `schoolrecord.gpaoverall.mean()`。请注意，我们需要记得将
    `inplace` 参数设置为 True，才能真正覆盖现有值：
- en: '[PRE33]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The mean is unchanged, of course, but there is a substantial reduction in the
    standard deviation, from 62 to 50\. This is a disadvantage of using the dataset
    mean for all missing values.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 均值当然没有改变，但标准差有了显著减少，从62降到了50。这是使用数据集均值来填补所有缺失值的一个缺点。
- en: 'The NLS data also has a fair number of missing values for `wageincome20`. The
    following code shows that 3,783 observations have missing values. We make a deep
    copy with the `copy` method, setting `deep` to True. We would not normally do
    this, but in this case we don’t want to change the values of `wageincome20` in
    the underlying DataFrame. We don’t want to do that here because we will try a
    different method of imputing values in the next couple of code blocks:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NLS数据集中的`wageincome20`也有相当多的缺失值。以下代码显示了3,783个观测值缺失。我们使用`copy`方法进行深拷贝，并将`deep`设置为True。通常我们不会这样做，但在这种情况下，我们不想改变底层DataFrame中`wageincome20`的值。我们这样做是因为接下来的代码块中我们会尝试使用不同的填充方法：
- en: '[PRE39]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Rather than assigning the mean value of `wageincome` to the missing values,
    we could use another common technique for imputing values. We could assign the
    nearest non-missing value from a preceding observation. We can use the `ffill`
    method of the Series object to do this (note that this does not impute a value
    for the first observation as there is no preceding value to use):'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与其将`wageincome`的平均值分配给缺失值，我们可以使用另一种常见的填充技术。我们可以将前一个观测值中的最近非缺失值赋给缺失值。我们可以使用Series对象的`ffill`方法来实现这一点（注意，首次观测值不会填充，因为没有前一个值可用）：
- en: '[PRE43]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '**Note**'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: 'If you have used `ffill` in pandas versions prior to 2.2.0, you might remember
    the following syntax:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在pandas 2.2.0之前的版本中使用过`ffill`，你可能还记得以下语法：
- en: '`wageincome.fillna(method="ffill", inplace=True)`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`wageincome.fillna(method="ffill", inplace=True)`'
- en: This syntax was deprecated, starting with pandas 2.2.0\. That is also true for
    the backward fill syntax, which we will use next.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这种语法在pandas 2.2.0版本中已被弃用。向后填充的语法也是如此，我们接下来将使用这种方法。
- en: 'We could have done a backward fill instead by using the `bfill` method. This
    sets missing values to the nearest following value. This produces the following:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们也可以使用`bfill`方法进行向后填充。这会将缺失值填充为最近的后续值。这样会得到如下结果：
- en: '[PRE47]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: If missing values are randomly distributed then forward or backward filling
    has one advantage over using the mean. It is more likely to approximate the distribution
    of the non-missing values for the variable. Notice that the standard deviation
    did not drop much after backward filling.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果缺失值是随机分布的，那么前向或后向填充相比使用平均值有一个优势。它更可能接近非缺失值的分布。注意，在后向填充后，标准差变化不大。
- en: There are times when it makes sense to base our imputation of values on the
    mean or median value for similar observations; say those that have the same value
    for a related variable. Let’s try that in the next step.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，根据相似观测值的平均值或中位数来填充缺失值是有意义的；例如，具有相同相关变量值的观测值。让我们在下一步中尝试这种方法。
- en: 'In the NLS DataFrame, weeks worked in 2020 is correlated with highest degree
    earned. The following code shows how the mean value of weeks worked changes with
    degree attainment. The mean for weeks worked is 38, but it is much lower for those
    without a degree (28) and much higher for those with a professional degree (48).
    In this case, it may be a better choice to assign 28 to missing values for weeks
    worked for individuals who have not attained a degree, rather than 38:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在NLS DataFrame中，2020年的工作周数与获得的最高学历有相关性。以下代码显示了不同学历水平下的工作周数平均值如何变化。工作周数的平均值是38，但没有学位的人为28，拥有职业学位的人为48。在这种情况下，给没有学位的人的缺失工作周数分配28可能比分配38更合适：
- en: '[PRE55]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The following code assigns the mean value of weeks worked across observations
    with the same degree attainment level for those observations missing weeks worked.
    We do this by using `groupby` to create a groupby DataFrame, `groupby([''highestdegree''])[''weeksworked20'']`.
    We then use `fillna` within `transform` to fill missing values with the mean for
    the highest degree group. Notice that we make sure to only do this imputation
    for observations where the highest degree information is not missing, `nls97.highestdegree.notnull()`.
    We will still have missing values for observations missing both highest degree
    and weeks worked:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码为缺失`weeksworked20`的观测值分配了相同学历水平组中的工作周数平均值。我们通过使用`groupby`创建一个分组DataFrame，`groupby(['highestdegree'])['weeksworked20']`来实现这一点。然后，我们在`transform`内使用`fillna`方法，将缺失值填充为该学历组的平均值。注意，我们确保只对学历信息不缺失的观测值进行填充，`nls97.highestdegree.notnull()`。对于同时缺失学历和工作周数的观测值，仍然会存在缺失值：
- en: '[PRE59]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: How it works...
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它的工作原理是...
- en: When there is very little data available it can make sense to remove an observation
    from our analysis. We did that in *step 4*. Another common approach is the one
    we used in *step 5*, assigning the overall dataset mean for the variable to missing
    values. We saw in that example one of the disadvantages of that approach. We can
    end up with a significantly reduced variance in our variable.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当可用数据非常少时，删除某个观测值可能是合理的。我们在*步骤4*中已经做过了。另一种常见的方法是我们在*步骤5*中使用的，即将该变量的整体数据集均值分配给缺失值。在这个例子中，我们看到了这种方法的一个缺点。我们可能会导致变量方差显著减小。
- en: In *step 9* we assigned values based on the mean value of that variable for
    a subset of our data. If we are imputing values for variable X[1], and X[1] is
    correlated with X[2], we can use the relationship between X[1] and X[2] to impute
    a value for X[1] that might make more sense than the dataset mean. This is pretty
    straightforward when X[2] is categorical. In this case we can impute the mean
    value of X[1] for the associated value of X[2].
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤9*中，我们基于数据子集的均值为变量赋值。如果我们为变量X[1]填充缺失值，并且X[1]与X[2]相关联，我们可以使用X[1]和X[2]之间的关系来填充X[1]的值，这比使用数据集的均值更有意义。当X[2]是分类变量时，这通常非常直接。在这种情况下，我们可以填充X[1]在X[2]的关联值下的均值。
- en: These imputation strategies—removing observations with missing values, assigning
    a dataset mean or median, using forward or backward filling, or using a group
    mean for a correlated variable—are fine for many predictive analytics projects.
    They work best when the missing values are not correlated with a target or dependent
    variable. When that is true, imputing values allows us to retain the other information
    from those observations without biasing our estimates.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些填充策略——删除缺失值观测、分配数据集的均值或中位数、使用前向或后向填充，或使用相关变量的组均值——适用于许多预测分析项目。当缺失值与目标变量或依赖变量没有相关性时，这些方法效果最佳。当这种情况成立时，填充缺失值能让我们保留这些观测中的其他信息，而不会偏倚估计结果。
- en: Sometimes, however, that is not the case and more complicated imputation strategies
    are required. The next few recipes explore multivariate techniques for cleaning
    missing data.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时情况并非如此，需要更复杂的填充策略。接下来的几个教程将探讨用于清理缺失数据的多变量技术。
- en: See also
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: Don’t worry if your understanding of what we did in *step 10*, using `groupby`
    and `transform`, is still a little shaky. We do much more with `groupby`, `transform`,
    and `apply` in *Chapter 9*, *Fixing Messy Data When Aggregating*.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对我们在*步骤10*中使用`groupby`和`transform`的理解仍然有些不清楚，不必担心。在*第9章*，*聚合时清理杂乱数据*中，我们将更深入地使用`groupby`、`transform`和`apply`。
- en: Imputing values with regression
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用回归法填充缺失值
- en: We ended the previous recipe by assigning a group mean to missing values rather
    than the overall sample mean. As we discussed, this is useful when the variable
    that determines the groups is correlated with the variable that has the missing
    values. Using regression to impute values is conceptually similiar to this, but
    we typically use it when the imputation will be based on two or more variables.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一教程的结尾处，给缺失值分配了组均值，而不是整体样本均值。正如我们所讨论的，这在决定组的变量与缺失值变量相关时非常有用。使用回归法填充值在概念上与此类似，但通常是在填充基于两个或更多变量时使用。
- en: Regression imputation replaces a variable’s missing values with values predicted
    by a regression model of correlated variables. This particular kind of imputation
    is known as deterministic regression imputation, since the imputed values all
    lie on the regression line, and no error or randomness is introduced.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 回归填充通过回归模型预测的相关变量值来替代变量的缺失值。这种特定的填充方法被称为确定性回归填充，因为填充值都位于回归线上，并且不会引入误差或随机性。
- en: One potential drawback of this approach is that it can substantially reduce
    the variance of the variable with missing values. We can use stochastic regression
    imputation to address this drawback. We explore both approaches in this recipe.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的一个潜在缺点是，它可能会大幅度减少缺失值变量的方差。我们可以使用随机回归填充来解决这一缺点。在本教程中，我们将探讨这两种方法。
- en: Getting ready
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will work with the `statsmodels` module to run a linear regression model
    in this recipe. `statsmodels` is typically included with scientific distributions
    of Python, but if you do not already have it, you can install it with `pip install
    statsmodels`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本教程中使用`statsmodels`模块来运行线性回归模型。`statsmodels`通常包含在Python的科学发行版中，但如果你还没有安装，可以通过`pip
    install statsmodels`来安装它。
- en: How to do it...
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: The `wageincome20` column on the NLS dataset has a number of missing values.
    We can use linear regression to impute values. The wage income value is the reported
    earnings for 2020.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: NLS数据集上的`wageincome20`列存在大量缺失值。我们可以使用线性回归来填补这些值。工资收入值是2020年的报告收入。
- en: 'We start by loading the NLS data again and checking for missing values for
    `wageincome20` and columns that might be correlated with `wageincome20`. We also
    load the `statsmodels` library:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先重新加载NLS数据，并检查`wageincome20`以及可能与`wageincome20`相关的列的缺失值。同时加载`statsmodels`库：
- en: '[PRE61]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We are missing values for `wageincome20` for more than 3,000 observations.
    There are fewer missing values for the other variables. Let’s convert the `highestdegree`
    column to numeric so that we can use it in a regression model:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对超过3,000个观测值的`wageincome20`缺失值。其他变量的缺失值较少。让我们将`highestdegree`列转换为数值，以便在回归模型中使用它：
- en: '[PRE63]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'As we have already discovered, we need to replace logical missing values for
    `parentincome` with actual missing values. After that, we can run some correlations.
    Each of the variables has some positive correlation with `wageincome20`, particularly
    `hdegnum`:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如我们已经发现的那样，我们需要将`parentincome`的逻辑缺失值替换为实际缺失值。之后，我们可以运行一些相关性分析。每个变量与`wageincome20`都有一定的正相关性，特别是`hdegnum`。
- en: '[PRE65]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We should check to see if observations with missing values for wage income
    are different in some important way from those with non-missing values. The following
    code shows that these observations have significantly lower degree attainment
    levels, parental income, and weeks worked. This is a clear case where assigning
    the overall mean would not be the best choice:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该检查一下，具有工资收入缺失值的观测对象在某些重要方面是否与那些没有缺失值的观测对象不同。以下代码显示，这些观测对象的学位获得水平、父母收入和工作周数显著较低。在这种情况下，使用整体均值来分配值显然不是最佳选择：
- en: '[PRE67]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Notice that we just work here with rows that have positive values for weeks
    worked. It does not make sense for someone who did not work in 2020 to have a
    wage income in 2020.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在这里仅处理具有正值工作周数的行。对于2020年未工作的人来说，在2020年有工资收入是没有意义的。
- en: Let’s try regression imputation instead. We start by replacing missing `parentincome`
    values with the mean. We collapse `hdegnum` into those attaining less than a college
    degree, those with a college degree, and those with a post-graduate degree. We
    set those up as dummy variables, with `0` or `1` values when `False` or `True`.
    This is a tried and true method for treating categorical data in regression analysis.
    It allows us to estimate different y-intercepts based on group membership.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们来试试回归插补。我们首先用平均值替换缺失的`parentincome`值。我们将`hdegnum`折叠为达到以下三种学位水平的人群：少于本科、本科及以上。我们将它们设置为哑变量，当`False`或`True`时，值为`0`或`1`。这是处理回归分析中分类数据的一种经过验证的方法。它允许我们基于组成员身份估计不同的y截距。
- en: (*Scikit-learn* has preprocessing features that can help us with tasks like
    these. We go over some of them in the next chapter.)
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: （*Scikit-learn*具有预处理功能，可以帮助我们处理这些任务。我们将在下一章节中介绍其中一些。）
- en: '[PRE71]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Next, we define a function, `getlm`, to run a linear model using the `statsmodels`
    module. The function has parameters for the name of the target or dependent variable,
    `ycolname`, and for the names of the features or independent variables, `xcolnames`.
    Much of the work is done by the `statsmodels` `fit` method, `OLS(y, X).fit()`:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个函数，`getlm`，用于使用`statsmodels`模块运行线性模型。该函数具有目标变量或依赖变量名称`ycolname`以及特征或自变量名称`xcolnames`的参数。大部分工作由`statsmodels`的`fit`方法完成，即`OLS(y,
    X).fit()`：
- en: '[PRE72]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Now we can use the `getlm` function to get the parameter estimates and the model
    summary. All of the coefficients are positive and significant at the 95% level,
    having *p*-values less than `0.05`. As expected, wage income increases with number
    of weeks worked and with parental income. Having a college degree gives a $18.5K
    boost to earnings, compared with not having a college degree. A post-graduate
    degree bumps up the earnings prediction even more, almost $45.6K more than for
    those with less than a college degree. (The coefficients on `degcol` and `degadv`
    are interpreted as relative to those without a college degree since that is the
    omitted dummy variable.)
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用 `getlm` 函数来获取参数估计和模型摘要。所有系数都是正的，并且在 95% 水平下显著，*p*-值小于 `0.05`。正如我们预期的那样，工资收入随着工作周数和父母收入的增加而增加。拥有大学学位的收入比没有大学学位的人多
    $18.5K。拥有研究生学位的人比那些学历较低的人多了近 $45.6K。（`degcol` 和 `degadv` 的系数是相对于没有大学学位的人来解释的，因为这个变量被省略掉了。）
- en: '[PRE73]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: We use this model to impute values for wage income where they are missing. We
    need to add a constant for the predictions since our model included a constant.
    We can convert the predictions to a DataFrame and then join it with the rest of
    the NLS data. Let’s also take a look at some of the predictions to see if they
    make sense.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用这个模型来插补缺失的工资收入值。由于我们的模型包含了常数项，因此我们需要在预测中添加一个常数。我们可以将预测结果转换为 DataFrame，然后将其与其他
    NLS 数据合并。让我们也来看一些预测值，看看它们是否合理。
- en: '[PRE75]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'We should look at some summary statistics for our wage income imputation and
    compare that with the actual wage income values. (Remember that the `wageincomeimp`
    column has the actual value for `wageincome20` when it was not missing, and imputed
    values otherwise.) The mean for `wageincomeimp` is somewhat less than that for
    `wageincome20`, which we anticipated given that folks with missing wage income
    had lower values for correlated variables. But the standard deviation is also
    lower. This can happen with deterministic regression imputation:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该查看一下我们的工资收入插补的汇总统计，并将其与实际的工资收入值进行比较。（记住，`wageincomeimp` 列包含了当 `wageincome20`
    没有缺失时的实际值，其他情况下则是插补值。）`wageincomeimp` 的均值略低于 `wageincome20`，这是我们预期的结果，因为工资收入缺失的人群通常在相关变量上表现较低。但是标准差也较低。这可能是确定性回归插补的结果：
- en: '[PRE77]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Stochastic regression imputation adds a normally distributed error to the predictions
    based on the residuals from our model. We want this error to have a mean of zero
    with the same standard deviation as our residuals. We can use NumPy’s normal function
    for that with `np.random.normal(0, lm.resid.std(), nls97.shape[0])`. The `lm.resid.std()`
    gets us the standard deviation of the residuals from our model. The final parameter
    value, `nls97.shape[0]`, indicates how many values to create; in this case we
    want a value for every row in our data.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机回归插补会在基于我们模型残差的预测中添加一个正态分布的误差。我们希望这个误差的均值为零，且标准差与我们的残差相同。我们可以使用 NumPy 的 `normal`
    函数来实现这一点，代码为 `np.random.normal(0, lm.resid.std(), nls97.shape[0])`。其中，`lm.resid.std()`
    获取模型残差的标准差。最后一个参数 `nls97.shape[0]` 指示我们需要生成多少个值；在这个例子中，我们需要为每一行数据生成一个值。
- en: 'We can join those values with our data and then add the error, `randomadd`,
    to our prediction. We set a seed so that we can reproduce the results:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些值与数据合并，然后将误差 `randomadd` 加到我们的预测值中。我们设置了一个种子，以便可以重现结果：
- en: '[PRE79]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'This should increase the variance but not have much of an effect on the mean.
    Let’s confirm that. We first need to replace missing wage income values with the
    stochastic prediction:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这应该会增加方差，但不会对均值产生太大影响。让我们验证一下这一点。我们首先需要用随机预测值替换缺失的工资收入值：
- en: '[PRE80]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: That seems to have worked. The imputed variable based on our stochastic prediction
    has pretty much the same standard deviation as the wage income variable.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎起作用了。基于我们的随机预测插补的变量，标准差几乎与工资收入变量相同。
- en: How it works...
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'Regression imputation is a good way to take advantage of all the data we have
    to impute values for a column. It is often superior to the imputation methods
    we examined in the previous recipe, particularly when missing values are not random.
    Deterministic regression imputation does, however, have two important limitations:
    it assumes a linear relationship between the regressors (our predictor variables)
    and the variable to be imputed, and it can substantially reduce the variance of
    the imputed variable, as we saw in *steps 8 and 9*.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 回归插补是一种有效的方式，可以利用我们拥有的所有数据来填补某一列的缺失值。它通常优于我们在上一篇文章中研究的插补方法，尤其是在缺失值不是随机时。然而，确定性回归插补有两个重要的局限性：它假设回归变量（我们的预测变量）与待插补变量之间存在线性关系，并且它可能会显著降低插补变量的方差，正如我们在*步骤8和9*中看到的那样。
- en: If we use stochastic regression imputation we will not artificially reduce our
    variance. We did this in *step 10*. This gave us better results, though it did
    not address the possible issue of a non-linear relationship between regressors
    and the imputed variable.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用随机回归插补，就不会人为地减少方差。我们在*步骤10*中就做了这个操作。这样，我们得到了更好的结果，尽管它并没有解决回归变量与插补变量之间可能存在的非线性关系问题。
- en: Before we started using machine learning widely for this work, regression imputation
    was our go to multivariate approach for imputation. We now have the option of
    using algorithms like *k*-nearest neighbors and random forest for this task, which
    have advantages over regression imputation in some cases. KNN imputation, unlike
    regression imputation, does not assume a linear relationship between variables,
    or that those variables are normally distributed. We explore KNN imputation in
    the next recipe.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始广泛使用机器学习之前，回归插补是我们常用的多变量插补方法。现在，我们可以选择使用像*k*-最近邻和随机森林等算法来执行此任务，这些方法在某些情况下比回归插补更具优势。与回归插补不同，KNN插补不假设变量之间存在线性关系，也不假设这些变量是正态分布的。我们将在下一部分中探讨KNN插补。
- en: Using k-nearest neighbors for imputation
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用K最近邻进行插补
- en: '**k-Nearest Neighbors** (**KNN**) is a popular machine learning technique because
    it is intuitive and easy to run and yields good results when there is not a large
    number of variables and observations. For the same reasons, it is often used to
    impute missing values. As its name suggests, KNN identifies the *k* observations
    whose variables are most similar to each observation. When used to impute missing
    values, KNN uses the nearest neighbors to determine what fill values to use.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**k-最近邻**（**KNN**）是一种流行的机器学习技术，因为它直观易懂，易于运行，并且在变量和观察值数量不大的情况下，能提供很好的结果。正因如此，它经常用于插补缺失值。正如其名字所示，KNN识别出与每个观察值变量最相似的*k*个观察值。当用于插补缺失值时，KNN使用最近邻来确定应该使用哪些填充值。'
- en: Getting ready
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will work with the KNN imputer from scikit-learn version 1.3.0\. If you do
    not already have scikit-learn, you can install it with `pip install scikit-learn`.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用来自scikit-learn 1.3.0版本的KNN插补器。如果你还没有安装scikit-learn，可以通过`pip install scikit-learn`进行安装。
- en: How to do it...
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: We can use KNN imputation to do the same imputation we did in the previous recipe
    on regression imputation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用KNN插补来执行与上一篇文章中回归插补相同的插补操作。
- en: 'We start by importing the `KNNImputer` from `scikit-learn` and loading the
    NLS data again:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先从`scikit-learn`导入`KNNImputer`，并重新加载NLS数据：
- en: '[PRE82]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Next, we prepare the variables. We collapse degree attainment into three categories—less
    than college, college, and post-college degree—each category represented by a
    different dummy variable. We also convert logical missing values for parent income
    to actual missing values:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们准备变量。我们将学位获得情况合并为三个类别——低于大学、大学和大学以上学位——每个类别用不同的虚拟变量表示。我们还将家长收入的逻辑缺失值转换为实际的缺失值：
- en: '[PRE83]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Let’s create a DataFrame with just wage income and a few correlated variables.
    We also select only those rows with positive values for weeks worked:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个仅包含工资收入和一些相关变量的DataFrame。我们还只选择那些有工作周数为正值的行：
- en: '[PRE84]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: We are now ready to use the `fit_transform` method of the KNN imputer to get
    values for all missing values in the passed DataFrame, `wagedata`. `fit_transform`
    returns a NumPy array with all the non-missing values from `wagedata`, plus the
    imputed ones. We convert this array into a DataFrame using the same index as `wagedata`.
    This will make it easy to join the data in the next step. (This will be a familiar
    step to folks who have some experience using scikit-learn. We will go over it
    in more detail in the next chapter.)
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用KNN填补器的`fit_transform`方法，为传入的DataFrame `wagedata`中的所有缺失值生成填补值。`fit_transform`返回一个NumPy数组，包含了`wagedata`中所有非缺失值以及填补的值。我们将这个数组转换成一个使用`wagedata`相同索引的DataFrame。这样在下一步中合并数据会更加方便。（对于一些有使用scikit-learn经验的人来说，这一步应该是熟悉的，我们将在下一章中详细讲解。）
- en: We need to specify the value to use for number of nearest neighbors, for *k*.
    We use a general rule of thumb for determining *k*, the square root of the number
    of observations divided by 2 (sqrt(*N*)/2). That gives us 38 for *k* in this case.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要指定用于最近邻数目的值，即*k*。我们使用一个通用的经验法则来确定*k*的值，即观察数量的平方根除以2（sqrt(*N*)/2）。在这个例子中，*k*的值为38。
- en: '[PRE86]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: We join the imputed data with the original NLS wage data and take a look at
    a few observations. Notice that with KNN imputation that we did not need to do
    any pre-imputation for missing values of correlated variables. (With regression
    imputation, we set parent income to the dataset mean.)
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将填补后的数据与原始的NLS工资数据进行合并，并查看一些观测值。请注意，在KNN填补过程中，我们不需要对相关变量的缺失值进行任何预处理填补。（在回归填补中，我们将父母收入设为数据集的均值。）
- en: '[PRE87]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Let’s take a look at summary statistics for the original and imputed variables.
    Not surprisingly, the imputed wage income mean is lower than the original mean.
    As we discovered in the previous recipe, observations with missing wage income
    have lower degree attainment, weeks worked, and parental income. We also lose
    some of the variance in wage income.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看原始变量和填补变量的汇总统计数据。毫不奇怪，填补后的工资收入均值低于原始均值。正如我们在前一个菜谱中发现的，缺失工资收入的观测值通常具有较低的学历、较少的工作周数和较低的父母收入。我们还失去了一些工资收入的方差。
- en: '[PRE89]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: That was easy! The preceding steps gave us reasonable imputations for wage income,
    and also for other variables with missing values, with minimal data preparation
    on our part.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 很简单！前面的步骤为工资收入以及其他缺失值的变量提供了合理的填补，并且我们几乎没有进行数据准备。
- en: How it works...
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Most of the work in this recipe was done in *step 4*, when we passed our DataFrame
    to the `fit_transform` method of the KNN imputer. The KNN imputer returned a NumPy
    array with imputations for missing values for all columns in our data, including
    wage income. It did this imputation based on values for the *k* most similar observations.
    We converted the NumPy array into a DataFrame that we joined with the initial
    DataFrame in *step 5*.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这道菜谱的大部分工作是在*第4步*中完成的，我们将DataFrame传递给了KNN填补器的`fit_transform`方法。KNN填补器返回了一个NumPy数组，为我们数据中的所有列填补了缺失值，包括工资收入。它基于*k*个最相似的观测值来进行填补。我们将这个NumPy数组转换为一个DataFrame，并在*第5步*中与初始DataFrame合并。
- en: KNN does imputations without making any assumptions about the distribution of
    the underlying data. With regression imputation, the standard assumptions for
    linear regression apply, that there is a linear relationship between variables
    and that they are distributed normally. If this is not the case, KNN is likely
    a better approach to imputation.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: KNN在进行填补时并不假设基础数据的分布。而回归填补则假设线性回归的标准假设成立，即变量之间存在线性关系且数据服从正态分布。如果不是这种情况，KNN可能是更好的填补方法。
- en: We did need to make an initial assumption about an appropriate value for *k*,
    what is known as a hyperparameter. Model builders generally do hyperparameter
    tuning to find the best value of *k*. Hyperparameter tuning for KNN is beyond
    the scope of this book, but I step the reader through it in my book *Data Cleaning
    and Exploration with Machine Learning*. We made a reasonable assumption about
    a good value for *k* in *step 4*.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确实需要对*k*的适当值做出初步假设，这就是所谓的超参数。模型构建者通常会进行超参数调优，以找到最佳的*k*值。KNN的超参数调优超出了本书的范围，但我在我的书《*数据清洗与机器学习探索*》中详细讲解了这一过程。在*第4步*中，我们对*k*的合理假设做出了初步判断。
- en: There’s more...
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Despite these advantages, KNN imputation does have limitations. As we just discussed,
    we had to tune the model with an initial assumption about a good value for *k*,based
    only on our knowledge of the size of the dataset. There is some risk of overfitting—fitting
    the data with non-missing values for the target variable so well that our estimates
    for the missing values are unreliable—as we increase the value of *k*. Hyperparameter
    tuning can help us identify the best value for *k*.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这些优点，KNN插补也有其局限性。正如我们刚才讨论的，我们必须通过初步假设来调整模型，选择一个合适的*k*值，这个假设仅基于我们对数据集大小的了解。随着*k*值的增加，可能会存在过拟合的风险——即过度拟合目标变量的非缺失值数据，以至于我们对缺失值的估计不可靠。超参数调优可以帮助我们确定最佳的*k*值。
- en: KNN is also computationally expensive and may be impractical for very large
    datasets. Finally, KNN imputation may not perform well when the correlation is
    weak between the variable to be imputed and the predictor variables, or when those
    variables are very highly correlated. An alternative to KNN for imputation, random
    forest imputation, can help us avoid the disadvantages of both KNN and regression
    imputation. We explore random forest imputation next.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: KNN也在计算上比较昂贵，对于非常大的数据集可能不切实际。最后，当待插补的变量与预测变量之间的相关性较弱，或者这些变量之间高度相关时，KNN插补可能表现不佳。与KNN插补相比，随机森林插补能够帮助我们避免KNN和回归插补的缺点。接下来我们将探讨随机森林插补。
- en: See also
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: There is a fuller discussion of KNN, and examples with real-world data, in my
    book *Data Cleaning and Exploration with Machine Learning*. That discussion will
    give you a better understanding of how the algorithm works, and will contrast
    it with other non-parametric machine learning algorithms, such as random forest.
    We look at random forest for imputing values in the next recipe.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我在我的书《*数据清洗与机器学习探索*》中对KNN有更详细的讨论，并且有真实世界数据的示例。这些讨论将帮助您更好地理解算法的工作原理，并与其他非参数机器学习算法（如随机森林）进行对比。我们将在下一个配方中探讨随机森林用于插补值。
- en: Using random forest for imputation
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用随机森林进行插补
- en: Random forest is an ensemble learning method, using bootstrap aggregating, also
    known as bagging, to improve model accuracy. It makes predictions by repeatedly
    taking the mean of multiple trees, yielding progressively better estimates. We
    will use the MissForest algorithm in this recipe, which is an application of the
    random forest algorithm to missing value imputation.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是一种集成学习方法，使用自助聚合（也称为bagging）来提高模型准确性。它通过重复计算多棵树的平均值来做出预测，从而逐步改进估计值。在这个配方中，我们将使用MissForest算法，它是将随机森林算法应用于缺失值插补的一种方法。
- en: MissForest starts by filling in the median or mode (for continuous or categorical
    variables respectively) for missing values, then uses random forest to predict
    values. Using this transformed dataset, with missing values replaced by initial
    predictions, MissForest generates new predictions, perhaps replacing the initial
    prediction with a better one. MissForest will typically go through at least 4
    iterations of this process.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: MissForest通过填充缺失值的中位数或众数（分别适用于连续或分类变量）开始，然后使用随机森林来预测值。使用这个转换后的数据集，其中缺失值被初始预测替换，MissForest会生成新的预测，可能会用更好的预测值替换初始预测。MissForest通常会经历至少4次迭代。
- en: Getting ready
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 做好准备
- en: You will need to install the `MissForest` and `MiceForest` modules to run the
    code in this recipe. You can install both with `pip`.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行这个配方中的代码，您需要安装`MissForest`和`MiceForest`模块。可以通过`pip`安装这两个模块。
- en: How to do it...
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到……
- en: Running MissForest is even easier than using the KNN imputer, which we used
    in the previous recipe. We will impute values for the same wage income data that
    we worked with previously.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 运行MissForest比使用我们在前一个配方中使用的KNN插补器还要简单。我们将对之前处理过的工资收入数据进行插补。
- en: 'Let’s start by importing the `MissForest` module and loading the NLS data.
    We import `missforest`, and also `miceforest`, which we discuss in later steps:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从导入`MissForest`模块并加载NLS数据开始。我们导入`missforest`，并且还导入`miceforest`，我们将在后续步骤中讨论它：
- en: '[PRE91]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'We should do the same data cleaning that we did in the previous recipe:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该做与前一个配方中相同的数据清洗：
- en: '[PRE92]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Now we are ready to run MissForest. Notice that the process is remarkably similar
    to our process for using the KNN imputer:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们准备运行MissForest。请注意，这个过程与我们使用KNN插补器的过程非常相似：
- en: '[PRE93]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Let’s take a look at a few of our imputed values and some summary statistics.
    The imputed values have a lower mean. This is not surprising given that we have
    already learned that the missing values are not distributed randomly, as individuals
    with lower degree attainment and weeks worked are more likely to have missing
    values for wage income:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看一下我们的一些插补值和一些汇总统计信息。插补后的值具有较低的均值。考虑到我们已经知道缺失值并非随机分布，且具有较低学位和工作周数的人更有可能缺失工资收入，这一点并不令人惊讶：
- en: '[PRE94]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: MissForest uses the random forest algorithm to generate highly accurate predictions.
    Unlike KNN, it does not require tuning with an initial value for *k*. It also
    is computationally less expensive than KNN. Perhaps most importantly, random forest
    imputation is less sensitive to low or very high correlation among variables,
    though that was not an issue in this example.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: MissForest使用随机森林算法生成高精度的预测。与KNN不同，它不需要为*k*选择初始值进行调优。它的计算成本也低于KNN。或许最重要的是，随机森林插补对变量之间的低相关性或高度相关性不那么敏感，尽管在这个示例中这并不是问题。
- en: How it works...
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We largely follow the same process here as we did with KNN imputation in the
    previous recipe. We start by cleaning the data a bit, extracting a numeric variable
    from the highest degree text, and replacing logical missing values for parental
    income with actual missing values.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里基本上遵循与前一个食谱中KNN插补相同的过程。我们首先稍微清理数据，从最高阶的文本中提取数值变量，并将父母收入的逻辑缺失值替换为实际缺失值。
- en: We then pass our data to the `fit_transform` method of a `MissForest` imputer.
    This method returns a DataFrame with imputed values for all columns.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将数据传递给`MissForest`插补器的`fit_transform`方法。该方法返回一个包含所有列插补值的数据框。
- en: There’s more...
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We could have used Multiple Imputation by Chained Equations (MICE), which can
    be implemented using random forests, for our imputation instead. One advantage
    of this approach is that MICE adds a random component to imputations, likely further
    reducing the possibility of overfitting even over `missforest`.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们本可以使用链式方程多重插补（MICE），它可以通过随机森林实现，作为替代插补方法。该方法的一个优势是，MICE为插补添加了一个随机成分，可能进一步减少了过拟合的可能性，甚至优于`missforest`。
- en: '`miceforest` can be run in much the same way as `missforest`.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '`miceforest`的运行方式与`missforest`非常相似。'
- en: 'We create a `kernel` with the `miceforest` instance we created in *step 1*:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用在*步骤1*中创建的`miceforest`实例创建一个`kernel`：
- en: '[PRE98]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'Then we can view the results of our imputation:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以查看插补结果：
- en: '[PRE101]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: This produces very similar results as `missforest`. Both approaches are excellent
    choices for missing value imputation.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了与`missforest`非常相似的结果。这两种方法都是缺失值插补的优秀选择。
- en: Using PandasAI for imputation
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PandasAI进行插补
- en: Many of the missing value imputation tasks we have explored in this chapter
    can also be completed using PandasAI. As we have discussed in previous chapters,
    AI tools can help us check the work we have done with traditional tools and can
    suggest alternative approaches that did not occur to us. It always makes sense,
    though, to look under the hood and be sure we understand what PandasAI, or other
    AI tools, are doing.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们探讨的许多缺失值插补任务也可以通过PandasAI完成。正如我们在之前的章节中讨论的那样，AI工具可以帮助我们检查使用传统工具所做的工作，并能建议我们没有想到的替代方法。然而，理解PandasAI或其他AI工具的工作原理始终是有意义的。
- en: We will use PandasAI in this recipe to identify missing values, impute missing
    values based on summary statistics, and assign missing values based on machine
    learning algorithms.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用PandasAI来识别缺失值，基于汇总统计插补缺失值，并根据机器学习算法分配缺失值。
- en: Getting ready
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will work with PandasAI in this recipe. It can be installed with `pip install`
    `pandasai`. You also need to get a token from [openai.com](https://openai.com)
    to send a request to the OpenAI API.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用PandasAI。可以通过`pip install` `pandasai`进行安装。你还需要从[openai.com](https://openai.com)获取一个令牌，以便向OpenAI
    API发送请求。
- en: How to do it...
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: In this recipe, we will carry out many of the tasks we have done earlier in
    this chapter using AI tools instead.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用AI工具来完成本章中之前执行过的许多任务。
- en: 'We start by importing the `pandas` and `numpy` libraries and `OpenAI` and `pandasai`.
    We will work a fair bit with the PandasAI `SmartDataFrame` module in this recipe.
    We will also load the NLS data:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先导入`pandas`和`numpy`库，以及`OpenAI`和`pandasai`。在这个食谱中，我们将与PandasAI的`SmartDataFrame`模块进行大量的工作。我们还将加载NLS数据：
- en: '[PRE103]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'We do the same data cleaning on the parent income and highest degree variables
    that we did in previous recipes:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对父母收入和最高学位变量进行与之前示例相同的数据清理：
- en: '[PRE104]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'We create a DataFrame with just the wage and degree data, and then a `SmartDataframe`
    from PandasAI:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个仅包含工资和学位数据的DataFrame，然后从PandasAI中创建一个`SmartDataframe`：
- en: '[PRE105]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'Show non-missing counts, averages, and standard deviations for all the variables.
    We send a natural language command to the `chat` method of the `SmartDataFrame`
    object to do that. Since `hdegnum` (highest degree) is a categorical variable,
    `chat` does not show means or standard deviations:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示所有变量的非缺失计数、平均值和标准差。我们向`SmartDataFrame`对象的`chat`方法发送一个自然语言命令来执行此操作。由于`hdegnum`（最高学位）是一个分类变量，`chat`不会显示均值或标准差：
- en: '[PRE106]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'Let’s impute values for the missing values based on the average for each variable.
    The `chat` method will return a pandas DataFrame in this case. There are no longer
    missing values for the income and weeks worked variables, but PandasAI figured
    out that the degree categorical variable should not be imputed based on average:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将基于每个变量的均值填充缺失值。此时，`chat`方法将返回一个pandas DataFrame。收入和工作周数的缺失值不再存在，但PandasAI识别出学位类别变量不应根据均值填充：
- en: '[PRE108]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: Let’s look again at the values for highest degree. Notice that the most frequent
    value is `2`, which you may recall from earlier recipes represents high school
    completion.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们再来看一下最高学位的值。注意到最频繁的值是`2`，你可能记得之前的内容中，`2`代表的是高中文凭。
- en: '[PRE110]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'We can set missing values for the degree variables to their most frequent non-missing
    value, which is not an uncommon way to handle missing values for categorical variables.
    All of the missing values now have a value of `2`:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以将学位变量的缺失值设置为其最频繁的非缺失值，这是一种常见的处理分类变量缺失值的方法。现在，所有的缺失值都被填充为`2`：
- en: '[PRE112]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: We could have used the built-in `SmartDataframe` function, `impute_missing_values`,
    instead. This will use forward fill to impute missing values. No values are imputed
    for the highest degree variable, `hdegnum`.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们本可以使用内置的`SmartDataframe`函数`impute_missing_values`。这个函数将使用前向填充来填补缺失值。对于最高学位变量`hdegnum`，没有填充任何值。
- en: '[PRE114]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: We can use KNN for missing value imputation for the income and weeks worked
    variables. We start over with an unchanged DataFrame. After the imputation, the
    `wageincome20` mean is lower than it was originally, as shown in *step 4*. This
    is not surprising, since we have seen in other recipes that individuals with missing
    `wageincome20` have lower values for other values correlated with `wageincome20`.
    The reduction in the standard deviation for `wageincome20` and `parentincome`
    is not great. The mean and standard deviation for `weeksworked20` are largely
    unchanged, which is good.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用KNN方法填充收入和工作周数的缺失值。我们从一个未更改的DataFrame开始。在填充后，`wageincome20`的均值比原来要低，如*步骤4*所示。这并不奇怪，因为我们在其他示例中看到，缺失`wageincome20`的个体在与`wageincome20`相关的其他变量上也有较低的值。`wageincome20`和`parentincome`的标准差变化不大。`weeksworked20`的均值和标准差几乎没有变化，这很好。
- en: '[PRE116]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: How it works...
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Whenever we pass a natural language command to the `chat` method of a `SmartDataframe`,
    pandas code is generated to run that command. Some of that is very familiar code
    to generate summary statistics. However, it also can generate code to run machine
    learning algorithms such as KNN or random forest. As discussed in previous chapters,
    it is always a good idea to review the `pandasai.log` file after running `chat`
    to understand the code that was created.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们将自然语言命令传递给`SmartDataframe`的`chat`方法时，Pandas代码会被生成并执行该命令。有些代码用于生成非常熟悉的摘要统计数据。然而，它也能生成用于运行机器学习算法的代码，如KNN或随机森林。如前几章所述，执行`chat`后查看`pandasai.log`文件始终是个好主意，这样可以了解所生成的代码。
- en: This recipe demonstrated how to use PandasAI to identify and impute values where
    they are missing. AI tools, particularly large language models, make it easy to
    pass natural language commands to generate code like the code we created earlier
    in this chapter.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 本示例展示了如何使用PandasAI来识别和填充缺失值。AI工具，特别是大语言模型，使得通过自然语言命令生成代码变得容易，就像我们在本章早些时候创建的代码一样。
- en: Summary
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We have explored the most popular approaches for missing value imputation in
    this chapter, and have discussed the advantages and disadvantages of each approach.
    Assigning an overall sample mean is not usually a good approach, particularly
    when observations with missing values are different from other observations in
    important ways. We also can substantially reduce our variance. Forward or backward
    filling allows us to maintain the variance in our data, but works best when the
    proximity of observations is meaningful, such as with time series or longitudinal
    data. In most non-trivial cases we will want to use a multivariate technique,
    such as regression, KNN, or random forest imputation. We examined all these approaches
    in this chapter, and for the next chapter, we will learn about encoding, transforming,
    and scaling features.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了最流行的缺失值插补方法，并讨论了每种方法的优缺点。通常情况下，赋予一个整体样本均值并不是一个好方法，特别是当缺失值的观测值与其他观测值在重要方面存在差异时。我们也可以显著降低方差。前向或后向填充方法可以帮助我们保持数据的方差，但在观测值之间的接近性具有意义时，效果最佳，例如时间序列或纵向数据。在大多数非平凡的情况下，我们将需要使用多元技术，如回归、KNN
    或随机森林插补。在本章中，我们已经探讨了所有这些方法，接下来的章节中，我们将学习特征编码、转换和标准化。
- en: Leave a review!
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 留下评价！
- en: Enjoying this book? Help readers like you by leaving an Amazon review. Scan
    the QR code below to get a free eBook of your choice.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 喜欢这本书吗？通过在亚马逊上留下评价帮助像你一样的读者。扫描下面的二维码，获取一本你选择的免费电子书。
- en: '![](img/Review_copy.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Review_copy.png)'
