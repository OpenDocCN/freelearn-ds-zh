- en: '*Chapter 1*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第一章*'
- en: Introduction to Data Science and Data Pre-Processing
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学与数据预处理简介
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将能够：
- en: Use various Python machine learning libraries
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用各种 Python 机器学习库
- en: Handle missing data and deal with outliers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理缺失数据和异常值
- en: Perform data integration to bring together data from different sources
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行数据集成，将来自不同来源的数据汇集在一起
- en: Perform data transformation to convert data into a machine-readable form
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行数据转换，将数据转换为机器可读的形式
- en: Scale data to avoid problems with values of different magnitudes
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据进行缩放，以避免不同量级值所带来的问题
- en: Split data into train and test datasets
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集和测试集
- en: Describe the different types of machine learning
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述不同类型的机器学习
- en: Describe the different performance measures of a machine learning model
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述机器学习模型的不同性能评估指标
- en: This chapter introduces data science and covers the various processes included
    in the building of machine learning models, with a particular focus on pre-processing.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了数据科学，并涵盖了构建机器学习模型中涉及的各种过程，特别关注预处理部分。
- en: Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: We live in a world where we are constantly surrounded by data. As such, being
    able to understand and process data is an absolute necessity.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生活在一个充满数据的世界中。因此，能够理解和处理数据是绝对必要的。
- en: 'Data Science is a field that deals with the description, analysis, and prediction
    of data. Consider an example from our daily lives: every day, we utilize multiple
    social media applications on our phones. These applications gather and process
    data in order to create a more personalized experience for each user – for example,
    showing us news articles that we may be interested in, or tailoring search results
    according to our location. This branch of data science is known as **machine learning**.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学是一个处理数据描述、分析和预测的领域。举个我们日常生活中的例子：每天，我们都会在手机上使用多个社交媒体应用。这些应用收集并处理数据，以便为每个用户创造更个性化的体验——例如，向我们展示可能感兴趣的新闻文章，或根据我们的位置信息调整搜索结果。数据科学的这一分支被称为**机器学习**。
- en: Machine learning is the methodical learning of procedures and statistical representations
    that computers use to accomplish tasks without human intervention. In other words,
    it is the process of teaching a computer to perform tasks by itself without explicit
    instructions, relying only on patterns and inferences. Some common uses of machine
    learning algorithms are in email filtering, computer vision, and computational
    linguistics.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是计算机通过程序化学习和统计表示来完成任务的过程，无需人工干预。换句话说，它是通过模式和推断来教计算机自己执行任务，而不是依赖于明确的指令。一些常见的机器学习算法应用包括电子邮件过滤、计算机视觉和计算语言学。
- en: This book will focus on machine learning and other aspects of data science using
    Python. Python is a popular language for data science, as it is versatile and
    relatively easy to use. It also has several ready-made libraries that are well
    equipped for processing data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将专注于使用 Python 进行机器学习及数据科学的其他方面。Python 是数据科学中一种流行的编程语言，因为它多功能且相对易用。它还拥有多个现成的库，非常适合用于数据处理。
- en: Python Libraries
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python 库
- en: Throughout this book, we'll be using various Python libraries, including pandas,
    Matplotlib, Seaborn, and scikit-learn.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将使用各种 Python 库，包括 pandas、Matplotlib、Seaborn 和 scikit-learn。
- en: '**pandas**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**pandas**'
- en: 'pandas is an open source package that has many functions for loading and processing
    data in order to prepare it for machine learning tasks. It also has tools that
    can be used to analyze and manipulate data. Data can be read from many formats
    using pandas. We will mainly be using CSV data throughout this book. To read CSV
    data, you can use the `read_csv()` function by passing `filename.csv` as an argument.
    An example of this is shown here:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 是一个开源包，具有许多用于加载和处理数据的功能，以便为机器学习任务做好准备。它还具有用于分析和操纵数据的工具。可以使用 pandas 从多种格式读取数据。本书主要使用
    CSV 数据。要读取 CSV 数据，您可以使用 `read_csv()` 函数，并将 `filename.csv` 作为参数传入。以下是示例代码：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the preceding code, `pd` is an alias name given to pandas. It is not mandatory
    to give an alias. To visualize a pandas DataFrame, you can use the `head()` function
    to list the top five rows. This will be demonstrated in one of the following exercises.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`pd` 是给 pandas 起的别名。为 pandas 起别名并非强制要求。要可视化一个 pandas DataFrame，您可以使用
    `head()` 函数来列出前五行数据。接下来的练习中会展示这一点。
- en: Note
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please visit the following link to learn more about pandas: https://pandas.pydata.org/pandas-docs/stable/.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请访问以下链接了解更多关于pandas的信息：[https://pandas.pydata.org/pandas-docs/stable/](https://pandas.pydata.org/pandas-docs/stable/)。
- en: '**NumPy**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**NumPy**'
- en: NumPy is one of the main packages that Python has to offer. It is mainly used
    in practices related to scientific computing and when working on mathematical
    operations. It comprises of tools that enable us to work with arrays and array
    objects.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy是Python提供的主要包之一。它主要用于科学计算相关的实践，特别是在进行数学运算时。它包含的工具使我们能够处理数组和数组对象。
- en: '**Matplotlib**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**Matplotlib**'
- en: Matplotlib is a data visualization package. It is useful for plotting data points
    in a 2D space with the help of NumPy.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Matplotlib是一个数据可视化包。它对于在二维空间中绘制数据点非常有用，可以借助NumPy实现。
- en: '**Seaborn**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**Seaborn**'
- en: Seaborn is also a data visualization library that is based on matplotlib. Visualizations
    created using Seaborn are far more attractive than ones created using matplotlib
    in terms of graphics.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Seaborn也是一个基于matplotlib的数据可视化库。使用Seaborn创建的可视化在图形效果上比matplotlib更具吸引力。
- en: '**scikit-learn**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**scikit-learn**'
- en: scikit-learn is a Python package used for machine learning. It is designed in
    such a way that it interoperates with other numeric and scientific libraries in
    Python to achieve the implementation of algorithms.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn是一个用于机器学习的Python包。它的设计方式使其可以与Python中的其他数值和科学库互操作，从而实现算法的实现。
- en: These ready-to-use libraries have gained interest and attention from developers,
    especially in the data science space. Now that we have covered the various libraries
    in Python, in the next section we'll explore the roadmap for building machine
    learning models.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这些现成可用的库吸引了开发者的兴趣，特别是在数据科学领域。现在我们已经介绍了Python中的各种库，接下来我们将探索构建机器学习模型的路线图。
- en: Roadmap for Building Machine Learning Models
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建机器学习模型的路线图
- en: 'The roadmap for building machine learning models is straightforward and consists
    of five major steps, which are explained here:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 构建机器学习模型的路线图非常直接，包含五个主要步骤，下面进行解释：
- en: '**Data Pre-processing**'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据预处理**'
- en: This is the first step in building a machine learning model. Data pre-processing
    refers to the transformation of data before feeding it into the model. It deals
    with the techniques that are used to convert unusable raw data into clean reliable
    data.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是构建机器学习模型的第一步。数据预处理是指在将数据输入模型之前对数据进行的转换。它处理的是将无法使用的原始数据转化为干净、可靠数据的技术。
- en: 'Since data collection is often not performed in a controlled manner, raw data
    often contains outliers (for example, age = 120), nonsensical data combinations
    (for example, model: bicycle, type: 4-wheeler), missing values, scale problems,
    and so on. Because of this, raw data cannot be fed into a machine learning model
    because it might compromise the quality of the results. As such, this is the most
    important step in the process of data science.'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于数据收集通常不是以受控方式进行的，原始数据通常包含异常值（例如，年龄=120）、无意义的数据组合（例如，模型：自行车，类型：四轮车）、缺失值、尺度问题等。因此，原始数据不能直接输入机器学习模型，因为它可能会影响结果的质量。因此，这是数据科学过程中最重要的一步。
- en: '**Model Learning**'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型学习**'
- en: After pre-processing the data and splitting it into train/test sets (more on
    this later), we move on to modeling. Models are nothing but sets of well-defined
    methods called algorithms that use pre-processed data to learn patterns, which
    can later be used to make predictions. There are different types of learning algorithms,
    including supervised, semi-supervised, unsupervised, and reinforcement learning.
    These will be discussed later.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在对数据进行预处理并将其拆分为训练集/测试集（稍后会详细介绍）之后，我们进入建模阶段。模型只是一些被称为算法的明确定义的方法，这些算法使用预处理过的数据来学习模式，之后可以用来做预测。学习算法有不同的类型，包括监督学习、半监督学习、无监督学习和强化学习。这些将在后面讨论。
- en: '**Model Evaluation**'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型评估**'
- en: In this stage, the models are evaluated with the help of specific performance
    metrics. With these metrics, we can go on to tune the hyperparameters of a model
    in order to improve it. This process is called **hyperparameter optimization**.
    We will repeat this step until we are satisfied with the performance.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在此阶段，模型通过特定的性能指标进行评估。通过这些指标，我们可以进一步调整模型的超参数以改进模型。这个过程称为**超参数优化**。我们将重复这一步骤，直到对模型的性能满意为止。
- en: '**Prediction**'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测**'
- en: Once we are happy with the results from the evaluation step, we will then move
    on to predictions. Predictions are made by the trained model when it is exposed
    to a new dataset. In a business setting, these predictions can be shared with
    decision makers to make effective business choices.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦我们对评估步骤的结果满意，我们将进入预测阶段。当训练好的模型接触到新的数据集时，它会进行预测。在商业环境中，这些预测可以与决策者共享，以做出有效的商业决策。
- en: '**Model Deployment**'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署**'
- en: The whole process of machine learning does not just stop with model building
    and prediction. It also involves making use of the model to build an application
    with the new data. Depending on the business requirements, the deployment may
    be a report, or it may be some repetitive data science steps that are to be executed.
    After deployment, a model needs proper management and maintenance at regular intervals
    to keep it up and running.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 机器学习的整个过程不仅仅止于模型构建和预测。它还涉及利用模型构建带有新数据的应用程序。根据商业需求，部署可能是一个报告，或者是一些需要执行的重复性数据科学步骤。部署后，模型需要定期进行适当的管理和维护，以确保其正常运行。
- en: This chapter will mainly focus on pre-processing. We will cover the different
    tasks involved in data pre-processing, such as data representation, data cleaning,
    and others.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本章主要关注预处理部分。我们将讨论数据预处理中的不同任务，如数据表示、数据清理等。
- en: Data Representation
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据表示
- en: The main objective of machine learning is to build models that understand data
    and find underlying patterns. In order to do so, it is very important to feed
    the data in a way that is interpretable by the computer. To feed the data into
    a model, it must be represented as a table or a matrix of the required dimensions.
    Converting your data into the correct tabular form is one of the first steps before
    pre-processing can properly begin.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的主要目标是构建能够理解数据并发现潜在模式的模型。为了实现这一目标，将数据以计算机能够理解的方式进行输入是非常重要的。为了将数据输入到模型中，它必须以表格或矩阵的形式表示，且具有所需的维度。在预处理能够正确开始之前，将数据转换为正确的表格形式是第一步。
- en: '**Data Represented in a Table**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**以表格形式表示的数据**'
- en: 'Data should be arranged in a two-dimensional space made up of rows and columns.
    This type of data structure makes it easy to understand the data and pinpoint
    any problems. An example of some raw data stored as a CSV (**comma separated values**)
    file is shown here:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 数据应该安排在由行和列组成的二维空间中。这种数据结构使得理解数据和发现问题变得容易。以下是一些存储为 CSV（**逗号分隔值**）文件的原始数据示例：
- en: '![Figure 1.1: Raw data in CSV format](img/C13322_01_01.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.1：CSV 格式的原始数据](img/C13322_01_01.jpg)'
- en: 'Figure 1.1: Raw data in CSV format'
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.1：CSV 格式的原始数据
- en: 'The representation of the same data in a table is as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 相同数据在表格中的表示如下：
- en: '![Figure 1.2: CSV data in table format](img/C13322_01_02.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2：表格格式的 CSV 数据](img/C13322_01_02.jpg)'
- en: 'Figure 1.2: CSV data in table format'
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.2：表格格式的 CSV 数据
- en: If you compare the data in CSV and table formats, you will see that there are
    missing values in both. We will cover what to do with these later in the chapter.
    To load a CSV file and work on it as a table, we use the pandas library. The data
    here is loaded into tables called DataFrames.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对比 CSV 格式和表格格式中的数据，你会发现两者都有缺失值。我们将在本章后续部分讨论如何处理这些缺失值。要加载 CSV 文件并将其作为表格处理，我们使用
    pandas 库。这里的数据被加载到称为 DataFrame 的表格中。
- en: Note
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'To learn more about pandas, visit the following link: http://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 pandas 的信息，请访问以下链接：[http://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html](http://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html)。
- en: Independent and Target Variables
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自变量和目标变量
- en: The DataFrame that we use contains variables or features that can be classified
    into two categories. These are independent variables (also called **predictor
    variables**) and dependent variables (also called **target variables**). Independent
    variables are used to predict the target variable. As the name suggests, independent
    variables should be independent of each other. If they are not, this will need
    to be addressed in the pre-processing (cleaning) stage.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的数据框（DataFrame）包含可以分为两类的变量或特征。这些是自变量（也称为**预测变量**）和因变量（也称为**目标变量**）。自变量用于预测目标变量。顾名思义，自变量应该彼此独立。如果它们不独立，需要在预处理（清理）阶段加以处理。
- en: '**Independent Variables**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**自变量**'
- en: 'These are all the features in the DataFrame except the **target variable**.
    They are of size (m, n), where m is the number of observations and n is the number
    of features. These variables must be normally distributed and should NOT contain:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是 DataFrame 中所有的特征，除了 **目标变量**。它们的尺寸是 (m, n)，其中 m 是观测值的数量，n 是特征的数量。这些变量必须服从正态分布，并且不应包含以下内容：
- en: Missing or NULL values
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值或 NULL 值
- en: Highly categorical data features or high cardinality (these terms will be covered
    in more detail later)
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高度分类的数据特征或高基数特征（这些术语将在后面详细讨论）
- en: Outliers
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常值
- en: Data on different scales
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同尺度的数据
- en: Human error
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人为错误
- en: Multicollinearity (independent variables that are correlated)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多重共线性（相互关联的自变量）
- en: Very large independent feature sets (too many independent variables to be manageable)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常大的独立特征集（自变量过多，难以管理）
- en: Sparse data
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稀疏数据
- en: Special characters
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特殊字符
- en: '**Feature Matrix and Target Vector**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征矩阵和目标向量**'
- en: 'A single piece of data is called a scalar. A group of scalars is called a vector,
    and a group of vectors is called a matrix. A matrix is represented in rows and
    columns. Feature matrix data is made up of independent columns, and the target
    vector depends on the feature matrix columns. To get a better understanding of
    this, let''s look at the following table:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一条数据称为标量。多个标量组成一个向量，多个向量组成一个矩阵。矩阵是通过行和列来表示的。特征矩阵数据由独立的列组成，而目标向量则依赖于特征矩阵的列。为了更好地理解这一点，我们来看一下以下表格：
- en: '![Figure 1.3: Table containing car details](img/C13322_01_03.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.3：包含汽车详细信息的表格](img/C13322_01_03.jpg)'
- en: 'Figure 1.3: Table containing car details'
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.3：包含汽车详细信息的表格
- en: 'As you can see in the table, there are various columns: Car Model, Car Capacity,
    Car Brand, and Car Price. All columns except Car Price are independent variables
    and represent the feature matrix. Car Price is the dependent variable that depends
    on the other columns (Car Model, Car Capacity, and Car Brand). It is a target
    vector because it depends on the feature matrix data. In the next section, we''ll
    go through an exercise based on features and a target matrix to get a thorough
    understanding.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在表格中看到的，有多个列：汽车型号、汽车容量、汽车品牌和汽车价格。除了汽车价格之外，所有列都是自变量，代表特征矩阵。汽车价格是因变量，它依赖于其他列（汽车型号、汽车容量和汽车品牌）。它是一个目标向量，因为它依赖于特征矩阵的数据。在下一部分，我们将通过一个基于特征和目标矩阵的练习来全面理解。
- en: Note
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: All exercises and activities will be primarily developed in Jupyter Notebook.
    It is recommended to keep a separate notebook for different assignments unless
    advised not to. Also, to load a sample dataset, the pandas library will be used,
    because it displays the data as a table. Other ways to load data will be explained
    in further sections.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 所有练习和活动将主要在 Jupyter Notebook 中进行开发。建议为不同的作业保持一个单独的 notebook，除非有特别的要求。另外，为了加载样本数据集，将使用
    pandas 库，因为它能以表格形式显示数据。其他加载数据的方法将在后续章节中解释。
- en: 'Exercise 1: Loading a Sample Dataset and Creating the Feature Matrix and Target
    Matrix'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 1：加载样本数据集并创建特征矩阵和目标矩阵
- en: 'In this exercise, we will be loading the `House_price_prediction` dataset into
    the pandas DataFrame and creating feature and target matrices. The `House_price_prediction`
    dataset is taken from the UCI Machine Learning Repository. The data was collected
    from various suburbs of the USA and consists of 5,000 entries and 6 features related
    to houses. Follow these steps to complete this exercise:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将把 `House_price_prediction` 数据集加载到 pandas DataFrame 中，并创建特征矩阵和目标矩阵。`House_price_prediction`
    数据集来自 UCI 机器学习库。该数据收集自美国的多个郊区，包含 5,000 条记录和与房屋相关的 6 个特征。按照以下步骤完成此练习：
- en: Note
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `House_price_prediction` dataset can be found at this location: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/USA_Housing.csv.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`House_price_prediction` 数据集可以在以下位置找到：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/USA_Housing.csv。'
- en: 'Open a Jupyter notebook and add the following code to import pandas:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 Jupyter notebook，并添加以下代码来导入 pandas：
- en: '[PRE1]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now we need to load the dataset into a pandas DataFrame. As the dataset is
    a CSV file, we''ll be using the `read_csv()` function to read the data. Add the
    following code to do this:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要将数据集加载到 pandas DataFrame 中。由于数据集是一个 CSV 文件，我们将使用 `read_csv()` 函数来读取数据。添加以下代码来实现：
- en: '[PRE2]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As you can see in the preceding code, the data is stored in a variable named
    `df`.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正如你在上面的代码中看到的，数据存储在名为 `df` 的变量中。
- en: 'To print all the column names of the DataFrame, we''ll use the `df.columns`
    command. Write the following code in the notebook:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要打印数据框的所有列名，我们将使用`df.columns`命令。在笔记本中编写以下代码：
- en: '[PRE3]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding code generates the following output:'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.4: List of columns present in the dataframe](img/C13322_01_04.jpg)'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.4：数据框中存在的列列表](img/C13322_01_04.jpg)'
- en: 'Figure 1.4: List of columns present in the dataframe'
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.4：数据框中存在的列列表
- en: 'The dataset contains n number of data points. We can find the total number
    of rows using the following command:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集包含 n 个数据点。我们可以使用以下命令找到行数的总数：
- en: '[PRE4]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding code generates the following output:'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.5: Total Index in the dataframe](img/C13322_01_05.jpg)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.5：数据框中的总索引](img/C13322_01_05.jpg)'
- en: 'Figure 1.5: Total Index in the dataframe'
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.5：数据框中的总索引
- en: As you can see in the preceding figure, our dataset contains 5000 rows, from
    index 0 to 5000.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如前图所示，我们的数据集包含 5000 行，索引从 0 到 5000。
- en: Note
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You can use the `set_index()` function in pandas to convert a column into an
    index of rows in a DataFrame. This is a bit like using the values in that column
    as your row labels.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在 pandas 中使用`set_index()`函数将某一列转换为数据框中行的索引。这有点像使用该列中的值作为行标签。
- en: '`Dataframe.set_index(''column name'', inplace = True'')''`'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Dataframe.set_index(''column name'', inplace = True'')''`'
- en: 'Let''s set the `Address` column as an index and reset it back to the original
    DataFrame. The pandas library provides the `set_index()` method to convert a column
    into an index of rows in a DataFrame. Add the following code to implement this:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将`Address`列设置为索引，然后将其重置回原始数据框。pandas 库提供了`set_index()`方法，将列转换为数据框中的行索引。添加以下代码来实现：
- en: '[PRE5]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding code generates the following output:'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.6: DataFrame with an indexed Address column](img/C13322_01_06.jpg)'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.6：带有索引的地址列的数据框](img/C13322_01_06.jpg)'
- en: 'Figure 1.6: DataFrame with an indexed Address column'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.6：带有索引的地址列的数据框
- en: The `inplace` parameter in the `set_index()` function is by default set to `False`.
    If the value is changed to `True`, then whatever operation we perform the content
    of the DataFrame changes directly without the copy being created.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`set_index()`函数中的`inplace`参数默认为`False`。如果将其值更改为`True`，那么我们执行的任何操作都会直接修改数据框的内容，而不会创建副本。'
- en: 'In order to reset the index of the given object, we use the `reset_index()`
    function. Write the following code to implement this:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要重置给定对象的索引，我们使用`reset_index()`函数。编写以下代码来实现：
- en: '[PRE6]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The preceding code generates the following output:'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.7: DataFrame with the index reset](img/C13322_01_07.jpg)'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.7：重置索引的数据框](img/C13322_01_07.jpg)'
- en: 'Figure 1.7: DataFrame with the index reset'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.7：重置索引的数据框
- en: Note
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The index is like a name given to a row and column. Rows and columns both have
    an index. You can index by row/column number or row/column name.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 索引就像是给行和列起的名字。行和列都有索引。你可以通过行/列号或者行/列名来索引。
- en: 'We can retrieve the first four rows and the first three columns using a row
    number and column number. This can be done using the `iloc` indexer in pandas,
    which retrieves data using index positions. Add the following code to do this:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用行号和列号来检索前四行和前三列数据。这可以通过 pandas 中的`iloc`索引器来完成，该索引器通过索引位置检索数据。添加以下代码来实现：
- en: '[PRE7]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Figure 1.8: Dataset of four rows and three columns](img/C13322_01_08.jpg)'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.8：包含四行和三列的数据集](img/C13322_01_08.jpg)'
- en: 'Figure 1.8: Dataset of four rows and three columns'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.8：包含四行和三列的数据集
- en: 'To retrieve the data using labels, we use the `loc` indexer. Add the following
    code to retrieve the first five rows of the Income and Age columns:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要使用标签检索数据，我们使用`loc`索引器。添加以下代码来检索收入和年龄列的前五行：
- en: '[PRE8]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Figure 1.9: Dataset of five rows and two columns](img/C13322_01_09.jpg)'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.9：包含五行和两列的数据集](img/C13322_01_09.jpg)'
- en: 'Figure 1.9: Dataset of five rows and two columns'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.9：包含五行和两列的数据集
- en: 'Now create a variable called `X` to store the independent features. In our
    dataset, we will consider all features except Price as independent variables,
    and we will use the `drop()` function to include them. Once this is done, we print
    out the top five instances of the `X` variable. Add the following code to do this:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在创建一个名为`X`的变量来存储独立特征。在我们的数据集中，我们将把除了价格以外的所有特征视为独立变量，并使用`drop()`函数将它们包括进来。完成后，打印出`X`变量的前五个实例。可以添加以下代码来实现：
- en: '[PRE9]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding code generates the following output:'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![Figure 1.10: Dataset showing the first five rows of the feature matrix](img/C13322_01_10.jpg)'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.10：显示特征矩阵前五行的数据集](img/C13322_01_10.jpg)'
- en: 'Figure 1.10: Dataset showing the first five rows of the feature matrix'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.10：显示特征矩阵前五行的数据集
- en: Note
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The default number of instances that will be taken for the head is five, so
    if you don't specify the number then it will by default output five observations.
    The axis parameter in the preceding screenshot denotes whether you want to drop
    the label from rows (axis = 0) or columns (axis = 1).
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 默认情况下，获取头部的实例数量为五，因此如果你没有指定数量，它将默认输出五个观测值。前面的截图中的axis参数表示你是否想从行（axis = 0）或列（axis
    = 1）中删除标签。
- en: 'Print the shape of your newly created feature matrix using the `X.shape` command.
    Add the following code to do this:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`X.shape`命令打印你新创建的特征矩阵的形状。添加以下代码来实现这一功能：
- en: '[PRE10]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding code generates the following output:'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![](img/C13322_01_11.jpg)'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C13322_01_11.jpg)'
- en: 'Figure 1.11: Shape of the feature matrix'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.11：特征矩阵的形状
- en: In the preceding figure, the first value indicates the number of observations
    in the dataset (**5000**), and the second value represents the number of features
    (**6**).
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的图中，第一个值表示数据集中观测值的数量（**5000**），第二个值表示特征的数量（**6**）。
- en: 'Similarly, we will create a variable called `y` that will store the target
    values. We will use indexing to grab the target column. Indexing allows you to
    access a section of a larger element. In this case, we want to grab the column
    named Price from the `df` DataFrame. Then, we want to print out the top 10 values
    of the variable. Add the following code to implement this:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，我们将创建一个名为`y`的变量，用来存储目标值。我们将使用索引来获取目标列。索引允许你访问一个更大元素的部分。在这种情况下，我们想从`df`数据框中获取名为Price的列。然后，我们希望打印出该变量的前10个值。添加以下代码来实现这一功能：
- en: '[PRE11]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding code generates the following output:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![Figure 1.12: Dataset showing the first 10 rows of the target matrix](img/C13322_01_12.jpg)'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.12：显示目标矩阵前10行的数据集](img/C13322_01_12.jpg)'
- en: 'Figure 1.12: Dataset showing the first 10 rows of the target matrix'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.12：显示目标矩阵前10行的数据集
- en: 'Print the shape of your new variable using the `y.shape` command. The shape
    should be one-dimensional, with a length equal to the number of observations (**5000**)
    only. Add the following code to implement this:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`y.shape`命令打印你新变量的形状。形状应该是一维的，长度仅等于观测值的数量（**5000**）。添加以下代码来实现这一功能：
- en: '[PRE12]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding code generates the following output:'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![Figure 1.13: Shape of the target matrix](img/C13322_01_13.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.13：目标矩阵的形状](img/C13322_01_13.jpg)'
- en: 'Figure 1.13: Shape of the target matrix'
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.13：目标矩阵的形状
- en: You have successfully created the feature and target matrices of a dataset.
    You have completed the first step in the process of building a predictive model.
    This model will learn the patterns from the feature matrix (columns in `X`) and
    how they map to the values in the target vector (`y`). These patterns can then
    be used to predict house prices from new data based on the features of those new
    houses.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你已成功创建了数据集的特征矩阵和目标矩阵。你已完成建立预测模型过程中的第一步。这个模型将从特征矩阵（`X`中的列）中学习模式，并了解它们如何与目标向量（`y`）中的值相匹配。这些模式可以用于基于新房屋的特征，从新数据中预测房价。
- en: In the next section, we will explore more steps involved in pre-processing.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将探讨更多的数据预处理步骤。
- en: Data Cleaning
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据清理
- en: Data cleaning includes processes such as filling in missing values and handling
    inconsistencies. It detects corrupt data and replaces or modifies it.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清理包括填补缺失值和处理不一致的过程。它可以检测到损坏的数据，并进行替换或修改。
- en: '**Missing Values**'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺失值**'
- en: 'The concept of missing values is important to understand if you want to master
    the skill of successful management and understanding of data. Let''s take a look
    at the following figure:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想掌握成功管理和理解数据的技能，理解缺失值的概念是非常重要的。让我们看看下图：
- en: '![Figure 1.14: Bank customer credit data](img/C13322_01_14.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.14：银行客户信用数据](img/C13322_01_14.jpg)'
- en: 'Figure 1.14: Bank customer credit data'
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.14：银行客户信用数据
- en: As you can see, the data belongs to a bank; each row is a separate customer
    and each column contains their details, such as age and credit amount. There are
    some cells that have either **NA** or are just empty. This is missing data. Each
    piece of information about the customer is crucial for the bank. If any of the
    information is missing, then it will be difficult for the bank to predict the
    risk of providing a loan to the customer.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，这些数据来自一家银行；每一行代表一个独立的客户，每一列包含他们的详细信息，如年龄和信用额度。有些单元格中要么是**NA**，要么是空白。这些都是缺失数据。银行需要知道每个客户的每一项信息。如果任何信息缺失，银行就难以预测是否能够向该客户提供贷款。
- en: '**Handling Missing Data**'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**处理缺失数据**'
- en: Intelligent handling of missing data will result in building a robust model
    capable of handling complex tasks. There are many ways to handle missing data.
    Let's now look at some of those ways.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 智能地处理缺失数据将帮助构建一个强健的模型，能够应对复杂的任务。处理缺失数据有多种方法。接下来我们将看看其中的一些方法。
- en: '**Removing the Data**'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**删除数据**'
- en: 'Checking missing values is the first and the most important step in data pre-processing.
    A model cannot accept data with missing values. This is a very simple and commonly
    used method to handle missing values: we delete a row if the missing value corresponds
    to the places in the row, or we delete a column if it has more than 70%-75% of
    missing data. Again, the threshold value is not fixed and depends on how much
    you wish to fix.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 检查缺失值是数据预处理中的第一步，也是最重要的一步。模型无法接受包含缺失值的数据。这是一个非常简单且常用的方法来处理缺失值：如果缺失值出现在某行中的位置，就删除该行；或者如果某一列的缺失数据超过70%-75%，就删除该列。同样，阈值不是固定的，取决于你希望修复多少数据。
- en: The benefit of this approach is that it is quick and easy to do, and in many
    cases no data is better than bad data. The drawback is that you may end up losing
    important information, because you're deleting a whole feature based on a few
    missing values.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的好处在于它快速且简单，并且在很多情况下，缺少数据比错误的数据更好。缺点是，你可能会丢失重要的信息，因为你是基于几个缺失值删除整个特征的。
- en: 'Exercise 2: Removing Missing Data'
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习2：删除缺失数据
- en: 'In this exercise, we will be loading the `Banking_Marketing.csv` dataset into
    the pandas DataFrame and handling the missing data. This dataset is related to
    direct marketing campaigns of a Portuguese banking institution. The marketing
    campaigns involved phone calls to clients to try and get them to subscribe to
    a particular product. The dataset contains the details of each client contacted,
    and whether they subscribed to the product. Follow these steps to complete this
    exercise:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将把`Banking_Marketing.csv`数据集加载到pandas DataFrame中，并处理缺失数据。这个数据集与葡萄牙一家银行的直接营销活动有关。营销活动包括打电话给客户，尝试让他们订阅某一特定产品。数据集包含了每个被联系客户的详细信息，以及他们是否订阅了该产品。请按照以下步骤完成这个练习：
- en: Note
  id: totrans-164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `Banking_Marketing.csv` dataset can be found at this location: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Banking_Marketing.csv.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`Banking_Marketing.csv`数据集可以在此位置找到：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Banking_Marketing.csv。'
- en: 'Open a Jupyter notebook. Insert a new cell and add the following code to import
    pandas and fetch the `Banking_Marketing.csv` dataset:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter笔记本。插入一个新单元格，并添加以下代码以导入pandas并获取`Banking_Marketing.csv`数据集：
- en: '[PRE13]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Once you have fetched the dataset, print the datatype of each column. To do
    so, use the `dtypes` attribute from the pandas DataFrame:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦获取了数据集，打印出每一列的数据类型。为此，可以使用pandas DataFrame的`dtypes`属性：
- en: '[PRE14]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The preceding code generates the following output:'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码会生成以下输出：
- en: '![Figure 1.15: Data types of each feature](img/C13322_01_15.jpg)'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.15：每个特征的数据类型](img/C13322_01_15.jpg)'
- en: 'Figure 1.15: Data types of each feature'
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.15：每个特征的数据类型
- en: 'Now we need to find the missing values for each column. In order to do that,
    we use the `isna()` function provided by pandas:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要找到每一列的缺失值。为此，我们使用pandas提供的`isna()`函数：
- en: '[PRE15]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The preceding code generates the following output:'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码会生成以下输出：
- en: '![Figure 1.16: Missing values of each column in the dataset](img/C13322_01_16.jpg)'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.16：数据集中每列的缺失值](img/C13322_01_16.jpg)'
- en: 'Figure 1.16: Missing values of each column in the dataset'
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.16：数据集中每列的缺失值
- en: In the preceding figure, we can see that there is data missing from three columns,
    namely `age`, `contact`, and `duration`. There are two NAs in the **age** column,
    six NAs in **contact**, and seven NAs in **duration**.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在上面的图中，我们可以看到有三列数据缺失，分别是`age`、`contact`和`duration`。**age**列有两个缺失值，**contact**列有六个缺失值，**duration**列有七个缺失值。
- en: 'Once you have figured out all the missing details, we remove all the missing
    rows from the DataFrame. To do so, we use the `dropna()` function:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你弄清楚所有缺失的细节，我们就从DataFrame中删除所有缺失的行。为此，我们使用`dropna()`函数：
- en: '[PRE16]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To check whether the missing vales are still present, use the `isna()` function:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了检查缺失值是否仍然存在，可以使用`isna()`函数：
- en: '[PRE17]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The preceding code generates the following output:'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上面的代码会生成以下输出：
- en: '![Figure 1.17: Each column of the dataset with zero missing values](img/C13322_01_17.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图1.17：数据集中每列没有缺失值](img/C13322_01_17.jpg)'
- en: 'Figure 1.17: Each column of the dataset with zero missing values'
  id: totrans-185
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.17：数据集中每列没有缺失值
- en: You have successfully removed all missing data from the DataFrame. In the next
    section, we'll look at the second method of dealing with missing data, which uses
    imputation.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地从DataFrame中删除了所有缺失数据。在接下来的章节中，我们将介绍第二种处理缺失数据的方法，即使用填补法。
- en: '**Mean/Median/Mode Imputation**'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '**均值/中位数/众数填补**'
- en: In the case of numerical data, we can compute its mean or median and use the
    result to replace missing values. In the case of the categorical (non-numerical)
    data, we can compute its mode to replace the missing value. This is known as imputation.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数值数据，我们可以计算其均值或中位数，并用结果替换缺失值。对于类别（非数值）数据，我们可以计算其众数来替代缺失值。这就是所谓的填补法（imputation）。
- en: The benefit of using imputation, rather than just removing data, is that it
    prevents data loss. The drawback is that you don't know how accurate using the
    mean, median, or mode is going to be in a given situation.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 使用填补法（imputation）而不是直接删除数据的好处在于，它可以防止数据丢失。缺点是你无法知道在特定情况下，使用均值、中位数或众数的准确性如何。
- en: Let's look at an exercise in which we will use imputation method to solve missing
    data problems.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个练习，使用填补法来解决缺失数据问题。
- en: 'Exercise 3: Imputing Missing Data'
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习3：填补缺失数据
- en: 'In this exercise, we will be loading the `Banking_Marketing.csv` dataset into
    the pandas DataFrame and handle the missing data. We''ll make use of the imputation
    method. Follow these steps to complete this exercise:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将把`Banking_Marketing.csv`数据集加载到pandas的DataFrame中，并处理缺失数据。我们将使用填补法。请按照以下步骤完成这个练习：
- en: Note
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `Banking_Marketing.csv` dataset can be found at this location: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Banking_Marketing.csv.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`Banking_Marketing.csv`数据集可以在以下位置找到：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Banking_Marketing.csv。'
- en: 'Open a Jupyter notebook and add a new cell. Load the dataset into the pandas
    DataFrame. Add the following code to do this:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter笔记本并添加一个新单元格，将数据集加载到pandas的DataFrame中。添加以下代码来实现这一点：
- en: '[PRE18]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Impute the numerical data of the `age` column with its mean. To do so, first
    find the mean of the `age` column using the `mean()` function of pandas, and then
    print it:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`age`列的均值填补缺失的数值数据。为此，首先使用pandas的`mean()`函数找到`age`列的均值，然后打印出来：
- en: '[PRE19]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The preceding code generates the following output:'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上面的代码会生成以下输出：
- en: '![Figure 1.18: Mean of the age column](img/C13322_01_18.jpg)'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.18：年龄列的均值](img/C13322_01_18.jpg)'
- en: 'Figure 1.18: Mean of the age column'
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.18：年龄列的均值
- en: 'Once this is done, impute the missing data with its mean using the `fillna()`
    function. This can be done with the following code:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦完成，使用`fillna()`函数用均值填补缺失数据。可以通过以下代码来完成：
- en: '[PRE20]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now we impute the numerical data of the duration column with its median. To
    do so, first find the median of the duration column using the `median()` function
    of the pandas. Add the following code to do so:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们用持续时间列的中位数填补缺失的数值数据。为此，首先使用pandas的`median()`函数找到持续时间列的中位数。添加以下代码来实现这一点：
- en: '[PRE21]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![Figure 1.19: Median of the duration](img/C13322_01_19.jpg)'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.19：持续时间的中位数](img/C13322_01_19.jpg)'
- en: 'Figure 1.19: Median of the duration'
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.19：持续时间的中位数
- en: Impute the missing data of the duration with its median using the `fillna()`
    function.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fillna()`函数，用持续时间的中位数填补缺失数据。
- en: '[PRE22]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Impute the categorical data of the contact column with its mode. To do so,
    first, find the mode of the contact column using the `mode()` function of pandas.
    Add the following code to do this:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`mode()`函数，将`contact`列的类别数据填补为其众数。为此，首先使用pandas的`mode()`函数找到`contact`列的众数。添加以下代码来实现这一点：
- en: '[PRE23]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](img/C13322_01_20.jpg)'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C13322_01_20.jpg)'
- en: 'Figure 1.20: Mode of the contact'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.20：联系方式的众数
- en: 'Impute the missing data of the contact column with its mode using the `fillna()`
    function. Add the following code to do this:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fillna()`函数用众数填充联系方式列的缺失数据。添加以下代码来实现：
- en: '[PRE24]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Unlike mean and median, there may be more than one mode in a column. So, we
    just take the first mode with index 0.
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与均值和中位数不同，列中可能有多个众数。因此，我们只取第一个众数，其索引为0。
- en: You have successfully imputed the missing data in different ways and made the
    data complete and clean.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地以不同的方式填充了缺失数据，并使数据完整且清洁。
- en: Another part of data cleaning is dealing with outliers, which will be discussed
    in the next section.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清理的另一个部分是处理异常值，我们将在下一节讨论。
- en: '**Outliers**'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**异常值**'
- en: 'Outliers are values that are very large or very small with respect to the distribution
    of the other data. We can only find outliers in numerical data. Box plots are
    one good way to find the outliers in a dataset, as you can see in the following
    figure:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值是指与其他数据的分布相比，非常大或非常小的值。我们只能在数值数据中找到异常值。箱型图是一种有效的识别数据集异常值的方法，如下图所示：
- en: '![Figure 1.21: Sample of outliers in a box plot](img/C13322_01.21.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图1.21：箱型图中的异常值示例](img/C13322_01.21.jpg)'
- en: 'Figure 1.21: Sample of outliers in a box plot'
  id: totrans-222
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.21：箱型图中的异常值示例
- en: Note
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: An outlier is not always bad data! With the help of business understanding and
    client interaction, you can discern whether to remove or retain the outlier.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值不一定是坏数据！借助商业理解和客户互动，你可以判断是否要移除或保留异常值。
- en: 'Let''s learn how to find outliers using a simple example. Consider a sample
    dataset of temperatures from a place at different times:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个简单的例子来学习如何查找异常值。考虑一个地方在不同时间的温度样本数据集：
- en: '[PRE25]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can now do the following:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以执行以下操作：
- en: 'First, we''ll sort the data:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们对数据进行排序：
- en: '[PRE26]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Next, we'll calculate the median (Q2). The median is the middle data after sorting.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们计算中位数（Q2）。中位数是排序后的中间数据。
- en: Here, the middle terms are 70 and 71 after sorting the list.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，排序后中间的项是70和71。
- en: The median is *(70 + 71) / 2 = 70.5*
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 中位数是*(70 + 71) / 2 = 70.5*
- en: Then we'll calculate the lower quartile (Q1). Q1 is the middle value (median)
    of the first half of the dataset.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们将计算下四分位数（Q1）。Q1是数据集前半部分的中位数。
- en: First half of the data = `60, 69, 70, 70, 70, 70`
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据的前半部分 = `60, 69, 70, 70, 70, 70`
- en: Points 3 and 4 of the bottom 6 are both equal to 70.
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下6个数据点的第3和第4个都等于70。
- en: The average is *(70 + 70) / 2 = 70*
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均值是*(70 + 70) / 2 = 70*
- en: Q1 = 70
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Q1 = 70
- en: Then we calculate the upper quartile (Q3).
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后计算上四分位数（Q3）。
- en: Q3 is the middle value (median) of the second half of the dataset.
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Q3是数据集后半部分的中位数。
- en: Second half of the data = `71, 71, 72, 72, 90, 320`
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据的后半部分 = `71, 71, 72, 72, 90, 320`
- en: Points 3 and 4 of the upper 6 are 72 and 72.
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上6个数据点的第3和第4个是72和72。
- en: The average is *(72 + 72) / 2 = 72*
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均值是*(72 + 72) / 2 = 72*
- en: Q3 = 72
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Q3 = 72
- en: Then we find the interquartile range (IQR).
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们找出四分位距（IQR）。
- en: IQR = Q3 – Q1 = 72 – 70
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: IQR = Q3 – Q1 = 72 – 70
- en: IQR = 2
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: IQR = 2
- en: Next, we find the upper and lower fences.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们找出上限和下限。
- en: Lower fence = Q1 – 1.5 (IQR) = 70 – 1.5(2) = 67
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下限 = Q1 – 1.5 (IQR) = 70 – 1.5(2) = 67
- en: Upper fence = Q3 + 1.5 (IQR) = 71.5 + 1.5(2) = 74.5
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上限 = Q3 + 1.5 (IQR) = 71.5 + 1.5(2) = 74.5
- en: Boundaries of our fences = 67 and 74.5
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的边界值 = 67 和 74.5
- en: Any data points lower than the lower fence and greater than the upper fence
    are outliers. Thus, the outliers from our example are 60, 90 and 320.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 任何低于下限并大于上限的数据点都是异常值。因此，我们例子中的异常值是60、90和320。
- en: 'Exercise 4: Finding and Removing Outliers in Data'
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习4：查找和移除数据中的异常值
- en: 'In this exercise, we will be loading the `german_credit_data.csv` dataset into
    the pandas DataFrame and removing the outliers. The dataset contains 1,000 entries
    with 20 categorial/symbolic attributes prepared by Prof. Hofmann. In this dataset,
    each entry represents a person who takes credit from a bank. Each person is classified
    as a good or bad credit risk according to the set of attributes. Follow these
    steps to complete this exercise:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将加载`german_credit_data.csv`数据集到pandas DataFrame中，并去除异常值。该数据集包含1,000条记录和20个分类/符号属性，由Hofmann教授准备。每条记录代表一个从银行借贷的人。根据这些属性，每个人被分类为良好或不良信用风险。按照以下步骤完成本练习：
- en: Note
  id: totrans-254
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The link to the `german_credit_data.csv` dataset can be found here: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/german_credit_data.csv.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`german_credit_data.csv` 数据集的链接可以在这里找到：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/german_credit_data.csv。'
- en: 'Open a Jupyter notebook and add a new cell. Write the following code to import
    the necessary libraries: pandas, NumPy, matplotlib, and seaborn. Fetch the dataset
    and load it into the pandas DataFrame. Add the following code to do this:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 Jupyter 笔记本并添加一个新单元格。编写以下代码来导入必要的库：pandas、NumPy、matplotlib 和 seaborn。获取数据集并将其加载到
    pandas DataFrame 中。添加以下代码来实现：
- en: '[PRE27]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In the preceding code, `%matplotlib inline` is a magic function that is essential
    if we want the plot to be visible in the notebook.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的代码中，`%matplotlib inline` 是一个魔法函数，如果我们希望图表在笔记本中可见，它是必不可少的。
- en: 'This dataset contains an `Age` column. Let''s plot a boxplot of the `Age` column.
    To do so, use the `boxplot()` function from the seaborn library:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个数据集包含一个 `Age` 列。让我们绘制 `Age` 列的箱型图。为此，使用 seaborn 库中的 `boxplot()` 函数：
- en: '[PRE28]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The preceding code generates the following output:'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![Figure 1.22: A box plot of the Age column](img/C13322_01_22.jpg)'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.22：年龄列的箱型图](img/C13322_01_22.jpg)'
- en: 'Figure 1.22: A box plot of the Age column'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.22：年龄列的箱型图
- en: We can see that some data points are outliers in the boxplot.
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以在箱型图中看到一些数据点是异常值。
- en: 'The boxplot uses the IQR method to display the data and the outliers (the shape
    of the data). But in order to print an outlier, we use a mathematical formula
    to retrieve it. Add the following code to find the outliers of the `Age` column
    using the IQR method:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 箱型图使用 IQR 方法来显示数据和异常值（数据的形状）。但是，为了打印出异常值，我们使用数学公式来检索它。添加以下代码来使用 IQR 方法查找 `Age`
    列的异常值：
- en: '[PRE29]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In the preceding code, Q1 is the first quartile and Q3 is the third quartile.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的代码中，Q1 是第一四分位数，Q3 是第三四分位数。
- en: 'Now we find the upper fence and lower fence by adding the following code, and
    print all the data above the upper fence and below the lower fence. Add the following
    code to do this:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在通过添加以下代码，我们可以找到上边界和下边界，并打印所有高于上边界和低于下边界的数据。添加以下代码来实现：
- en: '[PRE30]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To print all the data above the upper fence and below the lower fence, add
    the following code:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了打印所有高于上边界和低于下边界的数据，添加以下代码：
- en: '[PRE31]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The preceding code generates the following output:'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![Figure 1.23: Outlier data based on the Age column](img/C13322_01_23.jpg)'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.23：基于年龄列的异常数据](img/C13322_01_23.jpg)'
- en: 'Figure 1.23: Outlier data based on the Age column'
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.23：基于年龄列的异常数据
- en: 'Filter out the outlier data and print only the potential data. To do so, just
    negate the preceding result using the `~` operator:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 筛选掉异常数据并只打印潜在数据。为此，只需使用 `~` 运算符否定前面的结果：
- en: '[PRE32]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The preceding code generates the following output:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![Figure 1.24: Potential data based on the Age column](img/C13322_01_24.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.24：基于年龄列的潜在数据](img/C13322_01_24.jpg)'
- en: 'Figure 1.24: Potential data based on the Age column'
  id: totrans-279
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.24：基于年龄列的潜在数据
- en: You have successfully found the outliers using the IQR. In the next section,
    we will explore another method of pre-processing called data integration.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地使用 IQR 找到了异常值。在接下来的部分，我们将探讨另一种预处理方法——数据集成。
- en: Data Integration
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集成
- en: So far, we've made sure to remove the impurities in data and make it clean.
    Now, the next step is to combine data from different sources to get a unified
    structure with more meaningful and valuable information. This is mostly used if
    the data is segregated into different sources. To make it simple, let's assume
    we have data in CSV format in different places, all talking about the same scenario.
    Say we have some data about an employee in a database. We can't expect all the
    data about the employee to reside in the same table. It's possible that the employee's
    personal data will be located in one table, the employee's project history will
    be in a second table, the employee's time-in and time-out details will be in another
    table, and so on. So, if we want to do some analysis about the employee, we need
    to get all the employee data in one common place. This process of bringing data
    together in one place is called data integration. To do data integration, we can
    merge multiple pandas DataFrames using the `merge` function.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经确保移除数据中的杂质，使其变得干净。现在，下一步是将来自不同来源的数据合并，以获得一个统一的结构，包含更有意义和有价值的信息。如果数据被拆分到不同的来源，这通常是必需的。为了简单起见，假设我们有一些
    CSV 格式的数据，存放在不同的地方，所有这些数据都描述的是相同的场景。比如，我们有一些关于某个员工的数据存储在一个数据库中。我们不能指望所有关于员工的数据都存在同一个表格中。可能员工的个人信息在一个表格中，员工的项目历史在第二个表格中，员工的考勤数据在另一个表格中，等等。因此，如果我们想对员工进行分析，我们需要将所有员工数据整合到一个共同的地方。这一过程被称为数据整合。为了进行数据整合，我们可以使用
    `merge` 函数合并多个 pandas DataFrame。
- en: Let's solve an exercise based on data integration to get a clear understanding
    of it.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个数据整合的练习来清晰地理解它。
- en: 'Exercise 5: Integrating Data'
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 5：数据整合
- en: 'In this exercise, we''ll merge the details of students from two datasets, namely
    `student.csv` and `marks.csv`. The `student` dataset contains columns such as
    `Age`, `Gender`, `Grade`, and `Employed`. The `marks.csv` dataset contains columns
    such as `Mark` and `City`. The `Student_id` column is common between the two datasets.
    Follow these steps to complete this exercise:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将合并来自两个数据集（`student.csv` 和 `marks.csv`）的学生信息。`student` 数据集包含诸如 `Age`（年龄）、`Gender`（性别）、`Grade`（年级）和
    `Employed`（是否就业）等列。`marks.csv` 数据集包含 `Mark`（分数）和 `City`（城市）等列。`Student_id` 列在两个数据集之间是共同的。按照以下步骤完成此练习：
- en: Note
  id: totrans-286
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `student.csv` dataset can be found at this location: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/student.csv.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`student.csv` 数据集可以在此位置找到：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/student.csv。'
- en: 'The `marks.csv` dataset can be found at this location: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/mark.csv.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '`marks.csv` 数据集可以在此位置找到：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/mark.csv。'
- en: 'Open a Jupyter notebook and add a new cell. Write the following code to import
    pandas and load the `student.csv` and `marks.csv` datasets into the `df1` and
    `df2` pandas DataFrames:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 Jupyter notebook 并添加一个新单元格。编写以下代码以导入 pandas 并将 `student.csv` 和 `marks.csv`
    数据集加载到 `df1` 和 `df2` pandas DataFrame 中：
- en: '[PRE33]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To print the first five rows of the first DataFrame, add the following code:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要打印第一个 DataFrame 的前五行，请添加以下代码：
- en: '[PRE34]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The preceding code generates the following output:'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![Figure 1.25: The first five rows of the first DataFrame](img/C13322_01_25.jpg)'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.25：第一个 DataFrame 的前五行](img/C13322_01_25.jpg)'
- en: 'Figure 1.25: The first five rows of the first DataFrame'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.25：第一个 DataFrame 的前五行
- en: 'To print the first five rows of the second DataFrame, add the following code:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要打印第二个 DataFrame 的前五行，请添加以下代码：
- en: '[PRE35]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The preceding code generates the following output:'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![Figure 1.26: The first five rows of the second DataFrame](img/C13322_01_26.jpg)'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.26：第二个 DataFrame 的前五行](img/C13322_01_26.jpg)'
- en: 'Figure 1.26: The first five rows of the second DataFrame'
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.26：第二个 DataFrame 的前五行
- en: '`Student_id` is common to both datasets. Perform data integration on both the
    DataFrames with respect to the `Student_id` column using the `pd.merge()` function,
    and then print the first 10 values of the new DataFrame:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Student_id` 在两个数据集中都是共同的。使用 `pd.merge()` 函数对两个 DataFrame 进行数据整合，基于 `Student_id`
    列，然后打印新 DataFrame 的前 10 个值：'
- en: '[PRE36]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![Figure 1.27: First 10 rows of the merged DataFrame](img/C13322_01_27.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.27：合并后的 DataFrame 的前 10 行](img/C13322_01_27.jpg)'
- en: 'Figure 1.27: First 10 rows of the merged DataFrame'
  id: totrans-304
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.27：合并后的 DataFrame 的前 10 行
- en: Here, the data of the `df1` DataFrame is merged with the data of the `df2` DataFrame.
    The merged data is stored inside a new DataFrame called `df`.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`df1` 数据框的数据与 `df2` 数据框的数据进行了合并。合并后的数据存储在一个名为 `df` 的新数据框中。
- en: We have now learned how to perform data integration. In the next section, we'll
    explore another pre-processing task, data transformation.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经学习了如何进行数据集成。在下一部分中，我们将探索另一个预处理任务——数据转换。
- en: Data Transformation
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据转换
- en: Previously, we saw how we can combine data from different sources into a unified
    dataframe. Now, we have a lot of columns that have different types of data. Our
    goal is to transform the data into a machine-learning-digestible format. All machine
    learning algorithms are based on mathematics. So, we need to convert all the columns
    into numerical format. Before that, let's see all the different types of data
    we have.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们已经看到如何将来自不同来源的数据合并成一个统一的数据框。现在，我们有很多列，包含不同类型的数据。我们的目标是将数据转换为机器学习可以处理的格式。所有机器学习算法都是基于数学的。因此，我们需要将所有列转换为数值格式。在此之前，让我们看一下我们所拥有的不同类型的数据。
- en: 'Taking a broader perspective, data is classified into numerical and categorical
    data:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 从更广泛的角度来看，数据可以分为数值型数据和分类数据：
- en: '**Numerical**: As the name suggests, this is numeric data that is quantifiable.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数值型**：顾名思义，这些是可以量化的数字数据。'
- en: '**Categorical**: The data is a string or non-numeric data that is qualitative
    in nature.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类数据**：数据是字符串或非数值型数据，具有定性特征。'
- en: 'Numerical data is further divided into the following:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 数值型数据进一步分为以下几类：
- en: '**Discrete**: To explain in simple terms, any numerical data that is countable
    is called discrete, for example, the number of people in a family or the number
    of students in a class. Discrete data can only take certain values (such as 1,
    2, 3, 4, etc).'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离散型**：简单来说，任何可以计数的数值数据称为离散型数据，例如家庭中的人数或班级中的学生人数。离散型数据只能取某些特定值（如 1、2、3、4 等）。'
- en: '**Continuous**: Any numerical data that is measurable is called continuous,
    for example, the height of a person or the time taken to reach a destination.
    Continuous data can take virtually any value (for example, 1.25, 3.8888, and 77.1276).'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**连续型**：任何可测量的数值数据都称为连续型数据，例如一个人的身高或到达某地所花费的时间。连续型数据可以取几乎任何值（例如，1.25、3.8888
    和 77.1276）。'
- en: 'Categorical data is further divided into the following:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 分类数据进一步分为以下几类：
- en: '**Ordered**: Any categorical data that has some order associated with it is
    called ordered categorical data, for example, movie ratings (excellent, good,
    bad, worst) and feedback (happy, not bad, bad). You can think of ordered data
    as being something you could mark on a scale.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有序型**：任何有顺序的分类数据称为有序型分类数据，例如电影评分（优秀、好、差、最差）和反馈（满意、不差、差）。你可以将有序数据看作是可以在一个量表上标记的内容。'
- en: '**Nominal**: Any categorical data that has no order is called nominal categorical
    data. Examples include gender and country.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**名义型**：任何没有顺序的分类数据称为名义型分类数据。例如，性别和国家。'
- en: From these different types of data, we will focus on categorical data. In the
    next section, we'll discuss how to handle categorical data.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些不同类型的数据中，我们将重点讨论分类数据。在下一部分中，我们将讨论如何处理分类数据。
- en: Handling Categorical Data
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理分类数据
- en: 'There are some algorithms that can work well with categorical data, such as
    decision trees. But most machine learning algorithms cannot operate directly with
    categorical data. These algorithms require the input and output both to be in
    numerical form. If the output to be predicted is categorical, then after prediction
    we convert them back to categorical data from numerical data. Let''s discuss some
    key challenges that we face while dealing with categorical data:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 有些算法可以很好地处理分类数据，例如决策树。但大多数机器学习算法不能直接处理分类数据。这些算法要求输入和输出都必须是数值型的。如果需要预测的输出是分类数据，那么在预测之后，我们将其从数值数据转换回分类数据。让我们讨论一下处理分类数据时面临的一些关键挑战：
- en: '**High cardinality**: Cardinality means uniqueness in data. The data column,
    in this case, will have a lot of different values. A good example is User ID –
    in a table of 500 different users, the User ID column would have 500 unique values.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高基数**：基数指的是数据的唯一性。在这种情况下，数据列将包含大量不同的值。一个很好的例子是用户 ID——在一个包含 500 个不同用户的表格中，用户
    ID 列将有 500 个独特的值。'
- en: '**Rare occurrences**: These data columns might have variables that occur very
    rarely and therefore would not be significant enough to have an impact on the
    model.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稀有出现**：这些数据列可能包含非常少见的变量，因此它们对模型的影响不足。'
- en: '**Frequent occurrences**: There might be a category in the data columns that
    occurs many times with very low variance, which would fail to make an impact on
    the model.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**频繁出现**：数据列中可能存在一个类别，它出现的次数很多，但方差很小，这样的类别对模型没有影响。'
- en: '**Won''t fit**: This categorical data, left unprocessed, won''t fit our model.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无法适应**：这些未处理的类别数据无法适应我们的模型。'
- en: '**Encoding**'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '**编码**'
- en: To address the problems associated with categorical data, we can use encoding.
    This is the process by which we convert a categorical variable into a numerical
    form. Here, we will look at three simple methods of encoding categorical data.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决与类别数据相关的问题，我们可以使用编码。这是将类别变量转换为数字形式的过程。在这里，我们将介绍三种简单的编码类别数据的方法。
- en: '**Replacing**'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '**替换**'
- en: This is a technique in which we replace the categorical data with a number.
    This is a simple replacement and does not involve much logical processing. Let's
    look at an exercise to get a better idea of this.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种将类别数据替换为数字的技术。这是一个简单的替换过程，不涉及太多逻辑处理。让我们通过一个练习更好地理解这一点。
- en: 'Exercise 6: Simple Replacement of Categorical Data with a Number'
  id: totrans-329
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习6：将类别数据简单替换为数字
- en: 'In this exercise, we will use the `student` dataset that we saw earlier. We
    will load the data into a pandas dataframe and simply replace all the categorical
    data with numbers. Follow these steps to complete this exercise:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用前面看到的`student`数据集。我们将数据加载到pandas数据框中，并将所有类别数据简单地替换为数字。按照以下步骤完成此练习：
- en: Note
  id: totrans-331
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `student` dataset can be found at this location: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/student.csv.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '`student`数据集可以在以下位置找到：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/student.csv。'
- en: 'Open a Jupyter notebook and add a new cell. Write the following code to import
    pandas and then load the dataset into the pandas dataframe:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter notebook并添加一个新单元格。写入以下代码以导入pandas，并将数据集加载到pandas数据框中：
- en: '[PRE37]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Find the categorical column and separate it out with a different dataframe.
    To do so, use the `select_dtypes()` function from pandas:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到类别列，并将其与其他数据分开。为此，使用pandas中的`select_dtypes()`函数：
- en: '[PRE38]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The preceding code generates the following output:'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成的输出如下：
- en: '![Figure 1.28: Categorical columns of the dataframe](img/C13322_01_28.jpg)'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.28：数据框的类别列](img/C13322_01_28.jpg)'
- en: 'Figure 1.28: Categorical columns of the dataframe'
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.28：数据框的类别列
- en: 'Find the distinct unique values in the `Grade` column. To do so, use the `unique()`
    function from pandas with the column name:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到`Grade`列中的不同唯一值。为此，使用pandas中的`unique()`函数，指定列名：
- en: '[PRE39]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The preceding code generates the following output:'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成的输出如下：
- en: '![Figure 1.29: Unique values in the Grade column](img/C13322_01_29.jpg)'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.29：Grade列中的唯一值](img/C13322_01_29.jpg)'
- en: 'Figure 1.29: Unique values in the Grade column'
  id: totrans-344
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.29：Grade列中的唯一值
- en: 'Find the frequency distribution of each categorical column. To do so, use the
    `value_counts()` function on each column. This function returns the counts of
    unique values in an object:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到每个类别列的频率分布。为此，使用`value_counts()`函数对每一列进行处理。此函数返回对象中唯一值的计数：
- en: '[PRE40]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output of this step is as follows:'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这一步的输出结果如下：
- en: '![Figure 1.30: Total count of each unique value in the Grade column'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.30：Grade列中每个唯一值的总计数](img/C13322_01_30.jpg)'
- en: '](img/C13322_01_30.jpg)'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_30.jpg)'
- en: 'Figure 1.30: Total count of each unique value in the Grade column'
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.30：Grade列中每个唯一值的总计数
- en: 'For the `Gender` column, write the following code:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`Gender`列，写入以下代码：
- en: '[PRE41]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The output of this code is as follows:'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码的输出结果如下：
- en: '![Figure 1.31: Total count of each unique value in the Gender column'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.31：Gender列中每个唯一值的总计数](img/C13322_01_31.jpg)'
- en: '](img/C13322_01_31.jpg)'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_31.jpg)'
- en: 'Figure 1.31: Total count of each unique value in the Gender column'
  id: totrans-356
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.31：Gender列中每个唯一值的总计数
- en: 'Similarly, for the `Employed` column, write the following code:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似地，对于`Employed`列，写入以下代码：
- en: '[PRE42]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The output of this code is as follows:'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码的输出结果如下：
- en: '![Figure 1.32: Total count of each unique value in the Employed column'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.32：Employed列中每个唯一值的总计数](img/C13322_01_32.jpg)'
- en: '](img/C13322_01_32.jpg)'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_32.jpg)'
- en: 'Figure 1.32: Total count of each unique value in the Employed column'
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.32：Employed列中每个唯一值的总计数
- en: 'Replace the entries in the `Grade` column. Replace `1st class` with `1`, `2nd
    class` with `2`, and `3rd class` with `3`. To do so, use the `replace()` function:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 替换`Grade`列中的条目。将`1st class`替换为`1`，`2nd class`替换为`2`，`3rd class`替换为`3`。为此，使用`replace()`函数：
- en: '[PRE43]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Replace the entries in the `Gender` column. Replace `Male` with `0` and `Female`
    with `1`. To do so, use the `replace()` function:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 替换`Gender`列中的条目。将`Male`替换为`0`，将`Female`替换为`1`。为此，使用`replace()`函数：
- en: '[PRE44]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Replace the entries in the `Employed` column. Replace `no` with `0` and `yes`
    with `1`. To do so, use the `replace()` function:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 替换`Employed`列中的条目。将`no`替换为`0`，将`yes`替换为`1`。为此，使用`replace()`函数：
- en: '[PRE45]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Once all the replacements for three columns are done, we need to print the
    dataframe. Add the following code:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦完成三列的所有替换操作，我们需要打印数据框。添加以下代码：
- en: '[PRE46]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![Figure 1.33: Numerical data after replacement'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.33：替换后的数值数据'
- en: '](img/C13322_01_33.jpg)'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_01_33.jpg)'
- en: 'Figure 1.33: Numerical data after replacement'
  id: totrans-373
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.33：替换后的数值数据
- en: You have successfully converted the categorical data to numerical data using
    a simple manual replacement method. We will now move on to look at another method
    of encoding categorical data.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地使用简单的手动替换方法将分类数据转换为数值数据。接下来我们将看看另一种编码分类数据的方法。
- en: '**Label Encoding**'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '**标签编码**'
- en: This is a technique in which we replace each value in a categorical column with
    numbers from 0 to N-1\. For example, say we've got a list of employee names in
    a column. After performing label encoding, each employee name will be assigned
    a numeric label. But this might not be suitable for all cases because the model
    might consider numeric values to be weights assigned to the data. Label encoding
    is the best method to use for ordinal data. The scikit-learn library provides
    `LabelEncoder()`, which helps with label encoding. Let's look at an exercise in
    the next section.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种技术，其中我们将分类列中的每个值替换为从0到N-1的数字。例如，假设我们在一列中有一份员工名字列表。进行标签编码后，每个员工名字将分配一个数值标签。但这对于所有情况可能不适用，因为模型可能会将数值视为分配给数据的权重。标签编码是处理有序数据的最佳方法。scikit-learn库提供了`LabelEncoder()`，可以帮助进行标签编码。接下来我们将在下一节中查看一个练习。
- en: 'Exercise 7: Converting Categorical Data to Numerical Data Using Label Encoding'
  id: totrans-377
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 7：使用标签编码将分类数据转换为数值数据
- en: 'In this exercise, we will load the `Banking_Marketing.csv` dataset into a pandas
    dataframe and convert categorical data to numeric data using label encoding. Follow
    these steps to complete this exercise:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将把`Banking_Marketing.csv`数据集加载到pandas数据框中，并使用标签编码将分类数据转换为数值数据。请按照以下步骤完成此练习：
- en: Note
  id: totrans-379
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `Banking_Marketing.csv` dataset can be found here: https://github.com/TrainingByPackt/Master-Data-Science-with-Python/blob/master/Chapter%201/Data/Banking_Marketing.csv.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '`Banking_Marketing.csv`数据集可以在以下位置找到：https://github.com/TrainingByPackt/Master-Data-Science-with-Python/blob/master/Chapter%201/Data/Banking_Marketing.csv。'
- en: 'Open a Jupyter notebook and add a new cell. Write the code to import pandas
    and load the dataset into the pandas dataframe:'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter笔记本并添加一个新单元格。编写代码导入pandas并将数据集加载到pandas数据框中：
- en: '[PRE47]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Before doing the encoding, remove all the missing data. To do so, use the `dropna()`
    function:'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在进行编码之前，删除所有缺失的数据。为此，使用`dropna()`函数：
- en: '[PRE48]'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Select all the columns that are not numeric using the following code:'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码选择所有非数值类型的列：
- en: '[PRE49]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'To understand how the selection looks, refer to the following screenshot:'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要了解选择的内容，请参见以下截图：
- en: '![Figure 1.34: Non-numeric columns of the dataframe'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.34：数据框中的非数值列'
- en: '](img/C13322_01_34.jpg)'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_34.jpg)'
- en: 'Figure 1.34: Non-numeric columns of the dataframe'
  id: totrans-390
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.34：数据框中的非数值列
- en: 'Print the first five rows of the new dataframe. Add the following code to do
    this:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印新数据框的前五行。添加以下代码来执行此操作：
- en: '[PRE50]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The preceding code generates the following output:'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.35: Non-numeric values for the columns'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.35：列中的非数值类型'
- en: '](img/C13322_01_35.jpg)'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_35.jpg)'
- en: 'Figure 1.35: Non-numeric values for the columns'
  id: totrans-396
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.35：列中的非数值类型
- en: 'Iterate through this `category` column and convert it to numeric data using
    `LabelEncoder()`. To do so, import the `sklearn.preprocessing` package and use
    the `LabelEncoder()` class to transform the data:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历`category`列，并使用`LabelEncoder()`将其转换为数值数据。为此，导入`sklearn.preprocessing`包并使用`LabelEncoder()`类来转换数据：
- en: '[PRE51]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The preceding code generates the following output:'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.36: Values of non-numeric columns converted into numeric form'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.36：非数值列转换为数值形式的值'
- en: '](img/C13322_01_36.jpg)'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_01_36.jpg)'
- en: 'Figure 1.36: Values of non-numeric columns converted into numeric form'
  id: totrans-402
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.36：非数值列转换为数值形式
- en: In the preceding screenshot, we can see that all the values have been converted
    from categorical to numerical. Here, the original values have been transformed
    and replaced with the newly encoded data.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的截图中，我们可以看到所有的值已经从类别数据转换为数值数据。这里，原始值已被转换并替换为新编码的数据。
- en: 'You have successfully converted categorical data to numerical data using the
    `LabelEncoder` method. In the next section, we''ll explore another type of encoding:
    one-hot encoding.'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功使用 `LabelEncoder` 方法将类别数据转换为数值数据。在接下来的章节中，我们将探讨另一种编码方法：独热编码。
- en: '**One-Hot Encoding**'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '**独热编码**'
- en: In label encoding, categorical data is converted to numerical data, and the
    values are assigned labels (such as 1, 2, and 3). Predictive models that use this
    numerical data for analysis might sometimes mistake these labels for some kind
    of order (for example, a model might think that a label of 3 is "better" than
    a label of 1, which is incorrect). In order to avoid this confusion, we can use
    one-hot encoding. Here, the label-encoded data is further divided into n number
    of columns. Here, n denotes the total number of unique labels generated while
    performing label encoding. For example, say that three new labels are generated
    through label encoding. Then, while performing one-hot encoding, the columns will
    be divided into three parts. So, the value of n is 3\. Let's look at an exercise
    to get further clarification.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 在标签编码中，类别数据被转换为数值数据，并为每个值分配标签（如 1、2 和 3）。使用这些数值数据进行分析的预测模型有时可能会误认为这些标签具有某种顺序（例如，模型可能认为标签
    3 比标签 1 "更好"，这是错误的）。为了避免这种混淆，我们可以使用独热编码。在这里，标签编码的数据进一步被分成 n 列，其中 n 表示标签编码时生成的唯一标签的总数。例如，假设通过标签编码生成了三个新标签。那么，在执行独热编码时，列将分为三部分。所以，n
    的值为 3。让我们通过一个练习来进一步澄清。
- en: 'Exercise 8: Converting Categorical Data to Numerical Data Using One-Hot Encoding'
  id: totrans-407
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 8：使用独热编码将类别数据转换为数值数据
- en: 'In this exercise, we will load the `Banking_Marketing.csv` dataset into a pandas
    dataframe and convert the categorical data into numeric data using one-hot encoding.
    Follow these steps to complete this exercise:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将把 `Banking_Marketing.csv` 数据集加载到 pandas 数据框中，并使用独热编码将类别数据转换为数值数据。按照以下步骤完成此练习：
- en: Note
  id: totrans-409
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `Banking_Marketing` dataset can be found here: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Banking_Marketing.csv.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '`Banking_Marketing` 数据集可以在这里找到：[https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Banking_Marketing.csv](https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Banking_Marketing.csv)。'
- en: 'Open a Jupyter notebook and add a new cell. Write the code to import pandas
    and load the dataset into a pandas dataframe:'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Jupyter 笔记本并添加一个新单元格。编写代码导入 pandas 并将数据集加载到 pandas 数据框中：
- en: '[PRE52]'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Before doing the encoding, remove all the missing data. To do so, use the `dropna()`
    function:'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在进行编码之前，移除所有缺失数据。为此，使用 `dropna()` 函数：
- en: '[PRE53]'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Select all the columns that are not numeric using the following code:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码选择所有非数值型的列：
- en: '[PRE54]'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The preceding code generates the following output:'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![Figure 1.37: Non-numeric columns of the dataframe'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.37：数据框的非数值列'
- en: '](img/C13322_01_37.jpg)'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_37.jpg)'
- en: 'Figure 1.37: Non-numeric columns of the dataframe'
  id: totrans-420
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.37：数据框的非数值列
- en: 'Print the first five rows of the new dataframe. Add the following code to do
    this:'
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印新数据框的前五行。添加以下代码来实现：
- en: '[PRE55]'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The preceding code generates the following output:'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![Figure 1.38: Non-numeric values for the columns'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.38：列的非数值值'
- en: '](img/C13322_01_38.jpg)'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_38.jpg)'
- en: 'Figure 1.38: Non-numeric values for the columns'
  id: totrans-426
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.38：列的非数值值
- en: 'Iterate through these category columns and convert them to numeric data using
    `OneHotEncoder`. To do so, import the `sklearn.preprocessing` package and avail
    yourself of the `OneHotEncoder()` class do the transformation. Before performing
    one-hot encoding, we need to perform label encoding:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迭代这些类别列，并使用 `OneHotEncoder` 将其转换为数值数据。为此，导入 `sklearn.preprocessing` 包，并使用 `OneHotEncoder()`
    类进行转换。在执行独热编码之前，我们需要先进行标签编码：
- en: '[PRE56]'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The preceding code generates the following output:'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![Figure 1.39: Values of non-numeric columns converted into numeric data](img/C13322_01_39.jpg)'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.39：非数值列转换为数值数据](img/C13322_01_39.jpg)'
- en: 'Figure 1.39: Values of non-numeric columns converted into numeric data'
  id: totrans-431
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.39：非数值列转换为数值数据
- en: 'Once we have performed label encoding, we execute one-hot encoding. Add the
    following code to implement this:'
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们完成了标签编码，就可以执行一热编码。添加以下代码来实现这一操作：
- en: '[PRE57]'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Now we create a new dataframe with the encoded data and print the first five
    rows. Add the following code to do this:'
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们创建一个包含编码数据的新数据框，并打印前五行。添加以下代码来实现这一操作：
- en: '[PRE58]'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The preceding code generates the following output:'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.40: Columns with one-hot encoded values'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.40：具有一热编码值的列'
- en: '](img/C13322_01_40.jpg)'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_40.jpg)'
- en: 'Figure 1.40: Columns with one-hot encoded values'
  id: totrans-439
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.40：具有一热编码值的列
- en: 'Due to one-hot encoding, the number of columns in the new dataframe has increased.
    In order to view and print all the columns created, use the `columns` attribute:'
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于一热编码，新的数据框架中的列数增加了。为了查看和打印所有创建的列，请使用`columns`属性：
- en: '[PRE59]'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The preceding code generates the following output:'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.41: List of new columns generated after one-hot encoding'
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.41：经过一热编码生成的新列列表'
- en: '](img/C13322_01_41.jpg)'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_41.jpg)'
- en: 'Figure 1.41: List of new columns generated after one-hot encoding'
  id: totrans-445
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.41：经过一热编码生成的新列列表
- en: 'For every level or category, a new column is created. In order to prefix the
    category name with the column name you can use this alternate way to create one-hot
    encoding. In order to prefix the category name with the column name, write the
    following code:'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个级别或类别，会创建一个新的列。为了在列名前加上类别名，你可以使用另一种方法来创建一热编码。为了在列名前加上类别名，可以写下以下代码：
- en: '[PRE60]'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The preceding code generates the following output:'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.42: List of new columns containing the categories'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.42：包含类别的新列列表'
- en: '](img/C13322_01_42.jpg)'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_01_42.jpg)'
- en: 'Figure 1.42: List of new columns containing the categories'
  id: totrans-451
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.42：包含类别的新列列表
- en: You have successfully converted categorical data to numerical data using the
    `OneHotEncoder` method.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地使用`OneHotEncoder`方法将分类数据转换为数值数据。
- en: We will now move onto another data preprocessing step – how to deal with a range
    of magnitudes in your data.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将进入另一个数据预处理步骤——如何处理数据中的不同量级范围。
- en: Data in Different Scales
  id: totrans-454
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不同尺度的数据
- en: In real life, values in a dataset might have a variety of different magnitudes,
    ranges, or scales. Algorithms that use distance as a parameter may not weigh all
    these in the same way. There are various data transformation techniques that are
    used to transform the features of our data so that they use the same scale, magnitude,
    or range. This ensures that each feature has an appropriate effect on a model's
    predictions.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实生活中，数据集中的值可能具有不同的量级、范围或尺度。使用距离作为参数的算法可能不会以相同的方式加权这些特征。存在多种数据转换技术，用于将数据特征转换到相同的尺度、量级或范围。这确保了每个特征对模型预测的影响是合适的。
- en: Some features in our data might have high-magnitude values (for example, annual
    salary), while others might have relatively low values (for example, the number
    of years worked at a company). Just because some data has smaller values does
    not mean it is less significant. So, to make sure our prediction does not vary
    because of different magnitudes of features in our data, we can perform feature
    scaling, standardization, or normalization (these are three similar ways of dealing
    with magnitude issues in data).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据中的某些特征可能具有较大的数值（例如，年薪），而其他特征的数值可能相对较小（例如，在公司工作的年数）。仅仅因为某些数据的值较小并不意味着它不重要。因此，为了确保我们的预测不会因为数据中特征的不同量级而有所不同，我们可以进行特征缩放、标准化或归一化（这三种方式都用于处理数据中的量级问题）。
- en: 'Exercise 9: Implementing Scaling Using the Standard Scaler Method'
  id: totrans-457
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 9：使用标准缩放器方法实现缩放
- en: 'In this exercise, we will load the `Wholesale customer''s data.csv` dataset
    into the pandas dataframe and perform scaling using the standard scaler method.
    This dataset refers to clients of a wholesale distributor. It includes the annual
    spending in monetary units on diverse product categories. Follow these steps to
    complete this exercise:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将把`Wholesale customer's data.csv`数据集加载到pandas数据框中，并使用标准缩放器方法进行缩放。该数据集指的是某批发分销商的客户信息，包含了在不同产品类别上每年花费的货币数额。按照以下步骤完成本练习：
- en: Note
  id: totrans-459
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `Wholesale customer` dataset can be found here: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Wholesale%20customers%20data.csv.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '`Wholesale customer`数据集可以在此找到：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Wholesale%20customers%20data.csv。'
- en: 'Open a Jupyter notebook and add a new cell. Write the code to import pandas
    and load the dataset into the pandas dataframe:'
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter笔记本并添加一个新单元格。编写代码以导入pandas并将数据集加载到pandas数据框中：
- en: '[PRE61]'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Check whether there is any missing data. If there is, drop the missing data:'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查是否有任何缺失数据。如果有，删除缺失数据：
- en: '[PRE62]'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The preceding code generates the following output:'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.43: Different columns of the dataframe'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.43：数据框的不同列'
- en: '](img/C13322_01_43.jpg)'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_43.jpg)'
- en: 'Figure 1.43: Different columns of the dataframe'
  id: totrans-468
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.43：数据框的不同列
- en: As we can see, there are eight columns present in the dataframe, all of type
    `int64`. Since the null value is `False`, it means there are no null values present
    in any of the columns. Thus, there is no need to use the `dropna()` function.
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如我们所见，数据框中有八列，都是`int64`类型。由于空值为`False`，这意味着在任何列中都没有空值。因此，无需使用`dropna()`函数。
- en: 'Now perform standard scaling and print the first five rows of the new dataset.
    To do so, use the `StandardScaler()` class from `sklearn.preprocessing` and implement
    the `fit_transorm()` method:'
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在执行标准缩放，并打印新数据集的前五行。为此，使用`sklearn.preprocessing`中的`StandardScaler()`类，并实现`fit_transform()`方法：
- en: '[PRE63]'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The preceding code generates the following output:'
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.44: Data of the features scaled into a uniform unit'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.44：特征数据缩放为统一单位'
- en: '](img/C13322_01_44.jpg)'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_01_44.jpg)'
- en: 'Figure 1.44: Data of the features scaled into a uniform unit'
  id: totrans-475
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.44：特征数据缩放为统一单位
- en: Using the `StandardScaler` method, we have scaled the data into a uniform unit
    over all the columns. As you can see in the preceding table, the values of all
    the features have been converted into a uniform range of the same scale. Because
    of this, it becomes easier for the model to make predictions.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`StandardScaler`方法，我们已将数据缩放为所有列的统一单位。正如前面的表格所示，所有特征的值已转换为相同范围和尺度的统一值。因此，模型更容易进行预测。
- en: You have successfully scaled the data using the `StandardScaler` method. In
    the next section, we'll have a go at an exercise in which we'll implement scaling
    using the `MinMax` scaler method.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功使用`StandardScaler`方法对数据进行了缩放。在接下来的部分，我们将尝试一个练习，使用`MinMax`缩放器方法来实现数据缩放。
- en: 'Exercise 10: Implementing Scaling Using the MinMax Scaler Method'
  id: totrans-478
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 10：使用MinMax缩放器方法实现缩放
- en: 'In this exercise, we will be loading the `Wholesale customers data.csv` dataset
    into a pandas dataframe and perform scaling using the `MinMax` scaler method.
    Follow these steps to complete this exercise:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将把`Wholesale customers data.csv`数据集加载到pandas数据框中，并使用`MinMax`缩放器方法进行缩放。按照以下步骤完成此练习：
- en: Note
  id: totrans-480
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `Whole customers data.csv` dataset can be found here: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Wholesale%20customers%20data.csv.'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '`Whole customers data.csv`数据集可以在此找到：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Wholesale%20customers%20data.csv。'
- en: 'Open a Jupyter notebook and add a new cell. Write the following code to import
    the pandas library and load the dataset into a pandas dataframe:'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter笔记本并添加一个新单元格。编写以下代码以导入pandas库并将数据集加载到pandas数据框中：
- en: '[PRE64]'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Check whether there is any missing data. If there is, drop the missing data:'
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查是否有任何缺失数据。如果有，删除缺失数据：
- en: '[PRE65]'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The preceding code generates the following output:'
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.45: Different columns of the dataframe'
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.45：数据框的不同列'
- en: '](img/C13322_01_45.jpg)'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_45.jpg)'
- en: 'Figure 1.45: Different columns of the dataframe'
  id: totrans-489
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.45：数据框的不同列
- en: As we can see, there are eight columns present in the dataframe, all of type
    `int64`. Since the null value is `False`, it means there are no null values present
    in any of the columns. Thus, there is no need to use the `dropna()` function.
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如我们所见，数据框中有八列，都是`int64`类型。由于空值为`False`，这意味着在任何列中都没有空值。因此，无需使用`dropna()`函数。
- en: 'Perform `MinMax` scaling and print the initial five values of the new dataset.
    To do so, use the `MinMaxScaler()` class from `sklearn.preprocessing` and implement
    the `fit_transorm()` method. Add the following code to implement this:'
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行`MinMax`缩放，并打印新数据集的前五个值。为此，使用`sklearn.preprocessing`中的`MinMaxScaler()`类，并实现`fit_transform()`方法。添加以下代码以实现此功能：
- en: '[PRE66]'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The preceding code generates the following output:'
  id: totrans-493
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![Figure 1.46: Data of the features scaled into a uniform unit'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.46：特征数据缩放为统一单位'
- en: '](img/C13322_01_46.jpg)'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_01_46.jpg)'
- en: 'Figure 1.46: Data of the features scaled into a uniform unit'
  id: totrans-496
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.46：特征数据被缩放到统一的单位
- en: Using the `MinMaxScaler` method, we have again scaled the data into a uniform
    unit over all the columns. As you can see in the preceding table, the values of
    all the features have been converted into a uniform range of the same scale. You
    have successfully scaled the data using the `MinMaxScaler` method.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `MinMaxScaler` 方法，我们再次将所有列的数据缩放到统一的单位。正如在上述表格中所看到的，所有特征的值已经被转换为相同范围的统一尺度。你已经成功地使用
    `MinMaxScaler` 方法缩放了数据。
- en: 'In the next section, we''ll explore another pre-processing task: data discretization.'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将探讨另一个预处理任务：数据离散化。
- en: Data Discretization
  id: totrans-499
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据离散化
- en: So far, we have done the categorical data treatment using encoding and numerical
    data treatment using scaling.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经通过编码处理了类别数据，并通过缩放处理了数值数据。
- en: '**Data discretization** is the process of converting continuous data into discrete
    buckets by grouping it. Discretization is also known for easy maintainability
    of the data. Training a model with discrete data becomes faster and more effective
    than when attempting the same with continuous data. Although continuous-valued
    data contains more information, huge amounts of data can slow the model down.
    Here, discretization can help us strike a balance between both. Some famous methods
    of data discretization are **binning** and using a histogram. Although data discretization
    is useful, we need to effectively pick the range of each bucket, which is a challenge.'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据离散化**是将连续数据通过分组转换为离散桶的过程。离散化还因数据的易维护性而闻名。与使用连续数据训练模型相比，使用离散数据训练模型更加快速和有效。尽管连续值数据包含更多信息，但大量数据会拖慢模型的运行速度。在这里，离散化可以帮助我们在两者之间找到平衡。数据离散化的一些著名方法包括**分箱**和使用直方图。尽管数据离散化有用，但我们需要有效地选择每个桶的范围，这是一项挑战。'
- en: The main challenge in discretization is to choose the number of intervals or
    bins and how to decide on their width.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 离散化的主要挑战是选择区间或桶的数量，以及如何决定它们的宽度。
- en: Here we make use of a function called `pandas.cut()`. This function is useful
    to achieve the bucketing and sorting of segmented data.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们使用一个叫做 `pandas.cut()` 的函数。这个函数对于实现数据的分桶和排序非常有用。
- en: 'Exercise 11: Discretization of Continuous Data'
  id: totrans-504
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 11：连续数据的离散化
- en: 'In this exercise, we will load the `Student_bucketing.csv` dataset and perform
    bucketing. The dataset consists of student details such as `Student_id`, `Age`,
    `Grade`, `Employed`, and `marks`. Follow these steps to complete this exercise:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将加载 `Student_bucketing.csv` 数据集并执行分桶操作。该数据集包含学生的详细信息，如 `Student_id`、`Age`、`Grade`、`Employed`
    和 `marks`。按照以下步骤完成此练习：
- en: Note
  id: totrans-506
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `Student_bucketing.csv` dataset can be found here: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Student_bucketing.csv.'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '`Student_bucketing.csv` 数据集可以在这里找到：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Student_bucketing.csv。'
- en: 'Open a Jupyter notebook and add a new cell. Write the following code to import
    the required libraries and load the dataset into a pandas dataframe:'
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 Jupyter Notebook，添加一个新单元格。编写以下代码以导入所需的库并将数据集加载到 pandas 数据框中：
- en: '[PRE67]'
  id: totrans-509
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Once we load the dataframe, display the first five rows of the dataframe. Add
    the following code to do this:'
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦加载数据框，显示数据框的前五行。添加以下代码以完成此操作：
- en: '[PRE68]'
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The preceding code generates the following output:'
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![Figure 1.47: First five rows of the dataframe'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.47：数据框的前五行'
- en: '](img/C13322_01_47.jpg)'
  id: totrans-514
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_47.jpg)'
- en: 'Figure 1.47: First five rows of the dataframe'
  id: totrans-515
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.47：数据框的前五行
- en: 'Perform bucketing using the `pd.cut()` function on the `marks` column and display
    the top 10 columns. The `cut()` function takes parameters such as `x`, `bins`,
    and `labels`. Here, we have used only three parameters. Add the following code
    to implement this:'
  id: totrans-516
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pd.cut()` 函数对 `marks` 列进行分桶，并显示前 10 列。`cut()` 函数接受如 `x`、`bins` 和 `labels`
    等参数。在这里，我们只使用了三个参数。添加以下代码以实现此功能：
- en: '[PRE69]'
  id: totrans-517
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The preceding code generates the following output:'
  id: totrans-518
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![Figure 1.48: Marks column with five discrete buckets'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.48：具有五个离散桶的 `marks` 列'
- en: '](img/C13322_01_48.jpg)'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_01_48.jpg)'
- en: 'Figure 1.48: Marks column with five discrete buckets'
  id: totrans-521
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.48：具有五个离散桶的 `marks` 列
- en: 'In the preceding code, the first parameter represents an array. Here, we have
    selected the `marks` column as an array from the dataframe. `5` represents the
    number of bins to be used. As we have set bins to `5`, the labels need to be populated
    accordingly with five values: `Poor`, `Below_average`, `Average`, `Above_average`,
    and `Excellent`. In the preceding figure, we can see the whole of the continuous
    **marks** column is put into five discrete buckets. We have learned how to perform
    bucketing.'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，第一个参数表示一个数组。在这里，我们已从数据框中选择 `marks` 列作为数组。`5` 表示要使用的箱数。由于我们设置了箱数为 `5`，因此需要相应地填充标签，使用五个值：`Poor`,
    `Below_average`, `Average`, `Above_average` 和 `Excellent`。在上述图中，我们可以看到整个连续的 **marks**
    列被放入了五个离散的桶中。我们已经学会了如何进行分桶。
- en: We have now covered all the major tasks involved in pre-processing. In the next
    section, we'll look in detail at how to train and test your data.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经涵盖了所有预处理中涉及的主要任务。在下一节中，我们将详细讨论如何训练和测试您的数据。
- en: Train and Test Data
  id: totrans-524
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和测试数据
- en: Once you've pre-processed your data into a format that's ready to be used by
    your model, you need to split up your data into train and test sets. This is because
    your machine learning algorithm will use the data in the training set to learn
    what it needs to know. It will then make a prediction about the data in the test
    set, using what it has learned. You can then compare this prediction against the
    actual target variables in the test set in order to see how accurate your model
    is. The exercise in the next section will give more clarity on this.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将数据预处理为可以被模型使用的格式，您需要将数据分割为训练集和测试集。这是因为您的机器学习算法将使用训练集中的数据来学习所需的内容。然后，它将使用所学内容对测试集中的数据进行预测。您随后可以将此预测与测试集中的实际目标变量进行比较，以查看模型的准确性。下一节的练习将更加详细地解释这一点。
- en: We will do the train/test split in proportions. The larger portion of the data
    split will be the train set and the smaller portion will be the test set. This
    will help to ensure that you are using enough data to accurately train your model.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按比例进行训练/测试分割。数据分割的较大部分将是训练集，较小部分将是测试集。这将有助于确保您使用足够的数据来准确训练您的模型。
- en: In general, we carry out the train-test split with an 80:20 ratio, as per the
    Pareto principle. The Pareto principle states that "for many events, roughly 80%
    of the effects come from 20% of the causes." But if you have a large dataset,
    it really doesn't matter whether it's an 80:20 split or 90:10 or 60:40\. (It can
    be better to use a smaller split set for the training set if our process is computationally
    intensive, but it might cause the problem of overfitting – this will be covered
    later in the book.)
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们按照 80:20 的比例进行训练-测试分割，遵循帕累托原则。帕累托原则指出："对于许多事件，大约 80% 的效果来自于 20% 的原因。"
    但是，如果您有一个大型数据集，无论是 80:20 还是 90:10 或者 60:40 都无关紧要。（如果我们的过程计算密集型，使用较小的训练集可能会更好，但这可能会导致过拟合问题
    – 这将在本书的后续部分进行讨论。）
- en: 'Exercise 12: Splitting Data into Train and Test Sets'
  id: totrans-528
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '练习 12: 将数据分割为训练集和测试集'
- en: 'In this exercise, we will load the `USA_Housing.csv` dataset (which you saw
    earlier) into a pandas dataframe and perform a train/test split. Follow these
    steps to complete this exercise:'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 在此练习中，我们将加载 `USA_Housing.csv` 数据集（您之前看到的）到 pandas 数据框中，并执行训练/测试分割。按照以下步骤完成此练习：
- en: Note
  id: totrans-530
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `USA_Housing.csv` dataset is available here: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/USA_Housing.csv.'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '`USA_Housing.csv` 数据集可在此处获取：https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/USA_Housing.csv.'
- en: 'Open a Jupyter notebook and add a new cell to import pandas and load the dataset
    into pandas:'
  id: totrans-532
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 Jupyter 笔记本，并添加一个新的单元格来导入 pandas 并将数据集加载到 pandas 中：
- en: '[PRE70]'
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Create a variable called `X` to store the independent features. Use the `drop()`
    function to include all the features, leaving out the dependent or the target
    variable, which in this case is named `Price`. Then, print out the top five instances
    of the variable. Add the following code to do this:'
  id: totrans-534
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `X` 的变量来存储独立特征。使用 `drop()` 函数来包括所有特征，留出依赖或目标变量，本例中名为 `Price`。然后，打印出该变量的前五个实例。添加以下代码来完成这一步骤：
- en: '[PRE71]'
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The preceding code generates the following output:'
  id: totrans-536
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![Figure 1.49: Dataframe consisting of independent variables'
  id: totrans-537
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.49: 包含独立变量的数据框'
- en: '](img/C13322_01_49.jpg)'
  id: totrans-538
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_49.jpg)'
- en: 'Figure 1.49: Dataframe consisting of independent variables'
  id: totrans-539
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 1.49: 包含独立变量的数据框'
- en: 'Print the shape of your new created feature matrix using the `X.shape` command:'
  id: totrans-540
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `X.shape` 命令打印出你新创建的特征矩阵的形状：
- en: '[PRE72]'
  id: totrans-541
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The preceding code generates the following output:'
  id: totrans-542
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![Figure 1.50: Shape of the X variable'
  id: totrans-543
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.50：X 变量的形状'
- en: '](img/C13322_01_50.jpg)'
  id: totrans-544
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_50.jpg)'
- en: 'Figure 1.50: Shape of the X variable'
  id: totrans-545
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.50：X 变量的形状
- en: In the preceding figure, the first value indicates the number of observations
    in the dataset (**5000**), and the second value represents the number of features
    (**6**).
  id: totrans-546
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的图中，第一个值表示数据集中的观察数（**5000**），第二个值表示特征数（**6**）。
- en: 'Similarly, we will create a variable called `y` that will store the target
    values. We will use indexing to grab the target column. Indexing allows us to
    access a section of a larger element. In this case, we want to grab the column
    named Price from the `df` dataframe and print out the top 10 values. Add the following
    code to implement this:'
  id: totrans-547
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样地，我们将创建一个名为 `y` 的变量来存储目标值。我们将使用索引来获取目标列。索引允许我们访问更大元素的一部分。在本例中，我们希望从 `df` 数据框中提取名为
    Price 的列，并打印出前 10 个值。添加以下代码来实现：
- en: '[PRE73]'
  id: totrans-548
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The preceding code generates the following output:'
  id: totrans-549
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![Figure 1.51: Top 10 values of the y variable'
  id: totrans-550
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.51：y 变量的前 10 个值'
- en: '](img/C13322_01_51.jpg)'
  id: totrans-551
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_51.jpg)'
- en: 'Figure 1.51: Top 10 values of the y variable'
  id: totrans-552
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.51：y 变量的前 10 个值
- en: 'Print the shape of your new variable using the `y.shape` command:'
  id: totrans-553
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `y.shape` 命令打印出你新创建的变量的形状：
- en: '[PRE74]'
  id: totrans-554
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The preceding code generates the following output:'
  id: totrans-555
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![Figure 1.52: Shape of the y variable'
  id: totrans-556
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.52：y 变量的形状'
- en: '](img/C13322_01_52.jpg)'
  id: totrans-557
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_01_52.jpg)'
- en: 'Figure 1.52: Shape of the y variable'
  id: totrans-558
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.52：y 变量的形状
- en: The shape should be one-dimensional, with a length equal to the number of observations
    (**5000**).
  id: totrans-559
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集的形状应为一维，长度等于观察数量（**5000**）。
- en: 'Make train/test sets with an 80:20 split. To do so, use the `train_test_split()`
    function from the `sklearn.model_selection` package. Add the following code to
    do this:'
  id: totrans-560
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集按 80:20 的比例分成训练集和测试集。为此，请使用来自 `sklearn.model_selection` 包的 `train_test_split()`
    函数。添加以下代码来实现：
- en: '[PRE75]'
  id: totrans-561
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: In the preceding code, `test_size` is a floating-point value that defines the
    size of the test data. If the value is 0.2, then it is an 80:20 split. `test_train_split`
    splits the arrays or matrices into train and test subsets in a random way. Each
    time we run the code without `random_state`, we will get a different result.
  id: totrans-562
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在上面的代码中，`test_size` 是一个浮动值，定义了测试数据的大小。如果值为 0.2，则为 80:20 的分割比例。`test_train_split`
    会将数组或矩阵随机分割成训练集和测试集。每次我们运行代码而不指定 `random_state` 时，都会得到不同的结果。
- en: 'Print the shape of `X_train`, `X_test`, `y_train`, and `y_test`. Add the following
    code to do this:'
  id: totrans-563
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出 `X_train`、`X_test`、`y_train` 和 `y_test` 的形状。添加以下代码来实现：
- en: '[PRE76]'
  id: totrans-564
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The preceding code generates the following output:'
  id: totrans-565
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![Figure 1.53: Shape of train and test datasets'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.53：训练集和测试集的数据形状'
- en: '](img/C13322_01_53.jpg)'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_01_53.jpg)'
- en: 'Figure 1.53: Shape of train and test datasets'
  id: totrans-568
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.53：训练集和测试集的数据形状
- en: You have successfully split the data into train and test sets.
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地将数据分割成训练集和测试集。
- en: In the next section, you will complete an activity wherein you'll perform pre-processing
    on a dataset.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，你将完成一项活动，其中你将对数据集进行预处理。
- en: 'Activity 1: Pre-Processing Using the Bank Marketing Subscription Dataset'
  id: totrans-571
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 1：使用银行营销订阅数据集进行预处理
- en: In this activity, we'll perform various pre-processing tasks on the `Bank Marketing
    Subscription` dataset. This dataset relates to the direct marketing campaigns
    of a Portuguese banking institution. Phone calls are made to market a new product,
    and the dataset records whether each customer subscribed to the product.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将对 `Bank Marketing Subscription` 数据集进行各种预处理任务。该数据集与葡萄牙银行机构的直接营销活动相关。通过电话营销新产品，并记录每个客户是否订阅了该产品。
- en: 'Follow these steps to complete this activity:'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成此活动：
- en: Note
  id: totrans-574
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `Bank Marketing Subscription` dataset is available here: https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Banking_Marketing.csv.'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: '`Bank Marketing Subscription` 数据集可以在此处找到： [https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Banking_Marketing.csv](https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter01/Data/Banking_Marketing.csv)。'
- en: Load the dataset from the link given into a pandas dataframe.
  id: totrans-576
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从给定的链接加载数据集到 pandas 数据框中。
- en: Explore the features of the data by finding the number of rows and columns,
    listing all the columns, finding the basic statistics of all columns (you can
    use the `describe().transpose()` function), and listing the basic information
    of the columns (you can use the `info()` function).
  id: totrans-577
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过找到行数和列数、列出所有列、找到所有列的基本统计信息（可以使用`describe().transpose()`函数）和列出列的基本信息（可以使用`info()`函数），探索数据的特征。
- en: Check whether there are any missing (or NULL) values, and if there are, find
    how many missing values there are in each column.
  id: totrans-578
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查是否有任何缺失（或NULL）值，并找出每列有多少个缺失值。
- en: Remove any missing values.
  id: totrans-579
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除任何缺失值。
- en: Print the frequency distribution of the `education` column.
  id: totrans-580
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印`education`列的频率分布。
- en: The `education` column of the dataset has many categories. Reduce the categories
    for better modeling.
  id: totrans-581
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集的`education`列有许多类别。减少类别以进行更好的建模。
- en: Select and perform a suitable encoding method for the data.
  id: totrans-582
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择并执行适合数据的编码方法。
- en: Split the data into train and test sets. The target data is in the `y` column
    and the independent data is in the remaining columns. Split the data with 80%
    for the train set and 20% for the test set.
  id: totrans-583
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为训练集和测试集。目标数据在`y`列中，独立数据在其余列中。将数据以80%的训练集和20%的测试集分割。
- en: Note
  id: totrans-584
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 324.
  id: totrans-585
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以在第324页找到。
- en: Now that we've covered the various data pre-processing steps, let's look at
    the different types of machine learning that are available to data scientists
    in some more detail.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了各种数据预处理步骤，让我们更详细地看看数据科学家可用的不同类型的机器学习。
- en: Supervised Learning
  id: totrans-587
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习
- en: Supervised learning is a learning system that trains using labeled data (data
    in which the target variables are already known). The model learns how patterns
    in the feature matrix map to the target variables. When the trained machine is
    fed with a new dataset, it can use what it has learned to predict the target variables.
    This can also be called predictive modeling.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习是一种使用标记数据（目标变量已知的数据）进行训练的学习系统。模型学习如何将特征矩阵中的模式映射到目标变量。当训练后的机器用新数据集进行输入时，它可以利用所学内容预测目标变量。这也可以称为预测建模。
- en: 'Supervised learning is broadly split into two categories. These categories
    are as follows:'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习广泛分为两类。这些类别如下：
- en: '**Classification** mainly deals with categorical target variables. A classification
    algorithm helps to predict which group or class a data point belongs to.'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类** 主要处理分类目标变量。分类算法有助于预测数据点属于哪个组或类。'
- en: When the prediction is between two classes, it is known as binary classification.
    An example is predicting whether or not a customer will buy a product (in this
    case, the classes are yes and no).
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 当预测处于两个类之间时，称为二元分类。例如，预测客户是否会购买产品（在这种情况下，类别为是和否）。
- en: If the prediction involves more than two target classes, it is known as multi-classification;
    for example, predicting all the items that a customer will buy.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 如果预测涉及超过两个目标类，则称为多分类；例如，预测客户将购买的所有物品。
- en: '**Regression** deals with numerical target variables. A regression algorithm
    predicts the numerical value of the target variable based on the training dataset.'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归** 处理数值目标变量。回归算法基于训练数据集预测目标变量的数值。'
- en: Linear regression measures the link between one or more predictor variables and
    one outcome variable. For example, linear regression could help to enumerate the
    relative impacts of age, gender, and diet (the predictor variables) on height
    (the outcome variable).
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归 测量一个或多个 预测变量 与一个 结果变量 之间的关联。例如，线性回归可以帮助列举年龄、性别和饮食（预测变量）对身高（结果变量）的相对影响。
- en: '**Time series analysis**, as the name suggests, deals with data that is distributed
    with respect to time, that is, data that is in a chronological order. Stock market
    prediction and customer churn prediction are two examples of time series data.
    Depending on the requirement or the necessities, time series analysis can be either
    a regression or classification task.'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间序列分析**，顾名思义，处理的是随时间分布的数据，即按时间顺序排列的数据。股市预测和客户流失预测是时间序列数据的两个例子。根据需求或必要性，时间序列分析可以是回归或分类任务。'
- en: Unsupervised Learning
  id: totrans-596
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Unlike supervised learning, the unsupervised learning process involves data
    that is neither classified nor labeled. The algorithm will perform analysis on
    the data without guidance. The job of the machine is to group unclustered information
    according to similarities in the data. The aim is for the model to spot patterns
    in the data in order to give some insight into what the data is telling us and
    to make predictions.
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 与有监督学习不同，无监督学习过程涉及的数据既没有分类也没有标记。算法将对数据进行分析，而不需要指导。机器的任务是根据数据中的相似性将未分组的信息进行分组。其目标是让模型在数据中发现模式，从而为我们提供数据的洞察力并进行预测。
- en: An example is taking a whole load of unlabeled customer data and using it to
    find patterns to cluster customers into different groups. Different products could
    then be marketed to the different groups for maximum profitability.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子是，使用一整批未标记的客户数据来寻找模式，将客户分成不同的群体。然后可以针对不同的群体推销不同的产品，以实现最大的利润。
- en: 'Unsupervised learning is broadly categorized into two types:'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习大致分为两类：
- en: '**Clustering**: A clustering procedure helps to discover the inherent patterns
    in the data.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**：聚类过程有助于发现数据中的内在模式。'
- en: '**Association**: An association rule is a unique way to find patterns associated
    with a large amount of data, such as the supposition that when someone buys product
    1, they also tend to buy product 2.'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关联**：关联规则是一种独特的方式，用来发现与大量数据相关的模式，例如当某人购买产品 1 时，他们也倾向于购买产品 2。'
- en: Reinforcement Learning
  id: totrans-602
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化学习
- en: Reinforcement learning is a broad area in machine learning where the machine
    learns to perform the next step in an environment by looking at the results of
    actions already performed. Reinforcement learning does not have an answer, and
    the learning agent decides what should be done to perform the specified task.
    It learns from its prior knowledge. This kind of learning involves both a reward
    and a penalty.
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是机器学习的一个广泛领域，在这个领域中，机器通过观察已执行操作的结果来学习如何在环境中执行下一步操作。强化学习没有固定的答案，学习代理根据任务的要求决定应该做什么。它从以前的经验中学习。这种学习方式涉及奖励和惩罚。
- en: No matter the type of machine learning you're using, you'll want to be able
    to measure how effective your model is. You can do this using various performance
    metrics. You will see how these are used in later chapters in the book, but a
    brief overview of some of the most common ones is given here.
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用何种机器学习方法，你都希望能够衡量你的模型效果。你可以通过各种性能指标来做到这一点。你将在本书的后续章节中看到这些如何使用，但这里简要概述了其中一些最常见的指标。
- en: Performance Metrics
  id: totrans-605
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能指标
- en: 'There are different evaluation metrics in machine learning, and these depend
    on the type of data and the requirements. Some of the metrics are as follows:'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中有不同的评估指标，这些指标依赖于数据的类型和需求。以下是一些常见的指标：
- en: Confusion matrix
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: Precision
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度
- en: Recall
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回
- en: Accuracy
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率
- en: F1 score
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F1 分数
- en: '**Confusion Matrix**'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: '**混淆矩阵**'
- en: 'A **confusion matrix** is a table that is used to define the performance of
    the classification model on the test data for which the actual values are known.
    To understand this better, look at the following figure, showing predicted and
    actual values:'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: '**混淆矩阵**是一个表格，用来定义分类模型在测试数据上的表现，其中实际值是已知的。为了更好地理解这一点，请看下图，展示了预测值与实际值：'
- en: '![](img/C13322_01_54.jpg)'
  id: totrans-614
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C13322_01_54.jpg)'
- en: 'Figure 1.54: Predicted versus actual values'
  id: totrans-615
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.54：预测值与实际值
- en: 'Let''s examine the concept of a confusion matrix and its metrics, TP, TN, FP,
    and FN, in detail. Assume you are building a model that predicts pregnancy:'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细了解混淆矩阵及其指标，TP、TN、FP 和 FN。假设你正在构建一个预测怀孕的模型：
- en: '`True`.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`。'
- en: '`True`, which cannot happen. This is a type of error called a Type 1 error.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`，这是不可能发生的。它是一种错误，称为类型 1 错误。'
- en: '`False`, which is also an error. This is called a Type 2 error.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False`，这也是一种错误，称为类型 2 错误。'
- en: '`False`; that is a **True Negative**.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False`；即**真正负类**。'
- en: The Type 1 error is a more dangerous error than the Type 2 error. Depending
    on the problem, we have to figure out whether we need to reduce Type 1 errors
    or Type 2 errors.
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 类型 1 错误比类型 2 错误更危险。根据问题的不同，我们必须弄清楚是需要减少类型 1 错误还是类型 2 错误。
- en: '**Precision**'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确度**'
- en: 'Precision is the ratio of TP outcomes to the total number of positive outcomes
    predicted by a model. The precision looks at how precise our model is as follows:'
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度是 TP 结果与模型预测的所有正向结果的比例。精确度衡量我们模型的准确性，如下所示：
- en: '![](img/C13322_01_55.jpg)'
  id: totrans-624
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C13322_01_55.jpg)'
- en: 'Figure 1.55: Precision equation'
  id: totrans-625
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.55：精度公式
- en: '**Recall**'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率**'
- en: 'Recall calculates what proportion of the TP outcomes our model has predicted:'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率计算我们模型预测出的TP（真正例）结果所占的比例：
- en: '![](img/C13322_01_56.jpg)'
  id: totrans-628
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C13322_01_56.jpg)'
- en: 'Figure 1.56: Recall equation'
  id: totrans-629
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.56：召回率公式
- en: '**Accuracy**'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: '**准确率**'
- en: 'Accuracy calculates the ratio of the number of positive predictions made by
    a model out of the total number of predictions made:'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率计算模型在所有预测中正确预测正例的比例：
- en: '![](img/C13322_01_57.jpg)'
  id: totrans-632
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C13322_01_57.jpg)'
- en: 'Figure 1.57: Accuracy equation'
  id: totrans-633
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.57：准确率公式
- en: '**F1 score**'
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: '**F1得分**'
- en: 'F1 score is another accuracy measure, but one that allows us to seek a balance
    between precision and recall:'
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: F1得分是另一种准确度衡量方法，但它允许我们在精度和召回率之间寻求平衡：
- en: '![](img/C13322_01_58.jpg)'
  id: totrans-636
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C13322_01_58.jpg)'
- en: 'Figure 1.58: F1-score'
  id: totrans-637
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.58：F1得分
- en: 'When considering the performance of a model, we have to understand two other
    important concepts of prediction error: bias and variance.'
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑模型表现时，我们必须理解预测误差的另外两个重要概念：偏差和方差。
- en: '**What is bias?**'
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么是偏差？**'
- en: '**Bias** is how far a predicted value is from the actual value. High bias means
    the model is very simple and is not capable of capturing the data''s complexity,
    causing what''s called underfitting.'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: '**偏差**是指预测值与实际值之间的差距。高偏差意味着模型非常简单，无法捕捉到数据的复杂性，导致所谓的欠拟合。'
- en: '**What is variance?**'
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么是方差？**'
- en: '**High variance** is when the model performs too well on the trained dataset.
    This causes overfitting and makes the model too specific to the train data, meaning
    the model does not perform well on test data.'
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: '**高方差**是指模型在训练数据集上表现得过好。这会导致过拟合，使得模型对训练数据过于特定，也就是说，模型在测试数据上表现不佳。'
- en: '![](img/C13322_01_59.jpg)'
  id: totrans-643
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C13322_01_59.jpg)'
- en: 'Figure 1.59: High variance'
  id: totrans-644
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.59：高方差
- en: Assume you are building a linear regression model to predict the market price
    of cars in a country. Let's say you have a large dataset about the cars and their
    prices, but there are still some more cars whose prices need to be predicted.
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在构建一个线性回归模型，目的是预测一个国家中汽车的市场价格。假设你有关于汽车及其价格的大量数据集，但仍有一些汽车的价格需要预测。
- en: When we train our model with the dataset, we want our model to just find that
    pattern within the dataset, nothing more, because if it goes beyond that, it will
    start to memorize the train set.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们用数据集训练模型时，我们希望模型仅仅在数据集中找到那个模式，仅此而已，因为如果超出这个范围，它就会开始记住训练集中的数据。
- en: We can improve our model by tuning its hyperparameters - there is more on this
    later in the book. We work towards minimizing the error and maximizing the accuracy
    by using another dataset, called the validation set. The first graph shows that
    the model has not learned enough to predict well in the test set. The third graph
    shows that the model has memorized the training dataset, which means the accuracy
    score will be 100, with 0 error. But if we predict on the test data, the middle
    model will outperform the third.
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过调整模型的超参数来改进模型——书中的后续章节会详细介绍这一点。我们通过使用另一个数据集，即验证集，来努力最小化误差并最大化准确率。第一个图表显示模型还没有学到足够的知识来在测试集上进行良好的预测。第三个图表显示模型已经记住了训练数据集，这意味着准确率将是100，误差为0。但如果我们在测试数据上进行预测，中间的模型表现会优于第三个。
- en: Summary
  id: totrans-648
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the basics of data science and explored the process
    of extracting underlying information from data using scientific methods, processes,
    and algorithms. We then moved on to data pre-processing, which includes data cleaning,
    data integration, data transformation, and data discretization.
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了数据科学的基础，并探讨了使用科学方法、过程和算法从数据中提取潜在信息的过程。接着我们进入了数据预处理，包括数据清洗、数据集成、数据转换和数据离散化。
- en: We saw how pre-processed data is split into train and test sets when building
    a model using a machine learning algorithm. We also covered supervised, unsupervised,
    and reinforcement learning algorithms.
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到在使用机器学习算法构建模型时，如何将预处理过的数据分为训练集和测试集。我们还讨论了监督学习、无监督学习和强化学习算法。
- en: Lastly, we went over the different metrics, including confusion matrices, precision,
    recall, and accuracy.
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们介绍了不同的度量标准，包括混淆矩阵、精度、召回率和准确率。
- en: In the next chapter, we will cover data visualization.
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍数据可视化。
