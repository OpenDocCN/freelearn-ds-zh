- en: Working with the Spark Key/Value API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark键/值API
- en: In this chapter, we'll be working with the Spark key/value API. We will start
    by looking at the available transformations on key/value pairs. We will then learn
    how to use the `aggregateByKey` method instead of the `groupBy()` method. Later,
    we'll be looking at actions on key/value pairs and looking at the available partitioners
    on key/value data. At the end of this chapter, we'll be implementing an advanced
    partitioner that will be able to partition our data by range.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Spark键/值API。我们将首先查看可用的键/值对转换。然后，我们将学习如何使用`aggregateByKey`方法而不是`groupBy()`方法。稍后，我们将研究键/值对的操作，并查看可用的键/值数据分区器。在本章结束时，我们将实现一个高级分区器，该分区器将能够按范围对我们的数据进行分区。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Available actions on key/value pairs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用的键/值对操作
- en: Using aggregateByKey instead of groupBy()
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`aggregateByKey`而不是`groupBy()`
- en: Actions on key/value pairs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 键/值对操作
- en: Available partitioners on key/value data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用的键/值数据分区器
- en: Implementing a custom partitioner
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现自定义分区器
- en: Available actions on key/value pairs
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可用的键/值对操作
- en: 'In this section, we will be covering the following topics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将涵盖以下主题：
- en: Available transformations on key/value pairs
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用的键/值对转换
- en: Using `countByKey()`
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`countByKey()`
- en: Understanding the other methods
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解其他方法
- en: So, this is our well-known test in which we will be using transformations on
    key/value pairs.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这是我们众所周知的测试，我们将在其中使用键/值对的转换。
- en: 'First, we will create an array of user transactions for users `A`, `B`, `A`,
    `B`, and `C` for some amount, as per the following example:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将为用户`A`，`B`，`A`，`B`和`C`创建一个用户交易数组，以某种金额，如下例所示：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We then need to key our data by a specific field, as per the following example:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，根据以下示例，我们需要按特定字段对数据进行键入：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We will key it by `userId`, by invoking the `keyBy` method with a `userId` parameter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过调用`keyBy`方法并使用`userId`参数对其进行键入。
- en: Now, our data is assigned to the `keyed` variable and its type is a tuple. The
    first element is a string, that is, `userId` and the second element is `UserTransaction`.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的数据分配给了`keyed`变量，其类型为元组。第一个元素是字符串，即`userId`，第二个元素是`UserTransaction`。
- en: Let's look at the transformations that are available. First, we will look at
    `countByKey`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下可用的转换。首先，我们将看看`countByKey`。
- en: 'Let''s look at its implementation, as shown in the following example:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下它的实现，如下例所示：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This returns a `Map` of key `K`, and `Long` is a generic type because it can
    be any type of key. In this example, the key will be a string. Every operation
    that returns map is not entirely safe. If you see a signature of the method that
    is returning map, it is a sign that this data will be sent to the driver and it
    needs to fit in the memory. If there is too much data to fit into one driver's
    memory, then we will run out of memory. Hence, we need to be cautious when using
    this method.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回一个`Map`，键`K`和`Long`是一种通用类型，因为它可以是任何类型的键。在本例中，键将是一个字符串。每个返回映射的操作都不是完全安全的。如果您看到返回映射的方法的签名，这表明这些数据将被发送到驱动程序，并且需要适合内存。如果有太多的数据无法适应一个驱动程序的内存，那么我们将耗尽内存。因此，在使用此方法时，我们需要谨慎。
- en: 'We then perform an assert count that should contain the same elements as the
    map, as per the following example:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们执行一个包含与地图相同元素的断言计数，如下例所示：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`B` is `2` because we have two values for it. Also, `A` is one similar to `C`
    as they have only one value. `CountByKey()` is not memory expensive because it
    only stores key and counter. However, if the key is a complex and a big object,
    for example, a transaction with multiple fields, which is more than two, then
    that map could be really big.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`B`是`2`，因为我们有两个值。另外，`A`与`C`类似，因为它们只有一个值。`countByKey()`不占用内存，因为它只存储键和计数器。但是，如果键是一个复杂且大的对象，例如具有多个字段的交易，超过两个，那么该映射可能会非常大。'
- en: 'But let''s start this test, as shown in the following example:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们从下面的例子开始这个测试：
- en: '![](img/18dbf0ad-9949-4e70-acfc-f826330185be.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/18dbf0ad-9949-4e70-acfc-f826330185be.png)'
- en: From the preceding screenshot, we can see that our test passed.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的屏幕截图中，我们可以看到我们的测试通过了。
- en: We also have a `combineByKey()` method, which combines the same elements for
    the same key, and shares the negative `aggregateByKey()` that is able to aggregate
    different types. We have `foldByKey`, which is taking the current state and value,
    but returns the same type as the value for the key.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有一个`combineByKey()`方法，它将相同键的相同元素组合在一起，并共享负面的`aggregateByKey()`，能够聚合不同类型。我们有`foldByKey`，它正在获取当前状态和值，但返回与键的值相同的类型。
- en: We also have `groupByKey()`, which we learned about in the previous section.
    This groups everything by the specific key and returns the iterator of values
    for a key. This is a very memory expensive operation as well, so we need to be
    careful when we use it.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有`groupByKey()`，我们在上一节中了解过。这将根据特定键对所有内容进行分组，并返回键的值迭代器。这也是一个非常占用内存的操作，因此在使用时需要小心。
- en: In the next section, we'll be using `aggregateByKey` instead of `groupBy`. We
    will learn how `groupBy` works and fix its shortcomings.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将使用`aggregateByKey`而不是`groupBy`。我们将学习`groupBy`的工作原理并修复其缺陷。
- en: Using aggregateByKey instead of groupBy()
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用`aggregateByKey`而不是`groupBy()`
- en: In this section, we will explore the reason why we use `aggregateByKey` instead
    of `groupBy`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨为什么我们使用`aggregateByKey`而不是`groupBy`。
- en: 'We will cover the following topics:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Why we should avoid the use of `groupByKey`
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么我们应该避免使用`groupByKey`
- en: What `aggregateByKey` gives us
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aggregateByKey`给我们的是什么'
- en: Implementing logic using `aggregateByKey`
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`aggregateByKey`实现逻辑
- en: 'First, we will create our array of user transactions, as shown in the following
    example:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建我们的用户交易数组，如下例所示：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We will then use `parallelize` to create an RDD, as we want our data to be
    key-wise. This is shown in the following example:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用`parallelize`创建一个RDD，因为我们希望我们的数据按键排序。这在下面的例子中显示：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the preceding code, we invoked `keyBy` for `userId` to have the data of payers,
    key, and user transaction.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们调用了`keyBy`来对`userId`进行操作，以获得付款人、键和用户交易的数据。
- en: 'Let''s consider that we want to aggregate, where we want to execute some specific
    logic for the same key, as shown in the following example:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设我们想要聚合，我们想要对相同的键执行一些特定的逻辑，如下面的例子所示：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The reasoning for this can be for choosing a maximum element, minimum element,
    or to calculate average. `aggregateByKey` needs to take three parameters, as shown
    in the following example:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的原因可能是选择最大元素、最小元素或计算平均值。`aggregateByKey`需要接受三个参数，如下面的例子所示：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The first parameter is an initial parameter of type T, and defining `amountForUser`
    is an initial parameter that has a type of `ArrayBuffer`. This is very important
    because the Scala compiler will infer that type, and argument numbers `1` and
    `2` need to have exactly the same type T in this example: `ArrayBuffer.empty[long]`.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数是T类型的初始参数，定义`amountForUser`是一个类型为`ArrayBuffer`的初始参数。这非常重要，因为Scala编译器将推断出该类型，并且在这个例子中，参数1和2需要具有完全相同的类型T：`ArrayBuffer.empty[long]`。
- en: 'The next argument is a method that takes the current element that we are processing.
    In this example, `transaction: UserTransaction) =>` is a current transaction and
    also needs to take the state that we were initializing our function with, and,
    hence, it will be an array buffer here.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '下一个参数是一个方法，它接受我们正在处理的当前元素。在这个例子中，`transaction: UserTransaction) =>`是一个当前交易，也需要带上我们初始化函数的状态，因此这里将是一个数组缓冲区。'
- en: 'It needs to be of the same type that''s as shown in the following code block,
    so this is our type T:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 它需要与以下代码块中显示的相同类型，因此这是我们的类型T：
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: At this point, we are able to take any transaction and add it to the specific
    state. This is done in a distributed way. For one key, execution is done on one
    executor and, for exactly the same key, on different executors. This happens in
    parallel, so multiple trades will be added for the same key.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们能够获取任何交易并将其添加到特定状态中。这是以分布式方式完成的。对于一个键，执行在一个执行器上完成，对于完全相同的键，执行在不同的执行器上完成。这是并行进行的，因此对于相同的键将添加多个交易。
- en: Now, Spark knows that, for exactly the same key, it has multiple states of type
    T `ArrayBuffer` that it needs to merge. So, we need to `mergeAmounts` for our
    transactions for the same key.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Spark知道，对于完全相同的键，它有多个T类型的状态`ArrayBuffer`，需要合并。因此，我们需要为相同的键`mergeAmounts`我们的交易。
- en: 'The `mergeArgument` is a method that takes two states, both of which are intermediate
    states of type T, as shown in the following code block:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`mergeArgument`是一个方法，它接受两个状态，这两个状态都是T类型的中间状态，如下面的代码块所示：'
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this example, we want to merge the release buffers into one array buffer.
    Therefore, we issue `p1 ++= p2`. This will merge two array buffers into one.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们想要将释放缓冲区合并成一个数组缓冲区。因此，我们发出`p1 ++= p2`。这将两个数组缓冲区合并成一个。
- en: Now, we have all arguments ready and we are able to execute `aggregateByKey`
    and see what the results look like. The result is an RDD of string and type T,
    the `ArrayBuffer[long]`, which is our state. We will not be keeping `UserTransaction`
    in our RDD anymore, which helps in reducing the amount of memory. `UserTransaction`
    is a heavy object because it can have multiple fields and, in this example, we
    are only interested in the amount field. So, this way, we can reduce the memory
    that is used.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好所有参数，我们能够执行`aggregateByKey`并查看结果是什么样子的。结果是一个字符串和类型T的RDD，`ArrayBuffer[long]`，这是我们的状态。我们将不再在RDD中保留`UserTransaction`，这有助于减少内存使用。`UserTransaction`是一个重量级对象，因为它可以有多个字段，在这个例子中，我们只对金额字段感兴趣。因此，这样我们可以减少内存的使用。
- en: 'The following example shows what our result should look like:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的例子展示了我们的结果应该是什么样子的：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We should have a key, `A`, and an `ArrayBuffer` of `100` and `10001`, since
    it is our input data. `B` should be `4` and `10`, and lastly, `C` should be `10`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该有一个键`A`，和一个`ArrayBuffer`的`100`和`10001`，因为这是我们的输入数据。`B`应该是`4`和`10`，最后，`C`应该是`10`。
- en: 'Let''s start the test to check if we have implemented `aggregateByKey` properly,
    as shown in the following example:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始测试，检查我们是否已经正确实现了`aggregateByKey`，如下面的例子所示：
- en: '![](img/26cd4ebd-1378-493b-a9d9-3e2b5f821a41.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/26cd4ebd-1378-493b-a9d9-3e2b5f821a41.png)'
- en: From the preceding output, we can see that it worked as expected.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中，我们可以看到它按预期工作。
- en: In the next section, we'll be looking at the actions that are available on key/value
    pairs.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将研究可用于键/值对的操作。
- en: Actions on key/value pairs
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 键/值对上的操作
- en: In this section, we'll be looking at the actions on key/value pairs.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将研究键/值对上的操作。
- en: 'We will cover the following topics:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Examining actions on key/value pairs
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查键/值对上的操作
- en: Using `collect()`
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`collect()`
- en: Examining the output for the key/value RDD
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查键/值RDD的输出
- en: In the first section of this chapter, we covered transformations that are available
    on key/value pairs. We saw that they are a bit different compared to RDDs. Also,
    for actions, it is slightly different in terms of result but not in the method
    name.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第一部分中，我们介绍了可用于键/值对的转换。我们看到它们与RDD相比有些不同。此外，对于操作，结果略有不同，但方法名称并没有变化。
- en: Therefore, we'll be using `collect()` and we'll be examining the output of our
    action on these key/value pairs.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将使用`collect()`，并且我们将检查我们对这些键/值对的操作的输出。
- en: 'First, we will create our transactions array and RDD according to `userId`,
    as shown in the following example:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将根据`userId`创建我们的交易数组和RDD，如下面的例子所示：
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The first action that comes to our mind is to `collect()`. `collect()` takes
    every element and assigns it to the result, and thus our result is very different
    than the result of `keyBy`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先想到的操作是`collect()`。`collect()`会取出每个元素并将其分配给结果，因此我们的结果与`keyBy`的结果非常不同。
- en: 'Our result is a pair of keys, `userId`, and a value, that is, `UserTransaction`.
    We can see, from the following example, that we can have a duplicated key:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果是一对键，`userId`和一个值，即`UserTransaction`。我们可以从下面的例子中看到，我们可以有一个重复的键：
- en: '[PRE12]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As we can see in the preceding code, we have multiple occurrences of the same
    order. For a simple key as a string, duplication is not very expensive. However,
    if we have a more complex key, it will be expensive.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们可以看到同一个订单有多个出现。对于一个简单的字符串键，重复并不是很昂贵。然而，如果我们有一个更复杂的键，那么就会很昂贵。
- en: 'So, let''s start this test, as shown in the following example:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们开始这个测试，如下例所示：
- en: '![](img/0bcc197e-ee8b-4de6-ae59-4cb32a6655ff.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0bcc197e-ee8b-4de6-ae59-4cb32a6655ff.png)'
- en: We can see, from the preceding output, that our test has passed. To see the
    other actions, we will look at different methods.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中，我们可以看到我们的测试已经通过。要查看其他动作，我们将查看不同的方法。
- en: 'If a method is returning RDD, such as `collect[U] (f: PartialFunction[(String,
    UserTransaction), U])`, it means that this is not an action. If something returns
    RDD, it means that it is not an action. This is the case for key/value pairs.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '如果一个方法返回RDD，比如`collect[U] (f: PartialFunction[(String, UserTransaction), U])`，这意味着这不是一个动作。如果某些东西返回RDD，这意味着它不是一个动作。这适用于键/值对。'
- en: '`collect()` does not return an RDD but returns an array, thus it is an action. `count` returns
    `long`, so this is also an action. `countByKey` returns map. If we want to `reduce`
    our elements, then this is an action, but `reduceByKey` is not an action. This
    is the big difference between `reduce` and `reduceByKey`.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`collect()`不会返回RDD，而是返回数组，因此它是一个动作。`count`返回`long`，因此这也是一个动作。`countByKey`返回map。如果我们想要`reduce`我们的元素，那么这是一个动作，但`reduceByKey`不是一个动作。这就是`reduce`和`reduceByKey`之间的重大区别。'
- en: We can see that everything is normal according to the RDD, so actions are the
    same and differences are only in transformation.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到根据RDD，一切都是正常的，因此动作是相同的，差异只在于转换。
- en: In the next section, we will be looking at the available partitioners on key/value
    data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看一下键/值数据上可用的分区器。
- en: Available partitioners on key/value data
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 键/值数据上可用的分区器
- en: We know that partitioning and partitioners are the key components of Apache
    Spark. They influence how our data is partitioned, which means they influence
    where the data actually resides on which executors. If we have a good partitioner,
    then we will have good data locality, which will reduce shuffle. We know that
    shuffle is not desirable for processing, so reducing shuffle is crucial, and,
    therefore, choosing a proper partitioner is also crucial for our systems.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道分区和分区器是Apache Spark的关键组件。它们影响我们的数据如何分区，这意味着它们影响数据实际驻留在哪些执行器上。如果我们有一个良好的分区器，那么我们将有良好的数据局部性，这将减少洗牌。我们知道洗牌对处理来说是不可取的，因此减少洗牌是至关重要的，因此选择适当的分区器对我们的系统也是至关重要的。
- en: 'In this section, we will cover the following topics:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将涵盖以下主题：
- en: Examining `HashPartitioner`
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查`HashPartitioner`
- en: Examining `RangePartitioner`
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查`RangePartitioner`
- en: Testing
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试
- en: We will first examine our `HashPartitioner` and `RangePartitioner`. We will
    then compare them and test the code using both the partitioners.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先检查我们的`HashPartitioner`和`RangePartitioner`。然后我们将比较它们并使用两个分区器测试代码。
- en: 'First we will create a `UserTransaction` array, as per the following example:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建一个`UserTransaction`数组，如下例所示：
- en: '[PRE13]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We will then use `keyBy` (as shown in the following example) because the partitioner
    will automatically work on the key for our data:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将使用`keyBy`（如下例所示），因为分区器将自动处理我们数据的键：
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We will then take a `partitioner` of key data, as shown in the following example:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将获取键数据的`partitioner`，如下例所示：
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The code shows `partitioner.isEmpty`, because we have not defined any `partitioner`
    and thus it is empty at this point, as can be seen in the following example:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 代码显示`partitioner.isEmpty`，因为我们还没有定义任何`partitioner`，因此在这一点上它是空的，如下例所示：
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can specify a `partitioner` by using the `partitionBy` method, as shown
    in the following example:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`partitionBy`方法指定一个`partitioner`，如下例所示：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The method is expecting a `partitioner` abstract class implementation. We will
    have a couple of implementations, but first, let's focus on `HashPartitioner`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法期望一个`partitioner`抽象类的实现。我们将有一些实现，但首先，让我们专注于`HashPartitioner`。
- en: '`HashPartitioner` takes a number of partitions and has a number of partitions.
    `numPartition` returns our argument, but `getPartition` gets a bit more involved,
    as shown in the following example:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`HashPartitioner`需要一个分区数，并且有一个分区数。`numPartition`返回我们的参数，但`getPartition`会更加复杂，如下例所示：'
- en: '[PRE18]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: It first checks if our `key` is `null`. If it is `null`, it will land in partition
    number `0`. If we have data with `null` keys, they will all land in the same executors,
    and, as we know, this is not a good situation because the executors will have
    a lot of memory overhead and they can fail without memory exceptions.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 它首先检查我们的`key`是否为`null`。如果是`null`，它将落在分区号`0`。如果我们有带有`null`键的数据，它们都将落在相同的执行器上，正如我们所知，这不是一个好的情况，因为执行器将有很多内存开销，并且它们可能会因为内存异常而失败。
- en: If the `key` is not `null`, then it does a `nonNegativeMod` from `hashCode`
    and the number of partitions. It has to be the modulus of the number of partitions
    so that it can be assigned to the proper partition. Thus, the `hashCode` method
    is very important for our key.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`key`不是`null`，那么它会从`hashCode`和分区数中进行`nonNegativeMod`。它必须是分区数的模数，这样它才能分配到适当的分区。因此，`hashCode`方法对我们的键非常重要。
- en: If we are supplying a custom key and not a primitive type like an integer or
    string, which has a well-known `hashCode`, we need to supply and implement a proper
    `hashCode` as well. But the best practice is to use the `case` class from Scala
    as they have `hashCode` and equals implemented for you.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们提供了一个自定义的键而不是像整数或字符串这样的原始类型，它有一个众所周知的`hashCode`，我们需要提供和实现一个适当的`hashCode`。但最佳实践是使用Scala中的`case`类，因为它们已经为你实现了`hashCode`和equals。
- en: We have defined `partitioner` now, but `partitioner` is something that could
    be changed dynamically. We can change our `partitioner` to be `rangePartitioner`.
    `rangePartitioner` takes the partitions in an RDD.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经定义了`partitioner`，但`partitioner`是可以动态更改的。我们可以将我们的`partitioner`更改为`rangePartitioner`。`rangePartitioner`接受RDD中的分区。
- en: '`rangePartitioner` is more complex as it tries to divide our data into ranges,
    which is not as simple as `HashPartitioner` is in getting partition. The method
    is really complex as it is trying to spread our data evenly and has complex logic
    for spreading that into ranges.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`rangePartitioner`更复杂，因为它试图将我们的数据划分为范围，这不像`HashPartitioner`在获取分区时那样简单。该方法非常复杂，因为它试图均匀地分布我们的数据，并且对将其分布到范围中的逻辑非常复杂。'
- en: 'Let''s start our test to check if we were able to assign `partitioner` properly,
    as shown in the following output:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始我们的测试，检查我们是否能够正确地分配`partitioner`，如下所示的输出：
- en: '![](img/d0cd68c3-e380-4192-895c-307a2cd974ec.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d0cd68c3-e380-4192-895c-307a2cd974ec.png)'
- en: Our tests have passed. This means that, at the initial point, the `partitioner`
    was empty and then we had to shuffle RDD at `partitionBy`, and also a `branchPartitioner`.
    But it shows us only the number line where we created an instance of the `partitioner`
    interface.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的测试已经通过。这意味着，在最初的时候，`partitioner`是空的，然后我们必须在`partitionBy`处对RDD进行洗牌，还有一个`branchPartitioner`。但它只显示了我们创建`partitioner`接口的实例的数值线。
- en: In the next section, we'll try to improve it or try to tweak and play with the
    partitioner by implementing a custom partitioner.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将尝试改进它，或者尝试通过实现自定义分区器来调整和玩弄分区器。
- en: Implementing a custom partitioner
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现自定义分区器
- en: In this section, we'll implement a custom partitioner and create a partitioner
    that takes a list of parses with ranges. If our key falls into a specific range,
    we will assign the partition number index of the list.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将实现一个自定义的分区器，并创建一个接受带有范围的解析列表的分区器。如果我们的键落入特定范围，我们将分配列表的分区号索引。
- en: 'We will cover the following topics:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Implementing a custom partitioner
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现自定义分区器
- en: Implementing a range partitioner
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现一个范围分区器
- en: Testing our partitioner
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试我们的分区器
- en: We will implement the logic range partitioning based on our own range partitioning
    and then test our partitioner. Let's start with the black box test without looking
    at the implementation.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将根据我们自己的范围分区逻辑来实现范围分区，并测试我们的分区器。让我们从不查看实现的黑盒测试开始。
- en: 'The first part of the code is similar to what we have used already, but this
    time we have `keyBy` amount of data, as shown in the following example:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的第一部分与我们已经使用的类似，但这次我们有`keyBy`数量的数据，如下例所示：
- en: '[PRE19]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We are keying by the amount and we have the following keys: `100`, `4`, `100001`,
    `10`, and `10`.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按数量进行分组，我们有以下键：`100`，`4`，`100001`，`10`和`10`。
- en: 'We will then create a partitioner and call it `CustomRangePartitioner`, which
    will take a list of tuples, as shown in the following example:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将创建一个分区器，并将其命名为`CustomRangePartitioner`，它将接受一个元组列表，如下例所示：
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The first element is from `0` to `100`, which means if the key is within the
    range of `0` to `100`, it should go to partition `0`. So, we have four keys that
    should fall into that partition. The next partition number has a range of `100`
    and `10000`, so every record within that range should fall into partition number
    `1`, inclusive of both ends. The last range is between `10000` and `1000000` elements,
    so, if the record is between that range, it should fall into that partition. If
    we have an element out of range, then the partitioner will fail with an illegal
    argument exception.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个元素是从`0`到`100`，这意味着如果键在`0`到`100`的范围内，它应该进入分区`0`。因此，有四个键应该落入该分区。下一个分区号的范围是`100`和`10000`，因此该范围内的每条记录都应该落入分区号`1`，包括两端。最后一个范围是`10000`到`1000000`元素之间，因此，如果记录在该范围内，它应该落入该分区。如果我们有一个超出范围的元素，那么分区器将因非法参数异常而失败。
- en: 'Let''s look at the following example, which shows the implementation of our
    custom range partitioner:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下下面的例子，展示了我们自定义范围分区器的实现：
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It takes ranges as an argument list of tuples, as shown in the following example:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 它将范围作为元组的参数列表，如下例所示：
- en: '[PRE22]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Our `numPartitions` should be equal to `ranges.size`, so the number of partitions
    is equal to the number of ranges in size.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`numPartitions`应该等于`ranges.size`，因此分区的数量等于范围的数量。
- en: 'Next, we have the `getPartition` method. First, our partitioner will work only
    for integers, as shown in the following example:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有`getPartition`方法。首先，我们的分区器只对整数有效，如下例所示：
- en: '[PRE23]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We can see that this is an integer and cannot be used for other types. For the
    same reason, we first need to check whether our key is an instance of integer,
    and, if it is not, we get an `IllegalArgumentException` because that partitioner
    works only for the int type.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这是一个整数，不能用于其他类型。出于同样的原因，我们首先需要检查我们的键是否是整数的实例，如果不是，我们会得到一个`IllegalArgumentException`，因为该分区器只对int类型有效。
- en: 'We can now test our `keyInt` by using `asInstanceOf`. Once this is done, we
    are able to iterate over ranges and take the last range when the index is between
    predicates. Our predicate is a tuple `v`, and should be as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过`asInstanceOf`来测试我们的`keyInt`。完成后，我们可以遍历范围，并在索引在谓词之间时取最后一个范围。我们的谓词是一个元组`v`，应该如下所示：
- en: '[PRE24]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '`KeyInt` should be more than or equal to `v._1`, which is the first element
    of the tuple, but it should also be lower than the second element, `v._2`.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`KeyInt`应该大于或等于`v._1`，即元组的第一个元素，但也应该小于第二个元素`v._2`。'
- en: The start of the range is `v._1` and the end of the range is `v._2`, so we can
    check that our element is within range.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 范围的起始是`v._1`，范围的结束是`v._2`，因此我们可以检查我们的元素是否在范围内。
- en: 'In the end, we will print the for key we found in the index for debugging purposes,
    and we will return the index, which will be our partition. This is shown in the
    following example:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将打印我们在调试目的中找到的键的索引，并返回索引，这将是我们的分区。如下例所示：
- en: '[PRE25]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let''s start the following test:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始下面的测试：
- en: '![](img/485d4143-f478-4f9b-be3f-35c580667323.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/485d4143-f478-4f9b-be3f-35c580667323.png)'
- en: We can see that for key `100001`, the code returned partition number `2`, which
    is as expected. For key `100` returns partition one and for `10`, `4`, `10` it
    returns partition zero, which means our code works as expected.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到对于键`100001`，代码返回了预期的分区号`2`。对于键`100`返回分区一，对于`10`，`4`，`10`返回分区零，这意味着我们的代码按预期工作。
- en: Summary
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we first saw available the transformations on key/value pairs.
    We then learned how to use `aggregateByKey` instead of `groupBy`. We also covered
    actions on key/value pairs. Later, we looked at available partitioners like `rangePartitioner`
    and `HashPartition` on key/value data. By the end of this chapter, we had implemented
    our custom partitioner, which was able to assign partitions, based on the end
    and start of the range for learning purposes.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先看到了关于键/值对的转换操作。然后我们学习了如何使用`aggregateByKey`而不是`groupBy`。我们还涵盖了关于键/值对的操作。之后，我们看了一下可用的分区器，比如`rangePartitioner`和`HashPartition`在键/值数据上。在本章结束时，我们已经实现了我们自定义的分区器，它能够根据范围的起始和结束来分配分区，以便学习目的。
- en: In the next chapter, we will learn how to test our Spark jobs and Apache Spark
    jobs.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何测试我们的Spark作业和Apache Spark作业。
