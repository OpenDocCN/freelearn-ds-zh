- en: Chapter 3. Trident Topologies and Sensor Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章。Trident拓扑结构和传感器数据
- en: In this chapter, we will explore Trident topologies. Trident provides a higher-level
    abstraction on top of Storm. Trident abstracts away the details of transactional
    processing and state management. Specifically, Trident provides batching of tuples
    into a discrete set of transactions. Additionally, Trident provides abstractions
    that allow topologies to perform operations on the data such as functions, filters,
    and aggregations.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨Trident拓扑结构。Trident在Storm之上提供了一个更高级的抽象。Trident抽象了事务处理和状态管理的细节。具体来说，Trident将元组批处理成一组离散的事务。此外，Trident提供了允许拓扑对数据执行操作的抽象，如函数、过滤器和聚合。
- en: We will use the sensor data as an example to gain a better understanding of
    Trident. Often, the sensor data forms streams that are read from many different
    locations. Some traditional examples include the weather or traffic information,
    but the pattern extends to a wide range of sources. For example, applications
    that run on cell phones generate a plethora of event information. Processing event
    streams from phones is another instance of sensor data processing.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用传感器数据作为示例，以更好地理解Trident。通常，传感器数据形成从许多不同位置读取的流。一些传统的例子包括天气或交通信息，但这种模式延伸到各种来源。例如，运行在手机上的应用程序会生成大量的事件信息。处理来自手机的事件流是传感器数据处理的另一个实例。
- en: The sensor data contains events emitted by many devices, often forming a never-ending
    stream. This is a perfect use case for Storm.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 传感器数据包含许多设备发出的事件，通常形成一个永无止境的流。这是Storm的一个完美用例。
- en: 'In this chapter, we will cover:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Trident topologies
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident拓扑结构
- en: Trident spouts
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident喷泉
- en: Trident operations – filters and functions
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident操作-过滤器和函数
- en: Trident aggregators – Combiners and Reducers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident聚合器-组合器和减少器
- en: The Trident state
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident状态
- en: Examining our use case
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 审查我们的用例
- en: To better understand both the Trident topologies, as well as using Storm with
    sensor data, we will implement a Trident topology that collects medical reports
    to identify the outbreak of a disease.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解Trident拓扑结构以及使用传感器数据的Storm，我们将实现一个Trident拓扑结构，用于收集医疗报告以识别疾病的爆发。
- en: 'The topology will process diagnosis events that contain the following pieces
    of information:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑结构将处理包含以下信息的诊断事件：
- en: '| Latitude | Longitude | Timestamp | Diagnosis Code (ICD9-CM) |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 纬度 | 经度 | 时间戳 | 诊断代码（ICD9-CM） |'
- en: '| --- | --- | --- | --- |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 39.9522 | -75.1642 | 03/13/2013 at 3:30 PM | 320.0 (*Hemophilus meningitis*)
    |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 39.9522 | -75.1642 | 2013年3月13日下午3:30 | 320.0（血友病性脑膜炎） |'
- en: '| 40.3588 | -75.6269 | 03/13/2013 at 3:50 PM | 324.0 (*Intracranial abscess*)
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 40.3588 | -75.6269 | 2013年3月13日下午3:50 | 324.0（颅内脓肿） |'
- en: 'Each event will include the **Global Positioning System** (**GPS**) coordinates
    of the occurrence. The latitude and longitude are specified in the decimal format.
    The event also contains the ICD9-CM code, which indicates the diagnosis and a
    timestamp for the event. A complete list of ICD-9-CM codes are available at:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 每个事件将包括发生地点的全球定位系统（GPS）坐标。纬度和经度以十进制格式指定。事件还包含ICD9-CM代码，表示诊断和事件的时间戳。完整的ICD-9-CM代码列表可在以下网址找到：
- en: '[http://www.icd9data.com/](http://www.icd9data.com/.) .'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.icd9data.com/](http://www.icd9data.com/.) .'
- en: To detect an outbreak, the system will count the occurrences of specific disease
    codes within a geographic location over a specified period of time. To simplify
    things for this example, we will map every diagnosis event to the closest city.
    In a real system, you would most likely perform more sophisticated geospatial
    clustering of the events.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检测疫情爆发，系统将计算在指定时间段内特定疾病代码在地理位置内的发生次数。为了简化这个例子，我们将每个诊断事件映射到最近的城市。在一个真实的系统中，你很可能会对事件进行更复杂的地理空间聚类。
- en: Also, for the example, we will group the occurrences by hour since epoch. In
    a real-world system, you would most likely use a sliding window and calculate
    a trend against the moving average.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，对于这个例子，我们将按小时自纪元以来对发生次数进行分组。在一个真实的系统中，你很可能会使用滑动窗口，并计算相对移动平均值的趋势。
- en: Finally, we will use a simple threshold to determine if there is an outbreak.
    If the count of occurrences for the hour is greater than some threshold, the system
    will send an alert and dispatch the National Guard.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用一个简单的阈值来确定是否有疫情爆发。如果某个小时的发生次数大于某个阈值，系统将发送警报并派遣国民警卫队。
- en: To maintain a historical record, we will also persist the number of occurrences
    for each city, hour, and disease.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持历史记录，我们还将持久化每个城市、小时和疾病的发生次数。
- en: Introducing Trident topologies
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Trident拓扑结构
- en: To fulfill these requirements, we will need to count the occurrences in our
    topologies. This can be challenging while using standard Storm topologies because
    tuples can get replayed, which leads to double counting. As we will see in the
    next few sections, Trident provides primitives to solve this problem.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足这些要求，我们需要在我们的拓扑中计算发生的次数。在使用标准Storm拓扑时，这可能会有挑战，因为元组可能会被重放，导致重复计数。正如我们将在接下来的几节中看到的那样，Trident提供了解决这个问题的基本方法。
- en: 'We will use the following topology:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下拓扑：
- en: '![Introducing Trident topologies](img/8294OS_03_01.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![介绍Trident拓扑结构](img/8294OS_03_01.jpg)'
- en: 'The code for the preceding topology is as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 前述拓扑的代码如下：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The preceding code shows the wiring between the different Trident functions.
    First, the `DiagnosisEventSpout` function emits the events. The events are then
    filtered by the `DiseaseFilter` function, which filters out occurrences of diseases
    that we are not concerned with. After that, the event is associated with a city
    in the `CityAssignment` function. Then, the `HourAssignment` function assigns
    an hour to the event and adds a key to the tuple, which comprises the city, hour,
    and disease code. We then group by this key, which enables the counting and persisting
    of those counts in the `persistAggregate` function step in the topology. The counts
    are then passed along to the `OutbreakDetector` function, which thresholds the
    count, emitting an alert when the threshold is exceeded. Finally, the `DispatchAlert`
    function receives the alert, logs a message, and terminates the program. In the
    following section, we will take a deeper look into each of these steps.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码显示了不同Trident函数之间的连接。首先，`DiagnosisEventSpout`函数发出事件。然后，`DiseaseFilter`函数对事件进行过滤，过滤掉我们不关心的疾病发生。之后，事件与`CityAssignment`函数中的城市相关联。然后，`HourAssignment`函数为事件分配一个小时，并向元组添加一个键，该键包括城市、小时和疾病代码。然后，我们按照这个键进行分组，这使得在拓扑中的`persistAggregate`函数步骤中对这些计数进行计数和持久化。然后，这些计数传递给`OutbreakDetector`函数，该函数对计数进行阈值处理，当超过阈值时发出警报。最后，`DispatchAlert`函数接收警报，记录一条消息，并终止程序。在接下来的部分中，我们将更深入地研究每个步骤。
- en: Introducing Trident spouts
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Trident spout
- en: Let's first take a look at the spout in the topology. In contrast to Storm,
    Trident introduces the concept of **batches**. Unlike Storm spouts, Trident spouts
    must emit tuples in batches.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看一下拓扑中的spout。与Storm相比，Trident引入了**批次**的概念。与Storm的spout不同，Trident的spout必须以批次形式发出元组。
- en: 'Each batch is given its own unique transaction identifier. A spout determines
    the composition of a batch based on the constraints of its contract. There are
    three types of contracts for spouts: **Non-transactional**, **Transactional**,
    and **Opaque**.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 每个批次都有自己独特的事务标识符。spout根据其合同的约束确定批次的组成。spout有三种类型的合同：**非事务性**，**事务性**和**不透明**。
- en: Non-transactional spouts provide no guarantee on the composition of the batches
    and might overlap. Two different batches might contain the same tuples. Transactional
    spouts guarantee that batches are non-overlapping and that the same batch always
    contains the same tuples. Opaque spouts guarantee that batches are non-overlapping,
    but the contents of a batch may change.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 非事务性spout对批次的组成不提供任何保证，并且可能重叠。两个不同的批次可能包含相同的元组。事务性spout保证批次不重叠，并且相同的批次始终包含相同的元组。不透明spout保证批次不重叠，但批次的内容可能会改变。
- en: 'This is depicted in the following table:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这在以下表中表示出来：
- en: '| Spout type | Batches may overlap | Batch contents may change |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| Spout类型 | 批次可能重叠 | 批次内容可能改变 |'
- en: '| --- | --- | --- |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Non-transactional | X | X |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 非事务性 | X | X |'
- en: '| Opaque |   | X |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 不透明 |   | X |'
- en: '| Transactional |   |   |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 事务性 |   |   |'
- en: 'The interface for a spout looks like the following code snippet:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: spout的接口如下代码片段所示：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In Trident, the spout does not actually emit the tuples. Instead, the work is
    broken down between the `BatchCoordinator` and `Emitter` functions. The `Emitter`
    function is responsible for emitting the tuples, and the `BatchCoordinator` function
    is responsible for batch management and metadata such that the `Emitter` function
    can properly replay batches.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在Trident中，spout实际上并不发出元组。相反，工作在`BatchCoordinator`和`Emitter`函数之间进行分解。`Emitter`函数负责发出元组，而`BatchCoordinator`函数负责批处理管理和元数据，以便`Emitter`函数可以正确重播批次。
- en: 'The `TridentSpout` function simply provides accessor methods to the `BatchCoordinator`
    and `Emitter` functions and declares the fields that the spout will emit. The
    following is the listing of the `DiagnosisEventSpout` function for our example:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`TridentSpout`函数只是提供了对`BatchCoordinator`和`Emitter`函数的访问器方法，并声明了spout将发出的字段。以下是我们示例中的`DiagnosisEventSpout`函数的列表：'
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As shown in the `getOutputFields()` method in the preceding code, in our example
    topology, the spout emits a single field called `event`, which contains the `DiagnosisEvent`
    class.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面代码中的`getOutputFields()`方法所示，在我们的示例拓扑中，spout发出一个名为`event`的单个字段，其中包含`DiagnosisEvent`类。
- en: 'The `BatchCoordinator` class implements the following interface:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`BatchCoordinator`类实现了以下接口：'
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `BatchCoordinator` class is a generic class. The generic class is the metadata
    that is required to replay a batch. In our example, the spout emits random events
    and thus the metadata is ignored. However, in real-world systems, the metadata
    might contain the identifiers of the messages or objects that comprise a batch.
    With that information, the opaque and transactional spouts can abide to their
    contracts and ensure that the contents of batches do not overlap, and in the case
    of the transactional spout, the batch contents do not change.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`BatchCoordinator`类是一个通用类。通用类是重播批次所需的元数据。在我们的示例中，spout发出随机事件，因此元数据被忽略。然而，在现实世界的系统中，元数据可能包含组成批次的消息或对象的标识符。有了这些信息，不透明和事务性的spout可以遵守它们的合同，并确保批次的内容不重叠，并且在事务性spout的情况下，批次内容不会改变。'
- en: The `BatchCoordinator` class is implemented as a Storm Bolt operating in a single
    thread. Storm persists the metadata in Zookeeper. It notifies the coordinator
    when each transaction is complete.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`BatchCoordinator`类被实现为一个在单个线程中运行的Storm Bolt。Storm将元数据持久化在Zookeeper中。它在每个事务完成时通知协调器。'
- en: 'For our example, if we do no coordination, the following is the coordination
    used in the `DiagnosisEventSpout` class:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例，如果我们不进行协调，那么在`DiagnosisEventSpout`类中使用的协调如下：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The second component in a Trident spout is the `Emitter` function. The `Emitter`
    function performs the function of the Storm spout using a collector to emit tuples.
    The only distinction is that it uses a `TridentCollector` class, and the tuples
    must be included in a batch that was initialized by the `BatchCoordinator` class.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Trident spout的第二个组件是`Emitter`函数。`Emitter`函数使用收集器发出元组，执行Storm spout的功能。唯一的区别是它使用`TridentCollector`类，并且元组必须包含在由`BatchCoordinator`类初始化的批次中。
- en: 'The interface for an `Emitter` function looks like the following code snippet:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`Emitter`函数的接口如下代码片段所示：'
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As shown in the preceding code, the `Emitter` function has only one job—to
    emit the tuples for a given batch. To do this, the function is passed the metadata
    for the batch (which was constructed by the coordinator), information about the
    transaction, and the collector, which is what the `Emitter` function uses to emit
    the tuples. The listing for the `DiagnosisEventEmitter` class is as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码所示，`Emitter`函数只有一个任务-为给定的批次发出元组。为此，函数被传递了由协调器构建的批次的元数据，事务的信息以及收集器，`Emitter`函数使用它来发出元组。`DiagnosisEventEmitter`类的列表如下：
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The work is performed in the `emitBatch()` method. For this example, we will
    randomly assign a latitude and longitude, keeping it roughly within the United
    States, and we will use the `System.currentTimeMillis()` method for the timestamp
    on the diagnosis.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 工作是在`emitBatch()`方法中执行的。在这个示例中，我们将随机分配一个纬度和经度，大致保持在美国境内，并且我们将使用`System.currentTimeMillis()`方法来为诊断的时间戳。
- en: 'In real life, ICD-9-CM codes sparsely populate a range between 000 and 999\.
    For this example, we will only use diagnosis codes between 320 and 327\. These
    codes are listed as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实生活中，ICD-9-CM代码在000到999之间稀疏地填充了一个范围。在这个示例中，我们将只使用320到327之间的诊断代码。这些代码如下所示：
- en: '| Code | Description |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 描述 |'
- en: '| --- | --- |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 320 | Bacterial meningitis |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 320 | 细菌性脑膜炎 |'
- en: '| 321 | Meningitis due to other organisms |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 321 | 由其他生物引起的脑膜炎 |'
- en: '| 322 | Meningitis of unspecified cause |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 322 | 未指明原因的脑膜炎 |'
- en: '| 323 | Encephalitis myelitis and encephalomyelitis |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 323 | 脑炎、脊髓炎和脑脊髓炎 |'
- en: '| 324 | Intracranial and intraspinal abscess |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 324 | 颅内和脊髓脓肿 |'
- en: '| 325 | Phlebitis and thrombophlebitis of intracranial venous sinuses |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 325 | 静脉窦血栓性静脉炎和静脉炎 |'
- en: '| 326 | Late effects of intracranial abscess or pyogenic infection |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 326 | 颅内脓肿或化脓感染的后遗症 |'
- en: '| 327 | Organic sleep disorders |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 327 | 有机性睡眠障碍 |'
- en: One of these diagnosis codes is randomly assigned to the event.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个诊断代码被随机分配给了事件。
- en: In this example, we will use an object to encapsulate the diagnosis event. Just
    as easily, we could have emitted each of the components as a separate field in
    the tuple. There is a balancing act between object encapsulation and use of fields
    in the tuple. Often, it is a good idea to keep the number of fields down to a
    manageable number, but it also makes sense to include data used for the control
    flow and/or grouping as fields in the tuple.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用一个对象来封装诊断事件。同样地，我们可以将每个组件作为元组中的单独字段发出。对象封装和元组字段的使用之间存在一种平衡。通常，将字段数量保持在可管理的范围内是一个好主意，但也有道理将用于控制流和/或分组的数据作为元组中的字段包含进来。
- en: 'In our example, the `DiagnosisEvent` class is the key piece of data on which
    the topology is operating. That object looks like the following code snippet:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，`DiagnosisEvent`类是拓扑操作的关键数据。该对象如下代码片段所示：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The object is a simple JavaBean. Time is stored as a long variable, which is
    the time since the epoch. The latitude and longitude are each stored as doubles.
    The `diagnosisCode` class is stored as a string, just in case the system needs
    to be able to process other types of codes that are not based on ICD-9, such as
    alphanumeric codes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 该对象是一个简单的JavaBean。时间以长变量的形式存储，这是自纪元以来的时间。纬度和经度分别以双精度存储。`diagnosisCode`类以字符串形式存储，以防系统需要能够处理不基于ICD-9的其他类型的代码，比如字母数字代码。
- en: At this point, the topology is able to emit events. In a real implementation,
    we might integrate the topology into a medical claims processing engine or an
    electronic health records system at the point of practice.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，拓扑能够发出事件。在实际实现中，我们可能会将拓扑集成到医疗索赔处理引擎或电子健康记录系统中。
- en: Introducing Trident operations – filters and functions
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入Trident操作-过滤器和函数
- en: 'Now that we have events being generated, the next step is to add the logic
    components that implement the business process. In Trident, these are known as
    **operations**. In our topology, we are using two different types of operations:
    filters and functions.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经生成了事件，下一步是添加实现业务流程的逻辑组件。在Trident中，这些被称为**操作**。在我们的拓扑中，我们使用了两种不同类型的操作：过滤器和函数。
- en: 'Operations are applied to streams via methods on the `Stream` object. In this
    example, we use the following methods on the `Stream` object:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`Stream`对象上的方法将操作应用于流。在这个示例中，我们在`Stream`对象上使用以下方法：
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that the methods in the preceding code return forms of the `Stream` objects
    or `TridentState` that can be used to create additional streams. With this, operations
    can be chained together using fluent-style Java.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面代码中的方法返回`Stream`对象或`TridentState`的形式，可以用来创建额外的流。通过这种方式，操作可以使用流畅的Java链接在一起。
- en: 'Let''s take another look at the critical lines in our example topology:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再来看一下我们示例拓扑中的关键线路：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Typically, operations are applied by declaring a set of input fields and a set
    of output fields also known as **function fields**. The second line of the topology
    in the preceding code declares that we want `CityAssignment` to execute on each
    tuple in the stream. From that tuple, `CityAssignment` will operate on the `event`
    field and emit a function field labelled `city`, which is appended to the tuple.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，通过声明一组输入字段和一组输出字段，也称为**函数字段**，来应用操作。在前面代码的拓扑的第二行声明，我们希望`CityAssignment`在流中的每个元组上执行。从该元组中，`CityAssignment`将操作`event`字段并发出一个标记为`city`的函数字段，该字段将附加到元组中。
- en: Each operation has slightly different fluent-style syntax, which depends on
    what information the operation requires. In the following sections, we will cover
    the details of the syntax and the semantics of the different operations.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 每个操作都有略有不同的流畅式语法，这取决于操作需要的信息。在接下来的部分中，我们将介绍不同操作的语法和语义的细节。
- en: Introducing Trident filters
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入Trident过滤器
- en: The first piece of logic in our topology is a **filter**, which ignores disease
    events that are not of concern. In this example, the system will focus on meningitis.
    From the previous table, the only meningitis codes are 320, 321, and 322.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拓扑中的第一条逻辑是一个**过滤器**，它会忽略那些不相关的疾病事件。在这个例子中，系统将专注于脑膜炎。从之前的表中，脑膜炎的唯一代码是320、321和322。
- en: 'To filter events based on codes, we will leverage a Trident filter. Trident
    makes this easy by providing a `BaseFilter` class that we can subclass to filter
    tuples that the system does not care about. The `BaseFilter` class implements
    the `Filter` interface, which looks like the following code snippet:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了根据代码过滤事件，我们将利用Trident过滤器。Trident通过提供`BaseFilter`类来使这变得容易，我们可以对不关心的元组进行子类化以过滤元组。`BaseFilter`类实现了`Filter`接口，如下代码片段所示：
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To filter tuples in a stream, the application simply implements this interface
    by extending the `BaseFilter` class. In the example, we will filter events using
    the following filter:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要过滤流中的元组，应用程序只需通过扩展`BaseFilter`类来实现这个接口。在这个例子中，我们将使用以下过滤器来过滤事件：
- en: '[PRE11]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the preceding code, we will extract the `DiagnosisEvent` class from the tuple
    and examine the disease code. Since all the meningitis codes are less than or
    equal to 322, and we are not emitting any other codes, we simply check to see
    if the code is less than 322 to determine if the event relates to meningitis.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们将从元组中提取`DiagnosisEvent`类并检查疾病代码。由于所有的脑膜炎代码都小于或等于322，并且我们不发出任何其他代码，我们只需检查代码是否小于322来确定事件是否与脑膜炎有关。
- en: Returning `True` from a `Filter` operation will result in the tuple flowing
    along to downstream operations. If the method returns `False`, the tuple will
    not flow to downstream operations.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 从`Filter`操作中返回`True`将导致元组流向下游操作。如果方法返回`False`，元组将不会流向下游操作。
- en: 'In our topology, we apply the filter to each tuple in the stream using the
    `each(inputFields, filter)` method on the stream. The following line in our topology
    applies the filter to the stream:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的拓扑中，我们使用`each(inputFields, filter)`方法将过滤器应用于流中的每个元组。我们的拓扑中的以下一行将过滤器应用于流：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Introducing Trident functions
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入Trident函数
- en: In addition to filters, Storm provides an interface for generic functions. Functions
    are similar to Storm bolts in that they consume tuples and optionally emit new
    tuples. One distinction is that Trident functions are additive. The values emitted
    by functions are fields that are added to the tuple. They do not remove or mutate
    existing fields.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 除了过滤器，Storm还提供了一个通用函数的接口。函数类似于Storm的bolt，它们消耗元组并可选择发出新的元组。一个区别是Trident函数是增量的。函数发出的值是添加到元组中的字段。它们不会删除或改变现有字段。
- en: 'The interface for a function looks like the following code snippet:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的接口如下代码片段所示：
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Similar to a Storm bolt, the function implements a single method that contains
    the logic for that function. The function implementation can optionally use the
    `TridentCollector` to emit the tuple passed into the function. In this way, functions
    can also be used to filter tuples.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 与Storm的bolt类似，函数实现了一个包含该函数逻辑的单个方法。函数实现可以选择使用`TridentCollector`来发出传入函数的元组。这样，函数也可以用来过滤元组。
- en: 'The first function in our topology is the `CityAssignment` function that looks
    like the following code snippet:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拓扑中的第一个函数是`CityAssignment`函数，代码如下：
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this function, we use a static initializer to create a map of the cities
    we care about. For sample data, the function has a map that contains the coordinates
    for Philadelphia (PHL), New York City (NYC), San Francisco (SF), and Los Angeles
    (LA).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个函数中，我们使用静态初始化器来创建我们关心的城市的地图。对于示例数据，该函数有一个包含费城（PHL）、纽约市（NYC）、旧金山（SF）和洛杉矶（LA）坐标的地图。
- en: In the `execute()` method, the function loops through the cities and calculates
    the distance between the event and the city. In a real system, a geospatial index
    is likely more efficient.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在`execute()`方法中，函数循环遍历城市并计算事件与城市之间的距离。在真实系统中，地理空间索引可能更有效。
- en: Once the function determines the closest city, it emits the code for that city
    in the last few lines of the method. Remember that in Trident, instead of the
    function declaring what fields it will emit, the fields are declared when the
    operation is attached to the stream as the third parameter in the function call.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦函数确定了最近的城市，它会在方法的最后几行发出该城市的代码。请记住，在Trident中，函数不是声明它将发出哪些字段，而是在操作附加到流时作为函数调用中的第三个参数声明字段。
- en: The number of function fields declared must align with the number of values
    emitted by the function. If they do not align, Storm will throw an `IndexOutOfBoundsException`.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 声明的函数字段数量必须与函数发出的值的数量对齐。如果它们不对齐，Storm将抛出`IndexOutOfBoundsException`。
- en: 'The next function in our topology, `HourAssignment`, is used to convert the
    timestamp into an hour since epoch, which can then be used to group occurrences
    temporally. The code for `HourAssignment` looks as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拓扑中的下一个函数`HourAssignment`用于将时间戳转换为自纪元以来的小时，然后可以用于在时间上对事件进行分组。`HourAssignment`的代码如下：
- en: '[PRE15]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We overload this function slightly by emitting both the *hours* as well as a
    composite key comprising the city, diagnosis code, and the hour. Effectively,
    this acts as a unique identifier for each aggregate count, which we will discuss
    more in detail.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过发出*小时*以及由城市、诊断代码和小时组成的复合键来略微重载此函数。实际上，这充当了每个聚合计数的唯一标识符，我们将在详细讨论。
- en: 'The final two functions in our topology detect the outbreak and alert us about
    it. The code for the `OutbreakDetector` class is as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拓扑中的最后两个函数检测爆发并通知我们。`OutbreakDetector`类的代码如下：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This function extracts the count for the specific city, disease, and hour and
    sees if it has exceeded the threshold. If it has, it emits a new field that contains
    an alert. In the preceding code, notice that this function effectively acts as
    a filter but was implemented as a function because we wanted to add an additional
    field to the tuple that contains the alert. Since filters do not mutate the tuple,
    we must use a function that allows us to not only filter but also add new fields.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数提取特定城市、疾病和小时的计数，并查看是否超过了阈值。如果是，它会发出一个包含警报的新字段。在上述代码中，请注意，这个函数实际上充当了一个过滤器，但由于我们想要向包含警报的元组添加一个额外的字段，因此实现为函数。由于过滤器不会改变元组，我们必须使用一个允许我们不仅过滤而且添加新字段的函数。
- en: 'The final function in our topology simply dispatches the alert (and terminates
    the program). The listing for this topology is as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拓扑中的最后一个函数只是分发警报（并终止程序）。此拓扑的清单如下：
- en: '[PRE17]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This function is straightforward. It simply extracts the alert, logs the message,
    and terminates the program.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数很简单。它只是提取警报，记录消息，并终止程序。
- en: Introducing Trident aggregators – Combiners and Reducers
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Trident聚合器-组合器和减少器
- en: 'Akin to functions, **aggregators** allow topologies to combine tuples. Unlike
    functions, they replace tuple fields and values. There are three different types
    of aggregators: `CombinerAggregator`, `ReducerAggregator`, and `Aggregator`.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 与函数类似，**聚合器**允许拓扑结构组合元组。与函数不同，它们替换元组字段和值。有三种不同类型的聚合器：`CombinerAggregator`，`ReducerAggregator`和`Aggregator`。
- en: CombinerAggregator
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CombinerAggregator
- en: 'A `CombinerAggregator` is used to combine a set of tuples into a single field.
    It has the following signature:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`CombinerAggregator`用于将一组元组组合成一个单一字段。它具有以下签名：'
- en: '[PRE18]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Storm calls the `init()` method with each tuple, and then repeatedly calls the
    `combine()` method until the partition is processed. The values passed into the
    `combine()` method are partial aggregations, the result of combining the values
    returned by calls to `init()`. Partitions are discussed more in the following
    sessions, but a partition is effectively a subset of a stream of tuples that resides
    on the same host. After combing the values from processing the tuples, Storm emits
    the result of combining those values as a single new field. If a partition is
    empty, then Storm emits the value returned by the `zero()`method.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Storm对每个元组调用`init()`方法，然后重复调用`combine()`方法，直到分区被处理。传递到`combine()`方法的值是部分聚合，是通过调用`init()`返回的值的组合结果。分区将在后续会话中更详细地讨论，但分区实际上是流元组的子集，驻留在同一主机上。在处理元组的值后，Storm将组合这些值的结果作为单个新字段发出。如果分区为空，则Storm会发出`zero()`方法返回的值。
- en: ReducerAggregator
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReducerAggregator
- en: 'The `ReducerAggregator` has a slightly different signature:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`ReducerAggregator`具有稍微不同的签名：'
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Storm calls the `init()` method to retrieve the initial value. Then `reduce()`
    is called with each tuple until the partition is fully processed. The first parameter
    into the `reduce()` method is the cumulative partial aggregation. The implementation
    should return the result of incorporating the tuple into that partial aggregation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Storm调用`init()`方法来检索初始值。然后，对每个元组调用`reduce()`，直到分区完全处理。传递到`reduce()`方法的第一个参数是累积的部分聚合。实现应返回将元组合并到该部分聚合中的结果。
- en: Aggregator
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Aggregator
- en: 'The most general aggregation operation is the `Aggregator`. The signature for
    `Aggregator` is as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 最一般的聚合操作是`Aggregator`。`Aggregator`的签名如下：
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The `Aggregator` interface's `aggregate()` method is similar to the `execute()`
    method of a `Function` interface, but it also includes a parameter for the value.
    This allows the `Aggregator` to accumulate a value as it processes the tuples.
    Notice that with an `Aggregator`, since the collector is passed into both the
    `aggregate()` method as well as the `complete()` method, you can emit any arbitrary
    number of tuples.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`Aggregator`接口的`aggregate()`方法类似于`Function`接口的`execute()`方法，但它还包括一个值的参数。这允许`Aggregator`在处理元组时累积一个值。请注意，使用`Aggregator`，由于收集器被传递到`aggregate()`方法和`complete()`方法中，您可以发出任意数量的元组。'
- en: 'In our example topology, we leveraged a built-in aggregator named `Count`.
    The implementation for `Count` looks like the following code snippet:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例拓扑中，我们利用了一个名为`Count`的内置聚合器。`Count`的实现如下代码片段所示：
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We apply both grouping and counting in our example topology to count the occurrences
    of a disease during a specific hour near a particular city. The specific lines
    that accomplish this are as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例拓扑中，我们应用了分组和计数来计算特定城市附近特定小时内疾病发生的次数。实现这一目标的具体行为如下：
- en: '[PRE22]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Recall that Storm partitions the stream across the available hosts. This is
    shown in the following diagram:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，Storm将流分区到可用的主机上。这在下图中显示：
- en: '![Aggregator](img/8294OS_03_02.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![Aggregator](img/8294OS_03_02.jpg)'
- en: 'The `groupBy()` method forces a repartitioning of the data. It groups all the
    tuples that share the same value for the named field into the same partition.
    To do this, Storm must send the like tuples to the same host. The following diagram
    shows the repartitioning of the preceding data based on our `groupBy()` method:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`groupBy()`方法强制对数据进行重新分区。它将所有具有相同命名字段值的元组分组到同一分区中。为此，Storm必须将相似的元组发送到同一主机。以下图表显示了根据我们的`groupBy()`方法对前述数据进行的重新分区：'
- en: '![Aggregator](img/8294OS_03_03.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![聚合器](img/8294OS_03_03.jpg)'
- en: After repartitioning, the `aggregate` function is run on each group within each
    partition. In our example, we are grouping by city, hour, and disease code (using
    the key). Then, the `Count` aggregator is executed on each group, which in turn
    emits the occurrence count for downstream consumers.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 重新分区后，在每个分区内的每个组上运行`aggregate`函数。在我们的示例中，我们按城市、小时和疾病代码（使用键）进行分组。然后，在每个组上执行`Count`聚合器，进而为下游消费者发出发生次数。
- en: Introducing the Trident state
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入Trident状态
- en: 'Now that we have the counts for each aggregation, we want to persist with that
    information for further analysis. In Trident, persistence first starts with state
    management. Trident has a first-level primitive for state, but like the Storm
    API, it makes a few assumptions about what is being stored as state or how that
    state is persisted. At the highest level, Trident exposes a `State` interface
    as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经得到了每个聚合的计数，我们希望将该信息持久化以供进一步分析。在Trident中，持久化首先从状态管理开始。Trident具有一级状态的原始形式，但与Storm
    API一样，它对存储为状态或状态如何持久化做出了一些假设。在最高级别，Trident公开了一个`State`接口，如下所示：
- en: '[PRE23]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As mentioned previously, Trident groups tuples into batches. Each batch has
    its own transaction identifier. In the preceding interface, Trident informs the
    `State` object when the state is being committed and when the commit should complete.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Trident将元组分组为批处理。每个批处理都有自己的事务标识符。在前面的接口中，Trident在状态被提交时通知`State`对象，以及何时应完成提交。
- en: 'Like functions, there are methods on the `Stream` objects that introduce state-based
    operations into a topology. More specifically, there are two types of streams
    in Trident: `Stream` and `GroupedStream`. A `GroupedStream` is the result of performing
    a `groupBy` operation. In our topology, we group by the key generated by the `HourAssignment`
    function.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 与函数一样，在`Stream`对象上有一些方法将基于状态的操作引入拓扑。更具体地说，Trident中有两种类型的流：`Stream`和`GroupedStream`。`GroupedStream`是执行`groupBy`操作的结果。在我们的拓扑中，我们通过`HourAssignment`函数生成的键进行分组。
- en: 'On the `Stream` object, the following methods allow the topology to read and
    write state information:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Stream`对象上，以下方法允许拓扑读取和写入状态信息：
- en: '[PRE24]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `stateQuery()` method creates an input stream from state, and the various
    flavors of the `partitionPersist()` method allow a topology to update state information
    from tuples in a stream. The `partitionPersist()` method operates on each partition.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`stateQuery()`方法从状态创建输入流，`partitionPersist()`方法的各种变种允许拓扑从流中的元组更新状态信息。`partitionPersist()`方法在每个分区上操作。'
- en: 'In addition to the methods on the `Stream` object, the `GroupedStream` object
    allows a topology to aggregate statistics from a set of tuples and simultaneously
    persist with the collected information to state. The following are the state-related
    methods on a `GroupedStream` class:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`Stream`对象上的方法之外，`GroupedStream`对象允许拓扑从一组元组中聚合统计信息，并同时将收集到的信息持久化到状态。以下是`GroupedStream`类上与状态相关的方法：
- en: '[PRE25]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Like the base `Stream` object, the `stateQuery()` method creates an input stream
    from state. The various flavors of `persistAggregate()` allow a topology to update
    state information from tuples in a stream. Notice that the `GroupedStream` methods
    take an `Aggregator`, which it first applies before writing that information to
    the `State` object.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 像基本的`Stream`对象一样，`stateQuery()`方法从状态创建输入流。各种`persistAggregate()`的变种允许拓扑从流中的元组更新状态信息。请注意，`GroupedStream`方法采用`Aggregator`，它首先应用然后将信息写入`State`对象。
- en: 'Now let''s consider applying these functions to our example. In our system,
    we would like to persist with the occurrence counts by city, disease code, and
    hour. This would enable a report similar to the following table:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们考虑将这些函数应用到我们的示例中。在我们的系统中，我们希望按城市、疾病代码和小时持久化发生次数。这将使报告类似于以下表格：
- en: '| Disease | City | Date | Time | Occurrence Count |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 疾病 | 城市 | 日期 | 时间 | 发生次数 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Bacterial meningitis | San Francisco | 3/12/2013 | 3:00 PM | 12 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 细菌性脑膜炎 | 旧金山 | 2013年3月12日 | 下午3:00 | 12 |'
- en: '| Bacterial meningitis | San Francisco | 3/12/2013 | 4:00 PM | 50 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 细菌性脑膜炎 | 旧金山 | 2013年3月12日 | 下午4:00 | 50 |'
- en: '| Bacterial meningitis | San Francisco | 3/12/2013 | 5:00 PM | 100 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 细菌性脑膜炎 | 旧金山 | 2013年3月12日 | 下午5:00 | 100 |'
- en: '| Smallpox | New York | 3/13/2013 | 5:00 PM | 6 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 天花 | 纽约 | 2013年3月13日 | 下午5:00 | 6 |'
- en: 'To achieve this, we want to persist with the counts that we generate in the
    aggregation. We can use the `GroupedStream` interface (shown previously) returned
    by the `groupBy` function and call the `persistAggregate` method. Specifically,
    the following is the call we make in the example topology:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们希望持久化我们在聚合中生成的计数。我们可以使用`groupBy`函数返回的`GroupedStream`接口（如前所示），并调用`persistAggregate`方法。具体来说，以下是我们在示例拓扑中进行的调用：
- en: '[PRE26]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To understand persistence, we will first focus on the first parameter to this
    method. Trident uses a factory pattern to generate instances of `State`. The `OutbreakTrendFactory`
    is the factory our topology provides to Storm. The listing for `OutbreakTrendFactory`
    is as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解持久化，我们首先将关注此方法的第一个参数。Trident使用工厂模式生成`State`的实例。`OutbreakTrendFactory`是我们的拓扑提供给Storm的工厂。`OutbreakTrendFactory`的清单如下：
- en: '[PRE27]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The factory returns the `State` object that Storm uses to persist with information.
    In Storm, there are three types of state. Each type is described in the following
    table:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 工厂返回Storm用于持久化信息的`State`对象。在Storm中，有三种类型的状态。每种类型在下表中描述：
- en: '| **State type** | Description |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| **状态类型** | 描述 |'
- en: '| --- | --- |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Non-Transactional** | For persistence mechanisms that do not have rollback
    capabilities and where updates are permanent and commits are ignored. |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| **非事务性** | 对于没有回滚能力的持久性机制，更新是永久的，提交被忽略。 |'
- en: '| **Repeat Transactional** | For persistence that is idempotent, provided the
    batch contains the same tuples. |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| **重复事务** | 对于幂等性的持久性，只要批次包含相同的元组。 |'
- en: '| **Opaque Transactional** | Updates are based on the previous value, which
    makes the persistence resilient to changes in batch composition. |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| **不透明事务** | 更新基于先前的值，这使得持久性对批次组成的更改具有弹性。 |'
- en: To support counting and state updates in a distributed environment where batches
    can be replayed, Trident sequences state updates and uses different state update
    patterns to tolerate replays and faults. These are described in the following
    sections.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持在分布式环境中对批次进行重播的计数和状态更新，Trident 对状态更新进行排序，并使用不同的状态更新模式来容忍重播和故障。这些在以下部分中描述。
- en: The Repeat Transactional state
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重复事务状态
- en: For the Repeat Transactional state, the last committed batch identifier is stored
    with the data. The state is updated if and only if the batch identifier being
    applied is the next in sequence. If it is equal to or lower than the persisted
    identifier, then the update is ignored because it has already been applied.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 对于重复事务状态，最后提交的批处理标识符与数据一起存储。只有在应用的批处理标识符是下一个顺序时，状态才会更新。如果它等于或低于持久标识符，则更新将被忽略，因为它已经被应用过了。
- en: 'To illustrate this approach, consider the following sequence of batches where
    the state update is an aggregate count of the occurrences of that key as it is
    in our example:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这种方法，考虑以下批次序列，其中状态更新是该键出现次数的聚合计数，如我们的示例中所示：
- en: '| Batch # | State Update |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 批次 # | 状态更新 |'
- en: '| --- | --- |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | {SF:320:378911 = 4} |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 1 | {SF:320:378911 = 4} |'
- en: '| 2 | {SF:320:378911 = 10} |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 2 | {SF:320:378911 = 10} |'
- en: '| 3 | {SF:320:378911 = 8} |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 3 | {SF:320:378911 = 8} |'
- en: 'The batches then complete processing in the following order:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 然后批次按以下顺序完成处理：
- en: 1 à 2 à 3 à 3 (replayed)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 1 à 2 à 3 à 3 (重播)
- en: 'This would result in the following state modifications, where the middle column
    is the persistence of the batch identifier indicating the most recent batch incorporated
    in the state:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下状态修改，其中中间列是批次标识符的持久性，指示状态中最近合并的批次：
- en: '| Completed Batch # | State |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 完成的批次 # | 状态 |'
- en: '| --- | --- |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | { Batch = 1 } | { SF:320:378911 = 4 } |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 1 | { 批次 = 1 } | { SF:320:378911 = 4 } |'
- en: '| 2 | { Batch = 2 } | { SF:320:378911 = 14 } |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 2 | { 批次 = 2 } | { SF:320:378911 = 14 } |'
- en: '| 3 | { Batch = 3 } | { SF:320:378911 = 22 } |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 3 | { 批次 = 3 } | { SF:320:378911 = 22 } |'
- en: '| 3 (Replayed) | { Batch = 3 } | { SF:320:378911 = 22 } |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 3 (重播) | { 批次 = 3 } | { SF:320:378911 = 22 } |'
- en: 'Notice that when batch #3 completes the replay, it has no effect on the state
    because Trident has already incorporated its update in the state. For the Repeat
    Transactional state to function properly, batch contents cannot change between
    replays.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意，当批次 #3 完成重播时，它对状态没有影响，因为 Trident 已经在状态中合并了它的更新。为了使重复事务状态正常工作，批次内容在重播之间不能改变。'
- en: The Opaque state
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不透明状态
- en: The approach used in the Repeat Transactional state relies on the batch composition
    remaining constant, which may not be possible if a system encounters a fault.
    If the spout is emitting from a source that may have a partial failure, some of
    the tuples emitted in the initial batch might not be available for re-emission.
    The Opaque state allows the changing of batch composition by storing both current
    and previous states.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 重复事务状态所使用的方法依赖于批次组成保持不变，如果系统遇到故障，则可能不可能。如果喷口从可能存在部分故障的源发出，那么初始批次中发出的一些元组可能无法重新发出。不透明状态允许通过存储当前状态和先前状态来改变批次组成。
- en: 'Assume that we have the same batches as in the previous example, but this time
    when Batch 3 is replayed, the aggregate count will be different since it contains
    a different set of tuples as shown in the following table:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有与前面示例中相同的批次，但是这次当批次 3 重播时，聚合计数将不同，因为它包含了不同的元组集，如下表所示：
- en: '| Batch # | State update |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 批次 # | 状态更新 |'
- en: '| --- | --- |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | {SF:320:378911 = 4} |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 1 | {SF:320:378911 = 4} |'
- en: '| 2 | {SF:320:378911 = 10} |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 2 | {SF:320:378911 = 10} |'
- en: '| 3 | {SF:320:378911 = 8} |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 3 | {SF:320:378911 = 8} |'
- en: '| 3 (Replayed) | {SF:320:378911 = 6} |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 3 (重播) | {SF:320:378911 = 6} |'
- en: 'With Opaque state, the state would update as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不透明状态，状态将如下更新：
- en: '| Completed batch # | Batch committed | Previous state | Current state |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 完成的批次 # | 批次已提交 | 先前状态 | 当前状态 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1 | 1 | {} | { SF:320:378911 = 4 } |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | {} | { SF:320:378911 = 4 } |'
- en: '| 2 | 2 | { SF:320:378911 = 4 } | { SF:320:378911 = 14 } |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 2 | { SF:320:378911 = 4 } | { SF:320:378911 = 14 } |'
- en: '| 3 (Applies) | 3 | { SF:320:378911 = 14 } | { SF:320:378911 = 22 } |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 3 (应用) | 3 | { SF:320:378911 = 14 } | { SF:320:378911 = 22 } |'
- en: '| 3 (Replayed) | 3 | { SF:320:378911 = 14 } | { SF:320:378911 = 20 } |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 3 (重播) | 3 | { SF:320:378911 = 14 } | { SF:320:378911 = 20 } |'
- en: 'Notice that Opaque state stores the previous state information. Thus, when
    batch #3 is replayed, it can retransition the state using the new aggregate count.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意，不透明状态存储了先前的状态信息。因此，当批次 #3 被重播时，它可以使用新的聚合计数重新转换状态。'
- en: You may wonder why we would reapply the batch if it had already been committed.
    The scenario we are concerned with is one whereby the state update succeeded,
    but the downstream processing failed. In our example topology, perhaps the alert
    failed to dispatch. Under such circumstances, Trident would retry the batch. Now,
    in the worst-case scenario, when the spout was asked to re-emit the batch, one
    or more sources of data may be unavailable.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 也许你会想为什么我们会重新应用已经提交的批次。我们关心的情景是，状态更新成功，但下游处理失败。在我们的示例拓扑中，也许警报发送失败了。在这种情况下，Trident
    会重试批次。现在，在最坏的情况下，当喷口被要求重新发出批次时，一个或多个数据源可能不可用。
- en: In the case of a Transactional spout, it would need to wait until all the sources
    were again available. An Opaque Transactional spout would be able to emit the
    portion of the batch that was available, and processing could continue. Since
    Trident relies on sequential application of batches to state, it is imperative
    that no single batch be delayed, because that delays all processing in the system.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在Transactional spout的情况下，它需要等待直到所有的源再次可用。不透明的Transactional spout将能够发出可用的批次部分，处理可以继续进行。由于Trident依赖于对状态的批次的顺序应用，因此至关重要的是不要延迟任何一个批次，因为这会延迟系统中的所有处理。
- en: 'Given this approach, the choice of state should be based on the spout so as
    to guarantee idempotent behavior and not over-count or corrupt the state. The
    following table shows the possible pairings to guarantee idempotent behavior:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这种方法，状态的选择应该基于spout，以保证幂等行为，不会过度计数或损坏状态。以下表格显示了保证幂等行为的可能配对：
- en: '| Type of Spout | Non-Transactional state | Opaque State | Repeat Transactional
    state |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| Spout类型 | 非事务状态 | 不透明状态 | 重复事务状态 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Non-Transactional spout |   |   |   |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 非事务spout |   |   |   |'
- en: '| Opaque spout |   | X |   |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 不透明spout |   | X |   |'
- en: '| Transactional spout |   | X | X |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 事务spout |   | X | X |'
- en: 'Fortunately, Storm provides map implementations that shield the persistence
    layer from the complexities of the state management. Specifically, Trident provides
    `State` implementations that maintain the additional information to adhere to
    the guarantees outlined previously. The objects are named appropriately: `NonTransactionalMap`,
    `TransactionalMap`, and `OpaqueMap`.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Storm提供了地图实现，可以将持久性层屏蔽在状态管理的复杂性之外。具体来说，Trident提供了`State`实现，可以维护额外的信息，以遵守先前概述的保证。这些对象的命名很合适：`NonTransactionalMap`，`TransactionalMap`和`OpaqueMap`。
- en: Returning to our example, since we have no transactional guarantees, we chose
    to use a `NonTransactionalMap` as our `State` object.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的示例，由于我们没有事务保证，我们选择使用`NonTransactionalMap`作为我们的`State`对象。
- en: 'The `OutbreakTrendState` object looks like the following code snippet:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`OutbreakTrendState`对象如下代码片段所示：'
- en: '[PRE28]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'As shown in the preceding code, to leverage the `MapState` objects, we simply
    pass a backing map. In our example, this is the `OutbreakTrendBackingMap`. The
    code for that object is as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码所示，要利用`MapState`对象，我们只需传递一个支持映射。在我们的示例中，这是`OutbreakTrendBackingMap`。该对象的代码如下：
- en: '[PRE29]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In our example topology, we do not actually persist with the values. We simply
    put them in a `ConcurrentHashMap`. Obviously, that would not work across multiple
    hosts. The `BackingMap` is a clever abstraction, however. Simply changing the
    backing map instance that we pass into the constructor of the `MapState` object
    changes the persistence layer. We will see this in action in later chapters.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例拓扑中，我们实际上并不持久化值。我们只是把它们放在`ConcurrentHashMap`中。显然，这在多个主机上是行不通的。然而，`BackingMap`是一个巧妙的抽象。只需改变我们传递给`MapState`对象构造函数的支持映射实例，就可以改变持久性层。我们将在后面的章节中看到这一点。
- en: Executing the topology
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行拓扑
- en: 'The `OutbreakDetectionTopology` class has the following main method:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`OutbreakDetectionTopology`类有以下主要方法：'
- en: '[PRE30]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Executing this method will submit the topology to a local cluster. The spout
    will immediately start emitting diagnosis events, which the `Count` aggregator
    will collect. The threshold in the `OutbreakDetector` class is set such that the
    count will quickly exceed the threshold, at which point the program terminates
    with the following set of commands:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此方法将拓扑提交到本地集群。spout将立即开始发出诊断事件，`Count`聚合器将收集。`OutbreakDetector`类中的阈值设置得很快就会超过阈值，此时程序将终止，并显示以下一系列命令：
- en: '[PRE31]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Notice that the coordinator is notified upon successful completion of the batches,
    and within a few batches, the threshold is exceeded, and the system instructs
    us with an error message, `Dispatch the National Guard!`.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，协调器在批次成功完成时会收到通知，几个批次后，阈值被超过，系统会用错误消息`Dispatch the National Guard!`指示我们。
- en: Summary
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we created a topology that processes diagnosis information
    to identify anomalies, which would indicate an outbreak. This same data flow could
    be applied to any type of data, including weather, seismic information, or traffic
    data. We exercised the fundamental primitives in Trident to construct a system
    that is capable of counting events even if batches are replayed. Later on in this
    book, we will leverage these same constructs and patterns to perform similar functions.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们创建了一个拓扑，处理诊断信息以识别异常情况，这可能表明有疫情爆发。这些相同的数据流可以应用于任何类型的数据，包括天气、地震信息或交通数据。我们运用了Trident中的基本原语来构建一个系统，即使批次被重放，也能够计数事件。在本书的后面，我们将利用这些相同的结构和模式来执行类似的功能。
