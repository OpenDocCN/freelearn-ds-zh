- en: '*Chapter 3*: Pachyderm Pipeline Specification'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 3 章*：象皮管道规范'
- en: A **Machine Learning** (**ML**) pipeline is an automated workflow that enables
    you to execute the same code continuously against different combinations of data
    and parameters. A pipeline ensures that every cycle is automated and goes through
    the same sequence of steps. Like in many other technologies, in Pachyderm, an
    ML pipeline is defined by a single configuration file called the pipeline specification,
    or the pipeline spec.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）管道是一个自动化工作流，它使你能够对不同的数据和参数组合持续执行相同的代码。管道确保每个周期都是自动化的，并且按照相同的步骤顺序执行。在许多其他技术中，像在
    Pachyderm 中，机器学习管道是通过一个叫做管道规范（pipeline spec）的配置文件定义的。'
- en: The **Pachyderm pipeline specification** is the most important configuration
    in Pachyderm as it defines what your pipeline does, how often it runs, how the
    work is spread across Pachyderm workers, and where to output the result.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pachyderm 管道规范**是 Pachyderm 中最重要的配置，因为它定义了你的管道执行的任务、执行频率、工作如何分配给 Pachyderm
    工作节点，以及结果输出的地点。'
- en: 'This chapter is intended as a pipeline specification reference and will walk
    you through all the parameters you can specify for your pipeline. To do this,
    we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在作为管道规范参考，并将带你了解你可以为管道指定的所有参数。为此，我们将讨论以下主题：
- en: Pipeline specification overview
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管道规范概述
- en: Understanding inputs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解输入
- en: Exploring informational parameters
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索信息参数
- en: Exploring transformation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索转换
- en: Optimizing your pipeline
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化你的管道
- en: Exploring service parameters
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索服务参数
- en: Exploring output parameters
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索输出参数
- en: Pipeline specification overview
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道规范概述
- en: 'Typically, when you conduct an ML experiment, it involves multiple sequential
    steps. In the simplest scenario, your pipeline takes input from an input repository,
    applies your transformation code, and outputs the result in the output repository.
    For example, you may have a set of images to apply a monochrome filter to and
    then output the result in an output repository that goes by the same name as the
    pipeline. This workflow performs only one operation and can be called a **one-step
    pipeline**, or one-step workflow. A diagram for such a pipeline would look like
    this:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当你进行机器学习实验时，涉及多个顺序步骤。在最简单的场景下，你的管道从输入仓库获取输入，应用你的转换代码，并将结果输出到输出仓库。例如，你可能有一组图片，要应用单色滤镜，然后将结果输出到一个与管道同名的输出仓库。这个工作流仅执行一个操作，可以称为**单步管道**，或者单步工作流。这样管道的图示可能如下所示：
- en: '![Figure 3.1 – One-step workflow'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1 – 单步工作流'
- en: '](img/B17085_03_001.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17085_03_001.jpg)'
- en: Figure 3.1 – One-step workflow
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – 单步工作流
- en: 'The specification for this simple pipeline, in YAML format, would look like
    this:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单管道的规范，采用 YAML 格式，看起来会像这样：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This is the simplest pipeline specification that you can create. It must include
    the following parameters:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你可以创建的最简单的管道规范。它必须包含以下参数：
- en: '`name`: A descriptive name for your pipeline. Often, the name of the pipeline
    describes a step in your ML workflow. For example, if this pipeline applies a
    photo filter to your images, you can call it `apply-photo-filter`. Alternatively,
    if it validates your model, you could call it `cross-validation`.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：为你的管道指定一个描述性的名称。通常，管道的名称描述了机器学习工作流中的某个步骤。例如，如果这个管道对你的图片应用滤镜，你可以称它为 `apply-photo-filter`。或者，如果它进行模型验证，你可以称它为
    `cross-validation`。'
- en: '`transform`: This parameter includes your transformation code, which can be
    specified as a reference to a file or directly inline. We will discuss this parameter
    in more detail in the next section.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transform`：此参数包括你的转换代码，可以作为对文件的引用或直接内联指定。我们将在下一节详细讨论这个参数。'
- en: '`input`: This parameter refers to an existing input repository where the files
    for the pipeline are located. `input` is a filesystem inside your pipeline worker
    under the `pfs/` directory. For example, if your repository is called `photos`,
    it is stored under `pfs/photos` on your pipeline worker. Output repositories are
    created automatically by the pipeline and stored under `pfs/out`. All output repositories
    have the same name as the pipeline. For example, if your pipeline is called `apply-photo-filter`,
    the output repository will be stored as `apply-photo-filter` in `pfs/out/`.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input`：该参数指的是一个现有的输入仓库，文件位于该仓库中以供流水线使用。`input` 是你流水线工作节点下的一个文件系统，位于 `pfs/`
    目录下。例如，如果你的仓库名为 `photos`，它会存储在工作节点的 `pfs/photos` 下。输出仓库由流水线自动创建，并存储在 `pfs/out`
    下。所有输出仓库的名称与流水线名称相同。例如，如果你的流水线名为 `apply-photo-filter`，那么输出仓库会存储为 `apply-photo-filter`，位置在
    `pfs/out/`。'
- en: 'This is a very simple example of a pipeline. In a more realistic use case,
    you would likely have more than one pipeline step. In a typical ML pipeline, you
    need to perform pre-processing, training, and cross-validation steps, among others.
    When you have multiple pipelines chained together, this is called a **multi-step
    workflow**. For example, if you are creating an NLP pipeline, your pipeline may
    have the following structure:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单的流水线示例。在更现实的应用场景中，通常会有多个流水线步骤。在典型的机器学习流水线中，你需要执行数据预处理、训练、交叉验证等步骤。当多个流水线串联在一起时，这被称为
    **多步骤工作流**。例如，如果你正在创建一个自然语言处理（NLP）流水线，可能会有如下结构：
- en: '![Figure 3.2 – Multi-step workflow'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.2 – 多步骤工作流'
- en: '](img/B17085_03_002.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17085_03_002.jpg)'
- en: Figure 3.2 – Multi-step workflow
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – 多步骤工作流
- en: In the preceding diagram, each pipeline has a pipeline specification with a
    name, input repository, transformation code, and other parameters defined.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示意图中，每个流水线都有一个流水线规范，定义了名称、输入仓库、转换代码以及其他参数。
- en: All pipeline specifications must be written in **YAML Ain't Markup Language**
    (**YAML**) or **JavaScript Object Notation** (**JSON**) format. These formats
    are easy for people to read and write and are widely used in various configuration
    files in the industry. It is easier to write in than **Extensible Markup Language**
    (**XML**) or other similar formats.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所有流水线规范必须以 **YAML Ain't Markup Language**（**YAML**）或 **JavaScript Object Notation**（**JSON**）格式编写。这些格式便于人类阅读和编写，并广泛应用于各类行业中的配置文件中。它比
    **可扩展标记语言**（**XML**）或其他类似格式更容易编写。
- en: Now that we have reviewed the minimum pipeline specification and have looked
    at a more realistic example, let's review the other parameters that you can specify.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经回顾了最基本的流水线规范，并查看了一个更现实的示例，让我们来回顾一下你可以指定的其他参数。
- en: Understanding inputs
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解输入
- en: 'We described inputs in [*Chapter 2*](B17085_02_Final_SB_Epub.xhtml#_idTextAnchor037),
    *Pachyderm Basics*, in detail by providing examples. Therefore, in this section,
    we''ll just mention that inputs define the type of your pipeline. You can specify
    the following types of Pachyderm inputs:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[*第 2 章*](B17085_02_Final_SB_Epub.xhtml#_idTextAnchor037)《Pachyderm 基础》一章中详细描述了输入，并提供了示例。因此，在本节中，我们只会提到输入定义了流水线的类型。你可以指定以下几种类型的
    Pachyderm 输入：
- en: '**PFS** is a generic parameter that defines a standard pipeline and inputs
    in all multi-input pipelines.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PFS** 是一个通用参数，用于定义所有多输入流水线中的标准流水线和输入。'
- en: '**Cross** is an input that creates a cross-product of the datums from two input
    repositories. The resulting output will include all possible combinations of all
    datums from the input repositories.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cross** 是一种输入，它创建两个输入仓库中数据项的笛卡尔积。生成的输出将包含来自输入仓库的所有数据项的所有可能组合。'
- en: '**Union** is an input that adds datums from one repository to the datums in
    another repository.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Union** 是一种输入，它将一个仓库中的数据项添加到另一个仓库的数据项中。'
- en: '**Join** is an input that matches datums with a specific naming pattern.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Join** 是一种输入，它将具有特定命名模式的数据项匹配起来。'
- en: '**Spout** is an input that consumes data from a third-party source and adds
    it to the Pachyderm filesystem for further processing.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spout** 是一种输入，它从第三方来源获取数据，并将数据添加到 Pachyderm 文件系统中以供进一步处理。'
- en: '**Group** is an input that combines datums from multiple repositories based
    on a configured naming pattern.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Group** 是一种输入，它根据配置的命名模式将来自多个仓库的数据项组合在一起。'
- en: '**Cron** is a pipeline that runs according to a specified time interval.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cron** 是一种根据指定时间间隔运行的流水线。'
- en: '**Git** is an input that enables you to ingest data from a Git repository.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Git** 是一种输入，可以让你从 Git 仓库中导入数据。'
- en: For all inputs except for Cron and Git, you can define a `pfs` parameter that
    defines the input.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于除 Cron 和 Git 外的所有输入，你可以定义一个 `pfs` 参数来定义输入。
- en: pfs
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: pfs
- en: The `pfs` parameter, which stands for `pfs` inputs. You need to define one or
    multiple `pfs` inputs for all pipelines, except for Cron and Git.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`pfs` 参数，代表 `pfs` 输入。你需要为所有管道定义一个或多个 `pfs` 输入，除了 Cron 和 Git。'
- en: 'Here are the sub-parameters of the `pfs` input:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 `pfs` 输入的子参数：
- en: '`name`: The name of your pipeline.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：管道的名称。'
- en: '`repo`: A Pachyderm input repository where the data is stored.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo`：一个 Pachyderm 输入库，数据存储在此处。'
- en: '`branch`: A branch in the Pachyderm input repository where the data is stored.
    Often, this will be the `master` branch.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`branch`：Pachyderm 输入库中的一个分支，数据存储在此分支中。通常，这将是 `master` 分支。'
- en: '`glob`: A parameter that defines how to break the data into chunks for processing.
    You can read more about the `glob` parameter in the *Datums* section of [*Chapter
    2*](B17085_02_Final_SB_Epub.xhtml#_idTextAnchor037), *Pachyderm Basics*.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`glob`：一个定义如何将数据分块进行处理的参数。你可以在 [*第 2 章*](B17085_02_Final_SB_Epub.xhtml#_idTextAnchor037)，*Pachyderm
    基础知识* 中的 *Datums* 部分阅读更多关于 `glob` 参数的内容。'
- en: '`lazy`: A parameter that enables slower, less aggressive data downloading on
    a pipeline. The `lazy` parameter is useful when you need to look into a subset
    of your data.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lazy`：一个启用较慢、较不激进数据下载的参数。`lazy` 参数在你需要查看数据的一个子集时非常有用。'
- en: '`s3`: This parameter defines whether to include an S3 gateway sidecar on the
    pipeline. When you integrate with third-party applications through the S3 gateway,
    this ensures that the pipeline''s provenance is preserved.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s3`：这个参数定义是否在管道中包含 S3 网关 sidecar。当你通过 S3 网关与第三方应用集成时，它确保管道的来源信息被保留。'
- en: You can read more about the types of pipelines and inputs and view example pipelines
    in [*Chapter 2*](B17085_02_Final_SB_Epub.xhtml#_idTextAnchor037), *Pachyderm Basics*.
    The next section describes informational parameters that you can define for your
    pipeline.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [*第 2 章*](B17085_02_Final_SB_Epub.xhtml#_idTextAnchor037)，*Pachyderm 基础知识*
    中阅读更多关于管道和输入类型的信息，并查看示例管道。接下来的部分描述了可以为管道定义的信息性参数。
- en: Exploring informational parameters
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索信息性参数
- en: Pipeline informational parameters define basic information about the pipeline.
    Out of all of them, only the `name` parameter is required in any pipeline specification.
    All other parameters are optional and can be omitted. Let's look at these parameters
    in more detail.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 管道信息性参数定义了管道的基本信息。在所有这些参数中，只有 `name` 参数是任何管道规范中必需的。其他所有参数都是可选的，可以省略。让我们更详细地了解这些参数。
- en: name
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: name
- en: The `name` parameter is the descriptive name of your pipeline. Typically, you
    want to name a pipeline after the type of transformation it performs. For example,
    if your pipeline performs image classification, you may want to call it `image-classification`.
    A pipeline name must consist of alphanumeric characters, dashes, and underscores,
    and cannot exceed 63 symbols.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`name` 参数是管道的描述性名称。通常，你会根据管道执行的变换类型来命名管道。例如，如果你的管道执行图像分类，你可能想将其命名为 `image-classification`。管道名称必须由字母数字字符、短横线和下划线组成，并且不能超过
    63 个符号。'
- en: 'The following is an example of the `name` parameter in YAML format:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 `name` 参数的 YAML 格式示例：
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following is an example of the `name` parameter in JSON format:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 `name` 参数的 JSON 格式示例：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next, let's look at the `description` parameter.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来看看 `description` 参数。
- en: description
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: description
- en: 'The `description` parameter provides additional information about the pipeline.
    Although it is an optional parameter, it is good practice to add a short description
    to your pipeline. For example, if your pipeline performs image classification,
    you can add the following description: *A pipeline that performs image classification
    by using scikit-learn*.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`description` 参数提供关于管道的附加信息。虽然它是一个可选参数，但最好为你的管道添加一个简短的描述。例如，如果你的管道执行图像分类，你可以添加以下描述：*一个使用
    scikit-learn 进行图像分类的管道*。'
- en: 'The following is an example of the `description` parameter in YAML format:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 `description` 参数的 YAML 格式示例：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following is an example of the `description` parameter in JSON format:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 `description` 参数的 JSON 格式示例：
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Next, let's learn about `metadata`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们了解一下 `metadata`。
- en: metadata
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: metadata
- en: The `metadata` parameter enables you to specify Kubernetes labels or annotations.
    Labels are typically used to group Kubernetes objects into some sort of category
    and help simplify the management of those objects. Labels can be queried to display
    objects of the same type.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`metadata` 参数使您能够指定 Kubernetes 标签或注释。标签通常用于将 Kubernetes 对象分组到某种类别中，帮助简化这些对象的管理。标签可以查询以显示相同类型的对象。'
- en: Annotations, on the other hand, can be used to specify any random key-value
    pairs that are not defined within Kubernetes and could be used by external applications.
    You can use annotations to define the type of service, but things such as `pach_patch`
    or `pach_spec` instead. Multiple labels and annotations can be specified in each
    pipeline specification.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 注释则可以用来指定 Kubernetes 中未定义的任何随机键值对，这些键值对可以供外部应用程序使用。您可以使用注释来定义服务的类型，例如 `pach_patch`
    或 `pach_spec`。在每个流水线规范中，可以指定多个标签和注释。
- en: 'Here is an example of how to specify annotations in YAML format:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个如何在 YAML 格式中指定注释的示例：
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following example shows how to specify annotations in JSON format:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了如何在 JSON 格式中指定注释：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following example shows how to specify labels in YAML format:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了如何在 YAML 格式中指定标签：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, the following example shows how to specify labels in JSON format:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，以下示例展示了如何在 JSON 格式中指定标签：
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now that we've learned about the informational parameters, let's look at the
    `transformation` section of the Pachyderm pipeline.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了信息性参数，让我们看看 Pachyderm 流水线中的 `transformation` 部分。
- en: Exploring transformation
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索转换
- en: The `transformation` section is where you define your pipeline transformation
    code. It is the core of your pipeline's functionality. Most pipelines, unless
    they are a connector between two pipelines or a pipeline that exports results
    outside of Pachyderm, must have a `transformation` section.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformation` 部分是您定义流水线转换代码的地方。它是流水线功能的核心。除非是两个流水线之间的连接器，或者是将结果导出到 Pachyderm
    外部的流水线，大多数流水线都必须具有 `transformation` 部分。'
- en: The most important parameters of a transformation section – and the ones that
    are most commonly used – are `image` and `cmd` or `stdin`, `env`, and `secrets`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformation` 部分最重要的参数——也是最常用的——是 `image` 和 `cmd` 或 `stdin`、`env` 和 `secrets`。'
- en: Let's look at these parameters in more detail.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这些参数。
- en: image
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: image
- en: The `image` parameter defines a Docker image that your pipeline will run. A
    Docker image contains information about the environment in your pipeline container.
    For example, if you are running Python code, you will need to have some version
    of Python in your pipeline image. There are many publicly available containers
    that you can use for your pipeline.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`image` 参数定义了一个 Docker 镜像，您的流水线将在其中运行。一个 Docker 镜像包含了流水线容器中环境的相关信息。例如，如果您运行
    Python 代码，您需要在流水线镜像中包含某个版本的 Python。您可以使用许多公开可用的容器来构建您的流水线。'
- en: You can also include your scripts in that container. Unless your code is just
    a Bash script that can be specified through the `stdin` parameter inline, you
    will likely need to build your own Docker image, include your code in that image,
    and store it in a public or private container registry. Docker images are built
    from a `Dockerfile`, which describes the container environment and what you can
    run in the container. You can read more about Docker images at [https://docs.docker.com/](https://docs.docker.com/).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在该容器中包含您的脚本。除非您的代码只是一个可以通过 `stdin` 参数内联指定的 Bash 脚本，否则您可能需要构建自己的 Docker 镜像，将代码包含在镜像中，并将其存储在公共或私有容器注册表中。Docker
    镜像是通过 `Dockerfile` 构建的，`Dockerfile` 描述了容器环境以及您可以在容器中运行的内容。您可以在 [https://docs.docker.com/](https://docs.docker.com/)
    阅读更多关于 Docker 镜像的信息。
- en: Important note
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Do not use the Docker `CMD` instruction; instead, use `RUN`. The `CMD` instruction
    will fail.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 不要使用 Docker 的 `CMD` 指令；请改用 `RUN`。`CMD` 指令会失败。
- en: 'The following code shows how to specify a Docker `image` in YAML format:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 YAML 格式中指定 Docker `image`：
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following code shows how to specify a Docker `image` in JSON format:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 JSON 格式中指定 Docker `image`：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: However, just specifying a Docker image is not enough. You must define what
    to run, either through the `cmd` or `stdin` parameter.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅仅指定 Docker 镜像是不够的。您必须定义要运行的内容，可以通过 `cmd` 或 `stdin` 参数来实现。
- en: cmd
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: cmd
- en: The `cmd` parameter defines the code that the pipeline will run against your
    data. There is a lot of flexibility around what you can put in the `cmd` line.
    Typically, you want to specify the type of command you want to run, such as `python`,
    or set it to run a command-line shell, such as `sh`) or `bash`), and then specify
    the list of commands that you want to run in the `stdin` parameter.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`cmd`参数定义了管道将对数据运行的代码。你可以在`cmd`行中做很多灵活的配置。通常，你会指定要运行的命令类型，例如`python`，或者设置它运行命令行
    shell，例如`sh`或`bash`，然后在`stdin`参数中指定你想要运行的命令列表。'
- en: There is no difference or preference between the two approaches. The only difference
    is that if you specify a file in the `cmd` parameter, you will need to build a
    Docker image and include that file in the image.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法没有区别或优先之分。唯一的区别是，如果你在`cmd`参数中指定了文件，你需要构建一个 Docker 镜像并将该文件包含在镜像中。
- en: 'For example, if you have a Python 3 file that contains the code that you want
    to run against your data, you can specify it like this in YAML format:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你有一个 Python 3 文件，包含你希望在数据上运行的代码，你可以在 YAML 格式中像这样指定它：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Alternatively, you can specify labels in JSON format:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，你可以在 JSON 格式中指定标签：
- en: '[PRE12]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'However, if you want to specify your commands inline in the `stdin` parameter,
    just have the format specified in the `cmd` parameter like this, in YAML format:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你想在`stdin`参数中内联指定命令，只需按照`cmd`参数中指定的格式，如此，在 YAML 格式中：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You can do the same in JSON format:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用 JSON 格式来实现相同的功能：
- en: '[PRE14]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: See the *stdin* section for examples of how you can specify your inline code.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅*stdin*部分，了解如何指定内联代码的示例。
- en: Your `cmd` field can get even more complex than that, however. For example,
    you can specify a script inside the `cmd` parameter.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你的`cmd`字段可能会更复杂。例如，你可以在`cmd`参数中指定一个脚本。
- en: 'The following text is an example of the syntax you can use in the `cmd` field
    in YAML format:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下文本是你可以在 YAML 格式的`cmd`字段中使用的语法示例：
- en: '[PRE15]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The following text is an example of the syntax you can use in the `cmd` field
    in JSON format:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下文本是你可以在 JSON 格式的`cmd`字段中使用的语法示例：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Next, let's review the `stdin` parameter.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们回顾一下`stdin`参数。
- en: stdin
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: stdin
- en: The `stdin` parameter is similar to the UNIX standard input (`stdin`), and it
    enables communication between the Pachyderm environment and the pipeline worker.
    This means that you can put a code in the format specified in the `cmd` command
    inline in the `stdin` field. You could also specify paths to your code files as
    well, similar to the `cmd` parameter.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`stdin`参数类似于 UNIX 标准输入（`stdin`），它使 Pachyderm 环境与管道工作者之间能够进行通信。这意味着你可以在`stdin`字段中按`cmd`命令指定的格式插入代码。你也可以像`cmd`参数一样指定代码文件的路径。'
- en: This method does not require you to build a Docker image and allows you to configure
    your pipeline entirely through the pipeline specification. If you are unfamiliar
    with the Docker image-building process, this approach may feel more appealing.
    However, for more complex pipelines, you likely want to save your scripts in files,
    build Docker images, and use them in your pipeline.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法不需要你构建 Docker 镜像，允许你通过管道规范完全配置管道。如果你对 Docker 镜像构建过程不熟悉，这种方法可能更具吸引力。然而，对于更复杂的管道，你可能希望将脚本保存为文件，构建
    Docker 镜像，并在管道中使用它们。
- en: 'The following code shows the syntax you can use in the `stdin` field in YAML
    format:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了你可以在 YAML 格式的`stdin`字段中使用的语法：
- en: '[PRE17]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following is an example of the syntax you can use in the `stdin` field
    in JSON format:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是你可以在 JSON 格式的`stdin`字段中使用的语法示例：
- en: '[PRE18]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Because the preceding examples do not reference any files, you do not need to
    build a specific Docker image for them and include the file in there.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 由于前面的示例没有引用任何文件，你不需要为它们构建特定的 Docker 镜像并将文件包含在内。
- en: However, if you do reference any files or any environment prerequisites that
    are even slightly more complex than Bash, you likely need a Docker image. For
    example, if you have a `my-script.py` file that contains your code, you need to
    build a Docker image that will include that script, and you must reference it
    in your pipeline specification.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你引用了任何文件或任何比 Bash 稍微复杂的环境先决条件，你可能需要一个 Docker 镜像。例如，如果你有一个包含代码的`my-script.py`文件，你需要构建一个
    Docker 镜像，包含该脚本，并且你必须在管道规范中引用它。
- en: err_cmd
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: err_cmd
- en: 'The `err_cmd` parameter enables you to define how Pachyderm handles failed
    datums and ultimately allows you to treat failed datums as non-critical errors,
    allowing a job with failed datums to succeed and trigger the next job only with
    the healthy datums. `err_cmd` does not write any data to the output repo. The
    `err_cmd` field is often used in combination with the `err_stdin` field, where
    you specify the actual error code, though you could also refer to a file with
    your error code. If you want your pipeline to succeed even when the job contains
    failed datums, you can simply set `"err_cmd": true`.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`err_cmd`参数使您能够定义 Pachyderm 如何处理失败的数据项，并最终允许您将失败的数据项视为非关键错误，从而允许包含失败数据项的作业成功，并仅使用健康数据项触发下一个作业。`err_cmd`不会将任何数据写入输出仓库。`err_cmd`字段通常与`err_stdin`字段结合使用，您可以在其中指定实际的错误代码，尽管您也可以引用包含错误代码的文件。如果您希望即使作业包含失败的数据项，您的管道仍然成功，您只需设置`"err_cmd":
    true`。'
- en: 'The following is the syntax you can use in the `err_cmd` field in YAML format:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是您可以在`err_cmd`字段中使用的语法，格式为 YAML：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following is the syntax you can use in the `err_cmd` field in JSON format:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是您可以在`err_cmd`字段中使用的语法，格式为 JSON：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We will look at an example of how to use `err_cmd` in combination with `err_stdin`
    in the next section.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将查看如何将`err_cmd`与`err_stdin`结合使用的示例。
- en: err_stdin
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: err_stdin
- en: The `err_stdin` parameter is used in combination with the `err_cmd` parameter
    to specify the error code to run against failed datums. Similar to the `stdin`
    parameter, you can specify inline code to handle failed datums. For example, you
    may want to check if a datum is in a specific directory, and if it is, mark the
    datum as failed. Typically, you can just write a simple Bash script with an `if…
    then` condition to handle this.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`err_stdin`参数与`err_cmd`参数结合使用，用于指定针对失败数据项运行的错误代码。类似于`stdin`参数，您可以指定内联代码来处理失败的数据项。例如，您可能希望检查数据项是否位于特定目录中，如果是，则将该数据项标记为失败。通常，您可以编写一个简单的
    Bash 脚本，使用`if… then`条件来处理此问题。'
- en: 'The following code shows the syntax you can use in `err_stdin` with the `err_cmd`
    field in YAML format:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了您可以在`err_stdin`与`err_cmd`字段中结合使用的语法，格式为 YAML：
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following code shows the syntax you can use in `err_stdin` with the `err_cmd`
    field in JSON format:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了您可以在`err_stdin`与`err_cmd`字段中结合使用的语法，格式为 JSON：
- en: '[PRE22]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Next, let's learn about the `env` parameter.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们了解`env`参数。
- en: env
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: env
- en: The `env` parameter enables you to specify Pachyderm the environment variables
    and arbitrary variables that you need to communicate with other third-party tools.
    These parameters may include paths to directories and files, hostnames and ports,
    secret access keys, various identifiers, and many others.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`env`参数使您能够指定 Pachyderm 环境变量和您需要与其他第三方工具通信的任意变量。这些参数可以包括目录和文件路径、主机名和端口、密钥访问、各种标识符等。'
- en: Pachyderm variables can be included as well. For example, you can use the `LOG_LEVEL`
    environment variable to specify the verbosity of your log messages for `pachd`.
    As another example, you can also specify an AWS region and a bucket in the `env`
    field.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以包含 Pachyderm 变量。例如，您可以使用`LOG_LEVEL`环境变量来指定`pachd`的日志消息详细程度。另一个例子是，您还可以在`env`字段中指定
    AWS 区域和桶。
- en: 'The following code shows the syntax you can use in the `env` field in YAML
    format:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了您可以在`env`字段中使用的语法，格式为 YAML：
- en: '[PRE23]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following code shows the syntax you can use in the `env` field in JSON
    format:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了您可以在`env`字段中使用的语法，格式为 JSON：
- en: '[PRE24]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: For a complete list of Pachyderm variables, see the Pachyderm documentation
    at [https://docs.pachyderm.com/latest/deploy-manage/deploy/environment-variables/](https://docs.pachyderm.com/latest/deploy-manage/deploy/environment-variables/).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 Pachyderm 变量的完整列表，请参阅 Pachyderm 文档：[https://docs.pachyderm.com/latest/deploy-manage/deploy/environment-variables/](https://docs.pachyderm.com/latest/deploy-manage/deploy/environment-variables/)。
- en: secrets
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: secrets
- en: The `secrets` field enables you to specify Kubernetes secrets, which include
    sensitive information. This can include passwords or SSH public keys. You need
    to define a secret by either using the `env_var` and `key` parameters or the `mount_point`
    parameter.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`secrets`字段使您能够指定 Kubernetes 密钥，这些密钥包含敏感信息，如密码或 SSH 公钥。您需要通过使用`env_var`和`key`参数或`mount_point`参数来定义一个密钥。'
- en: 'The following code shows the syntax you can use in the `name` and `mount_path`
    fields to set the path to the `secrets` file in YAML format:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了您可以在`name`和`mount_path`字段中使用的语法，以设置`secrets`文件的路径，格式为 YAML：
- en: '[PRE25]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following code shows how to specify these parameters in JSON format:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何以JSON格式指定这些参数：
- en: '[PRE26]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The following code shows the syntax you can use in the `env_var` and `key`
    parameters to set secrets in YAML format:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了你可以在`env_var`和`key`参数中使用的语法，用于以YAML格式设置秘密：
- en: '[PRE27]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here is how to do the same in JSON format:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何以JSON格式执行相同操作：
- en: '[PRE28]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Next, let's learn about `image_pull_secrets`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来了解一下`image_pull_secrets`。
- en: image_pull_secrets
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: image_pull_secrets
- en: The `image_pull_secrets` parameter enables you to configure your Pachyderm pipeline
    to pull images from a private Docker registry. To specify this parameter, you
    need to create a Kubernetes secret with a Docker config, as described in the Kubernetes
    documentation at https://kubernetes.io/docs/concepts/containers/images/#creating-a-secret-with-a-docker-config,
    and then specify the secret in the pipeline specification under the `image_pull_secrets`
    parameter. You will need to use a full path to the Docker image for the pipeline
    to pull the image correctly.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`image_pull_secrets`参数使你能够配置Pachyderm管道，从私人Docker注册表拉取镜像。要指定此参数，你需要创建一个带有Docker配置的Kubernetes秘密，具体描述请参见Kubernetes文档：https://kubernetes.io/docs/concepts/containers/images/#creating-a-secret-with-a-docker-config，然后在管道规范中的`image_pull_secrets`参数下指定该秘密。你需要使用Docker镜像的完整路径，以确保管道能够正确拉取镜像。'
- en: 'The following code shows the syntax you can use in the `image_pull_secrets`
    parameter to enable the pipeline to pull images from a private Docker registry
    in YAML format:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了你可以在`image_pull_secrets`参数中使用的语法，用于启用管道从私人Docker注册表拉取镜像的YAML格式：
- en: '[PRE29]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This is how you would write the same in JSON format:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何以JSON格式编写相同内容：
- en: '[PRE30]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The next parameter that we will review is `accept_return_code`.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将审查的参数是`accept_return_code`。
- en: accept_return_code
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: accept_return_code
- en: The `accept_return_code` parameter enables you to specify an array of integers
    that define error codes that your pipeline will still be considered successful
    with. You can use this functionality in cases where you want your code to succeed,
    even if some part of it failed. This parameter is similar to the `err_cmd` functionality.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`accept_return_code`参数使你能够指定一个整数数组，定义管道仍然被视为成功的错误代码。你可以在希望即使某部分失败，代码仍然成功的情况下使用此功能。这个参数类似于`err_cmd`功能。'
- en: 'The following code shows the syntax you can use in the `accept_return_code`
    parameter to specify error codes in YAML format:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了你可以在`accept_return_code`参数中使用的语法，用于以YAML格式指定错误代码：
- en: '[PRE31]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Here is the same example in JSON format:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是以JSON格式的相同示例：
- en: '[PRE32]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The next parameter we will look at is `debug`.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看的参数是`debug`。
- en: debug
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: debug
- en: The `debug` parameter enables you to set the verbosity of the pipeline's logging
    output. Basic logging is enabled by default, but if you'd like to include more
    detailed messaging, set this parameter to `true`. By default, this parameter is
    set to `false`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`debug`参数使你能够设置管道日志输出的详细程度。默认启用基本日志记录，但如果你希望包含更多详细的消息，可以将此参数设置为`true`。默认情况下，此参数为`false`。'
- en: 'Here is how you can enable debug logging for your pipeline in YAML format:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何在YAML格式中启用管道的调试日志记录：
- en: '[PRE33]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This is how you would enable debug logging for your pipeline in JSON format:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何以JSON格式启用管道的调试日志记录：
- en: '[PRE34]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Next, let's learn how to use the `user` parameter.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来了解如何使用`user`参数。
- en: user
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: user
- en: The `user` parameter enables you to define a user and a group that runs the
    container's code. This parameter is similar to the Docker `USER` directive, and
    you can also define it through `Dockerfile`. By default, Pachyderm checks what's
    in your `Dockerfile` first and sets this value for the `user` parameter in the
    pipeline specification. If nothing is specified in your `Dockerfile` and the pipeline
    specification, the default parameter is used, which is `root`. The only time that
    you must explicitly specify a user in the pipeline specification is when you deploy
    Pachyderm with the `--no-expose-docker-socket` parameter.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`user`参数使你能够定义一个用户和一个组，用来运行容器的代码。这个参数类似于Docker的`USER`指令，你也可以通过`Dockerfile`来定义它。默认情况下，Pachyderm首先检查`Dockerfile`中的内容，并为管道规范中的`user`参数设置该值。如果在`Dockerfile`和管道规范中都没有指定，默认使用的参数值是`root`。只有在使用`--no-expose-docker-socket`参数部署Pachyderm时，必须在管道规范中显式指定用户。'
- en: You can read more about the Docker `USER` parameter at [https://docs.docker.com/engine/reference/builder/#user](https://docs.docker.com/engine/reference/builder/#user).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://docs.docker.com/engine/reference/builder/#user](https://docs.docker.com/engine/reference/builder/#user)上阅读更多关于Docker
    `USER`参数的信息。
- en: 'Here is how you can specify `user` in YAML format:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何在 YAML 格式中指定 `user` 的方式：
- en: '[PRE35]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Here is how you can specify `user` in JSON format:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何在 JSON 格式中指定 `user` 的方式：
- en: '[PRE36]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Now, let's learn about the `working_dir` parameter.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们了解 `working_dir` 参数。
- en: working_dir
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: working_dir
- en: The `working_dir` parameter enables you to specify a working directory for your
    pipeline container. This parameter is similar to the Docker `WORKDIR` directive,
    and you can also define it through `Dockerfile`. By default, Pachyderm checks
    what's in your `Dockerfile` first and sets this value for the `working_dir` parameter
    in the pipeline specification. If nothing is specified in `Dockerfile` and the
    pipeline specification, the default parameter is used, which is the root directory
    (`/`) or the directory that the Docker image inherits from the base image. The
    only time that you must explicitly specify a working directory in the pipeline
    specification is when you deploy Pachyderm with the `--no-expose-docker-socket`
    parameter.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '`working_dir` 参数使您能够为管道容器指定工作目录。此参数类似于 Docker 的 `WORKDIR` 指令，您也可以通过 `Dockerfile`
    定义它。默认情况下，Pachyderm 会首先检查 `Dockerfile` 中的内容，并将其值设置为管道规范中的 `working_dir` 参数。如果
    `Dockerfile` 和管道规范中都没有指定，则使用默认参数，即根目录（`/`）或 Docker 镜像从基础镜像继承的目录。只有在使用 `--no-expose-docker-socket`
    参数部署 Pachyderm 时，您才需要在管道规范中明确指定工作目录。'
- en: You can read more about the Docker `Workdir` parameter at [https://docs.docker.com/engine/reference/builder/#workdir](https://docs.docker.com/engine/reference/builder/#workdir).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [https://docs.docker.com/engine/reference/builder/#workdir](https://docs.docker.com/engine/reference/builder/#workdir)
    阅读更多关于 Docker `Workdir` 参数的信息。
- en: 'Here is how you can specify `workdir` in YAML format:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何在 YAML 格式中指定 `workdir` 的方式：
- en: '[PRE37]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The same parameter in JSON format would look like this:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在 JSON 格式中，相同的参数如下所示：
- en: '[PRE38]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Next, we'll look at the `dockerfile` parameter.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解 `dockerfile` 参数。
- en: dockerfile
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: dockerfile
- en: The `dockerfile` parameter enables you to specify a path to the location of
    the `Dockerfile` for your pipeline. This is useful when you use Pachyderm's `pachctl
    update-pipeline –build -f <pipeline-spec>` to build new Docker images for your
    pipeline. By default, Pachyderm will look for a `Dockerfile` in the same directory
    as the pipeline specification. But with the `dockerfile` parameter, you can set
    any path for it.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`dockerfile` 参数使您能够指定 `Dockerfile` 的路径，用于您的管道。当您使用 Pachyderm 的 `pachctl update-pipeline
    –build -f <pipeline-spec>` 来为管道构建新的 Docker 镜像时，这非常有用。默认情况下，Pachyderm 会在与管道规范相同的目录中查找
    `Dockerfile`。但通过 `dockerfile` 参数，您可以设置任何路径。'
- en: 'Here is how you can specify a path to Dockerfile in YAML format:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何在 YAML 格式中指定 Dockerfile 路径的方式：
- en: '[PRE39]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'You can do the same in JSON format like this:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以像这样在 JSON 格式中执行相同操作：
- en: '[PRE40]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: In this section, we learned about all the parameters that you can specify for
    your transformation code. In the next section, we will review how to control pipeline
    worker performance and assign resource limits to optimize your pipeline.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了可以为转换代码指定的所有参数。在下一节中，我们将回顾如何控制管道工作者的性能，并分配资源限制来优化管道。
- en: Optimizing your pipeline
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化您的管道
- en: This section will walk you through the pipeline specification parameters that
    may help you optimize your pipeline to perform better. Because Pachyderm runs
    on top of Kubernetes, it is a highly scalable system that can help you use your
    underlying hardware resources wisely.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将带您了解可能帮助您优化管道以提高性能的管道规范参数。由于 Pachyderm 运行在 Kubernetes 上，它是一个高度可扩展的系统，可以帮助您明智地使用底层硬件资源。
- en: One of the biggest advantages of Pachyderm is that you can specify resources
    for each pipeline individually, as well as defining how many workers your pipeline
    will spin off for each run and what their behavior will be when they are idle
    and waiting for new work to come.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Pachyderm 的最大优势之一是您可以为每个管道单独指定资源，以及定义每次运行时管道将生成多少个工作者，以及它们在空闲等待新工作时的行为。
- en: If you are just testing Pachyderm to understand whether or not it would work
    for your use case, the optimization parameters may not be as important. But if
    you are working on implementing an enterprise-level data science platform with
    multiple pipelines and massive amounts of data being injected into Pachyderm,
    knowing how to optimize your pipeline becomes a priority.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只是测试 Pachyderm，以了解它是否适合您的用例，那么优化参数可能不那么重要。但如果您正在实施一个包含多个管道且大量数据被注入到 Pachyderm
    中的企业级数据科学平台，了解如何优化管道将变得至关重要。
- en: You must understand the concept of Pachyderm datums before you proceed. Datums
    play a major role in pipeline scalability. If you have not read [*Chapter 2*](B17085_02_Final_SB_Epub.xhtml#_idTextAnchor037),
    *Pachyderm Basics,* yet, you may want to read it before you continue.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，您必须理解Pachyderm数据项的概念。数据项在管道可扩展性中起着重要作用。如果您还没有阅读[*第二章*](B17085_02_Final_SB_Epub.xhtml#_idTextAnchor037)，《Pachyderm基础》一章，建议在继续之前先阅读它。
- en: parallelism_spec
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: parallelism_spec
- en: '`parallelism_spec` defines the number of workers to spin off for your pipeline.
    You can specify either a `coefficient` or `constant` policy. By default, Pachyderm
    deploys one worker per pipeline with a `constant` policy of `1`.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`parallelism_spec`定义了为您的管道启动的工作节点数量。您可以指定`coefficient`或`constant`策略。默认情况下，Pachyderm会为每个管道部署一个工作节点，使用`constant`策略，值为`1`。'
- en: The `coefficient` policy means that Pachyderm will create several workers proportional
    to the specified coefficient. For example, if you have 50 nodes in your Kubernetes
    cluster and set the `coefficient` policy to `1`, Pachyderm will use all 50 nodes
    for this cluster. If you use the `coefficient` policy, your pipeline needs access
    to the Kubernetes administrative nodes. If you are running Pachyderm on a hosted
    version of Kubernetes, such as on the AWS or GKE platform, you may not have access
    to these, and the pipeline will constantly restart. In that case, you will have
    to use the `constant` policy instead.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '`coefficient`策略意味着Pachyderm将根据指定的系数创建多个工作节点。例如，如果您在Kubernetes集群中有50个节点，并将`coefficient`策略设置为`1`，Pachyderm将使用该集群的所有50个节点。如果您使用`coefficient`策略，您的管道需要访问Kubernetes的管理节点。如果您在托管版本的Kubernetes上运行Pachyderm，例如在AWS或GKE平台上，您可能无法访问这些节点，管道将不断重启。在这种情况下，您将必须使用`constant`策略。'
- en: The `constant` policy enables you to specify the exact number of worker nodes
    for your pipeline, such as 3, 25, or 100\. These workers will run in this pipeline
    infinitely. However, if you want your cluster to spin them down when idle, you
    can set the `standby:true` parameter so that your cluster resizes dynamically
    based on the workload.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`constant`策略使您能够为管道指定确切数量的工作节点，如3、25或100。这些工作节点将在该管道中无限期运行。然而，如果您希望在空闲时动态调整集群规模，您可以设置`standby:true`参数，以便集群根据工作负载动态调整大小。'
- en: 'The following code shows the syntax you can use in the `parallelism_spec` parameter
    to specify the `coefficient` policy in YAML format:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了您可以在`parallelism_spec`参数中使用的语法，用于指定`coefficient`策略的YAML格式：
- en: '[PRE41]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The following code shows the syntax you can use in the `parallelism_spec` parameter
    to specify the `coefficient` policy in JSON format:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了您可以在`parallelism_spec`参数中使用的语法，用于指定`coefficient`策略的JSON格式：
- en: '[PRE42]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'This is how you can define the `parallelism_spec` parameter to specify the
    `constant` policy in YAML format:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您可以在YAML格式中定义`parallelism_spec`参数以指定`constant`策略的方式：
- en: '[PRE43]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The following code shows how to use the `parallelism_spec` parameter to specify
    the `constant` policy in JSON format:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在`parallelism_spec`参数中使用`constant`策略的JSON格式：
- en: '[PRE44]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Next, let's learn how to use `reprocess_spec`.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们学习如何使用`reprocess_spec`。
- en: reprocess_spec
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: reprocess_spec
- en: '`reprocess_spec` enables you to force your pipeline to reprocess all datums.
    By default, Pachyderm skips reprocessing successful datums, but if your pipeline
    interacts with an external application or system, you may want to reprocess all
    the datums. This behavior protects the pipeline from connection and other errors.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`reprocess_spec`使您能够强制管道重新处理所有数据项。默认情况下，Pachyderm会跳过重新处理成功的数据项，但如果您的管道与外部应用程序或系统进行交互，您可能希望重新处理所有数据项。这种行为可以保护管道免受连接和其他错误的影响。'
- en: 'The following is the syntax you can use in `reprocess_spec` in YAML format:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是您可以在`reprocess_spec`中使用的YAML格式语法：
- en: '[PRE45]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The following is the syntax you can use in `reprocess_spec` in JSON format:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是您可以在`reprocess_spec`中使用的JSON格式语法：
- en: '[PRE46]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Next, we'll learn how to use `cache_size`.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习如何使用`cache_size`。
- en: cache_size
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: cache_size
- en: The `cache_size` parameter enables you to define the amount of cache memory
    for the user and storage container. Pachyderm pre-downloads the data before processing
    it and increasing `cache_size` may help increase the download speed. The default
    value is 64M, and you can increase this as needed to cache your datums. This is
    a fine-tuning parameter and should only be used once you have optimized your pipeline
    through `glob` and `parallelism_spec`.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`cache_size` 参数使您能够定义用户和存储容器的缓存内存大小。Pachyderm 会在处理数据之前预先下载数据，增加 `cache_size`
    可以帮助提高下载速度。默认值为 64M，您可以根据需要增加该值来缓存您的数据。这个参数是微调参数，只有在通过 `glob` 和 `parallelism_spec`
    优化了管道之后才应该使用。'
- en: 'The following is an example of the syntax you can use in the `cache_size` parameter
    to increase the cache''s size in YAML format:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是您可以在 `cache_size` 参数中使用的语法示例，用于以 YAML 格式增加缓存大小：
- en: '[PRE47]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'In JSON format, the same parameter would look like this:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在 JSON 格式中，相同的参数将如下所示：
- en: '[PRE48]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Now, let's review the `max_queue_size` parameter.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回顾一下 `max_queue_size` 参数。
- en: max_queue_size
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: max_queue_size
- en: The `max_queue_size` parameter defines how many datums the pipeline can download
    at the same time. You can use `max_queue_size` to make the pipeline pre-download
    the next datum while the other datums are being processed. By default, Pachyderm
    sets `max_queue_size` to `1`, meaning that only one datum can be downloaded at
    a time. This is a fine-tuning parameter that can improve the download speed of
    datums into the worker if the download time is significantly longer than the processing
    time. However, you should only adjust this parameter once you have configured
    the correct `glob` and `paralellism_spec`.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_queue_size` 参数定义了管道可以同时下载多少数据项。您可以使用 `max_queue_size` 使管道在处理其他数据项时预先下载下一个数据项。默认情况下，Pachyderm
    将 `max_queue_size` 设置为 `1`，意味着一次只能下载一个数据项。这是一个微调参数，如果下载时间显著长于处理时间，调整此参数可以提高数据项下载到工作节点的速度。然而，只有在正确配置了
    `glob` 和 `parallelism_spec` 后，您才应该调整此参数。'
- en: 'The following code shows how to use the `max_queue_size` parameter to increase
    the cache''s size in YAML format:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何使用 `max_queue_size` 参数以 YAML 格式增加缓存大小：
- en: '[PRE49]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The same key-value pair in JSON format looks as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在 JSON 格式中，相同的键值对如下所示：
- en: '[PRE50]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Next, we'll learn about `chunk_spec`.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习 `chunk_spec`。
- en: chunk_spec
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: chunk_spec
- en: The `chunk_spec` parameter defines how many datums to send to each worker for
    processing. By default, this parameter is set to `1`. A chunk of data can be set
    to `number` (number of datums) or `size_bytes`. For example, if you set `chunk_spec`
    in `number` (number of datums) to `3`, each worker will get a chunk of three datums
    at a time.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`chunk_spec` 参数定义了每个工作节点处理的数据项数量。默认情况下，此参数设置为 `1`。数据块可以通过 `number`（数据项数量）或
    `size_bytes`（字节大小）来设置。例如，如果您将 `chunk_spec` 中的 `number` 设置为 `3`，则每个工作节点一次会处理三个数据项。'
- en: With `size_bytes`, you can make evenly sized datums if the runtime of a datum
    is proportional to its size. If this is not the case, use the `number` parameter
    instead.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `size_bytes`，如果数据项的运行时间与其大小成正比，您可以使数据项大小均匀。如果不是这种情况，请改用 `number` 参数。
- en: 'The following code shows how to set `number` in the `chunk_spec` parameter
    to make the workers process this number of datums at a time in YAML format:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 `chunk_spec` 参数中设置 `number`，以使工作节点一次处理指定数量的数据项，并以 YAML 格式呈现：
- en: '[PRE51]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Here''s how you can set `number` in the `chunk_spec` parameter to make the
    workers process this number of datums at a time in JSON format:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您可以在 `chunk_spec` 参数中设置 `number`，使得工作节点一次处理指定数量数据项的 JSON 格式：
- en: '[PRE52]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The following code shows how to set `size_bytes` ( of datums) in the `chunk_spec`
    parameter to make the workers process this number of datums at a time in YAML
    format:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 `chunk_spec` 参数中设置 `size_bytes`（数据项的字节数），使得工作节点一次处理指定数量的数据项，并以 YAML
    格式呈现：
- en: '[PRE53]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'If you prefer to write in JSON format, setting `size_bytes` in the `chunk_spec`
    parameter to make the workers process this number of datums at a time would look
    like this:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您更喜欢使用 JSON 格式，设置 `chunk_spec` 参数中的 `size_bytes`，使工作节点一次处理指定数量的数据项，将是如下所示：
- en: '[PRE54]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Next, we will learn how to set resource limits.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习如何设置资源限制。
- en: resource_limits
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: resource_limits
- en: The `resource_limits` parameter enables you to restrict the amount of `type`
    for your GPU resources. The pipeline worker cannot use more resources than the
    limit you specify. The `resource_request` parameter is similar, but the worker
    can go over the requested amount of resources if they are available. You can read
    more about `resource_limits` and `resource_requests` in the Kubernetes documentation
    at [https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '`resource_limits` 参数使你能够限制 GPU 资源的 `type` 数量。管道工作者不能使用超过你指定的资源限制。`resource_request`
    参数类似，但如果有足够的资源，工作者可以使用超过请求的资源。你可以在 Kubernetes 文档中阅读更多关于 `resource_limits` 和 `resource_requests`
    的内容，链接：[https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits)。'
- en: 'The following code shows how to set the `resource_limits` parameter to limit
    Pachyderm worker resources in YAML format:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 YAML 格式中设置 `resource_limits` 参数以限制 Pachyderm 工作者资源：
- en: '[PRE55]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The following code shows how to set the `resource_limits` parameter to limit
    Pachyderm worker resources in JSON format:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 JSON 格式中设置 `resource_limits` 参数以限制 Pachyderm 工作者资源：
- en: '[PRE56]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: If you need to set a specific flavor of cloud resource, such as TPU in Google
    Kubernetes Engine, you can do so by configuring `pod_patch`. See the upcoming
    *pod_patch* section for more information.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要设置特定的云资源类型，例如 Google Kubernetes Engine 中的 TPU，你可以通过配置 `pod_patch` 来实现。有关更多信息，请参见接下来的
    *pod_patch* 部分。
- en: resource_requests
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: resource_requests
- en: The `resource_requests` parameter specifies the number of resources that a pipeline
    worker requests to process a unit of work. Unlike the `resource_limits` parameter,
    if more resources are available, the worker can use them. The syntax for this
    parameter is the same as for `resource_limits`.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`resource_requests` 参数指定管道工作者请求处理一个工作单元所需的资源数量。与 `resource_limits` 参数不同，如果有更多资源可用，工作者可以使用这些资源。该参数的语法与
    `resource_limits` 相同。'
- en: sidecar_resource_limits
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: sidecar_resource_limits
- en: This parameter is similar to `resource_limits` and defines the resource for
    the pipeline sidecar container. For some example syntax, see the *resource_limits*
    section.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 该参数类似于 `resource_limits`，并定义了管道 sidecar 容器的资源。有关一些示例语法，请参见 *resource_limits*
    部分。
- en: scheduling_spec
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scheduling_spec
- en: The `scheduling_spec` parameter enables you to specify which Pods to run your
    pipeline code on based on a specified `node_selector` or `priority_class`. `node_selectore`
    enables you to specify a specific group of nodes that have the same label, called
    `nodeSelector`, while `priority_class` enables you to schedule the pipeline on
    a group of nodes that matches a Kubernetes `PriorityClass`. The `scheduling_spec`
    parameter is typically used to schedule pipelines on specific workers because
    of the resources they provide. For more information about these properties, see
    https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
    and [https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass](https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '`scheduling_spec` 参数使你能够根据指定的 `node_selector` 或 `priority_class` 来指定运行管道代码的
    Pods。`node_selector` 允许你指定一组具有相同标签的节点，称为 `nodeSelector`，而 `priority_class` 允许你将管道调度到匹配
    Kubernetes `PriorityClass` 的节点组上。`scheduling_spec` 参数通常用于根据资源调度管道到特定的工作节点。有关这些属性的更多信息，请参见
    [https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector)
    和 [https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass](https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass)。'
- en: 'The following code shows how to define `nodeSelector` in YAML format:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 YAML 格式中定义 `nodeSelector`：
- en: '[PRE57]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The following code shows how to define `nodeSelector` in JSON format:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 JSON 格式中定义 `nodeSelector`：
- en: '[PRE58]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'To define the `PriorityClass` parameter in YAML format, use the following code:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 YAML 格式中定义 `PriorityClass` 参数，请使用以下代码：
- en: '[PRE59]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Or, if you prefer to write in JSON format, set `PriorityClass` like this:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你更喜欢使用 JSON 格式，请按以下方式设置 `PriorityClass`：
- en: '[PRE60]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Next, we'll learn how to set a timeout for a job.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习如何为一个作业设置超时。
- en: job_timeout
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: job_timeout
- en: The `job_timeout` parameter enables you to set a timeout for a Pachyderm job
    run. This means that if your job does not finish within the specified period,
    it will fail. By default, this parameter is disabled. You can set it to your preferred
    time value.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '`job_timeout` 参数使你能够为 Pachyderm 作业运行设置超时。这意味着如果作业在指定时间内未完成，它将失败。默认情况下，该参数是禁用的，你可以将其设置为你希望的时间值。'
- en: 'The following code shows how to define a `job_timeout` in YAML format:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 YAML 格式中定义 `job_timeout` 参数：
- en: '[PRE61]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Here is the same example in JSON format:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这是相同示例的 JSON 格式：
- en: '[PRE62]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Next, we'll learn about `datum_timeout`.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解 `datum_timeout`。
- en: datum_timeout
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: datum_timeout
- en: The `datum_timeout` timeout is similar to `job_timeout`, except that the timeout
    is set at the datum level of granularity. The syntax is the same.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '`datum_timeout` 超时与 `job_timeout` 类似，唯一的区别是超时设置在数据粒度级别。语法相同。'
- en: datum_tries
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: datum_tries
- en: The `datum_tries` parameter defines how many times Pachyderm will try to rerun
    a pipeline on a failed datum. By default, this parameter is set to `3`. If you
    want your pipeline to run only once and not try to process the failed datums again,
    set this value to `1`.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '`datum_tries` 参数定义了 Pachyderm 在数据失败时重试管道的次数。默认情况下，该参数设置为 `3`。如果你只希望管道运行一次，不再尝试处理失败的数据，请将此值设置为
    `1`。'
- en: 'The following code shows how to define the `job_tries` parameter in YAML format:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 YAML 格式中定义 `job_tries` 参数：
- en: '[PRE63]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'If you prefer to write in JSON format, you can use the following code instead:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更倾向于使用 JSON 格式编写，可以使用以下代码：
- en: '[PRE64]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: In this section, we learned how to achieve optimal performance by fine-tuning
    our pipeline specification. In the next section, you will learn how to configure
    some of the service parameters that assist in pipeline operations.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何通过微调管道规范来实现最佳性能。下一节，你将学习如何配置一些辅助管道操作的服务参数。
- en: Exploring service parameters
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索服务参数
- en: Now, let's look at service parameters. Service parameters include the parameters
    that let you collect statistics about your data, as well as patch your pipeline's
    Kubernetes configuration.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下服务参数。服务参数包括那些让你收集数据统计信息以及修补管道 Kubernetes 配置的参数。
- en: enable_stats
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: enable_stats
- en: The `enable_stats` parameter, as its name suggests, enables pipeline statistics
    logging. By default, this parameter is disabled. For debugging purposes, it is
    recommended that you set this parameter to `true`. Once you enable statistics
    collection, the statistics are saved in the `stats` folder. You cannot disable
    statistics collection.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '`enable_stats` 参数顾名思义，用于启用管道统计日志记录。默认情况下，该参数是禁用的。为了调试，建议将此参数设置为`true`。启用统计数据收集后，统计信息将保存在
    `stats` 文件夹中，且无法禁用统计数据收集。'
- en: 'The following code shows how to define the `enable_stats` parameter in YAML
    format:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 YAML 格式中定义 `enable_stats` 参数：
- en: '[PRE65]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The following code shows how to define the `enable_stats` parameter in JSON
    format:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 JSON 格式中定义 `enable_stats` 参数：
- en: '[PRE66]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Next, we'll learn about `pod_patch`.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解`pod_patch`。
- en: pod_patch
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: pod_patch
- en: The `pod_patch` parameter enables you to rewrite any field in your pipeline
    Pods. This can be useful for many things, but one example is mounting a volume
    in your pipeline. To create a `pod_patch`, you would typically use a JSON patch
    builder, convert it into a one-liner, and add it to your pipeline specification.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '`pod_patch` 参数使你能够重写管道 Pods 中的任何字段。这对许多场景有用，一个例子是将卷挂载到你的管道中。为了创建 `pod_patch`，你通常需要使用
    JSON patch 构建器，将其转换为一行格式，并添加到管道规范中。'
- en: 'The following code shows how to define the `pod_patch` parameter in YAML format:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在 YAML 格式中定义 `pod_patch` 参数：
- en: '[PRE67]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The same in JSON format looks like this:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是相同内容的 JSON 格式：
- en: '[PRE68]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: This is all you need to know about service parameters. In the next section,
    we will look at some parameters that enable you to configure the output branch
    and write your pipeline results to external storage.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你需要了解的所有服务参数。接下来的章节，我们将介绍一些使你能够配置输出分支并将管道结果写入外部存储的参数。
- en: Exploring output parameters
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索输出参数
- en: Output parameters enable you to configure what happens to your processed data
    after the result lands in the output repository. You can set it up to be placed
    in an external S3 repository or configure an egress.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 输出参数使你能够配置处理后的数据在结果落入输出库后发生的事情。你可以设置它将数据放置在外部 S3 存储库中或配置出口。
- en: s3_out
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: s3_out
- en: The `s3_out` parameter enables your Pachyderm pipeline to write output to an
    S3 repository instead of the standard `pfs/out`. This parameter requires a Boolean
    value. To access the output repository, you would have to use an S3 protocol address,
    such as `s3://<output-repo>`. The output repository will still be eponymous to
    your pipeline's name.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '`s3_out`参数使您的Pachyderm管道能够将输出写入S3存储库，而不是标准的`pfs/out`。此参数需要一个布尔值。要访问输出存储库，您需要使用S3协议地址，如`s3://<output-repo>`。输出存储库仍将与您的管道名称同名。'
- en: 'The following code shows how to define an `s3_out` parameter in YAML format:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在YAML格式中定义`s3_out`参数：
- en: '[PRE69]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Here''s how to do the same in JSON format:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是如何在JSON格式中做同样的操作：
- en: '[PRE70]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Now, let's learn about `egress`.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们了解一下`egress`。
- en: egress
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: egress
- en: The `egress` parameter enables you to specify an external location for your
    output data. Pachyderm supports Amazon S3 (the `s3://` protocol), Google Cloud
    Storage (the `gs://` protocol), and Azure Blob Storage (the `wasb://` protocol).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '`egress`参数使您能够指定输出数据的外部位置。Pachyderm支持Amazon S3（`s3://`协议）、Google Cloud Storage（`gs://`协议）和Azure
    Blob Storage（`wasb://`协议）。'
- en: 'The following code shows how to define an `egress` parameter in YAML format:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在YAML格式中定义`egress`参数：
- en: '[PRE71]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Here''s the same example but in JSON format:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是相同的示例，但使用的是JSON格式：
- en: '[PRE72]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Next, let's learn about how to configure an output branch in Pachyderm.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们了解如何在Pachyderm中配置输出分支。
- en: output_branch
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: output_branch
- en: The `output_branch` parameter enables you to write your results into a branch
    in an output repository that is different from the default `master` branch. You
    may want to do this if you want to create an experiment or a development output
    that you don't want the downstream pipeline to pick up.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '`output_branch`参数使您能够将结果写入输出存储库中的一个不同于默认`master`分支的分支。如果您希望创建一个实验或开发输出，而不希望下游管道拾取它，您可能需要这样做。'
- en: 'The following code shows how to define the `output_branch` parameter in YAML
    format:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在YAML格式中定义`output_branch`参数：
- en: '[PRE73]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The following code shows how to define the `output_branch` parameter in JSON
    format:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何在JSON格式中定义`output_branch`参数：
- en: '[PRE74]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: This concludes our overview of the Pachyderm pipeline specification.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了Pachyderm管道规范的内容。
- en: Summary
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about all the parameters you can specify in a Pachyderm
    pipeline, how to optimize it, and how to configure the transformation section.
    The pipeline specification is the most important configuration attribute of your
    pipeline as you will use it to create your pipeline. As you have learned, the
    pipeline specification provides a lot of flexibility regarding performance optimization.
    While it may be tricky to find the right parameters for your type of data right
    away, Pachyderm provides a lot of fine-tuning options that can help you achieve
    the best performance for your ML workflow.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了您可以在Pachyderm管道中指定的所有参数、如何优化管道以及如何配置转换部分。管道规范是您管道中最重要的配置属性，因为您将使用它来创建您的管道。如您所见，管道规范在性能优化方面提供了很大的灵活性。虽然一开始可能很难为您的数据类型找到合适的参数，但Pachyderm提供了许多微调选项，帮助您为您的机器学习工作流实现最佳性能。
- en: In the next chapter, you will learn how to install Pachyderm on your local computer.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将学习如何在本地计算机上安装Pachyderm。
- en: Further reading
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于本章中所涵盖的主题，请查看以下资源：
- en: '*Pachyderm Environment Variables*: [https://docs.pachyderm.com/latest/deploy-manage/deploy/environment-variables/](https://docs.pachyderm.com/latest/deploy-manage/deploy/environment-variables/)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Pachyderm环境变量*：[https://docs.pachyderm.com/latest/deploy-manage/deploy/environment-variables/](https://docs.pachyderm.com/latest/deploy-manage/deploy/environment-variables/)'
- en: '*Kubernetes Concepts*: [https://kubernetes.io/docs/concepts/](https://kubernetes.io/docs/concepts/)'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubernetes概念*：[https://kubernetes.io/docs/concepts/](https://kubernetes.io/docs/concepts/)'
- en: '*Pachyderm Pipeline Specification*: [https://docs.pachyderm.com/latest/reference/pipeline_spec/](https://docs.pachyderm.com/latest/reference/pipeline_spec/)'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Pachyderm管道规范*：[https://docs.pachyderm.com/latest/reference/pipeline_spec/](https://docs.pachyderm.com/latest/reference/pipeline_spec/)'
