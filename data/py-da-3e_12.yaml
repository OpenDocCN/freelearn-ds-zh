- en: Supervised Learning - Regression Analysis
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习 - 回归分析
- en: Regression is the most popular algorithm in statistics and machine learning.
    In the machine learning and data science field, regression analysis is a member
    of the supervised machine learning domain that helps us to predict continuous
    variables such as stock prices, house prices, sales, rainfall, and temperature.
    As a sales manager at an electronic store, for example, say you need to predict
    the sales of upcoming weeks for all types of products, such as televisions, air
    conditioners, laptops, refrigerators, and many more. Lots of factors can affect
    your sales, such as weather conditions, festivals, promotion strategy, competitor
    offers, and so on. Regression analysis is one of the tools that can help you to
    identify the importance of such factors that are important to make decisions at
    the store.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是统计学和机器学习中最受欢迎的算法。在机器学习和数据科学领域，回归分析是监督式机器学习领域的一个成员，它帮助我们预测连续变量，如股价、房价、销售额、降雨量和温度。例如，作为一家电子商店的销售经理，假设你需要预测未来几周所有类型产品的销售情况，如电视、空调、笔记本电脑、冰箱等。许多因素可能影响你的销售情况，如天气条件、节假日、促销策略、竞争对手的优惠等。回归分析是帮助你识别这些因素的重要性，从而做出商店决策的工具之一。
- en: Regression analysis identifies how the dependent variable depends upon independent
    variables. For example, say as an education officer you want to identify the impact
    of sports activities, smart classes, teacher-student ratio, extra classes, and
    teachers' training on students' results. **Ordinary Least Square** (**OLS**) minimizes
    the sum of squares error (or error variance) to find out the best fit function.
    It predicts the most probable outcome under the given conditions. The main objective
    of this chapter is to learn the fundamentals of **Multiple Linear Regression**
    (**MLR**), multicollinearity, dummy variables, regression, and model evaluation
    measures such as R-squared, **Mean Squared Error** (**MSE**), **Mean Absolute
    Error** (**MAE**), and **Root Mean Square Error** (**RMSE**). Another objective
    is creating a logistic regression classification model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析用于识别因变量如何依赖于自变量。例如，假设作为一名教育官员，你希望识别体育活动、智能课堂、师生比、额外课程和教师培训对学生成绩的影响。**普通最小二乘法**
    (**OLS**) 通过最小化平方误差和（或误差方差）来找出最佳拟合函数。它预测在给定条件下最可能的结果。本章的主要目标是学习**多重线性回归** (**MLR**)
    的基础知识、多重共线性、虚拟变量、回归以及模型评估指标，如R平方、**均方误差** (**MSE**)、**平均绝对误差** (**MAE**) 和**均方根误差**
    (**RMSE**)。另一个目标是创建一个逻辑回归分类模型。
- en: 'The topics covered in this chapter are listed as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖的主题如下：
- en: Linear regression
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归
- en: Understanding multicollinearity
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解多重共线性
- en: Dummy variables
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟变量
- en: Developing a linear regression model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发线性回归模型
- en: Evaluating regression model performance
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估回归模型性能
- en: Fitting polynomial regression
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拟合多项式回归
- en: Regression models for classification
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于分类的回归模型
- en: Logistic regression
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Implementing logistic regression using scikit-learn
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用scikit-learn实现逻辑回归
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter has the following technical requirements:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章有以下技术要求：
- en: 'You can find the code and the datasets at the following GitHub link: [https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter09](https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter09)[.](https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter09)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在以下GitHub链接中找到代码和数据集：[https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter09](https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter09)[。](https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter09)
- en: All the code blocks are available in the `ch9.ipynb` file.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有代码块都可以在`ch9.ipynb`文件中找到。
- en: This chapter uses three CSV files (`Advertising.csv`, `bloodpress.txt`, and
    `diabetes.csv`) for practice purposes.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章使用三个CSV文件（`Advertising.csv`、`bloodpress.txt` 和 `diabetes.csv`）用于练习。
- en: In this chapter, we will use the Matplotlib, `pandas`, Seaborn, and scikit-learn
    Python libraries.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Matplotlib、`pandas`、Seaborn和scikit-learn Python库。
- en: Linear regression
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归
- en: 'Linear regression is a kind of curve-fitting and prediction algorithm. It is
    used to discover the linear association between a dependent (or target) column
    and one or more independent columns (or predictor variables). This relationship
    is deterministic, which means it predicts the dependent variable with some amount
    of error. In regression analysis, the dependent variable is continuous and independent
    variables of any type are continuous or discrete. Linear regression has been applied
    to various kinds of business and scientific problems, for example, stock price,
    crude oil price, sales, property price, and GDP growth rate predictions. In the
    following graph, we can see how linear regression can fit data in two-dimensional
    space:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是一种曲线拟合和预测算法，用于发现因变量（或目标列）与一个或多个自变量（或预测变量）之间的线性关系。这种关系是确定性的，意味着它以一定的误差预测因变量。在回归分析中，因变量是连续的，而自变量可以是连续的或离散的。线性回归已广泛应用于各种商业和科学问题，如股票价格、原油价格、销售额、房产价格和GDP增长率的预测。在下图中，我们可以看到线性回归如何在二维空间中拟合数据：
- en: '![](img/95977f0e-4614-4e71-828e-8884f82c697d.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95977f0e-4614-4e71-828e-8884f82c697d.png)'
- en: 'The main objective is to find the best-fit line to understand the relationship
    between variables with minimum error. Error in regression is the difference between
    the forecasted and actual values. Coefficients of regression are estimated using
    the OLS method. OLS tries to minimize the sum of squares residuals. Let''s see
    the equation for the regression model:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 主要目标是找到最佳拟合线，以最小的误差理解变量之间的关系。回归中的误差是预测值与实际值之间的差异。回归系数是通过OLS方法估计的。OLS试图最小化残差平方和。我们来看回归模型的方程：
- en: '![](img/2b803453-31a3-48d7-80db-daf0360d947e.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2b803453-31a3-48d7-80db-daf0360d947e.png)'
- en: Here, *x* is the independent variable and *y* is a dependent variable. ![](img/10a567ab-2ffc-4cad-a44d-4f55a7de63ce.png)
    intercepts are the coefficient of *x*, and ![](img/31dddf97-8805-43a1-9041-8ba8eefe5a4c.png)
    (the Greek letter pronounced as epsilon) is an error term that will act as a random
    variable.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*x* 是自变量，*y* 是因变量。![](img/10a567ab-2ffc-4cad-a44d-4f55a7de63ce.png) 截距是 *x*
    的系数，![](img/31dddf97-8805-43a1-9041-8ba8eefe5a4c.png)（希腊字母发音为 epsilon）是作为随机变量的误差项。
- en: The parameters of linear regression are estimated using OLS. OLS is a method
    that is widely used to estimate the regression intercept and coefficients. It
    reduces the sum of squares of residuals (or error), which is the difference between
    the predicted and actual.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归的参数是通过OLS估计的。OLS是一种广泛用于估计回归截距和系数的方法。它通过减少残差平方和（或误差）来优化，这个误差是预测值与实际值之间的差异。
- en: After getting an idea about linear regression, it's now time to learn about
    MLR.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了线性回归之后，现在是时候学习MLR了。
- en: Multiple linear regression
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多重线性回归
- en: 'MLR is a generalized form of simple linear regression. It is a statistical
    method used to predict the continuous target variable based on multiple features
    or explanatory variables. The main objective of MLR is to estimate the linear
    relationship between the multiple features and the target variable. MLR has a
    wide variety of applications in real-life scenarios. The MLR model can be represented
    as a mathematical equation:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 多重线性回归（MLR）是简单线性回归的推广形式。它是一种统计方法，用于根据多个特征或解释变量预测连续的目标变量。MLR的主要目标是估计多个特征与目标变量之间的线性关系。MLR在现实生活中的应用非常广泛。MLR模型可以表示为数学方程：
- en: '![](img/9c36b729-f849-4365-aace-147be7590523.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9c36b729-f849-4365-aace-147be7590523.png)'
- en: Here, [![](img/7f873b49-b78d-4bdf-b9c0-53bb40257a87.jpg)] are the independent
    variables and ![](img/e3c23ddd-8528-4d2e-b4dd-6f2a6bd07539.png)is a dependent
    variable. ![](img/2842199b-fd9f-4687-8dba-118ffaa33717.png) intercepts are coefficients
    of *x* and ![](img/31dddf97-8805-43a1-9041-8ba8eefe5a4c.png) (the Greek letter
    pronounced as epsilon) is an error term that will act as a random variable.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，[![](img/7f873b49-b78d-4bdf-b9c0-53bb40257a87.jpg)] 是自变量，![](img/e3c23ddd-8528-4d2e-b4dd-6f2a6bd07539.png)
    是因变量。![](img/2842199b-fd9f-4687-8dba-118ffaa33717.png) 截距是 *x* 的系数，![](img/31dddf97-8805-43a1-9041-8ba8eefe5a4c.png)（希腊字母发音为
    epsilon）是作为随机变量的误差项。
- en: Now that we know what linear regression is, let's move on to multicollinearity.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道什么是线性回归，让我们继续讨论多重共线性。
- en: Understanding multicollinearity
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解多重共线性
- en: Multicollinearity represents the very high intercorrelations or inter-association
    among the independent (or predictor) variables.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 多重共线性表示自变量（或预测变量）之间高度的相互相关性或相互关系。
- en: 'Multicollinearity takes place when independent variables of multiple regression
    analysis are highly associated with each other. This association is caused by
    a high correlation among independent variables. This high correlation will trigger
    a problem in the linear regression model prediction results. It''s the basic assumption
    of linear regression analysis to avoid multicollinearity for better results:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 多重共线性发生在多元回归分析中的自变量彼此高度相关时。这种关联是由于自变量之间的高相关性造成的。这种高相关性会导致线性回归模型预测结果出现问题。在进行线性回归分析时，避免多重共线性是基本假设，以获得更好的结果：
- en: It occurs due to the inappropriate use of dummy variables.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是由于虚拟变量的不当使用而发生的。
- en: It also occurs due to the repetition of similar variables.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它还可能是由于相似变量的重复出现引起的。
- en: It is also caused due to synthesized variables from other variables in the data.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它还可能是由于从数据中的其他变量合成的变量引起的。
- en: It can occur due to high correlation among variables.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可能是由于变量之间的高相关性引起的。
- en: 'Multicollinearity causes the following problems:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 多重共线性会导致以下问题：
- en: It causes difficulty in estimating the regression coefficients precisely and
    coefficients become more susceptible to minor variations in the model.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它会导致回归系数的精确估计变得困难，并且系数对模型中的微小变化变得更加敏感。
- en: It can also cause a change in the signs and magnitudes of the coefficient.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它还可能导致系数的符号和大小发生变化。
- en: It causes difficulty in assessing the relative importance of independent variables.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使得评估自变量相对重要性变得困难。
- en: Removing multicollinearity
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移除多重共线性
- en: 'Multicollinearity can be detected using the following:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下方法检测多重共线性：
- en: The correlation coefficient (or correlation matrix) between independent variables
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自变量之间的相关系数（或相关矩阵）
- en: '**Variance Inflation Factor** (**VIF**)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方差膨胀因子**（**VIF**）'
- en: Eigenvalues
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征值
- en: 'Correlation coefficients or correlation matrices will help us to identify a
    high correlation between independent variables. Using the correlation coefficient,
    we can easily detect the multicollinearity by checking the correlation coefficient
    magnitude:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 相关系数或相关矩阵有助于我们识别自变量之间的高度相关性。通过相关系数，我们可以通过检查相关系数的大小来轻松检测多重共线性：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This results in the following output:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致以下输出：
- en: '![](img/d8b82130-814f-4543-8efc-62d31d07cf02.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d8b82130-814f-4543-8efc-62d31d07cf02.png)'
- en: 'In the preceding code block, we read the `bloodpress.txt` data using the `read_csv()`
    function. We also checked the initial records of the dataset. This dataset has
    `BP`, `Age`, `Weight`, `BSA`, `Dur`, `Pulse`, and `Stress` fields. Let''s check
    the multicollinearity in the dataset using the correlation matrix:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们使用`read_csv()`函数读取了`bloodpress.txt`数据。我们还检查了数据集的初始记录。这个数据集包含了`BP`、`Age`、`Weight`、`BSA`、`Dur`、`Pulse`和`Stress`字段。让我们使用相关矩阵来检查数据集中的多重共线性：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This results in the following output:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致以下输出：
- en: '![](img/3a140469-91e5-4f42-8f4e-ea89d8e9ddae.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3a140469-91e5-4f42-8f4e-ea89d8e9ddae.png)'
- en: In the preceding example, we are finding the correlation between multiple variables
    using the correlation matrix. We loaded the `bloodpress.txt` file and found the
    correlation using the `corr()` function. Finally, we visualized the correlation
    matrix using the `heatmap()` function.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们使用相关矩阵查找多个变量之间的相关性。我们加载了`bloodpress.txt`文件，并使用`corr()`函数找到了相关性。最后，我们使用`heatmap()`函数可视化了相关矩阵。
- en: Here, **BP** (**Blood** **Pressure**) is the dependent or target variable, and
    the rest of the columns are independent variables or features. We can see that
    **Weight** and **BSA** (**Body** **Surface** **Area**) have a high correlation.
    We need to remove one variable (either **Weight** or **BSA**) to remove the multicollinearity.
    In our case, weight is easier to measure compared to BSA, so experts will choose
    the weight and remove the BSA.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，**BP**（**血压**）是因变量或目标变量，其他列是自变量或特征。我们可以看到，**Weight**和**BSA**（**体表面积**）之间有很高的相关性。我们需要移除其中一个变量（**Weight**或**BSA**），以消除多重共线性。在我们的例子中，体重比体表面积更容易测量，因此专家会选择体重并移除体表面积。
- en: Dummy variables
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚拟变量
- en: Dummy variables are categorical independent variables used in regression analysis.
    It is also known as a Boolean, indicator, qualitative, categorical, and binary
    variable. Dummy variables convert a categorical variable with *N* distinct values
    into *N*–1 dummy variables. It only takes the 1 and 0 binary values, which are
    equivalent to existence and nonexistence.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟变量是回归分析中使用的分类自变量。它也被称为布尔值、指示变量、定性变量、分类变量和二元变量。虚拟变量将具有*N*个不同值的分类变量转换为*N*–1个虚拟变量。它只取1和0这两个二进制值，分别代表存在和不存在。
- en: '`pandas` offers the `get_dummies()` function to generate the dummy values.
    Let''s understand the `get_dummies()` function through an example:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`提供了`get_dummies()`函数来生成虚拟值。让我们通过一个例子来理解`get_dummies()`函数：'
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This results in the following output:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '|  | **Gender** |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|  | **Gender** |'
- en: '| 0 | F |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 0 | F |'
- en: '| 1 | M |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 1 | M |'
- en: '| 2 | M |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 2 | M |'
- en: '| 3 | F |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 3 | F |'
- en: '| 4 | M |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 4 | M |'
- en: 'In the preceding code block, we have created the DataFrame with the `Gender`
    column and generated the dummy variable using the `get_dummies()` function. Let''s
    see an example in the following code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们创建了包含`Gender`列的DataFrame，并使用`get_dummies()`函数生成了虚拟变量。让我们通过以下代码看一个例子：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This results in the following output:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, in the preceding example, the `get_dummies()` function is generating two
    columns, which means a separate column for each value.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，`get_dummies()`函数生成了两列，这意味着每个值都有一个单独的列。
- en: 'We can remove one column to avoid collinearity using the `drop_first=True`
    argument and drop first the *N*–1 dummies out of *N* categorical levels by removing
    the first level:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用`drop_first=True`参数，去掉一列，避免共线性问题，首先删除*N*个类别中的第一列虚拟变量：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This results in the following output:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE6]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the preceding code block, we have created the dummy variables for the `Gender`
    column using the `get_dummies()` function with the `drop_first=True` parameter.
    This has removed the first column and leaves *N–*1 columns. Let's now learn how
    to implement the linear regression model using the `scikit-learn` library.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们使用`get_dummies()`函数并设置`drop_first=True`参数，为`Gender`列创建了虚拟变量。这将删除第一列，剩下*N–*1列。现在，让我们学习如何使用`scikit-learn`库实现线性回归模型。
- en: Developing a linear regression model
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发线性回归模型
- en: 'After understanding the concepts of regression analysis, multicollinearity,
    and dummy variables, it''s time to get some hands-on experience with regression
    analysis. Let''s learn how to build the regression model using the scientific
    toolkit for machine learning (scikit-learn):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解回归分析、多重共线性和虚拟变量的概念之后，是时候通过实际操作体验回归分析了。让我们学习如何使用科学机器学习工具包（scikit-learn）构建回归模型：
- en: 'We will first load the dataset using the `read_csv()` function:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先使用`read_csv()`函数加载数据集：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This results in the following output:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/38b6e58b-5433-427c-9cf8-b4e8aa015617.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38b6e58b-5433-427c-9cf8-b4e8aa015617.png)'
- en: 'Now that we have loaded the `Advertising.csv` dataset using `read_csv()` and
    checked the initial records using the `head()` function, we will split the data
    into two parts: dependent or target variable and independent variables or features.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使用`read_csv()`加载了`Advertising.csv`数据集，并使用`head()`函数查看了初始记录，我们将数据拆分为两部分：因变量或目标变量和自变量或特征变量。
- en: 'In this step, we will split the data two times:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们将数据拆分两次：
- en: 'Split into two parts: dependent or target variable and independent variables
    or features.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据分为两部分：因变量或目标变量与自变量或特征变量。
- en: 'Split data into training and test sets. This can be done using the following
    code:'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集和测试集。这可以使用以下代码完成：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After splitting the columns into dependent and independent variable parts,
    we will split the data into train and test sets in a 75:25 ratio using `train_test_split()`.
    The ratio can be specified using the `test_size` parameter and `random_state`
    is used as a seed value for reproducing the same data split each time. If `random_state`
    is `None`, then it will randomly split the records each time, which will give
    different performance measures:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在将列分为因变量和自变量部分之后，我们将使用`train_test_split()`函数按75:25的比例将数据拆分为训练集和测试集。这个比例可以通过`test_size`参数指定，`random_state`用作种子值，确保每次拆分的数据相同。如果`random_state`为`None`，则每次都会随机拆分记录，可能会得到不同的性能度量：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In the preceding code block, we have divided the data into two parts – train
    and test sets – in a 75:25 or 3:1 ratio.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码块中，我们已经将数据分为两部分——训练集和测试集——比例为75:25或3:1。
- en: 'Let''s import the `LinearRegression` model, create its object, and fit it to
    the training dataset (`X_train`, `y_train`). After fitting the model, we can predict
    the values for testing data (`X_test`). We can see the intercept and coefficient
    of the regression equation using the `intercept_` and `coef_` attributes:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入`LinearRegression`模型，创建它的对象，并将其拟合到训练数据集（`X_train`, `y_train`）。在拟合模型后，我们可以预测测试数据（`X_test`）的值。通过`intercept_`和`coef_`属性，我们可以看到回归方程的截距和系数：
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This results in the following output:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the preceding code, we have prepared the linear regression model, performed
    the predictions on test sets, and displayed the intercepts and coefficients. In
    the upcoming section, we will assess the regression model's performance using
    model evaluation measures such as R-squared and error functions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码中，我们已经准备了线性回归模型，对测试集进行了预测，并显示了截距和系数。在接下来的部分，我们将使用回归评估指标（如R平方和误差函数）评估回归模型的性能。
- en: Evaluating regression model performance
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估回归模型性能
- en: 'In this section, we will review the regression evaluation measures for understanding
    the performance level of a regression model. Model evaluation is one of the key
    aspects of any machine learning model building process. It helps us to assess
    how our model will perform when we put it into production. We will use the following
    metrics for model evaluation:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将回顾回归模型评估指标，以了解回归模型的性能水平。模型评估是任何机器学习模型构建过程中的关键方面之一。它帮助我们评估当模型投入生产时的表现。我们将使用以下指标进行模型评估：
- en: '**R-squared**'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**R平方**'
- en: '**MSE**'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MSE**'
- en: '**MAE**'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MAE**'
- en: '**RMSE**'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RMSE**'
- en: R-squared
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: R平方
- en: 'R-squared (or coefficient of determination) is a statistical model evaluation
    measure that assesses the goodness of a regression model. It helps data analysts
    to explain model performance compared to the base model. Its value lies between
    0 and 1\. A value near 0 represents a poor model while a value near 1 represents
    a perfect fit. Sometimes, R-squared results in a negative value. This means your
    model is worse than the average base model. We can explain R-squared using the
    following formula:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: R平方（或决定系数）是一个统计学模型评估指标，用于评估回归模型的拟合优度。它帮助数据分析师解释模型相较于基准模型的表现。其值介于0和1之间。接近0的值表示模型较差，而接近1的值表示完美拟合。有时，R平方结果可能为负值，这意味着你的模型比平均基准模型还差。我们可以通过以下公式解释R平方：
- en: '![](img/e171c969-0da0-46c7-ab1b-33ce7bafd90e.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e171c969-0da0-46c7-ab1b-33ce7bafd90e.png)'
- en: 'Let''s understand all the components one by one:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一理解所有组件：
- en: '**Sum of Squares Regression** (**SSR**): This estimates the difference between
    the forecasted value and the mean of the data.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归平方和**（**SSR**）：这是预测值与数据均值之间差异的估算。'
- en: '**Sum of Squared** **Errors** (**SSE**): This estimates the change between
    the original or genuine value and the forecasted value.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**误差平方和**（**SSE**）：这是原始值与预测值之间变化的估算。'
- en: '**Total Sum of Squares** (**SST**): This is the change between the original
    or genuine value and the mean of the data.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总平方和**（**SST**）：这是原始值与数据均值之间的变化。'
- en: MSE
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MSE
- en: 'MSE is an abbreviation of mean squared error. It is explained as the square
    of change between the original and forecasted values and the average between them
    for all the values:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: MSE是均方误差（Mean Squared Error）的缩写。它的定义为原始值与预测值之间变化的平方，以及所有值之间的平均值：
- en: '![](img/87b88053-52bb-470b-bc8a-79aea12bcc15.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/87b88053-52bb-470b-bc8a-79aea12bcc15.png)'
- en: Here, ![](img/9e6905e4-62fa-4828-a207-b87404efc49d.png) is the original value
    and ![](img/fe8a8b54-b9f3-4efc-a833-c3d640a21db2.png) is the forecasted value.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/9e6905e4-62fa-4828-a207-b87404efc49d.png) 是原始值，![](img/fe8a8b54-b9f3-4efc-a833-c3d640a21db2.png)
    是预测值。
- en: MAE
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MAE
- en: 'MAE is an abbreviation of mean absolute error. It is explained as the absolute
    change between the original and forecasted values and the average between them
    for all the values:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: MAE是均绝对误差（Mean Absolute Error）的缩写。它的定义为原始值与预测值之间的绝对变化，以及所有值之间的平均值：
- en: '![](img/5459d946-f2a9-4dd7-8e2a-d092deee0b12.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5459d946-f2a9-4dd7-8e2a-d092deee0b12.png)'
- en: Here, ![](img/da944b30-ee27-4bef-9cf2-3dc08dac979b.png) is the original value,
    and ![](img/13e98d6f-6465-4fd5-a4c1-190fa165ad54.png) is the forecasted value.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/da944b30-ee27-4bef-9cf2-3dc08dac979b.png) 是原始值，![](img/13e98d6f-6465-4fd5-a4c1-190fa165ad54.png)
    是预测值。
- en: RMSE
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RMSE
- en: 'RMSE is an abbreviation of root mean squared error. It is explained as the
    square root of MSE:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: RMSE 是均方根误差的缩写。它可以解释为 MSE 的平方根：
- en: '![](img/ab6ed537-f2b1-4d2a-b07d-9804a8d06828.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ab6ed537-f2b1-4d2a-b07d-9804a8d06828.png)'
- en: 'Let''s evaluate the model performance on a testing dataset. In the previous
    section, we predicted the values for the test set. Now, we will compare the predicted
    values with the actual values of the test set (`y_test`). scikit-learn offers
    the `metrics` class for evaluating the models. For regression model evaluation,
    we have methods for R-squared, MSE, MAE, and RMSE. Each of the methods takes two
    inputs: the actual values of the test set and the predicted values (`y_test` and
    `y_pred`). Let''s assess the performance of the linear regression model:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在测试数据集上评估模型性能。在前一部分，我们预测了测试集的值。现在，我们将预测值与测试集的实际值（`y_test`）进行比较。scikit-learn
    提供了 `metrics` 类来评估模型。对于回归模型评估，我们有 R 平方值、MSE、MAE 和 RMSE 的评估方法。每个方法都需要两个输入：测试集的实际值和预测值（`y_test`
    和 `y_pred`）。让我们评估线性回归模型的表现：
- en: '[PRE12]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This results in the following output:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE13]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In the example, we have evaluated the linear regression model using MAE, MSE,
    RMSE, and R-squared. Here, R-squared is 0.85, which indicates that the model explains
    the 85% variability of the data.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们通过 MAE、MSE、RMSE 和 R 平方值评估了线性回归模型。在这里，R 平方值为 0.85，表示该模型解释了数据 85% 的变异性。
- en: Fitting polynomial regression
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拟合多项式回归
- en: 'Polynomial regression is a type of regression analysis that is used to adapt
    the nonlinear relationships between dependent and independent variables. In this
    type of regression, variables are modeled as the *n*th polynomial degree. It is
    used to understand the growth rate of various phenomena, such as epidemic outbreaks
    and growth in sales. Let''s understand the equation of polynomial regression:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式回归是一种回归分析方法，用于适应因变量与自变量之间的非线性关系。在这种回归类型中，变量被建模为 *n* 次多项式的形式。它用于理解各种现象的增长率，如流行病爆发和销售增长。让我们理解一下多项式回归的方程：
- en: '![](img/36c4aef7-f852-4525-b590-229645ada4ee.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36c4aef7-f852-4525-b590-229645ada4ee.png)'
- en: Here, ![](img/cb087be6-8131-4041-b20a-5e1039fef70b.png) is the independent variable
    and ![](img/280499c8-5605-4576-9ddf-a5735ed52c18.png) is a dependent variable.
    The ![](img/df2c782f-57c3-4404-8788-ef97f52c6ecc.png) intercepts, ![](img/761a1c0b-b2d7-488a-981a-1f69e3c7b7b3.png)...![](img/ab186eaf-109d-42ef-b318-77731682d08c.png),
    are a coefficient of *x* and ![](img/31dddf97-8805-43a1-9041-8ba8eefe5a4c.png)
    (the Greek letter pronounced as epsilon) is an error term that will act as a random
    variable.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/cb087be6-8131-4041-b20a-5e1039fef70b.png) 是自变量，![](img/280499c8-5605-4576-9ddf-a5735ed52c18.png)
    是因变量。![](img/df2c782f-57c3-4404-8788-ef97f52c6ecc.png) 截距，![](img/761a1c0b-b2d7-488a-981a-1f69e3c7b7b3.png)...![](img/ab186eaf-109d-42ef-b318-77731682d08c.png)
    是 *x* 的系数，![](img/31dddf97-8805-43a1-9041-8ba8eefe5a4c.png)（这个希腊字母发音为 epsilon）是误差项，作为随机变量起作用。
- en: 'Let''s see an example to understand the polynomial concept in detail:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个例子来详细理解多项式概念：
- en: '[PRE14]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This results in the following output:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/eae9d6ca-ec61-44ce-b87f-4652b0bff8cd.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eae9d6ca-ec61-44ce-b87f-4652b0bff8cd.png)'
- en: 'In the preceding code, we have displayed a dataset that has a polynomial relationship.
    Let''s see how we can map this relationship in regression analysis:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们展示了一个具有多项式关系的数据集。让我们来看一下如何在回归分析中映射这个关系：
- en: '[PRE15]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This results in the following output:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/a159cce1-d335-4ef7-8326-bf8697e80e27.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a159cce1-d335-4ef7-8326-bf8697e80e27.png)'
- en: In the preceding code, we have read the polynomial relationship dataset, converted
    the *X* column into a polynomial *n*th degree column using `PolynomialFeatures()`,
    and then applied linear regression on `X_polynomial` and `label`. The preceding
    output plot shows that the resultant model captures the performance. Now, it's
    time to jump to another type of regression model, which can be used for classification
    purposes.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们读取了多项式关系数据集，使用 `PolynomialFeatures()` 将 *X* 列转换为多项式 *n* 次方列，然后对 `X_polynomial`
    和 `label` 应用了线性回归。前面的输出图显示了结果模型的表现。现在，轮到我们转向另一种回归模型，这种模型可以用于分类目的。
- en: Regression models for classification
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于分类的回归模型
- en: Classification is the most utilized technique in the area of machine and statistical
    learning. Most machine learning problems are classification problems, such as
    detecting spam emails, analyzing financial risk, churn analysis, and discovering
    potential customers.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是机器学习和统计学习领域中使用最多的技术。大多数机器学习问题都是分类问题，例如，垃圾邮件检测、金融风险分析、客户流失分析以及潜在客户发现等。
- en: 'Classification can be of two types: binary and multi-class classification.
    Binary classification target variables have only two values: either 0 and 1 or
    yes or no. Examples of binary classification are whether a customer will buy an
    item or not, whether the customer will switch or churn to another brand or not,
    spam detection, disease prediction, and whether a loan applicant will default
    or not. Multi-class classification has more than two classes, for example, for
    categories of news articles, the classes could be sports, politics, business,
    and many more.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 分类可以分为两种类型：二分类和多分类。二分类目标变量只有两个值：0 和 1，或者是是和否。例如，二分类的实例包括：客户是否会购买某商品，客户是否会转向其他品牌或流失，垃圾邮件检测，疾病预测，以及贷款申请者是否会违约等。多分类则有多个类别，例如，新闻文章的类别可以包括体育、政治、商业等多个类。
- en: Logistic regression is one of the classification methods, although its name
    ends with regression. It is a commonly used binary class classification method.
    It is a basic machine learning algorithm for all kinds of classification problems.
    It finds the association between dependent (or target) variables and sets of independent
    variables (or features). In the next section, we will look at logistic regression
    in detail.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是其中一种分类方法，尽管它的名字以“回归”结尾。它是一种常用的二分类方法，是解决各种分类问题的基础机器学习算法。它找出因变量（或目标变量）与一组自变量（或特征）之间的关联。在接下来的部分中，我们将详细介绍逻辑回归。
- en: Logistic regression
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: 'Logistic regression is a kind of supervised machine learning algorithm that
    is utilized to forecast a binary outcome and classify observations. Its dependent
    variable is a binary variable with two classes: 0 or 1\. For example, it can be
    used to detect whether a loan applicant will default or not. It is a unique type
    of regression where the dependent or target variable is binary. It computes a
    log of the odds ratio of the target variable, which represents the probability
    of occurrence of an event, for example, the probability of a person suffering
    from diabetes.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一种有监督的机器学习算法，用于预测二元结果并进行观察分类。其因变量是一个二元变量，具有两个类别：0 或 1。例如，它可以用来检测贷款申请者是否会违约。它是一种特殊类型的回归，其中因变量是二元的。它计算目标变量的赔率比的对数，表示某事件发生的概率，例如，一个人患糖尿病的概率。
- en: 'Logistic regression is a kind of simple linear regression where the dependent
    or target variable is categorical. It uses the sigmoid function on the prediction
    result of linear regression. We can also use the logistic regression algorithm
    for multiple target classes. For multiple-class problems, it is called multinomial
    logistic regression. Multinomial logistic regression is a modification of logistic
    regression; it uses the softmax function instead of the sigmoid activation function:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一种简单的线性回归，其中因变量或目标变量是类别型的。它在线性回归的预测结果上使用了 sigmoid 函数。我们还可以使用逻辑回归算法来处理多个目标类别。在多类别问题中，它被称为多项逻辑回归。多项逻辑回归是对逻辑回归的一种修改；它使用
    softmax 函数代替 sigmoid 激活函数：
- en: '![](img/1dd8a555-b048-4adc-8249-330fd32b39a6.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1dd8a555-b048-4adc-8249-330fd32b39a6.png)'
- en: 'The sigmoid function is also known as a logistic function or an S-shaped curve.
    It maps input values between the ranges 0 and 1, which represents the probability
    of occurrence of an event. If the curve moves toward positive infinity, then the
    outcome becomes 1 and if the curve moves toward negative infinity, then the outcome
    becomes 1\. Let''s see the formula for the sigmoid function and logistic regression
    equation:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid 函数也叫做逻辑函数或 S 形曲线。它将输入值映射到 0 到 1 之间，这表示某事件发生的概率。如果曲线向正无穷延伸，则结果变为 1；如果曲线向负无穷延伸，则结果变为
    0。让我们看看 Sigmoid 函数和逻辑回归方程的公式：
- en: '![](img/8786165a-b015-4d0d-bfb9-b2e9e7bd4717.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8786165a-b015-4d0d-bfb9-b2e9e7bd4717.png)'
- en: 'The following formula shows the logistic regression equation:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 以下公式展示了逻辑回归方程：
- en: '![](img/681655c1-e4f0-470b-9df2-0bd7f8bece73.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/681655c1-e4f0-470b-9df2-0bd7f8bece73.png)'
- en: 'The term in the `log()` function is known as an odds ratio or "odds." The odds
    ratio is the ratio of the probability of the occurrence of an event to the probability
    of not occurrence of an event. In the following graph, you can see how logistic
    regression output behaves:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`log()` 函数中的项称为赔率比或“赔率”。赔率比是事件发生的概率与事件不发生的概率之比。在下图中，您可以看到逻辑回归输出的表现：'
- en: '![](img/55c4ce11-4880-4a18-9cef-47f075533ddc.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/55c4ce11-4880-4a18-9cef-47f075533ddc.png)'
- en: We can see the ratio lands roughly around 0.5 here. Let's explore logistic regression
    a bit more in the upcoming subsections.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这里的比率大致在 0.5 左右。接下来我们将在下面的小节中进一步探讨逻辑回归。
- en: Characteristics of the logistic regression model
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归模型的特点
- en: 'In this subsection, we will focus on the basic characteristics and assumptions
    of logistic regression. Let''s understand the following characteristics:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们将重点讨论逻辑回归的基本特征和假设。让我们了解以下特征：
- en: The dependent or target variable should be binary in nature.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因变量或目标变量应为二元类型。
- en: There should be no multicollinearity among independent variables.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自变量之间不应存在多重共线性。
- en: Coefficients are estimated using maximum likelihood.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系数通过最大似然法估计。
- en: Logistic regression follows Bernoulli distribution.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归遵循伯努利分布。
- en: There is no R-squared for model evaluation. The model was evaluated using concordance,
    KS statistics.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型没有 R 平方值用于评估。模型通过一致性和 KS 统计量进行评估。
- en: Types of logistic regression algorithms
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归算法类型
- en: 'There are various types of logistic regression algorithms available for different
    use cases and scenarios. In this section, we will focus on binary, multinomial,
    and ordinal logistic regression. Let''s see each of them and understand where
    we can utilize them:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的逻辑回归算法适用于不同的使用场景和情境。在本节中，我们将重点讨论二项逻辑回归、多项逻辑回归和顺序逻辑回归。让我们逐一了解这些模型，并理解它们的应用场景：
- en: '**Binary logistic regression m****odel**:'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二项逻辑回归模型**：'
- en: In the binary logistic regression model, the dependent or target column has
    only two values, such as whether a loan will default or not default, an email
    is spam or not spam, or a patient is diabetic or non-diabetic.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在二项逻辑回归模型中，因变量或目标列只有两个取值，例如贷款是否违约、电子邮件是否为垃圾邮件，或者患者是否为糖尿病患者。
- en: '**Multinomial logistic regression model**:'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多项逻辑回归模型**：'
- en: In a multinomial logistic regression model, a dependent or target column has
    three or more than three values, such as predicting the species of the iris flower
    and predicting the category of news articles, such as politics, business, and
    sports.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在多项逻辑回归模型中，因变量或目标列有三个或更多的取值，例如预测鸢尾花的种类，或预测新闻文章的类别，如政治、商业和体育。
- en: '**Ordinal logistic regression**:'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**顺序逻辑回归**：'
- en: In the ordinal logistic regression model, a dependent variable will have ordinal
    or sequence classes, such as movie and hotel ratings.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在顺序逻辑回归模型中，因变量将具有顺序或序列类别，例如电影和酒店评分。
- en: Advantages and disadvantages of logistic regression
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归的优缺点
- en: The logistic regression model not only provides prediction (0 or 1) but also
    gives the probabilities of outcomes, which helps us to understand the confidence
    of a prediction. It is easy to implement and understand and is interpretable.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型不仅提供预测（0 或 1），还给出结果的概率，这有助于我们理解预测的置信度。它易于实现和理解，并且具有可解释性。
- en: A large number of independent variables will increase the amount of variance
    explained, which results in model overfitting. Logistic regression cannot work
    with non-linear relationships. It will also not perform well with highly correlated
    feature variables (or independent variables).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果自变量数量过多，将增加解释的方差，这会导致模型过拟合。逻辑回归无法处理非线性关系，并且在特征变量（或自变量）高度相关时表现不佳。
- en: Implementing logistic regression using scikit-learn
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 实现逻辑回归
- en: 'Now that you know all about logistic regression, let''s implement it in Python
    using the `scikit-learn` library. Let''s create a model using naive Bayes classification.
    We will do so using the following steps:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了逻辑回归的所有内容，接下来让我们使用 `scikit-learn` 库在 Python 中实现它。我们将使用朴素贝叶斯分类来创建模型。我们将通过以下步骤进行：
- en: 'We will first import the dataset and the required libraries using the following
    code:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先导入数据集和所需的库，使用以下代码：
- en: '[PRE16]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This results in the following output:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/becd7d75-8005-43aa-9a97-1458940b7744.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/becd7d75-8005-43aa-9a97-1458940b7744.png)'
- en: In our preceding example, we are reading the Pima Indians Diabetes dataset.
    This dataset does not give the column names, so we have to do so.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们正在读取Pima Indians糖尿病数据集。此数据集没有列名，因此我们需要手动添加列名。
- en: 'In the `read_csv()` function, we will pass the header to `None` and names to
    the column list that was created before reading the CSV file:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`read_csv()`函数中，我们将`header`设置为`None`，并将之前创建的列名列表传递给`names`参数：
- en: '[PRE17]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After loading the dataset, we need to divide the dataset into independent (feature
    set) column features and dependent (or label) column targets. After this, the
    dataset will be partitioned into training and testing sets. Now, both the dependent
    and independent columns are divided into train and test sets (`feature_train`,
    `feature_test`, `target_train`, and `target_test`) using `train_test_split()`.
    `train_test_split()` takes dependent and independent DataFrames, `test_size` and
    `random_state`. Here, `test_size` will decide the ratio of the train-test split
    (that is, a `test_size` value of `0.3` means 30% testing set and the remaining
    70% will be the training set), and `random_state` is used as a seed value for
    reproducing the same data split each time. If `random_state` is `None`, then it
    will randomly split the records each time, which will give different performance
    measures:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据集后，我们需要将数据集分为独立（特征集）列特征和依赖（或标签）列目标。之后，数据集将被划分为训练集和测试集。现在，依赖列和独立列将使用`train_test_split()`函数分为训练集和测试集（`feature_train`、`feature_test`、`target_train`和`target_test`）。`train_test_split()`接受依赖和独立的DataFrame，`test_size`和`random_state`。其中，`test_size`决定训练-测试数据集的划分比例（例如，`test_size`为`0.3`表示30%的数据用于测试集，剩余的70%用于训练集），而`random_state`用作种子值，以确保每次划分的数据集相同。如果`random_state`为`None`，则每次都会随机划分记录，可能会得到不同的性能指标：
- en: '[PRE18]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This results in the following output:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '[PRE19]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now, we are ready to create a logistic regression model. First, we will import
    the `LogisticRegression` class and create its object or model. This model will
    fit on the training dataset (`X_train` and `y_train`). After training, the model
    is ready to make predictions using the `predict()` method. scikit-learn's `metrics`
    class offers various methods for performance evaluation, such as accuracy. The
    `accuracy_score()` methods will take actual labels (`y_test`) and predicted labels
    (`y_pred`).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备好创建一个逻辑回归模型。首先，我们将导入`LogisticRegression`类并创建其对象或模型。该模型将在训练数据集（`X_train`和`y_train`）上进行训练。训练完成后，模型即可使用`predict()`方法进行预测。scikit-learn的`metrics`类提供了多种性能评估方法，如准确率。`accuracy_score()`方法将接受实际标签（`y_test`）和预测标签（`y_pred`）。
- en: Summary
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discovered regression analysis algorithms. This will benefit
    you in gaining an important skill for predictive data analysis. You have gained
    an understanding of concepts such as regression analysis, multicollinearity, dummy
    variables, regression evaluation measures, and logistic regression. The chapter
    started with simple linear and multiple regressions. After simple linear and multiple
    regressions, our main focus was on multicollinearity, model development, and model
    evaluation measures. In later sections, we focused on logistic regression, characteristics,
    types of regression, and its implementation.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了回归分析算法。这将帮助你获得进行预测数据分析的重要技能。你已经掌握了回归分析、多重共线性、虚拟变量、回归评估指标和逻辑回归等概念。本章从简单线性回归和多重回归开始，之后我们的主要重点是多重共线性、模型开发和模型评估指标。在后续部分，我们重点介绍了逻辑回归、回归的特点、回归类型及其实现。
- en: The next chapter, [Chapter 10](ed220fe6-db8c-4167-8442-27233d957d09.xhtml),
    *Supervised Learning – Classification Techniques*, will focus on classification,
    its techniques, the train-test split strategy, and performance evaluation measures.
    In later sections, the focus will be on data splitting, the confusion matrix,
    and performance evaluation measures such as accuracy, precision, recall, F1-score,
    ROC, and AUC.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章，[第10章](ed220fe6-db8c-4167-8442-27233d957d09.xhtml)，*监督学习 – 分类技术*，将重点讨论分类及其技术、训练-测试数据集划分策略和性能评估指标。在后续部分，我们将重点介绍数据划分、混淆矩阵以及性能评估指标，如准确率、精确度、召回率、F1分数、ROC和AUC。
