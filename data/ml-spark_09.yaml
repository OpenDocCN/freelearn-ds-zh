- en: Dimensionality Reduction with Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark进行降维
- en: Over the course of this chapter, we will continue our exploration of unsupervised
    learning models in the form of **dimensionality reduction**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的过程中，我们将继续探索**降维**的无监督学习模型。
- en: Unlike the models we have covered so far, such as regression, classification,
    and clustering, dimensionality reduction does not focus on making predictions.
    Instead, it tries to take a set of input data with a feature dimension *D* (that
    is, the length of our feature vector), and extracts a representation of the data
    of dimension *k*, where *k* is usually significantly smaller than *D*. It is,
    therefore, a form of preprocessing or feature transformation rather than a predictive
    model in its own right.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与迄今为止我们所涵盖的模型（如回归、分类和聚类）不同，降维并不专注于进行预测。相反，它试图对具有特征维度*D*（即我们的特征向量的长度）的输入数据进行处理，并提取维度*k*的数据表示，其中*k*通常明显小于*D*。因此，它是一种预处理或特征转换，而不是一种独立的预测模型。
- en: It is important that the representation that is extracted should still be able
    to capture a large proportion of the variability or structure of the original
    data. The idea behind this is that most data sources will contain some form of
    underlying structure. This structure is typically unknown (often called latent
    features or latent factors), but if we can uncover some of this structure, our
    models could learn this structure, and make predictions from it rather than from
    the data in its raw form, which might be noisy or contain many irrelevant features.
    In other words, dimensionality reduction throws away some of the noise in the
    data, and keeps the hidden structure that is present.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，提取的表示仍应能够捕获原始数据的大部分变异性或结构。其背后的想法是，大多数数据源都会包含某种潜在结构。这种结构通常是未知的（通常称为潜在特征或潜在因素），但如果我们能够揭示部分结构，我们的模型就可以从中学习并进行预测，而不是直接从原始数据中进行预测，原始数据可能存在噪声或包含许多无关特征。换句话说，降维会丢弃数据中的一些噪声，并保留其中存在的隐藏结构。
- en: In some cases, the dimensionality of the raw data is far higher than the number
    of data points we have, so, without dimensionality reduction, it would be difficult
    for other machine learning models, such as classification and regression, to learn
    anything, as they need to fit a number of parameters that is far larger than the
    number of training examples (in this sense, these methods bear some similarity
    to the regularization approaches that we have seen being used in classification
    and regression).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，原始数据的维度远高于我们拥有的数据点数量，因此，如果没有降维，其他机器学习模型（如分类和回归）将很难学习任何东西，因为它们需要拟合的参数数量远大于训练样本的数量（在这种意义上，这些方法与我们在分类和回归中看到的正则化方法有些相似）。
- en: 'A few use cases of dimensionality reduction techniques include the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 降维技术的一些用例包括以下内容：
- en: Exploratory data analysis
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: Extracting features to train other machine learning models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取特征以训练其他机器学习模型
- en: Reducing storage and computation requirements for very large models in the prediction
    phase (for example, a production system that makes predictions)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少预测阶段非常大模型的存储和计算要求（例如，进行预测的生产系统）
- en: Reducing a large group of text documents down to a set of hidden topics or concepts
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将大量文本文档减少到一组隐藏的主题或概念
- en: Making learning and generalization of models easier when our data has a very
    large number of features (for example, when working with text, sound, images,
    or video data, which tends to be very high-dimensional)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们的数据具有非常多的特征时（例如在处理文本、声音、图像或视频数据时，这些数据往往是高维的），使模型的学习和泛化变得更容易
- en: 'In this chapter, we will do the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将进行以下操作：
- en: Introduce the types of dimensionality reduction models available in MLlib
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍MLlib中可用的降维模型类型
- en: Work with images of faces to extract features suitable for dimensionality reduction
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理人脸图像以提取适合降维的特征
- en: Train a dimensionality reduction model using MLlib
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MLlib训练降维模型
- en: Visualize and evaluate the results
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化和评估结果
- en: Perform parameter selection for our dimensionality reduction model
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为我们的降维模型执行参数选择
- en: Types of dimensionality reduction
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 降维的类型
- en: MLlib provides two models for dimensionality reduction; these models are closely
    related to each other. These models are **Principal Components Analysis** (**PCA**)
    and **Singular Value Decomposition** (**SVD**).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib提供了两种降维模型；这些模型彼此密切相关。这些模型是**主成分分析**（**PCA**）和**奇异值分解**（**SVD**）。
- en: Principal components analysis
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主成分分析
- en: PCA operates on a data matrix *X*, and seeks to extract a set of *k* principal
    components from *X*. The principal components are each uncorrelated to each other,
    and are computed such that the first principal component accounts for the largest
    variation in the input data. Each subsequent principal component is, in turn,
    computed such that it accounts for the largest variation, provided that it is
    independent of the principal components computed so far.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: PCA作用于数据矩阵*X*，并试图从*X*中提取一组*k*个主成分。这些主成分彼此不相关，并且计算它们的方式是，第一个主成分解释了输入数据中的最大变异性。然后，每个后续的主成分依次计算，以便它解释了最大的变异性，前提是它与迄今为止计算的主成分是独立的。
- en: In this way, the *k* principal components returned are guaranteed to account
    for the highest amount of variation in the input data possible. Each principal
    component, in fact, has the same feature dimensionality as the original data matrix.
    Hence, a projection step is required in order to actually perform dimensionality
    reduction, where the original data is projected into the *k*-dimensional space
    represented by the principal components.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，返回的 *k* 个主成分保证能够解释输入数据中的最大变化量。实际上，每个主成分的特征维度与原始数据矩阵相同。因此，实际进行降维需要投影步骤，其中原始数据被投影到由主成分表示的
    *k* 维空间中。
- en: Singular value decomposition
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奇异值分解
- en: 'SVD seeks to decompose a matrix *X* of dimension *m x n* into these three component
    matrices:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: SVD旨在将维度为 *m x n* 的矩阵 *X* 分解为这三个组件矩阵：
- en: '*U* of dimension *m x m*'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*U* 的维度为 *m x m*'
- en: '*S*, a diagonal matrix of size *m x n*; the entries of *S* are referred to
    as the **singular values**'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*S*，大小为 *m x n* 的对角矩阵；*S* 的条目被称为**奇异值**'
- en: '*VT* of dimension *n x n*'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*VT* 的维度为 *n x n*'
- en: '*X = U * S * V ^T*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*X = U * S * V ^T*'
- en: 'Looking at the preceding formula, it appears that we have not reduced the dimensionality
    of the problem at all, as by multiplying *U*, *S*, and *V*, we reconstruct the
    original matrix. In practice, the truncated SVD is usually computed. That is,
    only the top k singular values, which represent the most variation in the data,
    are kept, while the rest are discarded. The formula to reconstruct *X* based on
    the component matrices is then approximate, and is given as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的公式可以看出，我们实际上并没有降低问题的维度，因为通过乘以 *U*、*S* 和 *V*，我们重构了原始矩阵。实际上，通常计算截断奇异值分解。也就是说，只保留最高的
    *k* 个奇异值，它们代表数据中的最大变化量，而其余的则被丢弃。然后基于组件矩阵重构 *X* 的公式是近似的，如下所示：
- en: '*X ~ U[k] * S[k] * V[k T]*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*X ~ U[k] * S[k] * V[k T]*'
- en: 'An illustration of the truncated SVD is shown in this diagram:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 截断奇异值分解的示意图如下所示：
- en: '![](img/image_09_001.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_09_001.png)'
- en: The truncated singular value decomposition
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 截断奇异值分解
- en: Keeping the top *k* singular values is similar to keeping the top *k* principal
    components in PCA. In fact, SVD and PCA are directly related, as we will see a
    little later in this chapter.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 保留前 *k* 个奇异值类似于在PCA中保留前 *k* 个主成分。实际上，SVD和PCA直接相关，我们稍后会在本章中看到。
- en: A detailed mathematical treatment of both PCA and SVD is beyond the scope of
    this book.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对PCA和SVD的详细数学处理超出了本书的范围。
- en: An overview of dimensionality reduction can be found in the Spark documentation
    at [http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html](http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark文档中可以找到降维的概述：[http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html](http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html)。
- en: 'The following links contain a more in-depth mathematical overview of PCA and
    SVD respectively: [http://en.wikipedia.org/wiki/Principal_component_analysis](http://en.wikipedia.org/wiki/Principal_component_analysis) and [http://en.wikipedia.org/wiki/Singular_value_decomposition](http://en.wikipedia.org/wiki/Singular_value_decomposition).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下链接分别包含PCA和SVD的更深入的数学概述：[http://en.wikipedia.org/wiki/Principal_component_analysis](http://en.wikipedia.org/wiki/Principal_component_analysis)
    和 [http://en.wikipedia.org/wiki/Singular_value_decomposition](http://en.wikipedia.org/wiki/Singular_value_decomposition)。
- en: Relationship with matrix factorization
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与矩阵分解的关系
- en: PCA and SVD are both matrix factorization techniques, in the sense that they
    decompose a data matrix into subcomponent matrices, each of which has a lower
    dimension (or rank) than the original matrix. Many other dimensionality reduction
    techniques are based on matrix factorization.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: PCA和SVD都是矩阵分解技术，它们将数据矩阵分解为具有比原始矩阵更低维度（或秩）的子组件矩阵。许多其他降维技术都是基于矩阵分解的。
- en: 'You might remember another example of matrix factorization, that is, collaborative
    filtering, which we have already seen in [Chapter 6](d3bf76a8-26be-4db7-8310-b936d220407e.xhtml),
    *Building a Classification Model with Spark*. Matrix factorization approaches
    to collaborative filtering work by factorizing the ratings matrix into two components:
    the user factor matrix and the item factor matrix. Each of these has a lower dimension
    than the original data, so these methods also act as dimensionality reduction
    models.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得另一个矩阵分解的例子，即协同过滤，我们在[第6章](d3bf76a8-26be-4db7-8310-b936d220407e.xhtml)中已经看到了，*使用Spark构建分类模型*。协同过滤的矩阵分解方法通过将评分矩阵分解为两个组件来工作：用户因子矩阵和物品因子矩阵。每个矩阵的维度都低于原始数据，因此这些方法也充当降维模型。
- en: Many of the best performing approaches to collaborative filtering include models
    based on SVD. Simon Funk's approach to the Netflix prize is a famous example.
    You can look it up at [http://sifter.org/~simon/journal/20061211.html](http://sifter.org/~simon/journal/20061211.html).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 许多最佳的协同过滤方法都包括基于SVD的模型。Simon Funk对Netflix奖的方法就是一个著名的例子。您可以在[http://sifter.org/~simon/journal/20061211.html](http://sifter.org/~simon/journal/20061211.html)上查看。
- en: Clustering as dimensionality reduction
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类作为降维
- en: 'The clustering models we covered in the previous chapter can also be used for
    a form of dimensionality reduction. This works in the following way:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章中介绍的聚类模型也可以用于一种形式的降维。工作方式如下：
- en: Assume that we cluster our high-dimensional feature vectors using a K-means
    clustering model, with k clusters. The result is a set of *k* cluster centers.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设我们使用K均值聚类模型对高维特征向量进行聚类，得到 *k* 个聚类中心。
- en: We can represent each of our original data points in terms of how far it is
    from each of these cluster centers. That is, we can compute the distance of a
    data point to each cluster center. The result is a set of *k* distances for each
    data point.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以表示原始数据点中的每一个数据点与每个聚类中心的距离。也就是说，我们可以计算数据点到每个聚类中心的距离。结果是每个数据点的一组 *k* 个距离。
- en: These *k* distances can form a new vector of dimension *k*. We can now represent
    our original data as a new vector of lower dimension relative to the original
    feature dimension.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些*k*距离可以形成一个新的*k*维向量。现在，我们可以将我们的原始数据表示为相对于原始特征维度的较低维度的新向量。
- en: Depending on the distance metric used, this can result in both dimensionality
    reduction and a form of nonlinear transformation of the data, allowing us to learn
    a more complex model, while still benefiting from the speed and scalability of
    a linear model. For example, using a Gaussian or exponential distance function
    can approximate a very complex nonlinear feature transformation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 根据使用的距离度量，这可能导致数据的降维和一种非线性转换形式，使我们能够学习一个更复杂的模型，同时仍然受益于线性模型的速度和可扩展性。例如，使用高斯或指数距离函数可以近似一个非常复杂的非线性特征转换。
- en: Extracting the right features from your data
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据中提取正确的特征
- en: As with all machine learning models we have explored so far, dimensionality
    reduction models also operate on a feature vector representation of our data.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 与迄今为止我们所探索的所有机器学习模型一样，降维模型也是在我们数据的特征向量表示上操作的。
- en: For this chapter, we will dive into the world of image processing, using the
    **Labeled Faces in the Wild** (**LFW**) dataset of facial images. This dataset
    contains over 13,000 images of faces generally taken from the Internet, and belonging
    to well-known public figures. The faces are labeled with the person's name.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨图像处理领域，使用**野外标记人脸**（**LFW**）数据集的面部图像。该数据集包含来自互联网的超过13,000张面部图像，并属于知名公众人物。这些面部带有人名标签。
- en: Extracting features from the LFW dataset
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从LFW数据集中提取特征
- en: In order to avoid having to download and process a very large dataset, we will
    work with a subset of the images, using people who have names that start with
    an A. This dataset can be downloaded from [http://vis-www.cs.umass.edu/lfw/lfw-a.tgz](http://vis-www.cs.umass.edu/lfw/lfw-a.tgz).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免下载和处理非常庞大的数据集，我们将使用一部分图像，使用以A开头的人名。该数据集可以从[http://vis-www.cs.umass.edu/lfw/lfw-a.tgz](http://vis-www.cs.umass.edu/lfw/lfw-a.tgz)下载。
- en: For more details and other variants of the data, visit [http://vis-www.cs.umass.edu/lfw/](http://vis-www.cs.umass.edu/lfw/).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多详细信息和数据的其他变体，请访问[http://vis-www.cs.umass.edu/lfw/](http://vis-www.cs.umass.edu/lfw/)。
- en: 'The original research paper reference is:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 原始研究论文的引用是：
- en: '*Gary B. Huang*, *Manu Ramesh*, *Tamara Berg*, and *Erik Learned-Miller*. *Labeled
    Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments*.
    University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*Gary B. Huang*，*Manu Ramesh*，*Tamara Berg*和*Erik Learned-Miller*。*野外标记人脸：用于研究非受限环境中人脸识别的数据库*。马萨诸塞大学阿默斯特分校，技术报告07-49，2007年10月。'
- en: It can be downloaded from [http://vis-www.cs.umass.edu/lfw/lfw.pdf](http://vis-www.cs.umass.edu/lfw/lfw.pdf).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以从[http://vis-www.cs.umass.edu/lfw/lfw.pdf](http://vis-www.cs.umass.edu/lfw/lfw.pdf)下载。
- en: 'Unzip the data using the following command:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令解压数据：
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This will create a folder called `lfw`, which contains a number of subfolders,
    one for each person.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个名为`lfw`的文件夹，其中包含许多子文件夹，每个人一个。
- en: Exploring the face data
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索面部数据
- en: 'We will use the Spark application to analyze the data. Make sure the data is
    unzipped into the `data` folder as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Spark应用程序来分析数据。确保数据解压缩到`data`文件夹中，如下所示：
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The actual code is in the `scala` folder, except a few graphs, which are in
    the `python` folder:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的代码在`scala`文件夹中，除了一些图表在`python`文件夹中：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now that we've unzipped the data, we face a small challenge. Spark provides
    us with a way to read text files and custom Hadoop input data sources. However,
    there is no built-in functionality to allow us to read images.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经解压了数据，我们面临一个小挑战。Spark为我们提供了一种读取文本文件和自定义Hadoop输入数据源的方法。但是，没有内置功能允许我们读取图像。
- en: Spark provides a method called `wholeTextFiles`, which allows us to operate
    on entire files at once, compared to the `textFile` method that we have been using
    so far, which operates on the individual lines within a text file (or multiple
    files).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供了一个名为`wholeTextFiles`的方法，允许我们一次操作整个文件，与我们迄今为止一直使用的`textFile`方法相比，后者操作文本文件（或多个文件）中的各行。
- en: We will use the `wholeTextFiles` method to access the location of each file.
    Using these file paths, we will write custom code to load and process the images.
    In the following example code, we will use PATH to refer to the directory in which
    you extracted the `lfw` subdirectory.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`wholeTextFiles`方法来访问每个文件的位置。使用这些文件路径，我们将编写自定义代码来加载和处理图像。在下面的示例代码中，我们将使用PATH来引用您提取`lfw`子目录的目录。
- en: 'We can use a wildcard path specification (using the * character highlighted
    in the following code snippet) to tell Spark to look for files in each directory
    under the `lfw` directory:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用通配符路径规范（在下面的代码片段中突出显示*字符）告诉Spark在`lfw`目录下的每个目录中查找文件：
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Running the `first` command might take a little time, as Spark first scans
    the specified directory structure for all available files. Once completed, you
    should see an output similar to the one shown here:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`first`命令可能需要一些时间，因为Spark首先会扫描指定的目录结构以查找所有可用的文件。完成后，您应该看到类似于此处显示的输出：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You will see that `wholeTextFiles` returns an RDD that contains key-value pairs,
    where the key is the file location, while the value is the content of the entire
    text file. For our purposes, we only care about the file path, as we cannot work
    directly with the image data as a string (notice that it is displayed as "binary
    nonsense" in the shell output).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到`wholeTextFiles`返回一个包含键值对的RDD，其中键是文件位置，而值是整个文本文件的内容。对于我们的目的，我们只关心文件路径，因为我们不能直接将图像数据作为字符串处理（请注意，在shell输出中显示为“二进制无意义”）。
- en: Let's extract the file paths from the RDD. Note that earlier, the file path
    starts with the `file:` text. This is used by Spark when reading files in order
    to differentiate between different filesystems (for example, `file://` for the
    local filesystem, `hdfs://` for HDFS, `s3n://` for Amazon S3, and so on).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从RDD中提取文件路径。请注意，之前文件路径以`file:`文本开头。这是Spark在读取文件时使用的，以区分不同的文件系统（例如，本地文件系统的`file://`，HDFS的`hdfs://`，Amazon
    S3的`s3n://`等）。
- en: 'In our case, we will use custom code to read the images, so we don''t need
    this part of the path. Thus, we will remove it with the following `map` function:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们将使用自定义代码来读取图像，因此我们不需要路径的这一部分。因此，我们将使用以下`map`函数将其删除：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding function will display the file location with the `file:` prefix
    removed:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 上述函数将显示去除了`file:`前缀的文件位置：
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we will see how many files we are dealing with:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看到我们要处理多少个文件：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Running these commands creates a lot of noisy output in Spark, as it outputs
    all the file paths that are read to the console. Ignore this part, but after the
    command has completed, the output should look something like this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这些命令会在Spark中创建大量嘈杂的输出，因为它会将所有读取到的文件路径输出到控制台。忽略这部分，但在命令完成后，输出应该看起来像这样：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: So, we can see that we have `1055` images to work with.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到我们有`1055`张图像可以使用。
- en: Visualizing the face data
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化面部数据
- en: Although there are a few tools available in Scala or Java to display images,
    this is one area where Python and the `matplotlib` library shine. We will use
    Scala to process and extract the images and run our models, and IPython to display
    the actual images.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Scala或Java中有一些工具可用于显示图像，但这是Python和`matplotlib`库发光的一个领域。我们将使用Scala来处理和提取图像并运行我们的模型，使用IPython来显示实际的图像。
- en: 'You can run a separate IPython Notebook by opening a new terminal window and
    launching a new notebook as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过打开新的终端窗口并启动新的笔记本来运行单独的IPython笔记本，如下所示：
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If using Python Notebook, you should first execute the following code snippet
    to ensure that the images are displayed inline after each notebook cell (including
    the `%` character): `%pylab inline`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用Python Notebook，您应该首先执行以下代码片段，以确保在每个笔记本单元格之后内联显示图像（包括`%`字符）：`%pylab inline`
- en: 'Alternatively, you can launch a plain IPython console without the web notebook,
    enabling the `pylab` plotting functionality using the following command:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以启动一个普通的IPython控制台，而不是Web笔记本，使用以下命令启用`pylab`绘图功能：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The dimensionality reduction techniques in MLlib are only available in Scala
    or Java at the time of writing this book, so we will continue to use the Scala
    Spark shell to run the models. Therefore, you won't need to run a PySpark console.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，MLlib中的降维技术仅在Scala或Java中可用，因此我们将继续使用Scala Spark shell来运行模型。因此，您不需要运行PySpark控制台。
- en: We have provided the full Python code with this chapter as a Python script as
    well as in the IPython Notebook format. For instructions on installing IPython,
    see the code bundle.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提供了本章的完整Python代码，既作为Python脚本，也作为IPython笔记本格式。有关安装IPython的说明，请参阅代码包。
- en: 'Let''s display the image given by the first path, which we extracted earlier
    using PIL''s image library:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们显示通过之前提取的第一个路径给出的图像，使用PIL的图像库：
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You should see the screenshot displayed as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到截图显示如下：
- en: '![](img/image_09_002.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_09_002.png)'
- en: Extracting facial images as vectors
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取面部图像作为向量
- en: While a full treatment of image processing is beyond the scope of this book,
    you will need to know a few basics to proceed. Each color image can be represented
    as a three-dimensional array, or matrix, of pixels. The first two dimensions,
    that is the *x* and *y* axes, represent the position of each pixel, while the
    third dimension represents the **Red**, **Blue**, and **Green** (**RGB**) color
    values for each pixel.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本书不涵盖图像处理的全部内容，但您需要了解一些基础知识才能继续。每个彩色图像可以表示为一个像素的三维数组或矩阵。前两个维度，即*x*和*y*轴，表示每个像素的位置，而第三个维度表示每个像素的**红**、**蓝**和**绿**（**RGB**）颜色值。
- en: A grayscale image only requires one value per pixel (there are no RGB values),
    so it can be represented as a plain two-dimensional matrix. For many image processing
    and machine learning tasks related to images, it is common to operate on grayscale
    images. We will do this here by converting the color images to grayscale first.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 灰度图像每个像素只需要一个值（没有RGB值），因此它可以表示为一个普通的二维矩阵。对于许多与图像相关的图像处理和机器学习任务，通常会对灰度图像进行操作。我们将通过首先将彩色图像转换为灰度图像来实现这一点。
- en: It is also a common practice in machine learning tasks to represent an image
    as a vector instead of a matrix. We do this by concatenating each row (or, alternatively,
    each column) of the matrix to form a long vector (this is known as `reshaping`).
    In this way, each raw, grayscale image matrix is transformed into a feature vector,
    which is usable as input to a machine learning model.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习任务中，将图像表示为向量而不是矩阵也是一种常见做法。我们通过将矩阵的每一行（或者每一列）连接起来形成一个长向量来实现这一点（这被称为“重塑”）。这样，每个原始的灰度图像矩阵被转换成一个特征向量，可用作机器学习模型的输入。
- en: Fortunately, for us, the built-in Java **Abstract Window Toolkit** (**AWT**)
    contains various basic image-processing functions. We will define a few utility
    functions to perform this processing using the `java.awt` classes.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，内置的Java **抽象窗口工具包**（**AWT**）包含各种基本的图像处理功能。我们将定义一些实用函数来使用`java.awt`类执行此处理。
- en: Loading images
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载图像
- en: The first of these is a function to read an image from a file.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个是从文件中读取图像的函数。
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This preceding code is available in `Util.scala`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码在`Util.scala`中可用。
- en: 'This returns an instance of a `java.awt.image.BufferedImage` class, which stores
    the image data, and provides a number of useful methods. Let''s test it out by
    loading the first image into our Spark shell, as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回一个`java.awt.image.BufferedImage`类的实例，它存储图像数据，并提供许多有用的方法。让我们通过将第一张图像加载到我们的Spark
    shell中来测试一下：
- en: '[PRE13]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You should see the image details displayed in the shell.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在shell中看到显示的图像细节。
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: There is quite a lot of information here. Of particular interest to us is that
    the image width and height are `250` pixels, and as we can see, there are three
    components (that is, the RGB values) that are highlighted in the preceding output.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多信息。我们特别感兴趣的是图像的宽度和高度是`250`像素，正如我们所看到的，有三个组件（即RGB值）在前面的输出中被突出显示。
- en: Converting to grayscale and resizing the images
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将图像转换为灰度并调整大小
- en: The next function we will define will take the image that we have loaded with
    our preceding function, convert the image from color to grayscale, and resize
    the image's width and height.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义的下一个函数将采用我们用前述函数加载的图像，将图像从彩色转换为灰度，并调整图像的宽度和高度。
- en: These steps are not strictly necessary, but both steps are done in many cases
    for efficiency purposes. Using RGB color images instead of grayscale increases
    the amount of data to be processed by a factor of three. Similarly, larger images
    increase the processing and storage overhead significantly. Our raw 250 x 250
    images represent 187,500 data points per image using three color components. For
    a set of 1055 images, this is 197,812,500 data points. Even if stored as integer
    values, each value stored takes 4 bytes of memory, so just 1055 images represent
    around 800 MB of memory! As you can see, image-processing tasks can quickly become
    extremely memory intensive.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤并不是严格必要的，但在许多情况下都会为了效率而执行。使用RGB彩色图像而不是灰度图像会使要处理的数据量增加三倍。同样，较大的图像会显著增加处理和存储开销。我们的原始250
    x 250图像代表每个图像使用三个颜色组件的187,500个数据点。对于1055个图像集，这是197,812,500个数据点。即使存储为整数值，每个存储的值占用4字节的内存，因此仅1055个图像就代表大约800
    MB的内存！正如您所看到的，图像处理任务很快就会变得极其占用内存。
- en: If we convert to grayscale and resize the images to, say, 50 x 50 pixels, we
    only require 2500 data points per image. For our 1055 images, this equates to
    10 MB of memory, which is far more manageable for illustrative purposes.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将图像转换为灰度并将其调整为50 x 50像素，我们只需要每个图像2500个数据点。对于我们的1055个图像，这相当于10 MB的内存，这对于说明目的来说更容易管理。
- en: 'Let''s define our processing function. We will do the grayscale conversion
    and resizing in one step, using the `java.awt.image` package:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义我们的处理函数。我们将在一步中执行灰度转换和调整大小，使用`java.awt.image`包：
- en: '[PRE15]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The first line of the function creates a new image of the desired width and
    height, and specifies a grayscale color model. The third line draws the original
    image onto this newly created image. The `drawImage` method takes care of the
    color conversion and resizing for us! Finally, we return the new, processed image.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的第一行创建了一个所需宽度和高度的新图像，并指定了灰度颜色模型。第三行将原始图像绘制到这个新创建的图像上。`drawImage`方法会为我们处理颜色转换和调整大小！最后，我们返回新处理过的图像。
- en: 'Let''s test this out on our sample image. We will convert it to grayscale,
    and resize it to 100 x 100 pixels:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在样本图像上测试一下。我们将把它转换为灰度，并将其调整为100 x 100像素：
- en: '[PRE16]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You should see the following output on the console:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在控制台上看到以下输出：
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As you can see from the highlighted output, the image's width and height are
    indeed `100`, and the number of color components is `1`.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 从突出显示的输出中可以看出，图像的宽度和高度确实是`100`，颜色组件的数量是`1`。
- en: Next, we will save the processed image to a temporary location so that we can
    read it back and display it using the Python application.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将把处理过的图像保存到临时位置，以便我们可以读取它并使用Python应用程序显示它。
- en: '[PRE18]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: You should see a result of `true` displayed on your console, indicating that
    you've successfully saved the image to the `aeGray.jpg` file in your `/tmp` directory.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在控制台上看到`true`的结果，表示您已成功将图像保存到`/tmp`目录中的`aeGray.jpg`文件中。
- en: 'Finally, we will read the image in Python, and use matplotlib to display the
    image. Type the following code into your IPython Notebook or shell (remember that
    this should be open in a new terminal window):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将在Python中读取图像，并使用matplotlib显示图像。将以下代码键入到您的IPython Notebook或shell中（请记住这应该在一个新的终端窗口中打开）：
- en: '[PRE19]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This should display the image (note again, we haven't shown the image here).
    You will see that it is grayscale, and of slightly worse quality as compared to
    the original image. Furthermore, you will notice that the scale of the axes is
    different, representing the new 100 x 100 dimension instead of the original 250
    x 250 size.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该显示图像（再次注意，我们这里没有显示图像）。您会看到它是灰度的，与原始图像相比质量稍差。此外，您会注意到轴的比例不同，表示新的100 x 100尺寸，而不是原始的250
    x 250尺寸。
- en: '![](img/image_09_003.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_09_003.png)'
- en: Extracting feature vectors
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取特征向量
- en: 'The final step in the processing pipeline is to extract the actual feature
    vectors that will be the input to our dimensionality reduction model. As we mentioned
    earlier, the raw grayscale pixel data will be our features. We will form the vectors
    by flattening out the two-dimensional pixel matrix. The `BufferedImage` class
    provides a utility method to do just this, which we will use in our function as
    follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 处理管道中的最后一步是提取实际的特征向量，这些向量将成为我们降维模型的输入。正如我们之前提到的，原始灰度像素数据将成为我们的特征。我们将通过展平二维像素矩阵来形成这些向量。`BufferedImage`类提供了一个实用方法来执行此操作，我们将在我们的函数中使用它，如下所示：
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We can then combine these three functions into one utility function, which takes
    a file location together with the desired image's width and height, and returns
    the raw `Array[Double]` value that contains the pixel data.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将这三个函数合并成一个实用函数，该函数接受文件位置以及所需图像的宽度和高度，并返回包含像素数据的原始`Array[Double]`值。
- en: '[PRE21]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Applying this preceding function to each element of the RDD that contains all
    the image file paths will give us a new RDD that contains the pixel data for each
    image. Let''s do this and inspect the first few elements as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个前述函数应用于包含所有图像文件路径的RDD的每个元素，将为我们提供一个包含每个图像的像素数据的新RDD。让我们这样做，并检查前几个元素，如下所示：
- en: '[PRE22]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You should see output similar to this:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似于以下的输出：
- en: '[PRE23]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The final step is to create an MLlib `vector` instance for each image. We will
    cache the RDD to speed up our later computations:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是为每个图像创建一个MLlib`vector`实例。我们将缓存RDD以加快后续的计算速度：
- en: '[PRE24]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We used the `setName` function earlier to assign an RDD a name. In this case,
    we called it `image-vectors`. This is so that we can later identify it more easily
    when looking at the Spark web interface.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前使用`setName`函数为RDD分配了一个名称。在这种情况下，我们称之为`image-vectors`。这样我们在查看Spark网络界面时可以更容易地识别它。
- en: Normalization
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准化
- en: It is a common practice to standardize input data prior to running dimensionality
    reduction models, particularly, for PCA. As we did in [Chapter 6](d3bf76a8-26be-4db7-8310-b936d220407e.xhtml),
    *Building a Classification Model with Spark*, we will do this using the built-in
    `StandardScaler` provided by MLlib's `feature` package. We will only subtract
    the mean from the data in this case.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行降维模型之前，特别是对于PCA，将输入数据标准化是一种常见做法。就像我们在[第6章](d3bf76a8-26be-4db7-8310-b936d220407e.xhtml)中所做的那样，*使用Spark构建分类模型*，我们将使用MLlib的`feature`包提供的内置`StandardScaler`来进行这个操作。在这种情况下，我们只会从数据中减去平均值。
- en: '[PRE25]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '**Standard Scalar**: It standardizes features by removing the mean, and scaling
    to unit standard using column summary statistics on the samples in the training
    set.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**标准缩放器**：通过使用训练集中样本的列摘要统计信息，通过去除均值并缩放到单位标准差来标准化特征。'
- en: '`@param``withMean`: `False` by default. This centers the data with the mean
    before scaling. It builds a dense output, so this does not work on sparse input,
    and raises an exception.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`@param``withMean`：默认为`False`。这会在缩放之前使用均值对数据进行居中。它构建了一个密集输出，因此在稀疏输入上不起作用，并引发异常。'
- en: '`@param withStd`: `True` by default. This scales the data to unit standard
    deviation.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`@param withStd`：默认为`True`。这会将数据缩放到单位标准差。'
- en: '[PRE26]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Calling `fit` triggers a computation on our `RDD[Vector]`. You should see an
    output similar to the one shown here:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`fit`会触发对我们的`RDD[Vector]`的计算。你应该会看到类似于下面显示的输出：
- en: '[PRE27]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note that subtracting the mean works for dense input data. In Image processing,
    we always have dense input data, because each pixel has a value. However, for
    sparse vectors, subtracting the mean vector from each input will transform the
    sparse data into dense data. For very high-dimensional input, this will likely
    exhaust the available memory resources, so it is not advisable.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，减去均值适用于密集输入数据。在图像处理中，我们总是有密集的输入数据，因为每个像素都有一个值。然而，对于稀疏向量，从每个输入中减去均值向量将会将稀疏数据转换为密集数据。对于非常高维的输入，这可能会耗尽可用的内存资源，因此不建议这样做。
- en: Finally, we will use the returned `scaler` to transform the raw image vectors
    to vectors with the column means subtracted.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用返回的`scaler`将原始图像向量转换为减去列均值的向量。
- en: '[PRE28]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We mentioned earlier that the resized grayscale images would take up around
    10 MB of memory. Indeed, you can take a look at the memory usage in the Spark
    application monitor storage page by going to `http://localhost:4040/storage/`
    in your web browser.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到，调整大小的灰度图像将占用大约10MB的内存。确实，你可以通过在网页浏览器中输入`http://localhost:4040/storage/`来查看Spark应用程序监视器存储页面上的内存使用情况。
- en: 'Since we gave our RDD of image vectors a friendly name of `image-vectors`,
    you should see something like the following screenshot (note that, as we are using
    `Vector[Double]`, each element takes up 8 bytes instead of 4 bytes; hence, we
    actually use 20 MB of memory):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们给我们的图像向量RDD取了一个友好的名字`image-vectors`，你应该会看到类似以下的屏幕截图（请注意，由于我们使用的是`Vector[Double]`，每个元素占用8个字节而不是4个字节；因此，我们实际上使用了20MB的内存）：
- en: '![](img/image_09_004.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_09_004.png)'
- en: Size of image vectors in memory
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 内存中图像向量的大小
- en: Training a dimensionality reduction model
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练降维模型
- en: Dimensionality reduction models in MLlib require vectors as inputs. However,
    unlike clustering that operated on an `RDD[Vector]`, PCA and SVD computations
    are provided as methods on a distributed `RowMatrix` (this difference is largely
    down to syntax, as a `RowMatrix` is simply a wrapper around an `RDD[Vector]`).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib中的降维模型需要向量作为输入。然而，与操作`RDD[Vector]`的聚类不同，PCA和SVD计算是作为分布式`RowMatrix`的方法提供的（这种差异主要是语法上的，因为`RowMatrix`只是`RDD[Vector]`的一个包装器）。
- en: Running PCA on the LFW dataset
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在LFW数据集上运行PCA
- en: Now that we have extracted our image pixel data into vectors, we can instantiate
    a new `RowMatrix`.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将图像像素数据提取到向量中，我们可以实例化一个新的`RowMatrix`。
- en: '`def computePrincipalComponents(k: Int)`: Matrix'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`def computePrincipalComponents(k: Int)`: 矩阵'
- en: Computes the top `k` principal components. Rows correspond to observations,
    and columns correspond to variables. The principal components are stored as a
    local matrix of size n-by-`k`. Each column corresponds for one principal component,
    and the columns are in descending order of component variance. The row data do
    not need to be "centered" first; it is not necessary for the mean of each column
    to be `0`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 计算前`k`个主成分。行对应于观测值，列对应于变量。主成分存储为大小为n-by-`k`的本地矩阵。每列对应一个主成分，列按组件方差的降序排列。行数据不需要首先“居中”；每列的均值为`0`是不必要的。
- en: Note that this cannot be computed on matrices with more than `65535` columns.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这不能在具有超过`65535`列的矩阵上计算。
- en: '`K` is the number of top principal components.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`K`是前几个主成分的数量。'
- en: It returns a matrix of size n-by-k, whose columns are principal components
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回一个大小为n-by-k的矩阵，其列是主成分
- en: Annotations
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 注解
- en: '@Since( "1.0.0" )'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '@Since( "1.0.0" )'
- en: 'Call the `computePrincipalComponents` method to compute the top `K` principal
    components of our distributed matrix:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`computePrincipalComponents`方法来计算我们分布式矩阵的前`K`个主成分：
- en: '[PRE29]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: You will likely see quite a lot of output on your console while the model runs.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型运行时，你可能会在控制台上看到大量的输出。
- en: 'If you see warnings such as WARN LAPACK: Failed to load implementation from:
    com.github.fommil.netlib.NativeSystemLAPACK or WARN LAPACK: Failed to load implementation
    from: com.github.fommil.netlib.NativeRefLAPACK, you can safely ignore these.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你看到警告，比如WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK或WARN
    LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK，你可以安全地忽略这些警告。'
- en: This means that the underlying linear algebra libraries used by MLlib could
    not load the native routines. In this case, a Java-based fallback will be used,
    which is slower, but there is nothing to worry about for the purposes of this
    example.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着MLlib使用的基础线性代数库无法加载本机例程。在这种情况下，将使用基于Java的回退，速度较慢，但就本例而言，没有什么可担心的。
- en: 'Once the model training is complete, you should see a result that looks similar
    to the following one displayed on the console:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，您应该在控制台上看到类似以下显示的结果：
- en: '[PRE30]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Visualizing the Eigenfaces
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化特征脸
- en: 'Now that we have trained our PCA model, what is the result? Let''s inspect
    the dimensions of the resulting matrix:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练好了PCA模型，结果是什么？让我们检查一下结果矩阵的维度：
- en: '[PRE31]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: As you should see from your console output, the matrix of the principal components
    has `2500` rows and `10` columns.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您从控制台输出中看到的那样，主成分的矩阵有`2500`行和`10`列。
- en: '[PRE32]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Recall that the dimension of each image is 50 x 50, so here, we have the top
    10 principal components, each with a dimension identical to that of the input
    images. These principal components can be thought of as the set of latent (or
    hidden) features that capture the greatest variation in the original data.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，每个图像的维度是50 x 50，所以这里我们有前10个主成分，每个主成分的维度与输入图像相同。这些主成分可以被视为捕获原始数据中最大变化的一组潜在（或隐藏）特征。
- en: In facial recognition and image processing, these principal components are often
    referred to as **Eigenfaces**, as PCA is closely related to the eigenvalue decomposition
    of the covariance matrix of the original data.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在面部识别和图像处理中，这些主成分通常被称为**特征脸**，因为PCA与原始数据的协方差矩阵的特征值分解密切相关。
- en: See [http://en.wikipedia.org/wiki/Eigenface](http://en.wikipedia.org/wiki/Eigenface)
    for more details.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 更多细节请参见[http://en.wikipedia.org/wiki/Eigenface](http://en.wikipedia.org/wiki/Eigenface)。
- en: Since each principal component is of the same dimension as the original images,
    each component can itself be thought of and represented as an image, making it
    possible to visualize the Eigenfaces as we would the input images.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个主成分的维度与原始图像相同，因此每个成分本身可以被视为图像，并且可以将其表示为图像，从而可以像输入图像一样可视化特征脸。
- en: As we have often done in this book, we will use functionality from the Breeze
    linear algebra library as well as Python's numpy and matplotlib to visualize the
    Eigenfaces.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书中经常做的一样，我们将使用Breeze线性代数库的功能以及Python的numpy和matplotlib来可视化特征脸。
- en: 'First, we will extract the pc variable (an MLlib matrix) into a Breeze `DenseMatrix`
    as follows:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将把pc变量（一个MLlib矩阵）提取到Breeze的`DenseMatrix`中，如下所示：
- en: '[PRE33]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Breeze provides a useful function within the `linalg` package to write the matrix
    out as a CSV file. We will use this to save the principal components to a temporary
    CSV file.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Breeze在`linalg`包中提供了一个有用的函数，用于将矩阵写入CSV文件。我们将使用这个函数将主成分保存到临时CSV文件中。
- en: '[PRE34]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Next, we will load the matrix in IPython, and visualize the principal components
    as images. Fortunately, numpy provides a utility function to read the matrix from
    the CSV file we created.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在IPython中加载矩阵，并将主成分可视化为图像。幸运的是，numpy提供了一个从我们创建的CSV文件中读取矩阵的实用函数。
- en: '[PRE35]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'You should see the following output, confirming that the matrix we read has
    the same dimensions as the one we saved:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下输出，确认我们读取的矩阵与我们保存的矩阵具有相同的维度：
- en: '[PRE36]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We will need a utility function to display the images, which we define here:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个实用函数来显示图像，我们在这里定义：
- en: '[PRE37]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This preceding function is adapted from the LFW dataset example code in the
    **scikit-learn** documentation available at [http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html](http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这个前面的函数是从**scikit-learn**文档中的LFW数据集示例代码中改编的，可在[http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html](http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html)找到。
- en: 'We will now use this function to plot the top 10 Eigenfaces as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用这个函数来绘制前10个特征脸，如下所示：
- en: '[PRE38]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This last command should display the following plot:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这个最后的命令应该显示以下图表：
- en: '![](img/image_09_005.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_09_005.png)'
- en: Top 10 Eigenfaces
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 前10个特征脸
- en: Interpreting the Eigenfaces
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释特征脸
- en: Looking at the preceding images, we can see that the PCA model has effectively
    extracted recurring patterns of variation, which represent various features of
    the facial images. Each principal component can, as with clustering models, be
    interpreted. Again, like clustering, it is not always straightforward to interpret
    precisely what each principal component represents.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图像中，我们可以看到PCA模型有效地提取了重复变化模式，这些模式代表了面部图像的各种特征。每个主成分可以像聚类模型一样被解释。与聚类一样，准确解释每个主成分代表的内容并不总是直接的。
- en: We can see from these images that there appear to be some images that pick up
    directional factors (for example, images 6 and 9), some hone in on hair patterns
    (such as images 4, 5, 7, and 10), while others seem to be somewhat more related
    to facial features such as eyes, nose, and mouth (images 1, 7, and 9).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些图像中，我们可以看到有些图像似乎捕捉到了方向因素（例如图像6和9），有些则聚焦在头发图案上（例如图像4、5、7和10），而其他一些似乎与面部特征如眼睛、鼻子和嘴相关（图像1、7和9）。
- en: Using a dimensionality reduction model
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用降维模型
- en: It is interesting to be able to visualize the outcome of a model in this way;
    however, the overall purpose of using dimensionality reduction is to create a
    more compact representation of the data that still captures the important features
    and variability in the raw dataset. To do this, we need to use a trained model
    to transform our raw data by projecting it into the new, lower-dimensional space
    represented by the principal components.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 能够以这种方式可视化模型的结果是很有趣的；然而，使用降维的整体目的是创建数据的更紧凑表示，同时仍然捕获原始数据集中的重要特征和变异性。为此，我们需要使用训练好的模型将原始数据投影到由主成分表示的新的低维空间中。
- en: Projecting data using PCA on the LFW dataset
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在LFW数据集上使用PCA投影数据
- en: We will illustrate this concept by projecting each LFW image into a ten-dimensional
    vector. This is done through a matrix multiplication of the image matrix with
    the matrix of principal components. As the image matrix is a distributed MLlib
    `RowMatrix`, Spark takes care of distributing this computation for us through
    the `multiply` function.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过将每个LFW图像投影到一个十维向量中来说明这个概念。这是通过图像矩阵与主成分矩阵的矩阵乘法来实现的。由于图像矩阵是一个分布式MLlib`RowMatrix`，Spark会通过`multiply`函数来为我们分布计算。
- en: '[PRE39]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This preceding function will give you the following output:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 上述函数将给出以下输出：
- en: '[PRE40]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Observe that each image that had a dimension of 2500, has been transformed
    into a vector of size 10\. Let''s take a look at the first few vectors:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，每个维度为2500的图像已经被转换为大小为10的向量。让我们来看一下前几个向量：
- en: '[PRE41]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Here is the output:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '[PRE42]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: As the projected data is in the form of vectors, we can use the projection as
    an input to another machine learning model. For example, we could use these projected
    inputs together with a set of input data generated from various images without
    faces to train a facial recognition model. Alternatively, we could train a multiclass
    classifier, where each person is a class, thus creating a model that learns to
    identify the particular person that a face belongs to.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 由于投影数据是向量形式，我们可以将投影作为另一个机器学习模型的输入。例如，我们可以将这些投影输入与从各种没有人脸的图像生成的输入数据一起使用，来训练一个人脸识别模型。或者，我们可以训练一个多类分类器，其中每个人是一个类，从而创建一个学习识别特定人脸所属的模型。
- en: The relationship between PCA and SVD
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PCA和SVD之间的关系
- en: We mentioned earlier that there is a close relationship between PCA and SVD.
    In fact, we can recover the same principal components, and also apply the same
    projection into the space of principal components using SVD.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到PCA和SVD之间存在着密切的关系。事实上，我们可以恢复相同的主成分，并且也可以使用SVD将投影应用到主成分空间中。
- en: 'In our example, the right singular vectors derived from computing the SVD will
    be equivalent to the principal components we have calculated. We can see that
    this is the case by first computing the SVD on our image matrix and comparing
    the right singular vectors to the result of PCA. As was the case with PCA, SVD
    computation is provided as a function on a distributed `RowMatrix`:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，通过计算SVD得到的右奇异向量将等同于我们计算得到的主成分。我们可以通过首先在图像矩阵上计算SVD，然后将右奇异向量与PCA的结果进行比较来验证这一点。与PCA一样，SVD计算作为分布式`RowMatrix`上的函数提供：
- en: '[PRE43]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We can see that SVD returns a matrix `U` of dimension 1055 x 10, a vector `S`
    of the singular values of length `10`, and a matrix `V` of the right singular
    vectors of dimension 2500 x 10.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到SVD返回一个维度为1055 x 10的矩阵`U`，一个长度为`10`的奇异值向量`S`，以及一个维度为2500 x 10的右奇异向量矩阵`V`。
- en: '[PRE44]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The matrix V is exactly equivalent to the result of PCA (ignoring the sign
    of the values and floating point tolerance). We can verify this with this next
    utility function to compare the two by approximately comparing the data arrays
    of each matrix:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵V与PCA的结果完全相等（忽略数值的符号和浮点数容差）。我们可以使用下一个实用程序函数来验证这一点，通过大致比较每个矩阵的数据数组来比较它们：
- en: '[PRE45]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We will test the function on some test data, as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在一些测试数据上测试该函数，如下所示：
- en: '[PRE46]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This will give you the following output:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给出以下输出：
- en: '[PRE47]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Let''s try another test data:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试另一组测试数据：
- en: '[PRE48]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This will give you the following output:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给出以下输出：
- en: '[PRE49]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Finally, we can apply our equality function as follows:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以应用我们的相等函数如下：
- en: '[PRE50]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Here is the output:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '[PRE51]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Both SVD and PCA can be used to calculate the principal components and corresponding
    Eigen/Singular values; the extra step of calculating the covariance matrix can
    lead to numerical rounding off errors while calculating Eigen vectors. SVD summarizes
    the ways in which the data deviates from zero, and PCA summarizes the ways in
    which the data deviates from the mean data sample.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: PCA和SVD都可以用来计算主成分和相应的特征值/奇异值；计算协方差矩阵的额外步骤可能会导致在计算特征向量时出现数值舍入误差。SVD总结了数据偏离零的方式，而PCA总结了数据偏离平均数据样本的方式。
- en: The other relationship that holds is that the multiplication of the matrix `U`
    and vector `S` (or, strictly speaking, the diagonal matrix `S`) is equivalent
    to the PCA projection of our original image data into the space of the top 10
    principal components.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个保持的关系是矩阵`U`和向量`S`（或者严格来说，对角矩阵`S`）的乘积等同于将我们原始图像数据投影到前10个主成分空间中的PCA投影。
- en: 'We will now show that this is indeed the case. We will first use Breeze to
    multiply each vector in `U` by `S`, element-wise. We will then compare each vector
    in our PCA-projected vectors with the equivalent vector in our SVD projection,
    and sum up the number of equal cases, as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将展示这确实是这样。我们首先使用Breeze将`U`中的每个向量与`S`进行逐元素乘法。然后我们将比较PCA投影向量中的每个向量与我们SVD投影中的等价向量，并统计相等情况的数量，如下所示：
- en: '[PRE52]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This preceding code should display a result of 1055, as we would expect, confirming
    that each row of projected PCA is equal to each row of `projectedSVD`.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码应该显示一个结果为1055，这是我们所期望的，确认了PCA的每一行投影等于`projectedSVD`的每一行。
- en: Note that the **:*** operator, highlighted in the preceding code, represents
    element-wise multiplication of the vectors.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，上述代码中突出显示的**：***运算符表示向量的逐元素乘法。
- en: Evaluating dimensionality reduction models
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估降维模型
- en: Both PCA and SVD are deterministic models. That is, given a certain input dataset,
    they will always produce the same result. This is in contrast to many of the models
    we have seen so far, which depend on some random element (most often for the initialization
    of model weight vectors, and so on).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: PCA和SVD都是确定性模型。也就是说，给定某个特定的输入数据集，它们总是会产生相同的结果。这与我们迄今为止看到的许多模型形成对比，这些模型依赖于某种随机因素（最常见的是模型权重向量的初始化等）。
- en: Both models are also guaranteed to return the top principal components or singular
    values, and hence, the only parameter is *k*. Like clustering models, increasing
    *k* always improves the model performance (for clustering, the relevant error
    function, while for PCA and SVD, the total amount of variability explained by
    the *k* components). Therefore, selecting a value for *k* is a trade-off between
    capturing as much structure of the data as possible while keeping the dimensionality
    of projected data low.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种模型都保证返回前几个主成分或奇异值，因此唯一的参数是*k*。与聚类模型一样，增加*k*总是会提高模型性能（对于聚类来说是相关的错误函数，而对于PCA和SVD来说是*k*个成分解释的总变异量）。因此，选择*k*的值是在尽可能捕捉数据结构的同时保持投影数据的维度低之间的权衡。
- en: Evaluating k for SVD on the LFW dataset
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估LFW数据集上SVD的*k*
- en: 'We will examine the singular values obtained from computing the SVD on our
    image data. We can verify that the singular values are the same for each run,
    and that they are returned in a decreasing order, as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将检查通过对图像数据进行SVD计算得到的奇异值。我们可以验证每次运行时奇异值是相同的，并且它们以递减顺序返回，如下所示：
- en: '[PRE53]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'This last code should generate an output similar to the following:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码应该生成类似于以下内容的输出：
- en: '[PRE54]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Singular values
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奇异值
- en: Singular values lets us understand the trade-off between space and time for
    fidelity of the reduction.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 奇异值让我们理解降维的空间和时间的权衡。
- en: As with evaluating values of *k* for clustering, in the case of SVD (and PCA),
    it is often useful to plot the singular values for a larger range of *k*, and
    see where the point on the graph is where the amount of additional variance accounted
    for by each additional singular value starts to flatten out considerably.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 与评估聚类的*k*值一样，在SVD（和PCA）的情况下，通常有必要绘制更大范围的*k*的奇异值，并查看图表上的点，看看每个额外奇异值所解释的额外方差量在哪个点开始明显变平。
- en: 'We will do this by first computing the top 300 singular values, as shown next:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先计算前300个奇异值，如下所示：
- en: '[PRE55]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: We will write out the vector S of singular values to a temporary CSV file (as
    we did for our matrix of Eigenfaces previously), and then read it back in our
    IPython console, plotting the singular values for each *k*.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把奇异值向量S写入临时CSV文件（就像我们之前对Eigenfaces矩阵所做的那样），然后在IPython控制台中读取它，绘制每个*k*的奇异值。
- en: '[PRE56]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'You should see an image displayed similar to the one shown here:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似于这里显示的图像：
- en: '![](img/image_09_006.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_09_006.png)'
- en: Top 300 singular values
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 前300个奇异值
- en: A similar pattern is seen in the cumulative variation accounted for by the top
    300 singular values (which we will plot on a log scale for the *y* axis).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在前300个奇异值累积变化中也出现了类似的模式（我们将在*y*轴上绘制对数刻度）。
- en: '[PRE57]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Full Source code for Python plots can be found at the following link: [https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_09/data/python](https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_09/data/python)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: Python绘图的完整源代码可以在以下链接找到：[https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_09/data/python](https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_09/data/python)
- en: '![](img/image_09_007.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_09_007.png)'
- en: Cumulative sum of top 300 singular values
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 前300个奇异值的累积和
- en: We can see that after a certain value range for *k* (around 100 in this case),
    the graph flattens considerably. This indicates that a number of singular values
    (or principal components) equivalent to this value of *k* probably explains enough
    of the variation of the original data.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在*k*的某个数值范围之后（在这种情况下大约为100），图形明显变平。这表明与*k*值相当的奇异值（或主成分）可能足够解释原始数据的变化。
- en: Of course, if we are using dimensionality reduction to help improve the performance
    of another model, we could use the same evaluation methods used for that model
    to help us choose a value for *k*.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果我们正在使用降维来帮助提高另一个模型的性能，我们可以使用与该模型相同的评估方法来帮助我们选择*k*的值。
- en: For example, we could use the AUC metric, together with cross-validation, to
    choose both the model parameters for a classification model as well as the value
    of *k* for our dimensionality reduction model. This does come at the expense of
    higher computation cost, however, as we would have to recompute the full model
    training and testing pipeline.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以使用AUC指标，结合交叉验证，来选择分类模型的模型参数以及降维模型的*k*值。然而，这会增加计算成本，因为我们需要重新计算完整的模型训练和测试流程。
- en: Summary
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored two new unsupervised learning methods, PCA and
    SVD, for dimensionality reduction. We saw how to extract features for, and train,
    these models using facial image data. We visualized the results of the model in
    the form of Eigenfaces, saw how to apply the models to transform our original
    data into a reduced dimensionality representation, and investigated the close
    link between PCA and SVD.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探索了两种新的无监督学习方法，PCA和SVD，用于降维。我们看到如何提取特征，并训练这些模型使用面部图像数据。我们可视化了模型的结果，以Eigenfaces的形式展现，看到如何将模型应用于将原始数据转换为降维表示，并调查了PCA和SVD之间的密切联系。
- en: In the next chapter, we will delve more deeply into techniques for text processing
    and analysis with Spark.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更深入地探讨使用Spark进行文本处理和分析的技术。
