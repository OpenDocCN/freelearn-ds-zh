- en: Computing Foundations – Introduction to Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算基础 – Python 入门
- en: This chapter will provide an introduction to Python for analytics. It is meant
    mainly for novice programmers or developers who are not familiar with Python.
    By the end of the chapter, you will have a basic familiarity with the features
    of the Python base language, which is integral for healthcare analytics and machine
    learning. You will also understand how to get started using `pandas` and `scikit-learn`,
    two important Python libraries for analytics.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍 Python 在分析中的应用。该部分主要面向对 Python 不熟悉的初学者程序员或开发人员。本章结束时，你将对 Python 基础语言的特性有基本的了解，这对于医疗分析和机器学习至关重要。你还将了解如何开始使用
    `pandas` 和 `scikit-learn`，这两个 Python 数据分析的关键库。
- en: If you would like to follow along using the Jupyter Notebook, we encourage you
    to refer to the directions in [Chapter 1](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml),
    *Introduction to Healthcare Analytics*, to start a new Jupyter session. The notebook
    for this chapter is also available online at the book's official code repository.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想跟随 Jupyter Notebook 操作，我们建议你参考[第 1 章](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml)，*医疗分析入门*，来启动一个新的
    Jupyter 会话。本章的笔记本也可以在书籍的官方代码库中在线获取。
- en: Variables and types
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量和类型
- en: Basic variable types in Python consist of strings and numeric types. Let's look
    at both of these types in this section.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Python 中的基本变量类型包括字符串和数字类型。在本节中，我们将介绍这两种类型。
- en: Strings
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字符串
- en: 'In Python, a **string** is a variable type that stores text characters such
    as letters, numbers, special characters, and punctuation. In Python, we use single
    or double quotation marks to indicate that the variable is a string rather than
    a number:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，**字符串**是一种存储文本字符的变量类型，这些字符可以是字母、数字、特殊字符和标点符号。在 Python 中，我们使用单引号或双引号来表示一个变量是字符串，而不是数字：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Strings cannot be used for mathematical operations on numbers. But they can
    be used for other useful operations, as we see in the following example:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串不能用于数字的数学运算，但它们可以用于其他有用的操作，正如我们在以下示例中看到的：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The result of the preceding code is to print string `'12'`, not `'3'`. Instead
    of adding the two numbers, the `+` operator performs concatenation (appending
    the second string to the end of the first string) in Python when operating on
    two strings.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的结果是打印字符串 `'12'`，而不是 `'3'`。在 Python 中，`+` 运算符对两个字符串进行操作时，执行的是拼接操作（将第二个字符串附加到第一个字符串的末尾），而不是相加。
- en: Other operators that act on strings include the `*` operator (for repeating
    strings ![](img/14655201-6690-4b4c-ad90-85b3c37d6601.png) number of times, for
    example, `string_1 * 3`) and the `<` and `>` operators (to compare the ASCII values
    of the strings).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 其他作用于字符串的运算符包括 `*` 运算符（用于重复字符串 ![](img/14655201-6690-4b4c-ad90-85b3c37d6601.png)
    多次，例如，`string_1 * 3`）以及 `<` 和 `>` 运算符（用于比较字符串的 ASCII 值）。
- en: To convert data from a numeric type to a string, we can use the `str()` method.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要将数据从数字类型转换为字符串，我们可以使用 `str()` 方法。
- en: 'Because strings are sequences (of characters), we can index them and slice
    them (like we can do with other data containers, as you will see later). A slice
    is a contiguous section of a string. To index/slice them, we use integers enclosed
    in square brackets to indicate the character''s position:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由于字符串是字符序列，我们可以对其进行索引和切片（就像我们对其他数据容器所做的那样，稍后你会看到）。切片是字符串的连续部分。为了索引/切片它们，我们使用方括号中的整数来表示字符的位置：
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output is shown as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To slice strings, we include the beginning and end positions, separated by
    a colon, in the square brackets. Note that the end position will include all the
    characters *up to but not including* the end position, as we see in the following
    example:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要切片字符串，我们需要在方括号中包含起始位置和结束位置，二者用冒号隔开。请注意，结束位置会包含所有字符，*直到但不包括*该结束位置，正如我们在以下示例中看到的：
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output is as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Earlier, we mentioned the `str()` method. There are dozens of other methods
    for strings. A full list of them is available in the online Python documentation
    at [www.python.org](http://www.python.org). Methods include those for case conversion,
    finding specific substrings, and stripping whitespace. We'll discuss one more
    method here–the `split()` method. The `split()` method acts on a string and takes
    a `separator` argument.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 前面我们提到了 `str()` 方法。字符串有很多其他方法。它们的完整列表可以在在线 Python 文档中查看，网址是 [www.python.org](http://www.python.org)。这些方法包括大小写转换、查找特定子字符串和去除空格等操作。这里我们将讨论另外一个方法——`split()`
    方法。`split()` 方法作用于字符串，并接受一个 `separator` 参数。
- en: 'The output is a list of strings; each item in the list is a component of the
    original string, split by `separator`. This is very useful for parsing strings
    that are delimited by punctuation characters such as `,` or `;`. We will discuss
    lists in the next section. Here is an example of the `split()` method:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一个字符串列表；列表中的每个项目是原始字符串的一个组成部分，按`separator`分隔开。这对于解析由标点符号（如`,`或`;`）分隔的字符串非常有用。我们将在下一节讨论列表。下面是`split()`方法的示例：
- en: '[PRE6]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE7]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Numeric types
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数值类型
- en: 'The two numeric types in Python that are most useful for analytics are **integers**
    and **floating-point** numbers. To convert to these types, you can use the `int()`
    and `float()` functions, respectively. The most common operations on numbers are
    supported with the usual operators: `+`, `-`, `*`, `/`, `<`, and `>`. Modules
    containing special methods for numeric types that are particularly useful for
    analytics include `math` and `random`. More information on numeric types is available
    in the online Python documentation (see the link in the previous section).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，最常用于分析的两种数值类型是**整数**和**浮点数**。要将数据转换为这些类型，可以分别使用`int()`和`float()`函数。常见的数值操作都可以通过常用运算符来实现：`+`、`-`、`*`、`/`、`<`和`>`。包含特殊数值方法的模块，如`math`和`random`，对于分析尤其有用。更多有关数值类型的信息，可以参考在线Python文档（参见上一节中的链接）。
- en: Note that with some Python versions, dividing two integers using the / operator
    performs **floor division** (with the numbers after the decimal place omitted);
    for example, `10/4` would equal `2`, not `2.5`. This is a stealthy yet egregious
    error that can throw off numerical calculations. However, with the version of
    Python we are using in this book, we don't need to worry about this error.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在某些版本的Python中，使用`/`运算符对两个整数进行除法运算时，会执行**向下取整除法**（即忽略小数点后的部分）；例如，`10/4`会等于`2`，而不是`2.5`。这是一个隐蔽而严重的错误，可能会影响数值计算。然而，在本书中使用的Python版本里，我们不需要担心这个问题。
- en: The **Boolean type** is a special integer type that can be used to represent
    the `True` and `False` values. To convert an integer to a Boolean type, you can
    use the `bool()` function. A zero gets converted to `False`; any other integer
    would get converted to `True`. Boolean variables behave like 1 (True) and 0 (False),
    except that they return `True` and `False`, respectively, when converted to strings.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**布尔类型**是一个特殊的整数类型，用于表示`True`和`False`值。要将整数转换为布尔类型，可以使用`bool()`函数。零会被转换为`False`；其他任何整数都会被转换为`True`。布尔变量的行为像1（True）和0（False），不过在转换为字符串时，它们分别返回`True`和`False`。'
- en: Data structures and containers
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据结构和容器
- en: In the last section, we talked about variable types that store single values.
    Now we will move on to data structures that can hold multiple values. These data
    structures are lists, tuples, dictionaries, and sets. Lists and tuples are commonly
    referred to as sequences in Python. In this book, we will use the terms data structures
    and data containers interchangeably.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讲解了存储单一值的变量类型。接下来，我们将讨论能够存储多个值的数据结构。这些数据结构包括列表、元组、字典和集合。在Python中，列表和元组通常被称为序列。在本书中，我们将“数据结构”和“数据容器”这两个术语互换使用。
- en: Lists
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列表
- en: 'Lists are a widely used data structure that can hold multiple values. Let''s
    look at some features of lists:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 列表是一个广泛使用的数据结构，可以包含多个值。我们来看一下列表的一些特点：
- en: To make a list, we use square brackets, `[]`.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要创建一个列表，我们使用方括号`[]`。
- en: 'Example: `my_list = [1, 2, 3]`.'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例：`my_list = [1, 2, 3]`。
- en: Lists can hold any combination of numeric types, strings, Boolean types, tuples,
    dictionaries, or even other lists.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列表可以包含任意组合的数值类型、字符串、布尔类型、元组、字典，甚至其他列表。
- en: 'Example: `my_diverse_list = [51, ''Health'', True, [1, 2, 3]]`.'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例：`my_diverse_list = [51, 'Health', True, [1, 2, 3]]`。
- en: Lists, like strings, are sequences and support indexing and slicing.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列表和字符串一样，都是序列，支持索引和切片操作。
- en: For example, in the preceding example, `my_diverse_list[0]` would equal `51`.
    `my_diverse_list[0:2]` would equal `[51, 'Health']`. To access the `3` of the
    nested list, we can use `my_diverse_list[3][2]`.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，在上面的示例中，`my_diverse_list[0]`会等于`51`。`my_diverse_list[0:2]`会等于`[51, 'Health']`。要访问嵌套列表中的`3`，我们可以使用`my_diverse_list[3][2]`。
- en: Lists are **mutable** (unlike strings and tuples), meaning that we can change
    individual components using indices.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列表是**可变**的（不同于字符串和元组），这意味着我们可以通过索引来更改单个元素。
- en: For example, if we entered the `my_diverse_list[2] = False` command, our new
    `my_diverse_list` would be equal to `[51, 'Health', False, [1, 2, 3]]` .
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，如果我们输入了 `my_diverse_list[2] = False` 命令，那么我们的新 `my_diverse_list` 将等于 `[51,
    'Health', False, [1, 2, 3]]`。
- en: Notable advantages of lists for analytics include their vast array of helper
    methods, such as `append()`, `extend()`, and `join()`, and their interchangeability
    with the `pandas` and `numpy` data structures.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 列表在数据分析中的显著优势包括其丰富的辅助方法，如 `append()`、`extend()` 和 `join()`，以及它们与 `pandas` 和
    `numpy` 数据结构的互换性。
- en: Tuples
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 元组
- en: 'Tuples are similar to lists. To make a tuple, we use parentheses, `()`. Example:
    `my_tuple = (1, 2, 3)`. The main difference between tuples and lists is that tuples
    are **immutable**, so we cannot change any components of a tuple. If we tried
    `my_tuple[0] = 4`, an error would be thrown. Because their values are immutable,
    tuples are useful for setting constant variables.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 元组类似于列表。要创建元组，我们使用圆括号 `()`。示例：`my_tuple = (1, 2, 3)`。元组与列表的主要区别在于元组是 **不可变的**，因此我们不能更改元组中的任何元素。如果我们尝试
    `my_tuple[0] = 4`，则会抛出错误。由于它们的值是不可变的，元组在设置常量变量时非常有用。
- en: Dictionaries
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字典
- en: 'A **dictionary** is a common data structure in Python. It is used to store
    unidirectional mappings from keys to values. For example, if we wanted to create
    a dictionary that stored a list of patient names and their corresponding room
    numbers, we could use the following code:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**字典**是 Python 中常见的数据结构。它用于存储从键到值的单向映射。例如，如果我们想创建一个字典来存储病人姓名及其对应的房间号，我们可以使用以下代码：'
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s talk about the preceding code snippet in more detail:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地讨论一下前面的代码片段：
- en: The names in the `rooms` dictionary are referred to as **keys**. The keys in
    a dictionary must be unique. To access them, we can use the `keys()` function, `rooms.keys()`.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rooms` 字典中的名称被称为 **键**。字典中的键必须是唯一的。要访问它们，我们可以使用 `keys()` 函数，`rooms.keys()`。'
- en: The room numbers in the `rooms` dictionary are referred to as **values**. To
    access all of the values, we can use the `values()` function, `rooms.values()`.
    To access an individual value, we just supply the name of its key in square brackets.
    For example, `rooms['Smith']` will return `'141-A'`. For this reason, we say that
    a dictionary maps keys to their values.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rooms` 字典中的房间号被称为 **值**。要访问所有值，我们可以使用 `values()` 函数，`rooms.values()`。要访问单个值，我们只需提供其键的名称，用方括号括起来。例如，`rooms[''Smith'']`
    将返回 `''141-A''`。因此，我们可以说字典将键映射到其值。'
- en: To access a nested list of tuples that contains each key along with its corresponding
    value, we can use the `items()` function, `rooms.items()`.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要访问包含每个键及其对应值的嵌套元组列表，我们可以使用 `items()` 函数，`rooms.items()`。
- en: Dictionaries don't have to just be strings; in fact, the values can be any data
    type/structure. The keys can be particular variables such as integers or strings.
    While the values are mutable, the keys are immutable.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字典的值不一定只是字符串；事实上，值可以是任何数据类型/结构。键可以是特定的变量，例如整数或字符串。虽然值是可变的，但键是不可变的。
- en: Dictionaries have no intrinsic order, so indexing and slicing by number is not
    supported.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字典没有固有的顺序，因此不支持按数字索引和切片操作。
- en: Sets
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集合
- en: 'Although in Python the set doesn''t receive as much attention as its popular
    cousin the list, sets play an important role in analytics, so we include them
    here. To make a set, we use the built-in `set()` function. There are three things
    you need to know about sets:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在 Python 中集合不像它的流行表亲列表那样受到关注，但集合在数据分析中扮演着重要角色，因此我们在这里包括它们。要创建集合，我们使用内置的 `set()`
    函数。关于集合，你需要知道三件事：
- en: They are immutable
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们是不可变的
- en: They are unordered
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们是无序的
- en: The elements of a set are unique
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集合的元素是唯一的
- en: Therefore, sets in Python are very similar to their mathematical counterparts
    if you are familiar with the basic set theory. The set methods also duplicate
    typical set operations and include `union()`, `intersection()`, `add()`, and `remove()`.
    These functions come in handy when wanting to perform typical set-like operations
    on data structures, such as lists or tuples, following conversions to sets.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你熟悉基础集合论，Python 中的集合与其数学对应物非常相似。集合方法也复制了典型的集合操作，包括 `union()`、`intersection()`、`add()`
    和 `remove()`。当你想对数据结构（如列表或元组）执行典型的集合操作时，这些函数会派上用场，前提是将其转换为集合。
- en: Programming in Python – an illustrative example
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 编程– 通过示例说明
- en: In the previous sections, we discussed variable types and data containers. There
    are many more aspects of Python programming, such as control flow with if/else
    statements, loops, and comprehensions; functions; and classes and object-oriented
    programming. Commonly, Python programs are packaged into **modules**, which are
    self-standing scripts that can be run from the command line to perform computing
    tasks.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们讨论了变量类型和数据容器。Python编程中还有很多其他方面，如if/else语句、循环和推导式的控制流；函数；以及类和面向对象编程。通常，Python程序会被打包成**模块**，即独立的脚本，可以通过命令行运行执行计算任务。
- en: 'Let''s introduce some of these concepts in Python with a "module" of our own
    (you can use the Jupyter Notebook for this):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个“模块”来介绍一些Python的概念（你可以使用Jupyter Notebook来实现）：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'When you run this code, you should see the following output:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，你应该会看到以下输出：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding code is a Python module that prints the height and **body mass
    indices** (**BMIs**) for two mock patients. Let''s take a more detailed look at
    each element of this code:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码是一个Python模块，打印出两个虚拟患者的身高和**体重指数**（**BMI**）。让我们更详细地看看这段代码的每个元素：
- en: The first line of the code block is an **import statement**. This allows us
    to import functions and classes that have been written in other modules that are
    either distributed with Python, written as open source software, or written by
    ourselves. A **module** can simply be thought of as a file that contains Python
    functions, constants, and/or classes. It has a `.py` extension. To import a module
    in its entirety, we can simply use the `import` word followed by the module name,
    for example, `import math`. Notice we used the `from` keyword as well because
    we only want to import a specific function, the `pow()` function. This also saves
    us from the inconvenience of having to type `math.pow()` every time we want to
    raise something to a power.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码块的第一行是**导入语句**。这使我们能够导入其他模块中已编写的函数和类，这些模块可能是与Python一起分发的、开源软件编写的，或者是我们自己编写的。**模块**可以简单地理解为一个包含Python函数、常量和/或类的文件，它的扩展名为`.py`。要导入整个模块，我们只需使用`import`关键字后跟模块名称，例如`import
    math`。请注意，我们还使用了`from`关键字，因为我们只想导入特定的函数——`pow()`函数。这样也避免了每次想计算幂时都需要输入`math.pow()`的麻烦。
- en: The next two lines contain **constants** that we will use to perform unit conversions.
    Constants are usually indicated by capital letters.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来的两行包含了我们将用来进行单位转换的**常量**。常量通常用大写字母表示。
- en: Next, we define a `Patient` class that has a **constructor** and two **methods**.
    The constructor takes three arguments–the name, height, and weight–and sets three
    attributes of the specific `Patient` instance to equal those three values. It
    also converts the weight from pounds to kilograms and the height from inches to
    meters, and stores those values in two extra attributes.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们定义了一个`Patient`类，包含一个**构造函数**和两个**方法**。构造函数接受三个参数——姓名、身高和体重——并将特定`Patient`实例的三个属性设置为这些值。它还将体重从磅转换为千克，将身高从英寸转换为米，并将这些值存储在两个额外的属性中。
- en: The two methods are coded as **functions**, using the `def` keyword. `calculate_bmi()`
    returns the BMI of the patient, while `get_height()` simply returns the height
    in meters.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这两个方法被编码为**函数**，使用`def`关键字。`calculate_bmi()`返回患者的BMI，而`get_height()`则简单地返回身高（以米为单位）。
- en: Next, we have a mini `if` statement. All that this `if` statement is saying
    is to run the subsequent code only if it is the main module invoked at the command
    line. Other `if` statements may have multiple `elif` clauses and can also include
    a final `else` clause.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们有一个简短的`if`语句。这个`if`语句的作用是：只有在作为命令行调用的主模块时才执行后续代码。其他`if`语句可能包含多个`elif`子句，还可以包含一个最终的`else`子句。
- en: Next, we create a list of two patients, John Smith and Patty Johnson, with their
    heights and weights as listed in the code.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们创建了一个包含两位患者的信息的列表，分别是John Smith和Patty Johnson，以及他们的身高和体重数据。
- en: The following line uses a list **comprehension** to create a list of heights
    of the two patients. Comprehensions are very popular in Python programming and
    can also be performed with dictionaries.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下一行使用了列表**推导式**来创建两个患者的身高列表。推导式在Python编程中非常流行，也可以用于字典操作。
- en: Finally, our `print` statement prints the four numbers as the output (the two
    heights and the two BMI values).
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们的`print`语句会将四个数字作为输出（两个身高和两个BMI值）。
- en: Further references for the base Python programming language are given at the
    end of this chapter. You can also check out the online documentation at [www.python.org](http://www.python.org).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 本章末尾提供了更多关于基础 Python 编程语言的参考资料。你也可以访问在线文档 [www.python.org](http://www.python.org)。
- en: Introduction to pandas
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: pandas 简介
- en: 'Almost all of the features we''ve discussed so far are features of *base* Python;
    that is, no external packages or libraries were required. The truth of the matter
    is that the majority of the code we write in this book will pertain to one of
    several *external* Python packages commonly used for analytics. The **pandas**
    library ([http://pandas.pydata.org](http://pandas.pydata.org)) is an integral
    part of the later programming chapters. The functions of pandas for machine learning
    are threefold:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论的几乎所有功能都是 *基础* Python 的功能；也就是说，使用这些功能不需要额外的包或库。事实是，本书中我们编写的大部分代码将涉及几个常用于分析的
    *外部* Python 包。**pandas** 库（[http://pandas.pydata.org](http://pandas.pydata.org)）是后续编程章节的核心部分。pandas
    在机器学习中的功能有三方面：
- en: Import data from flat files into your Python session
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从平面文件导入数据到你的 Python 会话
- en: Wrangle, manipulate, format, and cleanse data using the pandas DataFrame and
    its library of functions
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 pandas DataFrame 及其函数库来整理、操作、格式化和清洗数据
- en: Export data from your Python session to flat files
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据从你的 Python 会话导出到平面文件
- en: Let's review each of these functions in turn.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一回顾这些功能。
- en: Flat files are popular methods of storing healthcare-related data (along with
    HL7 formats, which are not covered in this book). A **flat file** is a text file
    representation of data. Using flat files, data can be represented as rows and
    columns, similar to databases, except that punctuation or whitespace are used
    as column delimiters, while carriage returns are used as row delimiters. We will
    see an example flat file in [Chapter 7](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml),
    *Making Predictive Models in Healthcare*.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 平面文件是存储与医疗相关数据的常用方式（还有 HL7 格式，本书不涉及）。**平面文件**是数据的文本文件表示形式。使用平面文件，数据可以像数据库一样以行和列的形式表示，不同的是，标点符号或空白字符用作列的分隔符，而回车符则用作行的分隔符。我们将在[第
    7 章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)，*在医疗领域创建预测模型* 中看到一个平面文件的示例。
- en: pandas allows us to import data into a tabular Python data structure, called
    a **DataFrame**, from a variety of other Python structures and flat files, including
    Python dictionaries, pickle objects, **comma-separated values** (**csv**) files,
    **fixed-width format** (**fwf**) files, Microsoft Excel files, JSON files, HTML
    files, and even SQL database tables.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 允许我们从各种其他 Python 结构和平面文件中导入数据到一个表格化的 Python 数据结构，称为 **DataFrame**，包括
    Python 字典、pickle 对象、**逗号分隔值**（**csv**）文件、**定宽格式**（**fwf**）文件、Microsoft Excel 文件、JSON
    文件、HTML 文件，甚至是 SQL 数据库表。
- en: Once the data is in Python, there are additional functions that you can use
    to explore and transform the data. Need to perform a mathematical function on
    a column, such as finding its sum? Need to perform SQL-like operations, such as
    JOINs or adding columns (see [Chapter 3](46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml),
    *Machine Learning Foundations*)? Need to filter rows by a condition? All of the
    functionality is there in pandas' API. We will make good use of some of pandas'
    functionality in [Chapter 6](023c1d7e-f3f0-42e6-a2be-64bd5ba4ab80.xhtml), *Measuring
    Healthcare Quality* and in [Chapter 7](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml),
    *Making Predictive Models in Healthcare*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据进入 Python，你可以使用一些附加功能来探索和转换数据。需要对某一列执行数学运算，比如求和吗？需要执行类似 SQL 的操作，如 JOIN 或添加列（请参阅[第
    3 章](46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml)，*机器学习基础*）？需要按条件过滤行吗？这些功能都可以通过
    pandas 的 API 实现。我们将在[第 6 章](023c1d7e-f3f0-42e6-a2be-64bd5ba4ab80.xhtml)，*衡量医疗质量*
    和[第 7 章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)，*在医疗领域创建预测模型* 中充分利用 pandas
    的一些功能。
- en: Finally, when we are done exploring, cleansing, and wrangling our data, if we
    can choose to export it out as most of the formats listed. Or we can convert it
    to a NumPy array and train machine learning models, as we will do later in this
    book.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当我们完成数据探索、清洗和整理后，如果我们愿意，可以选择将数据导出为列出的多种格式之一。或者我们可以将数据转换为 NumPy 数组并训练机器学习模型，正如我们在本书后面会做的那样。
- en: What is a pandas DataFrame?
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 pandas DataFrame？
- en: A **pandas DataFrame** can be thought of as a two-dimensional, matrix-like data
    structure that consists of rows and columns. A pandas DataFrame is analogous to
    a dataframe in R or a table in SQL. Advantages over traditional matrices and other
    Python data structures include the ability to have columns of different types
    in the same DataFrame, a wide array of predefined functions for easy data manipulation,
    and one-line interfaces that allow quick conversion to other file formats including
    databases, flat file formats, and NumPy arrays (for integration with scikit-learn's
    machine learning functionality). Therefore, `pandas` is indeed the glue that holds
    together many machine learning pipelines, from data importation to algorithm application.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**pandas DataFrame**可以看作是一种二维的、类似矩阵的数据结构，由行和列组成。pandas DataFrame类似于R中的dataframe或SQL中的表。与传统矩阵和其他Python数据结构相比，它的优势包括可以在同一DataFrame中包含不同类型的列、提供广泛的预定义函数以便于数据操作，以及支持快速转换为其他文件格式（包括数据库、平面文件格式和NumPy数组）的单行接口（便于与scikit-learn的机器学习功能集成）。因此，`pandas`确实是连接许多机器学习管道的粘合剂，从数据导入到算法应用。'
- en: The limitations of pandas include slower performance and lack of built-in parallel
    processing for pandas functionality. Therefore, if you are working with millions
    or billions of data points, **Apache Spark** ([https://spark.apache.org/](https://spark.apache.org/))
    may be a better option, since it has parallel processing built into its language.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: pandas的局限性包括较慢的性能以及缺乏内建的并行处理功能。因此，如果你正在处理数百万或数十亿个数据点，**Apache Spark**（[https://spark.apache.org/](https://spark.apache.org/)）可能是一个更好的选择，因为它的语言内置了并行处理功能。
- en: Importing data
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入数据
- en: In this section, we demonstrate how to load data into Python via dictionaries,
    flat files, and databases.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们演示了如何通过字典、平面文件和数据库将数据加载到Python中。
- en: Importing data into pandas from Python data structures
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Python数据结构导入数据到pandas
- en: 'The first step in working with `pandas` DataFrames is to create one using the
    `pandas` constructor function, `DataFrame()`. The constructor takes many Python
    data structures as input. It also takes as input NumPy arrays and pandas **Series**,
    another type of one-dimensional `pandas` data structure that is similar to a list.
    Here we demonstrate how to convert a dictionary of lists into a DataFrame:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pandas` DataFrame的第一步是通过`pandas`构造函数`DataFrame()`来创建一个DataFrame。构造函数接受多种Python数据结构作为输入。它还可以接收NumPy数组和pandas的**Series**，Series是另一种一维的`pandas`数据结构，类似于列表。这里我们演示如何将一个字典的列表转换为DataFrame：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Importing data into pandas from a flat file
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从平面文件导入数据到pandas
- en: 'Because healthcare data can often be in flat file format, such as `.csv`  or
    `.fwf`, it is important to know of the `read_csv()` and `read_fwf()` functions
    that import data into `pandas` from these two formats, respectively. Both of the
    functions take as mandatory arguments the full path of the flat file, along with
    over a dozen additional optional arguments that specify options including the
    data types of the columns, the header rows, the columns to include in the DataFrame,
    and so on (a full listing of the function arguments is available online). It is
    often easiest to import all the columns as string types and convert the columns
    to other data types later on. In the following example, a DataFrame called `data`
    is created by using the `read_csv()` function to read in a flat `.csv` file that
    contains one header row (`row #0`):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '因为医疗保健数据通常采用平面文件格式，如`.csv`或`.fwf`，所以了解`read_csv()`和`read_fwf()`函数非常重要，这两个函数分别用于将数据从这两种格式导入`pandas`。这两个函数都需要作为必需参数提供平面文件的完整路径，并且还有十多个可选参数，用于指定诸如列的数据类型、标题行、要包含在DataFrame中的列等选项（完整的函数参数列表可以在线查看）。通常，最简单的方法是将所有列导入为字符串类型，然后再将列转换为其他数据类型。在下面的示例中，使用`read_csv()`函数从一个包含一个标题行（`row
    #0`）的平面`.csv`文件中读取数据，并创建一个名为`data`的DataFrame：'
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Because fixed-width files have no explicit character separator, the `read_fwf()`
    function needs an additional argument, `widths`, which is a list of integers specifying
    the column widths for each column. The length of `widths` should match the number
    of columns in the file. As an alternative, the `colspecs` argument takes in a
    list of tuples specifying the starting points and endpoints of each column:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 因为定宽文件没有显式的字符分隔符，`read_fwf()`函数需要一个额外的参数`widths`，它是一个整数列表，指定每一列的宽度。`widths`的长度应该与文件中的列数匹配。作为替代，`colspecs`参数接收一个元组列表，指定每列的起始点和终止点：
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Importing data into pandas from a database
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据库导入数据到pandas
- en: 'The `pandas` library also has functions to support the import of tables directly
    from SQL databases. Functions that can accomplish this include `read_sql_query()`
    and `read_sql_table()`. Before using these functions, the connection to the database
    must be established so that it can be passed to the function. In the following
    example, a table from a SQLite database is read into a DataFrame using the `read_sql_query()`
    function:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`库还支持从SQL数据库直接导入表格的函数。这些函数包括`read_sql_query()`和`read_sql_table()`。在使用这些函数之前，必须先建立与数据库的连接，以便将其传递给函数。以下示例展示了如何使用`read_sql_query()`函数将SQLite数据库中的表读取到DataFrame中：'
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If you wish to connect to a standard database, such as a MySQL database, the
    code would be similar, except for the connection statement, which would use the
    corresponding function for a MySQL database.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望连接到标准数据库，如MySQL数据库，代码将类似，唯一不同的是连接语句，它将使用针对MySQL数据库的相应函数。
- en: Common operations on DataFrames
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DataFrame的常见操作
- en: In this section, we'll go over DataFrame operations useful for performing analytics.
    For descriptions of additional operations, please refer to the official pandas
    documentation at [https://pandas.pydata.org/](https://pandas.pydata.org/).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍一些对执行分析有用的DataFrame操作。有关更多操作的描述，请参阅官方的pandas文档，网址为[https://pandas.pydata.org/](https://pandas.pydata.org/)。
- en: Adding columns
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加列
- en: Adding columns is a common operation in analytics, whether adding new columns
    from scratch or transforming existing columns. Let's go over both types of operations
    here.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 添加列是数据分析中常见的操作，无论是从头开始添加新列还是转换现有列。这里我们将介绍这两种操作。
- en: Adding blank or user-initialized columns
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加空白列或用户初始化的列
- en: 'To add a new column of a DataFrame, you can follow the name of the DataFrame
    with the name of the new column (enclosed in single quotes and square brackets)
    and set it equal to whatever value you like. To add a column of empty strings
    or integers, you can set the column equal to `""` or `numpy.nan`, respectively
    (the latter requires importing `numpy` beforehand). To add a column of zeros,
    set the column equal to `0`. The following examples illustrate these points:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加一个新的DataFrame列，你可以在DataFrame名称后加上新列的名称（用单引号和方括号括起来），并将其设置为你喜欢的任何值。要添加一个空字符串或整数的列，你可以将列设置为`""`或`numpy.nan`，后者需要事先导入`numpy`。要添加一个零的列，可以将列设置为`0`。以下示例说明了这些要点：
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output is as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Adding new columns by transforming existing columns
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过转换现有列添加新列
- en: 'In some cases, you might wish to add a new column that is a function of existing
    columns. In the following example, the new column, titled `example_new_column_3`,
    is added as a sum of the existing columns, `old_column_1` and `old_column_2`.
    The `axis=1` argument indicates that you wish to take the horizontal sum across
    the columns instead of the vertical sum of columns:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，你可能希望添加一个新列，该列是现有列的函数。在以下示例中，新的列`example_new_column_3`作为现有列`old_column_1`和`old_column_2`的和被添加。`axis=1`参数表示你希望对列进行横向求和，而不是对列进行纵向求和：
- en: '[PRE18]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output is as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE19]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following second example accomplishes a similar task using the pandas `apply()`
    function. `apply()` is a special function because it allows you to apply any function
    to columns in a DataFrame (including your own custom functions):'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下第二个示例使用pandas的`apply()`函数完成类似的任务。`apply()`是一个特殊的函数，因为它允许你将任何函数应用于DataFrame中的列（包括你自定义的函数）：
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE21]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Dropping columns
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除列
- en: 'To drop columns, you can use pandas'' `drop()` function. It takes a single
    column as well as a list of columns, and in this example, additional optional
    arguments indicate which is the axis along which to drop and whether or not to
    drop columns in place:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除列，可以使用pandas的`drop()`函数。它接受单个列名或列名列表，在此示例中，额外的可选参数指示沿哪个轴删除列，并且是否在原地删除列：
- en: '[PRE22]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE23]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Applying functions to multiple columns
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对多个列应用函数
- en: 'To apply a function over multiple columns in a DataFrame, the list of columns
    can be iterated over using a `for` loop. In the following example, a predefined
    list of columns is converted from the string type to the numeric type:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 要对DataFrame中的多个列应用函数，可以使用`for`循环遍历列的列表。在以下示例中，预定义的列列表从字符串类型转换为数字类型：
- en: '[PRE24]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here is the output:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '[PRE25]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Combining DataFrames
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合并DataFrame
- en: DataFrames can also be combined with each other, as long as they have the same
    number of entries along the combining axis. In this example, two DataFrames are
    concatenated vertically (for example, they contain the same number of columns,
    and their rows are stacked upon each other). DataFrames can also be concatenated
    horizontally (if they contain the same number of rows) by specifying the `axis`
    parameter. Note that the column names and row names should correspond to each
    other across the DataFrames; if they do not, new columns will be formed and NaN
    values will be inserted for any missing values.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame也可以彼此组合，只要它们在合并轴上有相同数量的条目。在此示例中，两个DataFrame被垂直连接（例如，它们包含相同数量的列，行按顺序堆叠）。DataFrame也可以水平连接（如果它们包含相同数量的行），通过指定`axis`参数来完成。请注意，列名和行名应在所有DataFrame之间相互对应；如果不对应，则会形成新的列，并为任何缺失的值插入NaN。
- en: 'First, we create a new DataFrame name, `df2`:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建一个新的DataFrame名称，`df2`：
- en: '[PRE26]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output is as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE27]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Next, we perform the concatenation. We set the optional `ignore_index` argument
    equal to `True` to avoid duplicate row indices:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们进行连接操作。我们将可选的`ignore_index`参数设置为`True`，以避免重复的行索引：
- en: '[PRE28]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output is as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE29]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Converting DataFrame columns to lists
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将DataFrame列转换为列表
- en: 'To extract the contents of a column into a list, you can use the `tolist()`
    function. After being converted to a list, the data can then be iterated over
    using `for` loops and comprehensions:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 要将列的内容提取到列表中，可以使用`tolist()`函数。转换为列表后，数据可以通过`for`循环和推导式进行迭代：
- en: '[PRE30]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output is as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE31]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Getting and setting DataFrame values
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取和设置DataFrame值
- en: 'The `pandas` library offers two main methods for selectively getting and setting
    values in DataFrames: `loc` and `iloc`. The `loc` method is mainly for **label-based
    indexing** (for example, identifying rows/columns using their indices/column names,
    respectively), while the `iloc` method is primarily for **integer-based indexing**
    (for example, identifying rows/columns using their integer positions in the DataFrame).
    The specific labels/indices of the rows and columns you wish to access are provided
    following the name of the DataFrame using square brackets, with row labels/indices
    preceding column labels/indices and separated from them by a comma. Let''s look
    at some examples.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`库提供了两种主要方法来选择性地获取和设置DataFrame中的值：`loc`和`iloc`。`loc`方法主要用于**基于标签的索引**（例如，使用索引/列名识别行/列），而`iloc`方法主要用于**基于整数的索引**（例如，使用行/列在DataFrame中的整数位置来识别）。您希望访问的行和列的具体标签/索引通过方括号紧跟在DataFrame名称后面提供，行标签/索引位于列标签/索引之前，并由逗号分隔。让我们来看一些示例。'
- en: Getting/setting values using label-based indexing with loc
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用基于标签的索引（loc）获取/设置值
- en: 'The `.loc` attribute of a DataFrame is used to select values using the labels
    of the entries. It can be used to retrieve single scalar values from a DataFrame
    (using singular string labels for both row and column), or multiple values from
    a DataFrame (using lists of row/column labels). Single and multiple indexing can
    also be used in combination to get multiple values from a single row or column.
    The following lines of code illustrate the retrieval of a single scalar value
    from the `df` DataFrame:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame的`.loc`属性用于通过条目的标签选择值。它可以用于从DataFrame中检索单个标量值（使用行列的单个字符串标签），或从DataFrame中检索多个值（使用行/列标签的列表）。还可以将单索引和多索引结合使用，从单行或单列中获取多个值。以下代码行演示了如何从`df`
    DataFrame中检索单个标量值：
- en: '[PRE32]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The output will be `7.0`.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果为`7.0`。
- en: 'Single/multiple values can also be set using the `.loc` attribute and an equals
    sign:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以使用`.loc`属性和等号设置单个/多个值：
- en: '[PRE33]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output is as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE34]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Getting/setting values using integer-based labeling with iloc
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用基于整数标签的iloc获取/设置值
- en: 'The `.iloc` attribute works very similarly to the `.loc` attribute, except
    that it uses the integer positions of the rows and columns being accessed, not
    their labels. In the following example, the value in the 101st row (not the 100th
    row, since indexing starts at 0) and the 100th column is transferred to `scalar_value`:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`.iloc`属性与`.loc`属性非常相似，只是它使用被访问的行和列的整数位置，而不是它们的标签。在以下示例中，第101行（不是第100行，因为索引从0开始）和第100列的值被转移到`scalar_value`中：'
- en: '[PRE35]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The output is `7.0`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果为`7.0`。
- en: Note that, similarly to `.loc`, lists containing multiple values can be passed
    to the `.iloc` attribute to change multiple entries of a DataFrame at once.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，与`.loc`类似，包含多个值的列表可以传递给`.iloc`属性，以一次性更改 DataFrame 中的多个条目。
- en: Getting/setting multiple contiguous values using slicing
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用切片获取/设置多个连续的值
- en: 'Sometimes, the multiple values that we wish to get or set are coincidentally
    in neighboring (contiguous) columns. When this is the case, we can use **slicing**
    within the square brackets to select multiple values. With slicing, we specify
    the starting point and endpoint of the data that we wish to access. We can use
    slicing with both `.loc` and `.iloc`, although slicing using integers and `.iloc`
    is more common. The following lines of code illustrate slicing to retrieve part
    of a DataFrame (we can also assign elements using an equals sign). Note that slicing
    can also be used to access values in lists and tuples (as covered previously in
    the current chapter):'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们希望获取或设置的多个值恰好位于相邻（连续）的列中。在这种情况下，我们可以在方括号内使用**切片**来选择多个值。通过切片，我们指定希望访问的数据的起始点和终止点。我们可以在`.loc`和`.iloc`中使用切片，尽管使用整数和`.iloc`的切片更为常见。以下代码行展示了如何通过切片从
    DataFrame 中提取部分内容（我们也可以使用等号进行赋值）。请注意，切片也可以用于访问列表和元组中的值（如本章之前所述）：
- en: '[PRE36]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output is as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE37]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Fast getting/setting of scalar values using at and iat
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用`at`和`iat`快速获取/设置标量值
- en: 'If we are certain that we only wish to get/set single values in a DataFrame,
    we can use the `.at` and `.iat` attributes, along with singular labels/integers,
    respectively. Just remember, the `i` in `.iloc` and `.iat` stands for "integer":'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们确定只希望获取/设置 DataFrame 中的单个值，可以使用 `.at` 和 `.iat` 属性，分别配合单一标签/整数。只需记住，`.iloc`
    和 `.iat` 中的 `i` 代表“整数”：
- en: '[PRE38]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The output is `11`.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果是`11`。
- en: Other operations
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他操作
- en: Two other common operations are filtering rows using a Boolean condition and
    sorting rows. Here we will review each of these operations.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 另外两个常见的操作是使用布尔条件筛选行和排序行。这里我们将回顾每个操作。
- en: Filtering rows using Boolean indexing
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用布尔索引筛选行
- en: So far, we've discussed using labels, integers, and slicing to select values
    in DataFrames. Sometimes, it is convenient to select certain rows that meet a
    certain condition in one of their statements. For example, if we wanted to restrict
    an analysis on people whose age is greater than or equal to 50 years.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了如何使用标签、整数和切片来选择 DataFrame 中的值。有时，选择符合特定条件的某些行会更加方便。例如，如果我们希望将分析限制在年龄大于或等于
    50 岁的人群中。
- en: 'pandas DataFrames support **Boolean indexing**, that is, indexing using a vector
    of Boolean values to indicate which values we wish to include, provided that the
    length of the Boolean vector is equal to the number of rows in the DataFrame.
    Because a conditional statement involving a DataFrame column yields exactly that,
    we can index DataFrames using such conditional statements. In the following example,
    the `df` DataFrame is filtered to include only rows in which the value of the
    `age` column is equal to or exceeds `50`:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: pandas DataFrame 支持**布尔索引**，即使用布尔值的向量进行索引，以指示我们希望包含哪些值，前提是布尔向量的长度等于 DataFrame
    中的行数。由于涉及 DataFrame 列的条件语句正是这样，我们可以使用此类条件语句来索引 DataFrame。在以下示例中，`df` DataFrame
    被筛选，只包括`age`列值大于或等于`50`的行：
- en: '[PRE39]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output is as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE40]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Conditional statements can be chained together using logical operators such
    as `|` or `&`.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 条件语句可以使用逻辑运算符如`|`或`&`进行链式连接。
- en: Sorting rows
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 排序行
- en: 'If you wish to sort a DataFrame by the value of one of its columns, that can
    be done using the `sort_values()` function; simply specify the column name as
    the first parameter. `ascending` is an optional parameter that lets you specify
    the sorting direction:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望按某一列的值对 DataFrame 进行排序，可以使用 `sort_values()` 函数；只需将列名作为第一个参数传递即可。`ascending`是一个可选参数，允许你指定排序方向：
- en: '[PRE41]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The output is as follows:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE42]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: SQL-like operations
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类似SQL的操作
- en: For people who are used to working with heterogeneously typed tables in SQL,
    switching to similar analyses in Python may seem like a daunting task. Fortunately,
    there are a number of `pandas` functions that can be combined to yield results
    similar to those yielded by common SQL queries, using operations such as grouping
    and joining. There is even a subsection in the `pandas` documentation ([https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html](https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html))
    that describes how to perform SQL-like operations with `pandas` DataFrames. We
    provide two such examples in this section.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些习惯于在 SQL 中处理异构类型表格的人来说，转向使用 Python 进行类似的分析可能看起来是一项艰巨的任务。幸运的是，有许多 `pandas`
    函数可以结合使用，从而得到与常见 SQL 查询相似的结果，使用诸如分组和连接等操作。`pandas` 文档中甚至有一个子部分（[https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html](https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html)）描述了如何使用
    `pandas` DataFrame 执行类似 SQL 的操作。在本节中，我们提供了两个这样的示例。
- en: Getting aggregate row COUNTs
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取聚合行计数
- en: 'Sometimes, you may wish to get a count or tally of the occurrences of particular
    values in a column. For example, you might have a healthcare dataset and you want
    to know how many times particular payment methods were used during patient visits.
    In SQL, you could write a query that uses a `GROUP BY` clause in conjunction with
    an aggregate function (in this case, `COUNT(*)`) to get a tally of the payment
    methods:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，您可能希望获取某一列中特定值的出现次数或统计。例如，您可能拥有一个医疗保健数据集，想要知道在患者就诊期间，特定支付方式被使用了多少次。在 SQL
    中，您可以编写一个查询，使用 `GROUP BY` 子句与聚合函数（在本例中为 `COUNT(*)`）结合，来获取支付方式的统计信息：
- en: '[PRE43]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'In `pandas`, the same result is accomplished by chaining together the `groupby()`
    and `size()` functions:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在`pandas`中，您可以通过将`groupby()`和`size()`函数链式调用来实现相同的结果：
- en: '[PRE44]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The output is as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE45]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Joining DataFrames
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接 DataFrame
- en: 'In [Chapter 4](e1b89921-e75b-4b16-a567-8970a173db53.xhtml), *Computing Foundations
    – Databases*, we discussed merging data from two database tables using the `JOIN`
    operation. To use a JOIN operation, you need to specify the names of the two tables,
    along with the type of JOIN (left, right, outer, or inner) and the columns on
    which to join:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](e1b89921-e75b-4b16-a567-8970a173db53.xhtml)，*计算基础 - 数据库*中，我们讨论了使用 `JOIN`
    操作合并来自两个数据库表的数据。要使用JOIN操作，您需要指定两个表的名称，以及JOIN的类型（左、右、外部或内部）和连接的列：
- en: '[PRE46]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'In pandas, you can accomplish table joins using the `merge()` or `join()` functions.
    By default, the `join()` function joins data on the index of the tables; however,
    other columns can be used by specifying the `on` parameter. If column names are
    overlapping in the two tables being joined, you will need to specify a `rsuffix`
    or `lsuffix` argument that renames the columns so they no longer have identical
    names:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 中，您可以使用 `merge()` 或 `join()` 函数来实现表连接。默认情况下，`join()` 函数基于表的索引连接数据；但是，可以通过指定
    `on` 参数来使用其他列。如果连接的两个表中有重复的列名，您需要指定 `rsuffix` 或 `lsuffix` 参数，以重命名列，使它们不再具有相同的名称：
- en: '[PRE47]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows (note the `NaN` values in Row 3, a row that was not
    present in `df`):'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下（请注意第3行中的`NaN`值，这是`df`中不存在的一行）：
- en: '[PRE48]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Introduction to scikit-learn
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: scikit-learn简介
- en: Entire books have been written on **scikit-learn** ([http://scikit-learn.org/stable/](http://scikit-learn.org/stable/)).
    The scikit-learn library has numerous submodules. Only a few of these submodules
    will be used in this book (in [Chapter 7](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml),
    *Making Predictive Models in Healthcare*). These include the `sklearn.linear_model`
    and `sklearn.ensemble` submodules, for example. Here we will give an overview
    of some of the more commonly used submodules. For convenience, we have grouped
    the relevant modules into various segments of the data science pipeline discussed
    in [Chapter 1](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml), *Introduction to Healthcare
    Analytics***.**
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 整本书都围绕**scikit-learn**（[http://scikit-learn.org/stable/](http://scikit-learn.org/stable/)）展开。scikit-learn
    库包含许多子模块。本书将只使用其中的一些子模块（在[第7章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)，*在医疗保健中创建预测模型*）。例如，包括
    `sklearn.linear_model` 和 `sklearn.ensemble` 子模块。在这里，我们将概述一些更常用的子模块。为了方便起见，我们已将相关模块分组为数据科学管道的各个部分，这些部分在[第1章](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml)，*医疗保健分析简介*中讨论过。
- en: Sample data
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例数据
- en: scikit-learn includes several sample datasets in the `sklearn.datasets` submodule.
    At least two of these datasets, `sklearn.datasets.load_breast_cancer` and `sklearn.datasets.load_diabetes`,
    are healthcare-related. These datasets have been already preprocessed and are
    small in size, spanning only dozens of features and hundreds of patients. The
    data we will use in [Chapter 7](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml), *Making
    Predictive Models in Healthcare* is much bigger and resembles the data you are
    likely to receive from modern healthcare organizations. These sample sklearn datasets,
    however, are useful for experimenting with scikit-learn functions.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn在`sklearn.datasets`子模块中包含了几个示例数据集。至少有两个数据集，`sklearn.datasets.load_breast_cancer`和`sklearn.datasets.load_diabetes`，是与健康相关的。这些数据集已经预处理过，且规模较小，仅包含几十个特征和几百个患者。在[第7章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)《医疗保健中的预测模型制作》中，我们使用的数据要大得多，且更像现代医疗机构提供的数据。然而，这些示例数据集对于实验scikit-learn功能仍然非常有用。
- en: Data preprocessing
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: Data preprocessing functionality is present in the `sklearn.preprocessing` submodule,
    among others. Some of the relevant functions of this module are discussed in the
    following sections.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理功能存在于`sklearn.preprocessing`子模块中，其他相关功能在以下章节中讨论。
- en: One-hot encoding of categorical variables
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类变量的独热编码
- en: Almost every dataset has some categorical data contained in it. **Categorical
    data** is discrete data in which the value can take on a finite number of possible
    values (usually encoded as a "string"). Because Python's scikit-learn can handle
    only numeric data, before performing machine learning with scikit-learn, we must
    find alternative ways of encoding categorical variables.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎每个数据集都包含一些分类数据。**分类数据**是离散数据，其中值可以取有限数量的可能值（通常编码为“字符串”）。由于Python的scikit-learn只能处理数值数据，因此在使用scikit-learn进行机器学习之前，我们必须找到其他方法来对分类变量进行编码。
- en: With **one-hot encoding**, also known as a **1-of-K encoding scheme**, a single
    categorical variable having *k* possible values is converted into *k* different
    binary variables, each one is positive if and only if the column's value for that
    observation equaled the value it represents. In [Chapter 7](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml),
    *Making Predictive Models in Healthcare*, we provide a detailed example of what
    one-hot encoding is and use a pandas function called `get_dummies()` to perform
    one-hot encoding on a real clinical dataset. scikit-learn also has a class used
    to perform one-hot encoding, however, it is the `OneHotEncoder` class in the `sklearn.preprocessing`
    module.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**独热编码**，也称为**1-of-K编码方案**，一个具有*k*个可能值的单一分类变量被转换为*k*个不同的二元变量，每个二元变量仅在该观测值的列值等于它所代表的值时为正。在[第7章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)《医疗保健中的预测模型制作》中，我们提供了独热编码的详细示例，并使用pandas的`get_dummies()`函数对真实的临床数据集进行独热编码。scikit-learn也有一个类可以用于执行独热编码，这个类是`sklearn.preprocessing`模块中的`OneHotEncoder`类。
- en: For instructions on how `OneHotEncoder` is used, you can visit the scikit-learn
    documentation: [http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何使用`OneHotEncoder`的说明，可以访问scikit-learn文档：[http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features)。
- en: Scaling and centering
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缩放和中心化
- en: 'For some machine learning algorithms, it is preferable to transform not only
    the categorical variables (using one-hot encoding, discussed previously) but also
    the continuous variables. Recall from [Chapter 1](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml),
    *Introduction to Healthcare Analytics* that a continuous variable is numerical
    and can take on any rational value (although in many cases they are restricted
    to integers). A particularly common practice is to **standardize** each continuous
    variable so that the *mean of the variable is zero and the standard deviation
    is one*. For example, take the `AGE` variable: it typically ranges from 0 to about
    100, with a mean of perhaps 40\. Let''s pretend that for a particular population,
    the mean of our `AGE` variable is 40 with a standard deviation of 20\. If we were
    to center and rescale our `AGE` variable, a person whose age was 40 would be represented
    as zero in the transformed variable. A person who was 20 years old would be represented
    as -1, a person who was 60 years old would be represented as 1, a person who was
    80 years old would be represented as 2, and a person who was 50 years old would
    be 0.5\. This transformation prevents variables with larger ranges from being
    overrepresented in the machine learning algorithm.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一些机器学习算法，通常建议不仅转换类别变量（使用之前讨论过的独热编码），还需要转换连续变量。回顾[第1章](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml)，*《医疗分析导论》*中提到，连续变量是数值型的，可以取任何有理数值（尽管在许多情况下它们限制为整数）。一个特别常见的做法是**标准化**每个连续变量，使得*变量的均值为零，标准差为一*。例如，考虑`AGE`变量：它通常范围从0到100左右，均值可能约为40。假设对于某个人群，`AGE`变量的均值为40，标准差为20。如果我们对`AGE`变量进行中心化和重缩放，年龄为40的人在转换后的变量中将表示为零。年龄为20岁的人将表示为-1，年龄为60岁的人将表示为1，年龄为80岁的人将表示为2，年龄为50岁的人将表示为0.5。这种转换可以防止具有更大范围的变量在机器学习算法中被过度表示。
- en: scikit-learn has many built-in classes and functions for centering and scaling
    data, including `sklearn.preprocessing.StandardScaler()`, `sklearn.preprocessing.MinMaxScaler()`,
    and `sklearn.preprocessing.RobustScaler()`. These various tools are specialized
    for centering and scaling different types of continuous data, such as normally
    distributed variables, or variables that have many outliers.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn有许多内置类和函数，用于数据的中心化和缩放，包括`sklearn.preprocessing.StandardScaler()`、`sklearn.preprocessing.MinMaxScaler()`和`sklearn.preprocessing.RobustScaler()`。这些不同的工具专门用于处理不同类型的连续数据，如正态分布变量或具有许多异常值的变量。
- en: For instructions on how the scaling classes are used, you can check out the
    scikit-learn documentation: [http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling](http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何使用缩放类的说明，您可以查看scikit-learn文档：[http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling](http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling)。
- en: Binarization
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二值化
- en: '**Binarization** is yet another type of transformation in which continuous
    variables are transformed into binary variables. For example, if we had a continuous
    variable named `AGE,` we could binarize the variable around 50 years by thresholding
    ages 50 and above to have a value of one, and ages with values below 50 to have
    a value of zero. Binarizing is good to save time and memory when you have many
    variables; however, in practice, the raw continuous values usually perform better
    since they are more informative.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**二值化**是另一种转换方法，它将连续变量转换为二进制变量。例如，如果我们有一个名为`AGE`的连续变量，我们可以通过设置年龄50岁为阈值，对年龄进行二值化，将50岁及以上的年龄设为1，将低于50岁的年龄设为0。二值化在处理有大量变量时节省了时间和内存；然而，实际上，原始的连续值通常表现得更好，因为它们包含更多的信息。'
- en: While binarization can also be performed in pandas using the code demonstrated
    earlier, scikit-learn comes with a `Binarizer` class that can also be used to
    binarize features. For instructions on using the `Binarizer` class, you can visit
    [http://scikit-learn.org/stable/modules/preprocessing.html#binarization](http://scikit-learn.org/stable/modules/preprocessing.html#binarization).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然也可以使用之前演示过的代码在pandas中执行二值化，但scikit-learn提供了一个`Binarizer`类，也可以用来对特征进行二值化。有关如何使用`Binarizer`类的说明，您可以访问[http://scikit-learn.org/stable/modules/preprocessing.html#binarization](http://scikit-learn.org/stable/modules/preprocessing.html#binarization)。
- en: Imputation
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 填充
- en: In [Chapter 1](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml), *Introduction to
    Healthcare Analytics*, we mentioned the importance of handling missing data. **Imputation**
    is one strategy for dealing with missing values in which missing values are filled
    in with estimates that are derived based on the data that is present. In healthcare,
    two common types of imputation are **zero imputation**, in which missing data
    is taken to be zero (for example, if a particular diagnosis has a value of `NULL`,
    most likely that is because it is not present in the patient chart) and **mean
    imputation**, in which the missing data is taken to be the mean of the distribution
    of the present data (for example, if a patient has a missing age, we can impute
    it as 40). We demonstrated various imputation methods in [Chapter 4](e1b89921-e75b-4b16-a567-8970a173db53.xhtml),
    *Computing Foundations – Databases*, and we will write our own custom functions
    for performing imputation in [Chapter 7](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml),
    *Making Predictive Models in Healthcare*.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 1 章](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml)，*医疗分析入门*中，我们提到了处理缺失数据的重要性。**插补**是处理缺失值的一种策略，通过用基于现有数据估算的值来填补缺失值。在医疗领域，常见的两种插补方法是**零插补**，即将缺失数据视为零（例如，如果某一诊断值为
    `NULL`，很可能是因为该信息没有出现在病历中）；以及**均值插补**，即将缺失数据视为现有数据分布的均值（例如，如果某患者缺少年龄，我们可以将其插补为
    40）。我们在[第 4 章](e1b89921-e75b-4b16-a567-8970a173db53.xhtml)，*计算基础——数据库*中演示了各种插补方法，我们将在[第
    7 章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)，*在医疗保健中构建预测模型*中编写我们自己的插补函数。
- en: Scikit-learn comes with an `Imputer` class for performing different types of
    imputation. You can see details on how it is used at [http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values](http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 提供了一个 `Imputer` 类来执行不同类型的插补。你可以在 [http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values](http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values)
    查看如何使用它的详细信息。
- en: Feature-selection
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征选择
- en: In machine learning, there is often a misconception that the more data you have,
    the better off you are. This is usually true with observations (for example, the
    number of rows in the dataset). However, with features, more isn't always better.
    In some cases, the performance may be paradoxically better with fewer features,
    because multiple features with high correlation are biasing the predictions, or
    because there are more features present than the number of observations.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，常常有一种误解，认为数据越多越好。对于观测数据（例如，数据集中的行数），这种说法通常是正确的。然而，对于特征来说，更多的特征并不总是更好。在某些情况下，使用较少的特征可能反而表现得更好，因为多个高度相关的特征可能会对预测产生偏差，或者特征的数量超过了观测值的数量。
- en: In other cases, the performance may be the same or infinitesimally worse with,
    say, half the features, but the smaller number of features may be desirable for
    a number of reasons, including time considerations, memory availability, or ease
    of explanation and interpretation to other non-technical stakeholders. In any
    case, it is almost always a good idea to perform some feature selection on the
    data. Even if you don't wish to remove any features, performing feature selection
    and ranking the feature importance can give you great insight into your model
    and understanding its predictive behavior and performance.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他情况下，性能可能与使用一半特征时相同，或者稍微差一点，但较少的特征可能因为多种原因而更为可取，包括时间考虑、内存可用性，或者便于向非技术相关人员解释和解释。无论如何，通常对数据进行特征选择是一个好主意。即使你不打算删除任何特征，进行特征选择并对特征重要性进行排序，也能为你提供对模型的深入洞察，帮助理解其预测行为和性能。
- en: There are a number of classes and functions in the `sklearn.feature_selection`
    module that are built for feature selection, and different sets of classes correspond
    to different methods of performing feature selection. For example, univariate
    feature selection involves measuring the statistical dependency between each predictor
    variable and the target variable, and this can be done using the `SelectKBest`
    or `SelectPercentile` classes, among others. The `VarianceThreshold` class removes
    features that have a low variance across observations, for example, those features
    that are almost always zero. And the `SelectFromModel` class prunes features that
    don't meet a certain strength requirement (in terms of either coefficient or feature
    importance) after the model has been fit.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.feature_selection` 模块中有许多类和函数是为特征选择而构建的，不同的类集合对应于不同的特征选择方法。例如，单变量特征选择涉及测量每个预测变量与目标变量之间的统计依赖性，这可以通过
    `SelectKBest` 或 `SelectPercentile` 类等实现。`VarianceThreshold` 类移除在观测值中方差较低的特征，例如那些几乎总是为零的特征。而
    `SelectFromModel` 类在模型拟合后，修剪那些不满足一定强度要求（无论是系数还是特征重要性）的特征。'
- en: For a full list of the feature selection classes in scikit-learn, you can visit
    [http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 scikit-learn 中所有特征选择类的完整列表，请访问[http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)。
- en: Machine learning algorithms
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习算法
- en: Machine learning algorithms provide a mathematical framework for making predictions
    for new observations. scikit-learn supports dozens of different ML algorithms
    that have different strengths and weaknesses. We will discuss some of these algorithms
    and their corresponding scikit-learn API functionality briefly here. We will use
    some of these algorithms in [Chapter 7](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml),
    *Making Predictive Models in Healthcare*.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法提供了一种数学框架，用于对新的观测值进行预测。scikit-learn 支持数十种不同的机器学习算法，这些算法具有不同的优缺点。我们将在这里简要讨论一些算法及其相应的
    scikit-learn API 功能。我们将在[第七章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)中使用这些算法，*在医疗保健中构建预测模型*。
- en: Generalized linear models
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广义线性模型
- en: As we discussed in [Chapter 3](46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml),
    *Machine Learning Foundations*, a **linear model** can be thought of casually
    as a weighted combination of features (for example, a weighted sum) to predict
    a target value. The features are determined by the observations; the weights of
    each feature are determined by the model. Linear regression predicts a continuous
    variable, while logistic regression can be thought of as an extended form of linear
    regression in which the predicted target undergoes a **logit transformation**
    to be converted to a variable that has a range between zero and one. Such a transformation
    is useful for performing binary classification tasks such as when there are two
    possible outcomes.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第三章](46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml)中讨论的，*机器学习基础*，**线性模型**可以简单地理解为特征的加权组合（例如加权和），用于预测目标值。特征由观测值决定；每个特征的权重由模型决定。线性回归预测连续变量，而逻辑回归可以看作是线性回归的扩展形式，其中预测的目标值经过**logit变换**，转化为一个范围在零到一之间的变量。这种变换对于执行二分类任务非常有用，比如当有两个可能的结果时。
- en: In scikit-learn, these two algorithms are represented by the `sklearn.linear_model.LogisticRegression`
    and `sklearn.linear_model.LinearRegression` classes. We will demonstrate logistic
    regression in [Chapter 7](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml), *Making
    Predictive Models in Healthcare*.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在 scikit-learn 中，这两种算法由 `sklearn.linear_model.LogisticRegression` 和 `sklearn.linear_model.LinearRegression`
    类表示。我们将在[第七章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)中演示逻辑回归，*在医疗保健中构建预测模型*。
- en: Ensemble methods
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成方法
- en: '**Ensemble methods** involve making predictions using combinations of different
    ML models. For example, a **random forest** is a collection of decision tree classifiers
    that have been decorrelated from each other by choosing and using specific feature
    sets for each tree. Additionally, **AdaBoost** is an algorithm that fits many
    weak learners on the data to make effective predictions. These algorithms are
    supported by the `sklearn.ensemble` module.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '**集成方法**涉及使用不同机器学习模型的组合来进行预测。例如，**随机森林**是由多个决策树分类器组成的集合，这些树通过为每棵树选择和使用特定的特征集来实现去相关。此外，**AdaBoost**是一种算法，它通过在数据上拟合许多弱学习器来做出有效预测。这些算法由`sklearn.ensemble`模块提供支持。'
- en: Additional machine learning algorithms
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他机器学习算法
- en: Some other popular machine learning algorithms include the Naive Bayes algorithm,
    k-nearest neighbors, neural networks, decision trees, and support vector machines.
    These are supported in scikit-learn by the `sklearn.naive_bayes`, `sklearn.neighbors`,
    `sklearn.neural_network`, `sklearn.tree`, and `sklearn.svm` modules, respectively.
    In [Chapter 7](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml), *Making Predictive
    Models in Healthcare*, we will make neural network models on a clinical dataset.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 其他一些流行的机器学习算法包括朴素贝叶斯算法、k-近邻算法、神经网络、决策树和支持向量机。这些算法在scikit-learn中分别由`sklearn.naive_bayes`、`sklearn.neighbors`、`sklearn.neural_network`、`sklearn.tree`和`sklearn.svm`模块提供支持。在[第7章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)
    *在医疗保健中构建预测模型*中，我们将使用临床数据集构建神经网络模型。
- en: Performance assessment
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能评估
- en: Lastly, once we make our model using our desired algorithm, it is important
    to measure its performance. The `sklearn.metrics` module is useful for this. As
    discussed in [Chapter 3](46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml), *Machine
    Learning Foundations*, the confusion matrix is particularly important for classification
    tasks, and it is supported by the `sklearn.metrics.confusion_matrix()` function.
    Determining the receiver operating characteristic (ROC) curve and calculating
    the **area under the curve** (**AUC**) can be accomplished using the `sklearn.metrics.roc_curve()`
    and `sklearn.metrics.roc_auc_score()` functions, respectively. Precision-recall
    curves are an alternative to the ROC curve that are important for imbalanced datasets,
    and they are supported by the `sklearn.metrics.precision_recall_curve()` function.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一旦我们使用所需的算法构建了模型，衡量其性能就变得至关重要。`sklearn.metrics`模块对于这一点非常有用。如[第3章](46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml)
    *机器学习基础*中所讨论的，混淆矩阵对于分类任务特别重要，并且由`sklearn.metrics.confusion_matrix()`函数支持。确定接收者操作特征（ROC）曲线并计算**曲线下面积**（**AUC**）可以分别通过`sklearn.metrics.roc_curve()`和`sklearn.metrics.roc_auc_score()`函数完成。精确率-召回率曲线是ROC曲线的替代方法，特别适用于不平衡数据集，并且由`sklearn.metrics.precision_recall_curve()`函数提供支持。
- en: Additional analytics libraries
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他分析库
- en: 'Here we mention three important packages that are frequently used for analytics:
    NumPy, SciPy, and matplotlib.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们提到三个常用于分析的主要包：NumPy、SciPy和matplotlib。
- en: NumPy and SciPy
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NumPy与SciPy
- en: '**NumPy** ([www.numpy.org](http://www.numpy.org/)) is Python''s matrix library.
    Using `numpy.array()` and similar constructs, large matrices can be created and
    various mathematical operations (including matrix addition and multiplication)
    can be performed on them. NumPy also has many functions for manipulating the shapes
    of matrices. Another feature of NumPy is the presence of familiar mathematical
    functions such as `sin()`, `cos()`, and `exp()`.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '**NumPy** ([www.numpy.org](http://www.numpy.org/)) 是Python的矩阵库。通过使用`numpy.array()`及类似的构造，可以创建大型矩阵并对其进行各种数学操作（包括矩阵加法和乘法）。NumPy还具有许多用于操作矩阵形状的函数。NumPy的另一个特点是提供了熟悉的数学函数，如`sin()`、`cos()`和`exp()`。'
- en: '**SciPy** ([www.scipy.org](http://www.scipy.org)) is a toolbox that contains
    many advanced mathematical modules. Its machine-learning-related subpackages include
    `cluster`, `stats`, `sparse`, and `optimize`. SciPy is an important package that
    enables scientific computing in Python.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '**SciPy** ([www.scipy.org](http://www.scipy.org)) 是一个包含许多高级数学模块的工具箱。与机器学习相关的子包包括`cluster`、`stats`、`sparse`和`optimize`。SciPy是一个重要的包，它使Python能够进行科学计算。'
- en: matplotlib
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: matplotlib
- en: '**matplotlib** ([https://matplotlib.org](https://matplotlib.org)) is a popular
    Python 2-D plotting library. According to its website, one "can generate plots,
    histograms, power spectra, bar charts, error charts, scatterplots, and so on,
    with just a few lines of code." Its plotting library comes with a myriad of options
    and features to enable a high degree of customization.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '**matplotlib** ([https://matplotlib.org](https://matplotlib.org)) 是一个流行的 Python
    二维绘图库。根据其官网介绍，用户“只需几行代码就可以生成图表、直方图、功率谱、条形图、误差图、散点图等。”它的绘图库提供了丰富的选项和功能，支持高度自定义。'
- en: Summary
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we took a whirlwind tour of the base Python language, along
    with two Python libraries that are important for performing analytics: pandas,
    and scikit-learn. We have now completed the foundational chapters of this book.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们快速浏览了基础的 Python 语言，以及两个在数据分析中非常重要的 Python 库：pandas 和 scikit-learn。我们现在已经完成了本书的基础章节。
- en: In [Chapter 6](023c1d7e-f3f0-42e6-a2be-64bd5ba4ab80.xhtml), *Measuring Healthcare
    Quality*, we will dive into some real-world healthcare provider performance data
    and analyze it using pandas.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第六章](023c1d7e-f3f0-42e6-a2be-64bd5ba4ab80.xhtml)《衡量医疗质量》中，我们将深入探讨一些真实的医疗服务提供者的表现数据，并使用
    pandas 进行分析。
