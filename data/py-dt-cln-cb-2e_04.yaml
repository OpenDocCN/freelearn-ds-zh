- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Identifying Outliers in Subsets of Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在数据子集中识别异常值
- en: Outliers and unexpected values may not be errors. They often are not. Individuals
    and events are complicated and surprise the analyst. Some people really are 7’4”
    tall and some really have $50 million salaries. Sometimes, data is messy because
    people and situations are messy; however, extreme values can have an out-sized
    impact on our analysis, particularly when we are using parametric techniques that
    assume a normal distribution.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值和意外值不一定是错误。它们通常不是。个体和事件是复杂的，常常出乎分析师的意料。有些人确实有7英尺4英寸的身高，也有些人年收入5000万美元。有时候，数据混乱是因为人们和情况本身就很混乱；然而，极端值可能会对我们的分析产生过大的影响，尤其是当我们使用假设正态分布的参数化技术时。
- en: These issues may become even more apparent when working with subsets of data.
    That is not just because extreme or unexpected values have more weight with smaller
    samples. It is also because they may make less sense when bivariate and multivariate
    relationships are considered. When the 7’4” person, or the person making $50 million,
    is 10 years old, the red flag gets even redder. This may suggest some measurement
    or data collection error.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理数据子集时，这些问题可能会变得更加明显。这不仅仅是因为在样本较小时，极端或意外的值权重更大。还因为当考虑双变量和多变量关系时，它们可能显得不合逻辑。当一个身高7英尺4英寸的人，或一个年收入5000万美元的人，只有10岁时，警示信号会更加显眼。这可能表明某些测量或数据收集的错误。
- en: But the key issue is the undue influence that outliers can have on the inferences
    we draw from our data. Indeed, it may be helpful to think of an outlier as an
    observation with variable values, or relationships between variable values, that
    are so unusual that they cannot help to explain relationships in the rest of the
    data. This matters for statistical inference because we cannot assume a neutral
    impact of outliers on our summary statistics or parameter estimates. Sometimes
    our models work so hard to construct parameter estimates that can account for
    patterns in outlier observations that we compromise the model’s explanatory or
    predictive power for all other observations. Raise your hand if you have ever
    spent days trying to interpret a model only to discover that your coefficients
    and predictions completely changed once you removed a few outliers.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 但关键问题是异常值对我们从数据中得出的推断可能产生的不当影响。事实上，将异常值视为具有非常规变量值，或变量值之间关系的观察，可能是有帮助的，这些观察值的异常之处使得它们无法帮助解释数据中其余部分的关系。这对于统计推断非常重要，因为我们不能假设异常值对我们的总结统计量或参数估计有中立的影响。有时，我们的模型会花费大量精力去构建能够解释异常值观察模式的参数估计，这样我们就会妥协模型对所有其他观察值的解释或预测能力。如果你曾经花费数天试图解读一个模型，却在去除一些异常值后才发现你的系数和预测完全改变了，那就举手吧。
- en: 'The identification and handling of outliers is among the most important data
    preparation tasks we have in a data analysis project. We explore a range of strategies
    for detecting and treating outliers in this chapter. Specifically, the recipes
    in this chapter examine the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值的识别和处理是数据分析项目中最重要的数据准备任务之一。在本章中，我们将探讨一系列用于检测和处理异常值的策略。具体来说，本章的食谱将涵盖以下内容：
- en: Identifying outliers with one variable
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用单一变量识别异常值
- en: Identifying outliers and unexpected values in bivariate relationships
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在双变量关系中识别异常值和意外值
- en: Using subsetting to examine logical inconsistencies in variable relationships
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用子集来检查变量关系中的逻辑不一致性
- en: Using linear regression to identify data points with significant influence
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线性回归识别具有显著影响的数据点
- en: Using *k*-nearest neighbors (KNN) to find outliers
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*k*最近邻（KNN）算法来发现异常值
- en: Using Isolation Forest to find anomalies
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用隔离森林（Isolation Forest）来发现异常值
- en: Using PandasAI to identify outliers
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PandasAI识别异常值
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need pandas, NumPy, and Matplotlib to complete the recipes in this
    chapter. I used pandas 2.1.4, but the code will run on pandas 1.5.3 or later.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要使用pandas、NumPy和Matplotlib来完成本章的食谱。我使用的是pandas 2.1.4，但代码也可以在pandas 1.5.3或更高版本上运行。
- en: The code in this chapter can be downloaded from the book’s GitHub repository,
    [https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以从本书的GitHub仓库下载，链接为[https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition)。
- en: Identifying outliers with one variable
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用单一变量识别异常值
- en: The concept of an outlier is somewhat subjective but is closely tied to the
    properties of a particular distribution; to its central tendency, spread, and
    shape. We make assumptions about whether a value is expected or unexpected based
    on how likely we are to get that value given the variable’s distribution. We are
    more inclined to view a value as an outlier if it is multiple standard deviations
    away from the mean and it is from a distribution that is approximately normal;
    one that is symmetrical (has low skew) and has relatively skinny tails (low kurtosis).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值的概念有一定的主观性，但它与特定分布的特性密切相关；即其集中趋势、分散度和形态。我们根据变量的分布假设某个值是否为预期或意外值，依据是该值出现在当前分布中的可能性。如果某个值远离均值多个标准差，并且该分布近似为正态分布（对称、偏度低且尾部较瘦），我们更倾向于将其视为异常值。
- en: This becomes clear if we imagine trying to identify outliers from a uniform
    distribution. There is no central tendency and there are no tails. Each value
    is equally likely. If, for example, COVID-19 cases per country were uniformly
    distributed, with a minimum of 1 and a maximum of 10,000,000, neither 1 nor 10,000,000
    would be considered an outlier.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们设想从均匀分布中识别异常值，这一点会变得清晰。均匀分布没有集中趋势，也没有尾部。每个值出现的概率相同。例如，如果每个国家的 COVID-19 病例数是均匀分布的，最小值为
    1，最大值为 10,000,000，那么 1 或 10,000,000 都不会被认为是异常值。
- en: We need to understand how a variable is distributed, then, before we can identify
    outliers. Several Python libraries provide tools to help us understand how variables
    of interest are distributed. We use a couple of them in this recipe to identify
    when a value is sufficiently out of range to be of concern.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要了解一个变量的分布情况，之后才能识别异常值。几个 Python 库提供了帮助我们理解感兴趣变量分布的工具。在本指南中，我们将使用其中的一些工具来识别当某个值偏离范围时，是否需要引起关注。
- en: Getting ready
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You will need the `matplotlib`, `statsmodels`, and `scipy` libraries, in addition
    to `pandas` and `numpy`, to run the code in this recipe. You can install `matplotlib`,
    `statsmodels`, and `scipy` by entering `pip install matplotlib`, `pip install
    statsmodels`, and `pip install scipy` in a terminal client or PowerShell (in Windows).
    You may also need to install `openpyxl` to save Excel files.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 `pandas` 和 `numpy`，你还需要 `matplotlib`、`statsmodels` 和 `scipy` 库来运行本指南中的代码。你可以通过在终端客户端或
    PowerShell（Windows 系统）中输入 `pip install matplotlib`、`pip install statsmodels` 和
    `pip install scipy` 来安装这些库。你可能还需要安装 `openpyxl` 来保存 Excel 文件。
- en: We will work with COVID-19 cases data in this recipe. This dataset has one observation
    for each country with total COVID-19 cases and deaths.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本指南中，我们将处理 COVID-19 病例数据。该数据集包含每个国家的 COVID-19 总病例数和死亡人数。
- en: '**Data note**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据说明**'
- en: Our World in Data provides COVID-19 public use data at [https://ourworldindata.org/covid-cases](https://ourworldindata.org/covid-cases).
    The dataset includes total cases and deaths, tests administered, hospital beds,
    and demographic data such as median age, gross domestic product, and a human development
    index, which is a composite measure of standard of living, educational levels,
    and life expectancy. The dataset used in this recipe was downloaded on March 3,
    2024.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Our World in Data 提供了 COVID-19 的公共数据，网址为 [https://ourworldindata.org/covid-cases](https://ourworldindata.org/covid-cases)。该数据集包括总病例数、死亡人数、已进行的测试数量、医院床位数量，以及诸如中位年龄、国内生产总值和人类发展指数等人口统计数据。人类发展指数是标准生活水平、教育水平和预期寿命的综合衡量标准。本指南使用的数据集于
    2024 年 3 月 3 日下载。
- en: How to do it...
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: 'We take a good look at the distribution of some of the key continuous variables
    in the COVID-19 data. We examine the central tendency and shape of the distribution,
    generating measures and visualizations of normality:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们详细查看 COVID-19 数据中一些关键连续变量的分布情况。我们分析分布的集中趋势和形态，生成正态性度量和可视化图表：
- en: Load the `pandas`, `numpy`, `matplotlib`, `statsmodels`, and `scipy` libraries,
    and the COVID-19 case data file.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 `pandas`、`numpy`、`matplotlib`、`statsmodels` 和 `scipy` 库，以及 COVID-19 病例数据文件。
- en: 'Also, set up the COVID-19 case and demographic columns:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，设置 COVID-19 病例和人口统计数据列：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Get descriptive statistics for the COVID-19 case data.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取 COVID-19 病例数据的描述性统计信息。
- en: 'Create a DataFrame with just the key case data:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个只包含关键信息的 DataFrame：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Show more detailed percentile data. We indicate that we only want to do this
    for numeric values so that the location column is skipped:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示更详细的百分位数据。我们指示只对数值进行操作，因此会跳过位置列。
- en: '[PRE3]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Note**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: Starting with pandas version 2.0.0, the default value for the `numeric_only`
    parameter is `False` for the `quantile` function. We needed to set the `numeric_only`
    value to `True` to get `quantile` to skip the `location` column.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从pandas版本2.0.0开始，`quantile`函数的`numeric_only`参数默认值为`False`。我们需要将`numeric_only`的值设置为`True`，以便让`quantile`跳过`location`列。
- en: 'You should also show skewness and kurtosis. Skewness and kurtosis describe
    how symmetrical the distribution is and how fat the tails of the distribution
    are, respectively. Both measures, for `total_cases` and `total_deaths`, are significantly
    higher than we would expect if our variables were distributed normally:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你还应该显示偏度和峰度。偏度和峰度分别描述了分布的对称性和尾部的肥胖程度。对于`total_cases`和`total_deaths`，这两个值显著高于如果变量呈正态分布时的预期值：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The prototypical normal distribution has a skewness of `0` and a kurtosis of
    `3`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 原型正态分布的偏度为`0`，峰度为`3`。
- en: Test the COVID-19 data for normality.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试COVID-19数据的正态性。
- en: 'Use the Shapiro-Wilk test from the `scipy` library. Print out the *p*-value
    from the test (the `null` hypothesis of a normal distribution can be rejected
    at the 95% level at any *p*-value below `0.05`):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`scipy`库中的Shapiro-Wilk检验。输出检验的*p*值（若* p *值低于`0.05`，则可在95%的置信水平上拒绝正态分布的`null`假设）：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Show normal quantile-quantile plots (`qqplots`) of total cases and total cases
    per million.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示总病例数和每百万总病例数的常规量化-量化图（`qqplots`）。
- en: 'The straight lines show what the distributions would look like if they were
    normal:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 直线显示了如果分布是正态分布时的样子：
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This results in the following scatterplots:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下散点图：
- en: '![](img/B18596_04_01.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_01.png)'
- en: 'Figure 4.1: Distribution of COVID-19 cases compared with a normal distribution'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1：COVID-19病例分布与正态分布的比较
- en: 'When adjusted by population with the total cases per million column, the distribution
    is closer to normal:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过按人口调整每百万总病例数列后，分布更接近正态分布：
- en: '![](img/B18596_04_02.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_02.png)'
- en: 'Figure 4.2: Distribution of COVID-19 cases per million compared with a normal
    distribution'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2：每百万COVID-19病例的分布与正态分布的比较
- en: Show the outlier range for total cases.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示总病例的异常值范围。
- en: 'One way to define an outlier for a continuous variable is by the distance above
    the third quartile or below the first quartile. If that distance is more than
    1.5 times the *interquartile range* (the distance between the first and third
    quartiles), that value is considered an outlier. The calculation in this step
    indicates that values above 3,197,208 can be considered outliers. In this case,
    we can ignore an outlier threshold that is less than 0, as that is not possible:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 定义连续变量异常值的一种方法是基于第三四分位数以上或第一四分位数以下的距离。如果该距离超过1.5倍的*四分位差*（第一四分位数和第三四分位数之间的距离），则该值被认为是异常值。本步骤中的计算表明，超过3,197,208的值可以被视为异常值。在这种情况下，我们可以忽略小于0的异常值阈值，因为这是不可能的：
- en: '[PRE12]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Generate a DataFrame of outliers and write it to Excel.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成异常值的DataFrame并将其写入Excel。
- en: 'Iterate over the four COVID-19 case columns. Calculate the outlier thresholds
    for each column as we did in the previous step. From the DataFrame, select those
    rows above the high threshold or below the low threshold. Add columns that indicate
    the variable examined (`varname`) for outliers and the threshold levels:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历四个COVID-19病例列。按照前一步的操作计算每列的异常值阈值。从DataFrame中选择那些高于上限阈值或低于下限阈值的行。添加表示所检验变量（`varname`）的异常值和阈值级别的列：
- en: '[PRE14]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This produces the following Excel file (some columns are hidden to save space):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下Excel文件（某些列已隐藏以节省空间）：
- en: '![outliers](img/B18596_04_03.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![outliers](img/B18596_04_03.png)'
- en: Figure 4.3 Excel file with outlier cases
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3：包含异常值案例的Excel文件
- en: There were 39 countries identified as outliers in the `total_deaths` values
    according to the interquartile method, and 33 `total_cases` outliers. Notice that
    there were no outliers for `total _cases_pm`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 根据四分位数法，共识别出39个国家在`total_deaths`值上为异常值，33个`total_cases`异常值。注意，`total_cases_pm`没有异常值。
- en: Look a little more closely at outliers for total deaths per million.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更加仔细地查看每百万总死亡数的异常值。
- en: 'Use the `varname` column we created in the previous step to select the outliers
    for `total_deaths_pm`. Show the columns `(median_age` and `hum_dev_ind`) that
    might help to explain the extreme values for those columns. We also show the 25^(th),
    50^(th), and 75^(th) percentile for those columns for the whole dataset for comparison:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们在上一步骤中创建的`varname`列来选择`total_deaths_pm`的离群值。显示可能有助于解释这些列极端值的列`(median_age`和`hum_dev_ind`)。我们还显示了这些列的25^(th)、50^(th)和75^(th)百分位的全数据集对比值：
- en: '[PRE17]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: All four countries are well beyond the 75^(th) percentile for deaths per million.
    Three of the four countries are near or above the 75^(th) percentile for both
    median age and the human development index. Surprisingly, there is a positive
    correlation between the human development index and deaths per million. We display
    a correlation matrix in the next recipe.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 所有四个国家的死亡人数每百万均远超75^(th)百分位。四个国家中的三个国家在中位年龄和人类发展指数方面接近或超过了75^(th)百分位。出乎意料的是，人类发展指数与每百万死亡人数之间存在正相关关系。我们将在下一个配方中显示相关性矩阵。
- en: 'Show a histogram of total cases:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示总病例数的直方图：
- en: '[PRE21]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This code produces the following plot:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码会生成以下图形：
- en: '![](img/B18596_04_04.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_04.png)'
- en: 'Figure 4.4: Histogram of total COVID-19 cases'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4：COVID-19总病例数的直方图
- en: 'Perform a log transformation of the COVID-19 data. Show a histogram of the
    log transformation of total cases:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对COVID-19数据进行对数转换。显示总病例数的对数转换后的直方图：
- en: '[PRE22]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This code produces the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码会生成以下内容：
- en: '![](img/B18596_04_05.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_05.png)'
- en: 'Figure 4.5: Histogram of total COVID-19 cases with log transformation'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5：COVID-19总病例数的对数转换直方图
- en: The tools we used in the preceding steps tell us a fair bit about how COVID-19
    cases and deaths are distributed, and about where outliers are located.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面的步骤中使用的工具为我们提供了有关COVID-19病例和死亡的分布，以及离群值所在位置的相当多的信息。
- en: How it works…
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The percentile data shown in *step 3* reflect the skewness of the cases and
    deaths data. If, for example, we look at the range of values between the 20^(th)
    and 30^(th) percentiles, and compare it with the range from the 70^(th) to the
    80^(th) percentiles, we see that the range is much greater in the higher percentiles
    for each variable. This is confirmed by the very high values for skewness and
    kurtosis, compared with normal distribution values of `0` and `3`, respectively.
    We run formal tests of normality in *step 4*, which indicate that the distributions
    of the COVID-19 variables are not normal at high levels of significance.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 3*中显示的百分位数据反映了病例和死亡数据的偏斜性。例如，如果我们观察20^(th)到30^(th)百分位之间的数值范围，并将其与70^(th)到80^(th)百分位之间的范围进行比较，会发现较高百分位的每个变量的范围都远大于较低百分位的范围。这一点从偏度和峰度的非常高值中得到了证实，而正态分布的偏度和峰度值分别为`0`和`3`。我们在*步骤
    4*中进行了正态性检验，结果表明，COVID-19变量的分布在高度显著性水平下不符合正态分布。'
- en: This is consistent with the `qqplots` that we ran in *step 5*. The distributions
    of both total cases and total cases per million differ significantly from normal,
    as represented by the straight line. Many cases hover around zero, and there is
    a dramatic increase in slope at the right tail.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们在*步骤 5*中运行的`qqplots`一致。总病例数和每百万总病例数的分布与正态分布有显著差异，如直线所示。许多病例集中在零附近，右尾的斜率急剧增加。
- en: We identify outliers in *steps 6 and 7*. Using 1.5 times the interquartile range
    to determine outliers is a reasonable rule of thumb. I like to output those values
    to an Excel file, along with the associated data, to see what patterns I can detect
    in the data. This often leads to more questions, of course. We will try to answer
    some of them in the next recipe, but one question we can consider now is what
    accounts for the countries with high deaths per million, as displayed in *step
    8*. Median age and the human development index seem like they might be a part
    of the story. It is worth exploring these bivariate relationships further, which
    we do in subsequent recipes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*步骤 6 和 7*中识别了离群值。使用1.5倍四分位差来确定离群值是一个合理的经验法则。我喜欢将这些值和相关数据输出到Excel文件中，以便查看我能在数据中发现什么模式。当然，这通常会引发更多的问题。我们将在下一个配方中尝试解答其中的一些问题，但我们现在可以考虑的一个问题是，是什么原因导致每百万死亡人数较高的国家，如*步骤
    8*所示。中位年龄和人类发展指数似乎可能是其中的一部分原因。值得进一步探索这些双变量关系，我们将在后续的配方中进行探索。
- en: Our identification of outliers in *step 7* assumes a normal distribution, an
    assumption that we have shown to be unwarranted. Looking at the distribution of
    total cases in *step 9*, it seems much more like a log-normal distribution, with
    values clustered around `0` and a right skew. We transform the data in *step 10*
    and plot the results of the transformation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*步骤7*中识别异常值的前提是假设正态分布，但这个假设我们已经证明是不成立的。查看*步骤9*中的总病例分布，它看起来更像是对数正态分布，值集中在`0`附近，并呈右偏。我们在*步骤10*中对数据进行了转换，并绘制了转换结果。
- en: There’s more…
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: We could have also used standard deviation, rather than interquartile ranges,
    to identify outliers in *steps 6 and 7*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用标准差，而不是四分位差，来识别*步骤6和7*中的异常值。
- en: I should add here that outliers are not necessarily data collection or measurement
    errors, and we may or may not need to make adjustments to the data. However, extreme
    values can have a meaningful and persistent impact on our analysis, particularly
    with small datasets like this one.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我应该在这里补充一点，异常值不一定是数据收集或测量错误，我们可能需要，也可能不需要对数据进行调整。然而，极端值可能会对我们的分析产生有意义且持久的影响，特别是在像这样的较小数据集上。
- en: The overall impression we should have of the COVID-19 case data is that it is
    relatively clean; that is, there are not many invalid values, narrowly defined.
    Looking at each variable independently of how it moves with other variables does
    not identify much that screams out as a clear data error. However, the distribution
    of the variables is statistically quite problematic. Building statistical models
    dependent on these variables will be complicated, as we might have to rule out
    parametric tests.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对COVID-19病例数据的总体印象是相对干净的；也就是说，严格定义下并没有太多无效值。独立地查看每个变量，而不考虑它与其他变量的关系，无法识别出明显的清晰数据错误。然而，变量的分布在统计学上是相当有问题的。基于这些变量构建统计模型将变得复杂，因为我们可能需要排除参数检验。
- en: It is also worth remembering that our sense of what constitutes an outlier is
    shaped by our assumption of a normal distribution. If, instead, we allow our expectations
    to be guided by the actual distribution of the data, we have a different understanding
    of extreme values. If our data reflects a social, or biological, or physical process
    that is inherently not normally distributed (uniform, logarithmic, exponential,
    Weibull, Poisson, and so on), our sense of what constitutes an outlier should
    adjust accordingly.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得记住的是，我们对什么构成异常值的理解是由我们对正态分布的假设所塑造的。相反，如果我们让期望值由数据的实际分布来引导，我们对极端值的理解会有所不同。如果我们的数据反映的是一个社会、或生物学、或物理过程，这些过程本身就不是正态分布（如均匀分布、对数分布、指数分布、威布尔分布、泊松分布等），那么我们对异常值的定义应该相应调整。
- en: See also
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: Boxplots might have also been illuminating here. We do a box plot on this data
    in *Chapter 5*, *Using Visualizations for the Identification of Unexpected Values*.
    We examine variable transformations in more detail in *Chapter 8*, *Encoding,
    Transforming, and Scaling Features*.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图在这里也可能会有启发作用。我们在*第5章*中对这些数据做了箱线图，*使用可视化识别意外值*。我们在*第8章*中更详细地探讨了变量转换，*编码、转换与特征缩放*。
- en: We explore bivariate relationships in this same dataset in the next recipe for
    any insights they might provide about outliers and unexpected values. In subsequent
    chapters, we consider strategies for imputing values for missing data and for
    making adjustments to extreme values.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一个配方中探讨这个数据集中双变量关系，以便从中获得任何关于异常值和意外值的见解。在后续章节中，我们将考虑补充缺失数据和对极端值进行调整的策略。
- en: Identifying outliers and unexpected values in bivariate relationships
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别双变量关系中的异常值和意外值
- en: A value might be unexpected, even if it is not an extreme value, when it does
    not deviate significantly from the distribution mean. Some values for a variable
    are unexpected when a second variable has certain values. This is easy to illustrate
    when one variable is categorical and the other is continuous.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一个值即使不是极端值，如果它没有显著偏离分布均值，也可能是意外的。当第二个变量有某些特定值时，第一个变量的一些值会变得意外。这在一个变量是分类变量而另一个是连续变量时，尤其容易说明。
- en: The following diagram illustrates the number of bird sightings per day over
    a period of several years, but shows different distributions for each of the two
    sites. One site has a mean sightings per day of 33, and the other 52\. (This is
    fictional data.) The overall mean (not shown) is 42\. What should we make of a
    value of 58 for daily sightings? Is that an outlier? That clearly depends on which
    of the two sites was being observed.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了几年期间每天的鸟类观察数量，但对两个地点的分布做了不同的展示。一个地点的平均每天观察数为33，另一个为52（这是虚拟数据）。总体平均值（未显示）为42。那么，58次每日观察应该如何解读？它是异常值吗？这显然取决于观察的是哪一个地点。
- en: 'If there were 58 sightings on a day at site A, 58 would be an unusually high
    number. Not so for site B, where 58 sightings would not be very different from
    the mean for that site:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在地点A有58次观察，58将是一个异常高的数值。而对于地点B来说，58次观察与该地点的平均值并没有太大不同：
- en: '![](img/B18596_04_06.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_06.png)'
- en: 'Figure 4.6: Daily bird sightings by site'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6：按地点分类的每日鸟类观察数
- en: 'This hints at a useful rule of thumb: whenever a variable of interest is significantly
    correlated with another variable, we should take that relationship into account
    when trying to identify outliers (or any statistical analysis with that variable
    actually). It is helpful to state this a little more precisely, and extend it
    to cases where both variables are continuous. If we assume a linear relationship
    between variable *x* and variable *y*, we can describe that relationship with
    the familiar *y* = *mx* + *b* equation, where *m* is the slope and *b* is the
    *y*-intercept. We can then expect *y* to increase by *m* for every 1 unit increase
    in *x*. Unexpected values are those that deviate substantially from this relationship,
    where the value of *y* is much higher or lower than what would be predicted given
    the value of *x*. This can be extended to multiple *x*, or predictor, variables.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这提示了一个有用的经验法则：每当某个感兴趣的变量与另一个变量显著相关时，在尝试识别异常值时（或者在进行任何涉及该变量的统计分析时），我们应当考虑到这种关系。将这一点表述得更准确一点，并扩展到两个变量都是连续的情况。如果我们假设变量
    *x* 和变量 *y* 之间存在线性关系，那么我们可以用熟悉的 *y* = *mx* + *b* 方程来描述这种关系，其中 *m* 是斜率，*b* 是 *y*
    截距。然后我们可以预期，*y* 会随着 *x* 增加 1 单位而增加 *m*。异常值是那些偏离这一关系较大的值，其中 *y* 的值远高于或低于根据 *x*
    的值所预测的值。这可以扩展到多个 *x* 或预测变量。
- en: In this recipe, we demonstrate how to identify outliers and unexpected values
    by examining the relationship of a variable to one other variable. In subsequent
    recipes in this chapter, we use multivariate techniques to make additional improvements
    in our outlier detection.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们演示了如何通过检查一个变量与另一个变量的关系来识别异常值和意外值。在本章接下来的例子中，我们使用多元方法来进一步改进我们的异常值检测。
- en: Getting ready
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We use the `matplotlib` and `seaborn` libraries in this recipe. You can install
    them with `pip` by entering `pip install matplotlib` and `pip install seaborn`
    with a terminal client or PowerShell (in Windows).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们使用了`matplotlib`和`seaborn`库。你可以通过终端客户端或PowerShell（在Windows中）输入`pip install
    matplotlib`和`pip install seaborn`来安装它们。
- en: How to do it...
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作方法...
- en: 'We examine the relationship between total cases and total deaths in the COVID-19
    database. We take a closer look at those countries where deaths are higher or
    lower than expected given the number of cases:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查了COVID-19数据库中总病例数和总死亡数之间的关系。我们仔细查看了那些死亡人数高于或低于根据病例数预期值的国家：
- en: 'Load `pandas`, `matplotlib`, `seaborn`, and the COVID-19 cumulative data:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载`pandas`、`matplotlib`、`seaborn`以及COVID-19累积数据：
- en: '[PRE23]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Generate a correlation matrix for the cumulative and demographic columns.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成累积数据和人口统计学列的相关性矩阵。
- en: 'Unsurprisingly, there is a high correlation (`0.76`) between total cases and
    total deaths and less of a correlation (`0.44`) between total cases per million
    and total deaths per million. There is a strong (`0.66`) relationship between
    GDP per capita and cases per million (Note that not all of the correlations are
    shown):'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，总病例数和总死亡数之间的相关性较高（`0.76`），而每百万总病例数与每百万总死亡数之间的相关性较低（`0.44`）。人均GDP与每百万病例数之间有强相关性（`0.66`）（注意，并未显示所有相关性）：
- en: '[PRE24]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Check to see whether some countries have unexpectedly high or low total deaths,
    given the total cases.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查一些国家是否存在与总病例数相比，总死亡人数异常高或低的情况。
- en: 'Use `qcut` to create a column that breaks the data into quantiles. Show a crosstab
    of total cases quantiles by total deaths quantiles:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`qcut`创建一个列，将数据分成分位数。显示按总死亡数分位数排列的总病例数分位数交叉表：
- en: '[PRE26]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Take a look at countries that do not fit along the diagonal.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 看看那些不符合对角线关系的国家。
- en: 'There is one country with high total cases but low total deaths. Since the
    `covidtotals` and `covidtotalsonly` DataFrames have the same index, we can use
    the Boolean series created from the latter to return selected rows from the former:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个国家病例总数很高，但死亡总数很低。由于`covidtotals`和`covidtotalsonly`数据框有相同的索引，我们可以使用从后者创建的布尔序列来返回前者的选定行：
- en: '[PRE28]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Make a scatterplot of total cases by total deaths.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制总病例数与总死亡数的散点图。
- en: 'Use Seaborn’s `regplot` method to generate a linear regression line in addition
    to the scatterplot:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Seaborn的`regplot`方法，除了散点图之外，还生成线性回归线：
- en: '[PRE30]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This produces the following scatterplot:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下散点图：
- en: '![](img/B18596_04_07.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_07.png)'
- en: 'Figure 4.7: Scatterplot of total cases and deaths with a linear regression
    line'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7：带有线性回归线的总病例数与死亡数散点图
- en: Examine unexpected values above the regression line.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查回归线之上的意外值。
- en: 'It is good to take a closer look at countries with cases and deaths coordinates
    that are noticeably above or below the regression line through the data. There
    are two countries with fewer than 40 million cases and more than 400 thousand
    deaths:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察数据中明显位于回归线之上或之下的国家，看看这些国家的病例数和死亡数坐标。有两个国家的病例数少于4000万，但死亡人数超过40万：
- en: '[PRE31]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Examine unexpected values below the regression line.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查回归线下方的意外值。
- en: 'There are two countries with more than 30 million cases but fewer than 100
    thousand deaths:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个国家的病例数超过3000万，但死亡数少于10万：
- en: '[PRE33]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Make a scatterplot of total cases per million by total deaths per million:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制每百万人总病例数与每百万人总死亡数的散点图：
- en: '[PRE35]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This produces the following scatterplot:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下散点图：
- en: '![](img/B18596_04_08.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_08.png)'
- en: 'Figure 4.8: Scatterplot of cases and deaths per million with a linear regression
    line'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8：每百万人病例数与死亡数散点图，带有线性回归线
- en: The preceding steps examined the relationship between variables in order to
    identify outliers.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的步骤考察了变量之间的关系，以识别异常值。
- en: How it works…
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其工作原理…
- en: A number of questions are raised by looking at the bivariate relationships that
    did not surface in our univariate exploration in the previous recipe. There is
    confirmation of anticipated relationships, such as with the total cases and total
    deaths, but this makes deviations from this all the more curious. There are possible
    substantive explanations for unusually high death rates, given a certain number
    of cases, but measurement error or poor reporting of cases cannot be ruled out
    either.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察双变量关系，我们提出了一些在前一个步骤中未显现出来的问题。我们确认了预期中的关系，比如总病例数与总死亡数的关系，但这也让偏离这种关系的情况更加引人注目。根据一定数量的病例数，有可能有实质性的解释来说明异常高的死亡率，但测量误差或病例报告不准确也不能排除。
- en: '*Step 2* shows a high correlation (0.76) between total cases and total deaths,
    but there is variation even there. We divide the cases and deaths into quantiles
    in *step 3* and then do a crosstab of the quantile values. Most countries are
    along the diagonal or close to it. However, one country has a very high number
    of cases but low deaths, Qatar. It is reasonable to wonder if there are potential
    reporting issues.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤2*显示了总病例数和总死亡数之间的高度相关性（0.76），但即便如此，仍然存在一些差异。我们在*步骤3*中将病例数和死亡数划分为分位数，然后做一个分位数值的交叉表。大多数国家位于对角线上或接近对角线。然而，有一个国家的病例数非常高，但死亡数较低，即卡塔尔。合理的怀疑是是否存在潜在的报告问题。'
- en: We make a scatterplot in *step 5* of the total cases and deaths. The strong
    upward sloping relationship between the two is confirmed, but there are a couple
    of countries whose deaths are above the regression line. We can see that two countries
    (Brazil and Russia) have higher deaths than would be predicted by the number of
    cases. Two countries, Japan and South Korea, have a much lower number of deaths.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*步骤5*中绘制了总病例数与总死亡数的散点图。两者之间强烈的向上倾斜关系得到了确认，但有一些国家的死亡数位于回归线之上。我们可以看到，巴西和俄罗斯的死亡数比根据病例数预测的要高，而日本和韩国的死亡数则远低于预测值。
- en: Not surprisingly, there is even more scatter around the regression line in the
    scatterplot of cases per million and deaths per million. There is a positive relationship,
    but the slope of the line is not very steep.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，在每百万案例和每百万死亡人数的散点图中，回归线周围的散点更为分散。虽然存在正相关关系，但回归线的斜率并不陡峭。
- en: There’s more…
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We are beginning to get a good sense of what our data looks like, but the data
    in this form does not enable us to examine how the univariate distributions and
    bivariate relationships might change over time. For example, one reason why countries
    might have more deaths per million than the number of cases per million would
    indicate could be that more time has passed since the first confirmed cases. We
    are not able to explore that in the cumulative data. We need the daily data for
    that, which we will look at in subsequent chapters.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经开始对数据的样貌有了较好的了解，但以这种形式的数据并不能让我们检查单变量分布和双变量关系如何随时间变化。例如，一个国家每百万死亡人数超过每百万案例人数的原因，可能是因为自首次确诊病例以来已经过去了更多的时间。我们无法在累积数据中探索这一点。为此，我们需要每日数据，在接下来的章节中我们将探讨这个问题。
- en: This recipe, and the previous one, show how much data cleaning can bleed into
    exploratory data analysis, even when you are first starting to get a sense of
    your data. I would definitely draw a distinction between data exploration and
    what we are doing here. We are trying to get a sense of how the data hangs together
    and why certain variables take on certain values in certain situations and not
    others. We want to get to the point where there are no huge surprises when we
    begin to do the analysis.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱，以及之前的那个，展示了数据清理如何渗透到探索性数据分析中，即使在你刚开始对数据有所了解时。我一定会在数据探索和我们现在所做的工作之间做出区分。我们正在尝试了解数据是如何相互关联的，以及为什么在某些情况下，某些变量会取某些值而在其他情况下不取。我们希望做到当我们开始进行分析时，数据中不会有大的惊讶。
- en: I find it helpful to do small things to formalize this process. I use different
    naming conventions for files that are not quite ready for analysis. If nothing
    else, this helps remind me that any numbers produced at this point are far from
    ready for distribution.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现做一些小的调整来规范这个过程很有帮助。我对那些尚未准备好进行分析的文件使用不同的命名规范。即使没有别的，这也帮助我提醒自己，在这个阶段生成的任何数据都远未准备好分发。
- en: See also
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: We still have not done much to examine possible data issues that only become
    apparent when examining subsets of data; for example, positive wage income values
    for people who say they are not working (both variables are on the **National
    Longitudinal Survey** or **NLS**). We do that in the next recipe.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然没有做太多工作来检查可能的数据问题，这些问题只有在检查数据子集时才会显现出来；例如，声称自己不工作的人的正工资收入值（这两个变量都来自**国家纵向调查**或**NLS**）。我们将在下一个食谱中解决这个问题。
- en: We do much more with Matplotlib and Seaborn in *Chapter 5*, *Using Visualizations
    for the Identification of Unexpected Values*.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第5章*中，我们将使用Matplotlib和Seaborn做更多工作，主题是*利用可视化识别异常值*。
- en: Using subsetting to examine logical inconsistencies in variable relationships
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用子集工具检查变量关系中的逻辑不一致性
- en: At a certain point, data issues come down to deductive logic problems, such
    as variable *x* has to be greater than some quantity *a* when variable *y* is
    less than some quantity *b*. Once we are through some initial data cleaning, it
    is important to check for logical inconsistencies. `pandas` makes this kind of
    error checking relatively straightforward with subsetting tools such as `loc`
    and Boolean indexing. This can be combined with summary methods on Series and
    DataFrames to allow us to easily compare values for a particular row with values
    for the whole dataset or some subset of rows. We can also easily aggregate over
    columns. Just about any question we might have about the logical relationships
    between variables can be answered with these tools. We work through some examples
    in this recipe.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些时候，数据问题归结为推理逻辑问题，比如当变量 *y* 小于某个量 *b* 时，变量 *x* 必须大于某个量 *a*。一旦完成一些初步的数据清理，检查逻辑不一致性就变得很重要。`pandas`通过子集工具如`loc`和布尔索引，使这种错误检查相对简单。我们可以将这些工具与Series和DataFrame的汇总方法结合使用，从而轻松地将特定行的值与整个数据集或某些行的子集进行比较。我们还可以轻松地对列进行聚合。关于变量之间的逻辑关系的任何问题，都可以通过这些工具得到解答。我们将在这个食谱中演示一些示例。
- en: Getting ready
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will work with the NLS data, mainly with data on employment and education.
    We use `apply` and `lambda` functions several times in this recipe, but go into
    more detail on their use in *Chapter 9*, *Fixing Messy Data When Aggregating*.
    However, it is not necessary to review *Chapter 9* to follow along, even if you
    have no experience with those tools.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 NLS 数据，主要涉及就业和教育方面的数据。在本例中，我们多次使用 `apply` 和 `lambda` 函数，但我们会在*第 9 章*，*在聚合时修复混乱数据*中详细介绍它们的使用。然而，即使你没有这些工具的经验，也不需要回顾*第
    9 章*，就能跟随操作。
- en: '**Data note**'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据说明**'
- en: The National Longitudinal Survey of Youth is conducted by the United States
    Bureau of Labor Statistics. This survey started with a cohort of individuals in
    1997 who were born between 1980 and 1985, with annual follow-ups each year up
    until 2023\. For this recipe, I pulled 106 variables on grades, employment, income,
    and attitudes toward government from the hundreds of data items on the survey.
    NLS data can be downloaded from [nlsinfo.org](https://nlsinfo.org).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 美国劳工统计局进行的国家青少年纵向调查（NLS）始于1997年，调查对象为1980至1985年间出生的一组人群，每年进行一次跟踪，直到2023年。本次例子中，我从调查中的数百个数据项中提取了106个变量，涵盖了成绩、就业、收入和对政府态度等信息。NLS
    数据可以从[nlsinfo.org](https://nlsinfo.org)下载。
- en: How to do it…
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作方法：
- en: 'We run a number of logical checks on the NLS data, such as individuals with
    post-graduate enrollment but no undergraduate enrollment, or those with wage income
    but no weeks worked. We also check for large changes in key values for a given
    individual from one period to the next:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对 NLS 数据进行了多次逻辑检查，比如有研究生入学记录但没有本科入学记录的个体，或者有工资收入但没有工作周数的个体。我们还检查给定个体在不同时期之间关键值的巨大变化：
- en: 'Import `pandas` and then load the NLS data:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas`，然后加载 NLS 数据：
- en: '[PRE36]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Look at some of the employment and education data.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看一些就业和教育数据。
- en: 'The dataset has weeks worked each year from 2000 through 2023, and college
    enrollment status each month from February 1997 through October 2022\. We use
    the ability of the `loc` accessor to choose all columns from the column indicated
    on the left of the colon through to the column indicated on the right; for example,
    `nls97.loc[:, "colenroct15":"colenrfeb22"]`:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中包含2000年至2023年每年的工作周数，以及1997年2月到2022年10月每月的大学入学状态。我们利用 `loc` 访问器来选择从冒号左侧指定的列到右侧指定的列的所有数据。例如，`nls97.loc[:,
    "colenroct15":"colenrfeb22"]`：
- en: '[PRE37]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Show individuals with wage income but no weeks worked:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 显示有工资收入但没有工作周数的个体：
- en: '[PRE43]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Check whether an individual was ever enrolled in a four-year college.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查个体是否曾经在四年制大学就读过。
- en: 'Chain several methods. First, create a DataFrame with columns that start with
    `colenr` (`nls97.filter(like="colenr")`). These are the college enrollment columns
    for October and February of each year. Then, use `apply` to run a `lambda` function
    that examines the first character of each `colenr` column (`apply(lambda x: x.str[0:1]==''3'')`).
    This returns a value of `True` or `False` for all of the college enrollment columns;
    `True` if the first value of the string is `3`, meaning enrollment at a four year
    college. Finally, use the `any` function to test whether any of the values returned
    from the previous step has a value of `True` (`any(axis=1)`). This will identify
    whether the individual was enrolled in a four-year college between February 1997
    and October 2022\. The first statement here shows the results of the first two
    steps for explanatory purposes only. Only the second statement needs to be run
    to get the desired results, which are to see whether the individual was enrolled
    at a four-year college at some point:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '链接多个方法。首先，创建一个包含以 `colenr` 开头的列的 DataFrame（`nls97.filter(like="colenr")`）。这些是每年10月和2月的大学入学列。然后，使用
    `apply` 运行一个 `lambda` 函数，检查每个 `colenr` 列的第一个字符（`apply(lambda x: x.str[0:1]==''3'')`）。这将为所有大学入学列返回一个
    `True` 或 `False` 值；如果字符串的第一个值为 `3`，表示四年制大学入学，则返回 `True`。最后，使用 `any` 函数测试从前一步返回的任何值是否为
    `True`（`any(axis=1)`）。这将识别个体是否在1997年2月到2022年10月期间曾就读四年制大学。这里的第一个语句仅用于说明前两步的结果。要获得所需的结果，只需运行第二个语句，查看个体是否曾在某个时刻入读四年制大学：'
- en: '[PRE45]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Show individuals with post-graduate enrollment but no bachelor’s enrollment.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示有研究生入学记录但没有本科入学记录的个体。
- en: 'We can use what we tested in *step 4* to do some checking. We want individuals
    who have a `4` (graduate enrollment) as the first character for `colenr` of any
    month, but who never had a value of `3` (bachelor enrollment). Note the ~ before
    the second half of the test, for negation. There are 24 individuals who fall into
    this category:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用在*步骤4*中测试的内容进行一些检查。我们希望找到那些在任何一个月的`colenr`字段的首字符为`4`（研究生入学），但从未出现过`3`（本科入学）值的个体。注意测试的第二部分前面的~符号，用于取反。共有24个个体符合这个条件：
- en: '[PRE49]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Show individuals with bachelor’s degrees or more, but no four-year college enrollment.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示拥有学士学位或更高学位，但没有四年制大学入学的个体。
- en: 'Use `isin` to compare the first character in `highestdegree` with all of the
    values in a list (`nls97.highestdegree.str[0:1].isin([''4'',''5'',''6'',''7''])`):'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`isin`来将`highestdegree`字段的首字符与列表中的所有值进行比较（`nls97.highestdegree.str[0:1].isin(['4','5','6','7'])`）：
- en: '[PRE53]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Show individuals with a high wage income.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示高工资收入的个体。
- en: 'Define high wages as three standard deviations above the mean. It looks as
    though wage income values have been truncated at $380,288:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 将高工资定义为高于平均值三个标准差的收入。看起来工资收入的值已经在380,288美元处被截断：
- en: '[PRE59]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Show individuals with large changes in weeks worked for the most recent year.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示在最近一年中，工作周数变化较大的个体。
- en: 'Calculate the average value for weeks worked between 2016 and 2020 for each
    person (`nls97.loc[:, "weeksworked16":"weeksworked20"].mean(axis=1)`). We indicate
    `axis=1` to calculate the mean across columns for each individual, rather than
    over individuals. We then find rows where the mean is *not* between half and twice
    the number of weeks worked in 2021\. (Notice our use of the *~* operator earlier.)
    We also indicate that we are not interested in rows that satisfy those criteria
    by being `null` for weeks worked in 2021\. There are 1,099 individuals with sharp
    changes in weeks worked in 2021, compared with the 2016 to 2020 average:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 计算每个人2016到2020年间的平均工作周数（`nls97.loc[:, "weeksworked16":"weeksworked20"].mean(axis=1)`）。我们通过`axis=1`来表示按列计算每个个体的平均值，而不是按个体计算。然后，我们找到那些平均值*不*在2021年工作周数的一半到两倍之间的行。（注意我们早些时候使用的*~*操作符）。我们还表示，对于那些2021年工作周数为`null`的行，我们不感兴趣。共有1,099个个体在2021年与2016至2020年平均值相比，工作周数发生了大幅变化：
- en: '[PRE61]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Show inconsistencies in the highest grade completed and the highest degree.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示最高学历和最高学位的不一致之处。
- en: 'Use the `crosstab` function to show `highestgradecompleted` by `highestdegree`
    for people with `highestgradecompleted` less than 12\. A good number of these
    individuals indicate that they have completed high school, which is unusual in
    the United States if the highest grade completed is less than 12:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`crosstab`函数，显示`highestgradecompleted`根据`highestdegree`的分类情况，筛选`highestgradecompleted`小于12的个体。这些个体中有相当一部分表明他们已经完成了高中学业，这在美国是比较不寻常的，除非完成的最高年级低于12年级：
- en: '[PRE65]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: These steps reveal several logical inconsistencies in the NLS data.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤揭示了NLS数据中的若干逻辑不一致。
- en: How it works…
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The syntax required to do the kind of subsetting that we have done in this recipe
    may seem a little complicated if you are seeing it for the first time. You do
    get used to it, however, and it allows you to quickly run any query against the
    data that you might imagine.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是第一次看到这个语法，可能会觉得做这类子集筛选的语法有点复杂。但你会逐渐习惯它，而且它允许你快速对数据运行任何你能想到的查询。
- en: Some of the inconsistencies or unexpected values suggest either respondent or
    entry error and warrants further investigation. It is hard to explain positive
    values for wage income when the `weeks worked` value is `0`. Other unexpected
    values might not be data problems at all, but suggest that we should be careful
    about how we use that data. For example, we might not want to use the weeks worked
    in 2021 by itself. Instead, we might consider using three-year averages in many
    analyses.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 一些不一致或意外的值表明可能存在受访者或录入错误，值得进一步调查。当`weeks worked`的值为`0`时，很难解释正的工资收入值。其他意外的值可能根本不是数据问题，而是表明我们应该小心如何使用这些数据。例如，我们可能不想单独使用2021年的工作周数。相反，我们可能考虑在许多分析中使用三年平均值。
- en: See also
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Selecting and organizing columns* and *Selecting rows* recipes in *Chapter
    3*, *Taking the Measure of Your Data*, demonstrate some of the techniques for
    subsetting data used here. We examine the `apply` functions in more detail in
    *Chapter 9*, *Fixing Messy Data When Aggregating*.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '*第3章*，*评估你的数据*中的*选择和组织列*与*选择行*食谱展示了这里使用的一些数据子集技术。我们将在*第9章*，*修复聚合数据时的脏数据*中更详细地讲解`apply`函数。'
- en: Using linear regression to identify data points with significant influence
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线性回归来识别具有显著影响的数据点
- en: The remaining recipes in this chapter use statistical modeling to identify outliers.
    The advantage of these techniques is that they are less dependent on the distribution
    of the variable of concern, and take more into account than can be revealed in
    either univariate or bivariate analyses. This allows us to identify outliers that
    are not otherwise apparent. On the other hand, by taking more factors into account,
    multivariate techniques may provide evidence that a previously suspect value is
    actually within an expected range, and provides meaningful information.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 本章剩余的教程使用统计建模来识别离群值。这些技术的优点在于它们不太依赖于关注变量的分布，并且比单变量或双变量分析考虑得更多。这使得我们能够识别那些原本不显眼的离群值。另一方面，通过考虑更多因素，多变量技术可能会提供证据，表明一个先前可疑的值实际上在预期范围内，并提供有意义的信息。
- en: In this recipe, we use linear regression to identify observations (rows) that
    have an out-sized influence on models of a target or dependent variable. This
    can indicate that one or more values for a few observations are so extreme that
    they compromise the model fit for all of the other observations.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们使用线性回归来识别对目标或因变量模型有过大影响的观察值（行）。这可能表明某些观察值的一个或多个值极端，以至于影响了其他所有观察值的模型拟合。
- en: Getting ready
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备开始
- en: The code in this recipe requires the `matplotlib` and `statsmodels` libraries.
    You can install them by entering `pip install matplotlib` and `pip install statsmodels`
    in a terminal window or PowerShell (in Windows).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程中的代码需要 `matplotlib` 和 `statsmodels` 库。你可以通过在终端窗口或 PowerShell（在 Windows 上）输入
    `pip install matplotlib` 和 `pip install statsmodels` 来安装它们。
- en: We will be working with data on total COVID-19 cases and deaths per country.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将处理有关每个国家 COVID-19 总病例和死亡数据。
- en: How to do it…
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'We will use the statsmodels `OLS` method to fit a linear regression model of
    the total cases per million of the population. We will then identify those countries
    that have the greatest influence on that model:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 statsmodels 的 `OLS` 方法来拟合每百万人总病例数的线性回归模型。然后，我们将识别出对该模型有最大影响的国家：
- en: 'Import `pandas`, `matplotlib`, and `statsmodels`, and load the COVID-19 case
    data:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas`、`matplotlib` 和 `statsmodels`，并加载 COVID-19 疫情数据：
- en: '[PRE67]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Create an analysis file and generate descriptive statistics.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建分析文件并生成描述性统计数据。
- en: 'Get just the columns required for analysis. Drop any row with missing data
    for the analysis columns:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 仅获取分析所需的列。删除分析列中有缺失数据的行：
- en: '[PRE68]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Fit a linear regression model.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合线性回归模型。
- en: 'There are good conceptual reasons to believe that population density, median
    age, and GDP per capita may be predictors of total cases per million. We use those
    three variables in our model:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 有充分的概念性理由相信，人口密度、中位年龄和人均 GDP 可能是每百万人总病例数的预测因子。我们在模型中使用这三个变量：
- en: '[PRE70]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Identify those countries with an out-sized influence on the model.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定对模型有过大影响的国家。
- en: 'Cook’s Distance values of greater than 0.5 should be scrutinized closely:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Cook 距离值大于 0.5 的数据应仔细审查：
- en: '[PRE72]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Create an influence plot.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建影响图。
- en: 'Countries with higher Cook’s Distance values have larger circles:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 具有更高 Cook 距离值的国家显示出更大的圆圈：
- en: '[PRE76]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'This produces the following plot:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下图表：
- en: '![](img/B18596_04_09.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_09.png)'
- en: 'Figure 4.9: Influence plot, including countries with the highest Cook’s Distance'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9：影响图，包括具有最高 Cook 距离的国家
- en: Run the model without the two outliers.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在不包括两个离群值的情况下运行模型。
- en: 'Removing these outliers impacts each coefficient of the model, but particularly
    population density (which is still not significant at the 95% confidence level):'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 删除这些离群值会影响模型的每个系数，特别是人口密度（即使在 95% 的置信水平下仍然不显著）：
- en: '[PRE77]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: This gives us a sense of the countries that are most unlike the others in terms
    of the relationship between demographic variables and total cases per million
    in population.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我们大致了解了哪些国家在与人口统计变量和每百万人总病例数的关系上与其他国家最为不同。
- en: How it works...
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Cook’s Distance is a measure of how much each observation influences the model.
    The large impact of the two outliers is confirmed in *step 6* when we rerun the
    model without them. The question for the analyst is whether outliers such as these
    add important information or distort the model and limit its applicability. The
    coefficient of 11570 for median age in the first regression results indicates
    that every one-year increase in median age is associated with an 11570 increase
    in cases per million people. That number is substantially smaller in the model
    without outliers, 9969.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: Cook’s 距离是衡量每个观察值对模型影响程度的指标。两个异常值对模型的巨大影响在 *步骤 6* 中得到了验证，当我们在不包含这些异常值的情况下重新运行模型时。分析师需要问的问题是，像这些异常值是否提供了重要的信息，还是扭曲了模型并限制了其适用性。第一次回归结果中，`median_age`
    的系数为 11570，表示中位数年龄每增加一年，病例数每百万人增加 11570。这一数字在去除异常值后的模型中大幅缩小，降至 9969。
- en: The `P>|t|` value in the regression output tells us whether the coefficient
    is significantly different from `0`. In the first regression, the coefficients
    for `median_age` and `gdp_per_capita` are significant at the 99% level; that is,
    the `P>|t|` value is less than 0.01.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 回归输出中的 `P>|t|` 值告诉我们系数是否显著不同于 `0`。在第一次回归中，`median_age` 和 `gdp_per_capita` 的系数在
    99% 的显著性水平上显著；也就是说，`P>|t|` 值小于 0.01。
- en: There’s more…
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: We ran a linear regression model in this recipe, not so much because we were
    interested in the parameter estimates of the model, but because we wanted to determine
    whether there were observations with potential out-sized influence on any multivariate
    analysis we might conduct. That definitely seems to be true in this case.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们运行了一个线性回归模型，并非主要是因为我们对模型的参数估计感兴趣，而是因为我们想要确定是否有任何观察值对我们可能进行的多元分析产生了潜在的过大影响。显然，这在此情况下确实是成立的。
- en: Often, it makes sense to remove the outliers, as we have done here, but that
    is not always true. When we have independent variables that do a good job of capturing
    what makes outliers different, then the parameter estimates for the other independent
    variables are less vulnerable to distortion. We also might consider transformations,
    such as the log transformation we did in a previous recipe, and the scaling we
    will do in the next two recipes. An appropriate transformation, given your data,
    can reduce the influence of outliers by limiting the size of residuals at the
    extremes.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，删除异常值是有道理的，正如我们在这里所做的那样，但这并不总是如此。当我们有能够很好地捕捉异常值不同之处的自变量时，其他自变量的参数估计会更不容易受到扭曲。我们也可以考虑转换，例如我们在前一个食谱中进行的对数转换，以及我们在接下来的两个食谱中将要进行的标准化。根据你的数据，适当的转换可以通过限制极端值的残差大小来减少异常值的影响。
- en: Using k-nearest neighbors to find outliers
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 k-最近邻找出异常值
- en: Unsupervised machine learning tools can help us identify observations that are
    unlike others when we have unlabeled data; that is, when there is no target or
    dependent variable. (In the previous recipe, we used total cases per million as
    the dependent variable.) Even when selecting targets and factors is relatively
    straightforward, it might be helpful to identify outliers without making any assumptions
    about relationships between variables. We can use **k****-nearest neighbors**
    (**KNN**) to find observations that are most unlike others, those where there
    is the greatest difference between their values and their nearest neighbors’ values.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督机器学习工具可以帮助我们识别与其他观察结果不同的观察值，特别是在我们没有标签数据的情况下；也就是说，当没有目标变量或因变量时。（在前一个食谱中，我们使用了每百万人总病例数作为因变量。）即使选择目标和因素相对简单，识别异常值而不对变量之间的关系做任何假设也可能会很有帮助。我们可以使用
    **k**-最近邻（**KNN**）来找出与其他观察值最不同的观测值，即那些它们的值与最近邻值之间差异最大的值。
- en: Getting ready
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You will need **Python Outlier Detection** (**PyOD**) and scikit-learn to run
    the code in this recipe. You can install both by entering `pip install pyod` and
    `pip install sklearn` in the terminal or PowerShell (in Windows).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要 **Python异常值检测** (**PyOD**) 和 scikit-learn 来运行这个食谱中的代码。你可以通过在终端或 PowerShell（在
    Windows 系统中）输入 `pip install pyod` 和 `pip install sklearn` 来安装这两个工具。
- en: How to do it…
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤…
- en: 'We will use KNN to identify countries whose attributes indicate that they are
    most anomalous:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 KNN 来识别属性最异常的国家：
- en: 'Load `pandas`, `pyod`, and `sklearn`, along with the COVID-19 case data:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 `pandas`、`pyod` 和 `sklearn`，以及 COVID-19 病例数据：
- en: '[PRE79]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Create a standardized DataFrame for the analysis columns:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为分析列创建一个标准化的 DataFrame：
- en: '[PRE80]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Run the KNN model and generate anomaly scores.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 KNN 模型并生成异常得分。
- en: 'We create an arbitrary number of outliers by setting the contamination parameter
    to 0.1:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将污染参数设置为0.1来创建一个任意数量的异常值：
- en: '[PRE81]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Show the predictions from the model.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示模型的预测结果。
- en: 'Create a DataFrame from the `y_pred` and `y_scores` NumPy arrays. Set the index
    to the `covidanalysis` DataFrame index so that we can easily combine it with that
    DataFrame later. Notice that the decision scores for outliers are all higher than
    those for the inliers (outlier = 0):'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 从`y_pred`和`y_scores`的NumPy数组中创建一个数据框。将索引设置为`covidanalysis`数据框的索引，以便稍后能够轻松地将其与该数据框合并。注意，异常值的决策得分都高于内点（异常值=0）的得分：
- en: '[PRE84]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Show COVID-19 data for the outliers.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示异常值的COVID-19数据。
- en: 'First, merge the `covidanalysis` and `pred` DataFrames:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，合并`covidanalysis`和`pred`数据框：
- en: '[PRE90]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: These steps show how we can use KNN to identify outliers based on multivariate
    relationships.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤展示了我们如何利用KNN基于多变量关系来识别异常值。
- en: How it works...
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: PyOD is a package of Python outlier detection tools. We use it here as a wrapper
    around scikit-learn’s KNN package. This simplifies some tasks.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: PyOD是一个Python异常值检测工具包。我们在这里将其作为scikit-learn的KNN包的封装器使用，这简化了某些任务。
- en: Our focus in this recipe is not on building a model, but on getting a sense
    of which observations (countries) are significant outliers once we take all the
    data we have into account. This analysis supports our developing sense that Singapore
    and Qatar are very different observations than the others in our dataset. They
    have very high decision scores. (The table in *step 5* is sorted in descending
    order of score.)
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 本例的重点不是构建模型，而是通过考虑我们拥有的所有数据，了解哪些观察结果（国家）是显著的异常值。这个分析支持我们逐渐形成的看法，即新加坡和卡塔尔在我们的数据集中与其他国家有很大不同。它们具有非常高的决策得分。（*步骤5*中的表格按得分降序排列。）
- en: Countries such as Bahrain and Luxembourg might also be considered outliers,
    though that is less clear cut. The previous recipe did not indicate that they
    had an overwhelming influence on a regression model. However, that model did not
    take both cases per million and deaths per million into account at the same time.
    That could also explain why Singapore is even more of an outlier than Qatar here.
    It has both high cases per million and below-average deaths per million.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 像巴林和卢森堡这样的国家也可能被视为异常值，尽管这种判断不那么明确。之前的方案没有表明它们对回归模型有压倒性的影响。然而，那个模型没有同时考虑每百万病例和每百万死亡人数。这也可能解释为什么新加坡在这里比卡塔尔更为异常。新加坡既有很高的每百万病例，又有低于平均水平的每百万死亡。
- en: Scikit-learn makes scaling very easy. We used the standard scaler in *step 2*,
    which returned the *z*-score for each value in the DataFrame. The *z*-score subtracts
    the variable mean from each variable value and divides it by the standard deviation
    for the variable. Many machine learning tools require standardized data to run
    well.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn使得数据标准化变得非常简单。我们在*步骤2*中使用了标准化器，它为数据框中的每个值返回了*z*分数。*z*分数将每个变量值减去该变量的均值，并除以该变量的标准差。许多机器学习工具需要标准化的数据才能良好运作。
- en: There’s more...
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: KNN is a very popular machine learning algorithm. It is easy to run and interpret.
    Its main limitation is that it will run slowly on large datasets.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: KNN是一个非常流行的机器学习算法。它易于运行和解释。它的主要限制是，在大型数据集上运行时速度较慢。
- en: We have skipped steps we might usually take when building machine learning models.
    We did not create separate training and testing datasets, for example. PyOD allows
    this to be done easily, but this is not necessary for our purposes here.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们跳过了构建机器学习模型时通常会采取的一些步骤。例如，我们没有创建单独的训练集和测试集。PyOD允许轻松完成此操作，但在这里我们并不需要这么做。
- en: See also
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: We go into detail on transforming data in *Chapter 8*, *Encoding, Transforming,
    and Scaling Features*. A good resource on using KNN is *Data Cleaning and Exploration
    with Machine Learning*, also by me.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第8章*《编码、转换和标准化特征》中详细介绍了数据转换。关于使用KNN的一个好资源是《使用机器学习进行数据清理与探索》，这本书也由我撰写。
- en: The PyOD toolkit has a large number of supervised and unsupervised learning
    techniques for detecting anomalies in data. You can get the documentation for
    this at [https://pyod.readthedocs.io/en/latest/](https://pyod.readthedocs.io/en/latest/).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: PyOD工具包提供了大量有监督和无监督学习技术，用于检测数据中的异常值。你可以在[https://pyod.readthedocs.io/en/latest/](https://pyod.readthedocs.io/en/latest/)找到相关文档。
- en: Using Isolation Forest to find anomalies
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用隔离森林检测异常值
- en: Isolation Forest is a relatively new machine learning technique for identifying
    anomalies. It has quickly become popular, partly because its algorithm is optimized
    to find anomalies, rather than normal values. It finds outliers by successive
    partitioning of the data until a data point has been isolated. Points that require
    fewer partitions to be isolated receive higher anomaly scores. This process turns
    out to be fairly easy on system resources. In this recipe, we demonstrate how
    to use it to detect outlier COVID-19 cases and deaths.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 孤立森林是一种相对较新的机器学习技术，用于识别异常值。它之所以快速流行，部分原因是其算法优化于发现异常值而不是正常值。它通过对数据的连续分区来找到异常值，直到一个数据点被孤立出来。需要更少分区来孤立的点将获得较高的异常分数。这个过程在系统资源上相对容易。在这个配方中，我们演示了如何使用它来检测异常的
    COVID-19 病例和死亡人数。
- en: Getting ready
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You will need scikit-learn and Matplotlib to run the code in this recipe. You
    can install them by entering `pip install sklearn` and `pip install matplotlib`
    in the terminal or PowerShell (in Windows).
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行本配方中的代码，您需要安装 scikit-learn 和 Matplotlib。您可以在终端或 PowerShell（Windows 中）中输入`pip
    install sklearn`和`pip install matplotlib`来安装它们。
- en: How to do it...
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点……
- en: 'We will use Isolation Forest to find the countries whose attributes indicate
    that they are most anomalous:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用孤立森林来找出那些属性表明它们是最异常的国家：
- en: 'Load `pandas`, `matplotlib`, and the `StandardScaler` and `IsolationForest`
    modules from `sklearn`:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载`pandas`、`matplotlib`以及从`sklearn`中加载的`StandardScaler`和`IsolationForest`模块：
- en: '[PRE92]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: Create a standardized analysis DataFrame.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个标准化分析的 DataFrame。
- en: 'First, remove all rows with missing data:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，删除所有带有缺失数据的行：
- en: '[PRE93]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Run an Isolation Forest model to detect outliers.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行孤立森林模型来检测异常值。
- en: 'Pass the standardized data to the `fit` method. 18 countries are identified
    as outliers. (These countries have anomaly values of `-1`.) This is determined
    by the contamination number of `0.1`:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 将标准化数据传递给`fit`方法。共有18个国家被识别为异常值。（这些国家的异常值为`-1`。）这是由`0.1`的污染度数确定的：
- en: '[PRE96]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: Create outlier and inlier DataFrames.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建异常值和正常值DataFrame。
- en: 'List the top 10 outliers according to anomaly score:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 根据异常分数列出前 10 个异常值：
- en: '[PRE100]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'Plot the outliers and inliers:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制异常值和正常值：
- en: '[PRE102]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'This produces the following plot:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下图表：
- en: '![](img/B18596_04_10.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_10.png)'
- en: 'Figure 4.10: Inlier and outlier countries by GDP, median age, and cases per
    million'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10：按人均 GDP、中位年龄和每百万人病例的正常值和异常值国家
- en: The preceding steps demonstrate the use of Isolation Forest as an alternative
    to KNN for anomaly detection.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 上述步骤演示了使用孤立森林作为异常检测的替代方法。
- en: How it works…
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: We used Isolation Forest in this recipe much like we used KNN in the previous
    recipe. In *step 3*, we passed a standardized dataset to the Isolation Forest
    `fit` method, and then used its `predict` and `decision_function` methods to get
    the anomaly flag and score, respectively. We used the anomaly flag in *step 4*
    to separate the data into inliers and outliers.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们使用孤立森林的方式类似于前一配方中使用 KNN 的方式。在*步骤 3*中，我们传递了一个标准化的数据集给孤立森林的`fit`方法，然后使用它的`predict`和`decision_function`方法来获取异常标志和分数，分别在*步骤
    4*中使用异常标志将数据分成正常值和异常值。
- en: We plot the inliers and outliers in *step 5*. Since there are only three dimensions
    in the plot, it does not quite capture all of the features in our Isolation Forest
    model, but the outliers (the red dots) clearly have a higher GDP per capita and
    median age; these are typically to the right of, and behind, the inliers.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*步骤 5*中绘制正常值和异常值。由于图中只有三个维度，它并没有完全捕捉到我们孤立森林模型中的所有特征，但是异常值（红色点）明显具有更高的人均 GDP
    和中位年龄；这些通常位于正常值的右侧和后方。
- en: The results from Isolation Forest are quite similar to the KNN results. Singapore,
    Bahrain, and Qatar have three of the four highest (most negative) anomaly scores.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 孤立森林的结果与KNN结果非常相似。新加坡、巴林和卡塔尔是四个最高（最负）异常分数中的三个国家。
- en: There’s more…
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: Isolation Forest is a good alternative to KNN, particularly when working with
    large datasets. The efficiency of its algorithm allows it to handle large samples
    and a high number of variables.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 孤立森林是KNN的一个很好的替代方法，特别是在处理大数据集时。其算法的高效性使其能够处理大样本和大量变量。
- en: The anomaly detection techniques we have used in the last three recipes were
    designed to improve multivariate analyses and the training of machine learning
    models. However, we might want to exclude the outliers they helped us identify
    much earlier in the analysis process. For example, if it makes sense to exclude
    Qatar from our modeling, it might also make sense to exclude Qatar from some descriptive
    statistics.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在过去三个食谱中使用的异常检测技术旨在改进多变量分析和机器学习模型的训练。然而，我们可能希望排除它们帮助我们在分析过程中较早识别的异常值。例如，如果排除卡塔尔对我们的建模有意义，那么排除卡塔尔在某些描述性统计中的数据可能也是合理的。
- en: See also
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'In addition to being useful for anomaly detection, the Isolation Forest algorithm
    is quite satisfying intuitively. (I think the same could be said about KNN.) You
    can read more about Isolation Forest here: [https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf).'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对异常检测有用外，Isolation Forest算法在直观上也相当令人满意。（我认为KNN也可以说是一样的。）你可以在这里阅读更多关于Isolation
    Forest的内容：[https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)。
- en: Using PandasAI to identify outliers
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PandasAI识别异常值
- en: We can use PandasAI to support some of the work we have done in this chapter
    to identify outliers. We can check for extreme values based on a univariate analysis.
    We can look at bivariate and multivariate relationships as well. PandasAI will
    also help us generate visualizations easily.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用PandasAI来支持本章中我们为识别异常值所做的一些工作。我们可以根据单变量分析检查极端值。我们还可以查看双变量和多变量关系。PandasAI还将帮助我们轻松生成可视化。
- en: Getting ready
  id: totrans-341
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You need to install PandasAI to run the code in this recipe. You can do that
    with `pip install pandasai`. We will work with the COVID-19 data again, which
    is available in the GitHub repository, as well as the code.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要安装PandasAI以运行这个食谱中的代码。你可以通过`pip install pandasai`来安装。我们将再次使用COVID-19数据，这些数据可以在GitHub仓库中找到，代码也是如此。
- en: You will also need an API key from OpenAI. You can get one at [platform.openai.com](https://platform.openai.com).
    You will need to setup an account and then click on your profile in the upper-right
    corner and then View API keys.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要一个来自OpenAI的API密钥。你可以在[platform.openai.com](https://platform.openai.com)获取一个。你需要注册一个账户，然后点击右上角的个人资料，再点击查看API密钥。
- en: The PandasAI library is improving rapidly, and some things have changed, even
    since I began writing this book. I have used PandasAI version 2.0.30 in this recipe.
    It also matters which version of pandas you use with it. I have use pandas version
    2.2.1 in this recipe.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: PandasAI库发展迅速，自从我开始编写这本书以来，一些内容已经发生了变化。我在本食谱中使用的是PandasAI版本2.0.30。使用的Pandas版本也很重要。我在本食谱中使用的是Pandas版本2.2.1。
- en: How to do it...
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We create a PandasAI instance in the following steps and use it to look for
    extreme and unexpected values in the COVID-19 data:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过以下步骤创建一个PandasAI实例，并用它来查找COVID-19数据中的极端和意外值：
- en: 'We import `pandas` and the `PandasAI` library:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入`pandas`和`PandasAI`库：
- en: '[PRE103]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'We load the COVID-19 data and create a `PandasAI SmartDataframe`:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们加载COVID-19数据并创建一个`PandasAI SmartDataframe`：
- en: '[PRE104]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'We can pass natural language queries to the `chat` method of the `SmartDataframe`.
    This includes plotting:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以将自然语言查询传递给`chat`方法的`SmartDataframe`。这包括绘制图表：
- en: '[PRE105]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'This produces the following plot:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了以下图表：
- en: '![](img/B18596_04_11.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_11.png)'
- en: 'Figure 4.11: Histogram of total cases per million'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11：每百万总病例的直方图
- en: 'We can also create a boxplot:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以创建一个箱型图：
- en: '[PRE106]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'This produces the following plot:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了以下图表：
- en: '![](img/B18596_04_12.png)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_12.png)'
- en: 'Figure 4.12: Boxplot of total cases per million'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12：每百万总病例的箱型图
- en: 'We can also show a scatterplot of the relationship between cases and deaths.
    We indicate that we want to use `regplot` to make sure that we get a regression
    line:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以显示病例与死亡之间关系的散点图。我们指定希望使用`regplot`，以确保绘制回归线：
- en: '[PRE107]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'This produces the following plot:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了以下图表：
- en: '![](img/B18596_04_13.png)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18596_04_13.png)'
- en: 'Figure 4.13: Scatterplot of the relationship between cases and deaths'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13：病例与死亡之间关系的散点图
- en: 'Show high and low values for total cases:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示总病例的高值和低值：
- en: '[PRE108]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: This sorted the data in ascending order for the high group, and then sorted
    the data in ascending order for the low group.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 这将高组的数据按升序排序，然后对低组的数据进行升序排序。
- en: 'We can find the countries with the highest number of cases for each region:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以找到每个地区病例数最多的国家：
- en: '[PRE110]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'We can get `chat` to show us countries where the number of cases was high but
    the number of deaths was relatively low:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以让`chat`向我们展示病例数较高而死亡数相对较低的国家：
- en: '[PRE112]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: These were just a few examples of how PandasAI can be used to help us find outliers
    or unexpected values with very little code.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是PandasAI如何帮助我们通过极少的代码找到异常值或意外值的几个示例。
- en: How it works…
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: We used PandasAI with the large language model provided by OpenAI in this recipe.
    You just need an API token. You can get one from [platform.openai.com](https://platform.openai.com).
    After you have a token, all you need to do to get started with sending natural
    language queries to a database is import the OpenAI and `SmartDataframe` modules
    and instantiate a `SmartDataframe` object.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个食谱中使用了PandasAI和OpenAI提供的大型语言模型。你只需要一个API令牌。你可以从[platform.openai.com](https://platform.openai.com)获取。获得令牌后，开始通过自然语言查询数据库时，只需导入OpenAI和`SmartDataframe`模块并实例化一个`SmartDataframe`对象。
- en: 'We created a `SmartDataframe` object in *step 2* with `covidtotalssdf = SmartDataframe(covidtotals,
    config={"llm": llm})`. Once we have a `SmartDataframe`, we can pass a variety
    of natural language instructions to its `chat` method. In this recipe, this ranged
    from requesting visualizations and finding the highest and lowest values to examining
    values for subsets of the data.'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在*步骤 2*中创建了一个`SmartDataframe`对象，代码为`covidtotalssdf = SmartDataframe(covidtotals,
    config={"llm": llm})`。一旦我们有了`SmartDataframe`，就可以通过其`chat`方法传递各种自然语言指令。在这个食谱中，这些指令从请求可视化、查找最高和最低值到检查数据子集的值不等。'
- en: 'It is a good idea to regularly check the `pandasai.log` file, which will be
    in the same folder as your Python script. Here is the code PandasAI generated
    in response to `covidtotalssdf.chat("Show total cases per million and total deaths
    per million for locationss with high total_cases_pm and low total_deaths_pm")`:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 定期检查`pandasai.log`文件是一个好主意，该文件与您的Python脚本位于同一文件夹中。以下是PandasAI在响应`covidtotalssdf.chat("Show
    total cases per million and total deaths per million for locationss with high
    total_cases_pm and low total_deaths_pm")`时生成的代码：
- en: '[PRE114]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '2024-04-18 09:30:01 [INFO] Executing Step 4: CachePopulation'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 2024-04-18 09:30:01 [INFO] 执行步骤 4：CachePopulation
- en: '2024-04-18 09:30:01 [INFO] Executing Step 5: CodeCleaning'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 2024-04-18 09:30:01 [INFO] 执行步骤 5：CodeCleaning
- en: 2024-04-18 09:30:01 [INFO]
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 2024-04-18 09:30:01 [INFO]
- en: 'Code running:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 代码运行中：
- en: '[PRE116]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: There’s more...
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: We generated a boxplot in *step 4*, which is an incredibly useful tool for visualizing
    the distribution of a continuous variable. The box shows the interquartile range,
    which is the distance between the first and third quartiles. The line in the box
    shows the median. We go into much more detail on boxplots in *Chapter 5*, *Using
    Visualizations for the Identification of Unexpected Values*.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*步骤 4*中生成了一个箱型图，这是一个非常有用的工具，用于可视化连续变量的分布。箱体显示了四分位距，即第一四分位数和第三四分位数之间的距离。箱内的线表示中位数。在*第五章*《使用可视化识别异常值》中，我们会详细讲解箱型图。
- en: See also
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: The *Using generative AI to create descriptive statistics* recipe in *Chapter
    3*, *Taking the Measure of Your Data*, provides some additional information on
    how PandasAI uses OpenAI, and on generating overall and by-group statistics and
    visualizations. We use PandasAI throughout this book whenever it is a good tool
    for improving our data preparation work or making it easier.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '*第三章*《衡量您的数据》中关于*使用生成型AI创建描述性统计*的食谱提供了更多信息，介绍了PandasAI如何使用OpenAI，以及如何生成总体和按组统计数据及可视化。我们在本书中随时使用PandasAI，凡是它能够改善我们的数据准备工作或简化操作时，我们都会使用它。'
- en: Summary
  id: totrans-392
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter introduced pandas tools for identifying outliers in our data. We
    explored a variety of univariate, bivariate, and multivariate approaches to detect
    observations sufficiently out of range, or otherwise unusual enough, to distort
    our analysis. These approaches included using the interquartile range to identify
    extreme values, investigating relationships with a correlated variable, and using
    parametric and non-parametric multivariate techniques such as linear regression
    and KNN respectively. We also saw how visualizations can help us get a better
    feel for how a variable is distributed, and how it moves with a correlated variable.
    We will go into much greater detail on how to create and interpret visualizations
    in the next chapter.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了用于识别数据中异常值的 pandas 工具。我们探索了多种单变量、双变量和多变量方法，用以检测足够偏离范围或其他异常的观测值，这些异常值可能会扭曲我们的分析。这些方法包括使用四分位距来识别极值，调查与相关变量的关系，以及分别使用线性回归和
    KNN 等参数化和非参数化的多变量技术。我们还展示了可视化如何帮助我们更好地理解变量的分布情况，以及它如何与相关变量一起变化。下一章我们将详细探讨如何创建和解释可视化。
- en: Join our community on Discord
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者讨论：
- en: '[https://discord.gg/p8uSgEAETX](https://discord.gg/p8uSgEAETX )'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://discord.gg/p8uSgEAETX](https://discord.gg/p8uSgEAETX)'
- en: '![](img/QR_Code10336218961138498953.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code10336218961138498953.png)'
