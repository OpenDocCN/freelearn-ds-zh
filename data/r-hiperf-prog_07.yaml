- en: Chapter 7. Processing Large Datasets with Limited RAM
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 使用有限RAM处理大数据集
- en: In the previous chapter, we learned how to optimize the memory consumption of
    R programs by reducing the copying of data and by removing temporary data. Sometimes,
    that is still not enough. We might have data that is too large to even fit into
    memory, let alone perform any computations on them, or even if the data can fit
    into memory, there is not much free memory left for the analyses that we need
    to perform.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何通过减少数据的复制和删除临时数据来优化R程序的内存消耗。有时，这仍然不够。我们可能有一些数据太大，甚至无法放入内存，更不用说对其进行任何计算了，或者即使数据可以放入内存，可供我们进行所需分析的空闲内存也不多。
- en: In this chapter, we will learn advanced techniques to overcome memory limitations
    and process large datasets.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习克服内存限制并处理大数据集的高级技术。
- en: 'This chapter covers:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖：
- en: Using memory-efficient data structures
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内存高效的数据结构
- en: Using memory-mapped files and processing data in chunks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内存映射文件和分块处理数据
- en: Using memory-efficient data structures
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用内存高效的数据结构
- en: One of the first things to consider when you work with a large dataset is whether
    the same information can be stored and processed using more memory-efficient data
    structures. But first we need to know how data is stored in R. Vectors are the
    basic building blocks of almost all data types in R. R provides atomic vectors
    of logical, integer, numeric, complex, character and raw types. Many other data
    structures are also built from vectors. Lists, for example, are essentially vectors
    in R's internal storage structures. They differ from atomic vectors in the way
    that they store pointers to other R objects rather than atomic values. That is
    why lists can contain objects of different types.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当你处理大数据集时，首先要考虑的是是否可以使用更内存高效的数据结构来存储和处理相同的信息。但首先我们需要知道数据在R中是如何存储的。向量是R中几乎所有数据类型的基本构建块。R提供了逻辑、整数、数值、复数、字符和原始类型的原子向量。许多其他数据结构也是从向量构建的。例如，列表在R的内部存储结构中本质上就是向量。它们与原子向量的不同之处在于它们存储指向其他R对象的指针，而不是原子值。这就是为什么列表可以包含不同类型的对象。
- en: 'Let''s examine how much memory is required for each of the atomic data types.
    To do that, we will create vectors of each type with 1 million elements and measure
    their memory consumption using `object.size()` (for character vectors, we will
    call `rep.int(NA_character_, 1e6)`, which will create a truly empty character
    vector containing the `NA` values, which as we shall see shortly, takes up less
    memory than a character vector containing empty strings):'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看每种原子数据类型需要多少内存。为此，我们将创建每种类型的包含一百万个元素的向量，并使用`object.size()`（对于字符向量，我们将调用`rep.int(NA_character_,
    1e6)`，这将创建一个真正包含`NA`值的空字符向量，正如我们很快将看到的，它比包含空字符串的字符向量占用更少的内存）来测量它们的内存消耗：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: These results were taken from a 64-bit version of R. Notice that all these vectors
    take up memory in multiples of 1 million plus an extra 40 bytes. These 40 bytes
    are taken up by the headers of the vectors that R uses to store information about
    the vectors, such as the lengths and data types. The remaining space is taken
    up by the data stored in the vectors.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果是从R的64位版本中获得的。请注意，所有这些向量都占用1百万字节以上的内存，额外还占用40字节。这40字节被向量头占用，R使用这些头存储有关向量的信息，例如长度和数据类型。剩余的空间被向量中存储的数据占用。
- en: 'By dividing these numbers by 1 million, we see that raw values take up 1 byte
    each, logical and integer values 4 bytes, numeric values 8 bytes, and complex
    values 16 bytes. The following figure depicts the structure and memory required
    for these types of vectors:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将这些数字除以一百万，我们发现原始值每个占用1字节，逻辑和整数值占用4字节，数值占用8字节，复数值占用16字节。以下图显示了这些类型向量的结构和内存需求：
- en: '![Using memory-efficient data structures](img/9263OS_07_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![使用内存高效的数据结构](img/9263OS_07_01.jpg)'
- en: Internal structure of logical, integer, numeric, and complex vectors
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑、整数、数值和复数向量的内部结构
- en: 'Character vectors and lists are a little different because they do not store
    the actual data within their vectors. Instead, they store pointers to other vectors
    that contain the actual data. In the computer''s memory, each element of a character
    vector or list is a pointer that occupies 4 bytes in a 32-bit R and 8 bytes in
    a 64-bit R. This is depicted in the following figure:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 字符向量和列表有一点不同，因为它们在其向量中不存储实际数据。相反，它们存储指向其他包含实际数据的向量的指针。在计算机的内存中，字符向量或列表的每个元素都是一个指针，在
    32 位 R 中占用 4 字节，在 64 位 R 中占用 8 字节。这将在以下图中展示：
- en: '![Using memory-efficient data structures](img/9263OS_07_02.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![使用内存高效的数据结构](img/9263OS_07_02.jpg)'
- en: Internal structure of lists and character vectors
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 列表和字符向量的内部结构
- en: 'Let''s examine character vectors more closely to see how they are stored. To
    do this, we will generate three different character vectors, all having 1 million
    strings with 10 characters each. The first vector simply contains 1 million copies
    of the `"0123456789"` string, generated using the `formatC()` function to take
    up ten characters. The second vector contains 1,000 copies of 1,000 unique strings,
    generated using `formatC()` to take up 10 characters. The third vector contains
    1 million unique strings with 10 characters each. Because these vectors contain
    the same number of strings with the same length, we would expect them to take
    up the same amount of memory. Let''s test this hypothesis:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地检查字符向量，看看它们是如何存储的。为此，我们将生成三个不同的字符向量，每个向量都有 1,000,000 个由 10 个字符组成的字符串。第一个向量简单地包含
    1,000,000 个 `"0123456789"` 字符串的副本，使用 `formatC()` 函数生成，以占用十个字符。第二个向量包含 1,000 个由
    `formatC()` 生成的 1,000 个唯一字符串的副本，每个字符串占用 10 个字符。第三个向量包含 1,000,000 个具有 10 个字符的唯一字符串。因为这些向量包含相同数量的字符串，且长度相同，我们预计它们将占用相同数量的内存。让我们测试这个假设：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It turns out that the three character vectors take up vastly different amounts
    of memory, depending on the actual content of the strings. This is because R stores
    only one copy of each unique string in its CHARSXP cache in order to save memory.
    The character vectors that we created actually store pointers to the strings in
    this cache, rather than the strings themselves.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，三个字符向量占用的内存量差异很大，这取决于字符串的实际内容。这是因为 R 为了节省内存，只在其 CHARSXP 缓存中存储每个唯一字符串的一个副本。我们创建的字符向量实际上存储的是指向这个缓存中字符串的指针，而不是字符串本身。
- en: Furthermore, each of the strings in this cache is a full-fledged R vector with
    a 24- or 40-byte header (in a 32-bit and 64-bit R respectively) and exactly one
    string. The null character is appended to the end of the string, and the total
    vector length is rounded up to the nearest multiple of eight. So, for example,
    the string `0123456789` would be stored as `0123456789\0` (where `\0` is the null
    character) plus five more bytes to make a total of 16 bytes. Adding on the 40-byte
    header in a 64-bit R, this 10-character string occupies 56 bytes of memory.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这个缓存中的每个字符串都是一个完整的 R 向量，具有 24 个或 40 字节的头信息（在 32 位和 64 位 R 中分别），以及一个字符串。空字符被附加到字符串的末尾，总向量长度向上取整到最接近的
    8 的倍数。例如，字符串 `0123456789` 将被存储为 `0123456789\0`（其中 `\0` 是空字符）加上五个额外的字节，总共 16 字节。在
    64 位 R 中，加上 40 字节的头信息，这个 10 个字符的字符串将占用 56 字节的内存。
- en: Turning back to the results, the first vector with 1 million copies of `0123456789`
    requires 8,000,040 bytes for the character vector itself that contains pointers
    and another 56 bytes for storing the string itself. This makes for a total of
    8,000,096 bytes, as reported by `object.size()`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 回到结果，包含 1,000,000 个 `0123456789` 复制品的第一个向量，其字符向量本身需要 8,000,040 字节，用于存储指针，另外还需要
    56 字节来存储字符串本身。这使得总字节数达到 8,000,096 字节，这是 `object.size()` 报告的。
- en: The second vector contains 1,000 unique strings, so it uses a total of *8,000,040
    + 1,000 × 56 = 8,056,040* bytes of memory.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个向量包含 1,000 个唯一字符串，因此总共使用 *8,000,040 + 1,000 × 56 = 8,056,040* 字节的内存。
- en: The third vector contains 1 million unique strings, so it uses a total of *8,000,040
    + 1,000,000 × 56 = 64,000,040* bytes of memory.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个向量包含 1,000,000 个唯一字符串，因此总共使用 *8,000,040 + 1,000,000 × 56 = 64,000,040* 字节的内存。
- en: Evidently the memory consumption of character vectors depends on the number
    of unique strings contained in the vector.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，字符向量的内存消耗取决于向量中包含的唯一字符串数量。
- en: Smaller data types
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 较小的数据类型
- en: Having understood how atomic vectors are stored in R, we now look at some simple
    strategies to reduce the memory footprint of large datasets so that they might
    fit in memory for analysis.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解了原子向量在 R 中的存储方式之后，我们现在来看看一些简单的策略来减少大数据集的内存占用，以便它们可以适应内存进行分析。
- en: 'One way is to coerce data to smaller data types, where possible. For example,
    if a dataset contains only integer values, storing them in an integer instead
    of numeric vector reduces memory consumption by about half:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是在可能的情况下将数据强制转换为较小的数据类型。例如，如果一个数据集只包含整数值，将它们存储在整数向量而不是数值向量中可以减少大约一半的内存消耗：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This also applies to character strings. Where there are many duplicated strings
    in a character vector, converting it to a factor vector can reduce the memory
    consumption, since factors are actually integer vectors that index a character
    vector of the unique strings (the levels of the factor) that appear in the data:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这也适用于字符字符串。在一个字符向量中，如果有许多重复的字符串，将其转换为因子向量可以减少内存消耗，因为因子实际上是索引唯一字符串（因子的水平）的整数向量：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: These same techniques can be applied to the components of other data structures,
    such as matrices, data frames, and lists that are built on atomic vectors.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些相同的技巧也可以应用于其他数据结构的组件，例如基于原子向量的矩阵、数据框和列表。
- en: Sparse matrices
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稀疏矩阵
- en: Sometimes the data might be very sparse, that is, it contains a lot of zeroes
    or empty values. Instead of storing a full vector of matrix in memory, using *sparse
    matrices* can significantly reduce the amount of memory required to represent
    the data. Sparse matrices are provided by the `Matrix` package that comes with
    R.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有时数据可能非常稀疏，即包含很多零或空值。与在内存中存储完整的矩阵向量相比，使用*稀疏矩阵*可以显著减少表示数据所需的内存量。R中的`Matrix`包提供了稀疏矩阵。
- en: 'Say we have a 1,000 by 1,000 matrix of numbers (1 million elements in total)
    with about 70 percent zeroes. We can use the `Matrix()` function to create either
    dense or sparse matrices from this data, depending on the sparse argument:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个1,000×1,000的数值矩阵（总共有1百万个元素），其中大约有70%的零。我们可以使用`Matrix()`函数从这个数据创建密集或稀疏矩阵，具体取决于稀疏参数：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The dense matrix requires about the same amount of memory as the numeric vector
    of raw data. The sparse matrix reduces the size of the data by 55 percent.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 稠密矩阵所需的内存量与原始数据的数值向量大致相同。稀疏矩阵通过减少55%的数据大小来减少数据量。
- en: 'Sparse matrices are also very useful for binary data (`TRUE`/`FALSE`, `0`/`1`,
    `"yes"`/`"no"`, `"hot"`/`"cold"`, and so on). Simply convert the binary data into
    logical values, where the majority class is `FALSE` (if the majority class if
    `TRUE`, just invert the data). We can then create sparse matrices that only store
    information about where the `TRUE` values occur in the matrix. Again, let''s test
    this on a 70 percent sparse matrix of 1 million logical values:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏矩阵对于二进制数据（`TRUE`/`FALSE`，`0`/`1`，`"yes"`/`"no"`，`"hot"`/`"cold"`等）也非常有用。只需将二进制数据转换为逻辑值，其中大多数类是`FALSE`（如果大多数类是`TRUE`，则反转数据）。然后我们可以创建只存储矩阵中`TRUE`值出现位置的稀疏矩阵。再次，让我们在一个70%稀疏的1百万个逻辑值矩阵上测试这个方法：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The sparse logical matrix is even more compact than the sparse numeric matrix,
    being 33 percent smaller.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏逻辑矩阵比稀疏数值矩阵更加紧凑，其大小减少了33%。
- en: Symmetric matrices
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对称矩阵
- en: 'Symmetric matrices, that is, matrices that are equal to their transpose are
    used in many statistical methods. Some examples include distance matrices, correlation
    matrices, and graph adjacency matrices. It is possible to save memory by keeping
    only half of the matrix, including the diagonal, since we can generate the other
    half of the matrix by taking the mirror image of the half matrix. The `Matrix`
    package provides the `dspMatrix` class to efficiently store symmetric matrices:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对称矩阵，即等于其转置的矩阵，在许多统计方法中都有应用。例如，距离矩阵、相关矩阵和图邻接矩阵。由于我们可以通过取一半矩阵的镜像来生成矩阵的另一半，包括对角线，因此只保留矩阵的一半可以节省内存。`Matrix`包提供了`dspMatrix`类来高效地存储对称矩阵：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Beyond sparse and symmetric matrices, the `Matrix` package provides several
    other efficient matrix-type data structures including triangular matrices and
    diagonal matrices. Depending on the type of data, some of these data structures
    might be even more memory-efficient than the generic sparse or symmetric matrices
    used in the preceding examples. Furthermore, the package makes it such that basic
    matrix operations, such as matrix multiplication (`%*%`), are applicable for both
    dense and sparse matrices. Hence, in most cases, we do not need to manually port
    matrix operations from their dense to sparse versions. Consult the documentation
    of the `Matrix` package for more details.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 除了稀疏和对称矩阵之外，`Matrix`软件包还提供了几种其他高效的矩阵类型数据结构，包括三角矩阵和对角矩阵。根据数据类型的不同，这些数据结构中的一些可能比前面示例中使用的通用稀疏或对称矩阵更节省内存。此外，该软件包使得基本的矩阵运算，如矩阵乘法（`%*%`），适用于密集和稀疏矩阵。因此，在大多数情况下，我们不需要手动将矩阵运算从密集版本转换为稀疏版本。有关更多详细信息，请参阅`Matrix`软件包的文档。
- en: Bit vectors
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 位向量
- en: Binary data can be represented in an even more efficient way, using bit vectors.
    Unlike logical values in R that take up four bytes or 32 bits, bit vectors store
    each logical value using only one bit. This reduces the memory consumption of
    logical values by a factor of 32\. Bit vectors, however, cannot store the `NA`
    value, so they are not suitable for data that contains the `NA` values.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制数据可以用位向量以更有效的方式表示。与R中的逻辑值不同，逻辑值占用四个字节或32位，位向量只使用一个位来存储每个逻辑值。这将逻辑值的内存消耗减少了32倍。然而，位向量不能存储`NA`值，因此它们不适用于包含`NA`值的数据。
- en: 'In R, bit vectors are provided by the `bit` package on CRAN. Let''s compare
    the sizes of a logical vector and the equivalent bit vector:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，CRAN上的`bit`软件包提供了位向量。让我们比较逻辑向量和等效位向量的大小：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As expected, the bit vector is 3.2 percent, or 1/32 as large as the logical
    vector.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，位向量的大小是3.2%，即逻辑向量的1/32。
- en: 'Bit vectors also allow for much quicker logical operations:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 位向量还允许进行更快的逻辑运算：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: When dealing with large amounts of logical or binary data, bit vectors not only
    save memory but also provide a speed boost when they are operated on.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理大量逻辑或二进制数据时，位向量不仅节省内存，而且在进行操作时还能提供速度提升。
- en: Using memory-mapped files and processing data in chunks
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用内存映射文件和分块处理数据
- en: Some datasets are so large that even after applying all memory optimization
    techniques and using the most efficient data types possible, they are still too
    large to fit in or be processed in the memory. Short of getting additional RAM,
    one way to work with such large data is to store them on a disk in the form of
    **memory-mapped files** and load the data into the memory for processing one small
    chunk at a time.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 有些数据集非常大，即使应用了所有内存优化技术并使用了最有效的数据类型，它们仍然太大，无法装入或处理在内存中。除了获取额外的RAM之外，处理此类大型数据的一种方法是将它们以**内存映射文件**的形式存储在磁盘上，并一次将一小部分数据加载到内存中进行处理。
- en: For example, say we have a dataset that would require 100 GB of RAM if it is
    fully loaded into the memory and another 100 GB of free memory for the computations
    that need to be performed on the data. If the computer on which the data is to
    be processed only has 64 GB of RAM, we might divide the data into four chunks
    of 25 GB each. The R program will then load the data into the memory one chunk
    at a time and perform the necessary computations on each chunk. After all the
    chunks have been processed, the results from each chunk-wise computation will
    finally be combined in order to compute the final results. Whether this can be
    done easily depends on the nature of the algorithm that is being run on the data.
    Some algorithms can easily be converted to compute on chunks of data, while others
    might require substantial effort to do so.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有一个数据集，如果完全加载到内存中，将需要100 GB的RAM，并且还需要额外的100 GB空闲内存来处理数据。如果处理数据的计算机只有64
    GB的RAM，我们可能需要将数据分成四个25 GB的数据块。然后R程序将一次加载一个数据块到内存中，并对每个数据块进行必要的计算。在所有数据块都处理完毕后，将最终将每个数据块的计算结果合并，以计算最终结果。这能否轻松完成取决于正在数据上运行的算法的性质。一些算法可以轻松地转换为对数据块进行计算，而其他算法可能需要付出相当大的努力才能做到这一点。
- en: 'There are two CRAN packages that provide memory-mapped files to work with large
    datasets in this manner: `bigmemory` and `ff`. We will look at each of these in
    turn.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个CRAN软件包提供了内存映射文件，以便以这种方式处理大型数据集：`bigmemory`和`ff`。我们将依次查看这些软件包。
- en: The bigmemory package
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大内存包
- en: The `bigmemory` CRAN package provides a matrix-like data structure called `big.matrix`.
    Data stored in `big.matrix` objects can be of type `double` (8 bytes, the default),
    `integer` (4 bytes), `short` (2 bytes), or `char` (1 byte).The `big.matrix` objects
    can exist in RAM or in the form of memory-mapped files, and they can be manipulated
    in very much the same way as standard R matrices.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`bigmemory` CRAN 包提供了一个类似于矩阵的数据结构，称为 `big.matrix`。存储在 `big.matrix` 对象中的数据可以是
    `double` 类型（8字节，默认），`integer` 类型（4字节），`short` 类型（2字节）或 `char` 类型（1字节）。`big.matrix`
    对象可以存在于 RAM 中或以内存映射文件的形式存在，并且可以像标准 R 矩阵一样进行操作。'
- en: Note
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: At the time of writing, `bigmemory` is not supported on Windows, but the package
    authors are working to fix this.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，`bigmemory` 在 Windows 上不受支持，但包作者正在努力解决这个问题。
- en: 'To create a `big.matrix` object, we can either call `big.matrix()` to create
    a new object, or `as.big.matrix()` to coerce a matrix into `big.matrix`. For the
    next example, we will create a new `big.matrix` object with 1 billion rows and
    3 columns in R''s temporary folder:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个 `big.matrix` 对象，我们可以调用 `big.matrix()` 来创建一个新对象，或者调用 `as.big.matrix()`
    将矩阵强制转换为 `big.matrix`。在下一个示例中，我们将创建一个包含10亿行和3列的新 `big.matrix` 对象，位于 R 的临时文件夹中：
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Running this might take a while, but when it is done, we have a new object
    `bm` that stores a pointer to the new memory-mapped file. We can find the new
    file called `bm` in the temporary directory with a size of 22 GB:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这个程序可能需要一段时间，但完成后，我们将有一个新的对象 `bm`，它存储指向新内存映射文件的指针。我们可以在临时目录中找到名为 `bm` 的新文件，大小为22
    GB：
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Such a large dataset would not have fit into the main memory of most computers.
    Another file, `bm.desc`, was created alongside the data file. This is used to
    retrieve the memory-mapped file at a later time or by another R program by calling
    something like `my.bm <- attach.big.matrix(file.path(tempdir(), "bm.desc"))`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这样大的数据集可能无法适应大多数计算机的主内存。还创建了一个名为 `bm.desc` 的文件，与数据文件一起使用。该文件用于在以后或由另一个 R 程序通过调用类似
    `my.bm <- attach.big.matrix(file.path(tempdir(), "bm.desc"))` 的方式检索内存映射文件。
- en: 'The `big.matrix` objects support many of the same operations as standard R
    matrices:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`big.matrix` 对象支持许多与标准 R 矩阵相同的操作：'
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: When the subsetting operator `[` is used, `bigmemory` materializes the selected
    portion of the data into the RAM as a matrix. As different parts of a `big.matrix`
    are used, `bigmemory` automatically loads the relevant portions of the data into
    the RAM and removes portions that are no longer needed. Because everything selected
    by `[` is loaded into the memory, care must be taken to ensure that the selected
    data can fit into the available memory. Calls such as `bm[, ]` will likely lead
    to out of memory errors.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用子集操作符 `[` 时，`bigmemory` 将选定的数据部分作为矩阵加载到 RAM 中。随着 `big.matrix` 的不同部分被使用，`bigmemory`
    会自动将相关数据部分加载到 RAM 中，并删除不再需要的部分。由于 `[` 选定的所有内容都会加载到内存中，因此必须注意确保选定的数据可以适应可用的内存。例如
    `bm[, ]` 的调用可能会引发内存不足错误。
- en: 'Let''s now see how an R program might work with `big.matrix` by processing
    one chunk of it at a time. First we will fill it with random data, one chunk at
    a time. The first column will contain integers from the Poisson distribution with
    a mean of 1,000\. The second column will contain binary data represented by ones
    and zeroes. The third will contain real numbers uniformly distributed between
    0 and 100,000\. The following code fills in `bm` with these random numbers in
    100 chunks of 10 million rows at a time:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一个 R 程序如何与 `big.matrix` 一起工作，一次处理一个数据块。首先我们将随机数据填充到它里面，一次一个数据块。第一列将包含均值为1000的泊松分布的整数。第二列将包含由一和零表示的二进制数据。第三列将包含在0到100000之间均匀分布的实数。以下代码以100个10百万行的块将随机数填充到
    `bm` 中：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Another example of a chunked computation is to find the standard deviation
    of each column. Calling `sd(bm[1, ])` might not work, as even a single column
    of data can exceed available memory. Two passes through the data are needed: one
    to compute the mean of each column, and another to compute the squared deviations
    from the mean.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 分块计算的一个例子是计算每一列的标准差。调用 `sd(bm[1, ])` 可能不会工作，因为即使是一列数据也可能超过可用的内存。需要通过数据两次：一次计算每一列的平均值，另一次计算与平均值的平方偏差。
- en: 'The data can be split into chunks of 10 million rows, as before. In the first
    pass, the column means are computed:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以分成1000万行的块，就像之前一样。在第一次遍历中，计算列的平均值：
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The code iterates through each chunk of data and computes the column sums of
    each chunk using the `colSums()` function. This is added to the global column
    sums, stored in `col.sums`. Once all the chunks have been processed, the column
    means are computed by dividing `col.sums` by the number of rows in the data.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 代码遍历每个数据块，并使用 `colSums()` 函数计算每个数据块的列和。这被添加到全局列和 `col.sums` 中。一旦所有数据块都经过处理，通过将
    `col.sums` 除以数据的行数来计算列均值。
- en: 'In the second pass, the squared deviations of the observations from the column
    means are computed:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次遍历时，计算观测值与列均值的平方偏差：
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Each chunk of data is first transposed using `t()` so that `col.means` can be
    subtracted from each column of the transposed data to calculate the deviations
    from the means. The deviations are then squared and summed over the rows as the
    data was transposed.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据块首先使用 `t()` 进行转置，以便从转置数据的每一列中减去 `col.means` 来计算与均值的偏差。然后对偏差进行平方，并在转置后的数据行上求和。
- en: Once all the chunks have been processed, the total squared deviations of each
    column are then divided by *n-1* to compute the variance of each column. Finally,
    the square roots of the column variances give the column standard deviations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有数据块都经过处理，每个列的总平方偏差然后除以 *n-1* 来计算每个列的方差。最后，列方差的平方根给出列标准差。
- en: 'The authors of `bigmemory` also wrote a companion package `biganalytics` that
    provides common statistical functions for `big.matrix` objects. We can compare
    the results of the preceding exercise with the `colsd()` function from `biganalytics`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`bigmemory` 的作者还编写了一个配套包 `biganalytics`，它为 `big.matrix` 对象提供了常用的统计函数。我们可以将前面练习的结果与
    `biganalytics` 的 `colsd()` 函数进行比较：'
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We have seen how to perform computations over chunks of data using `big.matrix`
    objects. The authors of `bigmemory` have also created other CRAN packages that
    provide useful functions that operate over `big.matrix` objects. These are listed
    in the following table:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何使用 `big.matrix` 对象在数据块上执行计算。`bigmemory` 的作者还创建了其他 CRAN 包，这些包提供了在 `big.matrix`
    对象上操作的有用函数。以下表格列出了这些函数：
- en: '| Package | Samples of functions provided |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 包 | 提供的函数样本 |'
- en: '| --- | --- |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `biganalytics` | Statistics: `colmean()`, `colmin()`, `min()`, `colmax()`,
    `max()`, `colrange()`, `range()`, `colvar()`, `colsd()`, `colsum()`, `sum()`,
    `colprod()`, `prod()`, and `colna()`Apply: `apply()`Linear models: `biglm.big.matrix()`,
    `bigglim.big.matrix()`Clustering: `bigkmeans()` |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `biganalytics` | 统计：`colmean()`、`colmin()`、`min()`、`colmax()`、`max()`、`colrange()`、`range()`、`colvar()`、`colsd()`、`colsum()`、`sum()`、`colprod()`、`prod()`
    和 `colna()`；应用：`apply()`；线性模型：`biglm.big.matrix()`、`bigglim.big.matrix()`；聚类：`bigkmeans()`
    |'
- en: '| `bigtabulate` | Table and `tapply`: `bigtabulate()`, `bigtable()`, `bigtsummary()`Split:
    `bigsplit()` |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `bigtabulate` | 表和 `tapply`：`bigtabulate()`、`bigtable()`、`bigtsummary()`；分割：`bigsplit()`
    |'
- en: '| `bigalgebra` | Arithmetic operations |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| `bigalgebra` | 算术运算 |'
- en: The ff package
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: The `ff` 包
- en: While `big.matrix` is useful for data that can be coerced to the same type,
    sometimes a more data frame-like memory-mapped format is required while dealing
    with heterogeneous data types. The `ff` CRAN package provides this capability.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`big.matrix`对于可以强制转换为相同类型的数据很有用，但在处理异构数据类型时，有时需要更类似数据框的内存映射格式。`ff` CRAN 包提供了这种功能。
- en: The `ff` CRAN package supports more data types than `bigmemory`. The following
    table shows the different data types, called `vmodes`, that can be stored in `ff`
    vectors, arrays and data frames.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`ff` CRAN 包支持比 `bigmemory` 更多的数据类型。下表显示了可以在 `ff` 向量、数组和数据框中存储的不同数据类型，称为 `vmodes`：'
- en: '| Data type or vmode | Description |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 数据类型或 vmode | 描述 |'
- en: '| --- | --- |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `Boolean` | 1-bit logical without `NA` |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `Boolean` | 无`NA`的1位逻辑 |'
- en: '| `Logical` | 2-bit logical with `NA` |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `Logical` | 2位带`NA`的逻辑 |'
- en: '| `Quad` | 2-bit unsigned integer without `NA` |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `Quad` | 无`NA`的2位无符号整数 |'
- en: '| `Nibble` | 4-bit unsigned integer without `NA` |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| `Nibble` | 无`NA`的4位无符号整数 |'
- en: '| `Byte` | 8-bit signed integer with `NA` |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| `Byte` | 带`NA`的8位符号整数 |'
- en: '| `Ubyte` | 8-bit unsigned integer without `NA` |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| `Ubyte` | 无`NA`的8位无符号整数 |'
- en: '| `Short` | 16-bit signed integer with `NA` |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| `Short` | 16位带`NA`的符号整数 |'
- en: '| `Ushort` | 16-bit unsigned integer without `NA` |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `Ushort` | 无`NA`的16位无符号整数 |'
- en: '| `Integer` | 32-bit signed integer with `NA` |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `Integer` | 带`NA`的32位符号整数 |'
- en: '| `Single` | 32-bit float |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| `Single` | 32位浮点数 |'
- en: '| `Double` | 64-bit float |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| `Double` | 64位浮点数 |'
- en: '| `Complex` | 2 x 64 bit float |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| `Complex` | 2 x 64位浮点数 |'
- en: '| `Raw` | 8-bit unsigned char |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| `Raw` | 8位无符号字符 |'
- en: '| `Factor` | Factor (stored as `integer`) |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| `Factor` | 因子（存储为 `integer`） |'
- en: '| `Ordered` | Ordered factor (stored as `integer`) |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| `Ordered` | 有序因子（存储为 `integer`） |'
- en: '| `POSIXct` | POSIXct (stored as a `double`) |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| `POSIXct` | POSIXct（存储为 `double`） |'
- en: '| `Date` | Date (stored as `double`) |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| `Date` | 日期（存储为 `double`） |'
- en: 'The `ff` objects can be created by passing a vector of values to the `ff()`
    function:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过将值向量传递给 `ff()` 函数来创建 `ff` 对象：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Because no filename was specified, `ff()` automatically creates a new file in
    R's temporary directory. The filename can also be specified using the `filename`
    argument, as shown in the next example.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有指定文件名，`ff()` 自动在 R 的临时目录中创建一个新文件。文件名也可以通过 `filename` 参数指定，如下一个示例所示。
- en: 'If a scalar is passed to `ff()` along with the dimensions for the new `ff`
    object, the scalar value will be used to initialize the object:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将标量传递给 `ff()` 并与新的 `ff` 对象的维度一起使用，标量值将用于初始化对象：
- en: '[PRE17]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The `vmode` argument sets the storage mode of the `ff` object:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`vmode` 参数设置 `ff` 对象的存储模式：'
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Data frames can be constructed using `ffdf()`. Here, we create a new `ffdf`
    object using the integer and quad `ff` vectors created in the preceding code:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框可以使用 `ffdf()` 构建出来。在这里，我们使用前面代码中创建的整数和四舍五入 `ff` 向量创建一个新的 `ffdf` 对象：
- en: '[PRE19]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `ff` objects provide the convenient `chunk()` function to split up the
    data into chunks based on the available memory. With its default arguments, `chunk()`
    recommends to load the entire data frame `d` in one chunk:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`ff` 对象提供了方便的 `chunk()` 函数，可以根据可用内存将数据分割成块。使用默认参数时，`chunk()` 建议一次性将整个数据框 `d`
    载入一个块中：'
- en: '[PRE20]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The maximum chunk size in bytes can also be set using the `BATCHBYTES` argument.
    When it is set to 2 million bytes, `chunk()` recommends splitting the data into
    four chunks:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最大的块大小（以字节为单位）也可以使用 `BATCHBYTES` 参数设置。当它设置为 200 万字节时，`chunk()` 建议将数据分割成四个块：
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In general, it is desirable to have smaller number chunks, as every chunk incurs
    an (typically small) I/O overhead that is required every time an R session needs
    to read data from disk.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，希望块的数量更少，因为每个块都会产生（通常是小的）I/O 开销，每次 R 会话需要从磁盘读取数据时都需要这些开销。
- en: The indices returned by `chunk()` can be used to index the rows of an `ffdf`
    or `ff` object. The following code iterates through each chunk of data, selecting
    the chunk with `d[idx, ]` and `q[idx]`, and performs some computations on the
    chunk.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`chunk()` 返回的索引可以用于索引 `ffdf` 或 `ff` 对象的行。以下代码遍历每个数据块，选择具有 `d[idx, ]` 和 `q[idx]`
    的块，并在该块上执行一些计算。'
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `ff` CRAN package has a companion package, `ffbase`, that provides useful
    functions for manipulating `ff` and `ffdf` objects. Here is a sample of these
    functions:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`ff` CRAN 包有一个配套包 `ffbase`，它提供了用于操作 `ff` 和 `ffdf` 对象的有用函数。以下是这些函数的示例：'
- en: '**Mathematics**: `abs()`, `sign()`, `sqrt()`, `ceiling()`, `floor()`, `log()`,
    `exp()`, `cos()`, `cosh()`, `sin()`, `sinh()`, `gamma()`'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数学**：`abs()`，`sign()`，`sqrt()`，`ceiling()`，`floor()`，`log()`，`exp()`，`cos()`，`cosh()`，`sin()`，`sinh()`，`gamma()` '
- en: '**Summaries**: `all()`, `any()`, `max()`, `min()`, `cumsum()`, `cummin()`'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**汇总**：`all()`，`any()`，`max()`，`min()`，`cumsum()`，`cummin()`'
- en: '**Uniqueness**: `duplicated()`, `unique()`'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**唯一性**：`duplicated()`，`unique()`'
- en: '**Apply**: `ffdfdply()`'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用**：`ffdfdply()`'
- en: 'When we are finished with the `ff` or `ffdf` objects, we can delete the files
    using `delete()` and remove the R variables using `rm()`:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们完成对 `ff` 或 `ffdf` 对象的操作后，可以使用 `delete()` 删除文件，并使用 `rm()` 删除 R 变量：
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Because the underlying vectors `i` and `q` are also deleted while deleting
    the data frame `d`, attempting to delete the vectors will result in an error.
    We can simply remove the R objects:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在删除数据框 `d` 时也会删除底层向量 `i` 和 `q`，尝试删除这些向量将导致错误。我们可以简单地删除 R 对象：
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Summary
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we learned how R stores vectors in memory, and how to estimate
    the amount of memory required for different types of data. We also learned how
    to use more efficient data structures like sparse matrices and bit vectors in
    order to store some types of data, so that they can be fully loaded and processed
    in the memory.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了 R 如何在内存中存储向量，以及如何估计不同类型数据所需的内存量。我们还学习了如何使用更高效的数据结构，如稀疏矩阵和位向量来存储某些类型的数据，以便它们可以在内存中完全加载和处理。
- en: For datasets that are still too large, we used `big.matrix`, `ff`, and `ffdf`
    objects to store memory on disk using memory-mapped files and processed the data
    one chunk at a time. The `bigmemory` and `ff` packages, along with their companion
    packages, provide a rich set of functionality for memory-mapped files that cannot
    be covered fully, in this book. We encourage you to look up the documentation
    for these packages to learn more about how to take advantage of the power of memory-mapped
    files when you handle large datasets.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于仍然太大的数据集，我们使用了`big.matrix`、`ff`和`ffdf`对象，通过内存映射文件将内存存储在磁盘上，并逐块处理数据。`bigmemory`和`ff`包及其配套包提供了一套丰富的功能，用于内存映射文件，这些功能在本书中无法完全涵盖。我们鼓励您查阅这些包的文档，以了解更多关于如何利用内存映射文件处理大型数据集的方法。
- en: In the next chapter, we will look beyond running R in a single process or thread,
    and learn how to run R computations in parallel.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将超越在单个进程或线程中运行R，学习如何并行运行R计算。
