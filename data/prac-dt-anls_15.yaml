- en: Bringing It All Together
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 整合一切
- en: Welcome to the capstone chapter, where we'll walk through some examples to show
    you how the skills learned you've throughout this book can be applied. In this
    chapter, we will learn about open source real-world datasets, some tips on how
    to report results, and a capstone project that blends, transforms, and visualizes
    data from multiple sources. Data analysis is a craft and a journey rewarded by
    the fact that you never stop learning new ways to work with data, provide insights,
    and answer questions. The **data literacy** skills of reading, working with, analyzing,
    and arguing with data is agnostic to any technology, but in my experience, nothing
    replaces the experience of using a specific technology head down and hands-on.
    Our tool of choice in this book was Jupyter Notebook, along with the extendable
    libraries available when using the Python ecosystem, such as pandas, NumPy, and
    NTLK. As you continue to practice and apply these skills, you will become a fungible
    asset who can solve problems using data personally and professionally.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到本章，我们将通过一些示例来展示你在这本书中学到的技能如何应用。在本章中，我们将学习关于开源真实世界数据集的知识，一些关于如何报告结果的小贴士，以及一个融合、转换和可视化来自多个数据源的数据的综合性项目。数据分析是一门技艺，也是一段旅程，其回报在于你永远不会停止学习新的数据处理方式、提供见解和解答问题的方法。**数据素养**技能，包括阅读、使用、分析和用数据辩论，与任何技术无关，但根据我的经验，没有任何经验能替代深入使用特定技术的体验。本书中我们选择使用的工具是Jupyter
    Notebook，以及在使用Python生态系统时可用的一些可扩展库，如pandas、NumPy和NTLK。随着你继续练习和应用这些技能，你将变成一个可以个人和职业上使用数据解决问题的通用资产。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Discovering real-world datasets
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现真实世界数据集
- en: Reporting results
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 报告结果
- en: Capstone project
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 综合性项目
- en: Let's get started!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The GitHub repository for this book can be found at [https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter12](https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter12).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本书对应的GitHub仓库地址为[https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter12](https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter12)。
- en: Furthermore, you can download and install the required software for this chapter
    from: [https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你可以从以下地址下载和安装本章所需的软件：[https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)。
- en: Discovering real-world datasets
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发现真实世界数据集
- en: Throughout this book, I have emphasized that the power of analytics comes from
    blending data together from multiple sources. An individual data source alone
    rarely includes all the fields required to answer key questions. For example,
    if you have a timestamp field but not a geographic field about a user, you can't
    answer any questions about the data related to where an event took place.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的整个过程中，我强调了分析的力量来自于将来自多个来源的数据融合在一起。单个数据源很少包含回答关键问题所需的所有字段。例如，如果你有一个时间戳字段但没有关于用户的地理位置字段，你就无法回答任何关于事件发生地点的数据相关的问题。
- en: As a good data analyst, always offer up creative solutions that have filled
    data gaps or offer a different perspective by including an external data source.
    Finding new data sources is much easier today than ever before. Let's go over
    a few examples.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名优秀的数据分析师，始终提供富有创造性的解决方案，这些解决方案填补了数据空白或通过包含外部数据源提供不同的视角。今天发现新的数据源比以往任何时候都要容易。让我们来看几个例子。
- en: Data.gov
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Data.gov
- en: '**Data.gov** is managed by the United States General Services Administration,
    which offers hundreds of thousands of datasets regarding various topics at the
    State and Federal levels. Most are curated from specific agencies and posted for
    public use. They are open source with limited restrictions. What I like about
    using data.gov is its catalog, which allows you to search across all the topics,
    tags, formats, and organizations. The site was created using open source technologies,
    including CKAN.org, which stands for Comprehensive Knowledge Archive Network.
    This is a platform explicitly built as an open data portal for organizations to
    host datasets and make them transparent. This process democratizes datasets and
    creates standards for publishers to follow, such as exposing data formats (CSV,
    API, and XML, for example) of the source and providing details about how often
    the data is refreshed.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**Data.gov** 由美国总务管理局管理，提供数十万个关于各州和联邦层面各种主题的数据集。大多数数据集由特定机构整理并公开发布。这些数据集是开源的，但有限制。我喜欢使用data.gov的原因是其目录，它允许您跨所有主题、标签、格式和组织进行搜索。该网站使用开源技术创建，包括CKAN.org，代表综合知识档案网络。这是一个专门为组织构建的开放数据门户平台，用于托管数据集并使其透明化。这个过程使数据集民主化，并为出版商制定了标准，例如公开数据格式（例如CSV、API和XML）的源以及提供有关数据更新频率的详细信息。'
- en: 'The following is a screenshot from the data.gov website where you can search
    for open source datasets from the United States government:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从data.gov网站截取的屏幕截图，您可以在该网站上搜索来自美国政府的开源数据集：
- en: '![](img/fef37123-cbaa-4aad-aa70-628a21f5ed24.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fef37123-cbaa-4aad-aa70-628a21f5ed24.png)'
- en: The DATA.GOV ([data.gov](http://data.gov)) site is a good starting point but
    it can be overwhelming to find specific data elements. I find the next example
    easier and faster to OVind and use datasets.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: DATA.GOV（[data.gov](http://data.gov)）网站是一个良好的起点，但寻找特定的数据元素可能会感到不知所措。我发现下一个例子更容易且更快地找到和使用数据集。
- en: The Humanitarian Data Exchange
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人道主义数据交换
- en: '**The Humanitarian Data Exchange** (**HDX**) has become topical due to the
    COVID-19 pandemic but has been sponsoring open source datasets for years. These
    datasets contain health-specific statistics from around the world with a focus
    on helping humanity. This is a true example of what is commonly known as **Data
    for Good** because the site provides transparency on the impact it has on people
    for free. What I like about this site is how it integrates the Creative Commons
    License into the data catalog so that you can understand any limitations around
    reusing or distributing the data from the source. Part of their terms of service
    is to restrict the use of any **Personally Identifiable Information** (**PII**)
    so that the data already adheres to regulations that support protecting individuals
    from being directly identified.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**人道主义数据交换**（**HDX**）由于COVID-19大流行而成为热门话题，但多年来一直在赞助开源数据集。这些数据集包含来自世界各地的健康特定统计数据，重点是帮助人类。这是一个通常被称为**数据善行**的真正例子，因为该网站免费提供其对人们影响的透明度。我喜欢这个网站的方式，它将Creative
    Commons许可证集成到数据目录中，这样您就可以了解关于从源头重新使用或分发数据的任何限制。他们的服务条款的一部分是限制任何**个人身份信息**（**PII**）的使用，这样数据就已经符合支持保护个人免受直接识别的法规。'
- en: 'The following is a screenshot from The Humanitarian Data Exchange website ([data.humdata.org](http://data.humdata.org)),
    where you can search for humanitarian datasets about locations all around the
    world:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从The Humanitarian Data Exchange（人道主义数据交换）网站（[data.humdata.org](http://data.humdata.org)）截取的屏幕截图，您可以在该网站上搜索关于世界各地位置的援助数据集：
- en: '![](img/c2e615e5-4ea4-4874-8ed7-2986ce574145.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c2e615e5-4ea4-4874-8ed7-2986ce574145.png)'
- en: If you are searching for financial data elements categorized by global statistical
    measures, You can begin your search at **The World Bank** data portal.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在寻找按全球统计指标分类的财务数据元素，您可以从**世界银行**数据门户开始搜索。
- en: The World Bank
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 世界银行
- en: '**The World Bank** has an open data repository that includes thousands of datasets
    categorized and conformed by country with metrics classified as indicators. The
    site allows you to compare your data to global baseline metrics such as **Gross
    Domestic Product** (**GDP**), which creates thresholds and performance metrics
    for your analysis. I find that the website is easy to navigate and is quick to
    identify datasets that can easily be joined to other datasets because it includes
    defined data type values such as ISO country codes.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**世界银行** 拥有一个开放的数据仓库，其中包含数千个数据集，这些数据集按国家分类并符合指标。该网站允许您将您的数据与全球基准指标进行比较，例如**国内生产总值**（**GDP**），这为您分析创建阈值和性能指标。我发现该网站易于导航，并且可以快速识别可以轻松与其他数据集连接的数据集，因为它包括定义的数据类型值，如ISO国家代码。'
- en: 'The following is a screenshot from the World Bank Open Data website ([data.worldbank.org](http://data.worldbank.org)),
    where you can search for financially focused datasets as they impact countries
    around the world:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从世界银行开放数据网站（[data.worldbank.org](http://data.worldbank.org)）的截图，您可以在其中搜索影响全球各国的金融数据集：
- en: '![](img/7edc9087-995c-4cc9-adf1-b4eb4978ce27.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7edc9087-995c-4cc9-adf1-b4eb4978ce27.png)'
- en: The World Bank data portal has many rich examples that include data visualizations
    for quick analysis and preview before you start using them. The next site we will
    look at, **Our World in Data**, has similar usability features.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 世界银行数据门户有许多丰富的示例，包括在使用它们之前进行快速分析和预览的数据可视化。我们将要查看的下一个网站，**我们的全球数据**，具有类似的可用性功能。
- en: Our World in Data
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的全球数据
- en: The **Our World in Data** site started with research data from Oxford University
    but has evolved into an online publication based on scientific studies focused
    on helping the world solve problems using data. I enjoy the site because you can
    uncover historical trends that provide context regarding how humanity is improving
    in many cases, but not at the same pace when you look at different countries.
    I also find their data visualizations easy to use and navigate; for example, you
    can filter and compare results between different countries or regions. Their data
    and site have become invaluable during the COVID-19 pandemic as you can track
    cases and compare progress between different countries and within the United States.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们的全球数据**网站始于牛津大学的研究数据，但已发展成为一个基于科学研究的在线出版物，旨在帮助世界使用数据解决问题。我喜欢这个网站，因为它可以揭示历史趋势，为人类在许多情况下如何改善提供背景信息，但当你查看不同国家时，改善的速度并不相同。我还发现他们的数据可视化易于使用和导航；例如，您可以在不同国家或地区之间过滤和比较结果。他们的数据和网站在COVID-19大流行期间变得非常有价值，因为您可以跟踪病例并比较不同国家以及美国国内的进展。'
- en: 'The following is a screenshot from the Our World in Data website ([ourworldindata.org](https://ourworldindata.org/)),
    where you can explore thousands of charts and open source data focused on helping
    solve global problems:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从我们的全球数据网站（[ourworldindata.org](https://ourworldindata.org/)）的截图，您可以在其中探索数千个图表和开源数据，这些数据专注于帮助解决全球问题：
- en: '![](img/b09a8c73-26d4-426d-b9ae-7e5eae3579fa.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b09a8c73-26d4-426d-b9ae-7e5eae3579fa.png)'
- en: With only the few examples I showcased here, you can see that you have access
    to thousands of datasets available to use for research, blending, or learning.
    Be mindful of the open source licenses that may restrict distribution or limit
    how often you can extract the data. This becomes important when building any automated
    data pipelines or using APIs to pull data on demand. You will probably have to
    find alternative paid data companies in those situations. In either case, even
    when the source data is conformed and structured, it may not answer all the questions
    required for your analysis. Another point to note is that the aggregation level
    of the data might not be very high. For example, if data is aggregated by country,
    you can't join the data by city. In those situations, being transparent in terms
    of how you are using the data from external sources is important, along with quoting
    the source and providing a disclaimer stating that external data is being used.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 仅凭这里展示的少数例子，你可以看到你有权访问数千个可用于研究、混合或学习的数据集。请注意可能限制分发或限制你提取数据频率的开源许可证。当构建任何自动化数据管道或使用API按需提取数据时，这一点变得很重要。在这种情况下，你可能不得不寻找替代的付费数据公司。在任何情况下，即使源数据是符合和结构化的，也可能无法回答你分析所需的所有问题。另一个需要注意的点是数据的聚合级别可能不是很高。例如，如果数据按国家聚合，你就不能按城市合并数据。在这些情况下，在如何使用外部数据方面保持透明度很重要，同时引用来源并提供声明，说明正在使用外部数据。
- en: Next, we will cover some best practices that can be used to report the results
    from your analysis.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍一些可以用来报告分析结果的最佳实践。
- en: Reporting results
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 报告结果
- en: How to present your analysis results will vary by the audience, the time available,
    and the level of detail required to tell a story about the data. Your data may
    have an inherent bias, be incomplete, or require more attributes in order to create
    a complete picture, so don't be afraid to include this information in your analysis.
    For example, if you have done some research on climate change, which is a very
    broad topic, presenting the consumers of your analysis with a narrow scope of
    assumptions specific to your dataset is important. How and where you include this
    information is not as important as ensuring it is available for peer review.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如何展示你的分析结果将根据受众、可用时间和所需详细程度来决定，以便讲述数据的故事。你的数据可能存在固有的偏差、不完整，或者需要更多属性来构建完整的画面，因此不要害怕在分析中包含这些信息。例如，如果你对气候变化进行了研究，这是一个非常广泛的话题，向你的分析消费者展示针对你数据集的具体假设的狭窄范围是很重要的。你如何以及在哪里包含这些信息并不像确保它们可供同行评审那样重要。
- en: Storytelling
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讲故事
- en: Storytelling with data requires some practice and you need time to sell your
    message to the audience. Like any good story, presenting the data results in a
    cadence with a beginning, middle, and end will help with the flow of the analysis
    being consumed. I also find using analogies to compare your findings will offer
    some connectivity between the data and the intended consumers. Knowing who you
    are presenting the results of your analysis to is just as important as understanding
    the data itself.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据讲故事需要一些练习，你需要时间来向受众传达你的信息。就像任何好的故事一样，以有开始、中间和结束的节奏展示数据结果将有助于分析内容的流畅性。我还发现使用类比来比较你的发现将在数据与预期消费者之间建立一些联系。了解你向谁展示分析结果与理解数据本身一样重要。
- en: For example, in poker, knowing the probability of your hand and your bankroll
    are not the only factors for success. Who you are playing against is a contributing
    factor to how much you will win or lose. So, understanding the reactions of the
    players at the table will help you make decisions to fold, call, or raise during
    the game.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在扑克牌游戏中，了解你的手牌概率和银行存款并不是成功的唯一因素。你对手的构成是影响你赢或输多少的一个因素。因此，了解桌面上玩家的反应将帮助你做出在游戏中弃牌、跟注或加注的决定。
- en: So, when presenting results, think like a poker player and be mindful of who
    you are presenting your data to in order to convince the audience about your conclusions.
    For example, if you are presenting to senior management, time is limited, so being
    direct, brief, and skipping to the summary results is suggested. If the audience
    is your peers, then walking through the journey of how you came to your conclusions
    will resonate because it builds credibility and trust.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在展示结果时，要像扑克玩家一样思考，并注意你向谁展示数据以便说服观众接受你的结论。例如，如果你向高级管理层展示，时间有限，因此建议直接、简洁，并跳到总结结果。如果观众是你的同侪，那么讲述你得出结论的过程将产生共鸣，因为它建立了信誉和信任。
- en: Regardless of the audience, if you present a chart with trends becoming higher
    over time, be prepared to offer proof of the underlining source, along with how
    the metric was calculated. Without that information, doubt about the ability to
    recreate your findings will lead to your analysis being dismissed.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 无论受众如何，如果你展示的图表随着时间的推移而趋势上升，请准备好提供证明基础来源的证据，以及如何计算该指标。如果没有这些信息，对重现你发现能力的怀疑将导致你的分析被驳回。
- en: A good data analyst will be able to **read the room** and understand how much
    detail is required when presenting results. There have been plenty of times when
    I have presented findings where I had to cut my message short because when I looked
    up to see how engaged the people were, I realized they were lost. Rather than
    continuing, I stopped and offered up questions so I could provide more clarity.
    Just changing the format to offer time for questions in the middle of the presentation
    helped both the audience and myself refocus our attention on the conclusions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个优秀的数据分析师将能够**读懂房间**，并了解在展示结果时需要多少细节。有很多次，我在展示发现时不得不缩短我的信息，因为当我抬头看人们参与度如何时，我意识到他们已经迷失了。与其继续下去，我停下来提出问题，这样我可以提供更多的清晰度。仅仅改变格式，在演示过程中提供提问时间，就帮助了观众和我重新将注意力集中在结论上。
- en: So, be authentic and provide transparency in your analysis. If you make a mistake
    or misinterpret the data, the audience will be forgiving as long as you continue
    to improve and avoid repeating a missed step. I find having peers, mentors, and
    managers who can provide honest and constructive feedback before you present yourself,
    helps improve your messaging and presentation of the data artifacts.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在分析中保持真实并提供透明度。如果你犯了错误或误解了数据，只要你继续改进并避免重复错误步骤，观众就会宽恕你。我发现，在展示自己之前，有能够提供诚实和建设性反馈的同侪、导师和经理，有助于改进你的信息和数据成果的展示。
- en: From a **data literacy** perspective, focus less on the technology used and
    more on the insights gained in your analysis. Realize that the people interpreting
    your results will come from a diverse set of perspectives. A CEO can understand
    a chart of the balance sheet of company financial data but probably does not care
    which NumPy library was used for your analysis. In our final exercise in this
    book, we will create a capstone project with a focus on answering a real-world
    question using data from multiple sources.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 从**数据素养**的角度来看，关注点应放在分析中获得的认识上，而不仅仅是所使用的技术。意识到解读你结果的人将来自不同的视角。CEO可以理解公司财务数据的资产负债表图表，但可能并不关心你分析中使用了哪个NumPy库。在我们这本书的最后一项练习中，我们将创建一个以使用来自多个来源的数据来回答现实世界问题为重点的毕业设计项目。
- en: The Capstone project
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 毕业设计项目
- en: For our real-world dataset example, we are going to use two different sources
    and blend them together using the techniques we've learned throughout this book.
    Since **Know Your Data** (**KYD**) still applies, let's walk through the sources.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的现实世界数据集示例，我们将使用两个不同的来源，并使用我们在本书中学到的技术将它们结合起来。由于**了解你的数据**（**KYD**）仍然适用，让我们来了解一下这些来源。
- en: KYD sources
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KYD来源
- en: The first source is from the World Bank and is a list of green bonds, which
    are used to fund the reduction of carbon emissions and climate-related projects.
    It was downloaded from the website, so it's a snapshot based on a point in time
    stored as a CSV file with 115 rows and 10 columns, including a header.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个来源来自世界银行，是一份绿色债券列表，这些债券用于资助减少碳排放和与气候相关项目。它从网站上下载的，因此是一个基于存储为CSV文件的时间点的快照，包含115行和10列，包括标题。
- en: 'A visual preview of the data in Microsoft Excel can be seen in the following
    screenshot:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下屏幕截图中可以看到Microsoft Excel中数据的视觉预览：
- en: '![](img/44f8155a-c7d3-4463-90d7-7705eeba8666.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/44f8155a-c7d3-4463-90d7-7705eeba8666.png)'
- en: 'The source data has some insights that we can mine through *as is*, such as
    the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 源数据中包含一些我们可以通过直接分析获得的见解，例如以下内容：
- en: How many **bonds** are issued by **Currency?**
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按货币发行的**债券**数量是多少？
- en: What is the total distribution of the bonds by **Currency**?
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 债券的**货币**分布总情况是怎样的？
- en: Which **bonds** are maturing in the next 3, 5, 7, or 10 years?
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些**债券**将在未来3年、5年、7年或10年到期？
- en: However, we have a data gap for the questions related to the local currency
    for the country of issuance. Since currency exchange rates fluctuate daily, there
    are more questions we could answer if we had that information available to join
    by the Currency field. So, our second source of data that we want to work with
    is from the **Humanitarian Data Exchange** (**HDX**) site. This includes the **Foreign
    Exchange** (**FX**) rate by country designated by the currency as it relates to
    the **United States Dollar** (**USD**) by date from `1/4/1999` to `5/7/2020` in
    the date format of M/D/YYYY. This is another CSV file that can be downloaded with
    5,465 rows and 34 columns on a specific date. There is a header row, and the first
    record of data includes metadata tags prefixed with a hash sign, #, which is used
    by the HDX site for metadata management and cataloging.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于发行国与当地货币相关的问题，我们存在数据缺口。由于货币汇率每日波动，如果我们有可用于通过货币字段加入的信息，我们就能回答更多的问题。因此，我们想要处理的第二个数据来源是来自**人道数据交换**（**HDX**）网站的数据。这包括按日期从`1/4/1999`到`5/7/2020`，以M/D/YYYY日期格式指定的货币作为基准的**外汇**（**FX**）汇率。这是一个可以下载的CSV文件，包含5,465行和34列，在特定日期上。文件中有一行标题，数据的第一条记录包括以井号（#）为前缀的元数据标签，这些标签由HDX网站用于元数据管理和编目。
- en: 'A visual preview of the data in Microsoft Excel can be seen in the following
    screenshot:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了在Microsoft Excel中的数据视觉预览：
- en: '![](img/5fa20245-f3b0-49a3-b7d2-ed686d00b10e.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5fa20245-f3b0-49a3-b7d2-ed686d00b10e.png)'
- en: Previewing data in Microsoft Excel or any spreadsheet tool is a best practice
    if you wish to visually understand the structure of the data before working with
    it in Jupyter Notebook. If the data volumes are large, break off a sample so it
    can be loaded on your workstation.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Jupyter Notebook处理数据之前，如果希望直观地了解数据的结构，在Microsoft Excel或任何电子表格工具中预览数据是一种最佳实践。如果数据量很大，可以提取样本以便在工作站上加载。
- en: So, our bonds data with currencies lists the values by rows and our FX rate
    data is listing the values for each currency by column with a value assigned for
    each specific date. There are a few ways to solve this but for our example, we
    are interested in blending the latest FX rate by currency to our bond data so
    that we can convert the **USD Equivalent** value into the **Local CCY Equivalent**.
    That way, we can perform analysis of the data in either USD or the respective
    country's currency and report the findings.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的债券数据按行列出值，我们的FX汇率数据则是按列列出每种货币的值，并为每个特定日期分配一个值。有几种方法可以解决这个问题，但以我们的示例为例，我们感兴趣的是将最新的FX汇率按货币与我们的债券数据混合，以便将**美元等值**转换为**当地货币等值**。这样，我们就可以在美元或相关国家的货币中进行数据分析，并报告结果。
- en: Exercise
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: 'Let''s open a new Jupyter Notebook session and get started:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打开一个新的Jupyter Notebook会话并开始：
- en: 'We are going to import the libraries required to work with and analyze the
    results by including the following commands:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将导入所需的库以处理和分析结果，包括以下命令：
- en: '[PRE0]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will read in the first `.csv` file using the `pandas` library and assign
    the result to a variable named `df_greenbonds`:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`pandas`库读取第一个`.csv`文件，并将结果分配给名为`df_greenbonds`的变量：
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Be sure to upload the source CSV file in the correct file location so that you
    can reference it in your Jupyter Notebook.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 确保将源CSV文件上传到正确的文件位置，以便在Jupyter Notebook中引用它。
- en: 'To validate all the records have loaded successfully, we need to run a `shape()`
    function against the DataFrame:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了验证所有记录都已成功加载，我们需要在DataFrame上运行一个`shape()`函数：
- en: '[PRE2]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output will look as follows, where the values `115` and `10` will be displayed.
    These match the number of rows and columns in the source CSV file:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中将显示值`115`和`10`。这些值与源CSV文件中的行数和列数相匹配：
- en: '![](img/bada3bff-2665-4c0b-907d-548e9c7b298f.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bada3bff-2665-4c0b-907d-548e9c7b298f.png)'
- en: 'To preview the DataFrame, we can run the following `head()` function:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要预览DataFrame，我们可以运行以下`head()`函数：
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output will look as follows, where the DataFrame results will be displayed
    in the Notebook:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中DataFrame的结果将在Notebook中显示：
- en: '![](img/7f52c4c7-6f01-4706-b86f-ef1e63ddb8ed.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7f52c4c7-6f01-4706-b86f-ef1e63ddb8ed.png)'
- en: 'We will read in the second CSV file using the `pandas` library and assign the
    result to a variable named `df_fx_rates`:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用 `pandas` 库读取第二个 CSV 文件，并将结果分配给名为 `df_fx_rates` 的变量：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Be sure to upload the source CSV file to the correct file location so that you
    can reference it in your Jupyter Notebook.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 确保将源 CSV 文件上传到正确的文件位置，以便你可以在 Jupyter Notebook 中引用它。
- en: 'To validate all the records have loaded successfully, run a `shape()` function
    against the DataFrame:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了验证所有记录都已成功加载，请在 DataFrame 上运行一个 `shape()` 函数：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output will look as follows, where the values `5464` and `34` will be displayed
    in parentheses. These match the number of rows and columns in the source CSV file:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中值 `5464` 和 `34` 将显示在括号中。这些值与源 CSV 文件中的行数和列数相匹配：
- en: '![](img/eb736af9-b7b4-4988-98bc-b649b6a4d695.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/eb736af9-b7b4-4988-98bc-b649b6a4d695.png)'
- en: 'To preview the DataFrame, we can run the following `head()` function:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了预览 DataFrame，我们可以运行以下 `head()` 函数：
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output will look as follows, where the DataFrame results will be displayed
    in the Notebook:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中 DataFrame 结果将在 Notebook 中显示：
- en: '![](img/0157ac3b-a660-434d-a8ee-3a5f90472b42.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0157ac3b-a660-434d-a8ee-3a5f90472b42.png)'
- en: 'Since we know from the prior chapters that data is inherently messy and requires
    some cleanup, we will delete the first row because it contains the HDX hashtag
    metadata values, which are not required for our analysis:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们知道从前面的章节中数据本身是杂乱的，需要一些清理，我们将删除第一行，因为它包含 HDX 标签元数据值，这些值对于我们的分析不是必需的：
- en: '[PRE7]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It is recommended that you clean up as you go through the analysis step by step
    in case you need to troubleshoot and recreate any prior steps in the data analysis
    workflow.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 建议你在分析步骤中逐步清理，以防需要调试并重新创建数据分析工作流程中的任何先前步骤。
- en: 'The output will look as follows, where the DataFrame results will be displayed
    in the Notebook:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中 DataFrame 结果将在 Notebook 中显示：
- en: '![](img/207cab68-a260-4634-9d3b-17becd4eb3e3.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/207cab68-a260-4634-9d3b-17becd4eb3e3.png)'
- en: 'For our analysis, we want to focus on the latest FX rate available in the file.
    You could take the first row available in the DataFrame, but a more robust method
    would be to use the `max()` function so that how the data is sorted becomes irrelevant.
    To verify that the correct value will work before we filter the DataFrame, use
    the following command:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们的分析，我们希望关注文件中可用的最新 FX 汇率。你可以取 DataFrame 中的第一行，但更稳健的方法是使用 `max()` 函数，这样数据的排序方式就无关紧要了。在过滤
    DataFrame 之前，为了验证正确的值将工作，请使用以下命令：
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output will look as follows, where the results from the command will be
    displayed in the Notebook. In this dataset, the max date at the time of download
    is `2020-05-07`, with the date format as `YYYY-MM-DD`:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中命令的结果将在 Notebook 中显示。在此数据集中，下载时的最大日期是 `2020-05-07`，日期格式为 `YYYY-MM-DD`：
- en: '![](img/ad385d86-1983-4768-ba44-59ed153e846d.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ad385d86-1983-4768-ba44-59ed153e846d.png)'
- en: 'From the prior step, we are confident that our filter will use the correct
    `Date` value, so we will create a new DataFrame with only one specific date value
    so that we can join the results in later steps. The new DataFrame is named `df_fx_rates_max_date`
    and is a result of filtering the original DataFrame, named `df_fx_rates`, by the
    `Date` field, where only the calculated max `Date` value will be returned. We
    will add the following `head()` function to validate the results in the Notebook:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上一步中，我们确信我们的过滤器将使用正确的 `Date` 值，因此我们将创建一个新的 DataFrame，其中只包含一个特定的日期值，以便在后续步骤中合并结果。新的
    DataFrame 命名为 `df_fx_rates_max_date`，它是通过 `Date` 字段过滤原始 DataFrame `df_fx_rates`
    的结果，其中只返回计算出的最大 `Date` 值。我们将在 Notebook 中添加以下 `head()` 函数以验证结果：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output will look as follows, where the results from the command will be
    displayed in the Notebook. The new DataFrame, named `df_fx_rates_max_date`, will
    only have one record with a header containing 34 columns. Each column will represent
    the latest available currency value using the three-letter country''s designation,
    such as `EUR`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中命令的结果将在 Notebook 中显示。新的 DataFrame，命名为 `df_fx_rates_max_date`，将只有一个包含
    34 列的记录。每一列将代表使用三位国家代码的最新可用货币值，例如 `EUR`：
- en: '![](img/2b1883d9-90d4-407a-b20d-7fb90fcc302c.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2b1883d9-90d4-407a-b20d-7fb90fcc302c.png)'
- en: 'We still have more work to do in order to join this data to our original bond
    DataFrame. We need to transform it using the `transpose()` function, which will
    change all the columns into rows. In other technologies, this concept is called
    a pivot, crosstab, or crosstable; this was covered in more detail in [Chapter
    4](c6eceec8-e006-404b-9be1-bc96de29991a.xhtml),*Creating Your First pandas DataFrame*.
    The results are stored in a new DataFrame called `df_rates_transposed`. We rename
    the columns to make it easier to work with them. We also need to run the following `head()`
    command to preview the results:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们仍然需要更多的工作来将此数据与我们的原始债券 DataFrame 合并。我们需要使用 `transpose()` 函数对其进行转换，这将所有列转换为行。在其他技术中，这个概念被称为
    pivot、crosstab 或 crosstable；这在 [第 4 章](c6eceec8-e006-404b-9be1-bc96de29991a.xhtml)“创建您的第一个
    pandas DataFrame”中已有更详细的介绍。结果存储在一个名为 `df_rates_transposed` 的新 DataFrame 中。我们重命名列以使其更容易处理。我们还需要运行以下
    `head()` 命令来预览结果：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output will look as follows, where the new DataFrame, named `df_rates_transposed`,
    is displayed. Here, all the columns have been converted into rows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中新的 DataFrame，命名为 `df_rates_transposed`，被显示。在这里，所有列都已被转换为行：
- en: '![](img/4767865b-6765-4e5d-9f19-c50afe379b74.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4767865b-6765-4e5d-9f19-c50afe379b74.png)'
- en: 'The goal is for our reference table to have all the FX rates by currency values
    in the same format. However, notice that, on the first row in the following diagram, the
    `Date` value is mixed with `Currency_values`, which need to have the same data
    type. The need to have conformed and consistent data values represented in structured
    data has been reinforced throughout this book, so we will clean up the DataFrame
    by dropping the `Date` record. We will also use the `reindex()` function to make
    it easier to join in the next step and then run the following `head()` command
    to verify the results:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目标是使我们的参考表具有所有按货币值排列的外汇汇率，并且格式相同。然而，请注意，在以下图表的第一行中，`Date` 值与需要具有相同数据类型的 `Currency_values`
    混合在一起。在整个本书中，需要将符合和一致的数据值表示为结构化数据的需求得到了加强，因此我们将通过删除 `Date` 记录来清理 DataFrame。我们还将使用
    `reindex()` 函数使其在下一步中更容易连接，然后运行以下 `head()` 命令来验证结果：
- en: '[PRE11]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output will look as follows, where the new DataFrame, named `df_rates_transposed`,
    is displayed as before, except now, the `Date` record has been deleted. This means
    the first row will be `EUR` with a `Currency_Value` of `1.0783`:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中新的 DataFrame，命名为 `df_rates_transposed`，显示方式与之前相同，但现在已删除 `Date` 记录。这意味着第一行将是
    `EUR`，其 `Currency_Value` 为 `1.0783`：
- en: '![](img/909df028-ecd0-4dae-8ed1-a2fa8a8e42dc.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/909df028-ecd0-4dae-8ed1-a2fa8a8e42dc.png)'
- en: 'We are now ready to join the transformed and cleaned FX rates to our original
    bonds source using the common `Currency` join key field. Because we want all the
    records from the `df_greenbonds` source and only the matching values from `df_rates_transposed`,
    we will use a left join. To display and verify the results, we use the following `head()`
    command:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经准备好使用共同的 `Currency` 连接键字段将转换和清洗后的外汇汇率与我们的原始债券源合并。因为我们希望从 `df_greenbonds`
    源获取所有记录，并且只匹配 `df_rates_transposed` 中的值，所以我们将使用左连接。为了显示和验证结果，我们使用以下 `head()` 命令：
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output will look as follows, where the results of the left join are stored
    in the `df_greenbonds_revised` DataFrame. The following screenshot shows a table
    with 5 rows and 11 columns. It includes a header row and index values that are
    not labeled:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中左连接的结果存储在 `df_greenbonds_revised` DataFrame 中。以下截图显示了一个包含 5 行和 11
    列的表格。它包括一个标题行和未标记的索引值：
- en: '![](img/d3fb925a-3455-4a43-a0a6-f3b4a28f4e38.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d3fb925a-3455-4a43-a0a6-f3b4a28f4e38.png)'
- en: Like in the preceding diagram, be sure to scroll to the right to see that a
    new column called `Currency_Value` is included.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，请确保向右滚动以查看包括了一个名为 `Currency_Value` 的新列。
- en: 'An advantage of constantly running the `head()` command to validate results
    in each step is that you can make observations about the data as you prepare and
    clean it for further analysis. In the preceding screenshot , we can see a `null()` value
    in `Currency_Value`, which is displayed as `NaN`. We covered working with NaN
    values in [Chapter 5](bea8a62c-4469-47e3-a668-10fbb91815ea.xhtml),*Gathering and
    Loading Data in Python*. This is a result of the left join and is expected because
    there was no value of `USD` in the FX rates source data. This makes sense because
    you don''t need to convert the currency of USD. However, this will have an impact
    when we attempt to create calculations from the values in this column. The solution,
    in this case, is to just convert all the `NaN` values to `1` because the FX rate
    conversion for USD is 1\. There will be no output after running this command:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 持续运行`head()`命令以验证每一步的结果的优势在于，你可以在准备和清理数据以进行进一步分析的同时对数据进行观察。在先前的屏幕截图中，我们可以看到`Currency_Value`中的`null()`值，显示为`NaN`。我们在[第5章](bea8a62c-4469-47e3-a668-10fbb91815ea.xhtml)中介绍了如何处理NaN值，*在Python中收集和加载数据*。这是由于左连接的结果，这是预期的，因为FX汇率源数据中没有`USD`的值。这很有道理，因为你不需要转换美元的货币。然而，当我们尝试从这个列的值中创建计算时，这将会产生影响。在这种情况下，解决方案是将所有的`NaN`值转换为`1`，因为美元的FX汇率转换是1。运行此命令后不会有输出：
- en: '[PRE13]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Since our CSV file sources do not include a data dictionary, the defined data
    type for each field is unknown. We can solve any inconsistencies within the data
    values by applying the `astype()` function. We will focus on the two columns we
    used for calculating the local currency rate by converting them into a `dtype`
    of the `float` type. There will be no output after running this command:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们的CSV文件源不包括数据字典，因此每个字段的定义数据类型是未知的。我们可以通过应用`astype()`函数来解决数据值中的任何不一致。我们将关注我们用于计算本地货币率的两个列，将它们转换为`float`类型的`dtype`。运行此命令后不会有输出：
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We are now ready to create a new calculated column in our existing DataFrame
    that will divide the `USD Equivalent` column by `Currency_Value`. The result will
    be stored in a new column named `Local CCY` in the same DataFrame. There will
    be no output after running this command:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已准备好在现有的DataFrame中创建一个新的计算列，该列将`USD Equivalent`列除以`Currency_Value`。结果将存储在同一DataFrame中的新列`Local
    CCY`中。运行此命令后不会有输出：
- en: '[PRE15]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, we can convert the data types of the specific columns back into integers
    and focus our attention on the key columns by explicitly identifying them. We
    can do this by using the following commands:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以将特定列的数据类型转换回整数，并通过明确标识它们来关注关键列。我们可以通过以下命令来完成：
- en: '[PRE16]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output will look as follows, where the results from the preceding commands
    will be displayed in the Notebook. The original column, `USD Equivalent`, is displayed
    as an integer and we now have the `Local CCY` column available to the right of
    `Currency_Value`:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中前面命令的结果将在笔记本中显示。原始列“美元等值”以整数形式显示，现在我们可以在“货币值”右侧看到“本地货币”列：
- en: '![](img/61e98320-646e-48fa-9bff-8a19b9877049.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/61e98320-646e-48fa-9bff-8a19b9877049.png)'
- en: 'To analyze the results, let''s group the data by `Currency` and only sum the
    values for both the `USD Equivalent` and `Local CCY` fields using the following
    commands:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了分析结果，让我们按`货币`对数据进行分组，并使用以下命令仅对`USD Equivalent`和`Local CCY`字段求和：
- en: '[PRE17]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output will look as follows, where the data is now aggregated by `Currency`,
    with the total sum of `USD Equivalent` and `Local CCY` also being displayed:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中数据现在按`货币`聚合，同时还会显示`USD Equivalent`和`Local CCY`的总和：
- en: '![](img/547ec7ea-af5e-466d-af9e-725a732d4f33.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/547ec7ea-af5e-466d-af9e-725a732d4f33.png)'
- en: 'Another type of analysis would be to see how the data is distributed by `Currency`
    visually by creating a horizontal bar chart using the `matplotlib` library''s `plot()`
    function:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一种分析类型是，通过使用`matplotlib`库的`plot()`函数创建水平条形图来直观地查看数据按`货币`的分布情况：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output will look as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![](img/6b65612c-0f3b-435a-9b33-2c82427cfd0e.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6b65612c-0f3b-435a-9b33-2c82427cfd0e.png)'
- en: As you can see, an overwhelming number of green bonds have been issued in USD
    because it has the largest bar by a large margin compared to the other currencies.
    The reason why this is the case is not evident by looking exclusively at this
    data, so additional analysis will need to be done. When you present your findings
    to others within the organization, this is often the reality, where blending data
    together offers more insights but then leads to more unanswered questions. This,
    in turn, leads to the need for more data to be added to your existing sources.
    Finding a balance between when to stop blending more and more data together is
    challenging, so adding incremental milestones to present your findings is encouraged.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，大量的绿色债券是以美元发行的，因为与其他货币相比，它拥有最大的条形图，并且差距很大。仅通过查看这些数据，无法明显看出这种情况的原因，因此需要进一步的分析。当你向组织内部的其他人展示你的发现时，这通常是现实情况，将数据混合在一起可以提供更多见解，但同时也导致了更多未解决的问题。这反过来又导致了需要将更多数据添加到现有来源中的需求。在何时停止混合更多数据之间找到平衡是具有挑战性的，因此鼓励添加增量里程碑来展示你的发现。
- en: Summary
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: With that, we have walked through many of the different concepts we covered
    throughout this book in one comprehensive exercise. In this chapter, we learned
    more about real-world data sources that can be used for analysis. We also created
    a repeatable workflow that can be summarized as a workflow that collects external
    data sources, joins them together, and then analyzes the results. Since we know
    the reality of working with data is never that straightforward, we walked through
    some inherent challenges of working with it. We have broken down the steps of
    collecting multiple sources, transforming them, and cleansing, joining, grouping,
    and visualizing the results. The more you work hands-on with data, the easier
    it is to apply these concepts to any dataset with the foundation remaining constant.
    As you increase your data literacy skills when it comes to working with data,
    you will notice the syntax and tools will change but that the challenges and opportunities
    to solve problems remain the same. I encourage you to continue investing in yourself
    by continuously learning more about data. I hope you find it as fulfilling a journey
    as I do!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经在一项综合练习中走过了这本书中涵盖的许多不同概念。在本章中，我们更多地了解了可用于分析的现实世界数据源。我们还创建了一个可重复的工作流程，可以概括为：收集外部数据源，将它们合并在一起，然后分析结果。由于我们知道与数据打交道的现实情况永远不会那么简单直接，所以我们探讨了与之相关的固有挑战。我们将收集多个来源的步骤、转换它们、清洗、合并、分组和可视化结果的过程进行了分解。你越是在实际操作中与数据打交道，就越容易将这些概念应用到任何数据集上，同时保持基础不变。当你在处理数据时提高你的数据素养技能，你会注意到语法和工具会发生变化，但解决问题的挑战和机遇保持不变。我鼓励你通过持续学习更多关于数据的知识来继续投资自己。我希望你发现这是一段像我一样充实的人生旅程！
- en: Further reading
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: The Humanitarian Data Exchange site: [https://data.humdata.org/](https://data.humdata.org/)
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人道主义数据交换网站：[https://data.humdata.org/](https://data.humdata.org/)
- en: Data.gov – the US government's open data: [https://www.data.gov/](https://www.data.gov/)
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Data.gov – 美国政府的开放数据：[https://www.data.gov/](https://www.data.gov/)
- en: The Creative Commons site: [https://creativecommons.org/](https://creativecommons.org/)
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创意共享网站：[https://creativecommons.org/](https://creativecommons.org/)
- en: The Open Data Commons site: [https://opendatacommons.org/](https://opendatacommons.org/)
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开放数据公共网站：[https://opendatacommons.org/](https://opendatacommons.org/)
- en: 'The Our World in Data site: [https://ourworldindata.org/](https://ourworldindata.org/)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的世界数据网站：[https://ourworldindata.org/](https://ourworldindata.org/)
- en: The World Bank Open Data site: [https://data.worldbank.org/](https://data.worldbank.org/)
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 世界银行开放数据网站：[https://data.worldbank.org/](https://data.worldbank.org/)
