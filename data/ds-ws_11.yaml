- en: 11\. Data Preparation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11. 数据准备
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: By the end of this chapter you will be able to filter DataFrames with specific
    conditions; remove duplicate or irrelevant records or columns; convert variables
    into different data types; replace values in a column and handle missing values
    and outlier observations.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你将能够根据特定条件筛选DataFrame；删除重复或无关的记录或列；将变量转换为不同的数据类型；替换列中的值，并处理缺失值和异常值。
- en: This chapter will introduce you to the main techniques you can use to handle
    data issues in order to achieve high quality for your dataset prior to modeling
    it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍你可以用来处理数据问题的主要技术，以便在建模之前实现数据集的高质量。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapter, you saw how critical it was to get a very good understanding
    of your data and learned about different techniques and tools to achieve this
    goal. While performing **Exploratory Data Analysis** (**EDA**) on a given **dataset**,
    you may find some potential issues that need to be addressed before the modeling
    stage. This is exactly the topic that will be covered in this chapter. You will
    learn how you can handle some of the most frequent data quality issues and prepare
    the dataset properly.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你看到了了解数据的重要性，并学到了不同的技术和工具来实现这一目标。在对给定的**数据集**进行**探索性数据分析**（**EDA**）时，你可能会发现一些潜在的问题，在建模阶段之前需要解决。正是本章将讨论的内容，你将学习如何处理一些最常见的数据质量问题，并适当准备数据集。
- en: This chapter will introduce you to the issues that you will encounter frequently
    during your data scientist career (such as **duplicated** **rows**, incorrect
    data types, incorrect values, and missing values) and you will learn about the
    techniques you can use to easily fix them. But be careful – some issues that you
    come across don't necessarily need to be fixed. Some of the suspicious or unexpected
    values you find may be genuine from a business point of view. This includes values
    that crop up very rarely but are totally genuine. Therefore, it is extremely important
    to get confirmation either from your stakeholder or the data engineering team
    before you alter the dataset. It is your responsibility to make sure you are making
    the right decisions for the business while preparing the dataset.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将向你介绍在数据科学家职业生涯中经常遇到的一些问题（如**重复行**、错误的数据类型、错误的值和缺失值），并介绍你可以使用的技术来轻松解决这些问题。但要小心——你遇到的一些问题不一定需要修复。你发现的一些可疑或意外值可能在业务角度上是合理的。这些可能是非常罕见但完全真实的值。因此，在修改数据集之前，与你的相关方或数据工程团队确认非常重要。确保你在准备数据集时为业务做出正确的决策是你的责任。
- en: For instance, in *Chapter 10*, *Analyzing a Dataset*, you looked at the *Online
    Retail dataset*, which had some negative values in the `Quantity` column. Here,
    we expected only positive values. But before fixing this issue straight away (by
    either dropping the records or transforming them into positive values), it is
    preferable to get in touch with your stakeholders first and get confirmation that
    these values are not significant for the business. They may tell you that these
    values are extremely important as they represent returned items and cost the company
    a lot of money, so they want to analyze these cases in order to reduce these numbers.
    If you had moved to the data cleaning stage straight away, you would have missed
    this critical piece of information and potentially came up with incorrect results.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，在*第10章*，*数据集分析*中，你查看了*在线零售数据集*，该数据集中`Quantity`列有一些负值。这里我们期望的是只有正值。但在直接解决这个问题（比如删除记录或将其转换为正值）之前，最好先与相关方沟通，确认这些值对于业务来说是否不重要。他们可能会告诉你，这些值非常重要，因为它们代表了退货商品，并且给公司带来了巨大的成本，所以他们希望分析这些情况，以减少这些数字。如果你直接进入数据清洗阶段，你可能会错过这一关键信息，进而得出错误的结论。
- en: Handling Row Duplication
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理行重复问题
- en: Most of the time, the datasets you will receive or have access to will not have
    been 100% cleaned. They usually have some issues that need to be fixed. One of
    these issues could be duplicated rows. Row duplication means that several observations
    contain the exact same information in the dataset. With the `pandas` package,
    it is extremely easy to find these cases.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，你收到或能访问的数据集可能并非100%清洁。它们通常存在一些需要修复的问题。其中一个问题可能是行重复。行重复意味着数据集中有几条记录包含完全相同的信息。使用`pandas`包，你可以非常轻松地找到这些情况。
- en: Let's use the example that we saw in *Chapter 10*, *Analyzing a Dataset*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用在*第10章*中看到的例子，*分析数据集*。
- en: 'Start by **importing** the dataset into a DataFrame:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 首先**导入**数据集到DataFrame：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `duplicated()` method from `pandas` checks whether any of the rows are
    duplicates and returns a `True` if the row is a duplicate and `False` if not:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`的`duplicated()`方法检查行是否为重复项，如果是重复项则返回`True`，否则返回`False`：'
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You should get the following output:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 11.1: Output of the duplicated() method'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.1：duplicated()方法的输出](img/B15019_11_01.jpg)'
- en: '](img/B15019_11_01.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_01.jpg)'
- en: 'Figure 11.1: Output of the duplicated() method'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1：duplicated()方法的输出
- en: Note
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The outputs in this chapter have been truncated to effectively use the page
    area.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的输出已被截断，以便有效地使用页面空间。
- en: 'In Python, the `True` and `False` binary values correspond to the numerical
    values 1 and 0, respectively. To find out how many rows have been identified as
    duplicates, you can use the `sum()` method on the output of `duplicated()`. This
    will add all the 1s (that is, `True` values) and gives us the count of duplicates:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，`True`和`False`这两个二进制值分别对应数值1和0。为了找出有多少行被标记为重复项，你可以在`duplicated()`的输出上使用`sum()`方法。这将把所有的1（即`True`值）加起来，从而给出重复项的数量：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You should get the following output:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Since the output of the `duplicated()` method is a `pandas` series of binary
    values for each row, you can also use it to subset the rows of a DataFrame. The
    `pandas` package provides different APIs for subsetting a DataFrame, as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`duplicated()`方法的输出是一个`pandas`系列，每一行对应一个二进制值，你也可以利用它来对子集化DataFrame的行。`pandas`包提供了不同的API来对子集化DataFrame，具体如下：
- en: df[<rows> or <columns>]
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: df[<行>或<列>]
- en: df.loc[<rows>, <columns>]
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: df.loc[<行>, <列>]
- en: df.iloc[<rows>, <columns>]
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: df.iloc[<行>, <列>]
- en: 'The first API subsets the DataFrame by `InvoiceNo`, `StockCode`, `InvoiceDate`,
    and `CustomerID`, you need to use the following code:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个API通过`InvoiceNo`、`StockCode`、`InvoiceDate`和`CustomerID`对DataFrame进行子集化，你需要使用如下代码：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You should get the following output:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 11.2: Subsetting columns'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.2：子集化列](img/B15019_11_02.jpg)'
- en: '](img/B15019_11_02.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_03.jpg)'
- en: 'Figure 11.2: Subsetting columns'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2：子集化列
- en: 'If you only want to filter the rows that are considered duplicates, you can
    use the same API call with the output of the `duplicated()` method. It will only
    keep the rows with **True** as a value:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只想过滤掉被认为是重复的行，可以在`duplicated()`方法的输出上使用相同的API调用。它将只保留值为**True**的行：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should get the following output:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 11.3: Subsetting the duplicated rows'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.3：子集化重复行](img/B15019_11_03.jpg)'
- en: '](img/B15019_11_03.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_03.jpg)'
- en: 'Figure 11.3: Subsetting the duplicated rows'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3：子集化重复行
- en: 'If you want to subset the rows and columns at the same time, you must use one
    of the other two available APIs: `.loc` or `.iloc`. These APIs do the exact same
    thing but `.loc` uses labels or names while `.iloc` only takes indices as input.
    You will use the `.loc` API to subset the duplicated rows and keep only the selected
    four columns, as shown in the previous example:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想同时对子集化行和列，必须使用其他两个可用的API之一：`.loc`或`.iloc`。这两个API功能相同，但`.loc`使用标签或名称，而`.iloc`仅接受索引作为输入。你将使用`.loc`
    API来子集化重复行，并只保留选定的四列，正如前面的示例所示：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should get the following output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 11.4: Subsetting the duplicated rows and selected columns using .loc'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.4：使用.loc子集化重复行和选定的列](img/B15019_11_02.jpg)'
- en: '](img/B15019_11_04.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_04.jpg)'
- en: 'Figure 11.4: Subsetting the duplicated rows and selected columns using .loc'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4：使用.loc子集化重复行和选定的列
- en: 'This preceding output shows that the first few duplicates are row numbers `517`,
    `527`, `537`, and so on. By default, `pandas` doesn''t mark the first occurrence
    of duplicates as duplicates: all the same, duplicates will have a value of `True`
    except for the first occurrence. You can change this behavior by specifying the
    `keep` parameter. If you want to keep the last duplicate, you need to specify
    `keep=''last''`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出显示，前几个重复项的行号分别为`517`、`527`、`537`等。默认情况下，`pandas`不会将重复项的第一次出现标记为重复：所有的重复项除了第一次出现外，其余都会标记为`True`。你可以通过指定`keep`参数来改变这个行为。如果你想保留最后一个重复项，你需要指定`keep='last'`：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You should get the following output:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 11.5: Subsetting the last duplicated rows'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.5：子集化最后的重复行](img/B15019_11_04.jpg)'
- en: '](img/B15019_11_05.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_05.jpg)'
- en: 'Figure 11.5: Subsetting the last duplicated rows'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5：子集化最后的重复行
- en: 'As you can see from the previous outputs, row `485` has the same value as row
    `539`. As expected, row `539` is not marked as a duplicate anymore. If you want
    to mark all the duplicate records as duplicates, you will have to use `keep=False`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出可以看到，行 `485` 的值与行 `539` 相同。正如预期的那样，行 `539` 不再被标记为重复行。如果你想标记所有重复记录为重复，你需要使用
    `keep=False`：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should get the following output:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.6: Subsetting all the duplicated rows'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.6：获取所有重复行的子集'
- en: '](img/B15019_11_06.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_06.jpg)'
- en: 'Figure 11.6: Subsetting all the duplicated rows'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6：获取所有重复行的子集
- en: This time, rows `485` and `539` have been listed as duplicates. Now that you
    know how to identify duplicate observations, you can decide whether you wish to
    remove them from the dataset. As we mentioned previously, you must be careful
    when changing the data. You may want to confirm with the business that they are
    comfortable with you doing so. You will have to explain the reason why you want
    to remove these rows. In the Online Retail dataset, if you take rows `485` and
    `539` as an example, these two observations are identical. From a business perspective,
    this means that a specific customer (`CustomerID 17908`) has bought the same item
    (`StockCode 22111`) at the exact same date and time (`InvoiceDate 2010-12-01 11:45:00`)
    on the same invoice (`InvoiceNo 536409`). This is highly suspicious. When you're
    talking with the business, they may tell you that new software was released at
    that time and there was a bug that was splitting all the purchased items into
    single-line items.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，行 `485` 和 `539` 被标记为重复行。现在你已经知道如何识别重复观察值，你可以决定是否要将它们从数据集中删除。如前所述，修改数据时必须小心。你可能需要向业务方确认，他们是否同意你删除这些数据行。你需要解释为什么要删除这些行。在在线零售数据集中，以行
    `485` 和 `539` 为例，这两条记录是完全相同的。从业务角度来看，这意味着一个特定的客户（`CustomerID 17908`）在同一个发票（`InvoiceNo
    536409`）上，在完全相同的日期和时间（`InvoiceDate 2010-12-01 11:45:00），购买了相同的商品（`StockCode 22111`）。这非常可疑。在与业务方沟通时，他们可能会告诉你，在那个时候发布了新软件，并且有一个BUG导致所有购买的商品都被拆分成单独的行项目。
- en: In this case, you know that you shouldn't remove these rows. On the other hand,
    they may tell you that duplication shouldn't happen and that it may be due to
    human error as the data was entered or during the data extraction step. Let's
    assume this is the case; now, it is safe for you to remove these rows.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你知道不应该删除这些行。另一方面，他们可能会告诉你重复不应该发生，可能是由于人工错误，在数据录入或数据提取步骤中发生了问题。假设确实是这种情况，那么现在可以安全地删除这些行。
- en: 'To do so, you can use the `drop_duplicates()` method from `pandas`. It has
    the same `keep` parameter as `duplicated()`, which specifies which duplicated
    record you want to keep or if you want to remove all of them. In this case, we
    want to keep at least one duplicate row. Here, we want to keep the first occurrence:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，你可以使用 `pandas` 的 `drop_duplicates()` 方法。它有与 `duplicated()` 相同的 `keep` 参数，用于指定你希望保留哪个重复记录，或者是否希望删除所有重复记录。在这种情况下，我们希望保留至少一行重复数据。这里，我们希望保留第一次出现的重复行：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You should get the following output:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.7: Dropping duplicate rows with keep=''first'''
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.7：使用 `keep=''first''` 删除重复行'
- en: '](img/B15019_11_07.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_07.jpg)'
- en: 'Figure 11.7: Dropping duplicate rows with keep=''first'''
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7：使用 `keep='first'` 删除重复行
- en: The output of this method is a new DataFrame that contains unique records where
    only the first occurrence of duplicates has been kept. If you want to replace
    the existing DataFrame rather than getting a new DataFrame, you need to use the
    `inplace=True` parameter.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的输出是一个新的 DataFrame，其中包含唯一的记录，只有第一次出现的重复项被保留。如果你希望替换现有的 DataFrame，而不是获得一个新的
    DataFrame，则需要使用 `inplace=True` 参数。
- en: 'The `drop_duplicates()` and `duplicated()` methods also have another very useful
    parameter: `subset`. This parameter allows you to specify the list of columns
    to consider while looking for duplicates. By default, all the columns of a DataFrame
    are used to find duplicate rows. Let''s see how many duplicate rows there are
    while only looking at the `InvoiceNo`, `StockCode`, `invoiceDate`, and `CustomerID`
    columns:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`drop_duplicates()` 和 `duplicated()` 方法还有一个非常有用的参数：`subset`。这个参数允许你在查找重复项时指定要考虑的列列表。默认情况下，DataFrame
    的所有列都会用来查找重复行。我们来看一下仅查看 `InvoiceNo`、`StockCode`、`invoiceDate` 和 `CustomerID` 列时，有多少重复行：'
- en: '[PRE10]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You should get the following output:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: By looking only at these four columns instead of all of them, we can see that
    the number of duplicate rows has increased from `5268` to `10677`. This means
    that there are rows that have the exact same values as these four columns but
    have different values in other columns, which means they may be different records.
    In this case, it is better to use all the columns to identify duplicate records.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 仅查看这四列，而不是所有列，我们可以看到重复行的数量已从`5268`增加到`10677`。这意味着有些行在这四列的值完全相同，但在其他列的值不同，可能是不同的记录。在这种情况下，最好使用所有列来识别重复记录。
- en: 'Exercise 11.01: Handling Duplicates in a Breast Cancer Dataset'
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习11.01：处理乳腺癌数据集中的重复数据
- en: 'In this exercise, you will learn how to identify duplicate records and how
    to handle such issues so that the dataset only contains **unique** records. Let''s
    get started:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你将学习如何识别重复记录，以及如何处理这些问题，使得数据集仅包含**唯一**记录。让我们开始吧：
- en: Note
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The dataset that we''re using in this exercise is the Breast Cancer Detection
    dataset, which has been shared by Dr. William H. Wolberg from the University of
    Wisconsin Hospitals and is hosted by the UCI Machine Learning Repository. The
    attribute information for this dataset can be found here: [https://packt.live/39LaIDx](https://packt.live/39LaIDx).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本练习中使用的数据集是乳腺癌检测数据集，分享者是来自威斯康星大学医院的Dr. William H. Wolberg，并由UCI机器学习库托管。该数据集的属性信息可以在此找到：[https://packt.live/39LaIDx](https://packt.live/39LaIDx)。
- en: 'This dataset can also be found in this book''s GitHub repository: [https://packt.live/2QqbHBC](https://packt.live/2QqbHBC).'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集也可以在本书的GitHub仓库中找到：[https://packt.live/2QqbHBC](https://packt.live/2QqbHBC)。
- en: Open a new **Colab** notebook.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的**Colab**笔记本。
- en: 'Import the `pandas` package:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`包：
- en: '[PRE12]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Assign the link to the `Breast Cancer` dataset to a variable called `file_url`:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Breast Cancer`数据集的链接赋值给一个名为`file_url`的变量：
- en: '[PRE13]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Using the `read_csv()` method from the `pandas` package, load the dataset into
    a new variable called `df` with the `header=None` parameter. We''re doing this
    because this file doesn''t contain column names:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`包中的`read_csv()`方法，加载数据集到一个名为`df`的新变量，并使用`header=None`参数。我们这么做是因为该文件没有列名：
- en: '[PRE14]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create a variable called `col_names` that contains the names of the columns:
    `Sample code number, Clump Thickness, Uniformity of Cell Size, Uniformity of Cell
    Shape, Marginal Adhesion, Single Epithelial Cell Size, Bare Nuclei, Bland Chromatin,
    Normal Nucleoli, Mitoses`, and `Class`:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`col_names`的变量，包含列名：`Sample code number, Clump Thickness, Uniformity of
    Cell Size, Uniformity of Cell Shape, Marginal Adhesion, Single Epithelial Cell
    Size, Bare Nuclei, Bland Chromatin, Normal Nucleoli, Mitoses` 和 `Class`：
- en: '[PRE15]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Assign the column names of the DataFrame using the `columns` attribute:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`columns`属性赋值DataFrame的列名：
- en: '[PRE16]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Display the shape of the DataFrame using the `.shape` attribute:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.shape`属性显示DataFrame的形状：
- en: '[PRE17]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You should get the following output:'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE18]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This DataFrame contains `699` rows and `11` columns.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该DataFrame包含`699`行和`11`列。
- en: 'Display the first five rows of the DataFrame using the `head()` method:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`head()`方法显示DataFrame的前五行：
- en: '[PRE19]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You should get the following output:'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.8: The first five rows of the Breast Cancer dataset'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图11.8：乳腺癌数据集的前五行'
- en: '](img/B15019_11_08.jpg)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_08.jpg)'
- en: 'Figure 11.8: The first five rows of the Breast Cancer dataset'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图11.8：乳腺癌数据集的前五行
- en: All the variables are numerical. The Sample code number column is an identifier
    for the measurement samples.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有变量都是数值型的。样本代码号列是测量样本的标识符。
- en: 'Find the number of duplicate rows using the `duplicated()` and `sum()` methods:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`duplicated()`和`sum()`方法查找重复行的数量：
- en: '[PRE20]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You should get the following output:'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE21]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Looking at the 11 columns in this dataset, we can see that there are `8` duplicate
    rows.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过查看该数据集的11列，我们可以看到有`8`行重复数据。
- en: 'Display the duplicate rows using the `loc()` and `duplicated()` methods:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`loc()`和`duplicated()`方法显示重复行：
- en: '[PRE22]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You should get the following output:'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.9: Duplicate records'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图11.9：重复记录'
- en: '](img/B15019_11_09.jpg)'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_09.jpg)'
- en: 'Figure 11.9: Duplicate records'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图11.9：重复记录
- en: 'The following rows are duplicates: `208`, `253`, `254`, `258`, `272`, `338`,
    `561`, and `684`.'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下行是重复的：`208`、`253`、`254`、`258`、`272`、`338`、`561`和`684`。
- en: 'Display the duplicate rows just like we did in *Step 9*, but with the `keep=''last''`
    parameter instead:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如同在*步骤9*中那样显示重复行，但这次使用`keep='last'`参数：
- en: '[PRE23]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You should get the following output:'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.10: Duplicate records with keep=''last'''
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.10：使用 keep=''last'' 的重复记录'
- en: '](img/B15019_11_10.jpg)'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_10.jpg)'
- en: 'Figure 11.10: Duplicate records with keep=''last'''
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.10：使用 keep='last' 的重复记录
- en: 'By using the `keep=''last''` parameter, the following rows are considered duplicates:
    `42`, `62`, `168`, `207`, `267`, `314`, `560`, and `683`. By comparing this output
    to the one from the previous step, we can see that rows 253 and 42 are identical.'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过使用`keep='last'`参数，以下行被认为是重复的：`42`，`62`，`168`，`207`，`267`，`314`，`560`，和`683`。通过将这个输出与前一步的输出进行比较，我们可以看到第253行和第42行是相同的。
- en: 'Remove the duplicate rows using the `drop_duplicates()` method along with the
    `keep=''first''` parameter and save this into a new DataFrame called `df_unique`:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`drop_duplicates()`方法以及`keep='first'`参数删除重复行，并将其保存到一个名为`df_unique`的新DataFrame中：
- en: '[PRE24]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Display the shape of `df_unique` with the `.shape` attribute:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.shape`属性显示`df_unique`的形状：
- en: '[PRE25]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You should get the following output:'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会得到以下输出：
- en: '[PRE26]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Now that we have removed the eight duplicate records, only `691` rows remain.
    Now, the dataset only contains unique observations.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们已经删除了八条重复记录，剩下的只有`691`行数据。现在，数据集只包含唯一的观察值。
- en: Note
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2EiArYI](https://packt.live/2EiArYI).
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 若要访问此部分的源代码，请参考[https://packt.live/2EiArYI](https://packt.live/2EiArYI)。
- en: You can also run this example online at [https://packt.live/349tLat](https://packt.live/349tLat).
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还可以在[https://packt.live/349tLat](https://packt.live/349tLat)在线运行这个例子。
- en: In this exercise, you learned how to identify and remove duplicate records from
    a real-world dataset.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你学习了如何识别并删除来自真实世界数据集的重复记录。
- en: Converting Data Types
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换数据类型
- en: Another problem you may face in a project is incorrect data types being inferred
    for some columns. As we saw in *Chapter 10*, *Analyzing a Dataset*, the `pandas`
    package provides us with a very easy way to display the data type of each column
    using the `.dtypes` attribute. You may be wondering, when did `pandas` identify
    the type of each column? The types are detected when you load the dataset into
    a `pandas` DataFrame using methods such as `read_csv()`, `read_excel()`, and so
    on.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你在项目中可能会遇到的另一个问题是某些列的数据类型被错误推断。正如我们在*第10章*《分析数据集》中所看到的，`pandas`包提供了一个非常简单的方法，通过`.dtypes`属性显示每一列的数据类型。你可能会想，`pandas`是什么时候识别每一列的数据类型的？当你使用`read_csv()`、`read_excel()`等方法将数据集加载到`pandas`
    DataFrame时，类型就被检测出来了。
- en: When you've done this, `pandas` will try its best to automatically find the
    best type according to the values contained in each column. Let's see how this
    works on the `Online Retail` dataset.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些操作后，`pandas`将尽力根据每一列中包含的值自动找出最佳数据类型。让我们看看这个方法在`Online Retail`数据集上的效果。
- en: 'First, you must import `pandas`:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你必须导入`pandas`：
- en: '[PRE27]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Then, you need to assign the URL to the dataset to a new variable:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你需要将数据集的URL赋给一个新变量：
- en: '[PRE28]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let''s load the dataset into a `pandas` DataFrame using `read_excel()`:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`read_excel()`将数据集加载到`pandas` DataFrame中：
- en: '[PRE29]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, let''s print the data type of each column:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们打印每一列的数据类型：
- en: '[PRE30]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'You should get the following output:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会得到以下输出：
- en: '![Figure 11.11: The data type of each column of the Online Retail dataset'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.11：在线零售数据集每列的数据类型'
- en: '](img/B15019_11_11.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_11.jpg)'
- en: 'Figure 11.11: The data type of each column of the Online Retail dataset'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.11：在线零售数据集每列的数据类型
- en: The preceding output shows the data types that have been assigned to each column.
    `Quantity`, `UnitPrice`, and `CustomerID` have been identified as numerical variables
    (`int64`, `float64`), `InvoiceDate` is a `datetime` variable, and all the other
    columns are considered text (`object`). This is not too bad. `pandas` did a great
    job of recognizing non-text columns.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的输出显示了每一列被分配的数据类型。`Quantity`、`UnitPrice`和`CustomerID`被识别为数值变量（`int64`、`float64`），`InvoiceDate`是一个`datetime`变量，其他所有列都被认为是文本（`object`）。这并不算太糟糕。`pandas`在识别非文本列方面做得很不错。
- en: But what if you want to change the types of some columns? You have two ways
    to achieve this.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果你想改变某些列的数据类型呢？你有两种方法可以实现这一点。
- en: 'The first way is to reload the dataset, but this time, you will need to specify
    the data types of the columns of interest using the `dtype` parameter. This parameter
    takes a dictionary with the column names as keys and the correct data types as
    values, such as {''col1'': np.float64, ''col2'': np.int32}, as input. Let''s try
    this on `CustomerID`. We know this isn''t a numerical variable as it contains
    a unique **identifier** (code). Here, we are going to change its type to **object**:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '第一种方法是重新加载数据集，但这一次，你需要使用`dtype`参数指定感兴趣列的数据类型。该参数接受一个字典，其中列名作为键，正确的数据类型作为值，例如{''col1'':
    np.float64, ''col2'': np.int32}，作为输入。让我们尝试在`CustomerID`上使用这个方法。我们知道它不是一个数值变量，因为它包含唯一的**标识符**（代码）。在这里，我们将把它的数据类型更改为**object**：'
- en: '[PRE31]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'You should get the following output:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 11.12: The data types of each column after converting CustomerID'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.12：转换CustomerID后每列的数据类型'
- en: '](img/B15019_11_12.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_12.jpg)'
- en: 'Figure 11.12: The data types of each column after converting CustomerID'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.12：转换CustomerID后每列的数据类型
- en: As you can see, the data type for `CustomerID` has effectively changed to a
    `category` type.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`CustomerID`的数据类型已成功更改为`category`类型。
- en: 'Now, let''s look at the second way of converting a single column into a different
    type. In `pandas`, you can use the `astype()` method and specify the new data
    type that it will be converted into as its `pandas` series, to be more precise),
    so you need to reassign it to the same column of the DataFrame. For instance,
    if you want to change the `InvoiceNo` column into a categorical variable, you
    would do the following:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看第二种将单列转换为不同类型的方法。在`pandas`中，你可以使用`astype()`方法，并指定要转换成的新数据类型，作为其`pandas`序列，更准确地说，你需要将其重新赋值给数据框的同一列。例如，如果你想将`InvoiceNo`列更改为分类变量，你可以这样做：
- en: '[PRE32]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You should get the following output:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 11.13: The data types of each column after converting InvoiceNo'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.13：转换InvoiceNo后每列的数据类型'
- en: '](img/B15019_11_13.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_13.jpg)'
- en: 'Figure 11.13: The data types of each column after converting InvoiceNo'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.13：转换InvoiceNo后每列的数据类型
- en: 'As you can see, the data type for `InvoiceNo` has changed to a categorical
    variable. The difference between `object` and `category` is that the latter has
    a finite number of possible values (also called discrete variables). Once these
    have been changed into categorical variables, `pandas` will automatically list
    all the values. They can be accessed using the `.cat.categories` attribute:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`InvoiceNo`的数据类型已更改为分类变量。`object`和`category`的区别在于，后者具有有限的可能值（也叫离散变量）。一旦这些被更改为分类变量，`pandas`将自动列出所有值。你可以通过`.cat.categories`属性访问它们：
- en: '[PRE33]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'You should get the following output:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 11.14: List of categories (possible values) for the InvoiceNo categorical
    variable'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.14：InvoiceNo分类变量的类别（可能值）列表'
- en: '](img/B15019_11_14.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_14.jpg)'
- en: 'Figure 11.14: List of categories (possible values) for the InvoiceNo categorical
    variable'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.14：InvoiceNo分类变量的类别（可能值）列表
- en: '`pandas` has identified that there are 25,900 different values in this column
    and has listed all of them. Depending on the data type that''s assigned to a variable,
    `pandas` provides different attributes and methods that are very handy for data
    transformation or feature engineering (this will be covered in *Chapter 12*, *Feature
    Engineering*).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`已识别出该列中有25,900个不同的值，并列出了所有这些值。根据变量分配的数据类型，`pandas`提供了不同的属性和方法，这些对于数据转换或特征工程非常有用（将在*第12章*，*特征工程*中讨论）。'
- en: As a final note, you may be wondering when you would use the first way of changing
    the types of certain columns (while loading the dataset). To find out the current
    type of each variable, you must load the data first, so why will you need to reload
    the data again with new data types? It will be easier to change the type with
    the `astype()` method after the first load. There are a few reasons why you would
    use it. One reason could be that you have already explored the dataset on a different
    tool, such as Excel, and already know what the correct data types are.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最后需要说明的是，你可能会想知道何时使用第一种更改某些列类型的方法（在加载数据集时）。为了找出每个变量的当前类型，你必须先加载数据，那么为什么还需要使用新的数据类型重新加载数据呢？在第一次加载后，使用`astype()`方法来更改类型会更容易。使用它的原因有几个。一个可能的原因是你已经在其他工具中探索了数据集，比如Excel，并且已经知道正确的数据类型是什么。
- en: The second reason could be that your dataset is big, and you cannot load it
    in its entirety. As you may have noticed, by default, `pandas` use 64-bit encoding
    for numerical variables. This requires a lot of memory and may be overkill.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个原因可能是你的数据集很大，无法一次性加载。如你所见，默认情况下，`pandas` 使用 64 位编码来处理数值变量，这会占用大量内存，可能有些过于浪费。
- en: For example, the `Quantity` column has an int64 data type, which means that
    the range of possible values is -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807\.
    However, in *Chapter 10*, *Analyzing a Dataset* while analyzing the distribution
    of this column, you learned that the range of values for this column is only from
    -80,995 to 80,995\. You don't need to use so much space. By reducing the data
    type of this variable to int32 (which ranges from -2,147,483,648 to 2,147,483,647),
    you may be able to reload the entire dataset.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`Quantity` 列的数据类型是 int64，这意味着可能的值范围是 -9,223,372,036,854,775,808 到 9,223,372,036,854,775,807。然而，在*第10章*，*数据集分析*中分析该列分布时，你了解到该列的值范围仅为
    -80,995 到 80,995。你不需要使用如此多的空间。通过将该变量的数据类型从 int64 降级为 int32（范围为 -2,147,483,648
    到 2,147,483,647），你可能能够重新加载整个数据集。
- en: 'Exercise 11.02: Converting Data Types for the Ames Housing Dataset'
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 11.02：为 Ames Housing 数据集转换数据类型
- en: In this exercise, you will prepare a dataset by converting its variables into
    the correct data types.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你将通过将变量转换为正确的数据类型来准备数据集。
- en: 'You will use the Ames Housing dataset to do this, which we also used in *Chapter
    10*, *Analyzing a Dataset*. For more information about this dataset, refer to
    the following note. Let''s get started:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用 Ames Housing 数据集来完成此任务，我们也在*第10章*，*数据集分析*中使用了该数据集。有关此数据集的更多信息，请参阅以下说明。让我们开始吧：
- en: Note
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The dataset that''s being used in this exercise is the Ames Housing dataset,
    which has been compiled by Dean De Cock: [https://packt.live/2QTbTbq](https://packt.live/2QTbTbq).'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习中使用的数据集是 Ames Housing 数据集，由 Dean De Cock 编制：[https://packt.live/2QTbTbq](https://packt.live/2QTbTbq)。
- en: 'For your convenience, this dataset has been uploaded to this book''s GitHub
    repository: [https://packt.live/2ZUk4bz](https://packt.live/2ZUk4bz).'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便，你可以在本书的 GitHub 仓库中找到该数据集：[https://packt.live/2ZUk4bz](https://packt.live/2ZUk4bz)。
- en: Open a new Colab notebook.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Colab 笔记本。
- en: 'Import the `pandas` package:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas` 包：
- en: '[PRE34]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Assign the link to the Ames dataset to a variable called `file_url`:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 Ames 数据集的链接赋值给一个名为 `file_url` 的变量：
- en: '[PRE35]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Using the `read_csv` method from the `pandas` package, load the dataset into
    a new variable called `df`:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pandas` 包的 `read_csv` 方法，将数据集加载到一个名为 `df` 的新变量中：
- en: '[PRE36]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Print the data type of each column using the `dtypes` attribute:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `dtypes` 属性打印每一列的数据类型：
- en: '[PRE37]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'You should get the following output:'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.15: List of columns and their assigned data types'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.15：列及其分配的数据类型列表'
- en: '](img/B15019_11_15.jpg)'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_15.jpg)'
- en: 'Figure 11.15: List of columns and their assigned data types'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.15：列及其分配的数据类型列表
- en: Note
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The preceding output has been truncated.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上面的输出已被截断。
- en: From *Chapter 10*, *Analyzing a Dataset* you know that the `Id`, `MSSubClass`,
    `OverallQual`, and `OverallCond` columns have been incorrectly classified as numerical
    variables. They have a finite number of unique values and you can't perform any
    mathematical operations on them. For example, it doesn't make sense to add, remove,
    multiply, or divide two different values from the `Id` column. Therefore, you
    need to convert them into categorical variables.
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在*第10章*，*数据集分析*中，你知道 `Id`、`MSSubClass`、`OverallQual` 和 `OverallCond` 列被错误地归类为数值变量。它们有有限数量的唯一值，不能进行任何数学运算。例如，将
    `Id` 列中的两个不同值相加、相减、相乘或相除是没有意义的。因此，你需要将它们转换为类别变量。
- en: 'Using the `astype()` method, convert the `''Id''` column into a categorical
    variable, as shown in the following code snippet:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `astype()` 方法，将 `'Id'` 列转换为类别变量，如下所示：
- en: '[PRE38]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Convert the `''MSSubClass''`, `''OverallQual''`, and `''OverallCond''` columns
    into categorical variables, like we did in the previous step:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `'MSSubClass'`、`'OverallQual'` 和 `'OverallCond'` 列转换为类别变量，就像我们在上一步中做的那样：
- en: '[PRE39]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Create a for loop that will iterate through the four categorical columns `(''Id'',
    ''MSSubClass'', ''OverallQual'',` and `''OverallCond''`) and print their names
    and categories using the `.cat.categories` attribute:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 for 循环，遍历四个类别列`('Id', 'MSSubClass', 'OverallQual',` 和 `'OverallCond'`)并使用
    `.cat.categories` 属性打印它们的名称和类别：
- en: '[PRE40]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You should get the following output:'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.16: List of categories for the four newly converted variables'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.16：四个新转换变量的类别列表'
- en: '](img/B15019_11_16.jpg)'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_16.jpg)'
- en: 'Figure 11.16: List of categories for the four newly converted variables'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.16：四个新转换变量的类别列表
- en: Now, these four columns have been converted into categorical variables. From
    the output of *Step 5*, we can see that there are a lot of variables of the `object`
    type. Let's have a look at them and see if they need to be converted as well.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，这四列已经被转换为类别变量。从*步骤 5*的输出中，我们可以看到有很多`object`类型的变量。让我们看看它们，看看是否也需要转换。
- en: 'Create a new DataFrame called `obj_df` that will only contain variables of
    the `object` type using the `select_dtypes` method along with the `include=''object''`
    parameter:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的DataFrame，命名为`obj_df`，该DataFrame仅包含`object`类型的变量，使用`select_dtypes`方法并加上`include='object'`参数：
- en: '[PRE41]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Create a new variable called `obj_cols` that contains a list of column names
    from the `obj_df` DataFrame using the `.columns` attribute and display its content:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`obj_cols`的新变量，包含`obj_df` DataFrame中列名的列表，使用`.columns`属性并显示其内容：
- en: '[PRE42]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'You should get the following output:'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.17: List of variables of the ''object'' type'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.17：“object”类型变量列表'
- en: '](img/B15019_11_17.jpg)'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_17.jpg)'
- en: 'Figure 11.17: List of variables of the ''object'' type'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.17：“object”类型变量列表
- en: 'Like we did in *Step 8*, create a `for` loop that will iterate through the
    column names contained in `obj_cols` and print their names and unique values using
    the `unique()` method:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像我们在*步骤 8*中做的那样，创建一个`for`循环，遍历`obj_cols`中包含的列名，并使用`unique()`方法打印它们的名称和唯一值：
- en: '[PRE43]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'You should get the following output:'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.18: List of unique values for each variable of the ''object'' type'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.18：每个“object”类型变量的唯一值列表'
- en: '](img/B15019_11_18.jpg)'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_18.jpg)'
- en: 'Figure 11.18: List of unique values for each variable of the ''object'' type'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.18：每个“object”类型变量的唯一值列表
- en: As you can see, all these columns have a finite number of unique values that
    are composed of text, which shows us that they are categorical variables.
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，所有这些列都包含有限数量的唯一值，且这些值由文本组成，这表明它们是类别变量。
- en: 'Now, create a `for` loop that will iterate through the column names contained
    in `obj_cols` and convert each of them into a categorical variable using the `astype()`
    method:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个`for`循环，遍历`obj_cols`中包含的列名，并使用`astype()`方法将每个列转换为类别变量：
- en: '[PRE44]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Print the data type of each column using the `dtypes` attribute:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印每一列的数据类型，使用`dtypes`属性：
- en: '[PRE45]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'You should get the following output:'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.19: List of variables and their new data types'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.19：变量及其新数据类型的列表'
- en: '](img/B15019_11_19.jpg)'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_19.jpg)'
- en: 'Figure 11.19: List of variables and their new data types'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.19：变量及其新数据类型的列表
- en: Note
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The preceding output has been truncated.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的输出已被截断。
- en: To access the source code for this specific section, please refer to [https://packt.live/2FvR8R6](https://packt.live/2FvR8R6).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此部分的源代码，请参考[https://packt.live/2FvR8R6](https://packt.live/2FvR8R6)。
- en: You can also run this example online at [https://packt.live/3aAmKka](https://packt.live/3aAmKka).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/3aAmKka](https://packt.live/3aAmKka)上运行此示例。
- en: You have successfully converted the columns that have incorrect data types (numerical
    or object) into categorical variables. Your dataset is now one step closer to
    being prepared for modeling.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地将具有错误数据类型（数值型或对象型）的列转换为类别变量。你的数据集现在距离准备好进行建模更进一步了。
- en: In the next section, we will look at handling incorrect values.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将讨论如何处理错误值。
- en: Handling Incorrect Values
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理错误值
- en: Another issue you may face with a new dataset is incorrect values for some of
    the observations in the dataset. Sometimes, this is due to a syntax error; for
    instance, the name of a country may be written all in lower case, all in upper
    case, as a title (where only the first letter is capitalized), or may even be
    abbreviated. France may take different values, such as 'France', 'FRANCE', 'france',
    'FR', and so on. If you define 'France' as the standard format, then all the other
    variants are considered incorrect values in the dataset and need to be fixed.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会遇到的另一个问题是数据集中某些观察值的错误值。有时，这是由于语法错误引起的；例如，某个国家的名称可能全为小写、全为大写、标题化（只有第一个字母大写），或者甚至缩写。例如，法国可能会有不同的值，如‘France’，‘FRANCE’，‘france’，‘FR’等。如果你将‘France’定义为标准格式，那么所有其他变体都被认为是数据集中的错误值，并需要修正。
- en: If this kind of issue is not handled before the modeling phase, it can lead
    to incorrect results. The model will think these different variants are completely
    different values and may pay less attention to these values since they have separated
    frequencies. For instance, let's say that 'France' represents 2% of the value,
    'FRANCE' 2% and 'FR' 1%. You know that these values correspond to the same country
    and should represent 5% of the values, but the model will consider them as different
    countries.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这种问题在建模阶段之前没有得到处理，可能会导致错误的结果。模型会认为这些不同的变体是完全不同的值，并可能不太关注这些值，因为它们有独立的频率。例如，假设'France'代表2%的值，'FRANCE'代表2%，'FR'代表1%。你知道这些值对应的是同一个国家，应该代表5%的值，但模型会把它们当作不同的国家处理。
- en: Let's learn how to detect such issues in real life by using the `Online Retail`
    dataset.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用`Online Retail`数据集来学习如何在实际生活中检测此类问题。
- en: 'First, you need to load the data into a `pandas` DataFrame:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要将数据加载到一个`pandas` DataFrame中：
- en: '[PRE46]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'In this dataset, there are two variables that seem to be related to each other:
    `StockCode` and `Description`. The first one contains the identifier code of the
    items sold and the other one contains their descriptions. However, if you look
    at some of the examples, such as `StockCode 23131`, the `Description` column has
    different values:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集中，有两个变量似乎彼此相关：`StockCode` 和 `Description`。第一个包含所售物品的标识代码，另一个包含它们的描述。然而，如果你查看一些例子，比如`StockCode
    23131`，`Description`列有不同的值：
- en: '[PRE47]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: You should get the following output
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.20: List of unique values for the Description column and StockCode
    23131'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.20：描述列和库存代码 23131 的唯一值列表'
- en: '](img/B15019_11_20.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_20.jpg)'
- en: 'Figure 11.20: List of unique values for the Description column and StockCode
    23131'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.20：描述列和库存代码 23131 的唯一值列表
- en: There are multiple issues in the preceding output. One issue is that the word
    `Mistletoe` has been misspelled so that it reads `Miseltoe`. The other errors
    are unexpected values and missing values, which will be covered in the next section.
    It seems that the `Description` column has been used to record comments such as
    `had been put aside`.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出中有多个问题。一个问题是单词`Mistletoe`拼写错误，变成了`Miseltoe`。其他错误是意外值和缺失值，这些将在下一节中讨论。看来`Description`列被用来记录诸如`had
    been put aside`的评论。
- en: 'Let''s focus on the misspelling issue. What we need to do here is modify the
    incorrect spelling and replace it with the correct value. First, let''s create
    a new column called `StockCodeDescription`, which is an exact copy of the `Description`
    column:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们专注于拼写错误问题。我们需要做的是修改错误的拼写并用正确的值替换它。首先，让我们创建一个名为`StockCodeDescription`的新列，它是`Description`列的完全副本：
- en: '[PRE48]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'You will use this new column to fix the misspelling issue. To do this, use
    the subsetting technique you learned about earlier in this chapter. You need to
    use `.loc` and filter the rows and columns you want, that is, all rows with `StockCode
    == 21131` and `Description == MISELTOE HEART WREATH CREAM` and the `Description`
    column:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用这个新列来修正拼写错误问题。为此，使用你在本章前面学到的子集技巧。你需要使用`.loc`并筛选你想要的行和列，即所有`StockCode ==
    21131`且`Description == MISELTOE HEART WREATH CREAM`的行，以及`Description`列：
- en: '[PRE49]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'If you reprint the value for this issue, you will see that the misspelling
    value has been fixed and is not present anymore:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你重新打印这个问题的值，你会看到拼写错误的值已经被修正，不再出现：
- en: '[PRE50]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'You should get the following output:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.21: List of unique values for the Description column and StockCode
    23131'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.21：描述列和库存代码 23131 的唯一值列表'
- en: after fixing the first misspelling issue
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 修正了第一个拼写错误问题后
- en: '](img/B15019_11_21.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_21.jpg)'
- en: 'Figure 11.21: List of unique values for the Description column and StockCode
    23131 after fixing the first misspelling issue'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.21：修正第一个拼写错误问题后的描述列和库存代码 23131 的唯一值列表
- en: 'As you can see, there are still five different values for this product, but
    for one of them, that is, `MISTLETOE`, has been spelled incorrectly: `MISELTOE`.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个产品仍然有五个不同的值，但其中一个值，即`MISTLETOE`，被拼写错误：`MISELTOE`。
- en: This time, rather than looking at an exact match (a word must be the same as
    another one), we will look at performing a partial match (part of a word will
    be present in another word). In our case, instead of looking at the spelling of
    `MISELTOE`, we will only look at `MISEL`. The `pandas` package provides a method
    called `.str.contains()` that we can use to look for observations that partially
    match with a given expression.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，我们不再查找完全匹配（一个单词必须与另一个单词完全相同），而是查找部分匹配（一个单词的部分内容出现在另一个单词中）。在我们的例子中，我们将不再查找`MISELTOE`的拼写，而只查找`MISEL`。`pandas`包提供了一种名为`.str.contains()`的方法，我们可以使用它来查找与给定表达式部分匹配的观察值。
- en: 'Let''s use this to see if we have the same misspelling issue (`MISEL`) in the
    entire dataset. You will need to add one additional parameter since this method
    doesn''t handle missing values. You will also have to subset the rows that don''t
    have missing values for the `Description` column. This can be done by providing
    the `na=False` parameter to the `.str.contains()` method:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这个方法来查看整个数据集中是否有相同的拼写错误问题（`MISEL`）。由于此方法无法处理缺失值，你需要添加一个额外的参数。此外，你还需要筛选出`Description`列中没有缺失值的行。这可以通过向`.str.contains()`方法提供`na=False`参数来实现：
- en: '[PRE51]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'You should get the following output:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.22: Displaying all the rows containing the misspelling ''MISELTOE'''
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.22：显示所有包含拼写错误''MISELTOE''的行'
- en: '](img/B15019_11_22.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_22.jpg)'
- en: 'Figure 11.22: Displaying all the rows containing the misspelling ''MISELTOE'''
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.22：显示所有包含拼写错误'MISELTOE'的行
- en: 'This misspelling issue (`MISELTOE`) is not only related to `StockCode 23131`,
    but also to other items. You will need to fix all of these using the `str.replace()`
    method. This method takes the string of characters to be replaced and the replacement
    string as parameters:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这个拼写错误问题（`MISELTOE`）不仅与`StockCode 23131`相关，还涉及其他项目。你需要使用`str.replace()`方法修复所有这些问题。该方法接受两个参数：需要替换的字符字符串和替换字符串：
- en: '[PRE52]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Now, if you print all the rows that contain the misspelling of `MISEL`, you
    will see that no such rows exist anymore:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你打印出所有包含拼写错误`MISEL`的行，你将看到这些行已经不存在了：
- en: '[PRE53]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: You should get the following output
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.23: Displaying all the rows containing the misspelling MISELTOE
    after cleaning up'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.23：清理后显示所有包含拼写错误MISELTOE的行'
- en: '](img/B15019_11_23.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_23.jpg)'
- en: 'Figure 11.23: Displaying all the rows containing the misspelling MISELTOE after
    cleaning up'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.23：清理后显示所有包含拼写错误MISELTOE的行
- en: You just saw how easy it is to clean observations that have incorrect values
    using the `.str.contains` and `.str.replace()` methods that are provided by the
    `pandas` package. These methods can only be used for variables containing strings,
    but the same logic can be applied to numerical variables and can also be used
    to handle extreme values or outliers. You can use the ==, >, <, >=, or <= operator
    to subset the rows you want and then replace the observations with the correct
    values.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚看到如何轻松清理数据中包含错误值的观察值，方法是使用`pandas`包提供的`.str.contains`和`.str.replace()`方法。这些方法只能用于包含字符串的变量，但相同的逻辑也可以应用于数值变量，并且可以用来处理极端值或异常值。你可以使用==、>、<、>=或<=运算符来筛选你想要的行，然后将观察值替换为正确的值。
- en: 'Exercise 11.03: Fixing Incorrect Values in the State Column'
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习11.03：修复State列中的错误值
- en: 'In this exercise, you will clean the `State` variable in a modified version
    of a dataset by listing all the finance officers in the USA. We are doing this
    because the dataset contains some incorrect values. Let''s get started:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你将通过列出所有美国的财务官员来清理数据集中`State`变量的值。我们之所以这样做，是因为数据集中包含一些错误的值。让我们开始吧：
- en: Note
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：
- en: The original dataset was shared by Forest Gregg and Derek Eder and can be found
    at [https://packt.live/2rTJVns](https://packt.live/2rTJVns).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集由Forest Gregg和Derek Eder共享，可以在[https://packt.live/2rTJVns](https://packt.live/2rTJVns)找到。
- en: 'The modified dataset that we''re using here is available in this book''s GitHub
    repository: [https://packt.live/2MZJsrk](https://packt.live/2MZJsrk).'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的修改版数据集可以在本书的GitHub仓库中找到：[https://packt.live/2MZJsrk](https://packt.live/2MZJsrk)。
- en: Open a new Colab notebook.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Colab笔记本。
- en: 'Import the `pandas` package:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`包：
- en: '[PRE54]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Assign the link to the dataset to a variable called `file_url`:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集链接赋值给一个名为`file_url`的变量：
- en: '[PRE55]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Using the `read_csv()` method from the `pandas` package, load the dataset into
    a new variable called `df`:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`包中的`read_csv()`方法，将数据集加载到一个名为`df`的新变量中：
- en: '[PRE56]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Print the first five rows of the DataFrame using the `.head()` method:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.head()` 方法打印出数据框的前五行：
- en: '[PRE57]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'You should get the following output:'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.24: The first five rows of the finance officers dataset'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.24：财务官员数据集的前五行'
- en: '](img/B15019_11_24.jpg)'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_24.jpg)'
- en: 'Figure 11.24: The first five rows of the finance officers dataset'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.24：财务官员数据集的前五行
- en: 'Print out all the unique values of the `State` variable:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出 `State` 变量的所有唯一值：
- en: '[PRE58]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'You should get the following output:'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.25: List of unique values in the State column'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.25：State 列中唯一值的列表'
- en: '](img/B15019_11_25.jpg)'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_25.jpg)'
- en: 'Figure 11.25: List of unique values in the State column'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.25：State 列中唯一值的列表
- en: All the states have been encoded into a two-capitalized character format. As
    you can see, there are some incorrect values with non-capitalized characters,
    such as `il` and `iL` (they look like spelling errors for Illinois), and unexpected
    values such as `8I`, `I`, and `60`. In the next few steps, you are going to fix
    these issues.
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有州的值都已编码为两位大写字符格式。如你所见，有些值是错误的，如 `il` 和 `iL`（看起来像是 Illinois 的拼写错误），还有一些意外的值，如
    `8I`、`I` 和 `60`。在接下来的几步中，你将解决这些问题。
- en: 'Print out the rows that have the `il` value in the `State` column using the
    `pandas` `.str.contains()` method and the subsetting API, that is, DataFrame [condition].
    You will also have to set the `na` parameter to `False` in `str.contains()` in
    order to exclude observations with missing values:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pandas` 的 `.str.contains()` 方法和子集 API 打印出 `State` 列中包含 `il` 值的行，即 DataFrame
    [条件]。你还需要在 `str.contains()` 中将 `na` 参数设置为 `False`，以排除缺失值的观测：
- en: '[PRE59]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'You should get the following output:'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.26: Observations with a value of il'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.26：具有 il 值的观测'
- en: '](img/B15019_11_26.jpg)'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_26.jpg)'
- en: 'Figure 11.26: Observations with a value of il'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.26：具有 il 值的观测
- en: 'As you can see, all the cities with the `il` value are from the state of Illinois.
    So, the correct `State` value should be `IL`. You may be thinking that the following
    values are also referring to Illinois: `Il`, `iL`, and `Il`. We''ll have a look
    at them next.'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，所有具有 `il` 值的城市都来自伊利诺伊州。因此，正确的 `State` 值应为 `IL`。你可能会认为以下值也指向伊利诺伊州：`Il`、`iL`
    和 `Il`。我们接下来将查看它们。
- en: 'Now, create a `for` loop that will iterate through the following values in
    the `State` column: `Il`, `iL`, `Il`. Then, print out the values of the City and
    State variables using the `pandas` method for subsetting, that is, `.loc()`: DataFrame.loc[row_condition,
    column condition]. Do this for each observation:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个 `for` 循环，迭代 `State` 列中的以下值：`Il`、`iL`、`Il`。然后，使用 `pandas` 的子集方法打印出 City
    和 State 变量的值，即 `.loc()`：DataFrame.loc[行条件，列条件]。对每个观测值执行此操作：
- en: '[PRE60]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'You should get the following output:'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.27: Observations with the il value'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.27：具有 il 值的观测'
- en: '](img/B15019_11_27.jpg)'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_27.jpg)'
- en: 'Figure 11.27: Observations with the il value'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.27：具有 il 值的观测
- en: Note
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The preceding output has been truncated.
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的输出已被截断。
- en: As you can see, all these cities belong to the state of Illinois. Let's replace
    them with the correct values.
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，这些城市都属于伊利诺伊州。我们将用正确的值替换它们。
- en: 'Create a condition mask (`il_mask`) to subset all the rows that contain the
    four incorrect values (`il`, `Il`, `iL`, and `Il`) by using the `isin()` method
    and a list of these values as a parameter. Then, save the result into a variable
    called `il_mask`:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个条件掩码（`il_mask`），使用 `isin()` 方法和这些值的列表作为参数，筛选出包含四个错误值（`il`、`Il`、`iL` 和 `Il`）的所有行。然后，将结果保存在一个名为
    `il_mask` 的变量中：
- en: '[PRE61]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Print the number of rows that match the condition we set in `il_mask` using
    the `.sum()` method. This will sum all the rows that have a value of `True` (they
    match the condition):'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.sum()` 方法打印出与我们在 `il_mask` 中设置的条件匹配的行数。这将对所有值为 `True`（匹配条件）的行进行求和：
- en: '[PRE62]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'You should get the following output:'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE63]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Using the `pandas` `.loc()` method, subset the rows with the `il_mask` condition
    mask and replace the value of the `State` column with `IL`:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pandas` 的 `.loc()` 方法，筛选出符合 `il_mask` 条件的行，并将 `State` 列的值替换为 `IL`：
- en: '[PRE64]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Print out all the unique values of the `State` variable once more:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次打印出 `State` 变量的所有唯一值：
- en: '[PRE65]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'You should get the following output:'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.28: List of unique values for the ''State'' column'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.28：''State'' 列唯一值的列表'
- en: '](img/B15019_11_28.jpg)'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_28.jpg)'
- en: '[PRE66]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'You should get the following output:'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.29: Subsetting the rows with a value of IL in the State column'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.29：在State列中筛选出值为IL的行'
- en: '](img/B15019_11_29.jpg)'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_29.jpg)'
- en: 'Figure 11.29: Subsetting the rows with a value of IL in the State column'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.29：在State列中筛选出值为IL的行
- en: There are only two cases where the `II` value has been used for the `State`
    column and both have `Bloomington` as the city, which is in Illinois. Here, the
    correct `State` value should be `IL`.
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`State`列中仅有两个地方使用了`II`值，且这两个地方的城市都是Bloomington，位于伊利诺伊州。此处，正确的`State`值应该是`IL`。'
- en: 'Now, create a `for` loop that iterates through the three incorrect values (`I`,
    `8I`, and `60`) and print out the subsetted rows using the same logic that we
    used in *Step 12*. Only display the `City` and `State` columns:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个`for`循环，迭代三个不正确的值（`I`、`8I`和`60`），并使用我们在*步骤12*中使用的相同逻辑输出子集行。只显示`City`和`State`列：
- en: '[PRE67]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'You should get the following output:'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.30: Observations with incorrect values (I, 8I, and 60)'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.30：包含不正确值（I、8I和60）的观测'
- en: '](img/B15019_11_30.jpg)'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_30.jpg)'
- en: 'Figure 11.30: Observations with incorrect values (I, 8I, and 60)'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.30：包含不正确值（I、8I和60）的观测
- en: All the observations that have incorrect values are cities in Illinois. Let's
    fix them now.
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有包含不正确值的观测都是位于伊利诺伊州的城市。让我们现在修复它们。
- en: 'Create a `for` loop that iterates through the four incorrect values (`II`,
    `I`, `8I`, and `60`) and reuse the subsetting logic from *Step 12* to replace
    the value in `State` with `IL`:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`for`循环，迭代四个不正确的值（`II`、`I`、`8I`和`60`），并重新使用*步骤12*中的子集逻辑将`State`中的值替换为`IL`：
- en: '[PRE68]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Print out all the unique values of the `State` variable:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出所有`State`变量的唯一值：
- en: '[PRE69]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'You should get the following output:'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.31: List of unique values for the State column'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.31：State列的唯一值列表'
- en: '](img/B15019_11_31.jpg)'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_31.jpg)'
- en: 'Figure 11.31: List of unique values for the State column'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.31：State列的唯一值列表
- en: 'You fixed the issues for the state of Illinois. However, there are two more
    incorrect values in this column: `In` and `ng`.'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你已经修复了伊利诺伊州的状态问题。然而，在这一列中还有两个不正确的值：`In`和`ng`。
- en: 'Repeat *Step 13*, but iterate through the `In` and `ng` values instead:'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*步骤13*，但改为迭代`In`和`ng`值：
- en: '[PRE70]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'You should get the following output:'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.32: Observations with incorrect values (In, ng)'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.32：包含不正确值（In，ng）'
- en: '](img/B15019_11_32.jpg)'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_32.jpg)'
- en: 'Figure 11.32: Observations with incorrect values (In, ng)'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.32：包含不正确值（In，ng）的观测
- en: The rows that have the `ng` value in `State` are missing values. We will cover
    this topic in the next section. The observation that has `In` as its `State` is
    a city in Indiana, so the correct value should be `IN`. Let's fix this.
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在`State`中具有`ng`值的行缺少值。我们将在下一部分中讨论这个话题。`State`为`In`的观测是印第安纳州的一个城市，所以正确的值应该是`IN`。让我们修正它。
- en: 'Subset the rows containing the `In` value in `State` using the `.loc()` and
    `.str.contains()` methods and replace the state value with `IN`. Don''t forget
    to specify the `na=False` parameter as `.str.contains()`:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.loc()`和`.str.contains()`方法筛选出`State`中包含`In`值的行，并将州值替换为`IN`。别忘了为`.str.contains()`指定`na=False`参数：
- en: '[PRE71]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Print out all the unique values of the `State` variable:'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出所有`State`变量的唯一值：
- en: '[PRE72]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'You should get the following output:'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.33: List of unique values for the State column'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.33：State列的唯一值列表'
- en: '](img/B15019_11_31.jpg)'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_31.jpg)'
- en: 'Figure 11.33: List of unique values for the State column'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.33：State列的唯一值列表
- en: Note
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/319pfGX](https://packt.live/319pfGX).
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/319pfGX](https://packt.live/319pfGX)。
- en: You can also run this example online at [https://packt.live/2E8ICHn](https://packt.live/2E8ICHn).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个例子，网址为[https://packt.live/2E8ICHn](https://packt.live/2E8ICHn)。
- en: You just fixed all the incorrect values for the `State` variable using the methods
    provided by the `pandas` package. In the next section, we are going to look at
    handling missing values.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚使用`pandas`包提供的方法修复了`State`变量中的所有不正确值。在下一部分，我们将讨论如何处理缺失值。
- en: Handling Missing Values
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理缺失值
- en: 'So far, you have looked at a variety of issues when it comes to datasets. Now
    it is time to discuss another issue that occurs quite frequently: missing values.
    As you may have guessed, this type of issue means that certain values are missing
    for certain variables.'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经看到了数据集中的各种问题。现在是时候讨论另一个经常发生的问题：缺失值。如你所料，这类问题意味着某些变量的某些值缺失。
- en: 'The `pandas` package provides a method that we can use to identify missing
    values in a DataFrame: `.isna()`. Let''s see it in action on the `Online Retail`
    dataset. First, you need to import `pandas` and load the data into a DataFrame:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`包提供了一个方法，我们可以用它来识别DataFrame中的缺失值：`.isna()`。我们来看一下它在`Online Retail`数据集上的应用。首先，你需要导入`pandas`并将数据加载到DataFrame中：'
- en: '[PRE73]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The `.isna()` method returns a `pandas` series with a binary value for each
    cell of a DataFrame and states whether it is missing a value (`True`) or not (`False`):'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '`.isna()`方法返回一个`pandas`系列，表示DataFrame中每个单元格的二进制值，指出它是否缺少值（`True`）或者不缺少值（`False`）：'
- en: '[PRE74]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'You should get the following output:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.34: Output of the .isna() method'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.34：`.isna()`方法的输出'
- en: '](img/B15019_11_34.jpg)'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_34.jpg)'
- en: 'Figure 11.34: Output of the .isna() method'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.34：`.isna()`方法的输出
- en: 'As we saw previously, we can give the output of a binary variable to the `.sum()`
    method, which will add all the `True` values together (cells that have missing
    values) and provide a summary for each column:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，我们可以将一个二元变量的输出传递给`.sum()`方法，它会将所有的`True`值加在一起（具有缺失值的单元格），并为每一列提供一个总结：
- en: '[PRE75]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'You should get the following output:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.35: Summary of missing values for each variable'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.35：每个变量的缺失值总结'
- en: '](img/B15019_11_35.jpg)'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_35.jpg)'
- en: 'Figure 11.35: Summary of missing values for each variable'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.35：每个变量的缺失值总结
- en: 'As you can see, there are `1454` missing values in the `Description` column
    and `135080` in the `CustomerID` column. Let''s have a look at the missing value
    observations for `Description`. You can use the output of the `.isna()` method
    to subset the rows with missing values:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，`Description`列中有`1454`个缺失值，而`CustomerID`列中有`135080`个缺失值。让我们来看一下`Description`中缺失值的观测。你可以使用`.isna()`方法的输出来提取缺失值的行：
- en: '[PRE76]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'You should get the following output:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.36: Subsetting the rows with missing values for Description'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.36：提取具有缺失值的描述行'
- en: '](img/B15019_11_36.jpg)'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_36.jpg)'
- en: 'Figure 11.36: Subsetting the rows with missing values for Description'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.36：提取具有缺失值的描述行
- en: From the preceding output, you can see that all the rows with missing values
    have `0.0` as the unit price and are missing the `CustomerID` column. In a real
    project, you will have to discuss these cases with the business and check whether
    these transactions are genuine or not. If the business confirms that these observations
    are irrelevant, then you will need to remove them from the dataset.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的输出中，你可以看到所有缺失值的行，`unit price`（单价）都是`0.0`，并且缺失了`CustomerID`列。在实际项目中，你需要与业务方讨论这些情况，检查这些交易是否真实。如果业务方确认这些观测数据无关，那么你需要从数据集中删除它们。
- en: 'The `pandas` package provides a method that we can use to easily remove missing
    values: `.dropna()`. This method returns a new DataFrame without all the rows
    that have missing values. By default, it will look at all the columns. You can
    specify a list of columns for it to look for with the `subset` parameter:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`包提供了一个方法，我们可以用它轻松地删除缺失值：`.dropna()`。这个方法会返回一个没有缺失值的DataFrame。默认情况下，它会查看所有列。你可以使用`subset`参数指定一个列列表，让它去查找：'
- en: '[PRE77]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'This method returns a new DataFrame with no missing values for the specified
    columns. If you want to replace the original dataset directly, you can use the
    `inplace=True` parameter:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法会返回一个新的DataFrame，其中指定的列没有缺失值。如果你希望直接替换原始数据集，可以使用`inplace=True`参数：
- en: '[PRE78]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Now, look at the summary of the missing values for each variable:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，来看一下每个变量的缺失值总结：
- en: '[PRE79]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'You should get the following output:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.37: Summary of missing values for each variable'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.37：每个变量的缺失值总结'
- en: '](img/B15019_11_37.jpg)'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_37.jpg)'
- en: 'Figure 11.37: Summary of missing values for each variable'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.37：每个变量的缺失值总结
- en: 'As you can see, there are no more missing values in the `Description` column.
    Let''s have a look at the `CustomerID` column:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，`Description`列中不再有缺失值。让我们看一下`CustomerID`列：
- en: '[PRE80]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'You should get the following output:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.38: Rows with missing values in CustomerID'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.38：缺失值的CustomerID行](img/B15019_11_38.jpg)'
- en: '](img/B15019_11_38.jpg)'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_41.jpg)'
- en: 'Figure 11.38: Rows with missing values in CustomerID'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.38：缺失值的CustomerID行
- en: This time, all the transactions look normal, except they are missing values
    for the `CustomerID` column; all the other variables have been filled in with
    values that seem genuine. There is no other way to infer the missing values for
    the `CustomerID` column. These rows represent almost 25% of the dataset, so we
    can't remove them.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，所有交易看起来都正常，只是`CustomerID`列缺失值；其他所有变量都已填充了看起来合理的值。无法推断`CustomerID`列的缺失值。这些行占数据集的约25%，因此不能将它们删除。
- en: 'However, most algorithms require a value for each observation, so you need
    to provide one for these cases. We will use the `.fillna()` method from `pandas`
    to do this. Provide the value to be imputed as `Missing` and use `inplace=True`
    as a parameter:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数算法要求每个观察值都有一个值，因此你需要为这些情况提供一个值。我们将使用`pandas`的`.fillna()`方法来做到这一点。将填充的值设置为`Missing`，并将`inplace=True`作为参数：
- en: '[PRE81]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'You should get the following output:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.39: Examples of rows where missing values for CustomerID'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.39：缺失值的CustomerID行示例](img/B15019_11_39.jpg)'
- en: have been replaced with Missing
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 已被替换为Missing
- en: '](img/B15019_11_39.jpg)'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_39.jpg)'
- en: 'Figure 11.39: Examples of rows where missing values for CustomerID have been
    replaced with Missing'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.39：缺失值的CustomerID已被替换为Missing的行示例
- en: 'Let''s see if we have any missing values in the dataset:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查数据集中是否有缺失值：
- en: '[PRE82]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'You should get the following output:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.40: Summary of missing values for each variable'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.40：各变量缺失值的总结](img/B15019_11_40.jpg)'
- en: '](img/B15019_11_40.jpg)'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_40.jpg)'
- en: 'Figure 11.40: Summary of missing values for each variable'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.40：各变量缺失值的总结
- en: You have successfully fixed all the missing values in this dataset. These methods
    also work when we want to handle missing numerical variables. We will look at
    this in the following exercise. All you need to do is provide a numerical value
    when you want to impute a value with `.fillna()`.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 你已成功修复了数据集中所有缺失的值。这些方法同样适用于处理缺失的数值变量。我们将在接下来的练习中讨论这一点。当你想要使用`.fillna()`填充缺失值时，只需提供一个数值。
- en: 'Exercise 11.04: Fixing Missing Values for the Horse Colic Dataset'
  id: totrans-423
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 11.04：修复马匹肠绞痛数据集中的缺失值
- en: In this exercise, you will be cleaning out all the missing values for all the
    numerical variables in the `Horse Colic` dataset.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你将清理`马匹肠绞痛`数据集中所有数值变量的缺失值。
- en: 'Colic is a painful condition that horses can suffer from, and this dataset
    contains various pieces of information related to specific cases of this condition.
    You can use the link provided in the Note section if you want to find out more
    about the dataset''s attributes. Let''s get started:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 肠绞痛是马匹可能遭受的一种疼痛情况，这个数据集包含了与该疾病的特定病例相关的各种信息。如果你想了解更多关于数据集属性的信息，可以使用“注”部分提供的链接。让我们开始吧：
- en: Note
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: This dataset is from the UCI Machine Learning Repository. The attributes information
    can be found at [https://packt.live/2MZwSrW](https://packt.live/2MZwSrW).
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集来自UCI机器学习库。关于属性的信息可以在[https://packt.live/2MZwSrW](https://packt.live/2MZwSrW)找到。
- en: 'For your convenience, the dataset file that we''ll be using in this exercise
    has been uploaded to this book''s GitHub repository: [https://packt.live/35qESZq](https://packt.live/35qESZq).'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便你，我们将在本练习中使用的数据集文件已经上传到本书的GitHub仓库：[https://packt.live/35qESZq](https://packt.live/35qESZq)。
- en: Open a new Colab notebook.
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Colab笔记本。
- en: 'Import the `pandas` package:'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`包：
- en: '[PRE83]'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Assign the link to the dataset to a variable called `file_url`:'
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集的链接赋值给名为`file_url`的变量：
- en: '[PRE84]'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Using the `.read_csv()` method from the `pandas` package, load the dataset
    into a new variable called `df` and specify the `header=None`, `sep=''\s+''`,
    and `prefix=''X''` parameters:'
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`包中的`.read_csv()`方法，将数据集加载到一个名为`df`的新变量中，并指定`header=None`、`sep='\s+'`和`prefix='X'`参数：
- en: '[PRE85]'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Print the first five rows of the DataFrame using the `.head()` method:'
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.head()`方法打印数据框的前五行：
- en: '[PRE86]'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'You should get the following output:'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.41: The first five rows of the Horse Colic dataset'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.41：马匹肠绞痛数据集的前五行](img/B15019_11_41.jpg)'
- en: '](img/B15019_11_41.jpg)'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_41.jpg)'
- en: 'Figure 11.41: The first five rows of the Horse Colic dataset'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.41：马匹肠绞痛数据集的前五行
- en: As you can see, the authors have used the `?` character for missing values,
    but the `pandas` package thinks that this is a normal value. You need to transform
    them into missing values.
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，作者使用了`?`字符表示缺失值，但`pandas`包认为这只是一个正常值。你需要将它们转换为缺失值。
- en: 'Reload the dataset into a `pandas` DataFrame using the `.read_csv()` method,
    but this time, add the `na_values=''?''` parameter in order to specify that this
    value needs to be treated as a missing value:'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.read_csv()`方法将数据集重新加载到`pandas`数据框中，但这次需要添加`na_values='?'`参数，指定将此值视为缺失值：
- en: '[PRE87]'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Print the first five rows of the DataFrame using the `.head()` method:'
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.head()`方法打印数据框的前五行：
- en: '[PRE88]'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'You should get the following output:'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.42: The first five rows of the Horse Colic dataset'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.42：马疝气数据集的前五行'
- en: '](img/B15019_11_42.jpg)'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_42.jpg)'
- en: 'Figure 11.42: The first five rows of the Horse Colic dataset'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.42：马疝气数据集的前五行
- en: Now, you can see that `pandas` have converted all the `?` values into missing
    values.
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，你可以看到`pandas`已将所有`?`值转换为缺失值。
- en: 'Print the data type of each column using the `dtypes` attribute:'
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`dtypes`属性打印每列的数据类型：
- en: '[PRE89]'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'You should get the following output:'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.43: Data type of each column'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.43：每列的数据类型'
- en: '](img/B15019_11_43.jpg)'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_43.jpg)'
- en: 'Figure 11.43: Data type of each column'
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.43：每列的数据类型
- en: 'Print the number of missing values for each column by combining the `.isna()`
    and `.sum()` methods:'
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过结合`.isna()`和`.sum()`方法，打印每列的缺失值数量：
- en: '[PRE90]'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'You should get the following output:'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.44: Number of missing values for each column'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.44：每列的缺失值数量'
- en: '](img/B15019_11_44.jpg)'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_44.jpg)'
- en: 'Figure 11.44: Number of missing values for each column'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.44：每列的缺失值数量
- en: 'Create a condition mask called `x0_mask` so that you can find the missing values
    in the `X0` column using the `.isna()` method:'
  id: totrans-464
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`x0_mask`的条件掩码，这样你就可以使用`.isna()`方法找到`X0`列中的缺失值：
- en: '[PRE91]'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Display the number of missing values for this column by using the `.sum()`
    method on `x0_mask`:'
  id: totrans-466
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.sum()`方法对`x0_mask`显示此列的缺失值数量：
- en: '[PRE92]'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'You should get the following output:'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE93]'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: Here, you got the exact same number of missing values for `X0` that you did
    in *Step 9*.
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，你得到了与*步骤 9*中`X0`相同的缺失值数量。
- en: 'Extract the mean of `X0` using the `.median()` method and store it in a new
    variable called `x0_median`. Print its value:'
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.median()`方法提取`X0`的均值，并将其存储在名为`x0_median`的新变量中。打印其值：
- en: '[PRE94]'
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'You should get the following output:'
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE95]'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: The median value for this column is `1`. You will replace all the missing values
    with this value in the `X0` column.
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个列的中位数值是`1`。你将用这个值替换`X0`列中的所有缺失值。
- en: 'Replace all the missing values in the `X0` variable with their median using
    the `.fillna()` method, along with the `inplace=True` parameter:'
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.fillna()`方法和`inplace=True`参数，用中位数值替换`X0`变量中的所有缺失值：
- en: '[PRE96]'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Print the number of missing values for `X0` by combining the `.isna()` and
    `.sum()` methods:'
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过结合`.isna()`和`.sum()`方法，打印`X0`的缺失值数量：
- en: '[PRE97]'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'You should get the following output:'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE98]'
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: There are no more missing values in the variables.
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 变量中不再有缺失值。
- en: 'Create a `for` loop that will iterate through all the columns of the DataFrame.
    In the for loop, calculate the median for each and save them into a variable called
    `col_median`. Then, impute missing values with this median value using the `.fillna()`
    method, along with the `inplace=True` parameter, and print the name of the column
    and its median value:'
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`for`循环，遍历数据框中的所有列。在循环中，计算每列的中位数，并将其保存到一个名为`col_median`的变量中。然后，使用`.fillna()`方法以及`inplace=True`参数，用这个中位数值填充缺失值，并打印列名及其中位数值：
- en: '[PRE99]'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'You should get the following output:'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.45: Median values for each column'
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.45：每列的中位数值'
- en: '](img/B15019_11_45.jpg)'
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_45.jpg)'
- en: 'Figure 11.45: Median values for each column'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.45：每列的中位数值
- en: 'Print the number of missing values for each column by combining the `.isna()`
    and `.sum()` methods:'
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过结合`.isna()`和`.sum()`方法，打印每列的缺失值数量：
- en: '[PRE100]'
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'You should get the following output:'
  id: totrans-491
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.46: Number of missing values for each column'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.46：每列的缺失值数量'
- en: '](img/B15019_11_46.jpg)'
  id: totrans-493
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_11_46.jpg)'
- en: 'Figure 11.46: Number of missing values for each column'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.46：每列的缺失值数量
- en: Note
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/34c1zUd](https://packt.live/34c1zUd).
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此部分的源代码，请参考 [https://packt.live/34c1zUd](https://packt.live/34c1zUd)。
- en: You can also run this example online at [https://packt.live/324mHt0](https://packt.live/324mHt0).
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/324mHt0](https://packt.live/324mHt0) 上在线运行这个示例。
- en: 'You have successfully fixed the missing values for all the numerical variables
    using the methods provided by the `pandas` package: `.isna()` and `.fillna()`.'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地使用 `pandas` 包提供的方法 `.isna()` 和 `.fillna()` 修复了所有数值变量的缺失值。
- en: 'Activity 11.01: Preparing the Speed Dating Dataset'
  id: totrans-499
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 11.01：准备快速约会数据集
- en: As an entrepreneur, you are planning to launch a new dating app into the market.
    The key feature that will differentiate your app from other competitors will be
    your high performing user-matching algorithm. Before building this model, you
    have partnered with a speed dating company to collect data from real events. You
    just received the dataset from your partner company but realized it is not as
    clean as you expected; there are missing and incorrect values. Your task is to
    fix the main data quality issues in this dataset.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名企业家，你计划推出一款新的约会应用程序。你的应用与其他竞争对手的主要区别将是你高效的用户匹配算法。在构建这个模型之前，你与一家快速约会公司合作，从真实活动中收集数据。你刚刚收到了合作伙伴公司提供的数据集，但你意识到数据并不像你预期的那样干净；存在缺失和错误的值。你的任务是修复该数据集中主要的数据质量问题。
- en: 'The following steps will help you complete this activity:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成此活动：
- en: Download and load the dataset into Python using `.read_csv()`.
  id: totrans-502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.read_csv()` 下载并加载数据集到 Python 中。
- en: Print out the dimensions of the DataFrame using `.shape`.
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.shape` 打印出 DataFrame 的维度。
- en: Check for duplicate rows by using `.duplicated()` and `.sum()` on all the columns.
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.duplicated()` 和 `.sum()` 检查所有列的重复行。
- en: Check for duplicate rows by using `.duplicated()` and `.sum()` for the identifier
    columns (`iid`, `id`, `partner`, and `pid`).
  id: totrans-505
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.duplicated()` 和 `.sum()` 检查标识符列（`iid`、`id`、`partner` 和 `pid`）的重复行。
- en: 'Check for unexpected values for the following numerical variables: `''imprace'',
    ''imprelig'', ''sports'', ''tvsports'', ''exercise'', ''dining'', ''museums'',
    ''art'', ''hiking'', ''gaming'', ''clubbing'', ''reading'', ''tv'', ''theater'',
    ''movies'', ''concerts'', ''music'', ''shopping'',` and `''yoga''`.'
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查以下数值变量是否有意外值：`'imprace'`, `'imprelig'`, `'sports'`, `'tvsports'`, `'exercise'`,
    `'dining'`, `'museums'`, `'art'`, `'hiking'`, `'gaming'`, `'clubbing'`, `'reading'`,
    `'tv'`, `'theater'`, `'movies'`, `'concerts'`, `'music'`, `'shopping'` 和 `'yoga'`。
- en: Replace the identified incorrect values.
  id: totrans-507
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 替换已识别的错误值。
- en: Check the data type of the different columns using `.dtypes`.
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.dtypes` 检查不同列的数据类型。
- en: Change the data types to categorical for the columns that don't contain numerical
    values using `.astype()`.
  id: totrans-509
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.astype()` 将不包含数值的列的数据类型更改为分类数据类型。
- en: Check for any missing values using `.isna()` and `.sum()` for each numerical
    variable.
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.isna()` 和 `.sum()` 检查每个数值变量的缺失值。
- en: Replace the missing values for each numerical variable with their corresponding
    mean or median values using `.fillna()`, `.mean()`, and `.median()`.
  id: totrans-511
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.fillna()`、`.mean()` 和 `.median()` 替换每个数值变量的缺失值，填充为相应的均值或中位数值。
- en: Note
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: 'The dataset for this activity can be found in this book''s GitHub repository:
    [https://packt.live/36u0jtR](https://packt.live/36u0jtR).'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的数据集可以在本书的 GitHub 仓库中找到：[https://packt.live/36u0jtR](https://packt.live/36u0jtR)。
- en: 'The original dataset has been shared by Ray Fisman and Sheena Iyengar from
    Columbia Business School: [https://packt.live/2Fp5rUg](https://packt.live/2Fp5rUg).'
  id: totrans-514
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 原始数据集由哥伦比亚商学院的 Ray Fisman 和 Sheena Iyengar 分享：[https://packt.live/2Fp5rUg](https://packt.live/2Fp5rUg)。
- en: 'The authors have provided a very useful document that describes the dataset
    and its features: [https://packt.live/2Qrp7gD](https://packt.live/2Qrp7gD).'
  id: totrans-515
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作者提供了一份非常有用的文档，描述了数据集及其特征：[https://packt.live/2Qrp7gD](https://packt.live/2Qrp7gD)。
- en: 'You should get the following output. The figure represents the number of rows
    with unexpected values for `imprace` and a list of unexpected values:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出。该图表示具有意外值的 `imprace` 行数以及意外值的列表：
- en: '![Figure 11.47: Number of rows with unexpected values for ''imprace'''
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 11.47: Number of rows with unexpected values for ''imprace'''
- en: and a list of unexpected values
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 以及一组意外的值列表。
- en: '](img/B15019_11_47.jpg)'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_47.jpg)'
- en: 'Figure 11.47: Number of rows with unexpected values for ''imprace'' and a list
    of unexpected values'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.47：具有意外值的 `imprace` 行数和意外值的列表。
- en: 'The following figure illustrates the number of rows with unexpected values
    and a list of unexpected values for each column:'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了具有意外值的行数以及每列意外值的列表：
- en: '![Figure 11.48: Number of rows with unexpected values and'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.48：具有意外值的行数和'
- en: a list of unexpected values for each column
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 每列的意外值列表
- en: '](img/B15019_11_48.jpg)'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_48.jpg)'
- en: 'Figure 11.48: Number of rows with unexpected values and a list of unexpected
    values for each column'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.48：具有意外值的行数以及每列意外值的列表
- en: 'The following figure illustrates a list of unique values for gaming:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了游戏的唯一值列表：
- en: '![Figure 11.49: List of unique values for gaming'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.49：游戏的唯一值列表'
- en: '](img/B15019_11_49.jpg)'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_49.jpg)'
- en: 'Figure 11.49: List of unique values for gaming'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.49：游戏的唯一值列表
- en: 'The following figure displays the data types of each column:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了每列的数据类型：
- en: '![Figure 11.50: Data types of each column'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.50：每列的数据类型'
- en: '](img/B15019_11_50.jpg)'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_50.jpg)'
- en: 'Figure 11.50: Data types of each column'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.50：每列的数据类型
- en: 'The following figure displays the updated data types of each column:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了每列的更新数据类型：
- en: '![Figure 11.51: Data types of each column'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.51：每列的数据类型'
- en: '](img/B15019_11_51.jpg)'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_51.jpg)'
- en: 'Figure 11.51: Data types of each column'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.51：每列的数据类型
- en: 'The following figure displays the number of missing values for numerical variables:'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了数值变量的缺失值数量：
- en: '![Figure 11.52: Number of missing values for numerical variables'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.52：数值变量的缺失值数量'
- en: '](img/B15019_11_52.jpg)'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_52.jpg)'
- en: 'Figure 11.52: Number of missing values for numerical variables'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.52：数值变量的缺失值数量
- en: 'The following figure displays the list of unique values for `int_corr`:'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了 `int_corr` 的唯一值列表：
- en: '![Figure 11.53: List of unique values for ''int_corr'''
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.53：''int_corr'' 的唯一值列表'
- en: '](img/B15019_11_53.jpg)'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_53.jpg)'
- en: 'Figure 11.53: List of unique values for ''int_corr'''
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.53：'int_corr' 的唯一值列表
- en: 'The following figure displays the list of unique values for numerical variables:'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了数值变量的唯一值列表：
- en: '![Figure 11.54: List of unique values for numerical variables'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.54：数值变量的唯一值列表'
- en: '](img/B15019_11_54.jpg)'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_54.jpg)'
- en: 'Figure 11.54: List of unique values for numerical variables'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.54：数值变量的唯一值列表
- en: 'The following figure displays the number of missing values for numerical variables:'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了数值变量的缺失值数量：
- en: '![Figure 11.55: Number of missing values for numerical variables'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.55：数值变量的缺失值数量'
- en: '](img/B15019_11_55.jpg)'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_11_55.jpg)'
- en: 'Figure 11.55: Number of missing values for numerical variables'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.55：数值变量的缺失值数量
- en: Note
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The solution to this activity can be found at the following address: [https://packt.live/2GbJloz](https://packt.live/2GbJloz).'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以在以下地址找到：[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。
- en: Summary
  id: totrans-556
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, you learned how important it is to prepare any given dataset
    and fix the main quality issues it has. This is critical because the cleaner a
    dataset is, the easier it will be for any machine learning model to easily learn
    about the relevant patterns. On top of this, most algorithms can''t handle issues
    such as missing values, so they must be handled prior to the modeling phase. In
    this chapter, you covered the most frequent issues that are faced in data science
    projects: duplicate rows, incorrect data types, unexpected values, and missing
    values.'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了准备给定数据集并修复其主要质量问题的重要性。这一点至关重要，因为数据集越干净，任何机器学习模型就越容易学到相关的模式。更重要的是，大多数算法无法处理缺失值等问题，因此必须在建模阶段之前解决这些问题。在本章中，你涵盖了数据科学项目中最常遇到的问题：重复行、错误的数据类型、意外值和缺失值。
- en: The goal of this chapter was to introduce you to the concepts that will help
    you to spot some of these issues and easily fix them so that you have the basic
    toolkit to be able to handle other cases. As a final note, throughout this chapter,
    we emphasized how important it is to discuss the issues you find with the business
    or the data engineering team you are working with. For instance, if you've detected
    unexpected values in a dataset, you may want to confirm that they don't have any
    special meaning from a business point of view before removing or replacing them.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是向您介绍一些概念，这些概念将帮助您发现一些问题并轻松修复它们，从而拥有基本工具箱，可以处理其他情况。最后需要注意的是，在本章的整个过程中，我们强调了与您所在的业务或数据工程团队讨论发现的问题的重要性。例如，如果您在数据集中检测到意外的值，您可能希望在删除或替换它们之前确认它们在业务上是否具有特殊意义。
- en: 'You also need to be very careful when fixing issues: you don''t want to alter
    the dataset too much so that it creates additional unexpected patterns. This is
    exactly why it is recommended that you replace any of the missing values of numerical
    variables with their **mean** or **median**. Otherwise, you will change its distribution
    drastically. For example, if the values of a variable are between 0 and 10, replacing
    all the missing values with -999 will drastically change their mean and **standard**
    **deviation**.'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 在修复问题时，您还需要非常小心：您不希望过度修改数据集，以免产生额外的意外模式。这正是为什么建议您用**平均值**或**中位数**替换数值变量中的任何缺失值。否则，您将会大幅改变其分布。例如，如果某个变量的值在0到10之间，将所有缺失值替换为-999将极大地改变它们的平均值和**标准**
    **偏差**。
- en: In the next chapter, we will discuss the interesting topic of feature engineering.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论特征工程这一有趣的主题。
