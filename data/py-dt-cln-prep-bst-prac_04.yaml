- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Cleaning Messy Data and Data Manipulation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清理杂乱数据与数据处理
- en: In this chapter, we’ll dive into the strategies of **data manipulation**, focusing
    on efficient techniques to clean and fix messy datasets. We’ll remove irrelevant
    columns, systematically address inconsistent data types, and fix dates and times.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨**数据处理**的策略，重点介绍高效清理和修复杂乱数据集的技巧。我们将移除无关列，系统地处理不一致的数据类型，并修复日期和时间。
- en: 'In this chapter, we’ll cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Renaming columns
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重命名列
- en: Removing irrelevant or redundant columns
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除无关或冗余的列
- en: Fixing data types
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复数据类型
- en: Working with dates and times
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理日期和时间
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You can find all the code for this chapter in the following GitHub link: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter04](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter04).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下 GitHub 链接找到本章的所有代码：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter04](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter04)。
- en: Each file is named according to the respective sections covered in this chapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 每个文件都根据本章所涉及的相应章节命名。
- en: Renaming columns
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重命名列
- en: Renaming columns with more descriptive and meaningful names makes it easier
    to understand the content and purpose of each column. Clear and intuitive column
    names enhance the interpretability of the dataset, especially when sharing or
    collaborating with others.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为列重命名更具描述性和意义的名称，使得每列的内容和目的更加容易理解。清晰直观的列名提高了数据集的可解释性，特别是在与他人共享或协作时。
- en: To better understand all the concepts introduced in this chapter, we will use
    a scenario across the chapter. Let’s consider an e-commerce company that wants
    to analyze customer purchase data to optimize its marketing strategies. The dataset
    includes information about customer transactions, such as purchase amount, payment
    method, and timestamp of the transactions. However, the dataset is messy and requires
    cleaning and manipulation to derive meaningful insights.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解本章中介绍的所有概念，我们将在本章中使用一个场景。假设有一家电子商务公司，想要分析客户的购买数据，以优化其营销策略。数据集包含有关客户交易的信息，如购买金额、支付方式和交易时间戳。然而，数据集很杂乱，需要清理和处理才能提取有意义的洞察。
- en: The distribution of the features is presented in the following figure. To build
    the following statistic charts, execute the file at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/1.descriptive_stats.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/1.descriptive_stats.py).
    The data and the following charts are created automatically once you run this
    script.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了特征的分布。要构建以下的统计图表，请执行文件：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/1.descriptive_stats.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/1.descriptive_stats.py)。运行此脚本后，数据和图表会自动生成。
- en: '![Figure 4.1 – Distribution of features before any data transformation](img/B19801_04_1.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – 数据转化前的特征分布](img/B19801_04_1.jpg)'
- en: Figure 4.1 – Distribution of features before any data transformation
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 数据转化前的特征分布
- en: 'We have five columns in the dataset:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含五个列：
- en: '`CustomerID`: A unique identifier for each customer. In this example, customer
    IDs range from `1` to `11`.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CustomerID`：每个客户的唯一标识符。在这个示例中，客户ID的范围是`1`到`11`。'
- en: '`ProductName`: This represents the name of the purchased product. In the dataset,
    three products are considered: `Product_A`, `Product_B`, and `Product_C`.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProductName`：表示购买的产品名称。在数据集中，考虑了三种产品：`Product_A`、`Product_B`和`Product_C`。'
- en: '`PurchaseAmount`: This indicates the amount spent by the customer on a particular
    product. The amounts are in an arbitrary currency.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PurchaseAmount`：表示客户在某个产品上的消费金额。金额使用的是任意货币。'
- en: '`PaymentMethod`: This describes the method used by the customer to make the
    purchase. Payment methods include `Card`, `PayPal`, `Cash`, and `Bank Transfer`.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PaymentMethod`：描述客户用于购买的支付方式。支付方式包括`Card`、`PayPal`、`Cash`和`Bank Transfer`。'
- en: '`Timestamp`: This represents the date and time when the purchase occurred.
    It is formatted as a `datetime` object.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Timestamp`：表示购买发生的日期和时间。它以`datetime`对象的格式呈现。'
- en: The first thing we are going to check and update are the column names. Let’s
    start with this in the following section.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要检查和更新的是列名。让我们在接下来的部分开始这项工作。
- en: Renaming a single column
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重命名单个列
- en: Now, the e-commerce company has decided to rebrand its products, necessitating
    a change in the column names related to product information. We’ll start by renaming
    a single column, and then we’ll further rename multiple columns to align with
    the rebranding initiative. For the renaming example, go to the file at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/2.rename_columns.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/2.rename_columns.py).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这家电子商务公司决定重新品牌化其产品，需要更改与产品信息相关的列名。我们将从重命名一个列开始，然后进一步重命名多个列以配合品牌重塑的计划。有关重命名示例，请访问
    [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/2.rename_columns.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/2.rename_columns.py)。
- en: 'Let’s have a look at how we can rename one column in the dataset:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在数据集中重命名一个列：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `inplace=True` argument is an optional parameter in pandas DataFrame methods
    that allows you to modify the DataFrame directly without creating a new DataFrame
    object.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`inplace=True` 参数是 pandas DataFrame 方法中的一个可选参数，它允许你直接修改 DataFrame，而不必创建一个新的
    DataFrame 对象。'
- en: When `inplace` is set to `True`, the DataFrame is modified in place, meaning
    the changes are applied to the original DataFrame object. This can be useful when
    you want to update or modify the DataFrame without assigning the modified DataFrame
    to a new variable.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当`inplace`设置为`True`时，DataFrame 会就地修改，这意味着更改会应用到原始的 DataFrame 对象上。这在你想更新或修改 DataFrame
    而无需将修改后的 DataFrame 分配给新变量时非常有用。
- en: If `inplace=True` is not specified or set to `False` (which is the default behavior),
    the DataFrame methods return a new modified DataFrame object, leaving the original
    DataFrame unchanged. In such cases, you need to assign the modified DataFrame
    to a new variable to store the changes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有指定`inplace=True`或者将其设置为`False`（这是默认行为），DataFrame 方法会返回一个新的修改后的 DataFrame
    对象，原始 DataFrame 不会被改变。在这种情况下，你需要将修改后的 DataFrame 分配给一个新变量以保存更改。
- en: Note
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: It’s important to note that using `inplace=True` can be a destructive operation
    since it modifies the original DataFrame directly. Therefore, it’s recommended
    to use it with caution and ensure that you have a backup of the original DataFrame
    if needed. If you have a large dataset, modifying it in place can help conserve
    memory.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，使用`inplace=True`可能是一个破坏性操作，因为它会直接修改原始的 DataFrame。因此，建议谨慎使用，并确保在需要时有原始
    DataFrame 的备份。如果你有一个大数据集，原地修改可以帮助节省内存。
- en: In the next section, we will rename multiple columns to align with the rebranding
    initiative.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将重命名多个列，以便与品牌重塑活动保持一致。
- en: Renaming all columns
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重命名所有列
- en: 'Following a rebranding initiative, the company decided to rename `OldProductName`
    as `NewProductName` and `PurchaseAmount` as `NewPurchaseAmount` to align with
    the updated product names. This code demonstrates how to rename multiple columns
    at once:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在一次品牌重塑活动后，公司决定将`OldProductName`重命名为`NewProductName`，并将`PurchaseAmount`重命名为`NewPurchaseAmount`，以便与更新后的产品名称一致。此代码演示了如何一次性重命名多个列：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If you want to rename columns in a DataFrame and need to ensure a smooth and
    error-free process, we can add error handling. For example, ensure that the columns
    you intend to rename actually exist in the DataFrame. If a column is misspelled
    or does not exist, the renaming operation will raise an error:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想重命名 DataFrame 中的列，并确保过程顺利且无错误，我们可以添加错误处理。例如，确保你打算重命名的列确实存在于 DataFrame 中。如果某个列名拼写错误或不存在，重命名操作将引发错误：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Ensure that the new column names do not already exist in the DataFrame to avoid
    overwriting existing columns.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 确保新的列名在 DataFrame 中不存在，以避免覆盖已有的列。
- en: Renaming a column is one of the simplest things we can do to make our data cleaner
    and easier to understand. The next thing we usually do is keep only the columns
    we need or care about, as we will discuss in the next section.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 重命名列是我们让数据更整洁、易于理解的最简单操作之一。接下来，我们通常会做的是只保留我们需要的或关心的列，如下一节所讨论的那样。
- en: Removing irrelevant or redundant columns
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除无关或冗余的列
- en: Large datasets often contain numerous columns, some of which may be irrelevant
    to the specific analyses or tasks at hand. By eliminating these columns, we can
    get some significant benefits. Firstly, storage requirements are dramatically
    reduced, leading to cost savings and more efficient use of resources. Additionally,
    the streamlined dataset results in faster query performance, optimized memory
    usage, and expedited processing times for complex analyses. This not only improves
    the overall efficiency of data processing tasks but also facilitates easier management
    and maintenance of large datasets. Furthermore, in cloud-based environments, where
    storage costs are a factor, the removal of unnecessary columns directly contributes
    to cost efficiency. So, let’s have a look at how we can drop columns in an efficient
    way.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 大型数据集通常包含大量列，其中一些可能与当前的分析或任务无关。通过删除这些列，我们可以获得一些显著的好处。首先，存储需求大幅减少，从而节省成本并提高资源的使用效率。此外，精简后的数据集使查询性能更快，内存使用更加优化，并且加快了复杂分析的处理时间。这不仅提高了数据处理任务的整体效率，也简化了大型数据集的管理和维护。此外，在基于云的环境中，存储成本是一个重要因素，删除不必要的列有助于提高成本效率。所以，让我们看看如何以高效的方式删除列。
- en: 'In the e-commerce dataset we presented earlier, we have collected information
    about customer purchases. However, as your analysis focuses on product-related
    metrics and customer behavior, certain columns, such as `CustomerID` and `Timestamp`,
    may be considered irrelevant to the current analysis. The goal is to streamline
    the dataset by dropping these columns. You can follow along with this example
    using this Python script [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/3.dropping_columns.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/3.dropping_columns.py):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前展示的电子商务数据集中，我们收集了有关客户购买的信息。然而，由于你的分析侧重于与产品相关的指标和客户行为，某些列，如`CustomerID`和`Timestamp`，可能对当前分析而言不相关。目标是通过删除这些列来精简数据集。你可以通过以下Python脚本进行操作：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/3.dropping_columns.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/3.dropping_columns.py)：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, if you have a look at the dataset, the column before the deletion was
    this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你查看数据集，删除前的列是这样的：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After dropping the two columns, we have the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 删除这两列后，我们得到如下结果：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Python, by default, is case-sensitive. This means that `ColumnName` and `columnname`
    are considered different.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Python默认区分大小写。这意味着`ColumnName`和`columnname`被视为不同的。
- en: 'We successfully removed the unnecessary columns, as demonstrated earlier. To
    further assess memory efficiency, we can calculate the memory consumption of the
    DataFrame both before and after the column deletion. The following code provides
    a Python example of how to calculate the memory used by the DataFrame before and
    after the drop of columns:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如前所示成功移除了不必要的列。为了进一步评估内存效率，我们可以计算删除列前后DataFrame的内存消耗。以下代码提供了一个Python示例，演示如何计算删除列前后DataFrame的内存使用量：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The initial memory usage of the DataFrame was approximately 0.00054 megabytes,
    and after dropping columns, it reduced to around 0.00037 megabytes. The achieved
    reduction in memory usage showcases an optimization of nearly 31%.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 初始时，DataFrame的内存使用量大约为0.00054兆字节，删除列后，内存使用量降至约0.00037兆字节。内存使用量的减少展示了接近31%的优化。
- en: While this example involves a small dataset, the principles of memory efficiency
    hold significant implications when extrapolated to big data scenarios. In large-scale
    datasets, the impact of removing unnecessary columns becomes even more pronounced.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个示例涉及的是一个小数据集，但当这些原则扩展到大数据场景时，内存效率的影响更加显著。在大规模数据集中，删除不必要的列的影响将更加明显。
- en: 'To underline the significance of the operation, consider a scenario with a
    substantial dataset. Initially, the dataset size was 100,000 megabytes, and after
    the removal of unnecessary columns, it was reduced to 69,000 megabytes. To execute
    the same workload, the initial option would be utilizing an AWS EC2 instance of
    type `r7g.4xlarge` with an hourly rate of $1.0064 and memory of 128 GiB, as we
    need 100 gigabytes of memory to load just the dataset. However, by reducing the
    dataset size to 61 gigabytes, an alternative, more cost-effective option is available,
    employing an `r7g.2xlarge` instance at $0.5032 per hour and memory of 64 GiB.
    In the context of a five-minute workload runtime, the cost associated with the
    operation before dropping the data was as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了强调操作的重要性，考虑一个包含大量数据集的场景。最初，数据集的大小为100,000兆字节，经过去除不必要的列后，大小减少到69,000兆字节。为了执行相同的工作负载，最初的选择是使用AWS
    EC2实例类型`r7g.4xlarge`，其小时费率为$1.0064，内存为128 GiB，因为我们需要100GB的内存才能加载数据集。然而，通过将数据集大小减少到61GB，便可以选择一种更具成本效益的替代方案，使用`r7g.2xlarge`实例，小时费率为$0.5032，内存为64
    GiB。在五分钟的工作负载运行时间的背景下，操作前的数据处理成本如下：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The solution became approximately 50% more cost-effective after dropping unnecessary
    columns. This represents the cost savings achieved by optimizing the dataset and
    utilizing a more suitable AWS instance type.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 去除不必要的列后，解决方案的成本大约降低了50%。这代表通过优化数据集并使用更合适的AWS实例类型所实现的成本节省。
- en: 'The simplicity of this example underscores a crucial message:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子的简洁性突显了一个重要的讯息：
- en: '*Streamline your data operations by focusing on what is truly essential and
    let this simplicity* *drive cost-effectiveness.*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*通过关注真正重要的部分来简化你的数据操作，让这种简洁性* *推动成本效益的提高。*'
- en: Transitioning from dropping columns to fixing inconsistent data types involves
    addressing the quality and integrity of the remaining columns in your dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从去除列到修复不一致数据类型的过渡涉及确保数据集中剩余列的质量和完整性。
- en: Dealing with inconsistent and incorrect data types
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理不一致和错误的数据类型
- en: 'When working with a DataFrame, it’s important to ensure that each column has
    the correct data type. Inconsistent or incorrect data types can lead to errors
    in analysis, unexpected behavior, and difficulties in performing operations. Let’s
    review how you can handle such situations. You can find the code for this example
    here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/4.data_types.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/4.data_types.py).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理DataFrame时，确保每一列具有正确的数据类型非常重要。不一致或错误的数据类型可能会导致分析中的错误、意外的行为以及在执行操作时遇到困难。让我们看看如何处理这种情况。你可以在这里找到这个例子的代码：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/4.data_types.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/4.data_types.py)。
- en: Inspecting columns
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查列
- en: 'Inspecting the data types of each column in the data is an essential step in
    identifying any inconsistencies or incorrect data types. The `dtypes` attribute
    of a DataFrame provides information about the data types of each column. Let’s
    check the data types of the columns in our dataset:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 检查数据中每一列的类型是识别任何不一致或错误数据类型的重要步骤。DataFrame的`dtypes`属性提供了每一列的数据类型信息。让我们检查数据集中各列的数据类型：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The types are presented here:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了几种类型：
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Inspecting the data types allows you to understand the current representation
    of the data and determine if any data type conversions or transformations are
    needed for further analysis or data cleaning tasks. In the following sections,
    we will perform different type transformations.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 检查数据类型可以帮助你了解当前数据的表示方式，并判断是否需要进行数据类型转换或变换以便进一步分析或数据清理。接下来的章节中，我们将进行不同类型的转换。
- en: Columnar type transformations
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列类型转换
- en: In the data world, various `astype` method is your friend. The most common type
    transformations that you should be comfortable with are presented in the next
    sections.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据处理的世界里，`astype`方法是你的好帮手。你应该熟悉的最常见的类型转换将在接下来的章节中介绍。
- en: Converting to numeric types
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换为数值类型
- en: 'In pandas, the `astype()` function is used to convert a column to a specified
    numeric data type. For example, to convert a column named `PurchaseAmount` to
    an integer type, you can use the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 中，`astype()` 函数用于将列转换为指定的数字数据类型。例如，要将名为`PurchaseAmount`的列转换为整数类型，可以使用以下方法：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now, let’s see how we can turn columns into strings.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何将列转换为字符串。
- en: Converting to string types
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换为字符串类型
- en: 'You can use the `astype()` function to convert a column into a string type:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`astype()`函数将列转换为字符串类型：
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now, let’s see how we can turn columns into categorical types.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何将列转换为类别类型。
- en: Converting to categorical types
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换为类别类型
- en: 'A **categorical type** refers to a data type that represents categorical or
    discrete variables. Categorical variables can take on a limited, and usually fixed,
    number of distinct categories or levels. These variables often represent qualitative
    data or attributes with no inherent order:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**类别类型**（**categorical type**）指的是表示类别或离散变量的数据类型。类别变量可以取有限的，通常是固定的不同类别或级别。这些变量通常表示定性数据或没有内在顺序的属性：'
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The last transformation we will discuss is the Boolean.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论的最后一个转换是布尔值（Boolean）。
- en: Converting to Boolean types
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换为布尔类型
- en: 'A `True`/`False`) values based on certain conditions or criteria. This transformation
    is often used to create binary indicators or flags, making it easier to work with
    and analyze data:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基于特定条件或标准的 `True`/`False` 值。这种转换通常用于创建二进制指示符或标志，使得数据更容易处理和分析：
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The preceding code part checks whether each element in the `ProductName` column
    contains the substring `Dive`. It returns a Boolean Series where each element
    is `True` if the condition is met and `False` otherwise:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码部分检查 `ProductName` 列中的每个元素是否包含子字符串 `Dive`。它返回一个布尔序列，其中每个元素如果满足条件则为 `True`，否则为
    `False`：
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `astype('bool')` method is used to explicitly cast the data type of the
    `HasDive` column to Boolean.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`astype(''bool'')` 方法用于显式地将 `HasDive` 列的数据类型转换为布尔类型。'
- en: Things to be aware of when using astype(bool)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `astype(bool)` 时需要注意的事项
- en: 'If you’re experiencing a situation where all values are being converted to
    `True`, it could be due to one of the following reasons:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遇到所有值都被转换为 `True` 的情况，可能是由于以下原因之一：
- en: 1\. `True` in a Boolean context, `.astype(bool)` will convert all non-zero values
    to `True`. In such cases, consider if the column contains unexpected or unintended
    non-zero values.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 在布尔上下文中，`.astype(bool)` 会将所有非零值转换为 `True`。在这种情况下，请考虑该列是否包含了意外或不必要的非零值。
- en: 2\. `True` when using `.astype(bool)`. Check if there are missing values present
    in the column and consider how you want to handle them. You may need to fill in
    or drop missing values before the conversion.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 使用 `.astype(bool)` 时为 `True`。检查该列中是否存在缺失值，并考虑如何处理这些缺失值。在转换之前，可能需要填充或删除缺失值。
- en: In the last section of this chapter, we’ll discuss how to handle dates and times.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后一部分，我们将讨论如何处理日期和时间。
- en: Working with dates and times
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理日期和时间
- en: Imagine you have data that includes information about when things happened –
    being able to understand and handle that time-related data is key for making sense
    of patterns and trends. It’s not just about understanding when things happened,
    but also about making it easier to visualize and tell stories with your data.
    Whether you’re diving into trends over time, filtering data for specific periods,
    or making predictions with machine learning, being good with dates and times is
    key to unlocking valuable insights from datasets that involve the dimension of
    time.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你有关于事件发生时间的数据——能够理解和处理这些时间相关的数据是理解模式和趋势的关键。它不仅仅是了解事件发生的时间，而是通过数据更轻松地进行可视化和讲述故事。无论是分析随时间变化的趋势，筛选特定时期的数据，还是使用机器学习进行预测，熟练掌握日期和时间是从涉及时间维度的数据集中解锁宝贵见解的关键。
- en: Now that we understand why dealing with dates and time is so important, the
    next step is learning how to grab that time-related info and make it work for
    us.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了为什么处理日期和时间如此重要，下一步是学习如何获取与时间相关的信息并让它为我们所用。
- en: Importing and parsing date and time data
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入并解析日期和时间数据
- en: Python provides several main functions to parse dates, depending on the format
    of the input date string and the desired output. Let’s discuss the commonly used
    functions for parsing dates.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Python 提供了几种主要的日期解析函数，具体取决于输入日期字符串的格式和所需的输出。让我们讨论一些常用的日期解析函数。
- en: pd.to_datetime() from the pandas library
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pandas 库中的 `pd.to_datetime()`
- en: 'This function is specifically designed for parsing date strings within pandas
    DataFrames or Series, but it can also be used independently. It is suitable when
    working with tabular data and allows handling multiple date formats simultaneously:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数专门用于解析pandas DataFrame或Series中的日期字符串，但也可以独立使用。当处理表格数据时非常适用，并且允许同时处理多种日期格式：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The `format` parameter specifies the expected format of the input string. In
    this example, `%Y` represents the four-digit year, `%m` represents the month,
    `%d` represents the day, `%H` represents the hour, `%M` represents the minute,
    and `%S` represents the second.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`format`参数指定了输入字符串的预期格式。在此示例中，`%Y`表示四位数字的年份，`%m`表示月份，`%d`表示日期，`%H`表示小时，`%M`表示分钟，`%S`表示秒。'
- en: Considerations
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 注意事项
- en: If your dataset contains missing or inconsistent timestamp values, consider
    using the `errors` parameter. For example, `errors='coerce'` will replace parsing
    errors with **Not a Time** (**NaT**) values.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据集包含缺失或不一致的时间戳值，请考虑使用`errors`参数。例如，`errors='coerce'`将把解析错误替换为**非时间**（**NaT**）值。
- en: While `pd.to_datetime` is efficient, it may have performance implications for
    large datasets. For improved performance, consider using the `infer_datetime_format=True`
    parameter to automatically infer the format (works well for standard formats).
    When `infer_datetime_format` is set to `True`, and `parse_dates` is enabled, Pandas
    will try to automatically deduce the format of datetime strings in the columns.
    If successful, it switches to a more efficient parsing method, potentially boosting
    parsing speed by 5-10 times in certain scenarios.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管`pd.to_datetime`效率较高，但对于大数据集，它可能会对性能产生影响。为了提高性能，考虑使用`infer_datetime_format=True`参数来自动推断格式（对标准格式效果较好）。当`infer_datetime_format`设置为`True`，并且`parse_dates`启用时，Pandas将尝试自动推断列中日期时间字符串的格式。如果成功，它将切换到更高效的解析方法，在某些场景下可能将解析速度提高5到10倍。
- en: If your data involves different time zones, consider using the `utc` and `tz`
    parameters to handle **Coordinated Universal Time** (**UTC**) conversion and time
    zone localization.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据涉及不同的时区，请考虑使用`utc`和`tz`参数来处理**协调世界时**（**UTC**）转换和时区本地化。
- en: In the next section, we will introduce another method, `strftime`. This method
    allows for the customization of datetime values, enabling the creation of specific
    and readable representations of time.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍另一种方法，`strftime`。此方法允许自定义日期时间值，从而创建特定且易于阅读的时间表示。
- en: strftime() from the datetime module
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: strftime()来自datetime模块
- en: 'This function is used to parse a date string into a datetime object based on
    *a specified format string*. It is suitable when you have a known date format
    and want precise control over the parsing process:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数用于根据*指定的格式字符串*将日期字符串解析为日期时间对象。当您有已知的日期格式并希望精确控制解析过程时，它非常适用：
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The resulting DataFrame is as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 结果 DataFrame 如下：
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The format is controlled by format specifiers, each starting with a percent
    (`%`) character, representing different components of the date and time (e.g.,
    `%Y` for the year, `%m` for the month, `%d` for the day, `%H` for the hour, `%M`
    for the minute, `%S` for the second, etc.). A full list of format specifiers can
    be found in the Python documentation: [https://strftime.org/](https://strftime.org/).'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 格式由格式说明符控制，每个说明符以百分号（`%`）字符开头，表示日期和时间的不同组成部分（例如，`%Y`表示年份，`%m`表示月份，`%d`表示日期，`%H`表示小时，`%M`表示分钟，`%S`表示秒等）。可以在Python文档中找到完整的格式说明符列表：[https://strftime.org/](https://strftime.org/)。
- en: Unlike the rigid structure required by `strftime`, `dateutil.parser.parse()`
    excels in interpreting a wide range of date and time representations, offering
    a dynamic solution for parsing diverse datetime strings, as we will see in the
    next section.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 与`strftime`所要求的严格结构不同，`dateutil.parser.parse()`在解释各种日期和时间表示方式方面表现出色，提供了一种动态的解决方案，用于解析多种不同的日期时间字符串，正如我们将在下一节中看到的那样。
- en: dateutil.parser.parse() from the dateutil library
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: dateutil.parser.parse()来自dateutil库
- en: 'This function provides a flexible approach to parse date strings, *automatically
    inferring* the format based on the input. It is useful when dealing with a variety
    of date formats or when the format is unknown:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数提供了一种灵活的方法来解析日期字符串，*自动推断*输入的格式。当处理多种日期格式或格式未知时，它非常有用：
- en: '[PRE18]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: One thing to note about this method is that the parser can infer and *handle
    time zone information*, making it convenient for working with data originating
    from different time zones.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这种方法的解析器可以推断并*处理时区信息*，使得处理来自不同时间区的数据变得更加便捷。
- en: In the next section, instead of treating dates and times, we shift our approach
    to splitting them into individual parts, such as days, months, and years.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分中，我们不再处理日期和时间，而是转向将其分割为各个部分，如天、月和年。
- en: Extracting components from dates and times
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取日期和时间的组件
- en: 'You can extract specific components of a datetime object, such as year, month,
    day, hour, minute, or second, using the attributes provided by the datetime module:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 datetime 模块提供的属性提取 datetime 对象的特定组件，如年份、月份、日期、小时、分钟或秒：
- en: '[PRE19]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Using the `.dt` accessor, we can extract the day, month, and year components
    from the `Timestamp` column and create new columns, `Day`, `Month`, and `Year`,
    as presented here:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `.dt` 访问器，我们可以从 `Timestamp` 列中提取天、月和年的组件，并创建新的列 `Day`、`Month` 和 `Year`，如下所示：
- en: '[PRE20]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Extracting components is useful in the following cases:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 提取组件在以下情况下非常有用：
- en: '**Temporal analysis**: If your analysis involves patterns or trends that vary
    across days, months, or years, extracting these components facilitates a more
    focused exploration.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间分析**：如果你的分析涉及到跨天、跨月或跨年的模式或趋势，提取这些组件有助于进行更为专注的探索。'
- en: '**Grouping and aggregation**: When grouping data based on temporal patterns,
    extracting components allows for easy aggregation and summarization.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分组与聚合**：当基于时间模式对数据进行分组时，提取组件可以方便地进行聚合和总结。'
- en: '**Time series analysis**: For time series analysis, breaking down datetime
    values into components is essential for understanding seasonality and trends.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间序列分析**：对于时间序列分析，将日期时间值分解为各个组件对理解季节性和趋势至关重要。'
- en: Moving on to calculate time differences and durations elevates our exploration
    of temporal data by introducing a dynamic dimension.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 继续计算时间差异和持续时间，将通过引入动态维度提升我们对时间数据的探索。
- en: Calculating time differences and durations
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算时间差异和持续时间
- en: 'When calculating the time difference between two datetime objects using subtraction,
    you harness the inherent capability of Python’s `datetime` library to produce
    a `timedelta` object. This object encapsulates the duration between the two timestamps,
    providing a comprehensive representation of the temporal gap in terms of days,
    hours, minutes, and seconds. The code for this section can be found here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/8.time_deltas.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/8.time_deltas.py):'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '当使用减法计算两个 datetime 对象之间的时间差时，你可以利用 Python `datetime` 库的内在能力来生成一个 `timedelta`
    对象。这个对象封装了两个时间戳之间的持续时间，以天、小时、分钟和秒为单位，提供了对时间差的全面表示。该部分的代码可以在此找到：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/8.time_deltas.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter04/8.time_deltas.py):'
- en: '[PRE21]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This pandas function, `.diff()`, calculates the difference between each element
    and the previous element in the `Timestamp` column. It effectively computes the
    time elapsed since the previous timestamp for each row.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 pandas 函数 `.diff()` 计算 `Timestamp` 列中每个元素与前一个元素之间的差异。它有效地计算了自上一个时间戳以来的时间差。
- en: '[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Similar to the first line, this computes the difference between each element
    and the following element in the `Timestamp` column. It calculates the time duration
    until the next timestamp. The negative sign is applied to reverse the sign of
    the time differences. This is done to get a positive representation of the time
    until the next purchase.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 与第一行类似，这计算了 `Timestamp` 列中每个元素与下一个元素之间的差异。它计算了直到下一个时间戳的时间持续。负号应用于反转时间差的符号。这样做是为了获取直到下次购买的时间差的正表示。
- en: 'Let’s see how the time delta is depicted in the data:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看数据中时间差是如何表现的：
- en: '[PRE23]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'If you are wondering when it is a good idea to consider adding some time differences
    in your data workflow, then read the following:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在考虑何时在数据工作流程中加入一些时间差异，可以阅读以下内容：
- en: '**Time-based analysis**: Calculating time differences allows for analyzing
    the duration between events or timestamps. It helps quantify the time taken for
    different processes, activities, or intervals.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于时间的分析**：计算时间差异可以分析事件或时间戳之间的持续时间。它有助于量化不同过程、活动或间隔所花费的时间。'
- en: '**Performance measurement**: By measuring the duration of tasks or events,
    you can evaluate performance metrics, such as response time, processing time,
    or time taken to complete an operation. This information can guide optimization
    efforts and identify areas for improvement.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能测量**：通过测量任务或事件的持续时间，可以评估性能指标，如响应时间、处理时间或完成操作所需的时间。这些信息可以指导优化工作，并识别改进的领域。'
- en: '**Event sequencing**: By comparing timestamps, you can determine the chronological
    order in which events occurred. This sequencing helps you understand the relationships
    between events and their dependencies.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件排序**：通过比较时间戳，您可以确定事件发生的时间顺序。这种排序有助于理解事件之间的关系及其依赖性。'
- en: '**Service-level agreement (SLA) monitoring**: Time differences are useful for
    SLA monitoring. By comparing timestamps related to SLA metrics, such as response
    time or resolution time, you can ensure compliance with agreed-upon service levels.
    Monitoring time differences helps identify SLA breaches and take appropriate actions.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务级别协议（SLA）监控**：时间差异对于SLA监控非常有用。通过比较与SLA指标相关的时间戳，例如响应时间或解决时间，您可以确保遵守约定的服务水平。监控时间差异有助于识别SLA违反并采取适当的措施。'
- en: The `.diff()` method in pandas is primarily used to compute the difference between
    *consecutive* elements in a Series or DataFrame. While it’s straightforward to
    compute first-order differences (i.e., differences between adjacent elements),
    there are additional considerations and variations to explore.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: pandas中的`.diff()`方法主要用于计算Series或DataFrame中*连续*元素之间的差异。虽然计算一阶差异（即相邻元素之间的差异）是直接的，但还有其他需要考虑和探索的变体。
- en: Specifying time intervals
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指定时间间隔
- en: 'You can customize `.diff()` to compute the difference between elements at a
    specific *time interval*. This is achieved by passing the `periods` parameter
    to specify the number of elements to shift:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以自定义`.diff()`来计算特定*时间间隔*内元素之间的差异。这是通过传递`periods`参数来指定要移动的元素数量：
- en: '[PRE24]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s observe the following results:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们观察以下结果：
- en: '[PRE25]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As you can see,`.diff(periods=2)` calculated the difference between each timestamp
    and the two positions before it. The `periods` parameter allows you to specify
    the number of elements to shift when computing the difference. In this case, it
    is `periods=2`, but you can assign to it any value that makes sense for your use
    case.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`.diff(periods=2)`计算了每个时间戳与之前两个位置之间的差异。`periods`参数允许您指定计算差异时要移动的元素数量。在这种情况下，它是`periods=2`，但您可以为其分配任何适合您用例的值。
- en: Handling missing values
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理缺失值
- en: 'The `.diff()` method introduces a NaN for the first 2 elements when used with
    `diff(periods=2)` since there are no previous elements to calculate the difference
    from. You can handle or fill in these missing values based on your specific use
    case:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`diff(periods=2)`时，`.diff()`方法会为前两个元素引入NaN，因为没有前一个元素来计算差异。您可以根据具体用例处理或填充这些缺失值：
- en: '[PRE26]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let’s observe the results:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们观察结果：
- en: '[PRE27]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: As you can see, `fillna(0)` replaced the NaN values with `0`.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`fillna(0)`将NaN值替换为`0`。
- en: Moving on from time differences and durations to time zones and daylight saving
    time, we’ll now address the nuances of handling temporal data across different
    regions.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 从时间差异和持续时间到时区和夏令时，我们现在将讨论如何处理跨不同区域的时间数据的细节。
- en: Handling time zones and daylight saving time
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理时区和夏令时
- en: 'Handling time zones is key when dealing with data that spans multiple geographical
    regions or when accurate time representation is crucial. Time zones help standardize
    time across different locations, considering the offset from UTC due to geographic
    boundaries and daylight-saving time adjustments. In our example dataset, we’ll
    demonstrate how to handle time zones using pandas:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 处理时区在处理跨多个地理区域的数据或准确的时间表示至关重要。时区帮助标准化不同地点的时间，考虑到由于地理边界和夏令时调整导致的UTC偏移。在我们的示例数据集中，我们将演示如何使用pandas处理时区：
- en: '[PRE28]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We localized the timestamps to a specific time zone, in this case, `'UTC'`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将时间戳本地化到特定的时区，在这个例子中是`'UTC'`。
- en: '[PRE29]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We then converted the localized timestamps to a different time zone, in this
    case, `''America/New_York''`. Let’s observe the following results:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将本地化的时间戳转换为不同的时区，在这个例子中是`'America/New_York'`。让我们观察以下结果：
- en: '[PRE30]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Curious about the significance of managing time zones? Let’s understand why
    it matters:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解管理时区的重要性吗？让我们来看看它为什么重要：
- en: When working with data collected from different time zones, it is essential
    to handle time zones to ensure accurate analysis and interpretation. Without proper
    time zone handling, the analysis might be skewed due to inconsistencies in time
    representation.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在处理来自不同时间区的数据时，必须处理时区以确保准确的分析和解读。如果没有正确的时区处理，分析结果可能会因为时间表示不一致而出现偏差。
- en: For applications that require precise time representation, such as financial
    transactions, log entries, or event tracking, handling time zones becomes crucial.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于需要精确时间表示的应用，如金融交易、日志条目或事件跟踪，时区处理变得至关重要。
- en: When integrating data from various sources or merging datasets, handling time
    zones becomes necessary to align timestamps accurately. This ensures the correct
    chronological ordering of events and prevents inconsistencies in time-based analysis.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在整合来自不同来源的数据或合并数据集时，时区处理变得必要，以确保时间戳的准确对齐。这确保了事件的正确时间顺序，并避免了基于时间的分析中的不一致。
- en: If you are developing applications or services that serve users across different
    time zones, handling time zones is crucial for providing accurate and relevant
    information to users based on their local time.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在开发面向不同时间区用户的应用或服务，处理时区是至关重要的，能够为用户提供基于他们本地时间的准确和相关信息。
- en: Considerations
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑事项
- en: Time zone handling should be implemented consistently throughout the data processing
    pipeline to avoid inconsistencies or errors.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 时区处理应该在数据处理流程中始终如一地实施，以避免不一致或错误。
- en: Let’s summarize the learnings from this chapter.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下本章的学习内容。
- en: Summary
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter was about the techniques for cleaning and manipulating data. Beginning
    with the challenges of messy data, we covered the removal of irrelevant columns
    and the handling of inconsistent data types. Practical use cases were demonstrated
    with an e-commerce dataset, showcasing Python code for effective data transformations.
    The importance of dropping unnecessary columns was emphasized, highlighting potential
    cost reductions and memory efficiency gains, particularly for big data. Data type
    transformations, including numeric, string, categorical, and Boolean conversions,
    were illustrated with practical examples. The chapter then explored intricate
    aspects of working with dates and times, showcasing methods such as `pd.to_datetime()`,
    `strftime`, and `dateutil.parser.parse()`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了清理和处理数据的技巧。从混乱数据的挑战开始，我们介绍了如何删除无关的列以及如何处理不一致的数据类型。通过电子商务数据集展示了实际案例，展示了使用
    Python 代码进行有效的数据转换。特别强调了删除不必要列的重要性，突出了潜在的成本降低和内存效率提升，尤其是在大数据环境下。数据类型转换，包括数字、字符串、分类和布尔值转换，通过实际示例进行了说明。接着，本章深入探讨了处理日期和时间的复杂问题，展示了诸如`pd.to_datetime()`、`strftime`和`dateutil.parser.parse()`等方法。
- en: As we wrap up this chapter, it lays a solid foundation for the upcoming one
    in which data merging and transformations will be discussed.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 随着本章的结束，它为下一章的数据合并和转换奠定了坚实的基础。
