- en: '*Chapter 12*: Building a Kafka Cluster'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 12 章*：构建 Kafka 集群'
- en: In this chapter, you will move beyond batch processing – running queries on
    a complete set of data – and learn about the tools used in stream processing.
    In stream processing, the data may be infinite and incomplete at the time of a
    query. One of the leading tools in handling streaming data is Apache Kafka. Kafka
    is a tool that allows you to send data in real time to topics. These topics can
    be read by consumers who process the data. This chapter will teach you how to
    build a three-node Apache Kafka cluster. You will also learn how to create and
    send messages (**produce**) and read data from topics (**consume**).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将超越批量处理 – 在完整数据集上运行查询 – 并了解流处理中使用的工具。在流处理中，数据在查询时可能是无限的和不完整的。处理流数据的主要工具之一是
    Apache Kafka。Kafka 是一个允许您将数据实时发送到主题的工具。这些主题可以被消费者读取并处理数据。本章将教您如何构建一个三节点 Apache
    Kafka 集群。您还将学习如何创建和发送消息（**生产**）以及从主题中读取数据（**消费**）。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Creating ZooKeeper and Kafka clusters
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 ZooKeeper 和 Kafka 集群
- en: Testing the Kafka cluster
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试 Kafka 集群
- en: Creating ZooKeeper and Kafka clusters
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 ZooKeeper 和 Kafka 集群
- en: Most tutorials on running applications that can be distributed often only show
    how to run a single node and then you are left wondering how you would run this
    in production. In this section, you will build a three-node ZooKeeper and Kafka
    cluster. It will run on a single machine. However, I will split each instance
    into its own folder and each folder simulates a server. The only modification
    when running on different servers would be to change localhost to the server IP.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数关于运行可分布式应用程序的教程通常只展示如何运行单个节点，然后您会想知道如何在生产环境中运行。在本节中，您将构建一个三节点 ZooKeeper 和
    Kafka 集群。它将在一台机器上运行。然而，我将每个实例分割到其自己的文件夹中，每个文件夹模拟一个服务器。在运行在不同服务器上的唯一修改就是将 localhost
    更改为服务器 IP。
- en: 'The next chapter will go into detail on the topic of Apache Kafka, but for
    now it is enough to understand that Kafka is a tool for building real-time data
    streams. Kafka was developed at LinkedIn and is now an Apache project. You can
    find Kafka on the web at [http://kafka.apache.org](http://kafka.apache.org). The
    website is shown in the following screenshot:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将详细介绍 Apache Kafka 的主题，但到目前为止，了解 Kafka 是一个用于构建实时数据流的工具就足够了。Kafka 是在 LinkedIn
    开发的，现在是一个 Apache 项目。您可以在 [http://kafka.apache.org](http://kafka.apache.org) 上找到
    Kafka。网站截图如下：
- en: '![Figure 12.1 – Apache Kafka website'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 12.1 – Apache Kafka website'
- en: '](img/Figure_12.1_B15739.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_12.1_B15739.jpg](img/Figure_12.1_B15739.jpg)'
- en: Figure 12.1 – Apache Kafka website
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.1 – Apache Kafka 网站
- en: 'Kafka requires another application, ZooKeeper, to manage information about
    the cluster, to handle discovery, and to elect leaders. You can install and build
    a ZooKeeper cluster on your own, but for this example, you will use the ZooKeeper
    scripts provided by Kafka. To learn more about ZooKeeper, you can find it at [http://zookeeper.apache.org](http://zookeeper.apache.org).
    The website is shown in the following screenshot:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 需要另一个应用程序 ZooKeeper 来管理有关集群的信息，处理发现并选举领导者。您可以自己安装和构建 ZooKeeper 集群，但在此示例中，您将使用
    Kafka 提供的 ZooKeeper 脚本。要了解更多关于 ZooKeeper 的信息，您可以在 [http://zookeeper.apache.org](http://zookeeper.apache.org)
    上找到它。网站截图如下：
- en: '![Figure 12.2 – The Apache ZooKeeper website'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 12.2 – The Apache ZooKeeper website'
- en: '](img/Figure_12.2_B15739.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_12.2_B15739.jpg](img/Figure_12.2_B15739.jpg)'
- en: Figure 12.2 – The Apache ZooKeeper website
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.2 – Apache ZooKeeper 网站
- en: The following section will walk you through building the cluster.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分将指导您构建集群。
- en: Downloading Kafka and setting up the environment
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载 Kafka 和设置环境
- en: 'You can download Apache Kafka from the website under the `wget` to download
    it from the command line. From your home directory, run the following commands:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从网站上的 `wget` 下载 Apache Kafka，从命令行运行以下命令：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding commands download the current Kafka version and extract it into
    the current directory. Because you will run three nodes, you will need to create
    three separate folders for Kafka. Use the following commands to create the directories:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的命令下载了当前的 Kafka 版本并将其提取到当前目录中。由于您将运行三个节点，您需要为 Kafka 创建三个单独的文件夹。使用以下命令创建目录：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You will now have three Kafka folders. You will also need to specify a log
    directory for each instance of Kafka. You can create three folders using the `mkdir`
    command, as shown:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您将拥有三个 Kafka 文件夹。您还需要为 Kafka 的每个实例指定一个日志目录。您可以使用 `mkdir` 命令创建三个文件夹，如下所示：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, you will need a `data` folder for ZooKeeper. Create the directory, and
    then enter it using `cd`, as shown:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要为 ZooKeeper 创建一个 `data` 文件夹。创建该目录，然后使用 `cd` 进入，如下所示：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You will run three ZooKeeper instances, so you will need to create a folder
    for each instance. You can do that using `mkdir`, as shown:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您将运行三个 ZooKeeper 实例，因此您需要为每个实例创建一个文件夹。您可以使用 `mkdir` 命令来完成，如下所示：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Each ZooKeeper instance needs an ID. It will look for a file named `myid` with
    an integer value in it. In each folder, create the corresponding `myid` file with
    the correct value. The following commands will create the file:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 ZooKeeper 实例需要一个 ID。它将寻找一个名为 `myid` 的文件，其中包含一个整数值。在每个文件夹中，创建相应的 `myid` 文件并设置正确的值。以下命令将创建该文件：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You have completed the prerequisite tasks for configuring ZooKeeper and Kafka.
    Now you can edit the configuration files for both. The next section will walk
    you through the process.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 您已完成配置 ZooKeeper 和 Kafka 的先决任务。现在您可以编辑两者的配置文件。下一节将指导您完成这个过程。
- en: Configuring ZooKeeper and Kafka
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置 ZooKeeper 和 Kafka
- en: The configuration files for both ZooKeeper and Kafka are in the Kafka directory
    in the `conf` folder. Since you have three Kafka directories, I will walk through
    using `Kafka_1` and the steps will need to be applied to every other directory.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ZooKeeper 和 Kafka 的配置文件都位于 Kafka 目录下的 `conf` 文件夹中。由于您有三个 Kafka 目录，我将通过 `Kafka_1`
    进行说明，步骤需要应用到其他每个目录。
- en: 'From the `~/kafka_1/conf` directory, you will need to edit the `zookeeper.properties`
    file. You will edit the data directory and the servers, as well as adding properties.
    The configuration file is shown in the following code block, with the modifications
    in bold (for the full file, refer to the GitHub repo):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从 `~/kafka_1/conf` 目录，您需要编辑 `zookeeper.properties` 文件。您将编辑数据目录和服务器，以及添加属性。配置文件如下所示，其中修改的内容用粗体标出（完整文件请参考
    GitHub 仓库）：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: After making the changes, you can save the file. You will now need to modify
    this file in the `kafka_2` and `kafka_3` directories. Note that the `dataDir`
    setting will end in `zookeeper_2` and `zookeeper_3`, respectively. Also, the port
    number should increment by one to `2182` and `2183`. Everything else will remain
    the same. Again, the only reason you are changing the directory and ports is so
    that you can run three servers on a single machine. On three distinct servers,
    you would leave the settings as they are, only changing localhost to the IP address
    of the server.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 修改完成后，您可以保存文件。现在您需要修改 `kafka_2` 和 `kafka_3` 目录中的此文件。请注意，`dataDir` 设置将分别以 `zookeeper_2`
    和 `zookeeper_3` 结尾。此外，端口号应递增到 `2182` 和 `2183`。其他所有内容都将保持不变。再次强调，您更改目录和端口号的唯一原因是可以在单台机器上运行三个服务器。在三个不同的服务器上，您将保持设置不变，只需将
    localhost 更改为服务器的 IP 地址。
- en: 'Now that ZooKeeper is configured, you can configure Kafka. In the same `conf`
    directory, open the `server.properties` file. The file is shown with the edits
    in bold (for the full file, refer to the GitHub repo):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，ZooKeeper 已配置完毕，您可以配置 Kafka。在相同的 `conf` 目录中，打开 `server.properties` 文件。文件中用粗体标出了编辑内容（完整文件请参考
    GitHub 仓库）：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For each Kafka directory, you will modify the `server.properties` file to have
    a broker ID of `1`, `2`, and `3`. You can use any integer, but I am keeping them
    the same as the folder names. Also, you will set the listeners to `localhost:9092`,
    `localhost:9093`, and `localhost:9094`. The `log.dirs` property will be set to
    each of the `log_1`, `log_2`, and `log_3` folders. All three configurations will
    have the same value for the `zookeeper.connect` property.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个 Kafka 目录，您需要修改 `server.properties` 文件，使其具有 `1`、`2` 和 `3` 的代理 ID。您可以使用任何整数，但我会保持它们与文件夹名称相同。此外，您需要将监听器设置为
    `localhost:9092`、`localhost:9093` 和 `localhost:9094`。`log.dirs` 属性将被设置为 `log_1`、`log_2`
    和 `log_3` 文件夹中的每一个。所有三个配置的 `zookeeper.connect` 属性都将具有相同的值。
- en: You have created all the necessary directories to simulate three servers and
    have configured both ZooKeeper and Kafka. You can now move on to starting the
    clusters.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您已创建了模拟三个服务器所需的所有必要目录，并已配置了 ZooKeeper 和 Kafka。现在您可以开始启动集群。
- en: Starting the ZooKeeper and Kafka clusters
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动 ZooKeeper 和 Kafka 集群
- en: To run the servers, you will need to open six terminals – you will not run them
    in the background.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行服务器，您需要打开六个终端 – 您不能在后台运行它们。
- en: Docker
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Docker
- en: You could use Docker Compose to run multiple containers and launch everything
    with a single file. Containers are an excellent tool, but beyond the scope of
    this book.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 Docker Compose 来运行多个容器，并通过单个文件启动所有内容。容器是一个出色的工具，但超出了本书的范围。
- en: 'In the first three terminals, you will launch the ZooKeeper cluster. In each
    terminal, enter the Kafka folder for each instance. Run the following command:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在前三个终端中，您将启动 ZooKeeper 集群。在每个终端中，输入每个实例的 Kafka 文件夹。运行以下命令：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: When you start all of the servers, a lot of text will scroll by as the servers
    look for others and hold an election. Once they connect, the text will stop, and
    the cluster will be ready.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当您启动所有服务器时，服务器将寻找彼此并举行选举，因此会有大量文本滚动。一旦它们连接，文本将停止，集群将准备就绪。
- en: 'To start the Kafka cluster, enter an instance of the `kafka` directory in each
    of the three remaining terminals. You can then run the following command in each
    terminal:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动 Kafka 集群，在每个剩余的三个终端中输入 `kafka` 目录的一个实例。然后，您可以在每个终端中运行以下命令：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'When you are finished, you will have a line in each terminal that should look
    like the following line:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当您完成时，每个终端都应该有一行看起来像以下这样的行：
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You now have two clusters of three nodes running for both ZooKeeper and Kafka.
    To test out the clusters and make sure everything is working properly, the next
    section will create a topic, a consumer and, a producer, and send some messages.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您有两个由三个节点组成的集群正在运行，分别用于 ZooKeeper 和 Kafka。为了测试集群并确保一切正常工作，下一节将创建一个主题、一个消费者和一个生产者，并发送一些消息。
- en: Testing the Kafka cluster
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试 Kafka 集群
- en: Kafka comes with scripts to allow you to perform some basic functions from the
    command line. To test the cluster, you can create a topic, create a producer,
    send some messages, and then create a consumer to read them. If the consumer can
    read them, your cluster is running.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 附带了一些脚本，允许您从命令行执行一些基本功能。要测试集群，您可以创建一个主题，创建一个生产者，发送一些消息，然后创建一个消费者来读取它们。如果消费者可以读取它们，则您的集群正在运行。
- en: 'To create a topic, run the following command from your `kafka_1` directory:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个主题，从您的 `kafka_1` 目录运行以下命令：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding command runs the `kafka-topics` script with the `create` flag.
    It then specifies the ZooKeeper cluster IP addresses and the topic. If the topic
    was created, the terminal will have printed the following line:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令使用 `create` 标志运行 `kafka-topics` 脚本。然后指定 ZooKeeper 集群的 IP 地址和主题。如果主题已创建，终端将打印以下行：
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can verify this by listing all the topics in the Kafka cluster using the
    same script, but with the `list` flag:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过使用相同的脚本并带有 `list` 标志来列出 Kafka 集群中的所有主题来验证这一点：
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The result should be a single line: `dataengineering`. Now that you have a
    topic, you can send and receive messages on it. The next section will show you
    how.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该是一行：`dataengineering`。现在您已经有一个主题，您可以在其上发送和接收消息。下一节将向您展示如何操作。
- en: Testing the cluster with messages
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用消息测试集群
- en: 'In the next chapters, you will use Apache NiFi and Python to send and receive
    messages, but for a quick test of the cluster, you can use the scripts provided
    to do this as well. To create a producer, use the following command:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，您将使用 Apache NiFi 和 Python 来发送和接收消息，但为了快速测试集群，您也可以使用提供的脚本来完成这项工作。要创建一个生产者，请使用以下命令：
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The preceding command uses the `kafka-console-producer` script with the `broker-list`
    flag that passes the `kafka` cluster servers. Lastly, it takes a topic, and since
    we only have one, it is `dataengineering`. When it is ready, you will have a `>`
    prompt to type messages into.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令使用带有 `broker-list` 标志的 `kafka-console-producer` 脚本，该标志传递 `kafka` 集群服务器。最后，它接受一个主题，因为我们只有一个，所以它是
    `dataengineering`。当它准备好时，您将有一个 `>` 提示符，可以输入消息。
- en: 'To read the messages, you will need to use the `kafka-console-consumer` script.
    The command is as shown:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要读取消息，您需要使用 `kafka-console-consumer` 脚本。命令如下所示：
- en: '[PRE15]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The consumer passes the `zookeeper` flag with the list of servers. It also specifies
    the topic and the `from-beginning` flag. If you had already read messages, you
    could specify an `offset` flag with the index of the last message so that you
    start from your last position.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者传递带有服务器列表的 `zookeeper` 标志。它还指定了主题和 `from-beginning` 标志。如果您已经读取了消息，您可以指定带有最后一条消息索引的
    `offset` 标志，这样您就可以从您的最后位置开始。
- en: 'Putting the producer and consumer terminals next to each other, you should
    have something like the following screenshot:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 将生产者和消费者终端并排放置，您应该会有以下截图类似的东西：
- en: '![Figure 12.3 – Producer and consumer'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 12.3 – 生产者和消费者'
- en: '](img/Figure_12.3_B15739.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![图12.3](img/Figure_12.3_B15739.jpg)'
- en: Figure 12.3 – Producer and consumer
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 – 生产者和消费者
- en: In the preceding screenshot, you will notice that I typed *first message* and
    *second message* twice. When the consumer turned on, it read all the messages
    on the topic. Once it has read them all, it will await new messages. If you type
    a message in the producer, it will show up in the consumer window after a short
    lag.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的屏幕截图中，你会注意到我两次输入了“第一条消息”和“第二条消息”。当消费者启动时，它会读取该主题上的所有消息。一旦它读取完毕，它将等待新的消息。如果你在生产者那里输入一条消息，它将在短暂的延迟后出现在消费者窗口中。
- en: You now have a fully functional Kafka cluster and are ready to move on to stream
    processing with NiFi and Python in the next chapter.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经拥有了一个完全功能化的Kafka集群，并准备好在下一章中继续使用NiFi和Python进行流处理。
- en: Summary
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned how to create a Kafka cluster, which required the
    creation of a ZooKeeper cluster. While you ran all of the instances on a single
    machine, the steps you took will work on different servers too. Kafka allows the
    creation of real-time data streams and will require a different way of thinking
    than the batch processing you have been doing.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何创建一个Kafka集群，这需要创建一个ZooKeeper集群。虽然你是在一台机器上运行所有实例，但你采取的步骤也适用于不同的服务器。Kafka允许创建实时数据流，并且需要与之前你进行的批量处理不同的思维方式。
- en: The next chapter will explain the concepts involved in streams in depth. You
    will also learn how to process streams in both NiFi and Python.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将深入解释流中涉及的概念。你还将学习如何在NiFi和Python中处理流。
