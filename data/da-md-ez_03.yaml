- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Transforming Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据转换
- en: Now that we have the basics of KNIME at hand, we can move to the next level.
    In this chapter, we will learn how to transform data to make the best out of it
    systematically. The following pages will show how to work with multiple tables,
    aggregate data points, apply expressions, and iterate through your workflows to
    automating their execution. All these new skills will make you an autonomous user
    of KNIME when manipulating real-world data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了 KNIME 的基础知识，可以进入下一个层次。在本章中，我们将学习如何系统地转换数据，以充分利用它。接下来的页面将展示如何处理多个表，汇总数据点，应用表达式，并通过工作流进行迭代，从而实现它们的自动执行。这些新技能将使你在处理现实世界数据时，成为
    KNIME 的独立用户。
- en: 'This chapter will answer the following questions:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将回答以下问题：
- en: What is a data model, and how can I visualize it?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是数据模型，我该如何可视化它？
- en: How can I combine several data tables?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何合并多个数据表？
- en: How can I aggregate data points and calculate formulas?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何汇总数据点并计算公式？
- en: How can KNIME automate the creation of summary reports?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何让 KNIME 自动化生成汇总报告？
- en: What do variables and loops look like in KNIME?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 KNIME 中，变量和循环是什么样子的？
- en: 'This chapter will end with a full tutorial based on real data and a very realistic
    business case: it will be an opportunity to put into practice all you''ve learned
    so far about KNIME while confronting the complexity of data you will face in your
    work. Before diving into the concrete ways to transform data, let''s invest a
    few minutes in the fundamentals of relational databases and data models.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将以一个基于真实数据和非常实际的商业案例的完整教程作为结束：这将是一个实践你迄今为止学到的所有 KNIME 知识的机会，同时面对你工作中将遇到的数据复杂性。在深入探讨数据转换的具体方法之前，让我们先花几分钟了解关系型数据库和数据模型的基础知识。
- en: Modeling your data
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据建模
- en: 'Data tables are hardly useful when they lie apart. In fact, by organizing them
    together in a database, we amplify their overall value as we unveil patterns and
    connections across data points. That is why data is typically stored in an ensemble
    of different tables connected with each other to virtually form a single body
    called a **Data Model**. When you work with multiple tables, it is beneficial
    to "visualize" what the underlying data model looks like: this gives you the ability
    to anticipate ways to leverage the data and interpret it correctly.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据表分散开时，它们几乎没有什么用处。实际上，通过将它们组织到一个数据库中，我们可以通过揭示数据点之间的模式和联系来放大它们的整体价值。这就是为什么数据通常存储在一个由多个互相连接的表组成的集合中，虚拟地形成一个叫做**数据模型**的整体。当你处理多个表时，"可视化"底层数据模型是什么样的非常有帮助：这使你能够预测如何利用数据并正确解读它。
- en: 'We shall bring the concept of a data model to life by going through a business
    example. Let''s imagine that we own a small store selling musical instruments.
    Our business model is pretty simple: we order instruments from manufacturers and
    store them in a warehouse. Customers call at our shop and get the chance to try
    a few instruments before deciding whether to purchase or not. Our most loyal customers
    sign up and get a membership card: occasionally, they receive a newsletter with
    new arrivals and special offers.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过一个商业案例来生动地呈现数据模型的概念。假设我们拥有一家销售乐器的小商店。我们的商业模式非常简单：我们从制造商那里订购乐器并将它们存放在仓库中。顾客会来到我们的商店，并有机会在决定是否购买之前试用一些乐器。我们最忠实的顾客会注册并获得会员卡：偶尔，他们会收到一封包含新到货和特别优惠的通讯。
- en: 'To manage our store''s activities, we use a simple information system that
    keeps track of products, sales, inventory, and customers. Data is organized in
    a simple database, made of four different tables, each having multiple columns,
    whose names are—fortunately—self-explanatory:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了管理我们商店的活动，我们使用一个简单的信息系统，用于追踪产品、销售、库存和客户。数据被组织在一个由四个不同表组成的简单数据库中，每个表都有多个列，且列名—幸运的是—是自解释的：
- en: '**Product Master Data**: This stores the list of products we buy and sell.
    For each product, we have a unique *Product_ID*, a *Category* (like Guitars, Violins,
    and Pianos), a short *Description* (which includes the model of the instrument),
    the *Brand*, and the *List_price*.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**产品主数据**：这存储了我们买卖的产品清单。对于每个产品，我们都有一个唯一的*Product_ID*，一个*类别*（比如吉他、小提琴和钢琴），一个简短的*描述*（包括乐器的型号），*品牌*，以及*列表价格*。'
- en: '**Sales Transactions**: This records all sales. Every row includes the *Date*
    of purchase, the *Receipt_ID* (counting the number of receipts created during
    each day), the *Product_ID*, the *Quantity* (number of items purchased), the *Discount_rate*
    that was applied (if any), the overall *Amount* paid, and—if the customers are
    members of our loyalty card program—their *Customer_ID*.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**销售交易**：这记录所有销售情况。每一行包括*购买日期*、*收据_ID*（统计每一天生成的收据数量）、*产品_ID*、*数量*（购买的商品数量）、应用的*折扣率*（如果有的话）、总*金额*以及——如果顾客是我们忠诚卡计划的会员——他们的*顾客_ID*。'
- en: '**Customer Master Data**: This carries preferences and contact details related
    to our loyalty card members. It includes the unique *Customer_ID*, *Full_Name*,
    *ZIP_Code* of where they live, *Email_Address*, *Telephone* number, and their
    primary *Instrument*.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**顾客主数据**：这包含与我们忠诚卡会员相关的偏好和联系信息。包括独特的*顾客_ID*、*全名*、住址的*邮政编码*、*电子邮箱地址*、*电话号码*以及他们的主要*工具*。'
- en: '**Inventory Transactions**: This accounts for all product movements in our
    warehouse, such as the loading of the items as they arrive and transferring them
    to the shop floor. Its columns are *Date* (which includes the time when it happened),
    *Product_ID*, and *Quantity* (this will be positive when items are loaded in and
    negative when they leave the warehouse).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**库存交易**：这记录了我们仓库中所有产品的移动情况，例如商品到货时的装载以及将其转移到店铺的过程。其列包括*日期*（记录发生时间）、*产品_ID*和*数量*（当商品进入仓库时为正值，离开仓库时为负值）。'
- en: 'By looking at this simple example, we can observe a few features that are worth
    elaborating on as they apply to most databases we would encounter in our work:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个简单的例子，我们可以观察到一些值得进一步阐述的特性，这些特性适用于我们在工作中可能遇到的大多数数据库：
- en: 'We see two different types of tables fulfilling two different needs: **Master
    Data** and **Transactional** tables. Master data tables aim at describing entities
    of business relevance, such as products, customers, suppliers, employees, and
    so on. In these kinds of tables, each row corresponds to an instance of the entity
    (for example, a specific product, or an individual customer), while every column
    describes a different aspect of the entity (like its name or description). On
    the other hand, transactional tables record events (like a monetary transaction,
    a sale, an order) occurring at a specific point in time. Every row corresponds
    to an event, while columns describe the event''s features and the entities that
    took part in it. Master data and transactional data tend to be updated and used
    in different fashions: master data tables are touched more rarely than transactional
    tables. Think about the frequency of adding a new product to the catalog or hiring
    an employee: these events occur much less often than regular sales or inventory
    movements do.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以看到两种不同类型的表格，分别满足两种不同的需求：**主数据**表和**事务性**表。主数据表旨在描述具有业务相关性的实体，例如产品、客户、供应商、员工等。在这些表格中，每一行代表实体的一个实例（例如，特定的产品或单独的客户），而每一列描述实体的不同方面（比如名称或描述）。另一方面，事务性表记录特定时间点发生的事件（例如，货币交易、销售、订单）。每一行对应一个事件，而列描述事件的特征和参与其中的实体。主数据和事务性数据通常以不同的方式进行更新和使用：主数据表的更新频率比事务性表低。试想一下，新增一个产品到目录或雇佣一个员工的频率：这些事件发生的频率远低于常规销售或库存变动。
- en: 'The tables are clearly connected to each other. In fact, many of their columns
    represent the same thing. For instance, *Product_ID*s of sold items are the same
    *Product_ID*s we find in the product master data. The two tables are related and,
    indeed, databases of this kind—omnipresent in firms—are called **Relational Databases**.
    The columns used to connect multiple tables are called **Keys**: when the rows
    of two tables have matching values in their keys, it means that these rows are
    connected and refer to the same event or entity. This means that all rows in the
    sales transactional table having a specific value in the column *Product_ID* (let''s
    say *PS012*) refer to sales of the same product. Thanks to the relationship occurring
    across the tables, you can then find the product''s description by looking up
    the value of *Product_ID* in the product master data (where you will find that
    *PS012* refers to—in this case—a *Steinway piano*).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表之间显然是互相关联的。事实上，它们的许多列代表的是相同的事物。例如，已售商品的*Product_ID*与我们在产品主数据中找到的*Product_ID*相同。这两个表是相关的，实际上，这类数据库——在企业中无处不在——被称为**关系数据库**。用于连接多个表的列被称为**键**：当两个表的行在其键中具有匹配的值时，表示这些行是连接的，指代同一事件或实体。这意味着，在销售事务表中，所有*Product_ID*列具有特定值（假设为*PS012*）的行，都指代同一产品的销售。通过表之间发生的关系，您可以通过查找产品主数据中的*Product_ID*值来找到该产品的描述（在这里，您会发现*PS012*指的是——在这个案例中——一架*斯坦威钢琴*）。
- en: 'A simple and effective way of describing the underlying data model of a relational
    database is through the **Entity-Relationship** (**ER**) **Diagram**. The ER diagram
    looks like a series of boxes connected with each other: each box is a table and
    displays its columns while the connections show the existing relationships across
    keys. *Figure 3.1* represents a simplified rendering of the ER diagram of our
    music store database: keys are highlighted with a bold font and a little icon:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 描述关系数据库底层数据模型的一个简单有效的方法是通过**实体关系**（**ER**）**图**。ER图看起来像是一系列互相连接的框：每个框代表一个表，并展示其列，而连接则显示跨键的现有关系。*图3.1*展示了我们音乐商店数据库的简化ER图：键以粗体字和小图标突出显示：
- en: '![](img/B17125_03_01.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_03_01.png)'
- en: 'Figure 3.1: The Entity-Relationship diagram of the music store database'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1：音乐商店数据库的实体关系图
- en: We will encounter diagrams of this kind throughout this book. I suggest you
    make the effort to sketch the ER diagrams of those tables you use at work the
    most, as it will simplify your thinking on how to best leverage them. In fact,
    mapping all the data available in the various systems of a firm is a tough but
    worthwhile exercise.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中我们会遇到这种类型的图表。我建议您尽力绘制您在工作中最常使用的表的ER图，因为这将简化您对如何最好利用它们的思考。事实上，映射企业中各种系统中所有可用的数据是一个艰难但值得的练习。
- en: 'Keeping this mapping up to date and—in general—managing data assets in a firm
    requires discipline and a set of formal roles, processes, and standards called
    **Data Governance**. A good (and often underestimated) practice of data governance
    is, indeed, to create a **Data Inventory**: this is a systematic description of
    all information assets in a company. As you build an inventory, you are forced
    to map master data and transactional tables correctly, spotting duplications and
    missing keys.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 保持这一映射的最新状态——以及通常来说——在公司中管理数据资产需要一定的纪律性和一套正式的角色、流程和标准，这些被称为**数据治理**。一个好的（而且经常被低估的）数据治理实践，实际上是创建一个**数据清单**：这是一份公司所有信息资产的系统性描述。当您建立数据清单时，您必须正确地映射主数据和事务表，发现重复项和缺失的键。
- en: 'A data inventory includes information about the data stored in tables, such
    as content, source, owners, and licensing: these are all examples of **Metadata**,
    a word that literally means "data about data."'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清单包括有关存储在表中的数据的信息，如内容、来源、所有者和许可：这些都是**元数据**的例子，这个词字面意思是“关于数据的数据”。
- en: Combining tables
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合并表
- en: 'Data models show us how data points within separate tables are logically connected
    with each other. In the practice of data analytics, we often need to combine data
    together by leveraging the logic relationships which the data model describes.
    The most common operation for combining two tables into a third one is called
    **Join**. By combining two tables together, we cross-enrich them as we merge all
    the information we have on a specific event or entity. The join operation will
    take the two tables and match the rows that have the same values in the columns
    we specify (**Matching Columns**). Let''s imagine we have the following two tables,
    which refer to sales transactions and to the product master data:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据模型向我们展示了不同表格中的数据点如何在逻辑上相互关联。在数据分析实践中，我们经常需要通过利用数据模型描述的逻辑关系将数据合并在一起。将两张表格合并成第三张表格的最常见操作称为**连接**。通过合并两张表格，我们可以交叉丰富它们，因为我们合并了关于特定事件或实体的所有信息。连接操作将两张表格中的行进行匹配，前提是我们指定的列中有相同的值（**匹配列**）。让我们假设有以下两张表格，分别表示销售交易和产品主数据：
- en: '| Sales |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 销售 |'
- en: '| Product | Date | Amount |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 产品 | 日期 | 销售额 |'
- en: '| Gibson Explorer B-2 | 21-Dec | 1040 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Gibson Explorer B-2 | 12月21日 | 1040 |'
- en: '| Squier Affinity | 21-Dec | 249 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 12月21日 | 249 |'
- en: '| Yamaha YDP-164 | 22-Dec | 1499 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| Yamaha YDP-164 | 12月22日 | 1499 |'
- en: '| Squier Affinity | 22-Dec | 249 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 12月22日 | 249 |'
- en: 'Table 3.1: Sales table'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.1：销售表
- en: '| Products |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 产品 |'
- en: '| Product | Category |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 产品 | 类别 |'
- en: '| Gibson Explorer B-2 | Guitars |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| Gibson Explorer B-2 | 吉他 |'
- en: '| Squier Affinity | Guitars |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 吉他 |'
- en: '| Yamaha YDP-164 | Pianos |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| Yamaha YDP-164 | 钢琴 |'
- en: 'Table 3.2: Products table'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.2：产品表
- en: 'What if we need to calculate the overall sales generated by each product category?
    The first table tells us the amount of sales for each transaction but misses the
    category information so we cannot aggregate those sales accordingly. The second
    table has the category bit but doesn''t tell us anything about sales. Each table
    is missing something, so we need to combine them by means of a join. The good
    news is that the two tables share a column (*Product*), which could serve for
    doing the matching. Let''s join them together using *Product* as a matching column:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要计算每个产品类别的总销售额怎么办？第一张表告诉我们每笔交易的销售额，但缺少类别信息，因此我们无法相应地汇总这些销售额。第二张表有类别信息，但没有提供任何关于销售的信息。每张表都有缺失的内容，所以我们需要通过连接将它们合并起来。好消息是，这两张表共享一个列（*产品*），可以用作匹配。我们将使用*产品*作为匹配列将它们连接在一起：
- en: '| Join of the two tables above |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 上述两张表的连接 |'
- en: '| Product | Date | Amount | Category |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 产品 | 日期 | 销售额 | 类别 |'
- en: '| Gibson Explorer B-2 | 21-Dec | 1040 | Guitars |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| Gibson Explorer B-2 | 12月21日 | 1040 | 吉他 |'
- en: '| Squier Affinity | 21-Dec | 449 | Guitars |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 12月21日 | 449 | 吉他 |'
- en: '| Yamaha YDP-164 | 22-Dec | 1499 | Piano |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| Yamaha YDP-164 | 12月22日 | 1499 | 钢琴 |'
- en: '| Squier Affinity | 22-Dec | 249 | Guitars |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 12月22日 | 249 | 吉他 |'
- en: 'Table 3.3: Joining the Products table and the Sales table'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.3：连接“产品”表和“销售”表
- en: See what happens? By joining the two tables, we obtain a third one as an output
    where we have, for each transaction, not only the product name, date, and amount
    (which would only be available in the first table) but also the category of each
    product (which is only available in the second table). This table can now be used
    for calculating how much sales are generated by each product category by just
    running the right aggregations (which we'll learn how to do in a few pages).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 看看会发生什么？通过连接这两张表，我们得到一个第三张输出表格，其中每个交易不仅包含产品名称、日期和金额（这些信息仅出现在第一张表格中），还包括每个产品的类别（这些信息仅出现在第二张表格中）。现在，这张表格可以用来计算每个产品类别产生的销售额，只需要进行正确的聚合操作（我们将在接下来的几页中学习如何操作）。
- en: 'To complete our introduction to joins, let''s consider one last aspect. Even
    if two tables have some columns in common (which could be leveraged for our matching),
    they will not necessarily have a correspondence between every row of their own
    and a row in the other table. In the earlier example, we might have, for instance,
    some transactions that refer to instruments not included in the product master
    data (maybe they are new arrivals and haven''t been categorized yet) or the other
    way around (products available in the master data that haven''t sold yet). If
    we combine tables without a perfect matching of the rows, the output might carry
    some blanks (the famous NULL values we met in the previous chapter) since we don''t
    have a corresponding value to use. Depending on our strategy to manage such missing
    matches (and the resulting incomplete rows in the output), we can implement different
    types of joins. Let''s imagine that we want to join the following two tables (by
    convention, the two tables combined in a join operation are called **Left** and
    **Right** table, hence the name of the headers in the following tables):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整介绍连接，我们再考虑一个最后的方面。即使两个表有一些公共列（可以用于匹配），它们也不一定每一行都有与另一表中对应行的匹配。在前面的例子中，我们可能会有一些交易，涉及到未包含在产品主数据中的乐器（可能是新到货的商品，尚未分类），或者反过来（主数据中的产品尚未售出）。如果我们在没有完美匹配行的情况下合并表格，输出可能会包含一些空白（就是我们在上一章中遇到的著名NULL值），因为我们没有相应的值可以使用。根据我们管理这些缺失匹配（以及输出中不完整行的结果）的策略，我们可以实现不同类型的连接。假设我们想连接以下两个表（按惯例，在连接操作中合并的两个表分别称为**左**表和**右**表，因此以下表格中的标题名称）：
- en: '| Left table: Sales |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 左表：销售 |'
- en: '| Product | Date | Amount |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 产品 | 日期 | 金额 |'
- en: '| Gibson Explorer B-2 | 21-Dec | 1040 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| Gibson Explorer B-2 | 21-Dec | 1040 |'
- en: '| Squier Affinity | 21-Dec | 249 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 21-Dec | 249 |'
- en: '| Korg B2 | 21-Dec | 499 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| Korg B2 | 21-Dec | 499 |'
- en: '| Yamaha YDP-164 | 22-Dec | 1274 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| Yamaha YDP-164 | 22-Dec | 1274 |'
- en: '| Squier Affinity | 22-Dec | 249 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 22-Dec | 249 |'
- en: '| Didgeridoo Black 2 | 22-Dec | 459 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| Didgeridoo Black 2 | 22-Dec | 459 |'
- en: 'Table 3.4: Left table'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.4：左表
- en: '| Right table: Products |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 右表：产品 |'
- en: '| Product | Category |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 产品 | 类别 |'
- en: '| Gibson Explorer B-2 | Guitars |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| Gibson Explorer B-2 | 吉他 |'
- en: '| Squier Affinity | Guitars |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 吉他 |'
- en: '| Yamaha YDP-164 | Pianos |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| Yamaha YDP-164 | 钢琴 |'
- en: '| Korg B2 | Pianos |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| Korg B2 | 钢琴 |'
- en: '| Steinway B-211 | Pianos |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| Steinway B-211 | 钢琴 |'
- en: '| American Jazz-5 | Basses |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| American Jazz-5 | 贝斯 |'
- en: 'Table 3.5: Right table'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.5：右表
- en: 'Notice that some products have no corresponding matches in the other table,
    as the following Venn diagram intuitively displays:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，某些产品在另一表中没有相应的匹配项，正如以下文氏图直观地展示的那样：
- en: '![Diagram, venn diagram'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![图示，文氏图'
- en: Description automatically generated](img/B17125_03_02.png)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_03_02.png)
- en: 'Figure 3.2: Venn diagram of Sales and Product tables: not all instruments are
    present in both tables'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2：销售表和产品表的文氏图：并非所有乐器都出现在两个表中
- en: 'Depending on how we prefer to manage the "non-matching" rows in the resulting
    output table, we have four different types of joins:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们希望如何管理结果输出表中“未匹配”行的方式，我们有四种不同类型的连接：
- en: '**Inner Join**: In this case, we only keep the rows with a match in both tables.
    We focus on the intersection of the keys across the two columns. By doing so,
    we avoid generating any NULL value due to non-matching keys. On the other side,
    we might be neglecting some rows which—even if incomplete—carry some valuable
    information, like sales of products not yet categorized.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内连接**：在这种情况下，我们只保留在两个表中都有匹配的行。我们关注的是两个列中键的交集。通过这样做，我们避免了由于键不匹配而生成任何NULL值。另一方面，我们可能会忽略一些行——即使它们不完整——也包含一些有价值的信息，例如尚未分类的产品销售。'
- en: '**Left Outer Join**: This type of join will keep all the rows existing in the
    left table, even those that have no match in the right table. In this way, we
    might incur some NULL values in the output, but we "preserve" the information
    stored in the left table.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**左外连接**：这种连接方式会保留左表中所有现有的行，即使它们在右表中没有匹配项。通过这种方式，我们可能会在输出中遇到一些NULL值，但我们“保留”了左表中的信息。'
- en: '**Right Outer Join**: This one is just the opposite of the previous one and
    will preserve all the rows in the right table, including the ones without a match
    in the left one.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**右外连接**：这种连接方式与前一种相反，保留右表中所有的行，包括那些在左表中没有匹配项的行。'
- en: '**Full Outer Join**: We go for this option when we cannot afford to lose anything!
    All rows in the two tables will be kept, even if they don''t have a match. This
    is the option that could potentially create most NULL values: it''s the price
    to pay to conserve all data.![](img/B17125_03_03.png)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完全外连接**：当我们不能承受丢失任何数据时，我们选择这个选项！即使没有匹配的行，两个表中的所有行也会保留下来。这是一个可能会产生最多NULL值的选项：这是为了保留所有数据的代价。![](img/B17125_03_03.png)'
- en: 'Figure 3.3: The four types of join: decide which rows you want to keep in the
    output'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3：四种连接类型：决定要保留哪些行
- en: 'In *Table 3.6*, you will find the results of applying the four types of joins:
    the NULL values are displayed as a question mark, as you would find in KNIME.
    The Inner Join has no NULL values, as anticipated:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在*表3.6*中，您将看到应用四种连接类型的结果：NULL值显示为问号，正如您在KNIME中看到的那样。内连接没有NULL值，正如预期的那样：
- en: '| Inner Join |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 内连接 |'
- en: '| Product | Date | Amount | Category |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 产品 | 日期 | 金额 | 类别 |'
- en: '| Gibson Explorer B-2 | 21-Dec | 1040 | Guitars |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| Gibson Explorer B-2 | 21-Dec | 1040 | 吉他 |'
- en: '| Squier Affinity | 21-Dec | 249 | Guitars |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 21-Dec | 249 | 吉他 |'
- en: '| Korg B2 | 21-Dec | 499 | Piano |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| Korg B2 | 21-Dec | 499 | 钢琴 |'
- en: '| Yamaha YDP-164 | 22-Dec | 1274 | Piano |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| Yamaha YDP-164 | 22-Dec | 1274 | 钢琴 |'
- en: '| Squier Affinity | 22-Dec | 249 | Guitars |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 22-Dec | 249 | 吉他 |'
- en: 'Table 3.6: Inner Join'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.6：内连接
- en: 'In the Left Outer Join, we will have a row referring to the Didgeridoo sales,
    even if it is yet uncategorized. What probably happened with this peculiar Aboriginal
    instrument is that it is a new shiny arrival that attracted the attention of a
    customer quickly, before we had the time to update the product master table by
    adding it:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在左外连接中，即使某些产品尚未分类，我们仍然会有一行记录与迪吉里杜管的销售相关。这个特殊的土著乐器可能是因为它是一个新到的亮眼商品，吸引了顾客的注意，而我们还没来得及通过更新产品主表来添加它：
- en: '| Left Outer Join |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 左外连接 |'
- en: '| Product | Date | Amount | Category |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 产品 | 日期 | 金额 | 类别 |'
- en: '| Gibson Explorer B-2 | 21-Dec | 1040 | Guitars |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| Gibson Explorer B-2 | 21-Dec | 1040 | 吉他 |'
- en: '| Squier Affinity | 21-Dec | 249 | Guitars |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 21-Dec | 249 | 吉他 |'
- en: '| Korg B2 | 21-Dec | 499 | Piano |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| Korg B2 | 21-Dec | 499 | 钢琴 |'
- en: '| Yamaha YDP-164 | 22-Dec | 1499 | Piano |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| Yamaha YDP-164 | 22-Dec | 1499 | 钢琴 |'
- en: '| Squier Affinity | 22-Dec | 249 | Guitars |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 22-Dec | 249 | 吉他 |'
- en: '| Didgeridoo Black 2 | 22-Dec | 459 | ? |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| Didgeridoo Black 2 | 22-Dec | 459 | ? |'
- en: 'Table 3.7: Left Outer Join'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.7：左外连接
- en: 'In the Right Outer Join, we are also forcing a row for those instruments that,
    given their price, have not sold yet. This view can be beneficial to discover
    products that might require some more advertisement in our next newsletters:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在右外连接中，我们也强制为那些因为价格原因尚未销售的乐器创建一行记录。这个视图可以帮助我们发现可能需要在下一期新闻简报中做更多广告的产品：
- en: '| Right Outer Join |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 右外连接 |'
- en: '| Product | Date | Amount | Category |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 产品 | 日期 | 金额 | 类别 |'
- en: '| Gibson Explorer B-2 | 21-Dec | 1040 | Guitars |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| Gibson Explorer B-2 | 21-Dec | 1040 | 吉他 |'
- en: '| Squier Affinity | 21-Dec | 249 | Guitars |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 21-Dec | 249 | 吉他 |'
- en: '| Korg B2 | 21-Dec | 499 | Piano |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| Korg B2 | 21-Dec | 499 | 钢琴 |'
- en: '| Yamaha YDP-164 | 22-Dec | 1499 | Piano |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Yamaha YDP-164 | 22-Dec | 1499 | 钢琴 |'
- en: '| Squier Affinity | 22-Dec | 249 | Guitars |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 22-Dec | 249 | 吉他 |'
- en: '| Steinway B-211 | ? | ? | Pianos |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Steinway B-211 | ? | ? | 钢琴 |'
- en: '| American Jazz-5 | ? | ? | Basses |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| American Jazz-5 | ? | ? | 贝斯 |'
- en: 'Table 3.8: Right Outer Join'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.8：右外连接
- en: 'The Full Outer Join will contain not only the products that never sold but
    also the ones that haven''t been categorized yet. Creating such a table can help
    us summarize sales by category and spot uncategorized and unsold products all
    at once:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 完全外连接不仅会包含那些从未销售过的产品，还包括那些尚未分类的产品。创建这样的表格可以帮助我们按类别汇总销售情况，并一目了然地发现那些未分类和未售出的产品：
- en: '| Full Outer Join |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 完全外连接 |'
- en: '| Product | Date | Amount | Category |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 产品 | 日期 | 金额 | 类别 |'
- en: '| Gibson Explorer B-2 | 21-Dec | 1040 | Guitars |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| Gibson Explorer B-2 | 21-Dec | 1040 | 吉他 |'
- en: '| Squier Affinity | 21-Dec | 249 | Guitars |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 21-Dec | 249 | 吉他 |'
- en: '| Korg B2 | 21-Dec | 499 | Piano |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| Korg B2 | 21-Dec | 499 | 钢琴 |'
- en: '| Yamaha YDP-164 | 22-Dec | 1499 | Piano |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| Yamaha YDP-164 | 22-Dec | 1499 | 钢琴 |'
- en: '| Squier Affinity | 22-Dec | 249 | Guitars |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| Squier Affinity | 22-Dec | 249 | 吉他 |'
- en: '| Didgeridoo Black 2 | 22-Dec | 459 | ? |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| Didgeridoo Black 2 | 22-Dec | 459 | ? |'
- en: '| Steinway B-211 | ? | ? | Pianos |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| Steinway B-211 | ? | ? | 钢琴 |'
- en: '| American Jazz-5 | ? | ? | Basses |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| American Jazz-5 | ? | ? | 贝斯 |'
- en: 'Table 3.9: Full Outer Join'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.9：完全外连接
- en: As this simple example unveiled for us, there might be value in any type of
    join. As data practitioners, we want to know what options we have available so
    that we can select which one to use, depending on the business case we face.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如这个简单示例所揭示的那样，任何类型的连接都有其价值。作为数据工作者，我们希望了解我们有哪些可用的选项，以便根据我们所面临的业务场景来选择使用哪一种。
- en: To perform joins in KNIME, we can leverage a very useful node which is called—unsurprisingly,
    we shall admit—**Joiner**.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在 KNIME 中执行连接操作时，我们可以利用一个非常有用的节点，这个节点被称为——我们不得不承认——**Joiner**。
- en: '![](img/NEW-Joiner_node.png) *Joiner*'
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/NEW-Joiner_node.png) *Joiner*'
- en: The node (available in **Manipulation > Column > Split & Combine**) joins the
    two tables connected at its input ports according to the user-provided matching
    criteria. To con-figure it (*Figure 3.4*), you first need to specify the criteria
    for the join by choosing the couple of columns in the two tables that are related
    and should match. To add the first couple of columns, click on the button labeled
    **Add matching criterion**. You will find two drop-down menus with the available
    columns of the tables connected with the upper and the lower input ports (by convention,
    they refer, to the **left** and the **right** tables of the join operation, respectively).
    You can add or remove columns to be matched by clicking on the + and the – buttons
    on the right. By default, all the couples of columns you enter here need to have
    matching values for rows to be matched. They also need to be of the same type
    (integers matching with integers, string match-ing with strings, and so on).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点（位于 **Manipulation > Column > Split & Combine**）会根据用户提供的匹配标准将连接在其输入端口的两个表连接起来。要配置它（*图
    3.4*），你首先需要通过选择两个相关并应当匹配的列，来指定连接的标准。要添加第一对列，点击标有 **Add matching criterion** 的按钮。你将看到两个下拉菜单，分别显示连接到上方和下方输入端口的表中的可用列（按照惯例，分别指代连接操作的
    **左** 表和 **右** 表）。你可以通过点击右侧的 + 和 - 按钮来添加或移除要匹配的列。默认情况下，所有在此输入的列对需要具有匹配的值，才能使行匹配。它们也需要是相同的类型（例如，整数与整数匹配，字符串与字符串匹配，等等）。
- en: To solve unmatching data types, the node allows you to convert the data types
    of the columns before assessing the matching criteria. For example, from the selector
    labeled as **Compare value in join columns by**, you can pick **string representation**
    to convert all values to strings before checking if they match.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决不匹配的数据类型，节点允许你在评估匹配标准之前转换列的数据类型。例如，在标有 **Compare value in join columns by**
    的选择器中，你可以选择 **string representation**，将所有值转换为字符串后再检查它们是否匹配。
- en: 'After clarifying the matching criteria, you need to decide the type of join
    operation you would like to perform (**Inner**, **Left outer**, **Right outer**,
    or **Full outer**). To do so, use the Venn diagrams you find in *Figure 3.3* as
    a guide. If you want an inner join, only the **Matching rows** box needs to stay
    selected. For the left or right outer joins, you have to tick also the Left or
    the **Right unmatched rows**, respectively. For the full outer, all box-es should
    be selected. As you noticed from its icon, the node has three outputs. The first
    output port on the top carries the result of the join. You can also decide to
    review the rows that did not find any match in the other table and place them
    in the second and third output ports. If you are interested in viewing the unmatched
    rows as well (it might be useful sometimes to understand why not all rows match),
    you need to tick the **Route unmatched rows to separate ports** box: this will
    activate the second and third ports which would—otherwise—stay inactive and marked
    with a red cross.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在明确匹配标准后，你需要决定希望执行哪种类型的连接操作（**Inner**、**Left outer**、**Right outer** 或 **Full
    outer**）。为此，可以参考 *图 3.3* 中的维恩图。如果你想要内连接，仅需要选择 **Matching rows** 选项框。对于左外连接或右外连接，你还需要分别勾选
    **Left unmatched rows** 或 **Right unmatched rows**。对于全外连接，所有框都应选中。如你从其图标中所见，节点有三个输出端口。顶部的第一个输出端口承载连接结果。你还可以选择查看那些未在另一个表中找到匹配的行，并将它们放入第二和第三个输出端口。如果你也有兴趣查看未匹配的行（有时这有助于理解为何并非所有行都能匹配），你需要勾选
    **Route unmatched rows to separate ports** 选项框：这将激活第二和第三个端口，否则它们将保持不活动并标记为红叉。
- en: 'One last option that you would select in most cases is **Merge joining columns**:
    by doing so, you keep only one "copy" of the pair of columns used to assess the
    matching. If you leave it unticked, you will keep both the two columns which were
    coming from the left and the right input tables: in most cases you don''t want
    that so this box should be al-ways selected.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一种在大多数情况下选择的选项是**合并连接列**：这样做，你只保留一对用于评估匹配的列“副本”。如果你不选中该选项，你将保留来自左侧和右侧输入表的两列：在大多数情况下，你不希望这样，因此此框应始终被选中。
- en: '![Graphical user interface, text, application, email'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_03_04.png)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_03_04.png)
- en: 'Figure 3.4: Configuration dialog of Joiner: select which columns should match'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4：连接器的配置对话框：选择哪些列应匹配
- en: 'In the second tab of the configuration dialog (**Column Selection**), you can
    specify which columns resulting from the join operation should be kept at the
    output port of the node. This might be handy when you know you will not need some
    of the columns in the subsequent steps of your workflow: in this case, just go
    through the columns in the boxes on the right and double-click on the ones to
    remove:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置对话框的第二个标签页（**列选择**）中，你可以指定哪些来自连接操作的列应保留在节点的输出端口。这在你知道在后续的工作流步骤中不需要某些列时非常有用：在这种情况下，只需浏览右侧框中的列，并双击那些需要移除的列：
- en: '![Graphical user interface'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面'
- en: Description automatically generated](img/B17125_03_05.png)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_03_05.png)
- en: 'Figure 3.5: Configuration dialog of Joiner: select which columns should match'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5：连接器的配置对话框：选择哪些列应匹配
- en: For those of you using Microsoft Excel, you will notice that you can implement
    a Left Outer Join in Excel with functions such as `vlookup()`. By using KNIME
    instead of Excel, you can run all types of join (not just the left outer) and
    easily define matching criteria on multiple columns (which in Excel would require
    some workarounds).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用 Microsoft Excel 的用户，你会注意到你可以通过 `vlookup()` 等函数在 Excel 中实现左外连接。通过使用 KNIME
    代替 Excel，你可以执行所有类型的连接（不仅仅是左外连接），并且可以轻松地在多个列上定义匹配标准（在 Excel 中这需要一些变通方法）。
- en: 'For completeness, there are a couple of other ways to combine tables beyond
    the join operator. If you don''t need to take care of any matching criteria and
    you just want to "stitch together" tables that have the same size in one dimension,
    you can:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，除了连接操作符之外，还有一些其他方法可以将表格合并。如果你不需要考虑任何匹配标准，并且只想将具有相同维度大小的表格“拼接在一起”，你可以：
- en: Append columns across two tables that have the same number of rows. You will
    obtain the columns of the first table just beside the second table columns, in
    whatever order they have in the original table. You can do so in KNIME by using
    the **Column** **Appender** node.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将两个具有相同行数的表格的列追加在一起。你将获得第一张表的列，紧跟着第二张表的列，顺序保持原表中的排列。你可以通过使用 KNIME 中的**列追加器**节点来实现。
- en: Concatenate rows of two tables having the same columns, putting the rows of
    the first table on top of the ones coming from the second table. The node for
    this is called just **Concatenate**.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将两张具有相同列的表格的行连接起来，将第一张表的行放在第二张表的行上方。这个节点叫做**连接**。
- en: '*Figure 3.6* give you an idea of how these two nodes would work:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.6* 展示了这两个节点是如何工作的：'
- en: '![](img/B17125_03_06.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_03_06.png)'
- en: 'Figure 3.6: Combining tables without matching criteria: you can append columns
    or concatenate rows with these two nodes'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6：无匹配标准的表格合并：你可以使用这两个节点追加列或连接行
- en: 'Now we are clear on the many ways available to us to combine several tables
    into one. Let''s move to the other omnipresent data transformation need: aggregating
    values to create summary views of a table.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经明确了有许多方法可以将多个表格合并为一个。接下来，我们来看看另一个无处不在的数据转换需求：聚合值以创建表格的摘要视图。
- en: Aggregating values
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚合值
- en: The information contained in a raw data table lies dispersed across all its
    rows. Often, we need to condense a large table into a smaller and more readable
    one where its values get aggregated or summarized following a given logic. For
    instance, if we have a table including all orders received in the last year and
    want to make sense of our sales' evolution over time, we might prefer to calculate
    a simpler table that shows the total number of orders generated every month. Instead
    of having a long table with as many rows as orders, we prefer scanning through
    its aggregation showing only twelve rows, one for each month.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据表中包含的信息分散在所有行中。通常，我们需要将大表压缩为更小、更易读的表格，其中的值按照给定的逻辑进行聚合或总结。例如，如果我们有一张包含去年所有接收订单的表格，并且想要理解销售额随时间的变化，我们可能更喜欢计算一个简单的表格，显示每个月生成的订单总数，而不是长长的表格，其中的行数与订单数一样多，我们更倾向于通过聚合显示只有十二行的表格，每月一行。
- en: 'The simpler way of aggregating data is by using a rather popular database operation
    called **Group By**: it combines rows in various groups and aggregates their values
    within each group. To perform a Group By, you will need to decide two things:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 汇总数据的简单方法是使用一种非常流行的数据库操作，称为**Group By**：它将各个组中的行合并并在每个组内聚合它们的值。要执行 Group By，您需要决定两件事：
- en: 'First, you must declare which columns define a **group**. All the rows showing
    the same values in the columns defining the group will be combined together into
    a single row in the output. Let''s take *Table 3.6* as an example. If you defined
    our group using column *Category*, the result of the Group By will have only two
    rows: one with the total sales of guitars and the other one with the total sales
    of pianos. You can define groups by multiple columns: in this case, you will get
    an aggregated row for each combination of unique values in the group columns.
    For example, if you selected both *Date* and *Category* as group definition, you
    will obtain multiple output rows for each category, one for each different day
    of sales.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，您必须声明哪些列定义了一个**组**。在定义组的列中显示相同值的所有行将在输出中合并成一行。让我们以*表3.6*为例。如果您使用列*类别*定义我们的组，那么
    Group By 的结果将只有两行：一个是吉他的总销售额，另一个是钢琴的总销售额。您可以通过多个列定义组：在这种情况下，您将为每个组列唯一值的每种组合获得一个汇总行。例如，如果您选择*日期*和*类别*作为组定义，那么每个类别将为不同销售日期的每一天获得多个输出行。
- en: Second, you need to decide how to summarize rows across, meaning which **aggregation
    function** to use. For instance, you could simply count all rows appearing in
    a group, summing up their values or calculating their average. In the case of
    the sales summary table, we decided to count the number of sales transactions,
    but we could have calculated the overall income generated each month by using
    the sum as an aggregation function instead.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，您需要决定如何跨行汇总，即使用哪种**聚合函数**。例如，您可以简单地计算出在一组中出现的所有行数，将它们的值相加或计算它们的平均值。在销售汇总表格中，我们决定计算销售交易的数量，但我们也可以使用求和作为聚合函数来计算每个月产生的总收入。
- en: 'It''s time to see the Group By operation in action on our music store example.
    Let''s use as input the result of the Inner Join in *Table 3.6*. We want to summarize
    our sales by product category, calculating the income generated by each category
    and the number of items sold in total:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候在我们的音乐店示例中看到 Group By 操作的实际效果了。让我们使用内连接结果作为输入，在*表3.6*中。我们希望通过产品类别总结我们的销售，计算每个类别生成的收入以及总销售的数量：
- en: '| Sales, group by Category |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 按类别分组的销售 |'
- en: '| Category | Sales | Quantity |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 销售额 | 数量 |'
- en: '| Guitars | 1538 | 3 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 吉他 | 1538 | 3 |'
- en: '| Pianos | 1773 | 2 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 钢琴 | 1773 | 2 |'
- en: 'Table 3.10: Summary of sales by category'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.10：按类别汇总的销售摘要
- en: As we would expect, the resulting table has just two rows, one for each category
    present in the original table. Let's meet the node that can perform aggregation
    of this kind in KNIME.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所预期的那样，生成的表格只有两行，分别对应原始表格中的每个类别。让我们来看看 KNIME 中能够执行这种聚合的节点。
- en: '![](img/image015.png) *GroupBy*'
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image015.png) *按组*'
- en: 'This node (**Manipulation > Row > Transform**) aggregates rows of a table by
    groups, defined by means of a subset of columns. Its basic configuration requires
    two steps. In the **Groups** panel, you need to select which columns define the
    groups by moving them to the list on the right, bordered in green. You can choose
    multiple columns: the output table will have one row for each unique combination
    of different values in all of the columns you specify here. If you don''t select
    a column, you will aggregate all rows at the input into one single grand total
    row at the output:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 此节点（**操作 > 行 > 转换**）按组对表格的行进行聚合，组的定义是通过一组列的子集来实现的。其基本配置需要两个步骤。在**分组**面板中，你需要选择哪些列定义了分组，并将它们移到右侧的列表中，右侧列表用绿色边框标出。你可以选择多列：输出表格将为每个指定列中不同值的唯一组合生成一行。如果你不选择任何列，则会将输入中的所有行汇总成一行总计数据输出：
- en: '![Graphical user interface, text, application'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序'
- en: Description automatically generated](img/B17125_03_07.png)
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_03_07.png)
- en: 'Figure 3.7: Group settings for a Group By: decide what columns define a group'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7：按组设置：决定哪些列定义一个组
- en: 'The second step is to declare which columns should be summarized and using
    which aggregation function. You can define the columns to aggregate upon by double-clicking
    on their name from the left list. Then, you can specify the aggregation function
    by selecting it from the drop-down menu under **Aggregation**. You can select
    the same column multiple times and aggregate it with different functions. In the
    drop-down menu at the bottom (**Column naming**), you can specify the naming convention
    to be used for the aggregate columns. The default option is **Aggregation method
    (column name)**, which will create headers like *Sum(Quantity)*:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是声明哪些列应该被汇总，以及使用哪个聚合函数。你可以通过双击左侧列表中的列名来定义要聚合的列。然后，你可以从下拉菜单中的**聚合**选项选择聚合函数。你可以多次选择相同的列，并使用不同的函数进行聚合。在底部的下拉菜单（**列命名**）中，你可以指定用于聚合列的命名约定。默认选项是**聚合方法（列名）**，这将创建类似于*Sum(Quantity)*的列标题：
- en: '![Graphical user interface, text, application'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序'
- en: Description automatically generated](img/B17125_03_08.png)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_03_08.png)
- en: 'Figure 3.8: Aggregation settings for a Group By: decide how to summarize your
    rows within each group'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8：按组聚合设置：决定如何在每个组内汇总你的行
- en: 'In *Table 3.11*, you find the most popular functions you can use for summarizing
    your rows within each group. For some of these functions, like Count or First,
    you need to decide whether to consider NULLs as values like all others or ignore
    them. If you want them to be ignored (focusing the aggregation on actual values
    only), tick the **Missing** checkbox on the right:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在*表 3.11*中，你可以找到用于汇总每组内行的最常用函数。对于这些函数中的一些，比如计数或首个，你需要决定是否将NULL值视为与其他值一样的值，还是忽略它们。如果你希望忽略NULL值（仅对实际值进行聚合），请勾选右侧的**缺失**复选框：
- en: '| Aggregation Function | Description |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 聚合函数 | 描述 |'
- en: '| Sum | Sums all values in a group, returning the total. |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 求和 | 对一组中的所有值进行求和，返回总和。 |'
- en: '| Count/Unique Count | Counts all rows within each group. Unique Count ignores
    duplicates and counts only distinct values. |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 计数/唯一计数 | 计算每组内的所有行。唯一计数忽略重复值，只计算不同的值。 |'
- en: '| Mean/Median | Calculates averages and the median value within each group.
    |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 平均值/中位数 | 计算每个组内的平均值和中位数值。 |'
- en: '| Mode | Takes the value with the highest number of occurrences in a group.
    |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 众数 | 获取每个组中出现次数最多的值。 |'
- en: '| First/Last | Takes the first/last value appearing in each group, depending
    on their sorting when input. Make sure you sort rows accordingly before. |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 首个/最后一个 | 获取每组中的第一个/最后一个值，取决于输入时的排序。确保在此之前先对行进行排序。 |'
- en: '| Minimum/Maximum | Takes the minimum and the maximum values within the group.
    |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 最小值/最大值 | 获取每个组内的最小值和最大值。 |'
- en: '| Concatenate/Unique Concatenate | Joins all values in a single string, using
    the delimiter indicated in the text box at the bottom. Unique Concatenate ignores
    duplicates. |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 连接/唯一连接 | 将所有值连接成一个字符串，使用文本框底部指定的分隔符。唯一连接会忽略重复值。 |'
- en: '| Correlation | Calculates correlation with another column (you can select
    it by clicking on the **Edit** button), across elements of each group. |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 相关性 | 计算与另一个列的相关性（你可以通过点击**编辑**按钮选择该列），在每个组的元素中计算。 |'
- en: 'Table 3.11: Summarizing functions'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.11：汇总函数
- en: Another way of aggregating data is by using the **Pivot** operation. While the
    Group By groups up being rows in the output table, with this operation, we can
    "rotate" some groups (that we call pivots) to appear vertically, as columns, in
    the output table. You can think of a pivot as a 2-dimensional matrix showing aggregations
    across horizontal groups (which will ultimately appear as rows of the pivot) and
    pivoted vertical groups (appearing as columns in the output matrix).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合数据的另一种方式是使用**Pivot**操作。与“Group By”操作将数据分组为输出表格的行不同，使用该操作我们可以“旋转”一些分组（我们称之为枢轴）使其垂直显示，作为列出现在输出表格中。你可以把枢轴看作一个二维矩阵，显示跨水平分组（最终会显示为枢轴的行）和旋转的垂直分组（作为输出矩阵的列）的聚合结果。
- en: 'Let''s see the Pivot operation in use on our music store example. Starting
    again from the Inner Join result, we would like to summarize our sales in a single
    table showing sums for each combination of categories (horizontal groups) and
    dates (vertical groups, or pivots):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在音乐商店示例中如何使用Pivot操作。再次从内连接结果开始，我们希望通过一个单独的表格总结我们的销售数据，显示每种类别（水平分组）和日期（垂直分组或枢轴）的每个组合的总和：
- en: '| Sales, pivot by Category and Dates |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 销售额，按类别和日期旋转 |'
- en: '| Date | 21-Dec | 22-Dec |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 日期 | 21-Dec | 22-Dec |'
- en: '| Category | Sales | Quantity | Sales | Quantity |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 销售额 | 数量 | 销售额 | 数量 |'
- en: '| Guitars | 1289 | 2 | 249 | 1 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 吉他 | 1289 | 2 | 249 | 1 |'
- en: '| Pianos | 499 | 1 | 1274 | 1 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 钢琴 | 499 | 1 | 1274 | 1 |'
- en: 'Table 3.12: Sales pivot by category and dates'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.12：按类别和日期的销售枢轴
- en: The resulting pivot table has two rows, one for each of the categories (like
    with Group By), and multiple columns showing the aggregations for each available
    date. In KNIME, we can use the **Pivoting** node to create such summaries.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的枢轴表格有两行，每个类别对应一行（与Group By类似），并且有多列，显示每个可用日期的聚合结果。在KNIME中，我们可以使用**Pivoting**节点来创建这样的汇总。
- en: '![](img/image021.png) *Pivoting*'
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image021.png) *Pivoting*'
- en: 'This node (**Manipulation > Row > Transform**) aggregates values by creating
    a pivot table. Its configuration dialog is similar to that of **GroupBy**, but
    contains an additional **Pivots** panel, as the following shows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 此节点（**Manipulation > Row > Transform**）通过创建枢轴表格来聚合值。它的配置对话框与**GroupBy**类似，但包含一个额外的**Pivots**面板，如下所示：
- en: In the **Groups** panel, you specify the input columns that define the horizontal
    groups, which will show as rows in the output pivot table.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**Groups**面板中，您指定定义水平分组的输入列，这些分组将在输出的枢轴表格中显示为行。
- en: In the **Pivots** panel, you specify instead which input columns to use for
    creating the vertical groups, appearing as columns in the resulting table.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**Pivots**面板中，您指定用于创建垂直分组的输入列，这些分组会作为列出现在结果表格中。
- en: Finally, in the **Aggregation** panel, you can select the input columns to summarize
    and the aggregation method to use.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，在**Aggregation**面板中，您可以选择要汇总的输入列和使用的聚合方法。
- en: 'Similar to what we have seen for the **GroupBy** node, the two drop-down menus
    at the bottom (**Column name** and **Aggregation name**) can be used to specify
    the naming convention for the columns of the resulting pivot. By default, you
    will have headers concatenating the name of each pivot with the aggregation method,
    like *21-Dec+Sum(Amount)*:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在**GroupBy**节点中看到的类似，底部的两个下拉菜单（**列名**和**聚合名**）可以用来指定生成的枢轴列的命名约定。默认情况下，您会看到列头将每个枢轴的名称与聚合方法连接在一起，比如
    *21-Dec+Sum(Amount)*：
- en: '![Graphical user interface, application, email'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_03_09.png)
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_03_09.png)
- en: 'Figure 3.9: Pivot setting: select the columns to use for the vertical groups
    (pivots)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9：枢轴设置：选择用于垂直分组（枢轴）的列
- en: 'The **Pivoting** node has not one but three output ports: you can view them
    by selecting one of the last three magnifying lens icons at the bottom of the
    pop-up menu after right-clicking on the node. The first output is the pivot matrix
    (most of the time, you will only need this one), the second one is the total aggregation
    of the horizontal groups only (pivots are ignored), while the third one is the
    grand total across all rows of the pivot (groups are ignored).'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pivoting**节点不仅有一个输出端口，而是有三个：您可以通过右键点击节点后，在弹出菜单底部选择最后三个放大镜图标之一来查看它们。第一个输出是枢轴矩阵（大多数情况下，您只需要这个），第二个输出是仅对水平分组的总聚合（忽略枢轴），第三个输出是所有枢轴行的总和（忽略分组）。'
- en: The concept of pivot tables has been popularized in Microsoft Excel. Knowing
    how to build a pivot in KNIME, you now have access to a broader range of aggregation
    methods, and you will be able to make the pivot operation part of a more extended,
    automated workflow of steps, removing all manual interventions such as refreshes
    and copy/paste.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 数据透视表的概念已被微软Excel普及。现在你已经知道如何在KNIME中构建数据透视表，你可以访问更广泛的聚合方法，并能够将数据透视操作纳入更广泛的自动化工作流程中，消除所有手动干预，如刷新和复制/粘贴。
- en: 'In some cases, you want to run the reverse operation, called **Unpivoting**:
    this will place the columns of a table to appear as multiple rows in the output
    table. If you want to perform this transformation in KNIME, check out the **Unpivoting**
    node.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，你可能需要进行反向操作，称为**反透视**：这将把表格中的列转换为在输出表格中显示为多行。如果你想在KNIME中执行这个转换，查看**反透视**节点。
- en: 'In *Figure 3.10*, you see a summary of the three table aggregations and disaggregation
    methods we have seen:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图3.10*中，你可以看到我们已经讨论过的三种表格聚合和拆解方法的总结：
- en: '![](img/B17125_03_10.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_03_10.png)'
- en: 'Figure 3.10: Transforming tables by aggregating and disaggregating: a summary
    of the most useful operations'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10：通过聚合和拆解转换表格：最有用操作的总结
- en: Combining tables and aggregating values are the fundamental data transformations
    you can do. Let's see them in action in a full tutorial, which will be an opportunity
    to learn a few more tricks about KNIME, like calculating formulas, visualizing
    data, and using loops and variables.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 合并表格和聚合值是你可以进行的基本数据转换。让我们在一个完整的教程中看看这些操作的实际应用，这将是学习KNIME更多技巧的机会，比如计算公式、可视化数据以及使用循环和变量。
- en: 'Tutorial: Sales report automation'
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 教程：销售报告自动化
- en: 'In this tutorial, you will impersonate the role of a business analyst working
    for a UK-based online retailer, selling all-occasion gifts. You are intrigued
    by data analytics and are reading a few (good) books about its potential. You
    have set for yourself the ambition of progressively amplifying the role of data
    analytics in the company by leveraging your new skills. You decide to start from
    something relatively simple: automate and improve the reporting of sales data.
    By doing so, you want to make a quick and visible impact and instill an *appetite*
    for more advanced analytics in your colleagues and managers, unlocking interest
    and investments.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你将扮演一位为一家总部位于英国的在线零售商工作的商业分析师，销售各种场合的礼品。你对数据分析充满兴趣，并且正在阅读一些关于其潜力的（优秀）书籍。你为自己设定了一个目标：通过利用你的新技能，逐步增强公司内数据分析的作用。你决定从一些相对简单的事情入手：自动化并改进销售数据的报告。通过这样做，你希望能够快速且显著地产生影响，激发同事和经理们对更高级数据分析的*兴趣*，从而解锁他们的兴趣和投资。
- en: The company you work for has grown quickly and didn't have the opportunity to
    adopt a sustainable business intelligence solution. The regular reporting is managed
    manually using Excel. The poor finance analyst responsible for it pulls data from
    the company website every Friday and, after a couple of hours of boring manual
    steps, sends an email with the latest status. Due to the manual nature of the
    activity, the reports are prone to human error, and almost every week this causes
    several *back and forth* emails, which leave no time for identifying business-meaningful
    patterns in the data and creating real value. You empathize with the finance analyst
    and decide to set aside a few hours to automate the full reporting process in
    KNIME.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 你所在的公司发展迅速，但没有机会采用可持续的商业智能解决方案。定期报告是通过手动操作Excel来管理的。负责此项工作的财务分析师每周五从公司网站提取数据，并经过几个小时枯燥的手动操作后，发送带有最新状态的电子邮件。由于这项活动的手动性质，报告容易出现人为错误，几乎每周都会引发几封*来回*的电子邮件，导致没有时间识别数据中的商业模式和创造实际价值。你非常理解财务分析师的处境，决定抽出几小时，利用KNIME自动化整个报告过程。
- en: 'First of all, you manage to retrieve a list of the most important business
    questions people ask about sales evolution. This initial list will be a good base
    for your initial endeavor:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你成功地提取了人们关于销售演变的最重要商业问题清单。这个初步清单将成为你初步努力的良好基础：
- en: What are the top ten products in our assortment, meaning the ones that generate
    the most significant number of sales?
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的产品系列中，哪些是销售量最大、最具影响力的前十个产品？
- en: What are the top three products within each subcategory?
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个子类别中排名前三的产品是什么？
- en: To which country do we sell the most?
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们卖得最多的是哪个国家？
- en: During the current calendar year to date, how much revenue was generated within
    each product category?
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 截至当前日历年， 每个产品类别产生了多少收入？
- en: What's the relative footprint of each category out of the total portfolio of
    products for the current year?
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相较于当前年度的总产品组合，每个类别的相对占比是多少？
- en: In which months should we expect a peak in sales for our seasonal categories?
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该在哪些月份预计季节性类别的销售达到峰值？
- en: You decide that your first automated report shall include a tabular view answering
    the first five business questions appearing above. For the last one, since the
    seasonal behavior of the business is not going to change significantly on a weekly
    basis, it will be enough to build a chart that depicts the patterns of sales by
    month as a one-off exercise. Having defined the minimum set of deliverables that
    your work should cover, you are ready to go to the next step and assess what data
    is required to make it happen.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 你决定，第一份自动化报告应包括一个表格视图，回答上述前五个商业问题。对于最后一个问题，由于业务的季节性行为不会在每周变化太大，构建一张展示月度销售模式的图表即可，作为一次性工作。定义了你的工作应涵盖的最小交付集后，你准备进入下一步，评估需要哪些数据来实现这些目标。
- en: Always start any data work by clarifying the business questions you are after.
    Many analytics initiatives fail because there is a lack of understanding of what
    the ultimate objective looks like. Make sure you always "visualize" what you want
    to obtain from your data analytics capabilities and how you expect it to practically
    affect your business. If possible, put it in writing, as we just did with the
    six questions above.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 进行任何数据工作时，首先要明确你所追求的商业问题。许多分析项目失败，原因在于缺乏对最终目标的理解。确保你始终“可视化”你想从数据分析中获得的结果，以及你期望它如何实际影响你的业务。如果可能，将其写下来，就像我们刚才列出的六个问题一样。
- en: With the help of the finance analyst (who is already getting very excited about
    your initiative), you retrieve the latest data required for the regular sales
    reporting and discover that it is scattered across three different tables.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在财务分析师（他已经为你的项目感到非常兴奋）的帮助下，你提取了定期销售报告所需的最新数据，并发现这些数据分散在三个不同的表格中。
- en: '**Product Master Data**: This includes a unique alphanumeric code (column *StockCode*),
    which serves as a product ID, a short *Description*, and two columns to locate
    each item within the two-level product hierarchy used in the company, namely *Category*
    and *Subcategory*. For example, within the category "Stationery," we find the
    subcategories "Notebooks" and "Stickers," while within "Home," we have "Clocks"
    and "Furniture."'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**产品主数据**：包括一个唯一的字母数字代码（*StockCode*列），作为产品ID，一个简短的*描述*，以及两个列用于定位每个商品在公司所使用的两级产品层级中的位置，即*Category*和*Subcategory*。例如，在“文具”类别下，我们有“笔记本”和“贴纸”子类别，而在“家居”类别下，我们有“时钟”和“家具”子类别。'
- en: '**Customer Master Data**: For each customer who has signed up to the website,
    it includes an identifier (*Customer_ID*) and the *Country* of residence.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户主数据**：对于每个已在网站上注册的客户，包括一个标识符（*Customer_ID*）和*Country*（居住国家）。'
- en: '**Sales Transactions**: This is the biggest table as it records all sales.
    For every invoice (identified with column *Invoice_ID*), this table can host multiple
    rows, one for each product (described through its *StockCode*) included within
    the transaction. For each row, we also have the number of purchased items (*Quantity*),
    the unit *Price*, the *Customer_ID* (which can be empty, if the customer hasn''t
    signed up), and a string describing the date and time of the purchase (*Invoice_time*).'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**销售交易**：这是最大的表格，因为它记录了所有销售。对于每个发票（通过*Invoice_ID*列标识），该表格可以包含多行，每行代表一个交易中的产品（通过其*StockCode*描述）。每一行还包括购买的商品数量（*Quantity*）、单价（*Price*）、*Customer_ID*（如果客户未注册，则可能为空）以及描述购买日期和时间的字符串（*Invoice_time*）。'
- en: 'The product and customer master data tables are available in two text files(named`productMD.csv`
    and`customerMD.csv`) extracted from the ordermanagement system. Transactions are
    stored, instead, in two separate Excel files(`TransactionL3M.xlsx`and`TransactionsHistory.xlsx`):
    the first one contains only the most recent sales, covering the latest three months
    of transactions, while the second one has the remainder of the transactions''
    history:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 产品和客户主数据表格存储在两个文本文件中（分别命名为`productMD.csv`和`customerMD.csv`），这些文件来自订单管理系统。交易数据则分别存储在两个Excel文件中（`TransactionL3M.xlsx`和`TransactionsHistory.xlsx`）：第一个文件仅包含最近三个月的销售记录，而第二个文件则包含其余的交易历史记录：
- en: '![](img/B17125_03_11.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_03_11.png)'
- en: 'Figure 3.11: An Entity-Relationship diagram of the online retailer database'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.11：在线零售商数据库的实体-关系图
- en: 'We now have enough knowledge to get started: should we realize we need more
    info on the data and the business needs, we can always go back to our finance
    analyst and ask for extra help. By looking at the list of business questions,
    we notice that we will need to aggregate our transactions using fields (such as
    *Category***,** *Country*),which **are** in different master data tables, so we
    will need to load all of them and combine them. Let''s open KNIME, create a new
    workflow (**File** | **New...** and **New KNIME Workflow**), and begin to build
    it.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经具备了足够的知识来开始：如果我们意识到需要更多关于数据和业务需求的信息，我们可以随时回去向我们的财务分析师寻求额外帮助。通过查看业务问题清单，我们注意到我们需要使用不同主数据表中的字段（例如*类别*、**国家**）对事务进行汇总，因此我们需要加载所有这些表并将它们合并。让我们打开
    KNIME，创建一个新工作流（**文件** | **新建...** 和 **新建 KNIME 工作流**），并开始构建它。
- en: As a first step, we load the transactional data, which is contained in two separate
    Excel files. Let's start from the history, dragging`TransactionsHistory.xlsx`on
    the blank workflow or implementing the **Excel Reader** node. In the configuration
    window, we notice that the preview includes all the columns we anticipated being
    there, so we can close it, leaving the options unchanged. We repeat the same for
    the other file (`TransactionsL3M.xlsx`) and run both nodes.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一阶段，我们加载包含在两个独立 Excel 文件中的交易数据。我们从历史数据开始，拖动`TransactionsHistory.xlsx`到空白工作流，或实现**Excel
    Reader**节点。在配置窗口中，我们注意到预览中包括了我们预计会出现的所有列，因此我们可以关闭它，保持选项不变。我们对另一个文件（`TransactionsL3M.xlsx`）重复相同的操作，然后运行这两个节点。
- en: The two tables we have loaded so far refer to transactions and share exactly
    the same columns. We can combine them and stack one on top of the other by using
    the **Concatenate** node.
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们目前加载的两个表都涉及事务，并且共享完全相同的列。我们可以通过使用**Concatenate**节点将它们合并并将一个叠加在另一个上。
- en: '![](img/image029.png) *Concatenate*'
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image029.png) *Concatenate*'
- en: 'The node (**Manipulation > Row > Transform**) concatenates two tables by adding
    the rows of the second table at the bottom of the rows of the first table. The
    node will combine the columns if they have the same header. You can use its configuration
    window to decide how to handle the columns that do not appear in both input tables.
    By default, all columns will be kept (the **Use union of columns** option from
    the **Column handling** section): this means that, if a column only exists in
    one table, it will show in the output as NULL values for all the rows coming from
    the other table. If instead, you go for the alternative option (**Use intersection
    of columns**), all non-matching columns will be discarded at the output:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点（**操作 > 行 > 转换**）通过将第二个表的行添加到第一个表的底部来连接两个表。如果列具有相同的标题，节点将合并这些列。您可以使用其配置窗口来决定如何处理在两个输入表中未出现的列。默认情况下，所有列都会保留（**列处理**部分的**使用列的并集**选项）：这意味着如果某个列仅存在于一个表中，它将在输出中以
    NULL 值显示于来自另一个表的所有行。如果选择另一个选项（**使用列的交集**），所有不匹配的列将在输出中被丢弃：
- en: '![Graphical user interface, text, application, email'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_03_12.png)
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_03_12.png)
- en: 'Figure 3.12: Configuration window of the Concatenate node: choose how to manage
    duplicate and non-matching columns'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.12：**连接**节点的配置窗口：选择如何处理重复和不匹配的列
- en: We can combine the two transaction tables and connect the outputs of the two
    **Excel Readers** as inputs to a **Concatenate** node. Since the two input tables
    share precisely the same columns (having identical names), we don't need to care
    about the configuration of the node and stick with its default behavior. As we
    run the node, we obtain at the output the full **Sales Transactions** table with
    more than 600,000 rows.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以将两个事务表合并，并将两个**Excel Reader**节点的输出连接作为**Concatenate**节点的输入。由于这两个输入表的列完全相同（列名相同），我们不需要关注节点的配置，可以使用其默认行为。运行该节点后，输出结果将是包含超过
    60 万行的完整**销售事务**表。
- en: 'Let''s now load the **Customer Master Data** table, stored in the `customerMD.csv`file.
    We can either drag and drop the file on the editor or implement a **CSV Reader**
    node and configure it by specifying the file''s path. Double-check in the configuration
    window that the node has rightly captured the column delimiter (in this case,
    a semicolon): you can always click on **Autodetect format** to get KNIME to guess
    it.'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们加载存储在`customerMD.csv`文件中的**客户主数据**表。我们可以通过将文件拖放到编辑器中，或者实现一个**CSV读取器**节点并通过指定文件路径来配置它。请在配置窗口中仔细检查该节点是否正确识别了列分隔符（在本例中是分号）：你也可以随时点击**自动检测格式**，让KNIME猜测格式。
- en: We can now combine the sales table with the customer master data to enrich each
    transaction with the information on the *Country* where it was generated. Let's
    connect the outputs of the **Concatenate** and **CSV Reader** nodes as inputs
    to a **Joiner** node. By double-clicking on the latter, we can configure it. First,
    we need to set the conditions for matching rows. We click on the **Add matching
    criterion** button and select *Customer_ID* from both tables. The second configuration
    step is to specify the type of join to make. We want to maintain all transactions
    (left table) even if they don't have a corresponding match on the customer master
    data (right table), so we decide to go for a left outer join. In fact, our colleague
    (who is starting to admire our agility in KNIME) confirms that, although not all
    customers are included in the customer master data, we should consider transactions
    coming from all product sales. To obtain a left outer join, we need to tick both
    the **Matching rows** and the **Left unmatched rows**. The Left outer join title
    on top of the white and yellow Venn diagram confirms that we did well. The last
    configuration step is to select **Merge joining columns** option so that we don't
    carry two copies of the *Customer_ID* columns.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以将销售表与客户主数据表合并，以便为每个交易提供生成该交易的*国家*信息。我们将**连接**节点和**CSV读取器**节点的输出连接到一个**连接器**节点。双击该节点后，我们可以进行配置。首先，我们需要设置匹配行的条件。我们点击**添加匹配标准**按钮，并从两个表中选择*Customer_ID*。第二步是指定连接的类型。我们希望保留所有交易（左表），即使它们在客户主数据（右表）中没有对应的匹配项，因此我们选择进行左外连接。事实上，我们的同事（他开始钦佩我们在KNIME中的敏捷操作）确认，尽管并非所有客户都包含在客户主数据中，但我们应该考虑所有产品销售的交易。为了获得左外连接，我们需要勾选**匹配的行**和**左侧未匹配的行**。白色和黄色的维恩图顶部的左外连接标题确认了我们的操作是正确的。最后一步是选择**合并连接列**选项，以避免携带两份*Customer_ID*列。
- en: 'When we close the configuration window and run the node, we notice that none
    of the rows got matched: in fact, the output table has got null values (the ''**?**''
    cells) in all rows. by reopening the configuration of the Joiner (*Figure 3.13*)
    we realize what happened: the *Customer_ID* columns in the two tables we are joining
    refer to the same attribute but have a different data type (string in transactions
    and integer in the customer master data). These things happen: given the different
    formats of the files carrying the tables, data types might have been interpreted
    differently.'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当我们关闭配置窗口并运行节点时，我们注意到没有任何行被匹配：实际上，输出表中的所有行都包含了空值（'**?**'单元格）。通过重新打开**连接器**的配置窗口（*图
    3.13*），我们意识到发生了什么：我们正在连接的两个表中的*Customer_ID*列指向相同的属性，但数据类型不同（交易表中是字符串，客户主数据表中是整数）。这种情况是常见的：由于承载表格的文件格式不同，数据类型可能被不同地解释。
- en: '![Graphical user interface'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面'
- en: Description automatically generated](img/B17125_03_13.png)
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_03_13.png)
- en: 'Figure 3.13: Non-matching joining columns: same content but different data
    types'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.13：不匹配的连接列：相同的内容但不同的数据类型
- en: '![](img/image035.png) *Number To String*'
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image035.png) *数字转文本*'
- en: 'This node (**Manipulation > Column > Convert & Replace**) converts numeric
    columns (like integers and decimal numbers) intro strings of text. Its configuration
    is trivial: you just need to select which numeric columns should be converted
    by keeping or removing them from the right selection panel:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点（**操作 > 列 > 转换 & 替换**）将数值列（如整数和小数）转换为文本字符串。它的配置非常简单：你只需要选择哪些数值列需要被转换，方法是从右侧的选择面板中保留或移除它们：
- en: '![Graphical user interface, text, application, email'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_03_14.png)
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_03_14.png)
- en: 'Figure 3.14: Number To String configuration: which numbers do you want to convert
    into text?'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.14：数字转文本配置：你希望将哪些数字转换为文本？
- en: To convert the *Customer_ID* column from the master data into a string, we add
    a **Number To String** node between **CSV Reader** and **Joiner**. The fastest
    way to do that is to drag the node from the repository and, by clicking the mouse
    button pressed, drop it on the connector which already exists between the two
    nodes (which will turn red when selected). We can now execute the **Joiner** node
    and notice that at its output (*Shift*+*F6* to open the view) we do not have any
    more NULL value. Instead, we read all transactions, enriched with an additional
    column (*Country*) at the right end, which is exactly what we were aiming at.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了将主数据中的*Customer_ID*列转换为字符串，我们在**CSV读取器**和**连接器**之间添加了一个**数字转字符串**节点。最快的方法是将节点从资源库拖到现有连接上，然后按住鼠标按钮放开（选中时连接会变红）。现在我们可以执行**连接器**节点，并注意到在其输出端（按*Shift*+*F6*打开视图）我们不再看到任何NULL值。相反，我们可以看到所有交易，右侧增加了一列*国家*，这正是我们所期望的。
- en: It's now time to load the **Product Master Data** table by loading the `productMD.csv`
    file through the usual CSV Reader node.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是时候通过常规的CSV读取器节点加载**产品主数据**表格了，我们将通过加载`productMD.csv`文件来实现。
- en: 'We can now add an additional **Joiner** downstream: the first input port should
    be connected with the first output of the previous **Joiner''s** node while the
    second port should get the product master data from the latest **CSV Reader**.
    In its configuration, we first select *StockCode* as matching columns from both
    the left and right tables: the data types nicely match so no conversion is needed.
    This time we want to run an inner join because we don''t want to carry sales from
    products that are not included in the product master data as they would not belong
    to any product category, making the reporting less readable. Thus, in the **Joiner''s**
    configuration window, we only keep the **Matching rows** box selected. Lastly,
    tick the **Merge joining columns** box so that we don''t carry two copies of the
    *StockCode* column. When we execute the node, we obtain a table indicating for
    each row the description of the product being sold and its classification within
    the hierarchy.'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以在下游添加一个额外的**连接器**：第一个输入端口应该与前一个**连接器**节点的第一个输出端口连接，而第二个端口则应接收来自最新**CSV读取器**的产品主数据。在其配置中，我们首先选择*StockCode*作为左表和右表的匹配列：数据类型完全匹配，因此无需转换。这次我们希望执行内连接，因为我们不希望携带不包含在产品主数据中的产品的销售记录，因为这些产品不属于任何产品类别，会使报表变得不易读。因此，在**连接器**的配置窗口中，我们只选中**匹配的行**框。最后，勾选**合并连接列**框，以避免重复显示*StockCode*列。当我们执行该节点时，得到一个表格，表明每一行所售产品的描述及其在层级中的分类。
- en: 'All the data has now been loaded and combined in a single table: we can proceed
    in preparing this table, generating the reports we need. We notice that all the
    business questions require aggregating sales in terms of generated income, while
    our table displays *Quantity* and *Price* for each line item in an invoice. To
    calculate the resulting income generated by each transaction, we need to implement
    a simple mathematical formula, which is what the next node is all about.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 所有数据现在已经加载并合并成一个表格：我们可以继续准备这个表格，生成所需的报表。我们注意到所有业务问题都需要按生成的收入对销售进行汇总，而我们的表格中为每个发票项显示的是*数量*和*价格*。为了计算每笔交易所产生的收入，我们需要实现一个简单的数学公式，这正是下一个节点的用途。
- en: '![](img/image039.png) *Math Formula*'
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image039.png) *数学公式*'
- en: 'This node (**Manipulation > Column > Convert & Replace**) evaluates an expression
    for each row of a table, returning its result in a given column. The configuration
    dialog looks very familiar: indeed, it is structured in the same way as for the
    **String Manipulation** node we met in *Chapter 2*, *Getting Started with KNIME*.
    The only difference is that here, you can use functions working on numbers, like
    `ceil()` or `floor()` to round up or down a decimal number to the nearest integer
    or `sqrt()` to calculate the square root. You find all the available functions
    in the list in the middle and, by selecting them, you will read their description
    and an example appearing in the text box on the right.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点（**操作 > 列 > 转换和替换**）会对每一行表格评估一个表达式，并将其结果返回到指定的列中。配置对话框看起来非常熟悉：实际上，它与我们在*第二章*《KNIME入门》中遇到的**字符串操作**节点的结构相同。唯一的区别是，在这里，你可以使用处理数字的函数，如`ceil()`或`floor()`，将小数数值四舍五入到最接近的整数，或者使用`sqrt()`来计算平方根。所有可用的函数都列在中间，通过选择它们，你可以在右侧的文本框中查看其描述和示例。
- en: 'The easiest way to build an expression is to double-click on the available
    columns on the right (only the numeric ones will show up) and create your expression
    using the central text box. In here, you can add all math operators you need,
    like `+`, `-`, `*`, `/`, and parentheses. The result of the expression for each
    row will be saved either in a new column (**Append Column**) or will substitute
    the content of an existing one (**Replace Column**), as you can select with the
    radio button at the bottom:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 构建表达式的最简单方法是双击右侧可用的列（只有数字列会显示），并使用中央文本框创建您的表达式。在这里，您可以添加所有需要的数学运算符，如`+`、`-`、`*`、`/`和括号。每行表达式的结果将保存在一个新列中（**Append
    Column**），或者将替换现有列的内容（**Replace Column**），您可以在底部的单选按钮中进行选择：
- en: '![](img/B17125_03_15.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_03_15.png)'
- en: 'Figure 3.15: Math Formula dialog: build your numeric expression by combining
    the columns you need'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15：Math Formula对话框：通过组合您需要的列构建数值表达式
- en: 'To calculate the revenues generated by each transaction, we implement a Math
    Formula and create a connection between this and the previous node (the **Joiner''s**
    upper output port). In the configuration window, we build the expression: `$Quantity$*$Price$`,
    select the option Append Column and give it the name `Sales`.'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要计算每笔交易产生的收入，我们实现一个数学公式，并将其与前一个节点（**Joiner's**的上部输出端口）连接起来。在配置窗口中，我们构建表达式：`$Quantity$*$Price$`，选择**Append
    Column**选项并将其命名为`Sales`。
- en: By looking at the resulting table, we observe a couple of opportunities for
    cleaning it up. First, we notice that the column *Country* has some missing values
    because some customers were missing in the master data. We should substitute it
    with the default value we use when a country is missing, which is the `Unspecified`
    string. Second, we find the category "Others" doesn't refer to actual product
    sales as it describes additional fees (like postage and bank commissions) and
    manual adjustments. The finance analyst confirms that all sales generated within
    "Others" should be excluded from any reporting.
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过查看生成的表格，我们观察到几个清理的机会。首先，我们注意到*Country*列有一些缺失值，因为一些客户在主数据中缺失。我们应该用默认值替换它，当国家缺失时我们使用的默认值是`Unspecified`字符串。其次，我们发现类别"Others"并不指代实际的产品销售，因为它描述了额外的费用（如邮费和银行佣金）以及手动调整。财务分析师确认，所有在"Others"类别下生成的销售应从任何报告中排除。
- en: To manage the missing countries, add the **Missing** **Value** node and configure
    it by using its second tab (**Column Settings**). Double-click on the column *Country*,
    which you find on the left, and select **Fix Value** in the dropdown that appears.
    Then, type `Unspecified` in the text box and click on **OK** to close the window.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要管理缺失的国家，请添加**Missing Value**节点，并使用其第二个选项卡（**Column Settings**）进行配置。双击左侧找到的*Country*列，在出现的下拉菜单中选择**Fix
    Value**。然后，在文本框中输入`Unspecified`，然后单击**OK**关闭窗口。
- en: To remove the rows referring to the "Others" category, we can use a **Row Filter**
    node. To configure it, select **Exclude rows by attribute value** on the right,
    then *Category* in the **Column to test** selector and, lastly, "Others" from
    the **use pattern matching** drop-down menu:![Graphical user interface, application
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要删除与"Others"类别相关的行，我们可以使用**Row Filter**节点。要配置它，请在右侧选择**Exclude rows by attribute
    value**，然后在**Column to test**选择器中选择*Category*，最后在**use pattern matching**下拉菜单中选择"Others":![图形用户界面，应用程序
- en: Description automatically generated](img/B17125_03_16.png)
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_03_16.png)
- en: 'Figure 3.16: Row Filter dialog: exclude the rows having a specific value in
    a given column'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.16：Row Filter对话框：排除具有给定列中特定值的行
- en: Having the table cleaned up (you should by now have 672,104 rows and 11 columns
    at the output port of the last node), we are finally able to generate the tables
    that answer each of our business questions. The first one asks for a list of the
    products that have generated the most significant amount of sales. At this point,
    the sales related to a product are scattered across multiple rows, one for each
    invoice that included the product. Hence, we will need to aggregate sales by product.
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当表格清理完毕（您现在应该在最后一个节点的输出端口处有672,104行和11列），我们最终能够生成回答我们每个业务问题的表格。第一个问题要求列出产生最大销售额的产品。此时，与产品相关的销售分散在多个行中，每个包含该产品的发票都有一行。因此，我们需要按产品聚合销售额。
- en: To obtain the total sales generated by each product, we implement a **GroupBy**
    node. In the configuration window, we select the columns that define the unique
    groups at the output. Since we want to have one row for each product and we also
    want to carry in the report the columns that describe it, in the **Groups** tab,
    we select the columns *StockCode*, *Description*, *Category*, and *Subcategory*,
    making sure they all end up in the green-bordered list on the right. The **GroupBy**
    node will create a row for each combination of values in the group columns but,
    since we know that for each *StockCode*, we have one single *Description*, *Category*,
    and *Subcategory*, we can safely keep all of them in the group description, to
    keep them in our output table, which will result in them being more informative.
    In the **Manual Aggregation** tab, we double-click on the columns *Sales* and
    *Quantity* and specify for both of them the option **Sum** as **Aggregation function**.
    To make our report more readable and avoid bulky column names, we select **Keep
    original name(s)** in the bottom dropdown labeled as **Column naming**. We can
    then click on **OK** and move to the next step.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了获取每个产品产生的总销售额，我们实现了一个**GroupBy**节点。在配置窗口中，我们选择定义输出中唯一分组的列。由于我们希望每个产品都有一行，并且希望报告中包含描述它的列，在**Groups**标签页中，我们选择了*StockCode*、*Description*、*Category*和*Subcategory*列，并确保它们最终都出现在右侧绿色边框的列表中。**GroupBy**节点将为每组列中每个值的组合创建一行，但由于我们知道对于每个*StockCode*，都有一个唯一的*Description*、*Category*和*Subcategory*，我们可以安全地将它们都保留在分组描述中，以便将它们保留在输出表格中，这将使得结果更加信息丰富。在**Manual
    Aggregation**标签页中，我们双击*Sales*和*Quantity*列，并为这两列都指定**Sum**作为**Aggregation function**。为了使报告更易读并避免列名过长，我们在底部的**Column
    naming**下拉框中选择**Keep original name(s)**。然后，我们可以点击**OK**并进入下一步。
- en: Since we want to show only the products generating the most sales, we need to
    sort the table by decreasing *Sales*, using the **Sorter** node. After implementing
    the node and making a connection with the previous one, we can select *Sales*
    in the drop-down menu and pick the **Descending** order.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们只想显示产生最大销售额的产品，因此我们需要使用**Sorter**节点按降序排列表格中的*Sales*。在实现该节点并与前一个节点建立连接后，我们可以在下拉菜单中选择*Sales*并选择**Descending**排序。
- en: The last step for answering this business question is to limit our ranked list
    of products to the top ten entries. Using the **Row** **Filter** node, we **select
    Include rows by number** on the left and then input `1` as **First** **row** **number**
    and `10` as **Last row number**.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解答这个业务问题的最后一步是将我们排名前十的产品列表限制为前十项。使用**Row** **Filter**节点，我们在左侧**选择按编号包含行**，然后输入`1`作为**First**
    **row** **number**，并输入`10`作为**Last row number**。
- en: 'After executing the last node and checking the resulting table, we are positively
    impressed as the screen displays the ten biggest selling products. This positive
    intermediate result encourages us to move ahead in our challenge:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 执行最后一个节点并检查结果表格后，我们感到非常满意，因为屏幕上显示了销售额最高的十个产品。这个积极的中间结果鼓励我们继续推进挑战：
- en: '![Graphical user interface, table'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，表格'
- en: Description automatically generated](img/B17125_03_17.png)
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_03_17.png)
- en: 'Figure 3.17: Top ten products by sales: who would have thought that a cake
    stand could make so much money?'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3.17: 按销售额排名前十的产品：谁会想到一个蛋糕架能赚这么多钱？'
- en: The next question asks us to report the top-selling products within each subcategory.
    Similar to what we already did for the previous question, we apply a filter to
    the products list, keeping only the ones appearing on top of the sorted list.
    However, this time, we need to repeat the filtering multiple times, once for each
    subcategory.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个问题要求我们报告每个子类别中最畅销的产品。类似于我们之前为前一个问题所做的，我们对产品列表应用过滤，只保留在排序列表顶部的产品。然而，这次我们需要重复过滤操作多次，每个子类别一次。
- en: 'In KNIME, you can *repeat* the execution of a portion of a workflow by creating
    a **Loop**. Implementing a loop in KNIME is quite simple: you have a set of start
    and end loop nodes (you find them in **Workflow Control > Loop Support**), which
    you can use to define the segment of the workflow to be repeated (the **Loop Body**).
    Depending on the type of **Loop** **Start** node you pick, you can decide the
    logic to follow for the repetition. Once the loop is executed, you will find the
    concatenated results of your loops at the output port of the **Loop** **End**
    node, with an extra column telling you the loop number each row refers to. It
    looks simple, and it actually is!'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在KNIME中，你可以通过创建**循环**来*重复*执行工作流中的某一部分。实现循环在KNIME中非常简单：你有一组起始和结束循环节点（可以在**工作流控制
    > 循环支持**中找到它们），你可以用这些节点来定义需要重复的工作流部分（**循环主体**）。根据你选择的**循环起始**节点的类型，你可以决定重复执行的逻辑。一旦循环执行完毕，你将在**循环结束**节点的输出端口找到拼接后的结果，并且会有一个额外的列标明每一行对应的循环编号。看起来很简单，实际上也是如此！
- en: 'You will find a graphical summary of the most popular loop nodes below. More
    specifically:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 下面你将看到最常用的循环节点的图形总结。更具体地说：
- en: '**Counting Loop Start**: Use this if you want to repeat a portion of a workflow
    a given number of times (which you can specify in the configuration dialog).'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计数循环起始**：如果你希望重复执行工作流的某一部分一定次数（你可以在配置对话框中指定次数），可以使用此节点。'
- en: '**Chunk Loop Start**: The loop will be repeated once for every fixed-size chunk
    of consecutive rows in the input table. You can decide the number of total loops
    or chunk size per loop to use. If you select a chunk size of 1, you will repeat
    a portion of the workflow for each individual row of the input table.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**块循环起始**：该循环会针对输入表中每一个固定大小的连续行块重复执行。你可以决定总循环次数或每次循环的块大小。如果选择块大小为1，那么你将对输入表中的每一行分别重复执行工作流的某一部分。'
- en: '**Group Loop Start**: The loop will be repeated for every group of rows, defined
    by each combination of unique values in the columns you decide. Remember the **GroupBy**
    node? In that case, you obtained an aggregated row for each group: in this case,
    you will repeat a portion of the workflow for each group. We''ll use this node
    shortly, which will make its behavior clearer.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组循环起始**：该循环将针对每一组行重复执行，组是通过你选择的列中每个唯一值的组合来定义的。还记得**分组**节点吗？在那时，你为每个组获得了一个聚合后的行；在这里，你将针对每个组重复执行工作流的某一部分。我们很快会使用这个节点，这将使它的行为更加清晰。'
- en: There are other nodes for starting and ending loops, which would extend the
    flexibility you have for repeating some sets of operations in your workflows.
    Have a look at the **Recursive Loop** nodes:with these you can*bring back* **t**he
    output of a loop to the start node, to repeat it over and over on the same rows.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他一些节点用于启动和结束循环，这些节点能扩展你在工作流中重复执行某些操作集的灵活性。请查看**递归循环**节点：使用这些节点，你可以*将* **t**循环的输出带回到起始节点，从而在同一行上重复执行。
- en: '*Figure 3.18* shows a summary of possible loop setups for your workflow. Remember:
    you can only have a single **Loop** **Start** and a **Loop** **End** node working
    together on the same loop body. The dashed lines in the figure show you three
    plausible options for **Loop** **Start** nodes:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.18* 显示了你的工作流中可能的循环设置摘要。记住：在同一个循环主体上，你只能有一个**循环起始**和一个**循环结束**节点协同工作。图中的虚线展示了三种可行的**循环起始**节点选项：'
- en: '![](img/B17125_03_18.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_03_18.png)'
- en: 'Figure 3.18: Loop nodes in KNIME: repeat a portion of the workflow as many
    times as you need'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18：KNIME中的循环节点：根据需要重复工作流的某一部分
- en: After this short digression on creating loops in KNIME, let's go back to our
    business case. We want to repeat the filtering of the top products for each subcategory,
    so we should implement a group loop, where the group is simply defined by the
    column *Subcategory*. Here's how the **Group Loop Start** node works.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在简短介绍了如何在KNIME中创建循环后，我们回到我们的业务案例。我们希望对每个子类别重复筛选出最畅销的产品，因此我们应该实现一个组循环，其中“组”由列*子类别*简单定义。下面是**组循环起始**节点的工作方式。
- en: '![](img/image049.png) *Group Loop Start*'
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image049.png) *组循环起始*'
- en: 'This node (available in **Workflow Control > Loop Support**) marks the starting
    point of the portion of workflow which will be repeated for each group. All the
    input rows showing the same values in the columns defining the group will be returned
    to the downstream loop for execution, one group at a time. Its configuration requires
    you to specify the columns that define each group. Using this node will require
    the implementation of a **Loop End** node, which will mark the end of the segment
    of nodes for which to repeat the execution:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点（在**工作流控制 > 循环支持**中提供）标志着每个组将要重复执行的工作流部分的起点。所有在定义组的列中具有相同值的输入行将一次性返回到下游循环进行执行。其配置要求你指定定义每个组的列。使用此节点时，需要实现**循环结束**节点，这将标志着需要重复执行的节点段的结束：
- en: '![Graphical user interface, application'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序'
- en: Description automatically generated](img/B17125_03_19.png)
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_03_19.png)
- en: 'Figure 3.19: Configuration window of the Group Loop Start node: decide which
    columns define the group through which you want to iterate'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.19：分组循环开始节点的配置窗口：决定定义你希望迭代的组的列
- en: Let's create our first loop in KNIME to answer our current business question.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 KNIME 中创建第一个循环，以回答当前的业务问题。
- en: We can reuse the sorted list of products we created for the previous question
    as a base for our grouped filtering. Drag and drop the **Group Loop Start** node
    and connect it downstream to the **Sorter** node. In its configuration window,
    select only *Subcategory* to appear in the **Include** panel on the right.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以重用之前为上一个问题创建的排序产品列表，作为我们分组过滤的基础。拖动并连接**分组循环开始**节点，并将其下游连接到**排序器**节点。在其配置窗口中，只选择*子类别*，使其出现在右侧的**包含**面板中。
- en: The loop will only have to select the top three products appearing in each group.
    To do so, we can replicate what we did for the overall top list of products. Let's
    implement a **Row Filter** node, select **Include rows by number**, and then input
    `1` as **First row number** and, in this case, `3` as **Last row number**.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 循环将只需选择每组中的前三个产品。为此，我们可以复制之前为整体顶级产品列表所做的操作。让我们实现一个**行过滤器**节点，选择**按数量包含行**，然后输入`1`作为**首行号**，并在此情况下输入`3`作为**尾行号**。
- en: To close a loop in a workflow, we need to indicate its end point by using the
    appropriate node.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要在工作流中结束一个循环，我们需要使用适当的节点来指示其结束点。
- en: '![](img/image053.png) *Loop End*'
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image053.png) *循环结束*'
- en: 'This node (**Workflow Control > Loop Support**) marks the end of a workflow
    loop. At each execution of a loop, it collects the intermediate results by storing
    the rows arriving at the input port. At the end of the last loop execution, it
    will return the intermediate results'' full concatenation. In its configuration
    window, you can decide whether or not to add an extra column that counts the loop
    number in which each intermediate row was generated (**Add iteration column**).
    In this node''s pop-up menu (right-click on the node once implemented), you will
    find additional options for executing it. If you click on **Step Loop Execution**,
    you will ask KNIME to run only one single iteration of the loop so you can check
    intermediate results:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点（**工作流控制 > 循环支持**）标志着工作流循环的结束。在每次执行循环时，它通过存储到达输入端口的行来收集中间结果。在最后一次循环执行结束时，它将返回中间结果的完整连接。在其配置窗口中，你可以决定是否添加一个额外的列来统计每个中间行生成时所处的循环次数（**添加迭代列**）。在此节点的弹出菜单中（实现节点后右键点击），你将找到执行它的其他选项。如果点击**单步执行循环**，你将要求
    KNIME 仅运行循环的一次迭代，以便检查中间结果：
- en: 'The coders among you will recognize that this step execution acts as a *breakpoint*
    that can be used to investigate and debug the way your loop is working. You can
    also set individual breakpoints at any point within your loop: check out the **Breakpoint**
    node for doing this.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 你们中的程序员会意识到，这一步执行充当了一个*断点*，可以用来调查和调试循环的工作方式。你还可以在循环的任何点设置单独的断点：可以查看**断点**节点来实现这一点。
- en: '![Graphical user interface, text, application'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序'
- en: Description automatically generated](img/B17125_03_20.png)
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_03_20.png)
- en: 'Figure 3.20: Loop End node dialog: do you want to add an iteration column?'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.20：循环结束节点对话框：你是否要添加一个迭代列？
- en: Sometimes, you need to collect multiple tables (with different columns) for
    each iteration of your loop. In this case, you can use the 2-port version of the
    **Loop End** node, which you will find in the same repository folder.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，您需要为每次循环收集多个表格（具有不同的列）。在这种情况下，您可以使用**循环结束**节点的两端版本，您可以在同一存储库文件夹中找到。
- en: 'Let''s implement a **Loop** **End** node, after the **Row** **Filter**, and
    untick the **Add iteration column** option: we don''t need it, as we keep the
    name of the *Subcategory* to indicate what we are referring to. The node''s output
    shows three rows for each subcategory, which is exactly what we needed to answer
    the business question:![Table'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现一个**循环结束**节点，在**行过滤器**后取消选中**添加迭代列**选项：我们不需要它，因为我们保持*子类别*的名称以指示我们所指的内容。节点的输出显示每个子类别三行，这正是我们需要回答业务问题的内容：![表
- en: Description automatically generated](img/B17125_03_21.png)
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动生成描述](img/B17125_03_21.png)
- en: 'Figure 3.21: Top products for each subcategory: each iteration of the loop
    returned three rows, which have been stitched together by the Loop End node to
    appear in the same table'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.21：每个子类别的顶级产品：每次循环返回三行，这些行已被循环结束节点拼接在同一张表中显示
- en: The next question asks us to report sales by country, identifying the ones we
    ship the most to. It will be enough to aggregate, once again, the sales table,
    this time grouping by country instead of grouping by product as we've done so
    far. We can reuse the **Row Filter's** output (which excluded the "Others" category)
    as a starting point for this new branch of the workflow.
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下一个问题要求我们按国家报告销售情况，识别我们发货最多的国家。我们只需再次聚合销售表，这次按国家分组，而不是按产品分组，我们可以重复使用**行过滤器**的输出（排除了“其他”类别）作为工作流程的新分支的起点。
- en: 'We need to implement a new **GroupBy** node, having a similar configuration
    to the first **GroupBy** we used earlier to aggregate by product but with a different
    definition of groups. Time is money, so let''s copy and paste the previous **GroupBy**
    and connect it with the first **Row Filter**, as anticipated above. In its configuration,
    let''s just work on the **Groups** panel: this time, we want *Country* to be the
    only column defining groups. We can leave the **Manual** **aggregation** tab unaltered,
    as we still want to sum revenues and quantities.'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要实施一个新的**分组**节点，其配置与我们早期用于按产品聚合的第一个**分组**节点类似，但组的定义不同。时间就是金钱，所以让我们复制并粘贴之前的**分组**节点，并将其连接到第一个**行过滤器**，如上所述。在其配置中，让我们只处理**组**面板：这次，我们希望*国家*是唯一定义组的列。我们可以保持**手动**
    **聚合**选项卡不变，因为我们仍然希望对收入和数量进行求和。
- en: To make our output clearer, let's use the **Sorter** node to order rows by decreasing
    *Sales*, similar to what we did in the earlier branch.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使我们的输出更清晰，让我们使用**排序器**节点按照*销售额*降序排列行，类似于我们在早期分支中所做的操作。
- en: 'As shown in *Figure 3.22*, we ascertain that most sales are made by UK-based
    customers, which makes sense, considering that we are talking about a British
    company:'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如*图 3.22*所示，我们可以确定大多数销售额来自于英国客户，考虑到我们在讨论一个英国公司，这是合理的。
- en: '![Table'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![表'
- en: Description automatically generated](img/B17125_03_22.png)
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动生成描述](img/B17125_03_22.png)
- en: 'Figure 3.22: Top products for each subcategory: each iteration of the loop
    returned three rows, which have been stitched together by the Loop End node to
    appear in the same table'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.22：每个子类别的顶级产品：每次循环返回三行，这些行已被循环结束节点拼接在同一张表中显示
- en: As we move to the next business questions, we notice that they all make reference
    to a dimension that, so far, we've ignored—time. To proceed in the creation of
    our reports, we will need to filter by date (two questions ask us to focus on
    the calendar year to date time frame) and reaggregate by month (to spot seasonal
    patterns). Managing time-related data in KNIME is relatively easy thanks to a
    set of nodes that are specifically designed for doing that. We have nodes that
    convert text to Date&Time data types (**String to Date&Time**), nodes that extract
    specific elements from a Date&Time data point like hour, month, or day of the
    week (**Extract Date&Time Fields**), and nodes that will filter rows according
    to some *temporal* logic (**Date&Time-based Row Filter**). In the next few pages,
    we will learn how to use such handy nodes one by one.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进入下一个业务问题时，我们注意到它们都涉及到一个我们至今忽略的维度——时间。为了继续生成我们的报告，我们需要按日期筛选（有两个问题要求我们聚焦于当前日历年的时间范围）并按月份重新聚合（以便发现季节性模式）。在
    KNIME 中管理与时间相关的数据相对简单，因为有一组专门为此设计的节点。我们有可以将文本转换为 Date&Time 数据类型的节点（**String to
    Date&Time**），可以从 Date&Time 数据点中提取特定元素（如小时、月份或星期几）的节点（**Extract Date&Time Fields**），以及根据某些*时间*逻辑筛选行的节点（**Date&Time-based
    Row Filter**）。在接下来的几页中，我们将逐一学习如何使用这些便捷的节点。
- en: '![](img/image061.png) *String to Date&Time*'
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image061.png) *String to Date&Time*'
- en: This node (**Other Data Types > Time Series > Transform**) converts text columns
    into Date&Time values so that they can be used in time-related nodes. The node
    attempts to automatically recognize the format of Date&Time fields within strings,
    leaving the user the possibility to input the text field's expected format manually.
    In its configuration window, you can first specify which string columns should
    be converted (ensure you keep on the right only the ones that include Date&Time).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点（**其他数据类型 > 时间序列 > 转换**）将文本列转换为 Date&Time 值，以便可以在与时间相关的节点中使用。该节点会尝试自动识别字符串中
    Date&Time 字段的格式，用户也可以手动输入文本字段的预期格式。在其配置窗口中，您可以首先指定哪些字符串列应该被转换（确保右侧仅包含包含 Date&Time
    的列）。
- en: 'In the **Replace/Append Selection** panel, you can decide whether to replace
    columns with their converted version or to add them, adding a fixed suffix to
    their headers. In the last panel, you can enter a string that explains the expected
    **Date format**: for instance, strings like `16/02/2023` will be correctly parsed
    using the format string `dd/MM/yyyy`. By clicking on the button **Guess data type
    and format**, KNIME will try to recognize the format by analyzing the first cell''s
    content, which you can read in the label below. If the automatic guess doesn''t
    work, you can enter your own string using characters like `d`, `M`, `y`, `h`,
    `m`, and `s`, which stand for day, month, year, hour, minutes, and seconds (check
    out the node description for the full list of format placeholders). You can also
    select a regional setting (called **Locale**, like **en-US** or **it-CH**) to
    determine the language expected for fields such as month or weekday names:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在**替换/追加选择**面板中，您可以决定是替换列为其转换后的版本，还是添加列，并在其标题中添加固定后缀。在最后一个面板中，您可以输入一个字符串来说明期望的**日期格式**：例如，字符串如
    `16/02/2023` 会使用格式字符串 `dd/MM/yyyy` 正确解析。点击**猜测数据类型和格式**按钮，KNIME 会尝试通过分析第一个单元格的内容来识别格式，您可以在下面的标签中查看该内容。如果自动猜测无法工作，您可以使用像
    `d`、`M`、`y`、`h`、`m` 和 `s` 这样的字符手动输入自己的字符串，这些字符分别代表天、月、年、小时、分钟和秒（查看节点描述以获取完整的格式占位符列表）。您还可以选择一个区域设置（称为**区域**，如**en-US**
    或 **it-CH**），以确定预计的语言，用于像月份或星期几名称这样的字段：
- en: '![Graphical user interface, application, email'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_03_23.png)
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_03_23.png)
- en: 'Figure 3.23: String to Date&Time configuration windows: convert a string of
    text into a Date&Time value'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.23：String to Date&Time 配置窗口：将文本字符串转换为 Date&Time 值
- en: Let's implement a **String** **to** **Date&Time** node and plug inside it the
    output of the first **Row** **Filter** (we can still reuse that one as it carries
    a cleaned version of the table). Let's keep only the column *Invoice_time* on
    the right selection panel and click on **Guess data type and format** to let KNIME
    find a way to interpret the string. We obtain the format string `'D'dd/M/yy'T'HH:mm:ss`,
    which perfectly matches the content of the first value in our table (`D01/12/17T07:45:00`).
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现一个**字符串** **到** **日期和时间**的节点，并将第一个**行过滤器**的输出连接进去（我们仍然可以重用它，因为它携带了已清理版本的表格）。在右侧选择面板中仅保留*Invoice_time*列，并点击**猜测数据类型和格式**，让KNIME找出一种方法来解释该字符串。我们得到的格式字符串是`'D'dd/M/yy'T'HH:mm:ss`，它完美匹配我们表格中第一个值的内容（`D01/12/17T07:45:00`）。
- en: 'After we run the node, we notice in the output table that the icon on top of
    the *Invoice_time* column is not an "S" any longer but a calendar picture: KNIME
    is now going to treat that column as a Date&Time field and we can use all the
    other time-related nodes for its manipulation. Since the business question focuses
    on the calendar year to date, we need to find a way to filter rows by dates, exactly
    what our next node is specialized in.'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行该节点后，我们注意到输出表中，*Invoice_time*列顶部的图标不再是“S”字母，而是一个日历图标：KNIME现在将把该列视为日期和时间字段，我们可以使用所有其他与时间相关的节点对其进行处理。由于业务问题聚焦于当前的日历年份，我们需要找到一种方法根据日期过滤行，这正是我们下一个节点的专长。
- en: '![](img/image065.png) *Date&Time-based Row Filter*'
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image065.png) *基于日期和时间的行过滤器*'
- en: 'This node (**Other Data Types > Time Series > Transform**) applies row-level
    filtering based on a specified time range. To configure it, you first need to
    select the column that shall be used for the filtering (it must be of Date&Time
    type). Then you can declare the interval of the rows to keep: you do so by specifying
    a lower bound (including all values happening later than the point in time you
    declare in the **Start** panel), an upper bound (keeping everything that occurs
    before what is declared in the **End** panel), or both (making it a closed interval).
    The upper bound can be defined either by inputting a specific point in time (option
    **Date&Time**), a composite interval from the start time (option **Duration**,
    which can be like `2y 1M`, meaning two years and one month from the start), or
    a specific number of time periods from the start (option **Numerical**, like plus
    or minus 10 hours from the start). By ticking the **Inclusive** checkbox, every
    value that is equal to the start (or the end) date will be kept in the output:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点（**其他数据类型 > 时间序列 > 转换**）根据指定的时间范围应用行级过滤。要配置它，首先需要选择用于过滤的列（该列必须为日期和时间类型）。然后，你可以声明要保留的行的区间：你可以指定一个下限（包括所有晚于你在**开始**面板中声明的时间点的值），上限（保留所有在**结束**面板中声明的时间点之前发生的内容），或两者（使其成为一个闭区间）。上限可以通过输入一个特定的时间点（选项**日期和时间**），从开始时间起的复合区间（选项**持续时间**，例如`2y
    1M`，表示从开始起的两年零一个月），或者从开始起的特定时间段数（选项**数字**，例如从开始起加或减10小时）来定义。通过选中**包含**复选框，所有等于开始（或结束）日期的值都会保留在输出中：
- en: '![Graphical user interface, text, application'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '![Graphical user interface, text, application'
- en: Description automatically generated](img/B17125_03_24.png)
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: Description automatically generated](img/B17125_03_24.png)
- en: 'Figure 3.24: Configuration of Date&Time-based Row Filter node: keep only the
    rows referring to a specific time range'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.24：基于日期和时间的行过滤器节点配置：仅保留与特定时间范围相关的行
- en: Since the business question refers to the latest calendar year only (which in
    our dataset is 2019), we need to implement a **Date&Time-based Row Filter** node
    to remove all earlier rows. For its configuration, we can untick the **End** box
    (we know that the date doesn't go beyond 2019) and input `2019-01-01` as **Date**
    and `00:00:00` as **Time** in the **Start** box.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于业务问题仅涉及最新的日历年（在我们的数据集中是2019年），我们需要实现一个**基于日期和时间的行过滤器**节点来移除所有早期的行。在其配置中，我们可以取消选中**结束**框（我们知道日期不会超过2019年），并在**开始**框中输入`2019-01-01`作为**日期**，`00:00:00`作为**时间**。
- en: Since the question asks how much revenue was generated within each product category,
    we just need to group the resulting rows (now referring to 2019 only) by *Category*.
    Implement a **GroupBy** node, keep only *Category* in the definition of **Groups**,
    and the usual sum of *Sales* and *Quantity* in the **Manual Aggregation** panel.
    Also, this time, we want to keep the naming simple and select **Keep original
    name(s)** in the dropdown at the bottom:![](img/B17125_03_25.png)
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于问题要求我们计算每个产品类别产生的收入，因此我们只需要按*类别*对结果行（现在仅指2019年的数据）进行分组。实现一个**分组**节点，在**分组**定义中仅保留*类别*，并在**手动聚合**面板中保留*销售额*和*数量*的常规求和。同时，这一次，我们希望保持命名简洁，选择**保留原始名称**在底部下拉框中：![](img/B17125_03_25.png)
- en: 'Figure 3.25: Sales by Category in 2019'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.25：2019年按类别销售情况
- en: 'Another question is answered! We managed to limit our sales to the time frame
    of interest and summarize sales at the granularity we need. For the next question,
    we have to deal with a slight complication: we are asked to compute each category''s
    relative footprint out of the total revenues. This means that we should divide
    the sales generated in the various categories by the grand total of sales. We
    can use the **Math** **Formula** node to implement this division: the numerator
    of the division is readily available (it''s the **Sales** column obtained after
    the **GroupBy** summarization we already did to answer the previous question).
    However, the denominator should be calculated separately and somehow included
    in the formula. This is where **variables** come in handy. Although not every
    user will need to use variables in KNIME, let''s go through the fundamentals.
    You can consider the next couple of pages as optional in your path to becoming
    an autonomous KNIME user.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 又一个问题得到了解答！我们成功地将销售限制在了感兴趣的时间范围内，并按我们需要的粒度汇总了销售数据。接下来的问题稍微复杂一些：我们需要计算每个类别的相对足迹，占总收入的比例。这意味着我们应该将各个类别产生的销售额除以总销售额。我们可以使用**数学公式**节点来实现这个除法运算：除法的分子很容易获取（它是**销售额**列，这是我们之前通过**分组汇总**节点得到的结果）。然而，分母需要单独计算并以某种方式包含在公式中。这就是**变量**派上用场的地方。虽然并不是每个用户都需要在KNIME中使用变量，但让我们了解一下基础知识。你可以将接下来几页内容视为成为独立KNIME用户的可选学习内容。
- en: Variables in KNIME can be used to control the configuration of any node dynamically.
    So far, we've always customized a node's behavior by manually operating on its
    configuration window. In most cases, this will be enough. However, sometimes we
    want to configure a node's parameter through a variable that might be, in turn,
    the output of some calculation executed in another node. For instance, in the
    case of our sales footprint calculation, we want to use the aggregation of total
    sales as a variable in our formula.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME中的变量可以用来动态控制任何节点的配置。到目前为止，我们一直通过手动操作节点的配置窗口来定制节点的行为。在大多数情况下，这已经足够了。然而，有时我们希望通过一个变量来配置节点的参数，而这个变量可能是某个在另一个节点中执行的计算结果。例如，在我们的销售足迹计算中，我们希望使用总销售额的汇总作为公式中的变量。
- en: In general, any configuration parameter of a node can be controlled by a variable.
    If you open the configuration window of any node and go to the tab called **Flow
    Variables** (which we have not used so far), you find a list of the parameters
    needed by that node, and you can select which variables (if available at that
    point in the workflow) should be used to control them.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，节点的任何配置参数都可以通过变量进行控制。如果你打开任何节点的配置窗口并进入名为**流程变量**的标签页（我们到目前为止还没有使用过），你会看到该节点所需参数的列表，并且可以选择哪些变量（如果在工作流的这一点有可用的变量）应当用于控制它们。
- en: To make variables available, you need to inject them into the workflow. The
    easiest way to do so is to transform the values of a data table into variables,
    using a special node called **Table Row to Variable**.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 要使变量可用，你需要将它们注入到工作流中。最简单的方法是使用一个特殊的节点——**表格行到变量**，将数据表中的值转换为变量。
- en: '![](img/image071.png) *Table Row to Variable*'
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image071.png) *表格行到变量*'
- en: 'This node (**Workflow Control > Variables**) takes all the values in the first
    row of the input table and transforms them into individual variables, each one
    named after the corresponding input column. Its configuration window lets you
    select the columns whose first row''s value should be transformed into variables:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点（**工作流控制 > 变量**）将输入表格的第一行中的所有值转换为独立的变量，每个变量的名称与对应的输入列相同。它的配置窗口让你选择哪些列的第一行值应该被转换成变量：
- en: '![](img/B17125_03_26.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_03_26.png)'
- en: 'Figure 3.26: Configuration of Table Row to Variable node: select the values
    to be transformed into variables'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.26：表行到变量节点的配置：选择要转换为变量的值
- en: The output port of this node is a red circle, which indicates flow variables.
    You can inject the variables into any node by just connecting this output port
    with the receiving node's body.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点的输出端口是一个红色圆圈，表示流变量。你只需将这个输出端口与接收节点的主体连接，就可以将变量注入到任何节点。
- en: Every node in KNIME has flow variable ports available. They are hidden by default.
    To unhide them, just right-click on the node and then click on **Show Flow Variable
    Ports**.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME中的每个节点都有可用的流变量端口。默认情况下，它们是隐藏的。要显示它们，只需右键点击节点，然后点击**显示流变量端口**。
- en: It's important to clarify that this node will only transform the *values in
    the first row* of a table into variables. If you need to iterate through different
    values, you can use **Table Row To Variable Loop Start**. Using this node (for
    example, in conjunction with a **Loop** **End** node, which you have already seen),
    you can create a loop where, at every iteration, the variables assume the value
    included in each of the input rows.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 需要澄清的是，这个节点仅会将表格中*第一行的值*转换为变量。如果你需要遍历不同的值，可以使用**表行到变量循环开始**节点。使用这个节点（例如，与**循环结束**节点一起使用，你已经见过它），你可以创建一个循环，在每次迭代时，变量的值会赋予每一行输入中的值。
- en: Now that we know how to implement variables in KNIME, we can create a variable
    that contains the total aggregation of sales, which we will then use in the **Math**
    **Formula** node, to calculate the sales footprint. Let's use **GroupBy** to aggregate
    total sales and then a **Table** **Row** **to** **Variable** node to transform
    that number into a variable.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何在KNIME中实现变量了，我们可以创建一个包含销售总聚合的变量，然后在**数学公式**节点中使用该变量，计算销售足迹。让我们使用**分组**来聚合总销售额，然后使用**表行到变量**节点将该数字转换为变量。
- en: 'We need to aggregate all the sales that happened in 2019 into one single row,
    holding the grand total of generated revenues. Let''s implement **GroupBy** and
    connect it to the output port of the **Date&Time-based Row Filter** node. Since
    we only need a row with the grand total, we can leave the **Group** panel empty:
    this will generate a warning on our node, but we know why we are doing this, so
    we can ignore it. On the **Manual Aggregation** panel, let''s add the usual *Sales*
    column and aggregate through the **Sum** function. To avoid any confusion with
    the variable name, let''s select **Aggregation method (column name)** as the naming
    convention this time (the menu at the bottom). Once we run the node, we obtain
    a simple output, which is exactly what we were after: a table with one row and
    one column, displaying the grand total of sales in 2019.'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要将2019年发生的所有销售合并成一行，保存生成的总收入。让我们实现**分组**并将其连接到**日期和时间基础的行筛选器**节点的输出端口。由于我们只需要一行包含总额的数据，因此可以将**分组**面板留空：这会在我们的节点上生成一个警告，但我们知道这么做的原因，因此可以忽略它。在**手动聚合**面板中，我们添加常见的*销售*列，并通过**求和**函数进行聚合。为了避免与变量名称混淆，这次我们选择**聚合方法（列名）**作为命名约定（底部菜单）。一旦我们运行节点，就会得到一个简单的输出，这正是我们想要的：一个包含2019年总销售额的单行单列表格。
- en: We are now ready to transform this value into a variable by implementing the
    **Table Row to Variable** node right after the **GroupBy**. No configuration is
    needed for this node, as we can transform all columns (just one in our case) into
    variables.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备通过在**分组**后实现**表行到变量**节点，将这个值转换为变量。此节点无需配置，因为我们可以将所有列（在我们的案例中只有一列）转换为变量。
- en: It's finally time to make the footprint calculation. Let's implement a **Math
    Formula** node and make the two connections we need. First, this node should receive
    as an input table the result of the **GroupBy** that we used a few steps ago to
    calculate the total sales by category. Second, we should inject the variable with
    the grand total of sales, by creating a connection between the red port of the
    **Table Row to Variable** node and the **Math Formula** node. To do so, you can
    click on the red circle, keep the button pressed, and release it on the **Math
    Formula** node icon.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在终于到了进行足迹计算的时候。让我们实现一个**数学公式**节点，并建立我们需要的两个连接。首先，这个节点应该接收作为输入的表格，即我们在几步之前用来按类别计算总销售额的**分组**结果。其次，我们应该通过创建一个连接，将**表行到变量**节点的红色端口与**数学公式**节点连接，从而注入包含总销售额的变量。为此，你可以点击红色圆圈，按住按钮，并将其释放到**数学公式**节点图标上。
- en: Although this is not needed, if you want to view any node's variable ports,
    just open the pop-up menu (right-click on the node) and then click on **Show Flow
    Variable Ports**.
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虽然这不是必需的，但如果你想查看任何节点的变量端口，只需打开弹出菜单（右键点击节点），然后点击**显示流变量端口**。
- en: 'The node configuration dialog now allows us to use the flow variable we have
    just injected. You will notice the variable (called *Sum(Sales)*) on the right
    within the **Flow Variable List**. We can calculate the footprint by using the
    mouse and keyboard and obtaining the expression: `$Sales$/$${DSum(Sales)}$$*100`.
    We can append the resulting column, assigning it the name *Footprint* and, for
    simplicity, converting it to an integer number by ticking the last checkbox at
    the bottom:'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 节点配置对话框现在允许我们使用刚刚注入的流变量。你会注意到该变量（名为*Sum(Sales)*)）出现在右侧的**流变量列表**中。我们可以通过使用鼠标和键盘计算足迹，并获得表达式：`$Sales$/$${DSum(Sales)}$$*100`。我们可以附加结果列，并将其命名为*Footprint*，为了简便起见，通过勾选底部的最后一个复选框将其转换为整数：
- en: '![](img/B17125_03_27.png)'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B17125_03_27.png)'
- en: 'Figure 3.27: Configuration of the Math Formula node for the footprint calculation:
    we found both columns and variables on the left, ready to be used in the expression'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.27：足迹计算的数学公式节点配置：我们可以看到左侧的列和变量，准备在表达式中使用
- en: 'Also, this business question has now found a proper answer: the output of Math
    Formula includes both the footprint of each category and its total sales, answering
    two questions at once. We have one last question to manage, which will require
    producing a chart. For all the previous ones, we have produced some tables: it
    would be nice to collect all these tables in a single Excel file with multiple
    tabs so we can disseminate our report easily and in a compact form.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这个商业问题现在已经得到了适当的答案：数学公式的输出包括每个类别的足迹和其总销售额，一次性解答了两个问题。我们还剩下最后一个问题需要解决，这将需要生成一个图表。对于之前的所有问题，我们已经生成了一些表格：把所有这些表格汇总到一个包含多个标签的Excel文件中，以便我们能够轻松地传播报告并以紧凑的形式呈现，这将是非常不错的。
- en: 'Let''s implement an **Excel Writer** node. Since this time we need to save
    four different tables in a single Excel file, we need to add three input ports
    to the node. To do so, click on the three dots appearing at the bottom left of
    the node icon and then **Add ports** | **Sheet Input Ports**. Repeat this, two
    more times, to obtain four input ports in total. Connect the output ports of the
    nodes providing the *answers* to the five questions we have managed so far (the
    overall top ten products, the top three by subcategory, the sales by country,
    and the output of the last Math Formula having both footprint and sales by category
    in 2019). In the **Excel Writer**''s configuration, this time we find four textboxes
    in the **Sheets** panel: we can use them to assign a meaningful name to guide
    whoever is reading the report. After declaring the full path and the name of the
    output file (click on the **Browse...** button to select it), we are ready to
    close the configuration and execute the node:![Graphical user interface, text,
    application, email'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现一个**Excel Writer**节点。由于这次我们需要将四个不同的表格保存到一个Excel文件中，我们需要为节点添加三个输入端口。为此，点击节点图标左下角出现的三个点，然后选择**添加端口**
    | **表单输入端口**。再重复这一操作两次，总共获得四个输入端口。将提供*回答*我们目前已处理的五个问题的节点的输出端口连接到这些输入端口（包括整体前十名产品、按子类别的前三名、按国家的销售额以及最后一个数学公式的输出，其中包含2019年按类别计算的足迹和销售额）。在**Excel
    Writer**的配置中，这次我们会看到**Sheets**面板中有四个文本框：我们可以使用它们为每个表格分配一个有意义的名称，帮助阅读报告的人理解。声明输出文件的完整路径和名称（点击**浏览...**按钮选择），然后我们就准备好关闭配置并执行该节点了：![图形用户界面，文本，应用程序，电子邮件
- en: Description automatically generated](img/B17125_03_28.png)
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_03_28.png)
- en: 'Figure 3.28: Configuration of the Excel Writer: you can name each sheet differently'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.28：Excel Writer的配置：你可以为每个工作表命名
- en: 'The resulting Excel file looks exactly as we expected: we have four tabs, each
    looking after a different aspect of our business, providing straightforward answers
    to the common questions we had:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 最终生成的Excel文件正如我们预期的那样：我们有四个标签，每个标签关注我们业务的不同方面，直接回答了我们曾经提出的常见问题。
- en: '![](img/B17125_03_29.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_03_29.png)'
- en: 'Figure 3.29: The output file in Excel has four sheets to answer five business
    questions'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.29：Excel中的输出文件包含四个工作表，解答了五个商业问题
- en: It's time to move on to the last and final business question, which is about
    monthly peaks of sales across our seasonal subcategories, which are "Christmas",
    "Summer", and "Easter". To show seasonal patterns across the year, we decide to
    aggregate sales by month/subcategory combinations. A pivot table will enable such
    bidimensional aggregation, which will be easy to display on a line chart. The
    only outstanding intricacy to solve is related to the aggregation by month. At
    this point, in fact, we do not have months indicated in a separate column, so
    we cannot perform the aggregation straightaway. Fortunately, there is a node that
    enables us the extraction of any temporal field from a Date&Time column.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候进入最后一个业务问题了，那就是关于我们季节性子类别（“圣诞节”、“夏季”和“复活节”）的月度销售峰值。为了展示全年的季节性模式，我们决定按月份/子类别组合汇总销售额。透视表将实现这种二维聚合，便于在折线图上显示。唯一需要解决的复杂问题是与按月份聚合相关的问题。实际上，到目前为止，我们并没有将月份单独列出，因此无法直接进行聚合。幸运的是，有一个节点可以从日期和时间列中提取任何时间字段。
- en: '![](img/image081.png) *Extract Date&Time Fields*'
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image081.png) *提取日期和时间字段*'
- en: 'This node (**Other Data Types > Time Series > Transform**) creates a separate
    column for each date or time field (such as Year, Month, Day of week, Hour, Minute,
    and so on), extracting it from a given Date&Time input column. Its configuration
    requires us to select the Date&Time source column and then tick the boxes of the
    fields to extract. Since some fields are prone to regional and language differences,
    you can specify the **Locale** you prefer to use. For instance, if you extract
    Month (name) for a date in December, with the **es-ES** locale (Spanish), you
    will get `diciembre`:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点（**其他数据类型 > 时间序列 > 转换**）会为每个日期或时间字段（如年份、月份、星期几、小时、分钟等）创建一个单独的列，从给定的日期和时间输入列中提取。其配置要求我们选择日期和时间源列，然后勾选要提取的字段。由于某些字段可能会受到地区和语言差异的影响，你可以指定你希望使用的**区域设置**。例如，如果你提取12月的月份名称，并使用**es-ES**区域设置（西班牙语），你将得到`diciembre`：
- en: '![Graphical user interface, application'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序]'
- en: Description automatically generated](img/B17125_03_30.png)
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '[描述自动生成](img/B17125_03_30.png)'
- en: 'Figure 3.30: Configuration of Extract Date&Time Fields node: select the fields
    you want to appear as a separate column'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.30：提取日期和时间字段节点的配置：选择你希望作为单独列显示的字段
- en: 'Let''s implement an **Extract Date&Time Fields** node and connect the **String
    to Date&Time** output port to it (we want to consider the full dataset—not just
    2019—so we want to build a separate branch). The configuration is straightforward:
    we only have one Data&Time field in the input table so we find it already selected
    in the drop-down selection at the top. We only need to extract **Month (number)**,
    so this will be the only box to tick.'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们实现一个**提取日期和时间字段**节点，并将**字符串到日期和时间**的输出端口连接到它（我们希望考虑整个数据集——不仅仅是2019年——因此我们希望构建一个单独的分支）。配置很简单：输入表中只有一个日期和时间字段，所以它已经在顶部的下拉菜单中被选中。我们只需要提取**月份（数字）**，所以这将是唯一需要勾选的框。
- en: 'We can now summarize sales by month and subcategory: add a **Pivoting** node
    and configure it so that **Groups** are defined by the newly created column (*Month
    (number)*), **Pivots** are defined by the column *Subcategory*, and the **Manual
    Aggregation** is on **Sum** of *Sales*. To keep the headers clean, let''s select
    **Pivot name** as **Column name** and **Keep original name(s)** as **Aggregation
    name** in the drop-down menus at the bottom.'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以按月份和子类别总结销售情况：添加一个**透视**节点，并配置它，使得**分组**由新创建的列（*Month (number)*）定义，**透视**由列*Subcategory*定义，**手动聚合**设置为**销售额**的**总和**。为了保持标题整洁，我们可以在底部的下拉菜单中选择**透视名称**作为**列名称**，并将**保持原始名称**作为**聚合名称**。
- en: Seasonality can be explained better through a nice chart instead of a table.
    To build a chart in KNIME, you can use one of the visualization nodes (check them
    out in the repository in **View > JavaScript**), like the one we will use for
    our line chart.
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 季节性可以通过一个漂亮的图表来更好地展示，而不是使用表格。要在KNIME中构建图表，你可以使用其中一个可视化节点（在**视图 > JavaScript**的库中查看），就像我们将用于折线图的节点。
- en: '![](img/image085.png) *Line Plot*'
  id: totrans-352
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image085.png) *折线图*'
- en: 'This node (**View > JavaScript**) generates a line plot based on the data given
    at the input port. When configuring the node, you need to specify what column
    to use for the horizontal axis (**x-axis**) and what columns to visualize as separate
    lines (**y-axis**). Additionally, you can generate a static vectorial image (in
    SVG format) at the node''s output port: to enable this, tick the **Create image
    at outport** box at the top:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 此节点（**查看 > JavaScript**）根据输入端口给定的数据生成一条折线图。在配置节点时，您需要指定用于横轴（**x轴**）的列，以及用于可视化为独立线条的列（**y轴**）。此外，您还可以在节点的输出端口生成静态矢量图像（SVG格式）：要启用此功能，请勾选顶部的**在输出端口创建图像**框：
- en: '![Graphical user interface, application'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序'
- en: Description automatically generated](img/B17125_03_31.png)
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_03_31.png)
- en: 'Figure 3.31: Configuration of Line Plot node: select which columns to use on
    the horizontal and vertical axes of your chart'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.31：折线图节点配置：选择在图表的横轴和纵轴上使用哪些列
- en: In the **Axis Configuration** panel, you can specify the titles of the horizontal
    and vertical axes, while in the **General Plot Options**, you can set **Chart**
    **title**, **Chart** **subtitle**, and the size of the output image.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在**轴配置**面板中，您可以指定横轴和纵轴的标题，而在**常规图表选项**中，您可以设置**图表** **标题**、**图表** **副标题**以及输出图像的大小。
- en: Let's implement a Line Plot chart (pick the JavaScript version from the node
    repository) and connect the first output of the **Pivoting** node with it. For
    its configuration, let's choose *Month (number)* for the **x-axis** and the columns
    related to the seasonal subcategories (*Christmas*, *Easter*, and *Garden*) for
    the **y-axis**. Let's also check the first option box so we generate the vectorial
    image at the outport. To make the chart more readable, we can add also the names
    of the axis (`Sales` and `Month` will do) using the **Axis Configuration** panel.
    To execute the node and open its output straightaway, right-click on the node
    and then select **Execute and Open Views** (or *Shift* + *F10*):![](img/B17125_03_32.png)
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现一个折线图（从节点库中选择JavaScript版本），并将**透视**节点的第一个输出连接到它。在配置时，选择*月份（数字）*作为**x轴**，并选择与季节性子类别（*圣诞节*、*复活节*、*花园*）相关的列作为**y轴**。我们还将勾选第一个选项框，以便在输出端口生成矢量图像。为了使图表更易读，我们还可以使用**轴配置**面板添加轴的名称（`销售`和`月份`即可）。要执行该节点并立即打开其输出，右键单击该节点，然后选择**执行并打开视图**（或*Shift*
    + *F10*）：![](img/B17125_03_32.png)
- en: 'Figure 3.32: Output of the Line Plot node: our seasonal subcategories display
    an unsurprising monthly pattern'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.32：折线图节点输出：我们的季节性子类别显示出不出奇的月度模式
- en: 'The chart''s output confirms to us the seasonality patterns that we would expect
    from our subcategories: the shape of the lines can help us to best plan for the
    demand that we will encounter in the coming years. It would be nice to export
    this chart as a vectorial file so that we can include it in shiny presentations
    and—most importantly, as we will learn—build an engaging story out of it!'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 图表的输出向我们确认了我们期望从子类别中得到的季节性模式：线条的形状可以帮助我们为未来几年可能遇到的需求做好规划。将此图表导出为矢量文件以便在精美的展示中使用会非常不错——最重要的是，正如我们将要学习的那样，利用这个图表构建一个引人入胜的故事！
- en: '![](img/image091.png) *Image Writer (Port)*'
  id: totrans-361
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/image091.png) *图像写入器（端口）*'
- en: 'This node (**IO > Write**) saves an image as a separate file. The only configuration
    needed is to specify the **Output** **location**. You can select it in your file
    system by clicking on the **Browse...** button:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 此节点（**IO > 写入**）将图像保存为单独的文件。唯一需要配置的项是指定**输出** **位置**。您可以通过点击**浏览...**按钮在文件系统中选择它：
- en: '![Graphical user interface, text, application, email'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_03_33.png)
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_03_33.png)
- en: 'Figure 3.33: Configuration of the Image Writer (Port) node: where do you want
    your image file to be?'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.33：图像写入器（端口）节点配置：您希望将图像文件保存在哪里？
- en: Let's implement the **Image** **Writer** **(Port)** node; connect the output
    of the **Line** **Plot** node with it (the green square connectors indicate that
    we are transferring images here), and configure it by specifying the location
    of the output file (make sure you indicate the full file name, including the `.svg`
    extension at the end).
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现**图像** **写入器** **（端口）**节点；将**折线图**节点的输出连接到该节点（绿色方形连接器表示我们在此传输图像），并通过指定输出文件的保存位置来配置它（确保您指定完整的文件名，包括`.svg`扩展名）。
- en: 'You made it! It took some time, but the investment was entirely worth it: your
    workflow is now able to generate a multi-page report (and, when needed, visual
    proof of the seasonal patterns) in a matter of seconds. Every time new data becomes
    available, the full workflow can be reset (select the initial nodes and press
    *F8*) and re-run by just executing the final nodes (or *Shift* + *F7* to execute
    all nodes at once): no more human error or tedious manual steps with Excel. The
    finance analyst is very thankful, as she can now reinvest the time she used to
    spend every Friday pulling together the reports in something more value adding,
    like analyzing the numbers in depth, offering a relevant interpretation of data
    evidence, and providing some recommendations for improving the business results
    moving forward.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 你做到了！虽然花了一些时间，但这笔投资是完全值得的：现在你的工作流可以在几秒钟内生成一个多页报告（并且在需要时，提供季节性模式的可视化证明）。每当有新数据可用时，整个工作流可以通过重置（选择初始节点并按*F8*）并只执行最终节点（或按*Shift*
    + *F7*一次执行所有节点）来重新运行：不再有人工错误或繁琐的Excel手动步骤。财务分析师非常感激，因为她现在可以将每周五用于整理报告的时间，重新投入到更具价值的工作中，例如深入分析数字，提供数据证据的相关解释，并为改善未来的业务成果提供一些建议。
- en: '![](img/B17125_03_35.png)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_03_35.png)'
- en: 'Figure 3.34: It looks like a fish, but it''s a workflow that automates sales
    reporting'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.34：看起来像一条鱼，但它是一个自动化销售报告的工作流
- en: After admiring you in action, she is now intrigued by KNIME and wants to learn
    how to automate her data work by herself in the future. You have successfully
    planted a seed of enthusiasm for data analytics in your workplace, and it seems
    it is contagiously propagating further.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到你实际操作后，她现在对KNIME产生了浓厚的兴趣，并希望将来能自己学习如何自动化她的数据工作。你已经成功地在工作场所种下了数据分析的热情种子，而且看起来这种热情正在有感染力地传播开来。
- en: Summary
  id: totrans-371
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'By completing this chapter, you have made decisive progress in becoming a confident
    user of data analytics. You have learned how to provide some logic structure to
    your database by creating a simple entity-relationship model. You have also experienced
    the essential operations for transforming data assets, such as combining tables
    and aggregating values as needed. Your analytics toolbox is getting fatter: with
    fourteen more KNIME nodes at your disposal, you can now build some simple descriptive
    analytics workflows and automate their executions through loops and variables.
    The full tutorial has allowed you to gather first-person experience in building
    a machine that provides systemic answers to recurring needs, starting from a set
    of business questions and delivering a repeatable process to answer them.'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章后，你在成为数据分析的自信用户方面已取得决定性进展。你已经学会了通过创建简单的实体-关系模型，为数据库提供一定的逻辑结构。你还体验了转换数据资产的基本操作，如按需合并表格和聚合值。你的分析工具箱变得更加丰富：有了十四个额外的KNIME节点，你现在可以构建一些简单的描述性分析工作流，并通过循环和变量自动化它们的执行。完整的教程让你积累了构建一个能够为反复出现的问题提供系统性答案的机器的第一手经验，从一组业务问题出发，并交付一个可重复的流程来回答它们。
- en: 'In the next chapter, we will get all of this to the next level by introducing
    the fundamental concepts of artificial intelligence: we will soon discover how
    to build machines that can autonomously learn from data and support our work.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将通过引入人工智能的基本概念将这一切提升到一个新的水平：我们将很快发现如何构建能够从数据中自主学习并支持我们工作的机器。
