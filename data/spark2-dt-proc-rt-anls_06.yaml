- en: Apache SystemML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache SystemML
- en: So far, we have only covered components that came along with the standard distribution
    of Apache Spark (except HDFS, Kafka and Flume, of course). However, Apache Spark
    can also serve as runtime for third-party components, making it as some sort of
    operating system for big data applications. In this chapter, we want to introduce
    Apache SystemML, an amazing piece of technology initially developed by the *IBM
    Almaden Research Lab* in California. Apache SystemML went through many transformation
    stages and has now become an Apache top level project.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只涵盖了Apache Spark标准发行版附带的组件（当然，除了HDFS、Kafka和Flume）。然而，Apache Spark也可以作为第三方组件的运行时，使其成为某种大数据应用的操作系统。在本章中，我们将介绍最初由*IBM
    Almaden Research Lab*在加利福尼亚开发的Apache SystemML，这是一项令人惊叹的技术。Apache SystemML经历了许多转变阶段，现在已成为Apache顶级项目。
- en: 'In this chapter, we will cover the following topics to get a greater insight
    into the subject:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨以下主题，以深入了解该主题：
- en: Using SystemML for your own machine learning applications on top of Apache Spark
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Apache Spark之上使用SystemML开发您自己的机器学习应用
- en: Learning ...
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习...
- en: Why do we need just another library?
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么我们需要另一个库？
- en: In order to answer this question, we have to know something about SystemML's
    history, which began ten years ago in 2007 as a research project in the *IBM Almaden
    Research Lab* in California. The project was driven by the intention to improve
    the workflow of data scientists, especially those who want to improve and add
    functionality to existing machine learning algorithms.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，我们需要了解SystemML的历史，该历史始于2007年，作为*IBM Almaden Research Lab*在加利福尼亚的一个研究项目。该项目旨在改善数据科学家的工作流程，特别是那些希望改进和增强现有机器学习算法功能的人。
- en: So, **SystemML** is a declarative markup language that can transparently distribute
    work on Apache Spark. It supports Scale-up using multithreading and SIMD instructions
    on CPUs as well as GPUs and also Scale-out using a cluster, and of course, both
    together.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，**SystemML**是一种声明性标记语言，能够透明地在Apache Spark上分发工作。它支持通过多线程和CPU上的SIMD指令以及GPU进行Scale-up，以及通过集群进行Scale-out，当然，两者可以同时进行。
- en: Finally, there is a cost-based optimizer in place to generate low-level execution
    plans taking statistics about the Dataset sizes into account. In other words,
    **Apache SystemML** is for machine learning, what Catalyst and Tungsten are for
    DataFrames.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，有一个基于成本的优化器，它生成考虑数据集大小统计信息的低级执行计划。换句话说，**Apache SystemML**之于机器学习，正如Catalyst和Tungsten之于DataFrames。
- en: Why on Apache Spark?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为何基于Apache Spark？
- en: Apache Spark solves a lot of common issues in data processing and machine learning,
    so Apache SystemML can make use of these features. For example, Apache Spark supports
    the unification of SQL, Graph, Stream, and machine learning data processing on
    top of a common RDD structure.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark解决了数据处理和机器学习中的许多常见问题，因此Apache SystemML可以利用这些功能。例如，Apache Spark支持在通用RDD结构之上统一SQL、图形、流和机器学习数据处理。
- en: In other words, it is a general **DAG** (**directed acyclic graph**) execution
    engine supporting lazy evaluation and distributed in-memory caching.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 换言之，它是一个支持惰性求值和分布式内存缓存的通用**DAG**（**有向无环图**）执行引擎。
- en: The history of Apache SystemML
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache SystemML的历史
- en: Apache SystemML is already ten years old. Of course, it went through multiple
    refactorings and is now a state-of-the-art, and one of the fastest, machine learning
    libraries in the world.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Apache SystemML已有十年历史。当然，它经历了多次重构，现已成为世界上最先进、最快的机器学习库之一。
- en: '![](img/99d7fcbd-805c-4eb7-8ce4-824feb427843.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99d7fcbd-805c-4eb7-8ce4-824feb427843.png)'
- en: As you can see in the preceding figure, a lot of research has been done for
    Apache SystemML. It is two years older than Apache Spark and in 2017 it has been
    turned into a top-level Apache project, leaving **incubator** status. Even during
    the time SystemML was started, the researchers at *IBM Research Almaden* realized
    that, very often, out-of-the-box machine learning algorithms perform very poorly
    on large Datasets.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，针对Apache SystemML进行了大量研究。它比Apache Spark早两年，并在2017年成为Apache顶级项目，脱离**孵化器**状态。甚至在SystemML启动之初，*IBM
    Research Almaden*的研究人员就意识到，通常情况下，开箱即用的机器学习算法在大数据集上表现非常糟糕。
- en: 'So, the data analysis pipeline, had to be tuned after a small-scale version
    of it had been prototyped. The following figure illustrates this:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据分析管道在经过小规模原型调整后必须进行优化。下图说明了这一点：
- en: '![](img/f320753c-315a-4185-884d-d5cf1092b0c4.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f320753c-315a-4185-884d-d5cf1092b0c4.png)'
- en: This means that the data scientist will prototype his application in a programming
    language of his choice, most likely Matlab, R or python and, finally, a systems
    programmer will pick this up and re-implement this in a JVM language like Java
    or Scala, which usually turns out to provide better performance and also linearly
    scales on data parallel framework like Apache Spark.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着数据科学家将在他选择的编程语言中设计他的应用程序，最可能是Matlab、R或Python，最终，系统程序员将接手这个工作，并将其重新实现为JVM语言，如Java或Scala，这通常会提供更好的性能，并且也能在数据并行框架如Apache
    Spark上进行线性扩展。
- en: The scaled version of the prototype will return results on the whole Dataset
    and the data scientist again is in charge of modifying the prototype and the whole
    cycle begins again. Not only the IBM Almaden Research staff members have experienced
    this, but even our team has seen it. So let's make the systems programmer redundant
    (or at least require him only to take care of our Apache Spark jobs) using Apache
    SystemML.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 原型的缩放版本将在整个数据集上返回结果，数据科学家再次负责修改原型，整个循环再次开始。不仅IBM Almaden研究中心的员工经历过这种情况，我们的团队也见证了这一点。因此，让我们使系统程序员变得多余（或者至少只需要他来处理我们的Apache
    Spark作业），使用Apache SystemML。
- en: A cost-based optimizer for machine learning algorithms
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习算法的成本优化器
- en: Let's start with an example to exemplify how Apache SystemML works internally.
    Consider a recommender system.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个例子开始，来说明Apache SystemML内部是如何工作的。考虑一个推荐系统。
- en: An example - alternating least squares
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个例子 - 交替最小二乘法
- en: A recommender system tries to predict the potential items that a user might
    be interested in, based on a history from other users.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统试图根据其他用户的历史记录预测用户可能感兴趣的潜在商品。
- en: 'So let''s consider a so-called item-user or product-customer matrix, as illustrated
    here:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们考虑一个所谓的商品-用户或产品-客户矩阵，如图所示：
- en: '![](img/fec9348c-089f-4c7a-a554-afe5dc4c2ed1.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fec9348c-089f-4c7a-a554-afe5dc4c2ed1.png)'
- en: This is a so-called **sparse** matrix because only a couple of cells are populated
    with non-zero values indicating a match between a customer *i* and a product *j*.
    Either by just putting a **one** in the cell or any other numerical value, for
    example, indicating the number of products bought or a rating for that particular
    product *j* from customer *i*. Let's call this matrix *r[ui]*, where *u* stands
    for user and *i* for item.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个所谓的**稀疏**矩阵，因为只有少数单元格填充了非零值，表示客户*i*和产品*j*之间的匹配。要么在单元格中放置一个**一**，要么放置任何其他数值，例如，表示购买的产品数量或客户*i*对特定产品*j*的评分。我们称这个矩阵为*r[ui]*，其中*u*代表用户，*i*代表商品。
- en: Those of you familiar with linear algebra might know that any matrix can be
    factorized by two smaller matrices. This means that you have to find two matrices
    *p[u]* and *q[i]* that, when multiplied with each other, reconstruct the original
    matrix *r[ui]*; let's call the reconstruction *r[ui]'*. The goal is to find *p[u]*
    and *q[i]* to reconstruct *r[ui]'* such that it doesn't differ too much from *r[ui]*.
    This is done using a sum of squared errors objective.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉线性代数的你可能知道，任何矩阵都可以通过两个较小的矩阵进行因式分解。这意味着你需要找到两个矩阵*p[u]*和*q[i]*，当它们相乘时，能够重构原始矩阵*r[ui]*；我们称这个重构为*r[ui]'*。目标是找到*p[u]*和*q[i]*以重构*r[ui]'*，使其与*r[ui]*的差异不过大。这通过求和平方误差目标函数来实现。
- en: 'The following figure illustrates this and the sparsity property of the matrix:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了这一点以及矩阵的稀疏性特性：
- en: '![](img/313de954-d123-4de2-9a17-946ba029838a.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/313de954-d123-4de2-9a17-946ba029838a.png)'
- en: Once we've found good factors *p[u]* and *q[i]*, we can construct *r[ui]'* and,
    finally, new non-zero cells will be present, which become the new predicted product
    suggestions. In case you haven't understood all the details, don't worry, as we
    don't need too much of this example to understand the rest of this chapter.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们找到了良好的因子*p[u]*和*q[i]*，我们就能构建*r[ui]'*，最终，新的非零单元格将出现，这些将成为新的预测产品推荐。如果你还没有完全理解所有细节，不用担心，因为理解本章其余部分并不需要太多这个例子。
- en: 'A common algorithm to find *p[u]* and *q[i]* is called **alternating least
    squares** (**ALS**)--alternating because in each iteration the optimization objective
    switches from *p[u]* to *q[i]* and vice versa. Don''t get bothered with it too
    much, but this is how it actually works, and, in Apache Spark MLlib, this is just
    a single line of Scala code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找*p[u]*和*q[i]*的常用算法称为**交替最小二乘法**（**ALS**）——交替是因为在每次迭代中，优化目标从*p[u]*切换到*q[i]*，反之亦然。对此不必过于纠结，但实际运作即是如此，而在Apache
    Spark MLlib中，这仅是一行Scala代码：
- en: '![](img/09984e95-cf71-420f-a20e-a54a99248aad.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/09984e95-cf71-420f-a20e-a54a99248aad.png)'
- en: 'So what''s wrong with this? Before we explain this, let''s take a look at how
    ALS is implemented in a statistical programming language such as R:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 那么问题何在？在我们解释之前，先来看看ALS如何在统计编程语言如R中实现：
- en: '![](img/11ca287a-c585-495a-b154-b356f6576364.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/11ca287a-c585-495a-b154-b356f6576364.png)'
- en: Again, don't worry if you don't understand each line, but the purpose of this
    figure is to show you that in R, this algorithm needs only 27 lines of code to
    be expressed. If we now take a look at the ALS implementation in MLlib, we'll
    see that it has more than 800 lines. You can find this implementation at [https://github.com/apache/spark/tree/master/mllib/src/main/scala/org/apache/spark/mllib/recommendation](https://github.com/apache/spark/tree/master/mllib/src/main/scala/org/apache/spark/mllib/recommendation).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，若你未能理解每一行代码也不必担心，此图旨在展示在R中，该算法仅需27行代码即可表达。若我们再查看MLlib中的ALS实现，会发现它有超过800行代码。你可在[https://github.com/apache/spark/tree/master/mllib/src/main/scala/org/apache/spark/mllib/recommendation](https://github.com/apache/spark/tree/master/mllib/src/main/scala/org/apache/spark/mllib/recommendation)找到此实现。
- en: So why do we need more than 800 lines in Scala on Spark and only 27 in R? This
    is because of performance optimizations. The ALS implementation in MLlib consists
    of more than 50% of performance optimization code. So what if we could perform
    the following?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 那么为何在Spark上需要超过800行的Scala代码，而在R中仅需27行呢？这是因为性能优化。MLlib中的ALS实现包含了超过50%的性能优化代码。如果我们能做到以下这些呢？
- en: Get rid of all performance optimizations in our algorithm implementation
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 去除我们算法实现中的所有性能优化
- en: Port our R code 1:1 to some parallel framework
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将我们的R代码1:1移植到某个并行框架
- en: In case of changes, just change our R implementation
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如有变动，只需修改我们的R实现
- en: This is where Apache SystemML kicks in, it supports all this. Apache SystemML's
    **DSL** (**domain specific language**) is a subset of R syntax, so you can just
    take the previous example and run it 1:1 without any modification on top of Apache
    SystemML. In addition, a cost-based performance optimizer generates a physical
    execution plan on top of Apache Spark in order to minimize execution time based
    on the size properties of your data. So let's find out how this works.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是Apache SystemML发挥作用的地方，它支持这一切。Apache SystemML的**DSL**（**特定领域语言**）是R语法的一个子集，因此你可以直接将之前的示例原封不动地运行在Apache
    SystemML之上，无需任何修改。此外，基于成本的性能优化器会在Apache Spark之上生成物理执行计划，以根据数据规模属性最小化执行时间。那么，让我们探究其工作原理。
- en: ApacheSystemML architecture
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache SystemML架构
- en: 'So the key thing on Apache SystemML is the optimizer. This component turns
    a high-level description of an algorithm in a domain-specific language into a
    highly optimized physical execution on Apache Spark, as shown in the following
    figure:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在Apache SystemML中，关键在于优化器。该组件将算法的高级描述在特定领域语言中转化为Apache Spark上高度优化的物理执行，如图所示：
- en: '![](img/0747c796-c870-468f-bf36-ba63cf7b6945.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0747c796-c870-468f-bf36-ba63cf7b6945.png)'
- en: Language parsing
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语言解析
- en: Let's open this black box a bit in order to understand what exactly is going
    on in the Apache SystemML optimizer. The first thing that the engine does is a
    compile step on the DSL. So first, syntax checking, then live variable analysis
    in order to determine which intermediate results are still needed, and finally
    a semantic check.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍稍揭开Apache SystemML优化器的神秘面纱，以便理解其中究竟发生了什么。引擎首先进行的是DSL的编译步骤。首先是语法检查，然后进行活跃变量分析以确定哪些中间结果仍需保留，最后进行语义检查。
- en: High-level operators are generated
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成高级操作符
- en: 'Once the previous step is passed, the execution plan using so-called **high-level
    operators** (**HOPs**) is generated. These are constructed from the **abstract
    syntax tree** (**AST**) of the DSL. The following important optimization steps
    are taking place during this phase:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦通过前述步骤，便生成使用所谓**高级操作符**（**HOPs**）的执行计划。这些操作符构建自DSL的**抽象语法树**（**AST**）。在此阶段，以下重要优化步骤正在进行：
- en: '**Static rewrites**: The DSL offers a rich set of syntactical and semantic
    features that makes an implementation easy to understand but may result in a non-optimal
    execution. Apache SystemML detects these branches of the AST and statically rewrites
    them to a better version, maintaining the semantic equivalency.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**静态重写**：DSL提供了一套丰富的语法和语义特性，使得实现易于理解，但可能导致非最优执行。Apache SystemML检测到这些AST分支，并静态地将其重写为更好的版本，保持语义等价。'
- en: '**Dynamic rewrites**: Dynamic rewrites are very similar to static rewrites
    but are driven by cost-based statistics considering the size of the Datasets ...'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态重写**：动态重写与静态重写非常相似，但它们是由基于成本的统计数据驱动的，考虑了数据集的大小...'
- en: How low-level operators are optimized on
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 低级操作符如何被优化
- en: 'Let''s have a look on, how low-level operators are selected and optimized on.
    We''ll stick to the weighted divide matrix multiplication example--a HOP that
    has been selected before the HOP optimizations process over an ordinary sequence
    of matrix multiplications. So now the question arises, for example, if it makes
    sense to use a parallel version of a LOP running parallel on the Apache Spark
    workers, or whether a local execution is preferable. In this example, Apache SystemML
    determines that all intermediate results fit into the main memory of the driver
    node and chooses the local operator, **WDivMM**, over the parallel operator, **MapWDivMM**.
    The following figure illustrates this process:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看，低级操作符是如何被选择和优化的。我们将坚持使用加权除法矩阵乘法的例子——一个在HOP优化过程之前被选中的HOP，而不是一系列普通的矩阵乘法。现在问题来了，例如，是否应该使用在Apache
    Spark工作节点上并行运行的LOP的并行版本，或者是否应该优先考虑本地执行。在这个例子中，Apache SystemML确定所有中间结果都适合驱动节点的主内存，并选择本地操作符**WDivMM**，而不是并行操作符**MapWDivMM**。下图说明了这一过程：
- en: '![](img/41cf44d5-92c7-4841-b372-0bd9d429d63f.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/41cf44d5-92c7-4841-b372-0bd9d429d63f.png)'
- en: Performance measurements
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能测量
- en: 'So is all this effort worth it? Let''s take a look at some performance comparisons
    between a local R script, MLlib, and Apache SystemML:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些努力值得吗？让我们来看一些本地R脚本、MLlib和Apache SystemML之间的性能比较：
- en: '![](img/730107a4-fa1e-4a18-9661-09639c998ed2.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/730107a4-fa1e-4a18-9661-09639c998ed2.png)'
- en: The ALS algorithm has been run on different Datasets with 1.2, 12, and 120 GB
    size using R, MLlib, and ApacheSystemML. We can clearly see that, even on the
    smallest Dataset, R is not a feasible solution as it took more than 24 hours,
    and we are not sure if it would have ever completed. On the 12 GB Dataset, we've
    noticed that ApacheSystemML runs significantly faster than MLlib, and finally,
    on the 120 GB Dataset, the ALS implementation of MLlib didn't finish in one day
    and we gave ...
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同大小的数据集（1.2GB、12GB和120GB）上运行ALS算法，使用R、MLlib和ApacheSystemML。我们可以清楚地看到，即使在最小的数据集上，R也不是一个可行的解决方案，因为它花费了超过24小时，我们不确定它是否能完成。在12GB的数据集上，我们注意到ApacheSystemML比MLlib运行得快得多，最后，在120GB的数据集上，MLlib的ALS实现一天内没有完成，我们...
- en: Apache SystemML in action
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache SystemML的实际应用
- en: 'So let''s take a look at a very simple example. Let''s create a script in Apache
    SystemML DSL--an R-like syntax--in order to multiply two matrices:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个非常简单的例子。让我们在Apache SystemML DSL中创建一个脚本——一种类似R的语法——以便乘以两个矩阵：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we generate some test data:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们生成一些测试数据：
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In order to use Apache SystemML, we have to create an `MLContext` object:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用Apache SystemML，我们必须创建一个`MLContext`对象：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now we have to convert our data to a format that Apache SystemML understands:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要将数据转换成Apache SystemML能理解的格式：
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we pass the data `X` and `Y` to the Apache SystemML runtime and also preregister
    a variable called `Z` in order to obtain the result from the runtime:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将数据`X`和`Y`传递给Apache SystemML运行时，并预先注册一个名为`Z`的变量，以便从运行时获取结果：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, we actually execute the script stored in `simpleScript` with the `executeScript`
    method and obtain the result from the runtime:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们实际执行了存储在`simpleScript`中的脚本，并使用`executeScript`方法从运行时获取结果：
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now `Z` contains `DataFrame` with the result of the matrix multiplication. Done!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在`Z`包含了一个带有矩阵乘法结果的`DataFrame`。完成！
- en: Summary
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: You've learned that there is room for additional machine learning frameworks
    and libraries, on top of Apache Spark and that, a cost-based optimizer similar
    to what we are already using in Catalyst can speed things up tremendously. In
    addition, separation from performance optimizations code and code for the algorithm
    facilitates further improvements on the algorithm side without having to care
    about performance at all.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你已了解到，在Apache Spark之上还有额外的机器学习框架和库的空间，并且，一个类似于我们在Catalyst中已使用的基于成本的优化器可以极大地加速处理。此外，将性能优化代码与算法代码分离，有助于在不考虑性能的情况下进一步改进算法方面。
- en: Additionally, these execution plans are highly adaptable to the size of the
    data and also to the available hardware configuration based on main memory size
    and potential accelerators such as GPUs. Apache SystemML dramatically improves
    on the life cycle of machine learning applications, especially if machine learning
    ...
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，这些执行计划高度适应数据量的大小，并根据主内存大小和可能的加速器（如GPU）等可用硬件配置进行调整。Apache SystemML显著提升了机器学习应用的生命周期，尤其是在机器学习方面...
