- en: Chapter 5. Persistence Using Redis and MongoDB
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。使用Redis和MongoDB进行持久化
- en: 'It is often necessary to store tuples in a persistent data store, such as a
    NoSQL database or a fast key-value cache, in order to perform additional analysis.
    In this chapter, we will revisit the Twitter trending analysis topology from [Chapter
    4](ch04.html "Chapter 4. Example Topology – Twitter"), *Example Topology – Twitter*
    with the help of two popular persistence media: Redis and MongoDB.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 通常需要将元组存储在持久性数据存储中，例如NoSQL数据库或快速键值缓存，以进行额外的分析。在本章中，我们将借助两种流行的持久性媒体Redis和MongoDB，重新访问来自[第4章](ch04.html
    "第4章。示例拓扑-推特")的Twitter趋势分析拓扑，*示例拓扑-推特*。
- en: Redis ([http://redis.io/](http://redis.io/)) is an open source and BSD-licensed
    advanced key-value cache and store. MongoDB is a cross-platform, document-oriented
    database ([https://www.mongodb.org/](https://www.mongodb.org/)).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Redis（[http://redis.io/](http://redis.io/)）是一个开源的BSD许可高级键值缓存和存储。MongoDB是一个跨平台的面向文档的数据库（[https://www.mongodb.org/](https://www.mongodb.org/)）。
- en: 'Here are the two problems that we will solve in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将解决以下两个问题：
- en: Finding the top trending tweet topics using Redis
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Redis查找热门推文话题
- en: Computing hourly aggregates of city mentions using MongoDB
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MongoDB计算城市提及的每小时聚合
- en: Finding the top n ranked topics using Redis
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Redis查找排名前n的话题
- en: 'The topology will compute a rolling ranking of the most popular words in the
    past 5 minutes. The word counts are stored in individual windows of 60 seconds
    in length. It consists of the following components:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑将计算过去5分钟内最受欢迎的单词的滚动排名。单词计数存储在长度为60秒的各个窗口中。它包括以下组件：
- en: 'Twitter stream spout (`twitterstream.py`): This reads tweets from the Twitter
    sample stream. This spout is unchanged from [Chapter 4](ch04.html "Chapter 4. Example
    Topology – Twitter"), *Example Topology – Twitter*.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Twitter流喷口（`twitterstream.py`）：这从Twitter样本流中读取推文。这个喷口与[第4章](ch04.html "第4章。示例拓扑-推特")中的相同，*示例拓扑-推特*。
- en: 'Splitter bolt (`splitsentence.py`): This receives tweets and splits them into
    words. This is also identical to the one in [Chapter 4](ch04.html "Chapter 4. Example
    Topology – Twitter"), *Example Topology – Twitter*.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割器螺栓（`splitsentence.py`）：这接收推文并将它们分割成单词。这也与[第4章](ch04.html "第4章。示例拓扑-推特")中的相同，*示例拓扑-推特*。
- en: 'Rolling word count bolt (`rollingcount.py`): This receives words and counts
    the occurrences. The Redis keys look like `twitter_word_count:<start time of current
    window in seconds>`, and the values are stored in a hash using the following simple
    format:'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滚动字数计数螺栓（`rollingcount.py`）：这接收单词并计算出现次数。 Redis键看起来像`twitter_word_count：<当前窗口开始时间（以秒为单位）>`，值存储在哈希中，格式如下：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This bolt uses the Redis `expireat` command to discard old data after 5 minutes.
    These lines of code perform the key work:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这个螺栓使用Redis的`expireat`命令在5分钟后丢弃旧数据。这些代码行执行关键工作：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this bolt, the following code does the most important work:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个螺栓中，以下代码完成了最重要的工作：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This bolt computes the top `maxSize` words across the last num_windows periods.
    The `zunionstore()` combines the word counts across the periods. The `zrevrange()`
    sorts the combined counts, returning the top `maxSize` words.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这个螺栓计算了在过去的num_windows周期内的前`maxSize`个单词。`zunionstore()`组合了各个时期的单词计数。`zrevrange()`对组合计数进行排序，返回前`maxSize`个单词。
- en: In the original Twitter example, roughly the same logic was implemented in `rollingcount.py`,
    `intermediaterankings.py`, and `totalrankings.py`. With Redis, we can implement
    the same calculations in just a few lines. The design delegates much of the work
    to Redis. Depending on your data volumes, this may not scale as well as the topology
    in the previous chapter. However, it demonstrates that Redis's capabilities go
    far beyond simply storing data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始的Twitter示例中，`rollingcount.py`，`intermediaterankings.py`和`totalrankings.py`中实现了大致相同的逻辑。使用Redis，我们可以用几行代码实现相同的计算。设计将大部分工作委托给了Redis。根据您的数据量，这可能不如前一章中的拓扑那样具有规模。但是，这表明了Redis的能力远远不止于简单存储数据。
- en: The topology configuration file – the Redis case
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拓扑配置文件-Redis案例
- en: Coming up is the topology configuration file. Depending on your Redis installation,
    you may need to change the value of `redis_url`.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是拓扑配置文件。根据您的Redis安装，您可能需要更改`redis_url`的值。
- en: 'Enter this code in `topology.yaml`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在`topology.yaml`中输入以下代码：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Rolling word count bolt – the Redis case
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 滚动字数计数螺栓-Redis案例
- en: The rolling word count bolt is similar to the word count bolt in [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel*. The bolt in the earlier
    chapter simply accumulated the word count indefinitely. This is not good for analyzing
    the top words on Twitter, where the popular topics can change from one moment
    to the next. Rather, we want counts that reflect the latest information. As explained
    earlier, the rolling word count bolt stores data in time-based buckets. Then,
    it periodically discards buckets that exceed 5 minutes in age. Thus, the word
    counts from this bolt only consider the last 5 minutes of data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动字数计数螺栓类似于[第3章](ch03.html "第3章。介绍Petrel")中的字数计数螺栓，*介绍Petrel*。早期章节中的螺栓只是无限累积了单词计数。这对于分析Twitter上的热门话题并不好，因为热门话题可能在下一刻就会改变。相反，我们希望计数反映最新的信息。如前所述，滚动字数计数螺栓将数据存储在基于时间的存储桶中。然后，定期丢弃超过5分钟的存储桶。因此，这个螺栓的单词计数只考虑最近5分钟的数据。
- en: 'Enter this code in `rollingcount.py`:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在`rollingcount.py`中输入以下代码：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Total rankings bolt – the Redis case
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总排名螺栓-Redis案例
- en: 'Enter the following code in `totalrankings.py`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在`totalrankings.py`中输入以下代码：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Defining the topology – the Redis case
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义拓扑-Redis案例
- en: 'Here is the `create.py` script that defines the structure of the topology:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这是定义拓扑结构的`create.py`脚本：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Running the topology – the Redis case
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行拓扑-Redis案例
- en: 'We have a few more small things to address before we run the topology:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行拓扑之前，我们还有一些小事情要处理：
- en: Copy the `logconfig.ini` file from the second example in [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel*, to this topology's directory.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[第3章](ch03.html "第3章 Petrel介绍")的第二个例子中复制`logconfig.ini`文件，*Petrel介绍*到这个拓扑的目录。
- en: 'Create a file called `setup.sh`. Petrel will package this script with the topology
    and run it at startup. This script installs the third-party Python libraries used
    by the topology. The file looks like this:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`setup.sh`的文件。Petrel将会把这个脚本和拓扑一起打包，并在启动时运行它。这个脚本安装了拓扑使用的第三方Python库。文件看起来是这样的：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Create a file called `manifest.txt` with these two lines:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`manifest.txt`的文件，包含以下两行：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Install the Redis server on a well-known node. All workers will store state
    here:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个已知的节点上安装Redis服务器。所有的工作节点都会在这里存储状态：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Install the Python Redis client on all Storm worker machines:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在所有Storm工作节点上安装Python Redis客户端：
- en: '[PRE10]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Before running the topology, let''s review the list of files that we''ve created.
    Make sure you have created these files correctly:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在运行拓扑之前，让我们回顾一下我们创建的文件列表。确保你已经正确创建了这些文件：
- en: '`topology.yaml`'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`topology.yaml`'
- en: '`twitterstream.py`'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`twitterstream.py`'
- en: '`splitsentence.py`'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`splitsentence.py`'
- en: '`rollingcount.py`'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rollingcount.py`'
- en: '`totalrankings.py`'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`totalrankings.py`'
- en: '`manifest.txt`'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`manifest.txt`'
- en: '`setup.sh`'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setup.sh`'
- en: 'Run the topology with the following command:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令运行拓扑：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Once the topology is running, open another terminal in the topology directory.
    Enter this command to see the log file for the total rankings bolt, sorted from
    oldest to newest:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑运行后，在拓扑目录中打开另一个终端。输入以下命令来查看总排名bolt的日志文件，从最旧到最新排序：
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'If this is the first time you are running the topology, there will be only
    one log file listed. A new file is created for each run. If there are several
    listed, choose the most recent one. Enter this command to monitor the contents
    of the log file (the exact filename will be different on your system):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是你第一次运行这个拓扑，那么只会列出一个日志文件。每次运行都会创建一个新文件。如果列出了几个文件，选择最近的一个。输入以下命令来监视日志文件的内容（确切的文件名在你的系统上会有所不同）：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Periodically, you will see an output like the following, listing the top 5
    words in descending order of popularity:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 定期地，你会看到类似以下的输出，按照流行度降序列出前5个单词：
- en: 'Example output from `totalrankings`:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`totalrankings`的示例输出：'
- en: '[PRE14]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Finding the hourly count of tweets by city name using MongoDB
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用MongoDB按城市名称查找每小时推文数量
- en: MongoDB is a popular database for storing large amounts of data. It is designed
    for easy scalability across many nodes.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB是一个用于存储大量数据的流行数据库。它被设计为在许多节点之间轻松扩展。
- en: 'To run this topology, you first need to install MongoDB and configure some
    database-specific settings. This example uses a MongoDB database called `cities`
    with a collection named `minute`. In order to compute the counts by city and minute,
    we must create a unique index on the `cities.minute` collection. To do this, launch
    the MongoDB command-line client:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行这个拓扑，首先需要安装MongoDB并配置一些特定于数据库的设置。这个例子使用一个名为`cities`的MongoDB数据库，其中包含一个名为`minute`的集合。为了计算每个城市和分钟的计数，我们必须在`cities.minute`集合上创建一个唯一索引。为此，启动MongoDB命令行客户端：
- en: '[PRE15]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a unique index on the `cities.minute` collection:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在`cities.minute`集合上创建一个唯一索引：
- en: '[PRE16]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This index stores a per minute time series of city counts in MongoDB. After
    running the example topology to capture some data, we'll run a standalone command-line
    script (`city_report.py`) to sum the per minute city counts by hour and city.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这个索引在MongoDB中存储了每分钟城市计数的时间序列。在运行示例拓扑捕获一些数据后，我们将运行一个独立的命令行脚本（`city_report.py`）来按小时和城市汇总每分钟的城市计数。
- en: This is a variant of the earlier Twitter topology. This example uses the Python
    geotext library ([https://pypi.python.org/pypi/geotext](https://pypi.python.org/pypi/geotext))
    to find city names in tweets.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这是之前Twitter拓扑的一个变种。这个例子使用了Python的geotext库（[https://pypi.python.org/pypi/geotext](https://pypi.python.org/pypi/geotext)）来查找推文中的城市名称。
- en: 'Here is an overview of the topology:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是拓扑的概述：
- en: Read the tweets.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读推文。
- en: Split them into words and find city names.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将它们拆分成单词并找到城市名称。
- en: In MongoDB, count the number of times a city is mentioned each minute.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在MongoDB中，计算每分钟提到一个城市的次数。
- en: 'Twitter stream spout (`twitterstream.py`): This reads tweets from the Twitter
    sample stream.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Twitter流spout（`twitterstream.py`）：从Twitter样本流中读取推文。
- en: 'City count bolt (`citycount.py`): This finds city names and writes to MongoDB.
    It is similar to the `SplitSentenceBolt` from the Twitter sample, but after splitting
    by words, it looks for city names.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 城市计数bolt（`citycount.py`）：这个模块找到城市名称并写入MongoDB。它类似于Twitter样本中的`SplitSentenceBolt`，但在拆分单词后，它会寻找城市名称。
- en: The `_get_words()` function here is slightly different from earlier examples.
    This is because geotext does not recognize lowercase strings as city names.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的`_get_words()`函数与之前的例子略有不同。这是因为geotext不会将小写字符串识别为城市名称。
- en: It creates or updates MongoDB records, taking advantage of the unique index
    on minute and city to accumulate the per minute counts.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 它创建或更新MongoDB记录，利用了分钟和城市的唯一索引来累积每分钟的计数。
- en: This is a common pattern for representing time series data in MongoDB. Each
    record also includes an `hour` field. The `city_report.py` script uses this to
    compute the hourly counts.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在MongoDB中表示时间序列数据的常见模式。每条记录还包括一个`hour`字段。`city_report.py`脚本使用这个字段来计算每小时的计数。
- en: 'Enter this code in `citycount.py`:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在`citycount.py`中输入以下代码：
- en: '[PRE17]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Defining the topology – the MongoDB case
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义拓扑 - MongoDB案例
- en: 'Enter the following code in `create.py`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在`create.py`中输入以下代码：
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Running the topology – the MongoDB case
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行拓扑 - MongoDB案例
- en: 'We have a few more small things to address before we run the topology:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们运行拓扑之前，我们还有一些小事情要处理：
- en: Copy the `logconfig.ini` file from the second example in [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel* to this topology's directory.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[第3章](ch03.html "第3章 Petrel介绍")的第二个例子中复制`logconfig.ini`文件，*Petrel介绍*到这个拓扑的目录。
- en: 'Create a file called `setup.sh`:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`setup.sh`的文件：
- en: '[PRE19]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Next, create a file called `manifest.txt`. This is identical to the Redis example.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建一个名为`manifest.txt`的文件。这与Redis示例相同。
- en: Install the MongoDB server. On Ubuntu, you can use the instructions given at
    [http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/](http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '安装MongoDB服务器。在Ubuntu上，您可以使用[http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/](http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/)中提供的说明。 '
- en: 'Install the Python MongoDB client on all Storm worker machines:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在所有Storm工作机器上安装Python MongoDB客户端：
- en: '[PRE20]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To verify that `pymongo` is installed and the index is created correctly, start
    an interactive Python session by running `python`. Then use this code:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要验证`pymongo`是否已安装并且索引已正确创建，请运行`python`启动交互式Python会话，然后使用此代码：
- en: '[PRE21]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You should see the following output. The second line is the index that we added:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下输出。第二行是我们添加的索引：
- en: '[PRE22]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Next, install `geotext`:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，安装`geotext`：
- en: '[PRE23]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Before running the topology, let''s review the list of files that we created.
    Make sure you have created these files correctly:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在运行拓扑之前，让我们回顾一下我们创建的文件列表。确保您已正确创建这些文件：
- en: '`topology.yaml`'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`topology.yaml`'
- en: '`twitterstream.py`'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`twitterstream.py`'
- en: '`citycount.py`'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`citycount.py`'
- en: '`manifest.txt`'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`manifest.txt`'
- en: '`setup.sh`'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setup.sh`'
- en: 'Run the topology with the following command:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令运行拓扑：
- en: '[PRE24]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `city_report.py` file is a standalone script that generates a simple hourly
    report from the data inserted by the topology. This script uses MongoDB aggregation
    to compute the hourly totals. As noted earlier, the report depends on the presence
    of an `hour` field.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`city_report.py`文件是一个独立的脚本，它从拓扑插入的数据中生成一个简单的每小时报告。此脚本使用MongoDB聚合来计算每小时的总数。正如前面所述，报告取决于是否存在`hour`字段。'
- en: 'Enter this code in `city_report.py`:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在`city_report.py`中输入此代码：
- en: '[PRE25]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Summary
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we saw how to use two popular NoSQL storage engines (Redis
    and MongoDB) with Storm. We also showed you how to create data in a topology and
    access it from other applications, demonstrating that Storm can be an effective
    part of an ETL pipeline.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到如何将两种流行的NoSQL存储引擎（Redis和MongoDB）与Storm一起使用。我们还向您展示了如何在拓扑中创建数据并从其他应用程序访问它，证明了Storm可以成为ETL管道的有效部分。
