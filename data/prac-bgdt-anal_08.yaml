- en: Machine Learning Deep Dive
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习深入探讨
- en: The prior chapter on machine learning provided a preliminary overview of the
    subject, including the different classes and core concepts in the subject area.
    This chapter will delve deeper into the theoretical aspects of machine learning
    such as the limits of algorithms and how different algorithms work.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 前一章关于机器学习提供了该主题的初步概述，包括该领域中的不同类别和核心概念。本章将深入探讨机器学习的理论方面，例如算法的限制以及不同算法的工作原理。
- en: '**Machine learning** is a vast and complex subject, and to that end, this chapter
    focuses on the breadth of different topics, rather than the depth. The concepts
    are introduced at a high level and the reader may refer to other sources to further
    their understanding of the topics.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**是一个广泛而复杂的主题，因此本章侧重于不同主题的广度，而非深度。概念以高层次的方式介绍，读者可以参考其他资源进一步了解这些主题。'
- en: We will start out by discussing a few fundamental theories in machine learning,
    such as Gradient Descent and VC Dimension. Next, we will look at Bias and Variance,
    two of the most important factors in any modelling process and the concept of
    bias-variance trade-off.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从讨论机器学习中的几个基础理论开始，例如梯度下降和VC维度。接下来，我们将探讨偏差和方差，这两者是任何建模过程中最重要的因素，并讨论偏差-方差平衡的概念。
- en: We'll then discuss the various machine learning algorithms, their strengths
    and areas of applications.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将讨论各种机器学习算法，它们的优点和应用领域。
- en: We'll conclude with exercises that leverage real-world datasets to perform machine
    learning operations using R.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过利用现实世界的数据集进行练习，使用R进行机器学习操作，最后得出结论。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The bias, variance, and regularization properties
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偏差、方差和正则化属性
- en: Gradient descent and VC dimension theories
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度下降与VC维度理论
- en: Machine learning algorithms
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习算法
- en: 'Tutorial: Machine learning with R'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教程：使用R进行机器学习
- en: The bias, variance, and regularization properties
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差、方差和正则化属性
- en: Bias, variance, and the closely related topic of regularization hold very special
    and fundamental positions in the field of machine learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差、方差和密切相关的正则化在机器学习领域中占有非常特殊和基础的位置。
- en: Bias happens when a machine learning model is too 'simple', leading to results
    that are consistently off from the actual values.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差发生在机器学习模型过于“简单”时，导致结果与实际值始终存在偏差。
- en: Variance happens when a model is too 'complex', leading to results that are
    very accurate on test datasets, but do not perform well on unseen/new datasets.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 方差发生在模型过于“复杂”时，导致模型在测试数据集上非常准确，但在未见过/新的数据集上表现不佳。
- en: Once users become familiar with the process of creating machine learning models,
    it would seem that the process is quite simplistic - get the data, create a training
    set and a test set, create a model, apply the model on the test dataset, and the
    exercise is complete. Creating models is easy; creating a *good* model is a much
    more challenging topic. But how can one test the quality of a model? And, perhaps
    more importantly, how does one go about building a 'good' model?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦用户熟悉了创建机器学习模型的过程，似乎这个过程非常简单——获取数据，创建训练集和测试集，创建模型，将模型应用于测试数据集，练习就完成了。创建模型很容易；创建一个*好的*模型则是一个更具挑战性的话题。但是，如何测试模型的质量呢？也许更重要的是，如何构建一个“好的”模型？
- en: The answer lies in a term called regularization. It's arguably a fancy word,
    but all it means is that during the process of creating a model, one benefits
    from penalizing an overly impressive performance on a training dataset and relaxing
    the same on a poorly performing model.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 答案在于一个叫做正则化的术语。它可能是一个华丽的词，但它的意思就是在创建模型的过程中，通过对训练数据集上过度良好的表现进行惩罚，同时对表现不佳的模型进行放松，从而获得更好的模型。
- en: To understand regularization, it would help to know the concepts of overfitting
    and underfitting. For this, let us look at a simple but familiar example of drawing
    lines of best fit. For those who have used Microsoft Excel, you may have noticed
    the option to draw the *line of best fit* - in essence, given a set of points,
    you can draw a line that represents the data and approximates the function that
    the points represent.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解正则化，了解过拟合和欠拟合的概念会有所帮助。为此，我们来看一个简单但熟悉的例子——拟合最佳线条。对于那些使用过Microsoft Excel的人来说，可能注意到有一个选项可以绘制*最佳拟合线*——本质上，给定一组点，你可以画出一条代表数据的线，并近似表示这些点所代表的函数。
- en: 'The following table shows the prices vs square footage of a few properties.
    In order to determine the relationship between house prices and the size of the
    house, we can draw a line of best fit, or a trend line, as shown as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格展示了几处房产的价格与平方英尺的关系。为了确定房价与房屋大小之间的关系，我们可以绘制一条最佳拟合线或趋势线，如下所示：
- en: '| **Sq. ft.** | **Price ($)** |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| **平方英尺** | **价格 ($)** |'
- en: '| 862 | 170,982 |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 862 | 170,982 |'
- en: '| 1235 | 227,932 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 1235 | 227,932 |'
- en: '| 932 | 183,280 |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 932 | 183,280 |'
- en: '| 1624 | 237,945 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 1624 | 237,945 |'
- en: '| 1757 | 275,921 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 1757 | 275,921 |'
- en: '| **1630** | 274,713 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| **1630** | 274,713 |'
- en: '| **1236** | 201,428 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| **1236** | 201,428 |'
- en: '| **1002** | 193,128 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| **1002** | 193,128 |'
- en: '| **1118** | 187,073 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| **1118** | 187,073 |'
- en: '| **1339** | 202,422 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| **1339** | 202,422 |'
- en: '| **1753** | 283,989 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| **1753** | 283,989 |'
- en: '| **1239** | 228,170 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| **1239** | 228,170 |'
- en: '| **1364** | 230,662 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **1364** | 230,662 |'
- en: '| **995** | 169,369 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| **995** | 169,369 |'
- en: '| **1000** | 157,305 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| **1000** | 157,305 |'
- en: 'If we were to draw a *line of best* *fit* using a linear trend line, the chart
    would look somewhat like this:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用线性趋势线绘制*最佳拟合线*，图表可能会像这样：
- en: '![](img/c352bb42-90f4-43a0-ab7a-05d53e2916ae.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c352bb42-90f4-43a0-ab7a-05d53e2916ae.png)'
- en: Excel provides an useful additional feature that allows users to draw an extension
    of the trend line which can provide an estimate, or a *prediction*, of unknown
    variables. In this case, extending the trendline will show us, based on the function,
    what the prices for houses in the 1,800-2,000 sq. ft. range are likely to be.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Excel提供了一个有用的附加功能，允许用户绘制趋势线的扩展，这可以提供一个估算值，或者一个*预测*，来预测未知变量。在这种情况下，延长趋势线将基于该函数向我们展示1,800-2,000平方英尺范围内房屋的价格。
- en: 'The linear function that describes the data is as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 描述数据的线性函数如下：
- en: '*y=126.13x + 54,466.81*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*y=126.13x + 54,466.81*'
- en: 'The following chart with an extended trend line shows that the price is most
    likely between `$275,000` and `$300,000`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的图表显示了一个扩展的趋势线，表明价格最有可能在`$275,000`到`$300,000`之间：
- en: '![](img/70b446ec-c433-4589-8aea-731806451a1c.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70b446ec-c433-4589-8aea-731806451a1c.png)'
- en: However, one may argue that the line is not the best approximation and that
    it may be possible to increase the value of R2, which in this case is 0.87\. In
    general, the higher the R^2, the better the model that describes the data. There
    are various different types of *R²* values, but for the purpose of this section,
    we'll assume that the higher the *R²*, the better the model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有人可能会认为这条线并不是最佳的近似，并且可能通过增加R²值（在本例中为0.87）来获得更好的结果。一般来说，R²越高，描述数据的模型越好。R²值有多种不同的类型，但在本节中，我们假设R²越高，模型越好。
- en: In the next section, we will draw a new trend line that has a much higher R^2,
    but using a polynomial function. This function has a higher R^2 (0.91 vs 0.87)
    and visually appears to be closer to the points on average.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分中，我们将绘制一个具有更高R²的新的趋势线，但使用多项式函数。这个函数的R²更高（0.91与0.87），并且在视觉上看起来平均更接近这些点。
- en: 'The function in this case is a 6^(th)-order polynomial:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，该函数是一个6^(次)阶多项式：
- en: '*y = -0.00x⁶ + 0.00x⁵ - 0.00x⁴ + 2.50x³ - 2,313.40x² + 1,125,401.77x - 224,923,813.17*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*y = -0.00x⁶ + 0.00x⁵ - 0.00x⁴ + 2.50x³ - 2,313.40x² + 1,125,401.77x - 224,923,813.17*'
- en: '![](img/98b77763-7482-4c42-9e49-62c7c75e2021.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/98b77763-7482-4c42-9e49-62c7c75e2021.png)'
- en: But, even though the line has a higher R^2, if we extend the trend line, intending
    to find what the prices of houses in the 1,800-2,000 sq. ft. range are likely
    to be, we get the following result.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，尽管该线的R²较高，如果我们延长趋势线，目的是找到1,800-2,000平方英尺范围内房屋的价格，我们会得到以下结果。
- en: Houses in the 1,800-2,000 sq. ft. range go from approx. $280,000 to negative
    $2 million at the 2,000^(th) sq. ft. In other words, people purchasing houses
    with 1800 sq. ft. are expected to spend $ 280,000 and those purchasing houses
    with 2,000 sq. ft. should, according to this function, with a 'higher R^2', receive
    $2 million! This, of course, is not accurate, but what we have just witnessed
    is what is known as **over-fitting**. The image below illustrates this phenomenon.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 1,800-2,000平方英尺范围内的房屋价格大约从$280,000到负$200万（在2,000平方英尺时）。换句话说，购买1,800平方英尺房屋的人预计将花费$280,000，而根据这个函数，购买2,000平方英尺房屋的人在具有'更高R²'的情况下，可能会得到$200万！这当然并不准确，但我们刚刚看到的现象被称为**过拟合**。下图展示了这一现象。
- en: '![](img/8f39c591-a89e-499e-921c-900f60f31753.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f39c591-a89e-499e-921c-900f60f31753.png)'
- en: 'At the other end of the spectrum is **under-fitting**. This happens when the
    model built does not describe the data. In the following chart, the function y
    = 0.25x - 200 is one such example:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另一端是**欠拟合**。当构建的模型无法描述数据时，就会发生这种情况。在下面的图表中，函数y = 0.25x - 200就是一个这样的例子：
- en: '![](img/60b80a9d-cace-4bbb-ac95-ed3eac84763b.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/60b80a9d-cace-4bbb-ac95-ed3eac84763b.png)'
- en: 'In brief, this section can be abbreviated as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本节可以简要概括如下：
- en: A function that fits the data too well, such that the function can approximate
    nearly all of the points in the training dataset is considered overfitting.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个拟合得太好的函数，能够近似训练数据集中的几乎所有点，被认为是过拟合。
- en: A function that does not fit the data at all, or in other words is far from
    the actual points in the training dataset, is considered underfitting.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个完全无法拟合数据的函数，换句话说，远离训练数据集中的实际点的函数，被认为是欠拟合。
- en: Machine learning is the process of balancing between overfitting and underfitting
    the data. This is arguably not an easy exercise, which is why even though building
    a model may be trivial, building a model that is reasonably good is a much more
    difficult challenge.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习是一个在数据的过拟合和欠拟合之间平衡的过程。这无疑是一项不容易的任务，这也是为什么即使构建一个模型可能很简单，构建一个合理的、效果较好的模型则是更具挑战性的原因。
- en: Underfitting is when your function is *not thinking at all* - it has a high
    bias.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欠拟合是指你的函数*根本没有思考*——它有很高的偏差。
- en: Overfitting is when your function is *thinking too hard* - it has a high variance.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过拟合是指你的函数*思考得太过*——它有很高的方差。
- en: Another example for underfitting and overfitting is given in coming example.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欠拟合和过拟合的另一个例子将在接下来的例子中给出。
- en: 'Say we are tasked with determining if a bunch of fruit are oranges or apples,
    and have been given their location in a fruit basket (left-side or right-side),
    size and weight:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的任务是判断一堆水果是橙子还是苹果，并且已经给出了它们在果篮中的位置（左侧或右侧）、大小和重量：
- en: '| ![](img/be16688e-a356-4b63-923b-d9e25b01abb1.png) | ![](img/f6035a45-cd01-4de4-be71-f428126da2b1.png)
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| ![](img/be16688e-a356-4b63-923b-d9e25b01abb1.png) | ![](img/f6035a45-cd01-4de4-be71-f428126da2b1.png)
    |'
- en: '| **Basket 1 (Training Dataset)** | **Basket 2 (Test Dataset)** |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| **篮子 1（训练数据集）** | **篮子 2（测试数据集）** |'
- en: An example of overfitting could be that, based on the training dataset, with
    regard to Basket 1 we could conclude that the only fruits located on the right
    hand side of the basket are oranges and those on the left are all apples.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合的一个例子可能是，基于训练数据集，在篮子 1 中我们可能会得出结论，认为篮子右侧的唯一水果是橙子，左侧的所有水果都是苹果。
- en: An example of underfitting could be that I conclude that the basket has only
    oranges.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一个欠拟合的例子可能是我得出结论认为篮子里只有橙子。
- en: '**Model 1**: In the first case - for overfitting - I have, in essence, memorized
    the locations.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型 1**：在第一种情况下——对于过拟合——我实际上已经记住了位置。'
- en: '**Model 2**: In the second case - for underfitting - I could not remember anything
    precisely at all.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型 2**：在第二种情况下——对于欠拟合——我根本没有准确记住任何东西。'
- en: Now, given a second basket - the test dataset where the positions of the apples
    and oranges are switched - if I were to use Model 1, I would incorrectly conclude
    that all the fruits on the right hand side are oranges and those on the left hand
    side are apples (since I memorized the training data).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，给定第二个篮子——测试数据集，其中苹果和橙子的位置信息已经交换——如果我使用模型 1，我会错误地得出结论，认为右侧的所有水果都是橙子，左侧的所有水果都是苹果（因为我记住了训练数据）。
- en: If I were to use Model 2, I would, again, incorrectly conclude that all the
    fruits are oranges.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我使用模型 2，我会再次错误地得出结论，认为所有水果都是橙子。
- en: There are, however, ways to manage the balance between underfitting and overfitting
    - or in other words, between high bias and high variance.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，确实有一些方法可以管理欠拟合和过拟合之间的平衡——或者换句话说，管理高偏差和高方差之间的平衡。
- en: One of the methods commonly used for bias-variance trade-off is known as regularization.
    This refers to the process of penalizing the model (for example, the model's coefficients
    in a regression) in order to produce an output that generalizes well across a
    range of data points.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的一种偏差-方差权衡方法是正则化。这是指惩罚模型（例如回归中的模型系数）的过程，以产生一个在多个数据点上都能很好地泛化的输出。
- en: 'The table on the next page illustrates some of the key concepts of bias and
    variance and illustrates options for remedial steps when a model has high bias
    or high variance:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 下一页的表格展示了偏差和方差的一些关键概念，并展示了在模型具有高偏差或高方差时的修正步骤：
- en: '![](img/7fd11d61-930f-4e67-a737-7ba72e754400.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7fd11d61-930f-4e67-a737-7ba72e754400.png)'
- en: In terms of the modeling process, a high bias is generally indicated by the
    fact that both the training set error as well as the test set error remain consistently
    high. For high variance (overfitting), the training set error decreases rapidly,
    but the test set error remains unchanged.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在建模过程中，高偏差通常表现为训练集误差和测试集误差始终保持较高的水平。对于高方差（过拟合），训练集误差迅速下降，但测试集误差保持不变。
- en: The gradient descent and VC Dimension theories
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度下降和 VC 维度理论
- en: Gradient descent and VC Dimension are two fundamental theories in machine learning.
    In general, **gradient descent** gives a structured approach to finding the optimal
    co-efficients of a function. The hypothesis space of a function can be large and
    with gradient descent, the algorithm tries to find a minimum (*a minima*) where
    the cost function (for example, the squared sum of errors) is the lowest.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降和 VC 维度是机器学习中的两个基本理论。通常，**梯度下降**为寻找函数的最优系数提供了一种结构化的方法。一个函数的假设空间可能非常大，而使用梯度下降时，算法会试图找到一个最小值（*极小值*），使得代价函数（例如，误差的平方和）最小。
- en: '**VC Dimension** provides an upper bound on the maximum number of points that
    can be classified in a system. It is in essence the measure of the richness of
    a function and provides an assessment of what the limits of a hypothesis are in
    a structured way. The number of points that can be exactly classified by a function
    or hypothesis is known as the VC Dimension of the hypothesis. For example, a linear
    boundary can accurately classify 2 or 3 points but not 4\. Hence, the VC Dimension
    of this 2-dimensional space would be 3.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**VC 维度**提供了系统中可以分类的最大点数的上限。它本质上是衡量函数丰富性的指标，并提供了一种结构化的方式来评估假设的极限。可以被函数或假设精确分类的点数称为该假设的
    VC 维度。例如，一个线性边界可以准确分类 2 或 3 个点，但不能分类 4 个点。因此，这个二维空间的 VC 维度是 3。'
- en: VC Dimension, like many other topics in computational learning theory, is both
    complex and interesting. It is a lesser known (and discussed) topic, but one that
    has a profound implication as it attempts to answer questions about what the limits
    of learning can be.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: VC 维度，像许多计算学习理论中的其他主题一样，既复杂又有趣。它是一个较少为人知（也讨论较少）的主题，但它有着深远的影响，因为它试图解答关于学习极限的问题。
- en: Popular machine learning algorithms
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流行的机器学习算法
- en: There are various different classes of machine learning algorithms. As such,
    since algorithms can belong to multiple 'classes' or categories at the same time
    at a conceptual level, it is hard to specifically state that an algorithm belongs
    exclusively to a single class. In this section, we will briefly discuss a few
    of the most commonly used and well-known algorithms.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法有各种不同的类别。因此，由于算法可以同时属于多个“类别”或“类”，在概念层面上很难明确指出一个算法仅属于单一类别。在本节中，我们将简要讨论一些最常用和最知名的算法。
- en: 'These include:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包括：
- en: Regression models
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归模型
- en: Association rules
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则
- en: Decision trees
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: Random forest
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Boosting algorithms
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升算法
- en: Support vector machines
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: K-means
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-means
- en: Neural networks
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络
- en: Note that in the examples, we have shown the basic use of the R functions using
    the entire dataset. In practice, we'd split the data into a training and test
    set, and once we have built a satisfactory model apply the same on the test dataset
    to evaluate the model's performance.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这些示例中，我们展示了使用整个数据集的 R 函数的基本用法。实际上，我们会将数据分为训练集和测试集，一旦构建了满意的模型，就会将相同的模型应用于测试数据集，以评估模型的表现。
- en: Regression models
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归模型
- en: Regression models range from commonly used linear, logistic, and multiple regression
    algorithms used in statistics to Ridge and Lasso regression, which penalizes co-efficients
    to improve model performance.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型从常用的线性回归、逻辑回归和多重回归算法到岭回归和套索回归等模型不等，这些回归模型通过对系数的惩罚来提高模型性能。
- en: In our earlier examples, we saw the application of **linear regression** when
    we created trend-lines. **Multiple linear regression** refers to the fact that
    the process of creating the model requires multiple independent variables.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的示例中，当我们创建趋势线时，我们看到了**线性回归**的应用。**多重线性回归**指的是创建模型的过程需要多个自变量。
- en: 'For instance:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '**Total Advertising Cost = x* Print Ads**, would be a simple linear regression;
    whereas'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**总广告费用 = x * 印刷广告**，这将是一个简单的线性回归；而'
- en: '**Total Advertising Cost = X + Print Ads + Radio Ads + TV Ads**, due to the
    presence of more than one independent variable (Print, Radio, and TV), would be
    a multiple linear regression.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**总广告费用 = X + 平面广告 + 广播广告 + 电视广告**，由于有多个独立变量（平面广告、广播广告和电视广告），因此这是一个多元线性回归。'
- en: '**Logistic regression** is another commonly used statistical regression modelling
    technique that predicts the outcome of a discrete categorical value, mainly for
    cases where the outcome variable is dichotomous (for example, 0 or 1, Yes or No,
    and so on). There can, however, be more than 2 discrete outcomes (for example,
    State NY, NJ, CT) and this type of logistic regression is known as **multinomial
    logistic regression**.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑回归**是另一种常用的统计回归建模技术，用于预测离散类别值的结果，主要用于结果变量为二元的情况（例如，0或1，Yes或No，等等）。然而，也可以有超过两个离散结果（例如，纽约州、纽约州、新泽西州），这种类型的逻辑回归称为**多项式逻辑回归**。'
- en: '**Ridge and Lasso Regressions** include a regularization term (λ) in addition
    to the other aspects of Linear Regression. The regularization term, Ridge Regression,
    has the effect of reducing the β coefficients (thus ''penalizing'' the co-efficients).
    In Lasso, the regularization term tends to reduce some of the co-efficients to
    0, thus eliminating the effect of the variable on the final model:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**岭回归和套索回归**在普通线性回归的基础上增加了正则化项（λ）。正则化项（岭回归）的效果是减少 β 系数（从而“惩罚”这些系数）。在套索回归中，正则化项通常将一些系数缩减为
    0，从而消除了该变量对最终模型的影响：'
- en: '![](img/c0734ce4-09ff-4e4f-9ae6-150d20324b53.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c0734ce4-09ff-4e4f-9ae6-150d20324b53.png)'
- en: '[PRE0]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Association rules
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关联规则
- en: Association rules mining, or **apriori**, attempts to find relationships between
    variables in a dataset. Association rules are frequently used for various practical
    real-world use cases. Given a set of variables, apriori can indicate the patterns
    inherent in a transactional dataset. One of our tutorials will be based on implementing
    an R Shiny Application for apriori and hence, more emphasis is being provided
    for the same in this section.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则挖掘，或称**apriori**，试图寻找数据集中变量之间的关系。关联规则通常用于各种实际的现实世界应用中。给定一组变量，apriori 可以指示出事务性数据集中的模式。我们的一些教程将基于实现一个R
    Shiny应用程序来进行apriori，因此，本节中将更多强调这一部分内容。
- en: For instance, let's say a supermarket chain is deciding the order for placing
    items on the shelves. An apriori algorithm run against a database containing sales
    transactions would identify the items that, say, are most often bought together.
    This permits the supermarket to determine which items, when placed strategically
    in close proximity to one another, can yield the most sales. This is also often
    referred to as *market basket analysis*.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设一个超市连锁正在决定物品在货架上的排列顺序。对包含销售交易的数据库运行 apriori 算法将识别出最常一起购买的物品。例如，这可以帮助超市确定哪些物品在彼此靠近的地方摆放，能够产生最大的销售额。这也通常被称为*市场篮子分析*。
- en: 'A simple example that reflects this could be as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的例子可以是这样的：
- en: '[PRE1]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In all these cases, the act of purchasing something on the left-hand side led
    to the purchase of the item mentioned on the right-hand side of the expression.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些情况下，左侧的购买行为会导致右侧表达式中提到的物品被购买。
- en: It is also possible to derive association rules from databases that do not necessarily
    contain *transactions*, but instead use a sliding window to go through events
    along a temporal attribute, such as with the WINEPI algorithm.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以从不一定包含*交易*的数据库中推导关联规则，而是使用滑动窗口通过时间属性沿事件进行遍历，比如使用WINEPI算法。
- en: 'There are 3 primary measures in apriori. To illustrate them, let us use a sample
    dataset containing items purchased in 4 separate transactions:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: apriori 中有 3 个主要的度量指标。为了说明它们，让我们使用一个包含 4 个独立交易中的物品的示例数据集：
- en: '| **Transaction** | **Item 1** | **Item 2** | **Item 3** |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| **交易** | **物品 1** | **物品 2** | **物品 3** |'
- en: '| 1 | Milk | Bread | Butter |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 牛奶 | 面包 | 黄油 |'
- en: '| 2 | Milk | Egg | Butter |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 牛奶 | 鸡蛋 | 黄油 |'
- en: '| 3 | Bread | Egg | Cheese |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 面包 | 鸡蛋 | 奶酪 |'
- en: '| 4 | Butter | Bread | Egg |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 黄油 | 面包 | 鸡蛋 |'
- en: Confidence
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信度
- en: 'Confidence refers to how often the right-hand side of the apriori expression
    is valid when the left-hand side is valid. For instance, given an expression:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 信度指的是当左侧有效时，右侧的 apriori 表达式在多大程度上有效。例如，给定一个表达式：
- en: '[PRE2]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We would like to know how often Bread was purchased *when Milk was also purchased*.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想知道在*购买牛奶时*，面包被购买的频率是多少。
- en: 'In this case:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下：
- en: '**Transaction 1**: Milk and Bread are both present'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易 1**：牛奶和面包都存在'
- en: '**Transaction 2**: Milk is present, but not Bread'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易 2**：牛奶存在，但面包不存在'
- en: '**Transactions 3 and 4**: Milk is not present'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易 3 和 4**：牛奶不存在'
- en: Hence, based on the what we saw, there were 2 transactions where Milk was present
    and of them, Bread was present in 1 transaction. Hence, the confidence for the
    rule {Milk} à {Bread} would be ½ = 50%
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，基于我们看到的情况，有 2 个交易中牛奶是存在的，其中 1 个交易中有面包。因此，规则 {牛奶} à {面包} 的置信度为 ½ = 50%
- en: 'Taking another expression:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 取另一个表达式：
- en: '[PRE3]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We would like to know, when Bread was purchased, how often was Butter also
    purchased?:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想知道，当面包被购买时，黄油有多频繁地被一起购买？
- en: '**Transaction 1**: Bread and Butter are both present'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易 1**：面包和黄油都存在'
- en: '**Transaction 2**: There is no Bread (Butter is present, but our point of reference
    is Bread and hence this does not count)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易 2**：没有面包（黄油存在，但我们的参考点是面包，因此这不算）'
- en: '**Transaction 3**: Bread is present but no Butter'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易 3**：面包存在，但没有黄油'
- en: '**Transaction 4**: Bread and Butter are both present'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易 4**：面包和黄油都存在'
- en: Hence, we have Bread in 3 of the transactions, and Bread & Butter in 2 of the
    3 transactions. Hence, in this case, the 'confidence' of the rule `{Bread} à {Butter}`
    is *2/3 = 66.7*.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们在 3 个交易中都有面包，在 3 个交易中的 2 个交易中都有面包和黄油。因此，在这种情况下，规则 `{面包} à {黄油}` 的“置信度”是
    *2/3 = 66.7*。
- en: Support
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持度
- en: Support refers to the number of times the rule is satisfied relative to the
    total number of transactions in the dataset.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度是指规则满足的次数相对于数据集中交易总数的比例。
- en: 'For instance:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '{Milk} --> {Bread}, occurs in 1 out of 4 Transactions (in Transaction 1). Hence,
    the support for this rule is ¼ = 0.25 (or 25%).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '{牛奶} --> {面包}，出现在 4 个交易中的 1 个交易中（在交易 1 中）。因此，该规则的支持度为 ¼ = 0.25（或 25%）。'
- en: '{Bread} --> {Butter}, occurs in 2 out of 4 Transactions (in Transaction 1 and
    4). Hence, the support for this rule is ½ = 0.50 (or 50%).'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包} --> {黄油}，出现在 4 个交易中的 2 个交易中（在交易 1 和 4 中）。因此，该规则的支持度为 ½ = 0.50（或 50%）。'
- en: Lift
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升度
- en: 'Lift is arguably the most important of the 3 measures; it measures the support
    of the rule relative to the support of the individual sides of the expression;
    put differently, it measures how strong the rule is with respect to a random occurrence
    of the LHS and RHS of the expression. It is formally defined as:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 提升度可以说是 3 个指标中最重要的一个；它衡量规则的支持度相对于表达式各个部分支持度的比率；换句话说，它衡量了该规则在随机出现的左侧（LHS）和右侧（RHS）条件下的强度。它的正式定义为：
- en: '*Lift = Support (Rule)/(Support(LHS) * Support (RHS))*'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '*提升度 = 支持度（规则）/（支持度（左侧） * 支持度（右侧））*'
- en: A low value for lift (say, less than or equal to 1) indicates that the LHS and
    RHS occurrence are independent of one another, whereas a higher lift measure indicates
    that the co-occurrence is significant.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 提升度值较低（例如小于或等于 1）表示左侧和右侧的发生是独立的，而较高的提升度则表示联合发生是显著的。
- en: In our prior example,
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的例子中，
- en: '{Bread} --> {Butter} has a lift of:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包} --> {黄油} 的提升度为：'
- en: Support ({Bread} --> {Butter})
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度（{面包} --> {黄油}）
- en: Support {Bread} * Support {Butter}
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 支持 {面包} * 支持 {黄油}
- en: = 0.50/((3/4) * (3/4)) = 0.50/(0.75 * 0.75) = 0.89.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: = 0.50/((3/4) * (3/4)) = 0.50/(0.75 * 0.75) = 0.89。
- en: This indicates that although the Confidence of the rule was high, the rule in
    and of itself is not significant relative to other rules that may be higher than
    1.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，尽管规则的置信度较高，但该规则本身相较于可能高于 1 的其他规则并不显著。
- en: 'An example of a rule with a Lift higher than 1 would be:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 提升度高于 1 的规则示例是：
- en: '{Item 1: Bread} --> {Item 3: Cheese}'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '{项目 1：面包} --> {项目 3：奶酪}'
- en: 'This has a Lift of:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提升度为：
- en: 'Support {Item 1: Bread --> Item 3: Cheese}/(Support {Item 1: Cheese} * Support
    {Item 3: Cheese})'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 支持 {项目 1：面包 --> 项目 3：奶酪}/(支持 {项目 1：奶酪} * 支持 {项目 3：奶酪})
- en: = (1/4)/((1/4)*(1/4) = 4.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: = (1/4)/((1/4)*(1/4)) = 4。
- en: Decision trees
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树
- en: Decision Trees are a predictive modeling technique that generates rules that
    derive the likelihood of a certain outcome based on the likelihood of the preceding
    outcomes. In general, decision trees are typically constructed similar to a **flowchart**,
    with a series of nodes and leaves that denote a parent-child relationship. Nodes
    that do not link to other nodes are known as leaves.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是一种预测建模技术，它生成规则，通过前期结果的可能性推导出某个结果的可能性。一般来说，决策树的构建类似于 **流程图**，由一系列节点和叶子组成，表示父子关系。没有连接到其他节点的节点被称为叶子节点。
- en: Decision Trees belong to a class of algorithms that are often known as **CART**
    (**Classification and Regression Trees**). If the outcome of interest is a categorical
    variable, it falls under a classification exercise, whereas if the outcome is
    a number, it is known as a regression tree.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树属于一种算法类别，通常被称为**CART**（**分类与回归树**）。如果感兴趣的结果是一个分类变量，则属于分类任务；如果结果是一个数值，则称为回归树。
- en: 'An example will help to make this concept clearer. Take a look at the chart:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子有助于更清楚地理解这一概念。请看图表：
- en: '![](img/7ac42b3c-4ec1-4a83-8c52-0e51853d030b.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7ac42b3c-4ec1-4a83-8c52-0e51853d030b.png)'
- en: 'The chart shows a hypothetical scenario: if school is closed/not closed. The
    rectangular boxes (in blue) represent the nodes. The first rectangle (School Closed)
    represent the *root* node, whereas the inner rectangles represent the *internal*
    nodes. The rectangular boxes with angled edges (in green and italic letters) represent
    the ''*leaves*'' (or *terminal* nodes).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表展示了一个假设场景：如果学校关闭/未关闭。矩形框（蓝色）代表节点。第一个矩形框（学校关闭）代表*根*节点，而内部矩形框代表*内部*节点。具有倾斜边缘的矩形框（绿色和斜体字母）代表‘*叶子*’（或*终端*节点）。
- en: Decision Trees are simple to understand and one of the few algorithms that are
    not a 'black box'. Algorithms such as those used to create Neural Networks are
    often considered black boxes, as it is very hard - if not impossible - to intuitively
    determine the exact path by which a final outcome was reached due to the complexity
    of the model.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树易于理解，是为数不多的非“黑箱”算法之一。像神经网络这样的算法通常被认为是黑箱，因为很难——如果不是不可能——凭直觉确定最终结果是通过何种路径得出的，因为模型的复杂性使得这一过程难以推断。
- en: In R, there are various facilities for creating Decision Trees. A commonly used
    library for creating them in R is `rpart`. We'll revisit our `PimaIndiansDiabetes`
    dataset to see how a decision tree can be created using the package.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，有多种方法可以创建决策树。一个常用的库是`rpart`，它可以用来在R中创建决策树。我们将再次查看`PimaIndiansDiabetes`数据集，看看如何使用该包创建决策树。
- en: We would like to create a model to determine how glucose, insulin, (body) mass,
    and age are related to diabetes. Note that in the dataset, diabetes is a categorical
    variable with a yes/no response.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要创建一个模型，以确定血糖、胰岛素、（体重）质量和年龄与糖尿病之间的关系。请注意，在数据集中，糖尿病是一个分类变量，响应为是/否。
- en: 'For visualizing the decision tree, we will use the `rpart.plot` package. The
    code for the same is given as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化决策树，我们将使用`rpart.plot`包。相关代码如下：
- en: '[PRE4]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](img/27b2b5d4-4128-4690-8f2c-328712a01cfe.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27b2b5d4-4128-4690-8f2c-328712a01cfe.png)'
- en: Reading from the top, the graph shows that that there are 500 cases of `diabetes=neg`
    in the dataset (out of a total of 768 records).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 从顶部开始，图表显示数据集中有500个`diabetes=neg`的案例（总共有768条记录）。
- en: '[PRE5]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Of the total number of records in the dataset (768) with value of glucose <
    128, there were 485 records marked as negative. Of these, the model correctly
    predicted 391 cases as negative (Node Number 2, the first one on the left from
    the bottom).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集中（共768条记录）血糖值小于128的记录中，共有485条记录被标记为阴性。在这些记录中，模型正确预测了391个案例为阴性（节点编号2，从底部往左数的第一个节点）。
- en: For the records which had a glucose reading of > 128, there were 283 records
    marked as positive (Node Number 3, the node immediately below the topmost/root
    node). The model correctly classified 174 of these cases.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 对于血糖值大于128的记录，共有283条记录被标记为阳性（节点编号3，紧接着根节点的节点）。该模型正确分类了174个案例。
- en: 'Another, more recent package for intuitive decision trees with comprehensive
    visual information is **FFTrees** (**Fast and Frugal Decision Trees**). The following
    example has been provided for informational purposes:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个更现代的直观决策树包是**FFTrees**（**快速简洁的决策树**）。以下示例仅供参考：
- en: '[PRE6]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](img/c984b3e7-7aa5-4ff3-a53e-d2b4d2eb1943.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c984b3e7-7aa5-4ff3-a53e-d2b4d2eb1943.png)'
- en: Decision Trees work by splitting the data recursively until a stopping criterion,
    such as when a certain depth has been reached, or the number of cases, is below
    a specified value. Each split is done based on the variable that will lead to
    a 'purer subset'.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树通过递归地拆分数据，直到达到停止标准，如达到某个深度或案例数低于指定值。每次拆分都基于能产生“更纯子集”的变量。
- en: In principle, we can grow an endless number of trees from a given set of variables,
    which makes it a particularly hard and intractable problem. Numerous algorithms
    exist which provide an efficient method for splitting and creating decision trees.
    One such method is Hunt's Algorithm.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，我们可以从给定的一组变量中生长无限数量的树，这使得这个问题变得特别复杂且难以处理。存在许多算法提供高效的决策树拆分和创建方法，其中之一是亨特算法（Hunt's
    Algorithm）。
- en: 'Further details about the algorithm can be found at: [https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf](https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf).'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 有关该算法的更多详细信息可以在此处找到：[https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf](https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf)。
- en: The Random forest extension
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林扩展
- en: Random forest is an extension of the decision tree model that we just discussed.
    In practice, Decision Trees are simple to understand, simple to interpret, fast
    to create using available algorithms, and overall, intuitive. However, Decision
    Trees are sensitive to small changes in the data, permit splits only along an
    axis (linear splits) and can lead to overfitting. To mitigate some of the drawbacks
    of decision trees, whilst still getting the benefit of their elegance, algorithms
    such as Random Forest create multiple decision trees and sample random features
    to leverage and build an aggregate model.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是我们刚才讨论的决策树模型的扩展。实际上，决策树简单易懂，易于解释，使用现有算法快速创建，且总体上直观。然而，决策树对数据中的微小变化敏感，只允许沿着一个轴（线性划分）进行分裂，并可能导致过拟合。为了减轻决策树的一些缺点，同时仍然能享受到其简洁性的好处，诸如随机森林之类的算法通过创建多个决策树并随机选择特征来利用并构建一个聚合模型。
- en: Random forest works on the principle of **bootstrap aggregating** or **bagging**.
    Bootstrap is a statistical term indicating random sampling with replacement. Bootstrapping
    a given set of records means taking a random number of records and possibly including
    the same record multiple times in a sample. Thereafter, the user would measure
    their metric of interest on the sample and then repeat the process. In this manner,
    the distribution of the values of the metric calculated from random samples multiple
    times is expected to represent the distribution of the population, and so the
    entire dataset.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林的原理是**自助聚合**（bootstrap aggregating）或**袋装法**（bagging）。自助法是一个统计学术语，表示带有替换的随机抽样。自助抽样一组记录意味着从中随机抽取记录，并可能多次包含相同的记录。随后，用户会在样本上衡量他们感兴趣的指标，并重复这个过程。通过这种方式，从多次随机抽样计算得到的指标值的分布预计能够代表总体的分布，从而代表整个数据集。
- en: 'An example of Bagging a set of 3 numbers, such as (1,2,3,4), would be:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 对一组3个数字（如1,2,3,4）进行袋装法的示例是：
- en: (1,2,3), (1,1,3), (1,3,3), (2,2,1), and others.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: (1,2,3)，(1,1,3)，(1,3,3)，(2,2,1)，以及其他组合。
- en: Bootstrap Aggregating, or *bagging*, implies leveraging a voting method using
    *multiple bootstrap samples* at a time, building a model on each individual sample
    (set of n records) and then finally aggregating the results.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 自助聚合（Bootstrap Aggregating），或称为*袋装法*，意味着利用投票方法，同时使用*多个自助样本*，在每个单独的样本（n条记录）上建立一个模型，然后最终聚合结果。
- en: Random forests also implement another level of operation beyond simple bagging.
    It also randomly selects the variables to be included in the model building process
    at each split. For instance, if we were to create a random forest model using
    the `PimaIndiansDiabetes` dataset with the variables pregnant, glucose, pressure,
    triceps, insulin, mass, pedigree, age, and diabetes, in each bootstrap sample
    (draw of n records), we would select a random subset of features with which to
    build the model--for instance, glucose, pressure, and insulin; insulin, age, and
    pedigree; triceps, mass, and insulin; and others.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林还实现了超越简单袋装法的另一个操作层次。它还会在每次分裂时随机选择要包含在模型构建过程中的变量。例如，如果我们使用`PimaIndiansDiabetes`数据集，并包括怀孕、葡萄糖、血压、三头肌、胰岛素、体重、家族史、年龄和糖尿病变量，在每次自助抽样（抽取n条记录）中，我们会选择一个随机的特征子集来构建模型——例如，葡萄糖、血压和胰岛素；胰岛素、年龄和家族史；三头肌、体重和胰岛素；等等。
- en: 'In R, the package commonly used for RandomForest is called by its namesake,
    RandomForest. We can use it via the package as is or via caret. Both methods are
    shown as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，常用的随机森林包名为RandomForest。我们可以通过该包直接使用它，或者通过caret包来使用。两种方法如下所示：
- en: 'Using Random Forest using the RandomForest package:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用RandomForest包来进行随机森林建模：
- en: '[PRE7]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Using Random Forest via caret using the `method="rf"` function:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用caret包通过`method="rf"`函数来使用随机森林：
- en: '[PRE8]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'It is also possible to see the splits and other related information in each
    tree of the original Random Forest model (which did not use caret). This can be
    done using the `getTree` function as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以查看原始随机森林模型（未使用caret）中每棵树的分割情况及其他相关信息。这可以通过如下方式使用`getTree`函数来完成：
- en: '[PRE9]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Boosting algorithms
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Boosting算法
- en: Boosting is a technique that uses weights and a set of *weak learners*, such
    as decision trees, in order to improve model performance. Boosting assigns weights
    to data based on model misclassification and future learner's (created during
    the boosting machine learning process) focus on the misclassified examples. Examples
    that were correctly classified will be reassigned new weights which will generally
    be lower than those that were not correctly classified. The weight can be based
    on a cost function, such as a majority vote, using subsets of the data.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Boosting是一种使用权重和一组*弱学习器*（如决策树）来提高模型性能的技术。Boosting根据模型的错误分类为数据分配权重，随后学习器（在Boosting机器学习过程中创建的）将重点关注错误分类的例子。正确分类的例子将被重新分配新的权重，通常低于那些未正确分类的例子。权重可以基于成本函数，例如使用数据子集的多数投票。
- en: In simple and non-technical terms, boosting uses *a series of weak learners,
    and each learner 'learns' from the mistakes of the prior learners*.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 用简单且非技术性的术语来说，Boosting使用*一系列弱学习器，每个学习器从前一个学习器的错误中“学习”*。
- en: Boosting is generally more popular compared to bagging as it assigns weights
    relative to model performance rather than assigning equal weights to all data
    points as in bagging. This is conceptually similar to the difference between a
    weighted average versus an average function with no weighting criteria.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 与Bagging相比，Boosting通常更受欢迎，因为它根据模型性能分配权重，而不是像Bagging那样对所有数据点分配相等的权重。这在概念上类似于加权平均与无权重平均之间的区别。
- en: 'There are several packages in R for boosting algorithms and some of the commonly
    used ones are as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中有多个用于Boosting算法的包，其中一些常用的如下：
- en: Adaboost
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adaboost
- en: '**GBM** (**Stochastic Gradient Boosting**)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GBM**（**随机梯度提升**）'
- en: XGBoost
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost
- en: Of these, XGBoost is a widely popular machine learning package that has been
    used very successfully in competitive machine learning platforms such as Kaggle.
    XGBoost has a very elegant and computationally efficient way to creating ensemble
    models. Because it is both accurate and extremely fast, users have often used
    XGBoost for compute-intensive ML challenges. You can learn more about Kaggle at
    [http://www.kaggle.com](http://www.kaggle.com).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，XGBoost是一个广泛流行的机器学习包，已经在Kaggle等竞争性机器学习平台中得到了非常成功的应用。XGBoost有一种非常优雅且计算高效的方式来创建集成模型。由于其高精度和极快的计算速度，用户常常在计算密集型的机器学习挑战中使用XGBoost。你可以在[http://www.kaggle.com](http://www.kaggle.com)了解更多关于Kaggle的信息。
- en: '[PRE10]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Support vector machines
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Support vector machines, commonly known as **SVMs**, are another class of machine
    learning algorithm that are used to classify data into one or another category
    using a concept called **hyperplane**, which is used to demarcate a linear boundary
    between points.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机，通常称为**SVMs**，是另一类机器学习算法，用于通过一个叫做**超平面**的概念将数据分类到不同类别中，超平面用于标定点之间的线性边界。
- en: 'For instance, given a set of black and white points on an x-y axis, we can
    find multiple lines that will separate them. The line, in this case, represents
    the function that delineates the category that each point belongs to. In the following
    image, lines H1 and H2 both separate the points accurately. In this case, how
    can we determine which one of H1 and H2 would be the optimal line?:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，给定一组黑白点在x-y轴上的分布，我们可以找到多条线来将它们分开。在这种情况下，线条代表了划定每个点所属类别的函数。在下图中，H1和H2两条线都能准确分开这些点。那么，如何判断H1和H2哪一条线是最佳的分割线呢？：
- en: '![](img/086d5f41-630d-4146-b5bc-34957e49f501.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/086d5f41-630d-4146-b5bc-34957e49f501.png)'
- en: Intuitively, we can say the line that is closest to the points - for instance,
    the vertical line H1 - might *not* be the optimal line to separate the points.
    Since the line is too close to the points, and so too specific to the points on
    the given dataset, a new point may be misclassified if it is even slightly off
    to the right or the left side of the line. In other words, the line is too sensitive
    to small changes in the data (which could be due to stochastic/deterministic noise,
    such as imperfections in the data).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，我们可以说与点最接近的直线——例如垂直线 H1——可能*不是*分隔这些点的最佳直线。由于这条线与点太接近，因此对于给定数据集中的点来说，过于具体。如果一个新点稍微偏离直线的左右侧，它可能会被误分类。换句话说，这条线对数据中的小变化过于敏感（这些小变化可能是由于随机/确定性噪声，比如数据中的不完美所引起的）。
- en: On the other hand, the line H2 manages to separate the data whilst maintaining
    the maximum possible distance from the points closest to the line. Slight imperfections
    in the data are unlikely to affect the classification of the points to the extent
    line H1 may have done. This, in essence, describes the principle of the maximum
    margin of separation as shown in the image below.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，直线 H2 成功地分隔了数据，并且保持了与最接近直线的点之间的最大可能距离。数据中的轻微不完美不太可能像直线 H1 那样影响点的分类。本质上，这描述了最大分隔边距的原则，如下图所示。
- en: '**![](img/6f17c69e-6d57-4497-a95a-c8b36d1cdb19.png)**'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/6f17c69e-6d57-4497-a95a-c8b36d1cdb19.png)**'
- en: The points close to the line, also known as the hyperplane, are known as the
    'support vectors' (hence the name). In the image, the points that lie on the dashed
    line are therefore the support vectors.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 与直线，也称为超平面，接近的点被称为“支持向量”（因此得名）。在图中，位于虚线上的点就是支持向量。
- en: 'In the real world, however, not all points may be ''linearly separable''. SVMs
    leverage a concept known as the ''kernel trick''. In essence, points that might
    not be linearly separable can be projected or mapped onto a higher dimensional
    surface. For example, given a set of points on a 2D x-y space that are not linearly
    separable, it may be possible to separate them if we were to project the points
    on a 3-dimensional space as shown in the following image. The points colored in
    red were not separable by a 2D line, but when mapped to a 3-dimensional surface,
    they can be separated by a hyperplane as shown in the following image:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在现实世界中，并非所有的点都是“线性可分”的。支持向量机（SVM）利用了一个叫做“核技巧”的概念。本质上，可能无法线性分隔的点可以通过投影或映射到更高维的表面。例如，给定一组在二维
    x-y 平面上的点，它们是不可线性分隔的，但如果我们将这些点投影到三维空间中，可能就能将它们分开。如下面的图片所示，那些用红色标出的点在二维线性分隔中无法分开，但当映射到三维表面时，它们可以通过超平面分开，如下图所示：
- en: '![](img/10a74760-3d89-464f-b9c2-685247b84ba6.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10a74760-3d89-464f-b9c2-685247b84ba6.png)'
- en: 'There are several packages in R that let users leverage SVM, such as `kernlab`,
    `e1071`, `klaR`, and others. Here, we illustrate the use of SVM from the `e1071`
    package, as shown as follow:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: R 中有几个包可以让用户使用支持向量机（SVM），例如 `kernlab`、`e1071`、`klaR` 等。这里，我们展示了如何使用 `e1071`
    包中的 SVM，代码如下：
- en: '[PRE11]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](img/469a697c-7c5c-457e-a232-e330b01b3e66.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](img/469a697c-7c5c-457e-a232-e330b01b3e66.png)'
- en: '[PRE12]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The K-Means machine learning technique
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-Means 机器学习技术
- en: K-Means is one of the most popular unsupervised machine learning techniques
    that is used to create clusters, and so categorizes data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: K-Means 是最流行的无监督机器学习技术之一，用于创建聚类，从而对数据进行分类。
- en: 'An intuitive example could be posed as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 一个直观的例子可以这样提出：
- en: Say a university was offering a new course on American History and Asian History.
    The university maintains a 15:1 student-teacher ratio, so there is 1 teacher per
    15 students. It has conducted a survey which contains a 10-point numeric score
    that was assigned by each student to their preference of studying American History
    or Asian History.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一所大学正在提供一门关于美国历史和亚洲历史的新课程。该大学保持 15:1 的师生比例，即每 15 个学生配 1 名教师。它进行了一项调查，调查内容是每位学生根据自己对学习美国历史或亚洲历史的偏好，给出了一个
    10 分制的数字评分。
- en: 'We can use the in-built K-Means algorithm in R to create 2 clusters and presumably,
    by the number of points in each cluster, it may be possible to get an estimate
    of the number of students who may sign up for each course. The code for the same
    is given as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 R 中内置的 K-Means 算法创建 2 个聚类，并且通过每个聚类中的点的数量，可以推测每门课程可能会有多少学生报名。相应的代码如下所示：
- en: '[PRE13]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following image could provide an intuitive estimate of the number of students
    who may sign up for each course (and thereby determine how many teachers may be
    required):'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像可能提供一个直观的估算，展示可能报名参加每门课程的学生数量（从而确定可能需要多少教师）：
- en: '![](img/33e06eed-9895-473c-a410-34899e68a800.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/33e06eed-9895-473c-a410-34899e68a800.png)'
- en: 'There are several variations of the K-Means algorithm, but the standard and
    the most commonly used one is Lloyd''s Algorithm. The algorithm steps are as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: K-Means算法有几种变体，但标准且最常用的是Lloyd算法。算法步骤如下：
- en: 'Given a set of n points (say in an x-y axis), in order to find k clusters:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组n个点（假设在x-y坐标轴上），为了找到k个聚类：
- en: Select k points at random from the dataset to represent the mid-points for k
    clusters (say, the *initial centroids*).
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据集中随机选择k个点作为k个聚类的中点（即*初始质心*）。
- en: The distance from each of the other points to the selected k points (representing
    k clusters) is measured and assigned to the cluster that has the lowest distance
    from the point.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个其他点与选定的k个点（代表k个聚类）之间的距离，并将其分配给距离该点最近的聚类。
- en: The cluster centers are recalculated as the mean of the points in the cluster.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚类中心被重新计算为聚类中所有点的均值。
- en: The distance between the centroids and all the other points are again calculated
    as in Step 2 and new centroids are calculated as in Step 3\. In this manner, Steps
    2 and 3 are repeated until no new data is re-assigned.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次计算质心与所有其他点之间的距离，如步骤2所示，并按照步骤3重新计算新的质心。以这种方式，步骤2和步骤3会重复进行，直到没有新的数据被重新分配。
- en: Various *distance and similarity measures* exist for clustering, such as **Euclidean
    Distance** (straight-line distance), **Cosine Similarity** (Cosine of angles between
    vectors), **Hamming Distance** (generally used for categorical variables), **Mahalanobis
    Distance** (named after P.C. Mahalanobis; this measures the distance between a
    point and the mean of a distribution), and others.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 存在多种*距离和相似度度量*用于聚类，例如**欧几里得距离**（直线距离）、**余弦相似度**（向量间角度的余弦值）、**汉明距离**（通常用于分类变量）、**马氏距离**（以P.C.马哈拉诺比斯命名；它度量一个点与分布均值之间的距离）等。
- en: 'Although the optimal number of clusters cannot always be unambiguously identified,
    there are various methods that attempt to find an estimate. In general, clusters
    can be measured by how close points within a cluster are to one another (within
    cluster variance, such as the sum of squares--WSS) and how far apart the clusters
    are (so higher distances between clusters would make the clusters more readily
    distinguishable). One such method that is used to determine the optimal number
    is known as the **elbow method**. The following chart illustrates the concept:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最优的聚类数并非总是可以明确确定，但有多种方法试图找到一个估算值。一般来说，聚类可以通过以下方式衡量：聚类内点之间的距离有多近（即聚类内的方差，如平方和WSS），以及聚类之间的距离有多远（较大的聚类间距使得聚类更容易区分）。其中一种用于确定最优聚类数的方法叫做**肘部法则**。以下图表说明了这一概念：
- en: '![](img/c0a29271-8d0e-4b07-9d74-bd3c2dc982c5.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c0a29271-8d0e-4b07-9d74-bd3c2dc982c5.png)'
- en: The chart shows a plot of the WSS (within the cluster sum of squares that we're
    seeking to minimize) versus the number of clusters. As is evident, increasing
    the number of clusters from 1 to 2 decreases the WSS value substantially. The
    value for WSS decreases rapidly up until the 4^(th) or 5^(th) cluster, when adding
    more clusters does not lead to a significant improvement in WSS. By visual assessment,
    the machine learning practitioner can conclude that the ideal number of clusters
    that can be created is between 3-5, based on the image.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示了WSS（我们试图最小化的聚类内平方和）与聚类数的关系。显然，从1个聚类增加到2个聚类时，WSS值大幅下降。WSS值在增加到第4或第5个聚类时快速减少，之后再增加聚类并没有显著改善WSS值。通过视觉评估，机器学习实践者可以得出结论，理想的聚类数在3到5之间，如图所示。
- en: Note that a low WSS score is not enough to determine the optimal number of clusters.
    It has to be done by inspecting the improvement in the metric. The WSS will eventually
    reduce to 0 when each point becomes an independent cluster.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，较低的WSS分数不足以确定最优的聚类数。必须通过检查度量的改进来完成。WSS最终会降到0，当每个点成为一个独立的聚类时。
- en: The neural networks related algorithms
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与神经网络相关的算法
- en: Neural Network related algorithms have existed for many decades. The first computational
    model was described by Warren McCulloch and Walter Pitts in 1943 in the Bulletin
    of Mathematical Biophysics.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络相关算法已经存在了几十年。第一个计算模型由沃伦·麦卡洛克和沃尔特·皮茨于1943年在《数学生物物理学公报》中描述。
- en: You can learn more about these concepts at [https://pdfs.semanticscholar.org/5272/8a99829792c3272043842455f3a110e841b1.pdf](https://pdfs.semanticscholar.org/5272/8a99829792c3272043842455f3a110e841b1.pdf)
    and [https://en.wikipedia.org/wiki/Artificial_neural_network](https://en.wikipedia.org/wiki/Artificial_neural_network).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://pdfs.semanticscholar.org/5272/8a99829792c3272043842455f3a110e841b1.pdf](https://pdfs.semanticscholar.org/5272/8a99829792c3272043842455f3a110e841b1.pdf)和[https://en.wikipedia.org/wiki/Artificial_neural_network](https://en.wikipedia.org/wiki/Artificial_neural_network)上了解更多这些概念。
- en: Various man-made objects in the physical world, such as aeroplanes, have drawn
    inspiration from nature. A neural network is in essence a representation of the
    phenomenon of data exchange between the axons and dendrons (also known as dendrites)
    of neurons in the *human nervous system*. Just as data passes between one neuron
    to multiple other neurons to make complex decisions, an artificial neural network
    in similar ways creates a network of neurons that receive input from other neurons.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 许多物理世界中的人造物体，如飞机，都从自然中获得了灵感。神经网络本质上是人类神经系统中轴突和树突（也称为树突）的数据交换现象的表现。就像数据从一个神经元传递到多个其他神经元以做出复杂决策一样，人工神经网络以类似的方式创建一个神经元网络，接收来自其他神经元的输入。
- en: 'At a high level, an artificial neural network consists of 4 main components:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次看，一个人工神经网络由四个主要组成部分构成：
- en: Input Layer
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入层
- en: Hidden Layer(s)
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏层
- en: Output Layer
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出层
- en: Nodes and Weights
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点和权重
- en: 'This is depicted in the following image:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这在下图中得到了体现：
- en: '![](img/1664ecf7-b0e7-4a0b-bcca-457fa1f07629.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1664ecf7-b0e7-4a0b-bcca-457fa1f07629.png)'
- en: Each node in the diagram produces an output based on the input from the preceding
    layer. The output is produced using an **activation function**. There are various
    types of activation functions and the output produced depends on the type of function
    used. Examples include binary step (0 or 1), tanh (between -1 and +1), sigmoid,
    and others.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的每个节点都基于来自前一层的输入产生输出。输出是通过**激活函数**生成的。激活函数有多种类型，输出的结果取决于使用的函数类型。例如包括二值阶跃函数（0或1）、tanh函数（-1到+1之间）、sigmoid函数等。
- en: 'The following diagram illustrates the concept:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示说明了这一概念：
- en: '![](img/a84f0aef-960d-4e7a-b280-d68dd85b9e11.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a84f0aef-960d-4e7a-b280-d68dd85b9e11.png)'
- en: 'The values x1 and x2 are the inputs, w1 and w2 represent the weights, and the
    node represents the point at which the inputs and their weights are evaluated
    and a specific output is produced by the activation function. The output f can
    thus be represented by:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 值x1和x2是输入，w1和w2表示权重，节点表示输入及其权重被评估并通过激活函数产生特定输出的点。因此，输出f可以表示为：
- en: '![](img/889c62d8-9180-48a5-bfe3-06c3cdcd33ed.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![](img/889c62d8-9180-48a5-bfe3-06c3cdcd33ed.png)'
- en: Here, f represents the activation function, and b represents the bias term.
    The bias term is independent of the weights and the input values and allows the
    user to shift the output to achieve a better model performance.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，f表示激活函数，b表示偏置项。偏置项独立于权重和输入值，允许用户调整输出，以实现更好的模型性能。
- en: Neural networks with multiple hidden layers (generally 2 or more) are computationally
    intensive, and in recent days, neural networks with multiple hidden layers, also
    known as deep neural networks or more generally deep learning, have become immensely
    popular.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有多个隐藏层（通常为2层或更多）的神经网络计算量大，近年来，拥有多个隐藏层的神经网络，也被称为深度神经网络或更广义上的深度学习，已经变得非常流行。
- en: A lot of the developments in the industry, driven by machine learning and artificial
    intelligence, have been the direct result of the implementation of such multi-layer
    neural networks.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 许多由机器学习和人工智能推动的行业发展，直接源自这些多层神经网络的实现。
- en: 'In R, the package `nnet` provides a readily usable interface to neural networks.
    Although in practice, neural networks generally require sophisticated hardware,
    GPU cards, and so on for illustration purposes, we have leveraged the `nnet` package
    to run the earlier classification exercise on the `PimaIndiansDiabetes` dataset.
    In the example, we will leverage caret in order to execute the `nnet` model:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，`nnet`包提供了一个易于使用的神经网络接口。尽管实际上，神经网络通常需要复杂的硬件、GPU卡等来进行展示，但为了示范，我们利用了`nnet`包在`PimaIndiansDiabetes`数据集上运行了先前的分类练习。在这个例子中，我们将利用caret来执行`nnet`模型：
- en: '[PRE14]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](img/c6baa443-294b-4514-8dcb-38bb030d0fbf.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6baa443-294b-4514-8dcb-38bb030d0fbf.png)'
- en: '[PRE15]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Tutorial - associative rules mining with CMS data
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 教程 - 使用CMS数据进行关联规则挖掘
- en: This tutorial will implement an interface for accessing rules created using
    the Apriori Package in R.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将实现一个接口，用于访问使用R中的Apriori包创建的规则。
- en: 'We''ll be downloading data from the CMS OpenPayments website. The site hosts
    data on payments made to physicians and hospitals by companies:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从CMS OpenPayments网站下载数据。该网站提供了有关公司向医生和医院支付的款项数据：
- en: '![](img/f21aafc2-9e34-4665-865d-54eda8ee3aad.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f21aafc2-9e34-4665-865d-54eda8ee3aad.png)'
- en: The site provides various ways of downloading data. Users can select the dataset
    of interest and download it manually. In our case, we will download the data using
    one of the Web-based APIs that is available to all users.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 该网站提供了多种下载数据的方式。用户可以选择感兴趣的数据集并手动下载。在我们的案例中，我们将使用所有用户都可以访问的基于Web的API来下载数据。
- en: Downloading the data
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载数据
- en: 'The dataset can be downloaded either at the Unix terminal (in the virtual machine)
    or by accessing the site directly from the browser. If you are downloading the
    dataset in the Virtual Machine, run the following command in the terminal window:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集可以通过Unix终端（在虚拟机中）或直接通过浏览器访问该网站进行下载。如果您是在虚拟机中下载数据集，请在终端窗口中运行以下命令：
- en: '[PRE16]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Alternatively, if you are downloading the data from a browser, enter the following
    URL in the browser window and hit *Enter*:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您是通过浏览器下载数据，请在浏览器窗口中输入以下URL并按*Enter*：
- en: '[https://openpaymentsdata.cms.gov/resource/vq63-hu5i.csv?$query=select Physician_First_Name
    as firstName,Physician_Last_Name as lastName,Recipient_City as city,Recipient_State
    as state,Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name as company,Total_Amount_of_Payment_USDollars
    as payment,Nature_of_Payment_or_Transfer_of_Value as paymentNature,Product_Category_or_Therapeutic_Area_1
    as category,Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1 as product
    where covered_recipient_type like "Covered Recipient Physician" and Recipient_State
    like "NY"](https://openpaymentsdata.cms.gov/resource/vq63-hu5i.csv?%24query=select%20Physician_First_Name%20as%20firstName,Physician_Last_Name%20as%20lastName,Recipient_City%20as%20city,Recipient_State%20as%20state,Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name%20as%20company,Total_Amount_of_Payment_USDollars%20as%20payment,Nature_of_Payment_or_Transfer_of_Value%20as%20paymentNature,Product_Category_or_Therapeutic_Area_1%20as%20category,Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1%20as%20product%20where%20covered_recipient_type%20like%20%22Covered%20Recipient%20Physician%22%20and%20Recipient_State%20like%20%22NY%22)'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://openpaymentsdata.cms.gov/resource/vq63-hu5i.csv?$query=select Physician_First_Name
    as firstName,Physician_Last_Name as lastName,Recipient_City as city,Recipient_State
    as state,Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name as company,Total_Amount_of_Payment_USDollars
    as payment,Nature_of_Payment_or_Transfer_of_Value as paymentNature,Product_Category_or_Therapeutic_Area_1
    as category,Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1 as product
    where covered_recipient_type like "Covered Recipient Physician" and Recipient_State
    like "NY"](https://openpaymentsdata.cms.gov/resource/vq63-hu5i.csv?%24query=select%20Physician_First_Name%20as%20firstName,Physician_Last_Name%20as%20lastName,Recipient_City%20as%20city,Recipient_State%20as%20state,Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name%20as%20company,Total_Amount_of_Payment_USDollars%20as%20payment,Nature_of_Payment_or_Transfer_of_Value%20as%20paymentNature,Product_Category_or_Therapeutic_Area_1%20as%20category,Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1%20as%20product%20where%20covered_recipient_type%20like%20%22Covered%20Recipient%20Physician%22%20and%20Recipient_State%20like%20%22NY%22)'
- en: 'As shown in the following image:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示：
- en: '![](img/2f67c791-65e6-4e7c-aca8-8011b4e0eb33.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2f67c791-65e6-4e7c-aca8-8011b4e0eb33.png)'
- en: Writing the R code for Apriori
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写Apriori的R代码
- en: The Apriori algorithm, as explained earlier, allows users to find relationships
    or patterns inherent in a dataset. For this, we will use the arules package in
    R/RStudio. The code will read the dataset downloaded (called `cms2016_2.csv` in
    the example) and run the apriori algorithm in order to find associative rules.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Apriori算法允许用户发现数据集中的关系或模式。为此，我们将使用R/RStudio中的arules包。代码将读取下载的数据集（在示例中为`cms2016_2.csv`）并运行Apriori算法来查找关联规则。
- en: 'Create a new R file in RStudio and enter the following code. Make sure that
    you change the location of the csv file that you downloaded to the appropriate
    directory where the file has been stored:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在RStudio中创建一个新的R文件，并输入以下代码。确保将你下载的CSV文件的位置更改为存储文件的适当目录：
- en: '[PRE17]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Shiny (R Code)
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Shiny（R代码）
- en: 'In RStudio, select File | New File | Shiny Web App:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在RStudio中，选择文件 | 新建文件 | Shiny Web应用：
- en: '![](img/f0044242-690a-47a1-92bd-7c09da18d9bb.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f0044242-690a-47a1-92bd-7c09da18d9bb.png)'
- en: 'Enter the following code in `app.R`:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在`app.R`中输入以下代码：
- en: '[PRE18]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The following image shows the code being copied and saved in a file called `app.R`.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了代码被复制并保存到名为`app.R`的文件中的过程。
- en: '![](img/fd2894d0-c621-4d9e-b169-450f2408f273.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fd2894d0-c621-4d9e-b169-450f2408f273.png)'
- en: Using custom CSS and fonts for the application
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为应用程序使用自定义CSS和字体
- en: For our application, we will use a custom CSS File. We will also use custom
    fonts in order to give the application a nice look-and-feel.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的应用程序，我们将使用自定义CSS文件。同时，我们还将使用自定义字体，以便为应用程序提供良好的外观和感觉。
- en: You can download the custom CSS File from the software repository for this book.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从本书的软件库下载自定义CSS文件。
- en: 'The CSS, Fonts, and other related files should be stored in a folder called
    `www` in the directory where you created the R Shiny Application:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: CSS、字体和其他相关文件应该存储在你创建R Shiny应用程序的目录中的名为`www`的文件夹里：
- en: '![](img/429dc22c-98bc-473a-89dc-7961b7811cc9.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![](img/429dc22c-98bc-473a-89dc-7961b7811cc9.png)'
- en: Running the application
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行应用程序
- en: 'If all goes well, you should be now able to run the application by clicking
    on the Run App option on the top of the page, as shown in the following images:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，你现在应该能够通过点击页面顶部的“运行应用程序”选项来运行应用程序，具体请参考下图：
- en: '![](img/ebc58a2c-7459-439d-9364-d22e13b55c10.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebc58a2c-7459-439d-9364-d22e13b55c10.png)'
- en: Upon clicking the "Run" button, the user will see a popup window similar to
    the one shown below. Note that popups should be enabled in the browser for this
    to function.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“运行”按钮后，用户将看到一个弹出窗口，类似于下方所示的内容。请注意，浏览器需要启用弹窗功能才能正常运行。
- en: '![](img/fa672f9b-88b0-4b6b-8da1-970452c79e7a.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fa672f9b-88b0-4b6b-8da1-970452c79e7a.png)'
- en: 'The app has multiple controls, such as:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序有多个控件，如下所示：
- en: '**Search LHS/RHS**: Enter any test that you want to filter for, in the Left-Hand
    Side or the Right-Hand Side of the rule.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**搜索LHS/RHS**：在规则的左侧（LHS）或右侧（RHS）输入你希望过滤的任何测试内容。'
- en: '**Support**: Indicates the prevalence of the rule in the dataset.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持度**：表示规则在数据集中的普及程度。'
- en: '**Confidence**: Of the rules, how many were exact matches.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**置信度**：规则中的精确匹配数量。'
- en: '**Lift**: Variable defining the importance of a rule. Numbers above 1 are considered
    significant.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Lift**：定义规则重要性的变量。大于1的数字被认为是显著的。'
- en: You can use this app for any other rules file as long as they are processed
    in a way similar to the one outlined before in the R Script section.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 只要它们以类似于R脚本部分中描述的方式处理，你可以将此应用程序用于任何其他规则文件。
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Machine learning practitioners are often of the opinion that creating models
    is easy, but creating a good one is much more difficult. Indeed, not only is creating
    a *good* model important, but perhaps more importantly, knowing how to identify
    a *good* model is what distinguishes successful versus less successful Machine
    Learning endeavors.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习从业者通常认为创建模型很容易，但创建一个好的模型则要困难得多。事实上，创建一个*好的*模型很重要，但或许更重要的是，知道如何识别一个*好的*模型，这才是成功的机器学习项目与不太成功的项目之间的关键区别。
- en: In this chapter, we read up on some of the deeper theoretical concepts in Machine
    Learning. Bias, Variance, Regularization, and other common concepts were explained
    with examples as and where needed. With accompanying R code, we also learnt about
    some of the common machine learning algorithms such as Random Forest, Support
    Vector Machines, and others. We concluded with a tutorial on how to create an
    exhaustive web-based application for Association Rules Mining against CMS OpenPayments
    data.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章，我们学习了一些机器学习中的深层理论概念。我们通过实例解释了偏差、方差、正则化等常见概念，并在需要时进行了详细说明。通过附带的R代码，我们还学习了如随机森林、支持向量机等常见的机器学习算法。最后，我们通过一个教程，讲解了如何为CMS
    OpenPayments数据创建一个全面的基于Web的关联规则挖掘应用程序。
- en: In the next chapter, we will read about some of the technologies that are being
    used in enterprises for both big data as well as machine learning. We will also
    discuss the merits of cloud computing and how they are influencing the selection
    of enterprise software and hardware stacks.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将了解一些正在企业中使用的技术，这些技术既适用于大数据，也适用于机器学习。我们还将讨论云计算的优点，以及它们如何影响企业软件和硬件堆栈的选择。
