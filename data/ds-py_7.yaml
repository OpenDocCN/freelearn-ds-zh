- en: '*Chapter 8*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*'
- en: Tips and Tricks of the Trade
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行业技巧与窍门
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Create better deep learning models faster with the help of transfer learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过迁移学习的帮助，更快地创建更好的深度学习模型
- en: Utilize and work with better models through the help of separate train, development
    and test datasets
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过帮助分离的训练、开发和测试数据集，利用和使用更好的模型
- en: Work with real life datasets
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用真实数据集
- en: Make use of AutoML to find the most optimal network with little to no work
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用AutoML找到最优的网络，几乎不需要任何工作
- en: Visualize neural network models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化神经网络模型
- en: Use training logs better
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更好地使用训练日志
- en: This final chapter shall describe concepts of transfer learning and show you
    how to use training logs effectively.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章最后将描述迁移学习的概念，并展示如何有效地使用训练日志。
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: Now that we have covered almost every topic that you need to be able to kick-start
    your data science journey, we will introduce you to some tools and tricks that
    data scientists use to become more efficient and create better machine learning
    systems. You will first learn about transfer learning, which helps you train models
    even when there is a lack of data. Then, we will move on to important tools and
    tricks that you can make use of to become a better data scientist.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了你启动数据科学之旅所需的几乎所有主题，我们将介绍一些数据科学家用来提高效率、创建更好的机器学习系统的工具和技巧。你将首先学习迁移学习，它可以帮助你在数据不足时训练模型。然后，我们将介绍一些重要的工具和技巧，帮助你成为更好的数据科学家。
- en: Transfer Learning
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习
- en: 'Training a complex neural network is hard and time-consuming due to the amount
    of data required for training. Transfer learning helps data scientists transfer
    part of the knowledge gained by one network to another. This is similar to how
    humans transfer knowledge from one person to another so that everyone does not
    have to start learning every new thing from scratch. Transfer learning helps data
    scientists train neural networks faster and with fewer data points. There are
    two ways to perform transfer learning depending on the situation. They are as
    follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 训练一个复杂的神经网络很困难且耗时，因为需要大量的数据进行训练。迁移学习帮助数据科学家将一个网络获得的部分知识转移到另一个网络上。这类似于人类如何将知识从一个人传递给另一个人，这样每个人就不必从头开始学习每一项新事物。迁移学习帮助数据科学家更快且用更少的数据点训练神经网络。根据情况，有两种方法可以执行迁移学习。具体如下：
- en: '**Use a pre-trained model**: In this approach, we use a pre-trained neural
    network model and use it to solve the problem at hand. A pre-trained model is
    a neural network that has been created for a different purpose to the one at hand,
    has been trained on some other dataset, and has been saved for future reuse. The
    pre-trained model must be trained on a similar or same dataset to get reasonable
    accuracy.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用预训练模型**：在这种方法中，我们使用一个预训练的神经网络模型，并用它来解决当前的问题。预训练模型是为与当前任务不同的目的而创建的神经网络，已经在某个其他数据集上进行了训练，并且已被保存以供将来重用。预训练模型必须在类似或相同的数据集上进行训练，以获得合理的准确度。'
- en: '**Create a model**: In this approach, we train the neural network model on
    a dataset that is like the problem at hand. We then use this model to perform
    the same steps as those for the pre-trained model approach. This is helpful when
    the actual dataset is small and we are unable to create an acceptable model.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创建一个模型**：在这种方法中，我们在一个类似实际问题的数据集上训练神经网络模型。然后，我们使用这个模型执行与预训练模型方法相同的步骤。当实际数据集较小，且我们无法创建一个可接受的模型时，这种方法非常有用。'
- en: As discussed in *Chapter 6*, *Decoding Images*, different layers of a neural
    network learn different features of an image. For example, the first layer might
    learn to recognize horizontal lines, and a few layers later, the network might
    learn to recognize eyes. This is the reason why transfer learning works for images;
    the feature extractor that we get can be used to extract information from new
    images of the same distribution. Now, you must be wondering why we don't use transfer
    learning for every problem we have.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如*第6章*《解码图像》中所讨论的那样，神经网络的不同层次学习图像的不同特征。例如，第一层可能学习识别水平线，而几层后，网络可能学会识别眼睛。这也是为什么迁移学习在图像上有效的原因；我们得到的特征提取器可以用来从同一分布的新图像中提取信息。现在，你一定会好奇，为什么我们不在每个问题上都使用迁移学习呢？
- en: 'Let''s try to understand this with the following diagram. Here, original dataset
    refers to the dataset used to train the network we will transfer knowledge from:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下图示来理解这一点。这里，原始数据集指的是用于训练我们将要迁移知识的网络的数据集：
- en: '![Figure 8.1: Steps to take for transfer learning in different conditions'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.1: 不同条件下进行迁移学习的步骤'
- en: '](img/C13322_08_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_01.jpg)'
- en: 'Figure 8.1: Steps to take for transfer learning in different conditions'
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 8.1: 不同条件下进行迁移学习的步骤'
- en: 'In the diagram, there are four regions:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在图示中，有四个区域：
- en: '**Small dataset** (similar the original dataset): This is the most common case
    and the case where transfer learning helps the most. Due to the similarity of
    the current dataset and the dataset that was used to train the pre-trained model,
    we can use the layers from the pre-trained model and just change the final dense
    layer part depending on the kind of problem.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小数据集**（类似于原始数据集）：这是最常见的情况，也是迁移学习最有效的场景。由于当前数据集与用于训练预训练模型的数据集相似，我们可以使用预训练模型的各层，并根据问题类型只修改最后的全连接层部分。'
- en: '**Large dataset** (similar to the original dataset): This is the most optimal
    situation. Due to the availability of data, it is suggested that you train the
    model from scratch, and to speed up the learning, we can use the weights from
    the pre-trained model to act as a starting point.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据集**（类似于原始数据集）：这是最理想的情况。由于数据的可用性，建议从头开始训练模型，并且为了加速学习，我们可以使用预训练模型的权重作为起点。'
- en: '**Small dataset** (different from original dataset): This is the worst situation
    in terms of transfer learning as well as deep learning. The only solution in this
    situation is to find a dataset like the current dataset and train a model on it,
    and then use transfer learning.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小数据集**（与原始数据集不同）：这是迁移学习和深度学习中最糟糕的情况。面对这种情况，唯一的解决方案是找到一个类似当前数据集的数据集，在其上训练一个模型，然后再使用迁移学习。'
- en: '**Large dataset** (different from original dataset): Due to the large size
    of the dataset, we can train the model from scratch. To make the training faster,
    the weights from a pre-trained model can be taken as the starting point, but this
    is not recommended.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据集**（与原始数据集不同）：由于数据集非常大，我们可以从头开始训练模型。为了加快训练速度，可以将预训练模型的权重作为起点，但这并不推荐。'
- en: Transfer learning has been successful for only two types of datasets—image and
    natural language (textual data) datasets. Word embedding, which we covered in
    *Chapter 7*, is an example of transfer learning. We will now see how to make use
    of transfer learning for image data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习仅在两种类型的数据集上取得了成功——图像数据集和自然语言（文本数据）数据集。我们在 *第 7 章* 中讨论的词嵌入就是一个迁移学习的例子。接下来，我们将看看如何将迁移学习应用于图像数据。
- en: Transfer Learning for Image Data
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图像数据的迁移学习
- en: 'In this section, we will load a pre-trained model using Keras and perform transfer
    learning. You will learn how to handle the two cases where the dataset is like
    the pre-trained model''s dataset. To start transfer learning, we first must load
    a pre-trained model. We will load the Inception model using Keras:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 Keras 加载一个预训练模型并进行迁移学习。你将学到如何处理数据集与预训练模型数据集相似的两种情况。要开始迁移学习，我们首先必须加载一个预训练模型。我们将使用
    Keras 加载 Inception 模型：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`include_top=False` removes the first fully connected layer of the network,
    allowing us to input images of any size that we want instead of relying on the
    image size of the original dataset. `weights=''imagenet''` assures that the pre-trained
    weights are loaded. If none is passed to `weights`, then the initialization of
    the weights will be random. The Inception model was a huge improvement over existing
    **convolutional neural network** (**CNN**) classifiers. Prior to Inception, the
    best models just stacked multiple convolution layers, hoping to get better performance.
    Inception, on the other hand, was complex as it used a lot of tricks to push performance
    both in terms of the accuracy and the time taken to predict.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`include_top=False` 去除了网络中的第一个全连接层，使我们可以输入任何大小的图像，而不依赖于原始数据集的图像大小。`weights=''imagenet''`
    确保加载预训练权重。如果没有传递给 `weights`，则权重将随机初始化。Inception 模型在现有的 **卷积神经网络**（**CNN**）分类器上做出了巨大的改进。在
    Inception 之前，最好的模型只是堆叠多个卷积层，希望能获得更好的性能。而 Inception 则不同，它采用了许多技巧，在提高准确率的同时，也减少了预测时间。'
- en: '![Figure 8.2: Single cell of the Inception network'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.2: Inception 网络的单个神经元'
- en: '](img/C13322_08_02.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_02.jpg)'
- en: 'Figure 8.2: Single cell of the Inception network'
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.2：Inception 网络的单个细胞
- en: 'The first case we will look at is a small dataset that is similar to the original
    dataset. In this case, we need to first freeze the layers of the pre-trained model.
    To do this, we simply make all the layers of this base model untrainable:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先查看的案例是一个与原始数据集相似的小型数据集。在这种情况下，我们需要首先冻结预训练模型的层。为此，我们只需使基础模型的所有层不可训练：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The next case is a large dataset that is similar to the original dataset. In
    this case, we need to train the model by taking the pre-trained weights to be
    the starting point. In this case, we do not make any modifications and simply
    train the whole model, which is a combination of `base_model` along with some
    additional dense layers depending on our problem. For example, if the problem
    is a two class classification problem we need to have the last dense layer to
    have 2 outputs. Another thing that we can do in this case is freeze the weights
    of the first few layers so that the training happens faster. Freezing the first
    few layers is helpful as these layers learn simple shapes, which can be applicable
    in any kind of problem. To freeze the first five layers in Keras, use the following
    code:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个案例是一个与原始数据集相似的大型数据集。在这种情况下，我们需要通过将预训练权重作为起点来训练模型。在这种情况下，我们不做任何修改，只是训练整个模型，该模型是`base_model`与一些额外的全连接层的组合，具体取决于我们的任务。例如，如果任务是二分类问题，我们需要使最后一层全连接层有
    2 个输出。我们在这种情况下还可以做的一件事是冻结前几层的权重，这样训练过程会更快。冻结前几层是有帮助的，因为这些层学习的是简单的形状，可以应用于任何类型的问题。要在
    Keras 中冻结前五层，请使用以下代码：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Exercise 58: Using InceptionV3 to Compare and Classify Images'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 58：使用 InceptionV3 比较和分类图像
- en: 'In this exercise, we will make use of the InceptionV3 model provided by Keras
    to perform classification between cats and dogs. We will use the same dataset
    (https://github.com/TrainingByPackt/Data-Science-with-Python/tree/master/Chapter08)
    we used in *Chapter 6*, *Decoding Images* and compare our results. We will freeze
    the Inception convolutional layers so that we do not have to retrain them:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将利用 Keras 提供的 InceptionV3 模型进行猫狗分类。我们将使用与*第 6 章*《解码图像》相同的数据集（https://github.com/TrainingByPackt/Data-Science-with-Python/tree/master/Chapter08），并比较我们的结果。我们将冻结
    Inception 卷积层，这样就不需要重新训练它们：
- en: 'First, create functions to read the image and its label from the filename.
    Here, the `PATH` variable contains the path to the training dataset:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，创建函数从文件名读取图像及其标签。这里，`PATH` 变量包含训练数据集的路径：
- en: '[PRE3]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Set the size and channel of the images:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置图像的大小和通道：
- en: '[PRE4]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, create a function to preprocess the images:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，创建一个函数来预处理图像：
- en: '[PRE5]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now create a generator function that reads the images and labels and processes
    the images:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在创建一个生成器函数，读取图像和标签并处理图像：
- en: '[PRE6]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we will read the validation data. Create a function to read the images
    and their labels:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将读取验证数据。创建一个函数来读取图像及其标签：
- en: '[PRE7]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Read the validation files:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取验证文件：
- en: '[PRE8]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Plot a few images from the dataset to see whether you loaded the files correctly:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据集中绘制一些图像，查看是否正确加载了文件：
- en: '[PRE9]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The sample images are as follows:'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 样本图像如下：
- en: '![](img/C13322_08_03.jpg)'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C13322_08_03.jpg)'
- en: 'Figure 8.3: Sample images from the loaded dataset'
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.3：从加载的数据集中提取的样本图像
- en: 'Load the Inception model and pass the shape of the input images:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 Inception 模型并传入输入图像的形状：
- en: '[PRE10]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Freeze the Inception model layers so that training is not performed on them:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 冻结 Inception 模型层，使得训练过程中不会对它们进行训练：
- en: '[PRE11]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now add the output dense layer according to our problem. Here `keep_prob` is
    the ratio of nodes to be kept while training. So, the dropout rate will be `1
    – keep_prob`:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在根据我们的问题，添加输出的全连接层。这里，`keep_prob`是训练过程中保留节点的比例。因此，丢弃率将是`1 – keep_prob`：
- en: '[PRE12]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, compile the model to make it ready for training:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，编译模型，使其准备好进行训练：
- en: '[PRE13]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'And then perform training of the model:'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后进行模型训练：
- en: '[PRE14]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Evaluate the model and get the accuracy:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型并获取准确性：
- en: '[PRE15]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The accuracy is as follows:'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 准确度如下：
- en: '![Figure 8.4: The accuracy of the model'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.4：模型的准确性'
- en: '](img/C13322_08_04.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_04.jpg)'
- en: 'Figure 8.4: The accuracy of the model'
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.4：模型的准确性
- en: As you can see earlier, the model gets an accuracy of 97.8%, which is much higher
    than the 73% accuracy we achieved in *Chapter 6*, *Decoding Images*. You can play
    around with the model we appended to the Inception model to see whether you can
    improve the accuracy. You can plot the incorrectly predicted images to get a sense
    of how well the model performs.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所示，模型的准确率为97.8%，这比我们在*第六章*，*解码图像*中获得的73%的准确率要高得多。你可以尝试修改我们附加到Inception模型上的模型，看看是否能提高准确率。你还可以绘制错误预测的图像，来了解模型的表现如何。
- en: '[PRE16]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The incorrectly predicted image is as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 错误预测的图像如下所示：
- en: '![Figure 8.5: The incorrectly predicted sample'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.5：错误预测的样本](img/C13322_08_05.jpg)'
- en: '](img/C13322_08_05.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_05.jpg)'
- en: 'Figure 8.5: The incorrectly predicted sample'
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.5：错误预测的样本
- en: 'Activity 21: Classifying Images using InceptionV3'
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动21：使用InceptionV3进行图像分类
- en: In this activity, we will make use of the InceptionV3 model provided by Keras
    to perform classification between cats and dogs. We will use the same dataset
    we used in *Chapter 6*, *Decoding Images* and compare our results. Here we will
    train the whole model, but we will make use of the weights that are present in
    the Inception pre-trained model as a starting point. This is similar to the exercise
    we just covered, but without freezing layers.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，我们将使用Keras提供的InceptionV3模型进行猫狗分类。我们将使用*第六章*，*解码图像*中使用的相同数据集并比较我们的结果。在这里，我们将训练整个模型，但我们将使用Inception预训练模型中的权重作为起点。这类似于我们刚才讨论的练习，但没有冻结层。
- en: Create a generator to get the images and labels.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个生成器来获取图像和标签。
- en: Create a function to get the labels and images. Then, create a function to preprocess
    the image and augment it.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数来获取标签和图像。然后，创建一个函数来预处理图像并对其进行增强。
- en: Load the validation dataset, which will not be augmented.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载验证数据集，这些数据集不会进行增强处理。
- en: Load the Inception model and add the final dense layers to it. Train the entire
    network.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载Inception模型并添加最终的全连接层。训练整个网络。
- en: You should see that this model gets us an accuracy of 95.4%, which is much higher
    than the 73% accuracy we achieved in *Chapter 6*, *Decoding Images*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到这个模型的准确率为95.4%，这比我们在*第六章*，*解码图像*中获得的73%的准确率要高得多。
- en: 'You must have noticed the preceding code was similar to *Exercise 58*, but
    here we did not freeze the layers. The model definitely benefited from taking
    the weights from the Inception model as the starting point. You can plot the incorrectly
    predicted images to get a sense of how well the model performs:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你一定注意到前面的代码与*练习58*相似，但这里我们没有冻结层。模型显然从Inception模型的权重中受益，将其作为起点。你可以绘制错误预测的图像，来了解模型的表现如何：
- en: '[PRE17]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 387.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第387页找到。
- en: 'The incorrectly predicted image is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 错误预测的图像如下所示：
- en: '![Figure 8.6: The incorrectly predicted sample from the dataset'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.6：数据集中错误预测的样本](img/C13322_08_06.jpg)'
- en: '](img/C13322_08_06.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_06.jpg)'
- en: 'Figure 8.6: The incorrectly predicted sample from the dataset'
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.6：数据集中错误预测的样本
- en: Useful Tools and Tips
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有用的工具和技巧
- en: In this section, you will first learn the importance of different splits of
    the dataset. After that, you learn some tips that will come handy when you start
    working on datasets that haven't been processed before. Then come tools such as
    pandas profiling and TensorBoard, which will make your life easier by providing
    easy access to information. We will take a look at AutoML and how it can be used
    to get high-performance models without much manual effort. Finally, we will visualize
    our Keras model and export the model diagram to a file.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将首先了解数据集的不同拆分的重要性。之后，你将学到一些技巧，这些技巧在处理未经过处理的数据集时会派上用场。然后，我们将介绍像pandas profiling和TensorBoard这样的工具，它们通过提供简便的信息访问，使你的工作更加轻松。我们还将看看AutoML，以及它如何在无需大量人工操作的情况下获得高性能模型。最后，我们将可视化我们的Keras模型并将模型图导出到文件。
- en: Train, Development, and Test Datasets
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练集、开发集和测试集
- en: We briefly talked about train, development, and test datasets in the previous
    chapters. Here, we will delve deeper into the topic.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前几章中简要讨论了训练集、开发集和测试集。在这里，我们将深入探讨这个话题。
- en: The training, or train set is a sample from the dataset, and we use this to
    create our machine learning models. The development, or dev set (also known as
    validation set), is a sample that helps us tune the hyperparameters of the created
    model. The testing or test set is the sample that we use to finally evaluate the
    model. Having all three sets is important for model development.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集（或训练数据集）是从数据集中获取的一个样本，我们用它来创建我们的机器学习模型。开发集（或验证集，也称为开发数据集）是一个样本，帮助我们调整已创建模型的超参数。测试集（或测试数据集）是我们用来最终评估模型的样本。拥有这三种数据集对模型开发至关重要。
- en: '**Distribution of the sets**'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据集的分布**'
- en: The development and testing sets should be from the same distribution and should
    represent the data that you expect your model to get in the future. If the distribution
    is different, the model will be tuned to a distribution that will not be seen
    by the model in the future, impacting the deployed model's performance. Your model
    could perform poorly due to the difference in distribution between the training
    and testing/dev sets. To rectify this, you can take some data points from test/dev
    set and introduce them into the training set. Make sure that the original images
    dominate their respective sets to prevent incorrect results.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 开发集和测试集应该来自相同的分布，并且应该代表你期望模型在未来接收到的数据。如果分布不同，模型将会调优到一个在未来看不见的分布，这会影响部署后的模型表现。由于训练集和测试/开发集之间的分布差异，模型可能会表现不佳。为了解决这个问题，你可以从测试/开发集获取一些数据点并将其引入到训练集中。确保原始图像主导各自的数据集，以防止出现不正确的结果。
- en: If the distribution of the training and development sets are different, we cannot
    identify whether the model is overfitting; in this case, a new train-dev set should
    be introduced to check for overfitting of the model. The training and train-dev
    set must have the same distribution. If there is a huge difference in the errors
    of the dev and train-dev sets, then there is a data mismatch problem. To rectify
    this, you will have to carry out manual error analysis, and in most cases, collect
    more data points.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果训练集和开发集的分布不同，我们无法识别模型是否过拟合；在这种情况下，应引入一个新的训练-开发集来检查模型的过拟合情况。训练集和训练-开发集必须具有相同的分布。如果开发集和训练-开发集的误差差异很大，那么就存在数据不匹配的问题。为了解决这个问题，你需要进行手动误差分析，并在大多数情况下，收集更多的数据点。
- en: Note
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The dev set is the same as the validation set we have been using all this time,
    we sometimes referred to it as the test set but that was only to get you started.
    It should also be noted that we train our model only on the training dataset.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 开发集与我们一直使用的验证集相同，我们有时称之为测试集，但那只是为了让你入门。还应该注意，我们仅在训练数据集上训练模型。
- en: '**Size of the sets**'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据集的大小**'
- en: The size of the dev and test sets should be determined based on the overall
    size of the dataset. If the size was 10,000 data points, then a 60%/20%/20% split
    would work well as the test and dev sets would have enough data points to accurately
    measure the performance of the model. On the other hand, if the dataset had 1,000,000
    data points, then a split of 98%/1%/1% would suffice as 10,000 is more than enough
    data points to gauge the performance of the model.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 开发集和测试集的大小应根据数据集的总体大小来确定。如果数据集的大小是10,000个数据点，那么60%/20%/20%的划分会很好，因为测试集和开发集都有足够的数据点来准确衡量模型的性能。另一方面，如果数据集有1,000,000个数据点，那么98%/1%/1%的划分就足够了，因为10,000个数据点已经足够评估模型的表现。
- en: The sample of the data of the three sets should remain the same, so that we
    evaluate all the models in the same environment. To do this, you can set a "seed"
    when creating random samples. Setting the random number seed helps us get the
    same random split of the data every time we run the experiment.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 三个数据集的样本应该保持一致，以便我们在相同的环境中评估所有模型。为此，你可以在创建随机样本时设置一个“种子”值。设置随机数种子有助于每次运行实验时获得相同的随机数据划分。
- en: Working with Unprocessed Datasets
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理未处理的数据集
- en: 'When you start working on more complex and less processed datasets, you will
    realize that most of the time you won''t have all the data that you need to create
    a satisfactory model. To tackle this, you need to identify external datasets that
    can help you in creating a competent model. The additional data that you use can
    be of the following two types:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始处理更复杂且未经过多处理的数据集时，你会发现大多数情况下，你无法获得创建令人满意模型所需的所有数据。为了解决这个问题，你需要识别可以帮助你创建合格模型的外部数据集。你使用的附加数据可以有以下两种类型：
- en: '**More data points for the same data**: This is helpful when the model is overfitting
    due to the small size of the dataset. If it is impossible to get more data points,
    you can use a simpler model—either a neural network with fewer layers or a linear
    model.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相同数据的更多数据点**：当模型由于数据集较小而过拟合时，这非常有用。如果无法获取更多数据点，可以使用更简单的模型——例如层数较少的神经网络或线性模型。'
- en: '**Additional data from different sources**: Sometimes there is some data missing
    from the dataset; for example, the state or country of the cities listed in the
    dataset, or the macroeconomic factors of the countries listed in the dataset,
    such as GDP and per-capita income. This data can be easily found on the internet
    and can be used to improve the model that you create.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**来自不同来源的额外数据**：有时候数据集中会缺少一些数据，例如数据集中城市的州或国家，或者数据集中列出的国家的宏观经济因素，如 GDP 和人均收入。此类数据可以轻松在互联网上找到，并可用于改进您创建的模型。'
- en: A best practice is to always start with **exploratory data analysis** (**EDA**).
    EDA helps us become intimately familiar with the dataset. It helps identify the
    best model as well as the variables that can be used for machine learning. Another
    important aspect of EDA is to check the data for anomalies. This helps us to ensure
    that the data reached us without any errors. The results of EDA can be shared
    with the stakeholders to confirm the validity of the data. Data scientists might
    need to revisit the EDA step multiple times while working on a project.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践是始终从**探索性数据分析**（**EDA**）开始。EDA 帮助我们深入了解数据集，有助于识别最佳模型及可用于机器学习的变量。EDA 的另一个重要方面是检查数据是否存在异常。这可以确保数据在传输过程中没有发生错误。EDA
    的结果可以与利益相关者共享，以确认数据的有效性。数据科学家在项目中可能需要多次回顾 EDA 步骤。
- en: Another thing to keep in mind is the application of your model. It is important
    to know whether your model will perform real-time processing or batch processing.
    This will help you choose your tools and models accordingly. For example, if real-time
    processing is a priority, then you would probably use a model that will produce
    results in less than a second, whereas if the application requires batch processing,
    then you can use complex neural network models that take more than a couple seconds
    to produce the predictions.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要牢记的事项是模型的应用场景。了解您的模型是用于实时处理还是批处理非常重要。这将帮助您选择合适的工具和模型。例如，如果实时处理是优先考虑的目标，那么您可能会使用一个能在不到一秒钟内产生结果的模型；而如果应用程序需要批处理，那么您可以使用那些需要几秒钟以上才能产生预测的复杂神经网络模型。
- en: 'Next, we will look into some best practices for handling training and performing
    hyperparameter tuning. Always shuffle your data before splitting it into training
    and testing sets. Another thing that can help converge faster is shuffling the
    training data during training. The `fit` function of Keras has a handy parameter
    called `True` to shuffle the training data before every epoch. An important parameter
    to keep in mind is the random number seed; This helps data scientists create reproducible
    results even with the random shuffles and splits. To set the seed for Keras, use
    the following:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨一些处理训练和进行超参数调优的最佳实践。在将数据拆分为训练集和测试集之前，始终对数据进行洗牌。另一个有助于更快收敛的做法是在训练过程中对训练数据进行洗牌。Keras
    的`fit`函数有一个非常有用的参数，名为`True`，它会在每个训练周期前洗牌训练数据。需要记住的一个重要参数是随机数种子；它帮助数据科学家即使在随机洗牌和拆分的情况下，也能创建可重复的结果。要为
    Keras 设置种子，请使用以下方法：
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The first two lines set the random seed for NumPy, and the next two lines set
    the seed for TensorFlow, which is the backend Keras uses.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 前两行设置了 NumPy 的随机种子，接下来的两行则为 TensorFlow 设置了种子，这是 Keras 使用的后端。
- en: If you are working with a large dataset, start with a subset of data and create
    the model. Try to overfit this model by making the network deeper or more complex.
    You can use regularization to limit the model from overfitting the data. When
    you are confident with the model, use the complete training data and tweak the
    created model to improve the performance of the model.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在处理一个大型数据集，建议先使用数据的子集来创建模型。尝试通过加深网络或使其更复杂来使模型过拟合。您可以使用正则化来限制模型过拟合数据。当您对模型有信心时，使用完整的训练数据并调整已创建的模型，以提高模型的性能。
- en: Dropout is a very powerful regularizer; you should experiment with different
    dropout rates as the optimal dropout rate varies from dataset to dataset. If the
    dropout probability is too low, there will be no effect. On the other hand, if
    it is too high, the model will start to underfit. Dropout rates between 20% and
    50% usually perform the best.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout是一种非常强大的正则化方法；你应该尝试不同的dropout率，因为最优的dropout率因数据集不同而不同。如果dropout概率太低，效果就不会显现。另一方面，如果概率过高，模型就会开始欠拟合。通常，20%到50%之间的dropout率效果最好。
- en: The learning rate is an important hyperparameter. Having a high learning rate
    will lead to the model overshooting the optimal solution, while having a low learning
    rate will cause the model to learn very slowly. As mentioned in *Chapter 5*, *Mastering
    Structured Data*, we can start with a high learning rate and reduce the learning
    rate after a few steps.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率是一个重要的超参数。学习率过大会导致模型越过最优解，而学习率过小则会导致模型学习非常缓慢。如*第5章*《掌握结构化数据》中提到的，我们可以从较高的学习率开始，并在经过几步后降低学习率。
- en: This helps us reach the optimal point faster and due to the reduction in step
    size preventing the model from overshooting the solution. To perform this reduction
    in the learning rate, we can use the `ReduceLROnPlateau` callback from Keras.
    The callback reduces the learning rate by a predefined factor if the selected
    metric stops improving.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这有助于我们更快地达到最优点，同时由于步长减小，避免了模型越过解的情况。为了实现学习率的减少，我们可以使用Keras中的`ReduceLROnPlateau`回调函数。如果选择的指标停止改进，该回调函数会按照预定义的因子降低学习率。
- en: Note
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To learn further on the dataset, refer to the documentation at https://keras.io/callbacks/#reducelronplateau.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 要进一步了解数据集，请参考文档：https://keras.io/callbacks/#reducelronplateau。
- en: '[PRE19]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We pass the quantity to be monitored into the `monitor` parameter. The `factor`
    refers to the factor by which the learning rate must be reduced; the new learning
    rate will be equal to the learning rate multiplied by the factor. `patience` is
    the number of epochs the callback will wait before changing the learning rate.
    `min_delta` refers to the threshold for measuring the improvement of the model
    on the monitored metric. `min_lr` refers to the lower bound on the learning rate.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要监控的数量传递给`monitor`参数。`factor`指的是学习率需要减少的倍数；新的学习率将等于当前学习率乘以这个因子。`patience`是回调函数等待的epochs数量，等待后才会改变学习率。`min_delta`表示衡量模型在监控指标上改进的阈值。`min_lr`表示学习率的下限。
- en: pandas Profiling
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pandas Profiling
- en: 'In the initial chapters, you learned different ways to explore structured datasets.
    EDA plays an important role when it comes to creating models for structured data.
    The steps used to perform EDA, such as null value identification, correlation,
    and counting unique values, rarely change, so it is better to create a function
    that will do all this for us without writing a lot of code. The pandas profiling
    library does just that: it takes a dataframe and performs analysis on the data
    and presents the results in an interactive output.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，你学习了不同的探索结构化数据集的方法。EDA在构建结构化数据模型时起着重要作用。执行EDA的步骤，如空值识别、相关性分析和计数唯一值等，通常不变，因此最好创建一个函数来完成这些任务，避免编写大量代码。pandas
    profiling库正是做到了这一点：它接收一个DataFrame，对数据进行分析并以交互式的输出形式展示结果。
- en: 'The output contains the following information for the relevant columns:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 输出包含相关列的以下信息：
- en: '**Essentials**: This contains information on the type of the variable, the
    unique values, and the missing values.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基本信息**：包含关于变量类型、唯一值和缺失值的信息。'
- en: '**Quantile statistics**: This contains information on the minimum value, Q1,
    the median, Q3, the maximum, the range, and the interquartile range.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分位数统计**：包含关于最小值、Q1、中央値、Q3、最大值、范围和四分位距的信息。'
- en: '**Descriptive statistics**: This contains information on the mean, the mode,
    the standard deviation, the sum, the median absolute deviation, and the coefficient
    of variation.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**描述性统计**：包含关于均值、众数、标准差、总和、中位数绝对偏差和变异系数的信息。'
- en: '**Most frequent values**: This contains information on the most common value
    count along with the frequency in percentage.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最频繁的值**：包含关于最常见值的计数以及其百分比频率的信息。'
- en: '**Histogram:** This contains information on a plot of the frequency of values
    of different features of the dataset.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直方图**：包含关于数据集不同特征值频率的图表信息。'
- en: '**Correlations**: These highlight highly correlated variables and suggests
    removal.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相关性**：这些突出显示了高度相关的变量，并建议将其移除。'
- en: 'To use pandas profiling, simply pass a data frame to the `pandas_profiling`
    object. Use the following code:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 pandas profiling，只需将数据框传递给 `pandas_profiling` 对象。使用以下代码：
- en: '[PRE20]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The following screenshot displays a part of the pandas profiling output for
    the telecom churn dataset we worked on in *Chapter 5*, *Mastering Structured Data*
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了我们在 *第 5 章* 中处理的电信流失数据集的 pandas profiling 输出的一部分，*精通结构化数据*
- en: '![Figure 8.7: A screenshot of the pandas profiling output'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.7：pandas profiling 输出的截图](img/C13322_08_07.jpg)'
- en: '](img/C13322_08_07.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_07.jpg)'
- en: 'Figure 8.7: A screenshot of the pandas profiling output'
  id: totrans-139
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.7：pandas profiling 输出的截图
- en: You can use this to explore datasets we worked on in the previous chapters.
    pandas profiling offers interactive output, so you are encouraged to go ahead
    and play around with the output.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用这个功能来探索我们在前几章中处理的数据集。pandas profiling 提供交互式输出，鼓励您去操作并玩转这些输出。
- en: TensorBoard
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TensorBoard
- en: '**TensorBoard** is a web app that can be used to view training logs and visualize
    your model''s accuracy and loss metrics. It was originally created to work with
    TensorFlow, but we can make use of TensorBoard using the **TensorBoard callback**
    in Keras. To start visualizing, create the Keras callback. Use the following code
    to do so:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorBoard** 是一个可以用来查看训练日志并可视化模型准确率和损失度量的 Web 应用。它最初是为了与 TensorFlow 一起使用而创建的，但我们可以通过
    Keras 中的 **TensorBoard 回调** 来使用 TensorBoard。要开始可视化，请创建 Keras 回调。使用以下代码来实现：'
- en: '[PRE21]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Keep a note of the log directory that you specify here; you will need this
    later. You can pass ''`batch`'', ''`epoch`'', or an integer in `update_freq`;
    this refers to how often the logs should be written. The next step is to start
    TensorBoard; to do that, open a terminal and run the following command:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 记住您在此处指定的日志目录；稍后您会需要它。您可以在 `update_freq` 中传递 '`batch`'、'`epoch`' 或整数值；这表示日志应写入的频率。下一步是启动
    TensorBoard；为此，打开终端并运行以下命令：
- en: '[PRE22]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now start training. Do not forget to pass the callback to the `fit` function.
    The first tab of TensorBoard shows the training logs of the model. You can create
    multiple folders inside the log folder to get the logs of different models on
    the same graph for comparison:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在开始训练。不要忘记将回调传递给 `fit` 函数。TensorBoard 的第一个标签页显示了模型的训练日志。您可以在日志文件夹内创建多个子文件夹，以便在同一图表上获取不同模型的日志进行比较：
- en: '![Figure 8.8: A screenshot showing the TensorBoard dashboard'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.8：显示 TensorBoard 仪表盘的截图](img/C13322_08_08.jpg)'
- en: '](img/C13322_08_08.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_08.jpg)'
- en: 'Figure 8.8: A screenshot showing the TensorBoard dashboard'
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.8：显示 TensorBoard 仪表盘的截图
- en: 'In the second tab, you can visualize the model that you have created. The following
    figure shows the model that we created in the first activity of the previous chapter:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个标签页中，您可以可视化您创建的模型。下图展示了我们在上一章的第一个活动中创建的模型：
- en: '![Figure 8.9: The model as interpreted by Keras'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.9：Keras 解释的模型](img/C13322_08_09.jpg)'
- en: '](img/C13322_08_09.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_09.jpg)'
- en: 'Figure 8.9: The model as interpreted by Keras'
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.9：Keras 解释的模型
- en: 'Another way to visualize training logs in Jupyter Notebook is to plot them
    using Matplotlib:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Jupyter Notebook 中可视化训练日志的另一种方法是使用 Matplotlib 绘制它们：
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following figure shows the model accuracy plot for the train and test set
    for our cats versus dogs model from *Activity 1*:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了我们在 *活动 1* 中使用的猫狗模型的训练集和测试集的准确率图：
- en: '![Figure 8.10: The accuracy log of the model'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.10：模型的准确率日志](img/C13322_08_10.jpg)'
- en: '](img/C13322_08_10.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_10.jpg)'
- en: 'Figure 8.10: The accuracy log of the model'
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.10：模型的准确率日志
- en: The accuracy log given above shows how the training and development set accuracy
    increased over different epochs. As you can see, the development set accuracy
    is more volatile than the training set accuracy. This is because the model hasn't
    seen these examples, towards the initial epochs this volatility will be high but
    as we create a robust model after having trained it for a larger number of epochs,
    the accuracy will become less volatile.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的准确率日志显示了训练集和开发集的准确率在不同的 epoch 上是如何变化的。正如你所看到的，开发集的准确率比训练集的准确率更为波动。这是因为模型没有见过这些例子，在初期的
    epochs 中波动较大，但随着我们在更多的 epochs 上进行训练，模型变得更稳健，准确率波动会减小。
- en: '[PRE24]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following figure shows the model loss plot for the train and test set for
    our cats-versus-dogs model from *Activity 21*:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了我们在 *活动 21* 中使用的猫狗模型的训练集和测试集的损失图：
- en: '![Figure 8.11: Loss log of the model'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.11：模型的损失日志](img/C13322_08_11.jpg)'
- en: '](img/C13322_08_11.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_11.jpg)'
- en: 'Figure 8.11: Loss log of the model'
  id: totrans-165
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.11：模型的损失日志
- en: Similar to the accuracy log, the loss log given above shows how the training
    and development set loss decreased over different epochs. The spike near epoch
    19 suggests that a really bad model which was overfit to the training set was
    created but, eventually the model started stabilizing and gave better results
    on the development set as well.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于准确度日志，上面给出的损失日志显示了训练集和开发集的损失在不同 epochs 中的变化。第 19 个 epoch 附近的波峰表明，模型曾因过拟合于训练集而表现非常糟糕，但最终模型开始稳定，并在开发集上也给出了更好的结果。
- en: If you are only concerned with the model logs, then you can use the code given
    earlier to plot the model logs after the training is over. If, however, you are
    training a model that takes a long time to train, it would be wise to use TensorBoard,
    as it provides a real-time plot of the training loss and accuracy.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只关心模型日志，那么你可以使用之前给出的代码，在训练结束后绘制模型日志。然而，如果你正在训练一个需要较长时间的模型，建议使用 TensorBoard，因为它可以实时绘制训练损失和准确度。
- en: AutoML
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoML
- en: 'Now that you have created multiple neural network models, you understand that
    there are two main components that go into creating well-performing networks.
    They are as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经创建了多个神经网络模型，你明白了构建表现良好的网络的两个主要组成部分。它们分别是：
- en: The architecture of the neural network
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络的架构
- en: The hyperparameters of the neural network
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络的超参数
- en: Depending on the problem, it could take tens of iterations to get to the best
    possible network. So far, we have been creating architectures and tuning the hyperparameters
    manually. AutoML can help us perform these tasks. It searches for the most optimal
    network and parameters for the dataset at hand. Auto-Keras is an open source library
    that helps us implement AutoML on Keras. Let's learn about how to use Auto-Keras
    with the help of an exercise.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 根据问题的不同，可能需要经过数十次迭代才能得到最佳网络。到目前为止，我们一直在手动创建架构并调优超参数。AutoML 可以帮助我们执行这些任务，它会为当前数据集搜索最优的网络和参数。Auto-Keras
    是一个开源库，帮助我们在 Keras 上实现 AutoML。让我们通过一个练习来学习如何使用 Auto-Keras。
- en: 'Exercise 59: Get a Well-Performing Network Using Auto-Keras'
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 59：使用 Auto-Keras 获取表现良好的网络
- en: In this exercise, we will make use of the Auto-Keras library to find the most
    optimal network and parameters for the cats-vs-dogs dataset (https://github.com/TrainingByPackt/Data-Science-with-Python/tree/master/Chapter08).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将利用 Auto-Keras 库，为 cats-vs-dogs 数据集（https://github.com/TrainingByPackt/Data-Science-with-Python/tree/master/Chapter08）找到最优的网络和参数。
- en: 'First, create a function to load the image labels:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，创建一个加载图像标签的函数：
- en: '[PRE25]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Set `SIZE` which is the dimension of the square image input.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 `SIZE`，它是输入图像的维度（宽高相等的图像）。
- en: '[PRE26]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Then create a function that reads images and their labels. Here `PATH` variable
    contains the path to the training dataset.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后创建一个函数来读取图像及其标签。此处 `PATH` 变量包含训练数据集的路径。
- en: '[PRE27]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Load the data and divide it into train and test sets:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据并将其划分为训练集和测试集：
- en: '[PRE28]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Now, let's start with AutoML
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们开始使用 AutoML。
- en: 'First, create an array with the training time for autokeras. It will terminate
    the process of finding the best possible model once this time is elapsed:'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，创建一个数组来设置 AutoKeras 的训练时间。时间一到，它会停止寻找最佳模型的过程：
- en: '[PRE29]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We will give autokeras an hour to find the best possible method.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将给 AutoKeras 一小时的时间来寻找最佳方法。
- en: 'Create an image classifier model using autokeras and perform training for the
    time specified in the previous step:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 AutoKeras 创建一个图像分类模型，并进行前一步中指定时间的训练：
- en: '[PRE30]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The output will be as follows:![](img/C13322_08_12.jpg)
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出将如下所示：![](img/C13322_08_12.jpg)
- en: 'Figure 8.12: Image classifier model'
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.12：图像分类模型
- en: 'Next, we save our model so that we can use it again:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们保存模型，以便以后可以再次使用它：
- en: '[PRE31]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Load the trained model and perform predictions using it:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载训练好的模型并使用它进行预测：
- en: '[PRE32]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Evaluate the accuracy of the model created by autokeras:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估由 AutoKeras 创建的模型的准确性：
- en: '[PRE33]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The accuracy of the model is as follows:![Figure 8.13: Model final accuracy'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的准确度如下：![图 8.13：模型最终准确度
- en: '](img/C13322_08_13.jpg)'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13322_08_13.jpg)'
- en: 'Figure 8.13: Model final accuracy'
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.13：模型最终准确度
- en: We successfully made use of autokeras to create an image classifier that detects
    if the provided image is of a cat or a dog. The accuracy that we get with this
    model is 72% after an hour of running it which is pretty good considering that
    we got a 73% accuracy for the model that we created in *Chapter 6*, *Decoding
    Images*, *Activity 22*. This shows the power of autoML but, sometimes we do not
    get good enough results in an acceptable time frame.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们成功地利用 autokeras 创建了一个图像分类器，用于检测提供的图像是猫还是狗。经过一小时的运行，这个模型的准确率为 72%，考虑到我们在*第
    6 章*，*解码图像*，*活动 22* 中创建的模型准确率为 73%，这已经相当不错了。这显示了 AutoML 的强大功能，但有时我们在可接受的时间框架内可能无法获得足够好的结果。
- en: Model Visualization Using Keras
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Keras 进行模型可视化
- en: 'So far, we have created a bunch of neural network models but haven''t visualized
    any of them. Keras has a very handy utility function that plots any model. To
    create a plot first define the model, we will take the model created in *Chapter
    6*, *Decoding images*, as shown in the following code:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经创建了一些神经网络模型，但还没有可视化它们。Keras 提供了一个非常实用的工具函数，可以绘制任何模型的图。要创建一个图形，首先定义模型，我们将使用*第
    6 章*中的模型，*解码图像*，如下面的代码所示：
- en: '[PRE34]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: And then save the model as an image using `plot_model`, as shown in the following
    code.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用 `plot_model` 将模型保存为图像，如以下代码所示。
- en: '[PRE35]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The `show_shapes` argument gives the visualization the input and output shapes
    of the layers. The saved image is as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`show_shapes` 参数会展示层的输入和输出形状。保存的图像如下：'
- en: '![Figure 8.14: Model visualization created by Keras'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.14：由 Keras 创建的模型可视化'
- en: '](img/C13322_08_14.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_14.jpg)'
- en: 'Figure 8.14: Model visualization created by Keras'
  id: totrans-209
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.14：由 Keras 创建的模型可视化
- en: 'Activity 22: Using Transfer Learning to Predict Images'
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 22：使用迁移学习预测图像
- en: 'We will create a project where you perform transfer learning to predict whether
    a given picture is of a dog or a cat. The model that you will be using as a baseline
    will be InceptionV3\. We will fine-tune this model to our dataset and thus modify
    the model to distinguish between cats and dogs. We will use TensorBoard to monitor
    the training metrics in real time and use the best practices discussed in this
    chapter. Make sure that the results are reproducible:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个项目，使用迁移学习来预测给定图片是狗还是猫。你将使用的基准模型是 InceptionV3\。我们将对这个模型进行微调，以适应我们的数据集，从而将模型调整为区分猫和狗。我们将使用
    TensorBoard 实时监控训练指标，并使用本章中讨论的最佳实践。确保结果是可复现的：
- en: Repeat everything you did in *Step 1* from the previous activity.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复你在前一个活动中的*第 1 步*所做的一切。
- en: Load the development and test datasets, which will not be augmented.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载开发集和测试集，这些数据集将不会进行数据增强。
- en: Load the Inception model and add the final dense layers to it. Train the entire
    network.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 Inception 模型并添加最终的全连接层。训练整个网络。
- en: Make use of all useful callbacks.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用所有有用的回调函数。
- en: Visualize the training using TensorBoard.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 TensorBoard 可视化训练过程。
- en: Note
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 391.
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第 391 页找到。
- en: 'You can plot the incorrectly predicted images to get a sense of how well the
    model performs using the following snippet:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下代码片段绘制预测错误的图像，以了解模型的性能：
- en: '[PRE36]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The incorrectly predicted image is as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 错误预测的图像如下：
- en: '![Figure 8.15: The incorrectly predicted sample'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.15：错误预测的样本'
- en: '](img/C13322_08_15.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13322_08_15.jpg)'
- en: 'Figure 8.15: The incorrectly predicted sample'
  id: totrans-224
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.15：错误预测的样本
- en: Summary
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered transfer learning and leveraged it to create deep
    learning models faster. We then moved on to learn the importance of separate training,
    development, and test datasets, followed by a section on dealing with real-life,
    unprocessed datasets. After that, we talk about what AutoML is and how we can
    find the most optimal network with little to no work. We learned how to visualize
    neural network models and training logs.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了迁移学习并利用它加速深度学习模型的创建。接着我们学习了训练集、开发集和测试集分开的重要性，并讨论了如何处理现实生活中的未处理数据集。之后，我们讲解了什么是
    AutoML，以及如何以最少的工作量找到最优的网络。最后，我们学习了如何可视化神经网络模型和训练日志。
- en: Now that you have completed this chapter, you are now capable of handling any
    kind of data to create machine learning models.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经完成了本章的学习，具备了处理任何数据以创建机器学习模型的能力。
- en: Finally, having completed this book, you should now have a strong understanding
    of the concepts of data science, and should be able to use the Python language
    to work with different datasets to solve business-case problems. The different
    concepts that you have learned, including those of preprocessing, data visualization,
    image augmentation, and human language processing, should have helped in providing
    you with an overall grasp of how to work with data.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，完成本书后，你应该对数据科学的概念有一个深入的理解，并且能够使用 Python 语言处理不同的数据集来解决商业案例问题。你所学到的不同概念，包括预处理、数据可视化、图像增强和自然语言处理等，应该帮助你全面掌握如何处理数据。
