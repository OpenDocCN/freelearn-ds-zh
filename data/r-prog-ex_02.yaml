- en: Understanding Votes with Descriptive Statistics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用描述性统计理解投票
- en: This chapter shows how to perform a descriptive statistics analysis to get a
    general idea about the data we're dealing with, which is usually the first step
    in data analysis projects and is a basic ability for data analysts in general.
    We will learn how to clean and transform data, summarize data in a useful way,
    find specific observations, create various kinds of plots that provide intuition
    for the data, use correlations to understand relations among numerical variables,
    use principal components to find optimal variable combinations, and put everything
    together into code that is reusable, understandable, and easily modifiable.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了如何进行描述性统计分析，以获得我们处理的数据的一般概念，这通常是数据分析项目的第一步，也是数据分析师的基本能力。我们将学习如何清洗和转换数据，以有用的方式总结数据，找到特定的观察结果，创建各种类型的图表，以提供对数据的直观理解，使用相关性来理解数值变量之间的关系，使用主成分来找到最优变量组合，并将所有这些整合到可重用、可理解和易于修改的代码中。
- en: Since this is a book about programming with R and not about doing statistics
    with R, our focus will be on the programming side of things, not the statistical
    side. Keep that in mind while reading it.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这本书是关于使用 R 进行编程的，而不是使用 R 进行统计分析，因此我们的重点将放在编程方面，而不是统计方面。阅读时请记住这一点。
- en: 'Some of the important topics covered in this chapter are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖的一些重要主题如下：
- en: Cleaning, transforming, and operating on data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清洗、转换和操作数据
- en: Creating various kinds of graphs programmatically
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以编程方式创建各种类型的图表
- en: Performing qualitative analysis with various tools in R
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 R 中的各种工具进行定性分析
- en: Building new variables with Principal Components Analysis
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用主成分分析构建新变量
- en: Developing modular and flexible code that is easy to work with
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发模块化和灵活的代码，易于使用
- en: This chapter's required packages
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本章所需软件包
- en: During this chapter we will make use of the following R packages. If you don't
    already have them installed, you can look into [Appendix](part0296.html#8Q96G0-f494c932c729429fb734ce52cafce730)*,
    Required Packages *for instructions on how do so.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下 R 软件包。如果您还没有安装它们，可以查阅[附录](part0296.html#8Q96G0-f494c932c729429fb734ce52cafce730)*，所需软件包*部分，了解如何安装。
- en: '| **Package** | **Used for** |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| **软件包** | **用途** |'
- en: '| `ggplot2` | High-quality graphs |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| `ggplot2` | 高质量图表 |'
- en: '| `viridis` | Color palette for graphs |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| `viridis` | 图表颜色调色板 |'
- en: '| `corrplot` | Correlation plots |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| `corrplot` | 相关性图 |'
- en: '| `ggbiplot` | Principal components plots |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| `ggbiplot` | 主成分图 |'
- en: '| `progress` | Show progress for iterations |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| `progress` | 显示迭代的进度 |'
- en: The Brexit votes example
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Brexit 投票示例
- en: In June 2016, a referendum was held in the **United Kingdom** (**UK**) to decide
    whether or not to remain part of the **European Union** (**EU**). 72% of registered
    voters took part, and of those, 51.2% voted to leave the EU. In February 2017,
    Martin Rosenbaum, freedom of information specialist at BBC News, published the
    article, *Local Voting Figures Shed New Light on EU Referendum* ([http://www.bbc.co.uk/news/uk-politics-38762034](http://www.bbc.com/news/uk-politics-38762034)).
    He obtained data from 1,070 electoral wards (the smallest administrative division
    for electoral purposes in the UK), with numbers for **Leave** and **Remain** votes
    in each ward.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 2016 年 6 月，英国举行了一次公投，以决定是否继续留在欧盟。72% 的注册选民参与了投票，其中 51.2% 的人投票离开欧盟。2017 年 2 月，BBC
    新闻的自由信息专家马丁·罗森鲍姆发表了文章《地方投票数据为欧盟公投提供了新的见解》（[http://www.bbc.co.uk/news/uk-politics-38762034](http://www.bbc.com/news/uk-politics-38762034)）。他从
    1,070 个选区（英国用于选举的最小行政区域）获得了数据，包括每个选区的离开和留下投票数。
- en: 'Martin Rosenbaum calculated some statistical associations between the proportion
    of **Leave** votes in a ward and some of its social, economic, and demographic
    characteristics by making use of the most recent UK census, which was conducted
    in 2011\. He used his data for a university class, and that''s the data we will
    use in this example, with some variables removed. The data is provided in a CSV
    file (`data_brexit_referendum.csv`) which can be found in the accompanying code
    repository for this book ([https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example)).
    The table shows the variables included in the data:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 马丁·罗森鲍姆通过利用2011年进行的最新英国人口普查，计算了选区中**Leave**投票比例与其一些社会、经济和人口特征之间的统计关联。他使用这些数据为大学课程授课，这就是我们将在本例中使用的数据，其中一些变量已被删除。数据以CSV文件（`data_brexit_referendum.csv`）的形式提供，可以在本书的配套代码库中找到（[https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example)）。表格显示了数据中包含的变量：
- en: '![](img/00009.jpeg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00009.jpeg)'
- en: Data variable descriptions
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据变量描述
- en: Cleaning and setting up the data
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清理和设置数据
- en: Setting up the data for this example is straightforward. We will load the data,
    correctly label missing values, and create some new variables for our analysis.
    Before we start, make sure the `data.csv` file is in the same directory as the
    code you're working with, and that your *working directory* is properly setup.
    If you don't know how to do so, setting up your working directory is quite easy,
    you simply call the `setwd()` function passing the directory you want to use as
    such. For example, `setwd(/home/user/examples/)` would use the `/home/user/examples` directory
    to look for files, and save files to.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 设置本例的数据非常直接。我们将加载数据，正确标记缺失值，并为我们的分析创建一些新变量。在我们开始之前，请确保`data.csv`文件与你的代码在同一目录下，并且你的*工作目录*已正确设置。如果你不知道如何操作，设置工作目录相当简单，你只需调用`setwd()`函数，并传入你想要使用的目录即可。例如，`setwd(/home/user/examples/)`将会使用`/home/user/examples`目录来查找文件，并将文件保存到该目录。
- en: If you don’t know how to do so, setting up your working directory is quite easy,
    you simply call the `setwd()` function passing the directory you want to use as
    such. For example, `setwd(/home/user/examples/)` would use the /home/user/examples
    directory to look for files, and save files to.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不知道如何操作，设置工作目录相当简单，你只需调用`setwd()`函数，并传入你想要使用的目录即可。例如，`setwd(/home/user/examples/)`将会使用/home/user/examples目录来查找文件，并将文件保存到该目录。
- en: We can load the contents of the `data.csv` file into a data frame (the most
    intuitive structure to use with data in CSV format) by using the `read.csv()`
    function. Note that the data has some missing values in the `Leave` variable.
    These values have a value of `-1` to identify them. However, the proper way to
    identify missing values in R is with `NA`, which is what we use to replace the
    `-1` values.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用`read.csv()`函数将`data.csv`文件的内容加载到数据框中（这是与CSV格式数据最直观的结构）。请注意，数据中的`Leave`变量有一些缺失值。这些值具有`-1`的值来标识它们。然而，在R中标识缺失值的正确方式是使用`NA`，这是我们用来替换`-1`值的。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To count the number of missing values in our data, we can use the `is.na()`
    function to get a logical (Boolean) vector that contains `TRUE` values to identify
    missing values and `FALSE` values to identify non-missing values. The length of
    such a vector will be equal to the length of the vector used as input, which is
    the `Leave` variable in our case. Then, we can use this logical vector as input
    for `sum()` while leverage the way R treats such `TRUE/FALSE` values to get the
    number of missing values. `TRUE` is treated as `1`, while `FALSE` is treated as
    `0`. We find that the number of missing values in the `Leave` variable is 267.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算数据中缺失值的数量，我们可以使用`is.na()`函数来获取一个包含`TRUE`值以标识缺失值和`FALSE`值以标识非缺失值的逻辑（布尔）向量。这样一个向量的长度将与用作输入的向量的长度相等，在我们的例子中是`Leave`变量。然后，我们可以使用这个逻辑向量作为`sum()`函数的输入，同时利用R处理这样的`TRUE/FALSE`值的方式来获取缺失值的数量。`TRUE`被视为`1`，而`FALSE`被视为`0`。我们发现`Leave`变量中的缺失值数量为267。
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If we want to, we can use a mechanism to fill the missing values. A common and
    straightforward mechanism is to impute the variable's mean. In our case, in [Chapter
    3](part0076.html#28FAO0-f494c932c729429fb734ce52cafce730), *Predicting Votes with
    Linear Models*, we will use linear regression to estimate these missing values.
    However, we will keep things simple for now and just leave them as missing values.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想，我们可以使用一种机制来填充缺失值。一种常见且简单的方法是估计变量的平均值。在我们的案例中，在[第3章](part0076.html#28FAO0-f494c932c729429fb734ce52cafce730)，*使用线性模型预测投票*中，我们将使用线性回归来估计这些缺失值。然而，我们现在将保持简单，只将它们作为缺失值留下。
- en: 'We now proceed to defining a new variable, `Proportion`, which will contain
    the percentage of votes in favor of leaving the EU. To do so we divide the `Leave`
    variable (number of votes in favor of leaving) by the `NVotes` variable (number
    of votes in total), for each ward. Given the vectorized nature of R, this is straightforward:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们继续定义一个新变量，名为`Proportion`，它将包含支持离开欧盟的投票百分比。为此，我们将`Leave`变量（支持离开的投票数）除以`NVotes`变量（总投票数），对于每个选区。鉴于R的向量化特性，这很简单：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We are creating a new variable in the data frame by simply assigning to it.
    There's no difference between creating a new variable and modifying an existing
    one, which means that we need to be careful when doing so to make sure we're not
    overwriting an old variable by accident.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过简单地赋值来在数据框中创建一个新变量。创建新变量和修改现有变量之间没有区别，这意味着我们在这样做时需要小心，以确保我们没有意外地覆盖了旧变量。
- en: 'Now, create a new variable that contains a classification of whether most of
    the wards voted in favor of leaving or remaining in the EU. If more than 50 percent
    of each ward''s votes were in favor of leaving, then we will mark the ward as
    having voted for leaving, and vice versa for remaining. Again, R makes this very
    simple with the use of the `ifelse()` function. If the mentioned condition (first
    parameter) holds true, then the value assigned will be `"Leave"` (second parameter);
    otherwise it will be `"Remain"` (third parameter). This is a vectorized operation,
    so it will be done for each observation in the data frame:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建一个新变量，该变量包含对每个选区是否大多数投票支持离开或留在欧盟的分类。如果一个选区的投票超过50%支持离开，那么我们将标记该选区为投票支持离开，反之亦然。同样，R使用`ifelse()`函数使这个过程变得非常简单。如果提到的条件（第一个参数）为真，则分配的值将是`"Leave"`（第二个参数）；否则，它将是`"Remain"`（第三个参数）。这是一个向量化操作，因此它将对数据框中的每个观测值执行：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Sometimes, people like to use a different syntax for these types of operations;
    they will use a *subset-assign approach,* which is slightly different from what
    we used. We won''t go into the details of the differences among these approaches,
    but keep in mind that the latter approach may give you an error in our case:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，人们喜欢为这些类型的操作使用不同的语法；他们会使用*子集赋值方法*，这与我们使用的方法略有不同。我们不会深入探讨这些方法之间的差异，但请记住，在我们的情况下，后一种方法可能会产生错误：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This happens because the `Proportion` variable contains some missing values
    that were consequences of the `Leave` variable having some `NA` values in the
    first place. Since we can't compute a `Proportion` value for observations with
    `NA` values in `Leave`, when we create it, the corresponding values also get an
    `NA` value assigned.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为`Proportion`变量包含一些缺失值，这些缺失值是`Leave`变量最初有一些`NA`值的结果。由于我们无法为`Leave`中具有`NA`值的观测值计算`Proportion`值，当我们创建它时，相应的值也会被分配一个`NA`值。
- en: If we insist on using the *subset-assign approach,* we can make it work by using
    the `which()` function. It will ignore (returning as `FALSE`) those values that
    contain `NA` in the comparison. This way it won't give us an error, and we will
    get the same result as using the `ifelse()` function. We should use the `ifelse()`
    function when possible because it's simpler, easier to read, and more efficient
    (more about this in [Chapter 9](part0229.html#6QCGQ0-f494c932c729429fb734ce52cafce730), *Implementing
    an Efficient Simple Moving Average*).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们坚持使用*子集赋值方法*，我们可以通过使用`which()`函数使其工作。它将忽略（返回`FALSE`）那些比较中包含`NA`的值。这样它就不会产生错误，我们将会得到与使用`ifelse()`函数相同的结果。当可能时，我们应该使用`ifelse()`函数，因为它更简单，更容易阅读，并且更高效（更多关于这一点在第9章[第9章](part0229.html#6QCGQ0-f494c932c729429fb734ce52cafce730)，*实现高效的简单移动平均*)。
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Down the road we will want to create plots that include the `RegionName` information
    and having long names will most likely make them hard to read. To fix that we
    can shorten those names while we are in the process of cleaning the data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来，我们希望创建包含 `RegionName` 信息的图表，而长名称可能会使它们难以阅读。为了解决这个问题，我们可以在清理数据的过程中缩短这些名称。
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note that the first line in the previous code block is assigning a transformation
    of the `RegionName` into character type. Before we do this, the type of the variable
    is factor (which comes from the default way of reading data with `read.csv()`),
    and it prevents us from assigning a different value from the ones already contained
    in the variable. In such a case, we will get an error, `Invalid factor level,
    NA generated`. To avoid this problem, we need to perform the type transformation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到上一个代码块中的第一行是将 `RegionName` 转换为字符类型的赋值。在我们这样做之前，变量的类型是因子（这是使用 `read.csv()`
    读取数据的默认方式产生的），它阻止我们从变量中分配不同的值。在这种情况下，我们会得到一个错误，`Invalid factor level, NA generated`。为了避免这个问题，我们需要执行类型转换。
- en: We now have clean data ready for analysis. We have created a new variable of
    interest for us (`Proportion`), which will be the focus of the rest of this chapter
    and the next one, since in this example, we're interested in finding out the relations
    among other variables and how people voted in the referendum.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了干净的数据，准备进行分析。我们创建了一个新的感兴趣变量（`Proportion`），这将是本章和下一章的焦点，因为在这个例子中，我们感兴趣的是找出其他变量之间的关系以及人们在公投中的投票情况。
- en: Summarizing the data into a data frame
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据汇总到数据框中
- en: To get a summary of the data, we may execute `summary(data)` and see the relevant
    summaries for each type of variable. The summary is tailored for each column's
    data type. As you can see, numerical variables such as `ID` and `NVotes` get a
    quantile summary, while factor (categorical) variables get a count for each different
    category, such as `AreaType` and `RegionName`. If there are many categories, the
    summary will show the categories that appear the most and group the rest into
    a (`Other`) group, as we can see at the bottom of `RegionName`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取数据的概要，我们可以执行 `summary(data)` 并查看每种类型变量的相关概要。概要针对每一列的数据类型进行了定制。正如您所看到的，数值变量，如
    `ID` 和 `NVotes`，会得到分位数概要，而因子（分类）变量会为每个不同的类别提供计数，例如 `AreaType` 和 `RegionName`。如果有许多类别，概要将显示出现次数最多的类别，并将其余的类别归入一个（其他）组，正如我们在
    `RegionName` 的底部所看到的。
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'From here, we can see that London is the region to which more wards belong,
    followed by the North West and West Midlands. We can also see that the ward with
    the least votes in all of the data had only 1,039 votes, the one with the most
    votes had 15,148, and the mean number of votes per ward was 5,703\. We will take
    a deeper look into these kinds of analyses later in the chapter. For now we''ll
    focus on making this summary data useful for further analysis. As you may have
    noticed, we can''t use the `summary()` results to make computations. We can try
    to save the summary into a variable, find out the variable type, and traverse
    it in an appropriate way. However, if we do that we will find that it''s text
    data, which means that we can''t use it for computations as it is:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以看到伦敦是拥有更多选区的地区，其次是西北部和西米德兰兹。我们还可以看到，所有数据中投票最少的选区只有 1,039 票，投票最多的是 15,148
    票，每个选区的平均投票数是 5,703。我们将在本章的后面部分更深入地探讨这类分析。现在，我们将专注于使这些汇总数据对进一步分析有用。如您所注意到的，我们无法使用
    `summary()` 的结果进行计算。我们可以尝试将概要保存到变量中，找出变量类型，并以适当的方式遍历它。然而，如果我们这样做，我们会发现它是文本数据，这意味着我们不能直接用它进行计算：
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Surely, there must be a way to get the `summary` data into a data frame for
    further analysis. This is R, so you can bet there is! The first thing we should
    note is that we can't directly translate the output of the `summary()` function
    into a data frame because of the non-numerical variables. These non-numerical
    variables contain a different summary structure which is not composed of the minimum,
    first quartile, median, mean, third quartile, and maximum values. This means that
    we first need to subset the data to get only the numerical variables. After all,
    a data frame is a rectangular structure with well defined rows and columns. If
    we tried to mix types (by including numerical and non-numerical summaries) into
    the data frame, we would have a hard time doing so.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，肯定有办法将 `summary` 数据放入数据框中进行进一步分析。这是R，所以你可以确信有！我们应该注意的第一件事是，由于非数值变量，我们无法直接将
    `summary()` 函数的输出转换为数据框。这些非数值变量包含不同的摘要结构，该结构不是由最小值、第一四分位数、中位数、平均值、第三四分位数和最大值组成的。这意味着我们首先需要子集数据，以仅获取数值变量。毕竟，数据框是一个具有良好定义的行和列的矩形结构。如果我们试图混合类型（通过包括数值和非数值摘要），那么在数据框中这样做将会很困难。
- en: 'To find if a column is numeric or not, we can use the `is.numeric()` function.
    For example, we can see that the `Proportion` column is numeric and the `RegionName`
    is not:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查一列是否为数值，我们可以使用 `is.numeric()` 函数。例如，我们可以看到 `Proportion` 列是数值的，而 `RegionName`
    则不是：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can then apply `is.numeric()` to each column by using the `sapply()` function.
    This will give us a logical (Boolean) vector with a `TRUE` or `FALSE` value for
    each column, indicating whether or not it''s numeric. Then we can use this logical
    vector to subset our data and get only the numerical columns with `data[, numerical_variables]`.
    As you can see, there are no non-numerical columns in the `data_numerical` object:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过使用 `sapply()` 函数将 `is.numeric()` 应用于每个列。这将给我们一个逻辑（布尔）向量，其中每个列都有一个 `TRUE`
    或 `FALSE` 值，指示该列是否为数值。然后我们可以使用这个逻辑向量来子集我们的数据，并仅获取具有 `data[, numerical_variables]`
    的数值列。正如你所见，`data_numerical` 对象中没有非数值列：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Since it doesn''t make much sense to get the `summary` values for the `ID`
    variable, we can remove it from the logical vector, effectively treating it as
    a non-numerical variable. If we do, we must remember to recreate the `data_numeric`
    object to make sure it doesn''t include the `ID` variable also:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于获取 `ID` 变量的 `summary` 值没有太多意义，我们可以将其从逻辑向量中移除，实际上将其视为非数值变量。如果我们这样做，我们必须记住重新创建
    `data_numeric` 对象，以确保它不包含 `ID` 变量：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To create our numerical variables summary, we first will apply the `summary()`
    function we used before to each numerical column using the `lapply()` function.
    The `lapply()` function returns a named list, where each list member has the corresponding
    column name:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建我们的数值变量摘要，我们首先将使用之前使用的 `summary()` 函数，通过 `lapply()` 函数将其应用于每个数值列。`lapply()`
    函数返回一个命名列表，其中每个列表成员都有相应的列名：
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now we need to put each member of this list together into a data frame. To do
    so, we will use the `cbind()` and `do.call()` functions. `do.call()` will consecutively
    apply `cbind()` to each member of the list generated by `lapply()` and return
    them all together. To get a reminder on how these vectorized operations work,
    take a look at [Chapter 1](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730),
    *Introduction to R:*
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要将这个列表的每个成员组合成一个数据框。为此，我们将使用 `cbind()` 和 `do.call()` 函数。`do.call()` 将依次将
    `cbind()` 应用于由 `lapply()` 生成的列表的每个成员，并将它们全部返回。要了解这些向量化操作是如何工作的，请参阅[第1章](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730)，*R语言简介*：
- en: '[PRE13]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We got our results, but not so fast! We got a warning, and it looks suspicious.
    What does this `number of rows of result is not a multiple of vector length` message
    mean? Aha! If we take a more detailed look at the list we previously got from
    our `lapply()` function, we can see that in the case of `Leave` (and `Proportion`)
    we get an extra column for `NAs` that we don't get for any other column. That
    means that when we try to use `cbind()` on these columns, the extra `NAs` column
    will create an extra space that needs to be filled. This is a problem we looked
    at in [Chapter 1](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730), *Intro**duction
    to R*.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了我们的结果，但别急着走！我们得到了一个警告，看起来很可疑。这个“结果行数不是向量长度的倍数”信息是什么意思？啊哈！如果我们更详细地查看我们之前从
    `lapply()` 函数得到的列表，我们可以看到在 `Leave`（和 `Proportion`）的情况下，我们得到了一个额外的 `NAs` 列，而其他任何列都没有。这意味着当我们尝试对这些列使用
    `cbind()` 时，额外的 `NAs` 列将创建一个需要填充的额外空间。这是我们之前在 [第1章](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730)，*R语言入门*
    中探讨过的问题。
- en: As we saw, then, R deals with it by repeating the vectors in order until all
    spaces are filled. In our case this means that the first element, the one corresponding
    to the minimum value, will be repeated for the `NAs` space for each column that
    doesn't have an `NAs` space. You can verify this by comparing the numbers of the
    `Min` and `NAs` columns for variables other than `Leave` or `Proportion` (for
    these two, the values should actually be different).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，R 通过重复向量直到所有空间都被填满来处理这个问题。在我们的情况下，这意味着第一个元素，即对应最小值的元素，将重复用于每个没有 `NAs`
    空间的列的 `NAs` 空间。你可以通过比较除了 `Leave` 或 `Proportion` 之外变量的 `Min` 和 `NAs` 列的数字来验证这一点（对于这两个变量，值实际上应该是不同的）。
- en: 'To fix it we can just remove the extra `NA` value''s row from the resulting
    data frame, but this would not deal with the warning''s source, only the symptom.
    To deal with the source, we need to have the  same number of columns for each
    variable before we apply `cbind()`. Since we already know that we have 267 missing
    values for the `Leave` variable, which then affects the `Proportion` variable,
    we can easily fix this by just ignoring that information. To do so, we simply
    use the *complete cases*, meaning that we keep observations that don''t have any
    `NA` values in any of their variables; or, put another way, we drop every observation
    that contains at least one `NA`. Once we do that, we get our results back and
    we don''t get any warnings:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们只需从结果数据框中移除额外的 `NA` 值的行，但这只会处理警告的症状，而不是根源。要处理根源，我们需要在应用 `cbind()`
    之前为每个变量有相同数量的列。由于我们已经知道 `Leave` 变量有 267 个缺失值，这随后影响了 `Proportion` 变量，我们可以很容易地通过忽略这些信息来解决这个问题。为此，我们只需使用
    *完整案例*，这意味着我们保留那些在任何变量中都没有 `NA` 值的观测值；或者，换句话说，我们删除包含至少一个 `NA` 的任何观测值。一旦我们这样做，我们就会得到我们的结果，并且不会得到任何警告：
- en: '[PRE14]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If we want to get the summary values as columns and the variables as rows,
    we can use the `rbind()` function instead of `cbind()`. The structure we actually
    end up using will depend on what we want to do with it. However, we can easily
    change between them later if we need to:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想将汇总值作为列，变量作为行，我们可以使用 `rbind()` 函数而不是 `cbind()`。我们最终使用的结构将取决于我们想用它做什么。然而，如果我们需要，我们可以很容易地在它们之间进行转换：
- en: '[PRE15]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now that we have this `numerical_summary` object, we can use it to perform
    computations, such as finding the range between the wards with the least and most
    proportions of votes in favor of leaving (0.6681), which may be useful to interpret
    the big difference among the *types* of wards we may find in the UK. If we want
    to know which wards are being used to get to this result, we can search for the
    wards with the least and most proportion of votes:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了这个 `numerical_summary` 对象，我们可以用它来进行计算，例如找出赞成离开（0.6681）比例最少和最多的区域之间的范围，这可能有助于解释我们在英国可能发现的区域类型之间的巨大差异。如果我们想知道哪些区域被用来得到这个结果，我们可以搜索赞成比例最少和最多的区域：
- en: '[PRE16]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you can see, this analysis already shows some interesting results. The UK
    ward that voted to leave the EU the most is characterized by older people (`MeanAge`)
    with low education levels (`NoQuals`, `L4Quals_plus`). On the other hand, the
    UK ward that voted to remain in the EU the most is characterized by younger people
    with much higher education levels. Of course, this is not the full picture, but
    it's a hint about the direction in which we need to look to further understand
    what's going on. For now, we have found that education and age seem to be relevant
    variables for the analysis.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这项分析已经显示了一些有趣的结果。投票离开欧盟最多的英国区域特点是老年人（`MeanAge`）和低教育水平（`NoQuals`，`L4Quals_plus`）。另一方面，投票留在欧盟最多的英国区域特点是年轻人，教育水平很高。当然，这并不是全部情况，但它提示我们需要进一步了解正在发生的事情的方向。到目前为止，我们发现教育和年龄似乎是分析的相关变量。
- en: Getting intuition with graphs and correlations
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过图表和相关性获得直观感受
- en: Now that we have some clean data to work with, we will create lots of plots
    to build intuition about the data. In this chapter, we will work with plots that
    are easy to create and are used for exploratory purposes. In [Chapter 4](part0091.html#2MP360-f494c932c729429fb734ce52cafce730),
    *Simulating Sales Data and Working with Databases,* we will look into publication
    ready plots that are a little more verbose to create.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一些干净的数据可以处理，我们将创建许多图表来建立对数据的直观理解。在本章中，我们将处理易于创建且用于探索目的的图表。在[第4章](part0091.html#2MP360-f494c932c729429fb734ce52cafce730)“模拟销售数据和数据库操作”中，我们将探讨创建起来稍微复杂一些的、可用于发表的图表。
- en: Visualizing variable distributions
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化变量分布
- en: Our first plot is a simple one and shows the proportion of votes by each `RegionName`.
    As you can see in the plot shown below, the London, North West, and West Midlands
    regions account for around 55 percent of the observations in the data.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一张图表非常简单，显示了每个`RegionName`的投票比例。如图下所示，伦敦、西北部和西米德兰兹地区的观测值占数据中的约55%。
- en: '![](img/00010.jpeg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00010.jpeg)'
- en: Vote Proportion by Region
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 按区域投票比例
- en: To create the plot, we need to create a table for the frequencies of each region
    in `RegionName` with the `table()` function, then we feed that to the `prop.table()`
    function, which computes the corresponding proportions, which in turn are used
    as heights for each bar.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建图表，我们需要使用`table()`函数为`RegionName`中的每个区域的频率创建一个表格，然后将这个表格输入到`prop.table()`函数中，该函数计算相应的比例，这些比例随后被用作每个条形的高度。
- en: 'We use the `barplot()` function to produce the plot, and we can specify some
    options, such as the title (`main`), the *y* axis label (`ylab`), and the color
    for the bars (`col`). As always, you can find out more about in the function''s
    parameters with `? barplot`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`barplot()`函数来生成图表，并且可以指定一些选项，例如标题（`main`）、y轴标签（`ylab`）和条形的颜色（`col`）。和往常一样，你可以通过`?
    barplot`来了解该函数的更多参数：
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Our next plot, shown below, is a little more eye-catching. Each point represents
    a ward observation, and it shows the `Proportion` of `Leave` votes for each ward,
    arranged in vertical lines corresponding to `RegionName` and colored by the proportion
    of white population for each ward. As you can see, we have another interesting
    finding; it seems that the more diversified a ward's population is (seen in the
    darker points), the more likely it is for the ward to vote in favor of remaining
    in the EU (a lower `Proportion` value).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来的图表，如图下所示，更具吸引力。每个点代表一个区域观测值，它显示了每个区域的`Leave`投票比例，这些比例按照`RegionName`对应的垂直线排列，并按每个区域的白色人口比例着色。如图所示，我们还有另一个有趣的发现；似乎一个区域的居民人口越多元化（在较暗的点中可见），该区域投票支持留在欧盟的可能性就越大（`Proportion`值较低）。
- en: '![](img/00011.jpeg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00011.jpeg)'
- en: Proportion by RegionName and White Population Percentage
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 按区域名称和白色人口百分比的比例
- en: 'To create the plot, we need to load the `ggplot2` and `viridis` packages; the
    first one will be used to create the actual plot, while the second one will be
    used to color the points with a scientifically interesting color palette called
    **Viridis** (it comes from color perception research done by Nathaniel Smith and
    Stéfan van der Walt, [http://bids.github.io/colormap/](http://bids.github.io/colormap/)).
    The details of the `ggplot2` syntax will be explained in [Chapter 4](part0091.html#2MP360-f494c932c729429fb734ce52cafce730),
    *Simulating Sales Data and Working with Databases*, but for now, all you need
    to know is that the function receives as a first parameter the data frame with
    the data that will be used for the plot, and as a second parameter an aesthetics
    object (`aes`), created with the `aes()` function, which in turn can receive parameters
    for the variable that should be used in the *x* axis, *y* axis, and color. After
    that, we add a *points layer* with the `geom_points()` function, and the Viridis
    color palette with the `scale_color_viridis()` function. Notice how we are adding
    plot objects while we work with `ggplot2`. This is a very convenient feature that
    provides a lot of power and flexibility. Finally, we show the plot with the `print()`
    function (in R, some functions used for plotting immediately show the plot (for
    example, `barplot`), while others return a plot object (for example, `ggplot2`)
    and need to be printed explicitly):'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建图表，我们需要加载`ggplot2`和`viridis`包；第一个包将用于创建实际的图表，而第二个包将用于使用名为**Viridis**的科学色彩调色板（它来自Nathaniel
    Smith和Stéfan van der Walt进行的颜色感知研究，[http://bids.github.io/colormap/](http://bids.github.io/colormap/)）来着色点。`ggplot2`语法的细节将在[第4章](part0091.html#2MP360-f494c932c729429fb734ce52cafce730)，*模拟销售数据和数据库操作*中解释，但就现在而言，你需要知道的是，该函数将数据框作为第一个参数接收，该数据框包含用于图表的数据，并将`aes`对象作为第二个参数接收，该对象通过`aes()`函数创建，它可以接收用于*x*轴、*y*轴和颜色的参数。之后，我们使用`geom_points()`函数添加一个*点层*，并使用`scale_color_viridis()`函数添加Viridis色彩调色板。注意我们在使用`ggplot2`时添加图表对象的方式。这是一个非常方便的功能，提供了很多功能和灵活性。最后，我们使用`print()`函数（在R中，一些用于绘图的函数会立即显示图表（例如，`barplot`），而其他函数返回一个图表对象（例如，`ggplot2`）并需要显式打印）来显示图表：
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The next set of plots, shown below, display histograms for the `NoQuals`, `L4Quals_plus`,
    and `AdultMeanAge` variables. As you can see, the `NoQuals` variable appears to
    be normally distributed, but the `L4Quals_plus` and `AdultMeanAge` variables seemed
    to be skewed towards the left and right, correspondingly. These tell us that most
    people in the sample don't have high education levels and are past 45 years of
    age.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表集显示了`NoQuals`、`L4Quals_plus`和`AdultMeanAge`变量的直方图。正如你所见，`NoQuals`变量似乎呈正态分布，但`L4Quals_plus`和`AdultMeanAge`变量似乎分别向左和向右偏斜。这告诉我们，样本中的大多数人教育水平不高，年龄超过45岁。
- en: '![](img/00012.jpeg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00012.jpeg)'
- en: Histogram for NoQuals, L4Quals_plus, and AdultMeanAge
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: NoQuals、L4Quals_plus和AdultMeanAge的直方图
- en: Creating these plots is simple enough; you just need to pass the variable that
    will be used for the histogram into the `hist()` function, and optionally specify
    a title and *x* axis label for the plots (which we leave empty, as the information
    is already in the plot's title).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 创建这些图表很简单；你只需将用于直方图的变量传递给`hist()`函数，并且可以可选地指定图表的标题和*x*轴标签（我们将其留空，因为信息已经在图表的标题中了）。
- en: For the book, we arranged plots in such a way that their spacing and understanding
    is efficient, but when you create the plots using the code shown, you'll see them
    one by one. There are ways to group various plots together, but we'll look at
    them in [Chapter 4](part0091.html#2MP360-f494c932c729429fb734ce52cafce730), *Simulating
    Sales Data and Working with Databases*).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这本书，我们以这种方式排列图表，使其间距和理解效率更高，但当你使用显示的代码创建图表时，你会逐个看到它们。有方法可以将各种图表组合在一起，但我们将它们放在[第4章](part0091.html#2MP360-f494c932c729429fb734ce52cafce730)，*模拟销售数据和数据库操作*中讨论。
- en: 'Let''s have a look at the following code:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下以下代码：
- en: '[PRE19]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now that we understand a bit more about the distribution of the `NoQuals`, `L4Quals_plus`,
    and `AdultMeanAge` variables, we will see their joint-distribution in the scatter
    plots shown below. We can see how these scatter plots resemble the histograms
    by comparing the *x* axis and *y* axis in the scatter plots to the corresponding *x* axis
    in the histograms, and comparing the frequency (height) in the histograms with
    the point density in the scatter plots.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对`NoQuals`、`L4Quals_plus`和`AdultMeanAge`变量的分布有了更多了解，我们将看到它们在下面显示的散点图中的联合分布。我们可以通过比较散点图中的*x*轴和*y*轴与直方图中的相应*x*轴，以及比较直方图中的频率（高度）与散点图中的点密度，来看到这些散点图如何类似于直方图。
- en: '![](img/00013.jpeg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00013.jpeg)'
- en: Scatter plots for NoQuals, L4Quals_plus vs AdultMeanAge
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: NoQuals与L4Quals_plus对成人平均年龄的散点图
- en: We find a slight relation that shows that the older the people, the lower the
    levels of education they have. This can be interpreted in a number of ways, but
    we'll leave that as an exercise, to keep focus on the programming, not the statistics.
    Creating these scatter plots is also very simple. Just send the `x` and `y` variables
    to the `plot()` function, and optionally specify labels for the axes.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现了一个轻微的关系，表明人们越老，他们的教育水平就越低。这可以有多种解释，但我们将其留作练习，以保持对编程的关注，而不是对统计学的关注。创建这些散点图也非常简单。只需将`x`和`y`变量发送到`plot()`函数，并可选地指定轴标签。
- en: '[PRE20]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Using matrix scatter plots for a quick overview
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用矩阵散点图进行快速概述
- en: What happens if we want to visualize a lot of scatter plots in a single graph
    to quickly get a sense for the data? In that case, we need *matrix scatter plots*.
    We have various package options to create such matrix scatter plots (such as the
    `car` package). However, to keep things simple, we will use a built-in function
    instead of an external package.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想在单个图中可视化许多散点图以快速了解数据，会发生什么？在这种情况下，我们需要*矩阵散点图*。我们有各种包选项来创建此类矩阵散点图（例如`car`包）。然而，为了保持简单，我们将使用内置函数而不是外部包。
- en: By looking at the graph shown below, we can get a big-picture view of the interactions
    among variables. The purpose of this type of visualization is not to provide details,
    but to provide a general overview. To read this plot we need to look at any interesting
    scatter plot in the matrix, and move both horizontally and vertically until we
    find the name associated with its axis.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看下面的图表，我们可以获得变量之间相互作用的整体视图。此类可视化的目的不是提供细节，而是提供一个一般性的概述。要阅读此图，我们需要查看矩阵中的任何有趣的散点图，并水平垂直移动，直到找到与其轴相关联的名称。
- en: For example, if you look at the plot immediately to the right of `NoQuals` and
    simultaneously immediately on top of `L4Quals_plus`, what you're looking at is
    at the relation between those two variables (`NoQuals` in the *y* axis, `L4Quals_plus`
    in the *x* axis), and we find that it's an inverse relation; the higher the percentage
    of people in a ward with high levels of education, the lower the percentage of
    people with low levels of education. Another obvious relation is that the higher
    the education level (`L4Quals_plus`), the higher the occupation (`HigherOccup`).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你看`NoQuals`右侧的图，同时立即在`L4Quals_plus`上方，你所看到的是这两个变量之间的关系（`NoQuals`在*y*轴上，`L4Quals_plus`在*x*轴上），我们发现这是一种反向关系；一个区域中受过高等教育的人的百分比越高，受过低教育的人的百分比就越低。另一个明显的关联是，教育水平（`L4Quals_plus`）越高，职业（`HigherOccup`）就越高。
- en: '![](img/00014.jpeg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00014.jpeg)'
- en: Matrix scatter plot
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵散点图
- en: 'Due to space restrictions, we were not able to show all variable relations,
    since the scatter plots would be too small to make sense of. However, we encourage
    the reader to add more variables to the matrix. There are some non-obvious relations.
    Finding them is left as an exercise for the reader:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 由于空间限制，我们无法显示所有变量关系，因为散点图会太小而无法理解。然而，我们鼓励读者将更多变量添加到矩阵中。有一些不明显的关系。找到它们留给读者作为练习：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Getting a better look with detailed scatter plots
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过详细的散点图获得更好的视角
- en: 'Now that we know how to get a big-picture view of the scatter plots to get
    a general sense of the relations among variables, how can we get a more detailed
    look into each scatter plot? Well, I''m glad you asked! To achieve this, we''ll
    do it in two steps. First, we are going to work on producing a single, detailed
    scatter plot that we''re happy with. Second, we''re going to develop a simple
    algorithm that will traverse all variable combinations and create the corresponding
    plot for each of them:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何从散点图中获得整体视图，以获得变量之间关系的总体感觉，那么我们如何能够更详细地查看每个散点图呢？嗯，很高兴你提出了这个问题！为了实现这一点，我们将分两步进行。首先，我们将努力制作一个单一、详细的散点图，让我们感到满意。其次，我们将开发一个简单的算法，该算法将遍历所有变量组合，并为每个组合创建相应的图表：
- en: '![](img/00015.jpeg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00015.jpeg)'
- en: Scatter plot for NoQuals vs AdultMeanAge vs Proportion with Regression Line
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图：NoQuals 对 AdultMeanAge 对 Proportion 与回归线
- en: The graph shown above shows our prototype scatter plot. It has a combination
    of variables in the `x` and `y` axes, `NoQuals` and `AdultMeanAge` in our case,
    assigns a color according to the corresponding `Proportion`, and places a line
    corresponding to a linear regression on top to get a general sense of the relation
    among the variables in the axes. Compare this plot to the left scatter plot of
    previous pair of scatter plots. They are the same plot, but this one is more detailed
    and conveys more information. This plot seems good enough for now.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 上图所示的是我们的原型散点图。它在`x`和`y`轴上组合了变量，在我们的例子中是`NoQuals`和`AdultMeanAge`，根据相应的`Proportion`分配颜色，并在顶部放置一条对应线性回归的线，以获得轴上变量之间关系的总体感觉。将此图与之前一对散点图中的左侧散点图进行比较。它们是同一个图，但这个图更详细，传达了更多信息。这个图现在看起来已经足够好了。
- en: '[PRE22]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now we need to develop the algorithm that will take all variable combinations
    and create the corresponding plots. We present the full algorithm and explain
    part by part. As you can see, we start defining the `create_graphs_iteratively`
    function, which receives two parameters: the `data` and the `plot_function`. The
    algorithm will get the variable names for the data and store them in the `vars`
    variables. It will then remove `Proportion` from such variables, because they
    will be used to create the combinations for the axis, and `Proportion` will never
    be used in the axis; it will be used exclusively for the colors.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要开发一个算法，该算法将接受所有变量组合并创建相应的图表。我们展示了完整的算法，并逐部分进行解释。正如你所看到的，我们开始定义`create_graphs_iteratively`函数，它接受两个参数：`data`和`plot_function`。该算法将获取数据的变量名称并将它们存储在`vars`变量中。然后它将从这些变量中移除`Proportion`，因为它们将被用来创建轴的组合，而`Proportion`将永远不会用于轴；它将仅用于颜色。
- en: Now, if we imagine all the variable combinations in a matrix like the one for
    the matrix scatter plot shown previously, then we need to traverse the upper triangle
    or the lower triangle to get all possible combinations (in fact, the upper and
    lower triangles from matrix of scatter plots are symmetrical because they convey
    the same information). To traverse these triangles, we can use a *known pattern,*
    which uses two for-loops, each for one axis, and where the inner loop need only
    start at the position of the outer loop (this is what forms a triangle). The `-1`
    and `+1` are there to make sure we start and finish in appropriate places in each
    loop without getting an error for array boundaries.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们想象所有变量组合在一个矩阵中，就像之前显示的矩阵散点图那样，那么我们需要遍历上三角形或下三角形以获得所有可能的组合（实际上，散点图的矩阵的上三角形和下三角形是对称的，因为它们传达相同的信息）。为了遍历这些三角形，我们可以使用一个*已知模式*，它使用两个for循环，每个循环对应一个轴，内循环只需要从外循环的位置开始（这就是形成三角形的原因）。`-1`和`+1`的存在是为了确保我们在每个循环中开始和结束在适当的位置，而不会因为数组边界错误而出现错误。
- en: Inside the inner loop is where we will create the name for the plot as a combination
    of the variable names and concatenate them using the `paste()` function, as well
    as create the plot with the `plot_function` we will send as a parameter (more
    on this ahead). The `png()` and `dev.off()` functions are there to save the plots
    to the computer's hard drive. Think of the `png()` function as the place where
    R starts looking for a graph, and `dev.off()` as the place where it stops the
    saving process. Feel free to look into their documentation or read more about *devices*
    in R.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在内循环内部，我们将创建图表的名称，它是变量名称的组合，并使用`paste()`函数将它们连接起来，同时使用我们将作为参数发送的`plot_function`创建图表（关于这一点后面会详细介绍）。`png()`和`dev.off()`函数用于将图表保存到计算机的硬盘上。将`png()`函数视为R开始寻找图形的地方，将`dev.off()`视为停止保存过程的地方。您可以自由查看它们的文档或阅读更多关于R中的*设备*的信息。
- en: '[PRE23]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We''re almost done; we just need to wrap the code we used to turn our plot
    prototype into a function and we will be all set. As you can see, we extracted
    the `x`, `y`, and `color` parameters for the `aes()` function as variables that
    are sent as parameters to the function (this is called **parametrizing arguments**),
    and we switched the `aes()` function with the `aes_string()` function, which is
    able to receive variables with strings for the parameters. We also added the option
    to send the `var_color` as `FALSE` to avoid using a color-version of the plot.
    Everything else is kept the same:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎完成了；我们只需将我们用来将绘图原型转换为函数的代码包装起来，我们就可以一切就绪。正如你所见，我们提取了`x`、`y`和`color`参数作为变量，并将它们作为参数发送给函数（这被称为**参数化参数**），并且我们将`aes()`函数替换为`aes_string()`函数，后者能够接收带有字符串参数的变量。我们还添加了将`var_color`作为`FALSE`发送的选项，以避免使用带有颜色的图表版本。其他一切保持不变：
- en: '[PRE24]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Since we will be checking in various places whether the `save_to` string is
    empty, we name the check and wrap it in the `not_empty()` function. Now it's a
    bit easier to read our code.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将在多个地方检查`save_to`字符串是否为空，因此我们给检查命名，并将其包装在`not_empty()`函数中。现在阅读我们的代码稍微容易一些。
- en: '[PRE25]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: With this `prototype_scatter_plot()` function, we can re-create the right scatter
    plots shown previously, as well as any other variable combination, quite easily.
    This seems pretty powerful, doesn't it?
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个`prototype_scatter_plot()`函数，我们可以轻松地重新创建之前显示的正确散点图，以及任何其他变量组合。这似乎非常强大，不是吗？
- en: '![](img/00016.jpeg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00016.jpeg)'
- en: Scatter plot for L4Quals_plus vs AdultMeanAge vs Proportion with Regression
    Line
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: L4Quals_plus与AdultMeanAge与Proportion的散点图，带有回归线
- en: 'Let''s have a look at the following code:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下代码：
- en: '[PRE26]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now that we have done the hard work, we can create all possible combinations
    quite easily. We just need to call the `create_plots_iteratively()` function with
    our data and the `prototype_scatter_plot()` function. Using functions as parameters
    for other functions is known as the **strategy pattern**. The name comes from
    the fact that we can easily change our strategy for plotting for any other one
    we want that receives the same parameters (`data`, `var_x`, and `var_y`) to create
    plots, without having to change our algorithm to traverse the variable combinations.
    This kind of flexibility is very powerful:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了艰苦的工作，我们可以非常容易地创建所有可能的组合。我们只需调用`create_plots_iteratively()`函数并传入我们的数据和`prototype_scatter_plot()`函数。将函数作为其他函数的参数使用称为**策略模式**。这个名字来源于我们可以轻松地更改我们的绘图策略，以适应任何其他我们想要的接收相同参数（`data`、`var_x`和`var_y`）以创建图表的策略，而无需更改我们的遍历变量组合的算法。这种灵活性非常强大：
- en: '[PRE27]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This will create all the plots for us and save them to our hard drive. Pretty
    cool, huh? Now we can look at each of them independently and do whatever we need
    with them, as we already have them as PNG files.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们创建所有图表并将它们保存到我们的硬盘上。很酷，不是吗？现在我们可以独立查看每一个，并使用它们做我们需要的任何事情，因为我们已经将它们作为PNG文件拥有了。
- en: Understanding interactions with correlations
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解相关性中的交互作用
- en: The correlation is a measure of the linear relation among two variables. Its
    value ranges from `-1`, representing a perfect inverse relation, to `1`, representing
    a perfect direct relation. Just as we created a matrix of scatter plots, we will
    now create a matrix of correlations, and resulting graph is shown below. Large
    circles mean high absolute correlation. Blue circles mean positive correlation,
    while red circles mean negative correlation.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 相关系数是衡量两个变量之间线性关系的一个度量。其值范围从`-1`（表示完美的反比关系）到`1`（表示完美的正比关系）。正如我们创建了散点图的矩阵，我们现在将创建相关性的矩阵，下面是得到的图形。大圆圈表示高绝对相关性。蓝色圆圈表示正相关，而红色圆圈表示负相关。
- en: To create this plot we will use the `corrplot()` function from the `corrplot`
    package, and pass it the correlations data computed by the `cor()` function in
    R, and optionally some parameters for the text labels (`tl`), such as color (`color`)
    and size (`cex`).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建这个图，我们将使用`corrplot()`函数从`corrplot`包中，并传递由R中的`cor()`函数计算的相关性数据，以及可选的文本标签参数（如颜色`color`和大小`cex`）。
- en: '![](img/00017.jpeg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00017.jpeg)'
- en: Variable Correlations
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 变量相关性
- en: 'Now, let''s look at the following code:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一下以下代码：
- en: '[PRE28]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'If we look at the relation among the `Proportion` variable and the other variables,
    variables in large blue circles are positively correlated with it, meaning that
    the more that variable increases, the more likely it is for the `Proportion` variable
    to also increase. For examples of this type, look at the relations among `AdultMeanAge`
    and `NoQuals` with `Proportion`. If we find large red circles among `Proportion`
    and other variables, it means that the more that variable increases, the more
    `Proportion` is likely to decrease. For examples of this type, look at the relations
    among `Age_25to29`, `Age_30to44`, and `L4Quals_plus` with `Proportion`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看`Proportion`变量与其他变量之间的关系，大蓝色圆圈中的变量与它呈正相关，这意味着该变量增加得越多，`Proportion`变量也增加的可能性就越大。例如，查看`AdultMeanAge`和`NoQuals`与`Proportion`之间的关系。如果我们发现`Proportion`与其他变量之间存在大红色圆圈，这意味着该变量增加得越多，`Proportion`减少的可能性就越大。例如，查看`Age_25to29`、`Age_30to44`和`L4Quals_plus`与`Proportion`之间的关系：
- en: Creating a new dataset with what we've learned
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用我们所学到的知识创建新的数据集
- en: What we have learned so far in this chapter is that age, education, and ethnicity
    are important factors in understanding the way people voted in the Brexit Referendum.
    Younger people with higher education levels are related with votes in favor of
    remaining in the EU. Older white people are related with votes in favor of leaving
    the EU. We can now use this knowledge to make a more succinct data set that incorporates
    this knowledge. First we add relevant variables, and then we remove non-relevant
    variables.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们所学到的知识是，年龄、教育和种族是理解人们在脱欧公投中投票方式的重要因素。受教育程度较高的年轻人与支持留在欧盟的投票相关。年长的白人与支持离开欧盟的投票相关。现在我们可以利用这些知识来创建一个更简洁的数据集，该数据集包含这些知识。首先，我们添加相关变量，然后移除非相关变量。
- en: 'Our new relevant variables are two groups of age (adults below and above 45),
    two groups of ethnicity (whites and non-whites), and two groups of education (high
    and low education levels):'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的新相关变量包括两组年龄（45岁以下的成年人及以上45岁的成年人）、两组种族（白人和非白人）和两组教育水平（高教育水平和低教育水平）：
- en: '[PRE29]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now we remove the old variables that were used to create our newly added variables.
    To do so without having to manually specify a full list by leveraging the fact
    that all of them contain the word `"Age"`, we create the `age_variables` logical
    vector, which contains a `TRUE` value for those variables that contain the word
    `"Age"` inside (`FALSE` otherwise), and make sure we keep our newly created `Age_18to44`
    and `Age_45plus` variables. We remove the other ethnicity and education levels
    manually:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们移除用于创建新变量的旧变量。为了做到这一点，而无需手动指定完整的列表，我们可以利用所有这些变量都包含单词`"Age"`的事实，我们创建了一个包含单词`"Age"`的变量逻辑向量，其中包含`TRUE`值（如果变量内部包含该单词，否则为`FALSE`），并确保我们保留新创建的`Age_18to44`和`Age_45plus`变量。我们手动移除其他种族和教育水平：
- en: '[PRE30]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We save our created `data_adjusted` object by selecting the new columns, create
    our new numerical variables for the new data structure, and save it as a CSV file:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过选择新列来保存创建的`data_adjusted`对象，为新的数据结构创建新的数值变量，并将其保存为CSV文件：
- en: '[PRE31]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Building new variables with principal components
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用主成分构建新变量
- en: '**Principal Component Analysis** (**PCA**) is a dimensionality reduction technique
    that is widely used in data analysis when there are many numerical variables,
    some of which may be correlated, and we would like to reduce the number of dimensions
    required to understand the data.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**主成分分析**（**PCA**）是一种降维技术，在数据分析中当存在许多数值变量，其中一些可能相关联，并且我们希望减少理解数据所需的维度时，被广泛使用。'
- en: It can be useful to help us understand the data, since thinking in more than
    three dimensions can be problematic, and to accelerate algorithms that are computationally
    intensive, especially with large numbers of variables. With PCA, we can extract
    most of the information into only one or two variables constructed in a very specific
    way, such that they capture the most variance while having the added benefit of
    being uncorrelated among them by construction.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 它可能有助于我们理解数据，因为思考超过三个维度可能会出现问题，并且可以加速计算密集型的算法，特别是当变量数量很多时。通过PCA，我们可以将大部分信息提取到仅由一个或两个以非常特定方式构建的变量中，这样它们可以捕捉到最大的方差，同时由于构造上的原因，它们之间是不相关的。
- en: The first principal component is a linear combination of the original variables
    which captures the maximum variance (information) in the dataset. No other component
    can have higher variability than the first principal component. Then, second principal
    component is orthogonal to the first one and is computed in such a way that it
    captures the maximum variance left in the data. And so on. The fact that all variables
    are linear combinations that are orthogonal among themselves is the key for them
    being uncorrelated among each other. Enough statistics talk; let's get on with
    the programming!
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 第一主成分是原始变量的线性组合，它捕捉了数据集中最大的方差（信息）。没有其他成分的方差可以比第一主成分更高。然后，第二主成分与第一个主成分正交，并且以这种方式计算，以捕捉数据中剩余的最大方差。依此类推。所有变量都是彼此正交的线性组合，这是它们彼此之间不相关的关键。足够多的统计学讨论；让我们继续编程吧！
- en: When performing PCA in R, we have a variety of functions which can do the task.
    To mention some of them, we have `prcomp()` and `princomp()` from the `stats`
    package (built-in), `PCA()` from the `FactoMineR` package, `dudi.pca()` from the
    `ade4` package, and `acp()` from the `amap` package. In our case, we'll use the
    `prcomp()` function that is built into R.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中进行PCA时，我们有各种函数可以完成这项任务。提及其中一些，我们有来自`stats`包（内置）的`prcomp()`和`princomp()`，来自`FactoMineR`包的`PCA()`，来自`ade4`包的`dudi.pca()`，以及来自`amap`包的`acp()`。在我们的案例中，我们将使用R内置的`prcomp()`函数。
- en: 'To perform our PCA, we will use the adjusted data from the previous section.
    First, we remove numerical variables which are correlated with `Proportion`. Then
    we perform the PCA by sending the numerical data to the `prcomp()` function, as
    well as some normalization parameters. `center = TRUE` will subtract each variable''s
    mean from itself, and `scale. = TRUE` will make each variable''s variance unitary,
    effectively normalizing the data. Normalizing the data is very important when
    performing PCA, as it''s a method sensitive to scales:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行我们的PCA，我们将使用上一节调整后的数据。首先，我们移除与`比例`相关的数值变量。然后，我们将数值数据发送到`prcomp()`函数，以及一些归一化参数。`center
    = TRUE`将从每个变量中减去其均值，而`scale. = TRUE`将使每个变量的方差为单位方差，从而有效地归一化数据。在执行PCA时归一化数据非常重要，因为它是一种对尺度敏感的方法：
- en: '[PRE32]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: When we print the `pca` object, we can see the standard deviations for each
    variable, but more importantly, we can see the weights used for each variable
    to create each principal component. As we can see, when we look at the full output
    in our computer, among the most important weights (the largest absolute values)
    we have the age and ethnicity variables, as well as others, such as home ownership.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们打印`pca`对象时，我们可以看到每个变量的标准差，但更重要的是，我们可以看到用于创建每个主成分的每个变量的权重。正如我们所见，当我们查看计算机上的完整输出时，在最重要的权重（绝对值最大的）中，我们有年龄和种族变量，以及其他一些变量，如房屋所有权。
- en: 'If you want to get the axis value for each observation in the new coordinate
    system composed of the principal components, you simply need to multiply each
    observation in your data (each row) with the corresponding weights from the rotation
    matrix from the `pca` object (`pca$rotation`). For example, to know where the
    first observation in the data should be placed in regards to the second principal
    component, you can use the following:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想获取新坐标系统中每个观测值的轴值，该坐标系统由主成分组成，您只需将数据中的每个观测值（每行）与`pca`对象中的旋转矩阵（`pca$rotation`）对应的权重相乘即可。例如，要知道数据中的第一个观测值相对于第二个主成分的位置，您可以使用以下方法：
- en: '[PRE33]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: In general, you can apply matrix operations to get coordinates for all the observations
    in your data in regards to all the principal components in your `pca` object by
    using the following line, which will perform a matrix multiplication. Note that
    you don't need to do this yourself since R will do it automatically for you when
    analyzing the results.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，您可以通过以下行将矩阵运算应用于您的数据中所有观测值相对于`pca`对象中所有主成分的坐标，这将执行矩阵乘法。请注意，您不需要亲自进行此操作，因为R在分析结果时会自动为您完成。
- en: '[PRE34]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: When we look at the summary of `pca`, we can see the standard deviations for
    each principal component, as well as its proportion of the variance captured and
    its accumulation. This information is useful when deciding how many principal
    components we should keep for the rest of the analysis. In our case, we find that
    with just the first two principal components, we have captured approximately 70
    percent of the information in the data, which for our case may be good enough.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看`pca`的摘要时，我们可以看到每个主成分的标准差，以及它所捕获的方差比例和累积值。当决定在剩余分析中保留多少主成分时，这些信息很有用。在我们的案例中，我们发现仅用前两个主成分，我们就已经捕捉到了数据中大约70%的信息，对于我们的情况可能已经足够了。
- en: The 70% number can be arrived at by adding the `Proportion of variance` value
    for the principal components we want to consider (in order and starting at `PC1`).
    In this case, if we add the `Proportion of variance` for `PC1` and `PC2`, we get
    $0.411 + 0.280 = 0.691$, which is almost 70 percent. Note that you can simply
    look at the `Cumulative proportion` to find this number without having to perform
    the sum yourself, as it accumulates the `Proportion of variance` incrementally,
    starting at `PC1`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 70%这个数字可以通过将我们要考虑的主成分的`Proportion of variance`值相加得到（按顺序，从`PC1`开始）。在这种情况下，如果我们把`PC1`和`PC2`的`Proportion
    of variance`相加，我们得到$0.411 + 0.280 = 0.691$，这几乎就是70%。请注意，您可以直接查看`Cumulative proportion`来找到这个数字，而无需亲自进行求和，因为它会递增地累积`Proportion
    of variance`，从`PC1`开始。
- en: '![](img/00018.jpeg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00018.jpeg)'
- en: Principal Component's Variances
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分的方差
- en: 'Take one moment to think about how powerful this technique is: with just two
    variables, we are able to capture 70 percent of the information contained in the
    original 40 variables:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 请花一点时间思考一下这项技术的强大之处：仅用两个变量，我们就能捕捉到原始40个变量中包含的70%信息：
- en: '[PRE35]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'In the graph shown above, we can see the variances (in the form of squared
    standard deviations) from the `summary(pca)` results. We can see how each subsequent
    principal component captures a lower amount of the total variance:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图中，我们可以看到`summary(pca)`结果中的方差（以平方标准差的形式）。我们可以看到每个后续主成分如何捕捉到更少的总方差：
- en: '[PRE36]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Finally, following graph shows a scatter plot of the ward observations (points)
    over a plane created by the two principal components from our analysis; it is
    called a **biplot**. Since these two principal components are formed as linear
    combinations of the original variables, we need some guidance when interpreting
    them. To make it easy, the arrows point towards the direction of that variable's
    association to the principal component axis. The further the arrow is from the
    center, the stronger the effect on the principal components.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，下面的图显示了ward观测值（点）在由我们的分析中两个主成分创建的平面上的散点图；它被称为**双变量图**。由于这两个主成分是原始变量的线性组合，因此在解释它们时我们需要一些指导。为了简化，箭头指向变量与主成分轴关联的方向。箭头离中心越远，对主成分的影响就越强。
- en: '![](img/00019.jpeg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00019.jpeg)'
- en: PCA Biplot
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 双变量图
- en: 'With this biplot, we can see that `Proportion` is strongly related to the wards
    that voted to leave the EU, which is obvious since that''s by construction. However,
    we can also see some other interesting relations. For example, other than the
    effects we have found so far (age, education, and ethnicity), people owning their
    own homes is also slightly associated with a higher tendency towards voting to
    leave the EU. On the other side, a previously unknown relation is the fact that
    the more dense a ward''s population is (think about highly populated cities),
    the more likely it is that they will vote to remain in the EU:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个双图，我们可以看到`比例`与投票离开欧盟的选区有很强的相关性，这是显而易见的，因为这是构造出来的。然而，我们还可以看到一些其他有趣的关系。例如，除了我们迄今为止发现的效果（年龄、教育和种族）之外，拥有自己的房子的人也与投票离开欧盟的更高倾向略有关联。另一方面，一个以前未知的关系是，一个选区的居民越密集（想想高度人口密集的城市），他们投票留在欧盟的可能性就越大：
- en: '[PRE37]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Putting it all together into high-quality code
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将所有内容整合成高质量的代码
- en: Now that we have the fundamentals about analyzing data with descriptive statistics,
    we're going to improve our code's structure and flexibility by breaking it up
    into functions. Even though this is common knowledge among efficient programmers,
    it's not a common practice among data analysts. Many data analysts would simply
    paste the code we have developed all together, as-is, into a single file, and
    run it every time they wanted to perform the analysis. We won't be adding new
    features to the analysis. All we'll do is reorder code into functions to encapsulate
    their inner-workings and communicate intention with function names (this substantially
    reduces the need for comments).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了使用描述性统计来分析数据的基础知识，我们将通过将其分解成函数来改进代码的结构和灵活性。尽管这在高效程序员中是常识，但在数据分析师中却不是常见的做法。许多数据分析师会直接将我们开发的代码整体粘贴到一个文件中，每次他们想要进行数据分析时都运行它。我们不会向分析中添加新功能。我们唯一要做的就是将代码重新排序到函数中，以封装其内部工作原理并通过函数名传达意图（这大大减少了注释的需求）。
- en: We'll focus on producing *high-quality* code that is easy to read, reuse, modify,
    and fix (in case of bugs). The way we actually do it is a matter of style, and
    different ways of arranging code are fit for different contexts. The method we'll
    work with here is one that has served me well for a variety of situations, but
    it may not be the best for yours. If it doesn't suit your needs, feel free to
    change it. Whichever style you prefer, making an investment in creating a habit
    of constantly producing high-quality code will make you a more efficient programmer
    in the long run, and a point will come where you will not want to program inefficiently
    any more.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将专注于编写*高质量*的代码，这种代码易于阅读、重用、修改和修复（以防出现错误）。我们实际的做法是一个风格问题，不同的代码排列方式适合不同的上下文。我们将采用的方法是一种在各种情况下都对我很有帮助的方法，但它可能并不适合你。如果你觉得它不适合你的需求，请随意更改它。无论你更喜欢哪种风格，投资于培养不断生产高质量代码的习惯，将使你在长期内成为一个更高效的程序员，并且最终你会不想再以低效的方式进行编程。
- en: Planning before programming
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编程前的规划
- en: 'Often, people start programming before having a general idea of what they want
    to accomplish. If you''re an experienced programmer, this may be a good way to
    get a feel for the problem, since you have already developed intuition, and you''ll
    probably end up throwing away the first couple of attempts anyway. However, if
    you''re a novice programmer, I recommend you make your objectives clear and explicit
    before writing any code (putting them into writing can help). It will help you
    make better decisions by asking yourself how a certain way of doing things will
    affect your objectives. So, before we set up anything, we need to understand and
    make our general objectives explicit:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，人们在还没有一个关于他们想要完成什么的一般想法之前就开始编程。如果你是一个经验丰富的程序员，这可能是一个了解问题的好方法，因为你已经发展出了直觉，而且你很可能会扔掉前几次尝试。然而，如果你是一个新手程序员，我建议你在编写任何代码之前明确你的目标（将它们写下来可以帮助）。通过问自己某种做事方式将如何影响你的目标，这将帮助你做出更好的决定。因此，在我们设置任何东西之前，我们需要理解和明确我们的总体目标：
- en: Understand the big picture of the analysis quickly.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 快速理解分析的大致情况。
- en: Reproduce our analysis automatically by executing a single file.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行单个文件自动重现我们的分析。
- en: Save all the resulting objects, text, and images for the analysis.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存分析产生的所有对象、文本和图像。
- en: Measure the amount of time it takes to perform the full analysis.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量执行完整分析所需的时间量。
- en: When working on iterative processes, know the completed percentage.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在进行迭代过程工作时，要知道完成百分比。
- en: Be able to find and change each part of the analysis easily.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 能够轻松找到并更改分析的每一部分。
- en: To fulfill these general objectives, we need to develop modular code with well-managed
    dependencies that are flexible (easy to change) and friendly to side-effects (saving
    objects, texts, and images). Even if your explicit objectives don't require it,
    you should make a habit of programming this way, even when just doing data analysis.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这些一般目标，我们需要开发模块化代码，具有良好管理的依赖关系，这些代码是灵活的（易于更改）并且对副作用友好（保存对象、文本和图像）。即使你的明确目标不需要这样做，你也应该养成这样编程的习惯，即使只是在进行数据分析时也是如此。
- en: Understanding the fundamentals of high-quality code
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解高质量代码的基本原理
- en: Code that is modular, flexible, and whose dependencies are well-managed, is
    said to be **highly-cohesive** and **loosely-coupled**. These terms are mostly
    used in object-oriented environments (more about these in [Chapter 8](part0178.html#59O440-f494c932c729429fb734ce52cafce730),
    *Object-Oriented System to Track Cryptocurrencies*), but apply generally to any
    system. **Highly-cohesive** means that things that are supposed to be together,
    are. **Loosely-coupled** means that things that are not supposed to be together,
    are not. The following image shows these characteristics, where each of the circles
    can be a function or an object in general. These are the basics of dependency
    management. Many books focused on these topics have been, and continue to be,
    published. For the interested reader, Steve McConnell's *Code Complete* (Microsoft
    Press, 2004) and Robert Martin's *Clean Code* (Prentice Hall, 2009) are excellent
    references. In this book, you'll see some of these techniques applied.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 模块化、灵活且依赖关系管理良好的代码被称为**高度内聚**和**松散耦合**。这些术语主要在面向对象环境中使用（更多内容请参阅第8章，[《面向对象的加密货币跟踪系统》](part0178.html#59O440-f494c932c729429fb734ce52cafce730)），但它们适用于任何系统。**高度内聚**意味着应该在一起的事物确实在一起。**松散耦合**意味着不应该在一起的事物确实没有在一起。以下图像展示了这些特征，其中每个圆圈都可以是一个函数或对象。这些都是依赖关系管理的基本原则。许多专注于这些主题的书籍已经出版，并且仍在出版。对于感兴趣的读者，Steve
    McConnell的《代码大全》（Microsoft Press，2004）和Robert Martin的《代码整洁之道》（Prentice Hall，2009）是极好的参考。在这本书中，你将看到一些这些技术的应用。
- en: '![](img/00020.jpeg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00020.jpeg)'
- en: High cohesion and low coupling (left) vs Low cohesion and high coupling (right)
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 高内聚和低耦合（左）与低内聚和高耦合（右）
- en: 'The most important principles for high-quality code are:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 高质量代码最重要的原则是：
- en: Make things small and focused on a single responsibility.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将事物分解成小而专注于单一职责的部分。
- en: Make the concrete depend on the abstract (not vice versa).
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 具体依赖于抽象（而不是相反）。
- en: Make things that are highly-cohesive and loosely-coupled.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使事物具有高度内聚性和松散耦合性。
- en: By *things,* I mean functions, methods, classes, and objects in general. We'll
    touch more on what these are in [Chapter 8](part0178.html#59O440-f494c932c729429fb734ce52cafce730),
    O*bject-Oriented System to Track Cryptocurrencies*.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说“事物”时，指的是函数、方法、类和对象等。我们将在第8章中更多地讨论这些内容，[《面向对象的加密货币跟踪系统》](part0178.html#59O440-f494c932c729429fb734ce52cafce730)。
- en: We start by creating two files: `functions.R` and `main.R`. The `functions.R` file
    contains high-level functions (mainly called from the `main.R` file) as well as
    low-level functions (used within other functions). By reading the `main.R` file,
    we should have a clear idea of what the analysis does (this is the purpose of
    the high-level functions), and executing it should re-create our analysis for
    any data that fits our base assumptions (for this example, these are mainly data
    structures).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建两个文件：`functions.R` 和 `main.R`。`functions.R` 文件包含高级函数（主要从 `main.R` 文件中调用）以及低级函数（在其他函数中使用）。通过阅读
    `main.R` 文件，我们应该对分析的内容有一个清晰的认识（这是高级函数的目的），执行它应该能够为符合我们基本假设的任何数据重新创建我们的分析（对于这个例子，这些主要是数据结构）。
- en: We should always keep related code at the same level of abstraction. This means
    that we don't want to program things at the big-picture level and implement it
    with mixed details, and separating our code into the `main.R` and `functions.R` is
    a first step in this direction. Furthermore, none of the code in the `main.R` file
    should depend on details of the implementation. This makes it modular in the sense
    that if we want to change the way something is implemented, we can do so without
    having to change the high-level code. However, the way we implement things depends
    on what we want the analysis to ultimately do, which means that concrete implementations
    should depend on the abstract implementations that in turn depend on our analysis'
    purpose (stated as code in the `main.R` file).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该始终将相关代码保持在相同的抽象级别。这意味着我们不想在大图层面编程，然后用混合的细节来实现它，将代码分离到`main.R`和`functions.R`是朝这个方向迈出的第一步。此外，`main.R`文件中的任何代码都不应依赖于实现的细节。这使得代码模块化，从某种意义上说，如果我们想改变某个实现的方式，我们可以这样做，而无需更改高级代码。然而，我们实现事物的方式取决于我们想要分析最终要做什么，这意味着具体的实现应该依赖于抽象的实现，而抽象的实现又依赖于我们分析的目的（在`main.R`文件中以代码的形式表述）。
- en: When we bring knowledge from one set of code to another, we're generating a
    dependency, because the code that knows about other code depends on it to function
    properly. We want to avoid these dependencies as much as possible, and most importantly,
    we want to manage their direction. As stated before, the abstract should not depend
    on the concrete, or put another way, the concrete should depend on the abstract.
    Since the analysis (`main.R`) is on the abstract side, it should not depend on
    the implementation details of the concrete functions. But, how can our analysis
    be performed without knowledge of the functions that implement it? Well, it can't.
    That's why we need an intermediary, the abstract functions. These functions are
    there to provide stable knowledge to `main.R` and guarantee that the analysis
    its looking for will be performed, and they remove the dependency of `main.R` on
    the implementation details by managing that knowledge themselves. This may seem
    a convoluted way of working and a tricky concept to grasp, but when you do, you'll
    find out that it's very simple, and you'll be able to create code that is pluggable,
    which is a big efficiency boost. You may want to take a look at the books referenced
    previously to get a deeper sense of these concepts.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将知识从一个代码集带到另一个代码集时，我们正在生成一个依赖关系，因为了解其他代码的代码依赖于它才能正常工作。我们尽可能地避免这些依赖关系，最重要的是，我们想要管理它们的方向。正如之前所述，抽象不应依赖于具体，或者换句话说，具体应依赖于抽象。由于分析（`main.R`）在抽象方面，它不应依赖于具体函数的实现细节。但是，我们的分析如何在没有了解实现它的函数的知识的情况下进行呢？嗯，它不能。这就是为什么我们需要一个中介，即抽象函数。这些函数的存在是为了向`main.R`提供稳定的知识，并保证所寻找的分析将被执行，并且通过管理这些知识来消除`main.R`对实现细节的依赖。这可能看起来是一种复杂的工作方式，也是一个难以理解的概念，但当你理解它时，你会发现它非常简单，你将能够创建可插入的代码，这将大大提高效率。你可能想看看之前提到的书籍，以更深入地了解这些概念。
- en: '![](img/00021.jpeg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00021.jpeg)'
- en: General code structure
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 通用代码结构
- en: The previous graph shows that our analysis depends on the abstract functions
    (interfaces), as well as the concrete code that implements those interfaces. These
    abstract functions let us invert the dependency between the concrete functions
    and the analysis. We'll go deeper into these concepts in [Chapter 8](part0178.html#59O440-f494c932c729429fb734ce52cafce730),
    *Object-Oriented System to Track Cryptocurrencies*.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的图表显示，我们的分析依赖于抽象函数（接口），以及实现这些接口的具体代码。这些抽象函数让我们逆转了具体函数和分析之间的依赖关系。我们将在第8章[面向对象系统跟踪加密货币](part0178.html#59O440-f494c932c729429fb734ce52cafce730)中更深入地探讨这些概念。
- en: Programming by visualizing the big picture
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过可视化大图进行编程
- en: Now, we will work with a top-down approach, meaning that we'll start with abstract
    code first and gradually move into the implementation details. Generally I find
    this approach to be more efficient when you have a clear idea of what you want
    to do. In our case, we'll start by working with the `main.R` file.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将采用自顶向下的方法，这意味着我们将首先从抽象代码开始，然后逐渐过渡到实现细节。通常我发现这种方法在你对想要做什么有清晰的想法时更有效。在我们的情况下，我们将从处理`main.R`文件开始。
- en: The first thing to note is that we will use the `proc.time()` function twice,
    once at the beginning and once at the end, and we will use the difference among
    these two values to measure how much time it took for the whole code to execute.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的第一点是，我们将使用 `proc.time()` 函数两次，一次在开始时，一次在结束时，我们将使用这两个值之间的差异来衡量整个代码执行所需的时间。
- en: The second thing to note is that the `empty_directories()` function makes sure
    each of the specified directories exist, and deletes any files contained in them.
    We use it to clean up our directories at the beginning of each execution, to make
    sure we have the latest files, and only the files created in the last run. The
    actual code is shown below, and it simply iterates through each of the directories
    passed, removes any files inside recursively with the `unlink()` function, and
    makes sure the directory exists with the `dir.create()` function. It avoids showing
    any warnings due to the directory already existing, which is not a problem in
    our case, by using the `showWarnings = FALSE` parameter.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的第二点是，`empty_directories()` 函数确保指定的每个目录都存在，并删除它们包含的任何文件。我们在每次执行开始时使用它来清理目录，以确保我们拥有最新的文件，并且只有上一次运行中创建的文件。实际的代码如下所示，它简单地遍历传递给每个目录，使用
    `unlink()` 函数递归地删除任何文件，并使用 `dir.create()` 函数确保目录存在。通过使用 `showWarnings = FALSE`
    参数，它避免了由于目录已存在而显示任何警告，这在我们的情况下不是问题。
- en: '[PRE38]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: From [Chapter 1](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730), *Introduction
    to R*, we use of the `print_section()` and `empty_directories()` functions to
    print headers and delete directory contents (to re-create the results every time
    we run the function with empty directories), respectively, and we'll use the mechanism
    shown with `proc.time()` to measure execution time.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [第1章](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730)，《R语言入门》，我们使用 `print_section()`
    和 `empty_directories()` 函数分别打印标题和删除目录内容（每次我们使用空目录运行函数时重新创建结果），并且我们将使用 `proc.time()`
    显示的机制来测量执行时间。
- en: Now that the previous two points are out of the way, we proceed to show the
    full contents of the `main.R` file.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在前面两点已经解决，我们继续展示 `main.R` 文件的全部内容。
- en: '[PRE39]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: As you can see, with just this file, you get the big picture of the analysis,
    and are able to reproduce your analysis by running a single file, save the results
    to disk (note the `save_to` arguments), and measure the amount of time it takes
    to perform the full analysis. From our general objectives list, objectives one
    through four are fulfilled by this code. Fulfilling objectives five and six will
    be accomplished by working on the `functions.R` file, which contains lots of small
    functions. Having this `main.R` file gives us a map of what needs to be programmed,
    and even though right now it would not work because the functions it uses do not
    yet exist, by the time we finish programming them, this file will not require
    any changes and will produce the desired results.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，仅凭这个文件，你就能获得分析的大致轮廓，并且能够通过运行单个文件来重现你的分析，将结果保存到磁盘（注意 `save_to` 参数），并测量执行完整分析所需的时间。从我们的总体目标列表中，目标一至四通过此代码实现。实现目标五和六将通过在
    `functions.R` 文件上工作来完成，该文件包含许多小函数。拥有这个 `main.R` 文件为我们提供了需要编程的地图，尽管现在它可能无法工作，因为其中使用的函数尚未存在，但当我们完成编程时，此文件将不需要任何更改并产生预期的结果。
- en: Due to space restrictions, we won't look at the implementation of all the functions
    in the `main.R` file, just the representative ones: `prepare_data()`, `plot_scatter_plot()`,
    and `all_scatter_plots()`. The other functions use similar techniques to encapsulate
    the corresponding code. You can always go to this book's code repository ([https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example))
    to see the rest of the implementation details. After reading this book, you should
    be able to figure out exactly what's going on in every file in that repository.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 由于空间限制，我们不会查看 `main.R` 文件中所有函数的实现，只看代表性的：`prepare_data()`、`plot_scatter_plot()`
    和 `all_scatter_plots()`。其他函数使用类似的技术来封装相应的代码。你始终可以访问这本书的代码仓库 ([https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example))
    来查看其余的实现细节。阅读完这本书后，你应该能够确切地了解该仓库中每个文件中发生的事情。
- en: We start with `prepare_data()`. This function is abstract and uses four different
    concrete functions to do its job, `read.csv()`, `clean_data()`, `transform_data()`,
    and, if required, `complete.cases()`. The first function, namely `read.csv()`,
    receives the path to a CSV file to read data from and loads into a data frame
    object named `data` in this case. The fourth function you have seen before in
    [Chapter 1](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730), *Introduction
    to R*, so we won't explain it here. Functions two and three are created by us,
    and we'll explain them. Note that `main.R` doesn't know about how data is prepared,
    it only asks for data to be prepared, and delegates the job to the abstract function
    `prepare_data()`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`prepare_data()`函数开始。这个函数是抽象的，并使用四个不同的具体函数来完成其工作，分别是`read.csv()`、`clean_data()`、`transform_data()`，以及在需要时使用`complete.cases()`。第一个函数，即`read.csv()`，接收要读取数据的CSV文件路径，并将数据加载到名为`data`的数据框对象中。第四个函数你在[第1章](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730)，*R语言简介*中已经见过，所以这里我们不再解释。第二个和第三个函数是我们自己创建的，我们将对它们进行解释。请注意，`main.R`并不了解数据是如何准备的，它只要求准备数据，并将任务委托给抽象函数`prepare_data()`。
- en: '[PRE40]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The `clean_data()` function simply encapsulates the re-coding of -1 for `NA` for
    now. If our cleaning procedure suddenly got more complex (for example, new data
    sources requiring more cleaning or realizing we missed something and we need to
    add it to the cleaning procedure), we would add those changes to this function
    and we would not have to modify anything else in the rest of our code. These are
    some of the advantages of encapsulating code into functions that communicate intention
    and isolate what needs to be done into small steps:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`clean_data()`函数目前只是简单地封装了将`NA`的-1重新编码的过程。如果我们的清理过程突然变得更加复杂（例如，需要更多清理的新数据源或意识到我们遗漏了某些内容，需要将其添加到清理过程中），我们将把这些更改添加到这个函数中，而无需修改代码的其他部分。这些都是将代码封装到函数中，以传达意图并隔离需要执行的小步骤的一些优点：'
- en: '[PRE41]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'To transform our data by adding the extra `Proportion` and `Vote` variables,
    and re-label the region names, we use the following function:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了通过添加额外的`Proportion`和`Vote`变量以及重新标记区域名称来转换我们的数据，我们使用了以下函数：
- en: '[PRE42]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: All of these lines of code you have seen before. All we are doing is encapsulating
    them into functions that communicate intention and allow us to find where certain
    procedures are taking place so that we can find them and change them easily if
    we need to do so later on.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 你之前已经看到过所有这些代码行。我们所做的只是将它们封装到函数中，以传达意图，并允许我们找到某些过程发生的位置，这样我们就可以在需要时轻松地找到并更改它们。
- en: Now we look into `plot_scatter_plot()`. This function is between being an abstract
    and a concrete function. We will use it directly in our `main.R` file, but we
    will also use it within other functions in the `functions.R` file. We know that
    most of the time we'll use `Proportion` as the color variable, so we add that
    as a default value, but we allow for the user to remove the color completely by
    checking if the argument was sent as `FALSE`, and since we will use this same
    function to create graphs that resemble all the scatter plots we have created
    up to this point, we will make the regression line optional.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看`plot_scatter_plot()`函数。这个函数介于抽象和具体函数之间。我们将在`main.R`文件中直接使用它，但也会在`functions.R`文件中的其他函数中使用它。我们知道大多数时候我们会使用`Proportion`作为颜色变量，所以我们将其作为默认值添加，但允许用户通过检查参数是否被发送为`FALSE`来完全移除颜色，并且由于我们将使用这个相同的函数来创建类似于我们迄今为止创建的所有散点图的图形，我们将回归线设置为可选。
- en: Note that in the case of the former graphs, the *x* axis is a continuous variable, but
    in the case of the latter graph, it's a categorical (*factor*) variable. This
    kind of flexibility is very powerful and is available to us due to `ggplot2`'s
    capability to adapt to these changes. Formally, this is called **polymorphism**,
    and it's something we'll explain in [Chapter 8](part0178.html#59O440-f494c932c729429fb734ce52cafce730),
    *Object-Oriented System to Track Cryptocurrencies*.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在前面的图形中，*x*轴是一个连续变量，但在后面的图形中，它是一个分类的（*因子*）变量。这种灵活性非常强大，并且由于`ggplot2`能够适应这些变化，我们才能拥有它。正式上，这被称为**多态性**，我们将在[第8章](part0178.html#59O440-f494c932c729429fb734ce52cafce730)，*面向对象系统追踪加密货币*中对其进行解释。
- en: Finally, instead of assuming the user will always want to save the resulting
    graph to disk, we make the `save_to` argument optional by providing an empty string
    for it. When appropriate, we check to see if this string is empty with `not_empty()`,
    and if it's not empty, we set up the PNG saving mechanism.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们不再假设用户总是希望将生成的图表保存到磁盘上，因此我们将`save_to`参数设置为可选，为其提供一个空字符串。当合适的时候，我们使用`not_empty()`函数检查这个字符串是否为空，如果不为空，我们设置PNG保存机制。
- en: '[PRE43]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Now we look into `all_scatter_plots()`. This function is an abstract function
    that hides from the user's knowledge the name of the function that will create
    graphs iteratively, conveniently named `create_graphs_iteratively()`, and the
    graphing function, the `plot_scatter_plot()` function we saw before. In case we
    want to improve the iterative mechanism or the graphing function, we can do so
    without requiring changes from people that use our code, because that knowledge
    is encapsulated here.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一下`all_scatter_plots()`函数。这个函数是一个抽象函数，它隐藏了用户所不知道的函数名称，即用于迭代创建图表的函数，这个函数被方便地命名为`create_graphs_iteratively()`，以及之前看到的绘图函数`plot_scatter_plot()`。如果我们想改进迭代机制或绘图函数，我们可以在不要求使用我们代码的人做出任何更改的情况下做到这一点，因为这种知识被封装在这里。
- en: Encapsulate what changes frequently or is expected to change.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 封装那些经常变化或预期会变化的元素。
- en: The `create_graphs_iteratively()` function is the same we have seen before,
    except for the progress bar code. The `progress` package provides the `progress_bar$new()` function
    that creates a progress bar in the terminal while an iterative process is being
    executed so that we see what percentage of the process has been completed and
    know how much time is remaining (see [Appendix](part0296.html#8Q96G0-f494c932c729429fb734ce52cafce730),
    *Required Packages* for more information).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`create_graphs_iteratively()`函数与之前我们看到的一样，只是进度条代码有所不同。`progress`包提供了`progress_bar$new()`函数，在迭代过程执行时在终端创建进度条，这样我们可以看到完成过程的百分比，并知道剩余多少时间（有关更多信息，请参阅[附录](part0296.html#8Q96G0-f494c932c729429fb734ce52cafce730)，*必需的包*）。'
- en: 'Note the change in the `save_to` argument from the functions `plot_scatter_plot()` and
    `all_scatter_plots()`. In the former, it''s a filename; in the latter, a directory
    name. The difference is small, but important. The incautious reader might not
    notice it and it may be a cause for confusion. The `plot_scatter_plot()` function
    produces a single plot, and thus receives a file name. However, the `all_scatter_plots()` will
    produce, by making use of `plot_scatter_plot()`, a lot of graphs, so it must know
    where all of them need to be saved, create the final image names dynamically,
    and send them one-by-one to `plot_scatter_plot()`. Finally, since we want the
    regression to be included in these graphs, we just send the `regression = TRUE` parameter:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`plot_scatter_plot()`和`all_scatter_plots()`函数中`save_to`参数的变化。在前者中，它是一个文件名；在后者中，是一个目录名。这种差异虽小，但很重要。粗心大意的读者可能不会注意到这一点，这可能会导致混淆。`plot_scatter_plot()`函数生成单个图表，因此接收一个文件名。然而，`all_scatter_plots()`函数将通过使用`plot_scatter_plot()`生成大量的图表，因此它必须知道所有这些图表需要保存的位置，动态创建最终的图像名称，并将它们逐个发送到`plot_scatter_plot()`。最后，由于我们希望回归分析包含在这些图表中，我们只需发送`regression
    = TRUE`参数：
- en: '[PRE44]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The other functions that we have not looked at in detail follow similar techniques
    as the ones we showed, and the full implementation is available at this book's
    code repository ([https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example)).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尚未详细查看的其他函数，其技术方法与我们展示的方法类似，完整的实现可以在本书的代码仓库中找到（[https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example)）。
- en: Summary
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter showed how to perform a qualitative analysis that is useful as
    a first step when doing data analysis. We showed some descriptive statistics techniques
    and how to implement them programmatically. With these skills, we are able to
    perform simple yet powerful analyses and save the results for later use. Specifically,
    we showed how to do basic data cleaning, how to create graphs programmatically,
    how to create matrix scatter plots and matrix correlations, how to perform Principal
    Component Analysis, and how to combine these tools to understand the data at hand.
    Finally, we touched on the basics of high-quality code and showed how to transform
    your initial data analysis code into programs that are modular, flexible, and
    easy to work with.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了如何进行定性分析，这在数据分析的第一步中非常有用。我们展示了描述性统计技术及其编程实现。凭借这些技能，我们能够执行简单而强大的分析，并将结果保存以供以后使用。具体来说，我们展示了如何进行基本数据清洗，如何编程创建图表，如何创建矩阵散点图和矩阵相关性，如何进行主成分分析，以及如何将这些工具结合起来理解手头的数据。最后，我们简要介绍了高质量代码的基础知识，并展示了如何将你的初始数据分析代码转换为模块化、灵活且易于工作的程序。
- en: In [Chapter 3](part0076.html#28FAO0-f494c932c729429fb734ce52cafce730), *Predicting
    Votes with Linear Models,* we'll show how to extend the current analysis with
    qualitative tools. Specifically, we'll show how to use linear models to understand
    the quantitative effects of variables on the proportion of votes in favor of the
    UK leaving and remaining in the EU, how to make predictions for wards whose vote
    data we don't have, and how to measure the accuracy of those predictions with
    the data we do have. These are essential skills for any data analyst and, just
    as we did in this chapter, we'll see how to implement them programmatically.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](part0076.html#28FAO0-f494c932c729429fb734ce52cafce730)，“使用线性模型预测选票”，我们将展示如何使用定性工具扩展当前的分析。具体来说，我们将展示如何使用线性模型来理解变量对英国离开和留在欧盟的投票比例的定量影响，如何对没有投票数据的选区进行预测，以及如何使用我们拥有的数据来衡量这些预测的准确性。这些是任何数据分析师必备的技能，正如我们在本章中所做的那样，我们将看到如何通过编程实现这些技能。
