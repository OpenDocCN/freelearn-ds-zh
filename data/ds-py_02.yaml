- en: Chapter 2. Python and Jupyter Notebooks to Power your Data Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章 Python 和 Jupyter Notebooks 助力你的数据分析
- en: '"The Best Line of Code is the One You Didn''t Have to Write!"'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “最好的代码是你不必写的那一行！”
- en: – *Unknown*
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: – *未知*
- en: 'In the previous chapter, I gave a developer''s perspective on data science
    based on real experience and discussed three strategic pillars required for successful
    deployment with in the enterprise: data, services, and tools. I also discussed
    the idea that data science is not only the sole purview of data scientists, but
    rather a team sport with a special role for developers.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我从开发者的角度，基于真实经验探讨了数据科学，并讨论了成功部署企业所需的三个战略支柱：数据、服务和工具。我还讨论了一个观点，即数据科学不仅仅是数据科学家的专属领域，它实际上是一个团队合作的过程，其中开发者扮演着特殊的角色。
- en: 'In this chapter, I''ll introduce a solution—based on Jupyter Notebooks, Python,
    and the PixieDust open source library—that focuses on three simple goals:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将介绍一个解决方案——基于 Jupyter Notebooks、Python 和 PixieDust 开源库——它专注于三个简单的目标：
- en: Democratizing data science by lowering the barrier to entry for non-data scientists
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过降低非数据科学家的准入门槛，实现数据科学的普及
- en: Increasing collaboration between developers and data scientists
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加开发者与数据科学家之间的合作
- en: Making it easier to operationalize data science analytics
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让数据科学分析更易于操作化
- en: Note
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'This solution only focuses on the tools pillar and not on data and services, which
    should be implemented independently, although we''ll cover some of it when discussing
    the sample applications starting in [Chapter 6](ch06.xhtml "Chapter 6. Analytics
    Study: AI and Image Recognition with TensorFlow"), *Analytics Study: AI and Image
    Recognition with TensorFlow*.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 该解决方案仅聚焦于工具层面，而不涉及数据和服务，尽管我们将在[第6章](ch06.xhtml "第6章. 数据分析研究：使用 TensorFlow 的
    AI 与图像识别") *数据分析研究：使用 TensorFlow 的 AI 与图像识别*中讨论一些内容，数据和服务应独立实现。
- en: Why choose Python?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择 Python？
- en: Like many developers, when it came to building data-intensive projects, using
    Python wasn't my first choice. To be honest, having worked with Java for so many
    years, Scala seemed much more attractive to me at first, even though the learning
    curve was pretty steep. Scala is a very powerful language that elegantly combines
    object-oriented and functional programming, which is sorely lacking in Java (at least until
    Java 8 started to introduce lambda expressions).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多开发者一样，在构建数据密集型项目时，使用 Python 并不是我的首选。说实话，经过多年的 Java 工作经验后，最初 Scala 对我来说更具吸引力，尽管学习曲线相当陡峭。Scala
    是一种非常强大的语言，它优雅地结合了面向对象编程和函数式编程，而这些在 Java 中是极为缺乏的（至少直到 Java 8 开始引入 Lambda 表达式）。
- en: Scala also provides a very concise syntax that translates into fewer lines of
    code, higher productivity, and ultimately fewer bugs. This comes in very handy,
    especially when a large part of your work is to manipulate data. Another reason
    for liking Scala is the better API coverage when using big data frameworks such
    as Apache Spark, which are themselves written in Scala. There are also plenty
    of other good reasons to prefer Scala, such as it's a strong typed system and
    its interoperability with Java, online documentation, and high performance.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 还提供了非常简洁的语法，这转化为更少的代码行、更高的生产力，最终也减少了错误。这在你大部分工作都涉及数据操作时非常有用。喜欢 Scala 的另一个原因是，当使用像
    Apache Spark 这样的“大数据”框架时，它的 API 支持更好，而这些框架本身就是用 Scala 编写的。还有很多其他理由使得 Scala 更受青睐，比如它是一个强类型系统，能够与
    Java 互操作，拥有在线文档，并且性能高。
- en: 'So, for a developer like myself who is starting to get involved in data science,
    Scala would seem like a more natural choice, but yet, spoiler alert, we ended
    up focusing on Python instead. There are multiple reasons for this choice:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于像我这样的开发者，刚开始涉足数据科学时，Scala 似乎是一个更自然的选择，但实际上，剧透一下，我们最终选择了 Python。这一选择有多个原因：
- en: Python, as a language, has a lot going on for itself too. It is a dynamic programming
    language with similar benefits to Scala, such as functional programming, and concise
    syntax, among others.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 作为一种语言也有很多优点。它是一种动态编程语言，具有与 Scala 类似的优势，比如函数式编程和简洁的语法等。
- en: Python has seen, over the last few years, a meteoric rise among data scientists,
    overtaking longtime rival R as the overall preferred language for data science,
    as demonstrated by a quick search for the terms `Python Data Science`, `Python
    Machine Learning`, `R Data Science`, and `R Machine Learning` on Google Trends:![Why
    choose Python?](img/B09699_02_01.jpg)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在过去几年里，Python在数据科学家中迅速崛起，超过了长期竞争对手R，成为数据科学领域的首选语言，这一点通过在Google Trends上搜索`Python
    Data Science`、`Python Machine Learning`、`R Data Science`和`R Machine Learning`可以看到：![为什么选择Python？](img/B09699_02_01.jpg)
- en: Interest trends for 2017
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2017年的兴趣趋势
- en: In a virtuous circle, Python's rising popularity fuels a vast and growing ecosystem
    of wide-ranging libraries that can be easily imported into your projects using
    the pip Python package installer. Data scientists now have access to many powerful
    open source Python libraries for data manipulation, data visualization, statistics, mathematics,
    machine learning, and natural language processing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在良性循环中，Python日益增长的流行度推动了一个庞大而不断扩展的生态系统，涵盖了各种各样的库，这些库可以通过pip Python包安装器轻松导入到项目中。数据科学家现在可以使用许多强大的开源Python库进行数据处理、数据可视化、统计学、数学、机器学习和自然语言处理。
- en: Even beginners can quickly build a machine learning classifier using the popular
    scikit-learn package ([http://scikit-learn.org](http://scikit-learn.org)) without
    being a machine learning expert, or quickly plot rich charts using Matplotlib
    ([https://matplotlib.org](https://matplotlib.org)) or Bokeh ([https://bokeh.pydata.org](https://bokeh.pydata.org)).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是初学者，也可以通过流行的scikit-learn包 ([http://scikit-learn.org](http://scikit-learn.org))
    快速构建机器学习分类器，而不需要成为机器学习专家，或者使用Matplotlib ([https://matplotlib.org](https://matplotlib.org))
    或Bokeh ([https://bokeh.pydata.org](https://bokeh.pydata.org)) 快速绘制丰富的图表。
- en: 'In addition, Python has also emerged as one of the top languages for developers
    as shown in this IEEE Spectrum 2017 survey ([https://spectrum.ieee.org/computing/software/the-2017-top-programming-languages](https://spectrum.ieee.org/computing/software/the-2017-top-programming-languages)):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，Python也成为了开发者的顶级语言之一，正如IEEE Spectrum 2017年调查所示 ([https://spectrum.ieee.org/computing/software/the-2017-top-programming-languages](https://spectrum.ieee.org/computing/software/the-2017-top-programming-languages)):'
- en: '![Why choose Python?](img/B09699_02_02.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![为什么选择Python？](img/B09699_02_02.jpg)'
- en: Usage statistics by programming languages
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 按编程语言划分的使用统计
- en: 'This trend is also confirmed on GitHub where Python is now number three in
    the total number of repositories, just behind Java and JavaScript:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这一趋势在GitHub上也得到了确认，Python现在在所有仓库的总数中排名第三，仅次于Java和JavaScript：
- en: '![Why choose Python?](img/B09699_02_03.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![为什么选择Python？](img/B09699_02_03.jpg)'
- en: GitHub repositories statistics by programming language
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 按编程语言划分的GitHub仓库统计
- en: The preceding chart shows some interesting statistics, demonstrating how active
    the Python developer community is. Python - related repositories that are active
    on GitHub are the third biggest in size, with similarly healthy total code pushes
    and opened issues per repository.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图表展示了一些有趣的统计数据，说明了Python开发者社区的活跃程度。在GitHub上，Python相关的活跃仓库是第三大，拥有健康的总代码推送和每个仓库的开启问题数量。
- en: Python has also become ubiquitous on the web, powering numerous high-profile
    websites with web development frameworks, such as Django ([https://www.djangoproject.com](https://www.djangoproject.com)),
    Tornado ([http://www.tornadoweb.org](http://www.tornadoweb.org)) and TurboGears
    ([http://turbogears.org](http://turbogears.org)). More recently, there are signs
    that Python is also making its way into the field of cloud services with all major
    Cloud providers including it in some capacity in their offerings.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Python还在网页开发中变得无处不在，许多知名网站都采用了如Django ([https://www.djangoproject.com](https://www.djangoproject.com))、Tornado
    ([http://www.tornadoweb.org](http://www.tornadoweb.org))和TurboGears ([http://turbogears.org](http://turbogears.org))等网页开发框架。最近，Python也开始渗透到云服务领域，所有主要云服务提供商都将其作为某种程度的服务纳入其产品中。
- en: Python obviously has a bright future in the field of data science, especially
    when used in conjunction with powerful tools such as Jupyter Notebooks, which
    have become very popular in the data scientist community. The value proposition
    of Notebooks is that they are very easy to create and perfect for quickly running
    experiments. In addition, Notebooks support multiple high-fidelity serialization
    formats that can capture instructions, code, and results, which can then very
    easily be shared with other data scientists on the team or as open source for
    everyone to use. For example, we're seeing an explosion of Jupyter Notebooks being
    shared on GitHub, numbering in excess of 2.5 million and counting.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，Python 在数据科学领域有着光明的前景，特别是当与强大的工具如 Jupyter Notebooks 一起使用时，Jupyter Notebooks
    在数据科学家社区中已经变得非常流行。Notebook 的价值主张在于，它们非常容易创建，非常适合快速运行实验。此外，Notebook 支持多种高保真度的序列化格式，可以捕捉指令、代码和结果，然后很容易与团队中的其他数据科学家分享，或作为开源项目供所有人使用。例如，我们看到越来越多的
    Jupyter Notebooks 在 GitHub 上被分享，数量已超过 250 万，并且还在不断增加。
- en: 'The following screenshot shows the result of a GitHub search for any file with
    the extension `.ipynb,` which is the most popular format for serialized Jupyter
    Notebooks (JSON format):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了在 GitHub 上搜索所有扩展名为 `.ipynb` 的文件的结果，这是最流行的 Jupyter Notebooks 序列化格式（JSON
    格式）：
- en: '![Why choose Python?](img/B09699_02_04.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![为什么选择 Python？](img/B09699_02_04.jpg)'
- en: Search results for Jupyter Notebooks on GitHub
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GitHub 上搜索 Jupyter Notebooks 的结果
- en: This is great, but Jupyter Notebooks are too often thought of as data scientist
    tools only. We'll see in the coming chapters that they can be much more and that
    they can also help all types of teams solve data problems. For example, they can
    help business analysts quickly load and visualize a dataset, enable developers
    to work with data scientists directly within a Notebook to leverage their analytics
    and build powerful dashboards, or allow DevOps to effortlessly deploy these dashboards
    into scalable, enterprise-ready microservices that can run as standalone web applications
    or embeddable components. It is based on this vision of bringing the tools of
    data science to non-data scientists that the PixieDust open source project was
    created.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，但 Jupyter Notebooks 常常被认为仅仅是数据科学家的工具。我们将在接下来的章节中看到，它们可以做得更多，而且可以帮助所有类型的团队解决数据问题。例如，它们可以帮助业务分析师快速加载和可视化数据集，使开发者能够直接在
    Notebook 中与数据科学家合作，利用他们的分析并构建强大的仪表盘，或允许 DevOps 将这些仪表盘轻松地部署到可扩展的企业级微服务中，这些微服务可以作为独立的
    Web 应用程序运行，或者作为可嵌入的组件。正是基于将数据科学工具带给非数据科学家的愿景，才创建了 PixieDust 开源项目。
- en: Introducing PixieDust
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 PixieDust
- en: Tip
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: '**Fun fact**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**有趣的事实**'
- en: I am often asked how I came up with the name PixieDust, for which I answer that
    I simply wanted to make Notebook simple, as in magical, for non-data scientists.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我经常被问到我如何想出“PixieDust”这个名字，对此我回答说，我只是想让 Notebook 对非数据科学家来说变得简单，就像魔法一样。
- en: 'PixieDust ([https://github.com/ibm-watson-data-lab/pixiedust](https://github.com/ibm-watson-data-lab/pixiedust))
    is an open-source project composed primarily of three components designed to address the
    three goals stated at the beginning of this chapter:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: PixieDust ([https://github.com/ibm-watson-data-lab/pixiedust](https://github.com/ibm-watson-data-lab/pixiedust))
    是一个开源项目，主要由三个组件组成，旨在解决本章开头提到的三个目标：
- en: A helper Python library for Jupyter Notebooks that provides simple APIs to load
    data from various sources into popular frameworks, such as pandas and Apache Spark
    DataFrame, and then to visualize and explore the dataset interactively.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个为 Jupyter Notebooks 提供的辅助 Python 库，提供简单的 API 来将数据从各种来源加载到流行的框架中，如 pandas 和
    Apache Spark DataFrame，然后交互式地可视化和探索数据集。
- en: A simple Python-based programming model that enables developers to "productize"
    the analytics directly into the Notebook by creating powerful dashboards called
    PixieApps. As we'll see in the next chapters, PixieApps are different from traditional
    **BI** (short for, **Business Intelligence**) dashboards because developers can
    directly use HTML and CSS to create an arbitrary complex layout. In addition,
    they can embed in their business logic access to any variable, class, or function
    created in the Notebook.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种基于 Python 的简单编程模型，使开发者能够通过创建强大的仪表盘（称为 PixieApps）将分析“产品化”到 Notebook 中。正如我们将在接下来的章节中看到的，PixieApps
    与传统的 **BI**（即 **商业智能**）仪表盘不同，因为开发者可以直接使用 HTML 和 CSS 创建任意复杂的布局。此外，他们还可以在其业务逻辑中嵌入对
    Notebook 中创建的任何变量、类或函数的访问。
- en: A secure microservice web server called PixieGateway that can run PixieApps
    as standalone web applications or as components that can be embedded into any
    website. PixieApps can easily be deployed from the Jupyter Notebook using a graphical
    wizard and without requiring any code changes. In addition, PixieGateway supports
    the sharing of any charts created by PixieDust as embeddable web pages, allowing
    data scientists to easily communicate results outside of the Notebook.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种名为 PixieGateway 的安全微服务 Web 服务器，可以将 PixieApps 作为独立的 Web 应用程序运行，或作为可以嵌入任何网站的组件。PixieApps
    可以通过 Jupyter Notebook 使用图形向导轻松部署，并且无需任何代码更改。此外，PixieGateway 支持将任何由 PixieDust 创建的图表作为可嵌入的网页共享，使数据科学家可以轻松地将结果传达给
    Notebook 外部的受众。
- en: 'It is important to note that the PixieDust `display()` API primarily supports
    two popular data processing frameworks:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，PixieDust `display()` API 主要支持两种流行的数据处理框架：
- en: '**pandas** ([https://pandas.pydata.org](https://pandas.pydata.org)): By far
    the most popular Python data analysis package, pandas provides two main data structures:
    DataFrame for manipulating two-dimensional table-like datasets, and Series for
    one-dimensional column-like datasets.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pandas** ([https://pandas.pydata.org](https://pandas.pydata.org)): 迄今为止最受欢迎的
    Python 数据分析包，pandas 提供了两种主要的数据结构：DataFrame 用于处理类似二维表格的数据集，Series 用于处理一维列状数据集。'
- en: Note
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Currently, only pandas DataFrames are supported by PixieDust `display()`.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前，PixieDust `display()` 只支持 pandas DataFrame。
- en: '**Apache Spark DataFrame** ([https://spark.apache.org/docs/latest/sql-programming-guide.html](https://spark.apache.org/docs/latest/sql-programming-guide.html)):
    This is a high-level data structure for manipulating distributed datasets across
    a Spark Cluster. Spark DataFrames are built on top of the lower-level **RDD**
    (short for, **Resilient Distributed Dataset**) with the added functionality that
    it supports SQL queries.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Spark DataFrame** ([https://spark.apache.org/docs/latest/sql-programming-guide.html](https://spark.apache.org/docs/latest/sql-programming-guide.html)):
    这是一个高层数据结构，用于操作 Spark 集群中分布式数据集。Spark DataFrame 建立在低层的 **RDD**（即 **Resilient Distributed
    Dataset**）之上，并且增加了支持 SQL 查询的功能。'
- en: 'Another less commonly used format supported by PixieDust `display()` is an
    array of JSON objects. In this case, PixieDust will use the values to build the
    rows and keys are used as columns, for example, as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种 PixieDust `display()` 支持的较少使用的格式是 JSON 对象数组。在这种情况下，PixieDust 会使用这些值来构建行，并将键作为列，例如如下所示：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In addition, PixieDust is highly extensible both at the data handling and rendering
    level. For example, you can add new data types to be rendered by the visualization
    framework or if you want to leverage a plotting library you particularly like,
    you can easily add it to the list of renderers supported by PixieDust (see the
    next chapters for more details).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，PixieDust 在数据处理和渲染层面都具有高度的可扩展性。例如，你可以向可视化框架添加新的数据类型，或者如果你特别喜欢某个绘图库，你可以轻松地将其添加到
    PixieDust 支持的渲染器列表中（更多细节请参见接下来的章节）。
- en: 'You will also find that PixieDust contains a few extra utilities related to
    Apache Spark, such as the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你还会发现，PixieDust 包含了一些与 Apache Spark 相关的附加工具，例如以下内容：
- en: '**PackageManager**: This lets you install Spark packages inside a Python Notebook.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PackageManager**：这使你可以在 Python Notebook 中安装 Spark 包。'
- en: '**Scala Bridge**: This lets you use Scala directly in a Python Notebook using
    the `%%scala` magic. Variables are automatically transferred from Python to Scala and
    vice versa.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scala 桥接**：这使你可以在 Python Notebook 中直接使用 Scala，通过 `%%scala` 魔法命令。变量会自动从 Python
    转移到 Scala，反之亦然。'
- en: '**Spark Job Progress Monitor**: Track the status of any Spark job by showing
    a progress bar directly in the cell output.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark 作业进度监控器**：通过在单元格输出中显示进度条，跟踪任何 Spark 作业的状态。'
- en: Before we dive into each of the three PixieDust components, it would be a good
    idea to get access to a Jupyter Notebook, either by signing up to a hosted solution
    on the cloud (for example, Watson Studio at [https://datascience.ibm.com](https://datascience.ibm.com))
    or installing a development version on your local machine.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解 PixieDust 的三个组件之前，建议先获取一个 Jupyter Notebook，可以通过注册云端托管解决方案（例如，Watson
    Studio，网址：[https://datascience.ibm.com](https://datascience.ibm.com)）或在本地机器上安装开发版来实现。
- en: Note
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can install the Notebook server locally by following the instructions here:
    [http://jupyter.readthedocs.io/en/latest/install.html](http://jupyter.readthedocs.io/en/latest/install.html).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照以下说明在本地安装 Notebook 服务器：[http://jupyter.readthedocs.io/en/latest/install.html](http://jupyter.readthedocs.io/en/latest/install.html)。
- en: 'To start the Notebook server locally, simply run the following command from
    a Terminal:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本地启动Notebook服务器，只需从终端运行以下命令：
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The Notebook home page will automatically open in a browser. There are many
    configuration options to control how the Notebook server is launched. These options
    can be added to the command line or persisted in the Notebook configuration file.
    If you want to experiment with all the possible configuration options, you can
    generate a configuration file using the `--generate-config` option as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Notebook主页将自动在浏览器中打开。有许多配置选项可以控制Notebook服务器的启动方式。这些选项可以添加到命令行或持久化到Notebook配置文件中。如果你想尝试所有可能的配置选项，可以使用`--generate-config`选项生成一个配置文件，如下所示：
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will generate the following Python file, `<home_directory>/.jupyter/jupyter_notebook_config.py`,
    which contains a set of auto-documented options that have been disabled. For example,
    if you don''t want to have the browser automatically opened when the Jupyter Notebook
    starts, locate the line that contains the `sc.NotebookApp.open_browser` variable,
    uncomment it, and set it to `False`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下Python文件`<home_directory>/.jupyter/jupyter_notebook_config.py`，其中包含一组已禁用的自动文档选项。例如，如果你不希望Jupyter
    Notebook启动时自动打开浏览器，找到包含`sc.NotebookApp.open_browser`变量的行，取消注释并将其设置为`False`：
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: After making that change, simply save the `jupyter_notebook_config.py` file
    and restart the Notebook server.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在做完更改后，只需保存`jupyter_notebook_config.py`文件并重新启动Notebook服务器。
- en: 'The next step is to install the PixieDust library using the `pip` tool:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用`pip`工具安装PixieDust库：
- en: 'From the Notebook itself, enter the following command in a cell:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Notebook本身，输入以下命令在单元格中执行：
- en: '[PRE4]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: The exclamation point syntax is specific to Jupyter Notebook and
    denotes that the rest of the command will be executed as a system command. For
    example, you could use `!ls` to list all the files and directories that are under
    the current working directory.'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**注意**：感叹号语法是Jupyter Notebook特有的，表示后续的命令将作为系统命令执行。例如，你可以使用`!ls`列出当前工作目录下的所有文件和目录。'
- en: 'Run the cell using the **Cell** | **Run Cells** menu or the **Run** icon on
    the toolbar. You can also use the following keyboard shortcuts to run a cell:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用**单元格** | **运行单元格**菜单或工具栏上的**运行**图标来运行单元格。你也可以使用以下键盘快捷键来运行单元格：
- en: '*Ctrl* + *Enter*: Run and keep the current cell selected'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Ctrl* + *Enter*：运行并保持当前单元格选中'
- en: '*Shift* + *Enter*: Run and select the next cell'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Shift* + *Enter*：运行并选中下一个单元格'
- en: '*Alt* + *Enter*: Run and create new empty cell just below'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Alt* + *Enter*：运行并在下方创建一个新的空单元格'
- en: Restart the kernel to make sure the `pixiedust` library is correctly loaded
    into the kernel.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新启动内核以确保`pixiedust`库已正确加载到内核中。
- en: 'The following screenshot shows the results after installing `pixiedust` for
    the first time:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了首次安装`pixiedust`后的结果：
- en: '![Introducing PixieDust](img/B09699_02_05.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![介绍PixieDust](img/B09699_02_05.jpg)'
- en: Installing the PixieDust library on a Jupyter Notebook
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在Jupyter Notebook上安装PixieDust库
- en: Tip
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: I strongly recommend using Anaconda ([https://anaconda.org](https://anaconda.org)),
    which provides excellent Python package management capabilities. If, like me,
    you like to experiment with different versions of Python and libraries dependencies,
    I suggest you use Anaconda virtual environments.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈推荐使用Anaconda（[https://anaconda.org](https://anaconda.org)），它提供了优秀的Python包管理功能。如果你像我一样喜欢尝试不同版本的Python和库依赖，我建议你使用Anaconda虚拟环境。
- en: 'They are lightweight Python sandboxes that are very easy to create and activate
    (see [https://conda.io/docs/user-guide/tasks/manage-environments.html](https://conda.io/docs/user-guide/tasks/manage-environments.html)):'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 它们是轻量级的Python沙箱，创建和激活非常简单（请参见[https://conda.io/docs/user-guide/tasks/manage-environments.html](https://conda.io/docs/user-guide/tasks/manage-environments.html)）：
- en: 'Create a new environment: `conda create --name env_name`'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建新环境：`conda create --name env_name`
- en: 'List all environments: `conda env list`'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有环境：`conda env list`
- en: 'Activate an environment: `source activate env_name`'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活环境：`source activate env_name`
- en: I also recommend that, optionally, you get familiar with the source code, which
    is available at [https://github.com/ibm-watson-data-lab/pixiedust](https://github.com/ibm-watson-data-lab/pixiedust)
    and [https://github.com/ibm-watson-data-lab/pixiegateway](https://github.com/ibm-watson-data-lab/pixiegateway).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我还推荐你可以选择性地熟悉源代码，源代码可以在[https://github.com/ibm-watson-data-lab/pixiedust](https://github.com/ibm-watson-data-lab/pixiedust)和[https://github.com/ibm-watson-data-lab/pixiegateway](https://github.com/ibm-watson-data-lab/pixiegateway)找到。
- en: We are now ready to explore the PixieDust APIs starting with `sampleData()`
    in the next section.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好在下一节中探索 PixieDust API，从`sampleData()`开始。
- en: SampleData – a simple API for loading data
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SampleData – 一个简单的数据加载 API
- en: Loading data into a Notebook is one of the most repetitive tasks a data scientist
    can do, yet depending on the framework or data source being used, writing the code can
    be difficult and time-consuming.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据加载到 Notebook 中是数据科学家最常做的重复性任务之一，但根据使用的框架或数据源，编写代码可能会很困难且耗时。
- en: Let's take a concrete example of trying to load a CSV file from an open data
    site (say [https://data.cityofnewyork.us](https://data.cityofnewyork.us)) into
    both a pandas and Apache Spark DataFrame.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个具体的例子来说明，尝试从一个开放数据网站（例如 [https://data.cityofnewyork.us](https://data.cityofnewyork.us)）加载
    CSV 文件到 pandas 和 Apache Spark DataFrame。
- en: Note
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: Going forward, all the code is assumed to run in a Jupyter Notebook.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：接下来的所有代码都假定在 Jupyter Notebook 中运行。'
- en: 'For pandas, the code is pretty straightforward as it provides an API to directly
    load from URL:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 pandas，代码相当简单，因为它提供了一个直接从 URL 加载的 API：
- en: '[PRE5]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The last statement, calling `building_df,` will print its contents in the output
    cell. This is possible without a print because Jupyter is interpreting the last
    statement of a cell calling a variable as a directive to print it:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一条语句，调用`building_df,`，将在输出单元中打印其内容。由于 Jupyter 会将单元格最后一条调用变量的语句作为打印指令，因此可以在不显式使用
    `print` 的情况下实现此操作：
- en: '![SampleData – a simple API for loading data](img/B09699_02_06.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![SampleData – 一个简单的数据加载 API](img/B09699_02_06.jpg)'
- en: The default output of a pandas DataFrame
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: pandas DataFrame 的默认输出
- en: 'However, for Apache Spark, we need to first download the data into a file then
    use the Spark CSV connector to load it into a DataFrame:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于 Apache Spark，我们首先需要将数据下载到文件中，然后使用 Spark CSV 连接器将其加载到 DataFrame 中：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is slightly different since `building_df` is now a Spark DataFrame:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 输出略有不同，因为 `building_df` 现在是一个 Spark DataFrame：
- en: '![SampleData – a simple API for loading data](img/B09699_02_07.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![SampleData – 一个简单的数据加载 API](img/B09699_02_07.jpg)'
- en: Default output of a Spark DataFrame
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Spark DataFrame 的默认输出
- en: Even though this code is not that big, it has to be repeated every time and,
    most likely, will require spending the time to do a Google search to remember
    the correct syntax. The data may also be in a different format, for example, JSON,
    which will require calling different APIs both for pandas and Spark. The data
    may also not be well-formed and can contain a bad line in a CSV file or have a
    wrong JSON syntax. All these issues are unfortunately not rare and contribute
    to the 80/20 rule of data science, which states that data scientists spends on
    average 80% of their time acquiring, cleaning, and loading data and only 20% doing
    the actual analysis.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这段代码并不复杂，但每次都需要重复执行，并且很可能需要花时间做 Google 搜索来记住正确的语法。数据也可能采用不同的格式，例如 JSON，这需要调用不同的
    API，无论是对于 pandas 还是 Spark。数据可能也不是很规范，可能在 CSV 文件中有错误行，或者 JSON 语法不正确。所有这些问题不幸的是并不罕见，并且符合数据科学的
    80/20 法则，该法则表明数据科学家平均花费 80% 的时间来获取、清洗和加载数据，仅有 20% 的时间用于实际分析。
- en: 'PixieDust provides a simple `sampleData` API to help improve the situation.
    When called with no parameters, it displays a list of pre-curated datasets ready
    for analysis:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: PixieDust 提供了一个简单的 `sampleData` API 来帮助改善这种情况。当不带参数调用时，它会显示一个预先策划的、准备好进行分析的数据集列表：
- en: '[PRE7]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The results are shown as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![SampleData – a simple API for loading data](img/B09699_02_08.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![SampleData – 一个简单的数据加载 API](img/B09699_02_08.jpg)'
- en: PixieDust built-in datasets
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: PixieDust 内置数据集
- en: The list of prebuilt curated datasets can be customized to fit the organization,
    which is a good step toward our *data* pillar, as described in the previous chapter.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 预构建的策划数据集列表可以根据组织的需要进行自定义，这是朝着我们*数据*支柱迈出的好步骤，如上一章所述。
- en: The user can then simply call the `sampleData` API again with the ID of the
    prebuilt dataset and get a Spark DataFrame if the Spark framework in the Jupyter
    Kernel is available or fall back to a pandas DataFrame if not.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以简单地再次调用 `sampleData` API，传入预构建数据集的 ID，如果 Jupyter 内核中有 Spark 框架可用，则会获得一个
    Spark DataFrame；如果不可用，则会回退为 pandas DataFrame。
- en: In the following example, we call `sampleData()` on a Notebook connected with
    Spark. We also call `enableSparkJobProgressMonitor()` to display real-time information
    about the Spark jobs involved in the operation.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们在与 Spark 连接的 Notebook 上调用 `sampleData()`。我们还调用 `enableSparkJobProgressMonitor()`
    来显示涉及操作的 Spark 作业的实时信息。
- en: Note
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: Spark jobs are processes that run on a particular node in the Spark
    cluster with a specific subset of the data. In the case of loading a large amount
    data from a data source, each Spark job is given a specific subset to work on
    (the actual size depends on the number of nodes in the cluster and the size of
    the overall data), running in parallel with the other jobs.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：Spark 作业是在 Spark 集群中的特定节点上运行的进程，处理特定子集的数据。对于从数据源加载大量数据的情况，每个 Spark 作业会分配一个特定的子集来处理（实际大小取决于集群中的节点数和总体数据的大小），并与其他作业并行运行。'
- en: 'In a separate cell, we run the following code to enable the Spark Job Progress
    Monitor:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个单独的单元格中，我们运行以下代码来启用 Spark 作业进度监视器：
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The results are as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We then invoke `sampleData` to load the `cars` dataset:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们调用 `sampleData` 来加载 `cars` 数据集：
- en: '[PRE10]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The results are shown as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![SampleData – a simple API for loading data](img/B09699_02_09.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![SampleData – a simple API for loading data](img/B09699_02_09.jpg)'
- en: Loading a built-in dataset with PixieDust sampleData API
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PixieDust sampleData API 加载内置数据集
- en: 'The user can also pass an arbitrary URL that points to a downloadable file;
    PixieDust currently supports JSON and CSV files. In this case, PixieDust will
    automatically download the file, cache it in a temporary area, detect the format,
    and load it into a Spark or pandas DataFrame depending on whether Spark is available
    in the Notebook. Note that the user can also force loading into pandas even if
    Spark is available using the `forcePandas` keyword argument:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 用户还可以传入指向可下载文件的任意 URL；PixieDust 目前支持 JSON 和 CSV 文件。在这种情况下，PixieDust 会自动下载该文件，缓存到临时区域，检测格式，并根据
    Notebook 中是否可用 Spark 将其加载到 Spark 或 pandas DataFrame 中。请注意，即使 Spark 可用，用户也可以通过使用
    `forcePandas` 关键字参数强制加载到 pandas 中：
- en: '[PRE11]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The results are as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '[PRE12]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `sampleData()` API is also smart enough to recognize URLs that point to
    compressed files of the ZIP and GZ types. In this case, it will automatically
    unpack the raw binary data and load the file included in the archive. For ZIP
    files, it looks at the first file in the archive and, for GZ files, it simply
    decompresses the content as GZ files are not archives and do not contain multiple
    files. The `sampleData()` API will then load the DataFrame from the decompressed
    file.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`sampleData()` API 足够智能，能够识别指向 ZIP 和 GZ 类型压缩文件的 URL。在这种情况下，它会自动解压原始二进制数据，并加载归档中包含的文件。对于
    ZIP 文件，它会查看归档中的第一个文件，而对于 GZ 文件，它会简单地解压内容，因为 GZ 文件不是归档文件，不包含多个文件。`sampleData()`
    API 然后会从解压后的文件加载 DataFrame。'
- en: 'For example, we can directly load borough information from a ZIP file provided
    by the London open data website and display the results as a pie chart using the
    `display()` API, as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以直接从伦敦开放数据网站提供的 ZIP 文件加载区信息，并使用 `display()` API 将结果显示为饼图，具体如下：
- en: '[PRE13]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The results are as follows (assuming that your Notebook is connected to Spark,
    otherwise a pandas DataFrame will be loaded):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下（假设你的 Notebook 已连接到 Spark，否则将加载一个 pandas DataFrame）：
- en: '[PRE14]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can then call `display()` on the `london_info` DataFrame, as shown here:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以在 `london_info` DataFrame 上调用 `display()`，如图所示：
- en: '[PRE15]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We select **Pie Chart** in the Chart menu and in the **Options** dialog, we
    drag and drop the `Area name` column in the **Keys** area and the `Crime rates
    per thousand population 2014/15` in the **Values** area, as shown in the following
    screenshot:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在图表菜单中选择 **饼图**，在 **选项** 对话框中，将 `Area name` 列拖放到 **键** 区域，将 `Crime rates per
    thousand population 2014/15` 拖放到 **值** 区域，如下图所示：
- en: '![SampleData – a simple API for loading data](img/B09699_02_10.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![SampleData – a simple API for loading data](img/B09699_02_10.jpg)'
- en: Chart options for visualizing the london_info DataFrame
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 用于可视化 london_info DataFrame 的图表选项
- en: 'After clicking on the **OK** button in the **Options** dialog, we get the following
    results:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **选项** 对话框中点击 **确定** 按钮后，我们得到以下结果：
- en: '![SampleData – a simple API for loading data](img/B09699_02_11.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![SampleData – a simple API for loading data](img/B09699_02_11.jpg)'
- en: Pie chart created from a URL pointing at a compressed file
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 从指向压缩文件的 URL 创建饼图
- en: Many times, you have found a great dataset, but the file contains errors or
    the data that's important to you is in the wrong format or buried in some unstructured
    text that needs to be extracted into its own column. This process is also known
    as **data wrangling** and can be very time-consuming. In the next section, we
    will look at an extension to PixieDust called `pixiedust_rosie` that provides
    a `wrangle_data` method, which helps with this process.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 许多时候，您可能找到了一个很棒的数据集，但文件中包含错误，或者对您重要的数据格式不正确，或者被埋在一些非结构化文本中需要提取到自己的列中。这个过程也被称为**数据整理**，可能非常耗时。在接下来的部分中，我们将看到一个名为`pixiedust_rosie`的PixieDust扩展，它提供了一个`wrangle_data`方法，可以帮助处理这个过程。
- en: Wrangling data with pixiedust_rosie
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用pixiedust_rosie整理数据
- en: Working in a controlled experiment is, most of the time, not the same as working
    in the real world. By this I mean that, during development, we usually pick (or
    I should say manufacture) a sample dataset that is designed to behave; it has
    the right format, it complies with the schema specification, no data is missing,
    and so on. The goal is to focus on verifying the hypotheses and build the algorithms,
    and not so much on data cleansing, which can be very painful and time-consuming.
    However, there is an undeniable benefit to get data that is as close to the real
    thing as early as possible in the development process. To help with this task,
    I worked with two IBM colleagues, Jamie Jennings and Terry Antony, who volunteered
    to build an extension to PixieDust called `pixiedust_rosie`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在受控实验中工作，大多数情况下与在真实世界中工作并不相同。我的意思是，在开发过程中，我们通常会选择（或者我应该说制造）一个设计良好、符合模式规范、没有数据缺失等特性的样本数据集。目标是专注于验证假设并构建算法，而不是数据清洗，这可能非常痛苦和耗时。然而，在开发过程的早期尽可能接近真实数据确实有不可否认的好处。为了帮助完成这项任务，我与两位IBM同事Jamie
    Jennings和Terry Antony合作，他们志愿构建了一个名为`pixiedust_rosie`的PixieDust扩展。
- en: 'This Python package implements a simple `wrangle_data()` method to automate
    the cleansing of raw data. The `pixiedust_rosie` package currently supports CSV
    and JSON, but more formats will be added in the future. The underlying data processing
    engine uses the **Rosie Pattern Language** (**RPL**) open source component, which
    is a regular expressions engine designed to be simpler to use for developers,
    more performant, and scalable to big data. You can find more information about
    Rosie here: [http://rosie-lang.org](http://rosie-lang.org).'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这个Python包实现了一个简单的`wrangle_data()`方法来自动清理原始数据。`pixiedust_rosie`包目前支持CSV和JSON格式，但未来将添加更多格式。底层数据处理引擎使用了**Rosie模式语言（RPL）**开源组件，这是一个专为开发人员设计、更高效、可扩展到大数据的正则表达式引擎。您可以在这里找到更多关于Rosie的信息：[http://rosie-lang.org](http://rosie-lang.org)。
- en: 'To get started, you need to install the `pixiedust_rosie` package using the
    following command:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用，您需要使用以下命令安装`pixiedust_rosie`包：
- en: '[PRE16]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `pixiedust_rosie` package has a dependency on `pixiedust` and `rosie,` which will
    be automatically downloaded if not already installed on the system.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`pixiedust_rosie`包依赖于`pixiedust`和`rosie`，如果系统上尚未安装，将自动下载。'
- en: 'The `wrangle_data()` method is very similar to the `sampleData()` API. When
    called with no parameters, it will show you the list of pre-curated datasets,
    as shown here:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`wrangle_data()`方法与`sampleData()` API非常相似。如果不带参数调用，它将显示预先筛选数据集的列表，如下所示：'
- en: '[PRE17]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This produces the following results:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下结果：
- en: '![Wrangling data with pixiedust_rosie](img/B09699_02_12.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![使用pixiedust_rosie整理数据](img/B09699_02_12.jpg)'
- en: List of pre-curated datasets available for wrangle_data()
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 预先筛选的数据集列表可用于`wrangle_data()`。
- en: 'You can also invoke it with the ID of a pre-curated dataset or a URL link,
    for example, as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过预先筛选的数据集的ID或URL链接来调用它，例如：
- en: '[PRE18]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the preceding code, we invoke `wrangle_data()` on a CSV file referenced by
    the `url` variable. The function starts by downloading the file in the local filesystem
    and performs an automated data classification on a subset of the data, to infer
    the data schema. A schema editor PixieApp is then launched, which provides a set
    of wizard screens to let the user configure the schema. For example, the user
    will be able to drop and rename columns and, more importantly, destructure existing
    columns into new columns by providing Rosie patterns.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码中，我们在由`url`变量引用的CSV文件上调用`wrangle_data()`。该函数首先下载文件到本地文件系统，并对数据的一个子集执行自动化数据分类，以推断数据架构。随后启动一个架构编辑器PixieApp，提供一组向导屏幕，允许用户配置架构。例如，用户将能够删除和重命名列，更重要的是，通过提供Rosie模式将现有列解构为新列。
- en: 'The workflow is illustrated in the following diagram:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流在以下图示中进行说明：
- en: '![Wrangling data with pixiedust_rosie](img/B09699_02_13.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![使用pixiedust_rosie处理数据](img/B09699_02_13.jpg)'
- en: wrangle_data() workflow
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`wrangle_data()`工作流'
- en: 'The first screen of the `wrangle_data()` wizard shows the schema that has been inferred
    by the Rosie data classifier as shown in the following screenshot:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`wrangle_data()`向导的第一个屏幕显示了Rosie数据分类器推断出的架构，如下图所示：'
- en: '![Wrangling data with pixiedust_rosie](img/B09699_02_14.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![使用pixiedust_rosie处理数据](img/B09699_02_14.jpg)'
- en: The wrangle_data() schema editor
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`wrangle_data()`架构编辑器'
- en: 'The preceding schema widget shows the column names, `Rosie Type` (advanced type
    representation specific to Rosie) and `Column Type` (map to the supported pandas
    types). Each row also contains three action buttons:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的架构小部件显示了列名、`Rosie 类型`（特定于Rosie的高级类型表示）和`列类型`（映射到支持的pandas类型）。每一行还包含三个操作按钮：
- en: '**Delete column**: This removes the columns from the schema. This column will
    not appear in the final pandas DataFrame.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**删除列**：这将从架构中删除列。此列将不会出现在最终的pandas DataFrame中。'
- en: '**Rename column**: This changes the name of the column.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重命名列**：这将改变列的名称。'
- en: '**Transform column**: This transforms a column by destructuring it into new
    columns.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转换列**：通过将列解构为新列来转换列。'
- en: At any time, the user is able to preview the data (shown in the preceding SampleData widget)
    to validate that the schema configuration is behaving as intended.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 用户随时可以预览数据（如上面的SampleData小部件所示），以验证架构配置是否按预期运行。
- en: When the user clicks on the transform column button, a new screen is shown that
    lets the user specify patterns for building new columns. In some cases, the data
    classifier will be able to automatically detect the patterns, in which case, a
    button will be added to ask the user whether the suggestions should be applied.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户点击转换列按钮时，显示一个新屏幕，允许用户指定用于构建新列的模式。在某些情况下，数据分类器能够自动检测这些模式，在这种情况下，会添加一个按钮询问用户是否应用这些建议。
- en: 'The following screenshot shows the **Transform Selected Column** screen with
    automated suggestions:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了带有自动化建议的**转换选定列**屏幕：
- en: '![Wrangling data with pixiedust_rosie](img/B09699_02_15.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![使用pixiedust_rosie处理数据](img/B09699_02_15.jpg)'
- en: Transform column screen
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 转换列屏幕
- en: 'This screen shows four widgets with the following information:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 此屏幕显示四个小部件，包含以下信息：
- en: Rosie Pattern input is where you can enter a custom Rosie Pattern that represents
    the data for this column. You then use the **Extract Variables** button to tell
    the schema editor which part of the pattern should be extracted into a new column
    (more on that is explained soon).
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rosie模式输入框是您可以输入自定义Rosie模式的位置，用于表示此列的数据。然后，您使用**提取变量**按钮告诉架构编辑器应该将模式中的哪一部分提取到新列中（更多细节稍后解释）。
- en: There's a help widget that provides a link to the RPL documentation.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个帮助小部件，提供指向RPL文档的链接。
- en: There's a preview of the data for the current column.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示当前列的数据预览。
- en: There's a preview of the data with the Rosie Pattern applied.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示应用了Rosie模式的数据预览。
- en: 'When the user clicks on the **Extract Variables** button, the widget is updated
    as follow:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户点击**提取变量**按钮时，部件将更新为如下：
- en: '![Wrangling data with pixiedust_rosie](img/B09699_02_16.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![使用pixiedust_rosie处理数据](img/B09699_02_16.jpg)'
- en: Extracting Rosie variables into columns
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 将Rosie变量提取到列中
- en: 'At this point, the user has the option to edit the definition and then click
    on the **Create Columns** button to add the new columns to the schema. The **Sample
    of New Column(s)** widget is then updated to show a preview of what the data would
    look like. An error is shown in this widget if the pattern definition contains
    bad syntax:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，用户可以选择编辑定义，然后点击**创建列**按钮，将新列添加到架构中。**新列示例**小部件随后会更新，显示数据预览。如果模式定义包含错误语法，则此小部件会显示错误：
- en: '![Wrangling data with pixiedust_rosie](img/B09699_02_17.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![使用 pixiedust_rosie 清理数据](img/B09699_02_17.jpg)'
- en: Preview of new columns after applying pattern definitions
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 应用模式定义后的新列预览
- en: 'When the user clicks on the **Commit Columns** button, the main schema editor
    screen is displayed again with the new columns added, as shown in the following
    screenshot:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户点击**提交列**按钮时，主架构编辑器界面会再次显示，新增的列会被添加进来，如下图所示：
- en: '![Wrangling data with pixiedust_rosie](img/B09699_02_18.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![使用 pixiedust_rosie 清理数据](img/B09699_02_18.jpg)'
- en: Schema editor with new columns
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 带有新列的架构编辑器
- en: 'The final step is to click on the **Finish** button to apply the schema definition
    to the raw file and create a pandas DataFrame that will be available as a variable
    in the Notebook. At this point, the user is presented with a dialog box that contains
    a default variable name that can be edited, as shown in the following screenshot:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是点击**完成**按钮，将架构定义应用到原始文件中，并创建一个 pandas 数据框，该数据框将作为变量在笔记本中使用。此时，用户将看到一个对话框，其中包含一个可以编辑的默认变量名，如下图所示：
- en: '![Wrangling data with pixiedust_rosie](img/B09699_02_19.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![使用 pixiedust_rosie 清理数据](img/B09699_02_19.jpg)'
- en: Edit the variable name for the Result Pandas DataFrame
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑结果 Pandas 数据框的变量名称
- en: 'After clicking on the **Finish** button, `pixiedust_rosie` goes over the entire
    dataset, applying the schema definition. When done, it creates a new cell just
    below the current one with a generated code that invokes the `display()` API on
    the newly generated pandas DataFrame, as shown here:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**完成**按钮后，`pixiedust_rosie` 会遍历整个数据集，应用架构定义。完成后，它会在当前单元格下方创建一个新单元格，其中包含生成的代码，调用`display()`
    API 来显示新生成的 pandas 数据框，如下所示：
- en: '[PRE19]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Running the preceding cell will let you explore and visualize the new dataset.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面的单元格将让你探索和可视化新数据集。
- en: The `wrangle_data()` capability we've explored in this section is a first step
    toward helping data scientists spend less time cleaning the data and more time
    analyzing it. In the next section, we will discuss how to help data scientists
    with data exploration and visualization.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中探讨的`wrangle_data()`功能是帮助数据科学家减少数据清理时间、更多时间进行数据分析的第一步。在下一节中，我们将讨论如何帮助数据科学家进行数据探索和可视化。
- en: Display – a simple interactive API for data visualization
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Display – 一个简单的交互式数据可视化 API
- en: 'Data visualization is another very important data science task that is indispensable
    for exploring and forming hypotheses. Fortunately, the Python ecosystem has a
    lot of powerful libraries dedicated to data visualization, such as these popular
    examples:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可视化是数据科学中另一个非常重要的任务，它在探索和形成假设中是不可或缺的。幸运的是，Python 生态系统拥有许多强大的库，专门用于数据可视化，例如以下这些流行的例子：
- en: 'Matplotlib: [http://matplotlib.org](http://matplotlib.org)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Matplotlib: [http://matplotlib.org](http://matplotlib.org)'
- en: 'Seaborn: [https://seaborn.pydata.org](https://seaborn.pydata.org)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Seaborn: [https://seaborn.pydata.org](https://seaborn.pydata.org)'
- en: 'Bokeh: [http://bokeh.pydata.org](http://bokeh.pydata.org)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bokeh: [http://bokeh.pydata.org](http://bokeh.pydata.org)'
- en: 'Brunel: [https://brunelvis.org](https://brunelvis.org)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Brunel: [https://brunelvis.org](https://brunelvis.org)'
- en: However, similar to data loading and cleaning, using these libraries in a Notebook
    can be difficult and time-consuming. Each of these libraries come with their own
    programming model and APIs are not always easy to learn and use, especially if
    you are not an experienced developer. Another issue is that these libraries do
    not have a high-level interface to commonly used data processing frameworks such
    as pandas (except maybe Matplotlib) or Apache Spark and, as a result, a lot of
    data preparation is needed before plotting the data.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，类似于数据加载和清理，在笔记本中使用这些库可能会很困难且耗时。每个库都有自己独特的编程模型，API 学习和使用起来并不总是容易，特别是如果你不是一个有经验的开发者。另一个问题是，这些库没有提供一个高层次的接口来与常用的数据处理框架（如
    pandas（也许 Matplotlib 除外）或 Apache Spark）进行对接，因此，在绘制数据之前，需要进行大量的数据准备工作。
- en: To help with this problem, PixieDust provides a simple `display()` API that
    enables Jupyter Notebook users to plot data using an interactive graphical interface
    and without any required coding. This API doesn't actually create charts but does
    all the heavy lifting of preparing the data before delegating to a renderer by
    calling its APIs according to the user selection.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助解决这个问题，PixieDust提供了一个简单的`display()` API，使得Jupyter Notebook用户可以通过交互式图形界面绘制数据，无需编写任何代码。这个API并不直接创建图表，而是通过调用渲染器的API来处理数据准备工作，根据用户的选择委托给相应的渲染器。
- en: The `display()` API supports multiple data structures (pandas, Spark, and JSON)
    as well as multiple renderers (Matplotlib, Seaborn, Bokeh, and Brunel).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`display()` API支持多种数据结构（如pandas、Spark和JSON）以及多种渲染器（如Matplotlib、Seaborn、Bokeh和Brunel）。'
- en: 'As an illustration, let''s use the built-in car performance dataset and start
    visualizing the data by calling the `display()` API:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，让我们使用内置的汽车性能数据集，开始通过调用`display()` API来可视化数据：
- en: '[PRE20]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The first time the command is called on the cell, a tabular view is displayed
    and, as the user navigates through the menus, selected options are stored in the
    cell metadata as JSON so they can be used again the next time the cell is running.
    The output layout for all the visualizations follows the same pattern:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 当命令首次在单元格中调用时，系统会显示一个表格视图，随着用户在菜单中的导航，所选的选项会以JSON格式存储在单元格的元数据中，确保下次运行该单元格时可以重新使用。所有可视化的输出布局遵循相同的模式：
- en: There's an extensible top-level menu for switching between charts.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个可扩展的顶级菜单，用于在不同的图表之间切换。
- en: There's a download menu for downloading the file in the local machine.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个下载菜单，允许将文件下载到本地计算机。
- en: There's a filter toggle button that lets users refine their exploration by filtering
    the data. We'll discuss the filter capability in the *Filtering* section.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个过滤切换按钮，允许用户通过过滤数据来精炼他们的探索。我们将在*过滤*部分讨论过滤功能。
- en: There's a Expand/Collapse Pixiedust Output button for collapsing/expanding the output
    content.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个展开/折叠Pixiedust输出按钮，用于折叠或展开输出内容。
- en: There's an **Options** button that invokes a dialog box with configurations
    specific to the current visualization.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个**选项**按钮，点击后会弹出一个对话框，包含当前可视化的特定配置。
- en: There's a **Share** button that lets you publish the visualization on the web.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个**分享**按钮，可以让你将可视化结果发布到网络上。
- en: Note
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注
- en: '**Note**: This button can only be used if you have deployed a PixieGateway,
    which we''ll discuss in detail in [Chapter 4](ch04.xhtml "Chapter 4. Publish your
    Data Analysis to the Web - the PixieApp Tool"), *Publish your Data Analysis to
    the Web - the PixieApp Tool*.'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**注**：此按钮仅在你部署了PixieGateway后可用，详细内容将在[第4章](ch04.xhtml "第4章. 将数据分析发布到网络 - PixieApp工具")，*将数据分析发布到网络
    - PixieApp工具*中讨论。'
- en: There's a contextual set of options on the right-hand side of the visualization.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可视化的右侧有一组上下文相关的选项。
- en: There's the main visualization area.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有主可视化区域。
- en: '![Display – a simple interactive API for data visualization](img/B09699_02_20.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![显示 – 一个简单的交互式数据可视化API](img/B09699_02_20.jpg)'
- en: Visualization output layout for the table renderer
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 表格渲染器的可视化输出布局
- en: 'To start creating a chart, first select the appropriate type in the menu. Out
    of the box, PixieDust supports six types of charts: **Bar Chart**, **Line Chart**,
    **Scatter Plot**, **Pie Chart**, **Map**, and **Histogram**. As we''ll see in
    [Chapter 5](ch05.xhtml "Chapter 5. Python and PixieDust Best Practices and Advanced
    Concepts"), *Python and PixieDust Best Practices and Advanced Concepts*, PixieDust
    also provides APIs to let you customize these menus by adding new ones or adding
    options to existing ones:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始创建图表，首先在菜单中选择合适的类型。PixieDust默认支持六种类型的图表：**柱状图**、**折线图**、**散点图**、**饼图**、**地图**和**直方图**。正如我们在[第5章](ch05.xhtml
    "第5章. Python和PixieDust最佳实践及高级概念")，*Python和PixieDust最佳实践及高级概念*中看到的，PixieDust还提供API，允许你通过添加新的菜单项或为现有菜单添加选项来自定义这些菜单：
- en: '![Display – a simple interactive API for data visualization](img/B09699_02_21.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![显示 – 一个简单的交互式数据可视化API](img/B09699_02_21.jpg)'
- en: PixieDust Charts menu
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: PixieDust图表菜单
- en: The first time a chart menu is called, an options dialog will be displayed to
    configure a set of basic configuration options, such as what to use for the *X*
    and *Y* axes, the type of aggregation, and many more. To save you time, the dialog
    will be prepopulated with the data schema that PixieDust automatically introspected
    from the DataFrame.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 当首次调用图表菜单时，将显示一个选项对话框，用于配置一组基本的配置选项，例如使用*X*轴和*Y*轴的内容、聚合类型等。为了节省时间，对话框将预填充PixieDust从DataFrame自动推测的数据架构。
- en: 'In the following example, we will create a bar chart showing the average mileage
    consumption by horsepower:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将创建一个条形图，显示按马力划分的平均油耗：
- en: '![Display – a simple interactive API for data visualization](img/B09699_02_22.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![显示 – 一种简单的交互式数据可视化API](img/B09699_02_22.jpg)'
- en: Bar chart dialog options
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 条形图对话框选项
- en: 'Clicking **OK** will display the interactive interface in the cell output area:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**OK**将在单元格输出区域显示交互式界面：
- en: '![Display – a simple interactive API for data visualization](img/B09699_02_23.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![显示 – 一种简单的交互式数据可视化API](img/B09699_02_23.jpg)'
- en: Bar chart visualization
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 条形图可视化
- en: 'The canvas shows the chart in the center area and some contextual options on
    the side relevant to the type of chart selected. For example, we can select the
    field **origin** in the **Cluster By** combobox to show a breakdown by country
    of origin:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 画布显示图表在中心区域，并在侧边展示与所选图表类型相关的上下文选项。例如，我们可以在**Cluster By**下拉框中选择**origin**字段，按原产国展示细分：
- en: '![Display – a simple interactive API for data visualization](img/B09699_02_24.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![显示 – 一种简单的交互式数据可视化API](img/B09699_02_24.jpg)'
- en: Clustered bar chart visualization
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类条形图可视化
- en: As mentioned before, PixieDust `display()` doesn't actually create the chart,
    rather it prepares the data based on the selected options and does the heavy lifting
    of calling the APIs of a renderer engine, with the correct parameters. The goal
    behind this design is for each chart type to support multiple renderers without
    any extra coding, providing as much freedom of exploration to the user as possible.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，PixieDust的`display()`实际上并不创建图表，而是根据选定的选项准备数据，并且通过渲染引擎的API调用做重载工作，使用正确的参数。这种设计的目标是让每种图表类型支持多种渲染器，无需额外编程，尽可能为用户提供自由的探索空间。
- en: Out of the box, PixieDust supports the following renderers provided that the
    corresponding libraries are installed. For those that are not installed, a warning
    will be generated in the PixieDust log and the corresponding renderer will not
    be displayed in the menu. We'll cover in detail the PixieDust log in [Chapter
    5](ch05.xhtml "Chapter 5. Python and PixieDust Best Practices and Advanced Concepts"),
    *Python and PixieDust Best Practices and Advanced Concepts*.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 开箱即用，PixieDust支持以下渲染器，前提是已安装相应的库。对于未安装的库，PixieDust日志中将生成警告，并且对应的渲染器将不会在菜单中显示。我们将在[第5章](ch05.xhtml
    "第5章. Python和PixieDust最佳实践与高级概念")中详细介绍PixieDust日志，*Python和PixieDust最佳实践与高级概念*。
- en: Matplotlib ([https://matplotlib.org](https://matplotlib.org))
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib ([https://matplotlib.org](https://matplotlib.org))
- en: Seaborn ([https://seaborn.pydata.org](https://seaborn.pydata.org))
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Seaborn ([https://seaborn.pydata.org](https://seaborn.pydata.org))
- en: Note
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'This library needs to be installed using: `!pip install seaborn.`'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该库需要使用以下命令安装：`!pip install seaborn.`
- en: Bokeh ([https://bokeh.pydata.org](https://bokeh.pydata.org))
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bokeh ([https://bokeh.pydata.org](https://bokeh.pydata.org))
- en: Note
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'This library needs to be installed using: `!pip install bokeh.`'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该库需要使用以下命令安装：`!pip install bokeh.`
- en: Brunel ([https://brunelvis.org](https://brunelvis.org))
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brunel ([https://brunelvis.org](https://brunelvis.org))
- en: Note
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'This library needs to be installed using: `!pip install brunel.`'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该库需要使用以下命令安装：`!pip install brunel.`
- en: Google Map ([https://developers.google.com/maps](https://developers.google.com/maps))
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Map ([https://developers.google.com/maps](https://developers.google.com/maps))
- en: Mapbox ([https://www.mapbox.com](https://www.mapbox.com))
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mapbox ([https://www.mapbox.com](https://www.mapbox.com))
- en: Note
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: Google Map and Mapbox require an API key that you can obtain on their
    respective sites.'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**注意**：Google Map和Mapbox需要API密钥，您可以在各自的站点上获取。'
- en: 'You can switch between renderers using the **Renderer** combobox. For example,
    if we want more interactivity to explore the chart (such as zooming and panning),
    we can use the Bokeh renderer instead of Matplotlib, which gives us only a static
    image:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用**Renderer**下拉框在不同的渲染器之间切换。例如，如果我们想要更多的交互性来探索图表（如缩放和平移），我们可以使用Bokeh渲染器，而不是Matplotlib，后者仅提供静态图像：
- en: '![Display – a simple interactive API for data visualization](img/B09699_02_25.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![显示 – 一个简单的交互式数据可视化API](img/B09699_02_25.jpg)'
- en: Cluster bar chart using the Bokeh renderer
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Bokeh渲染器的簇状条形图
- en: Another chart type worth mentioning is Map, which is interesting when your data contains
    geospatial information, such as longitude, latitude, or country/state information.
    PixieDust supports multiple types of geo-mapping rendering engines including the
    popular Mapbox engine.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得一提的图表类型是Map，当你的数据包含地理空间信息时，它特别有趣，例如经度、纬度或国家/州信息。PixieDust支持多种类型的地理映射渲染引擎，包括流行的Mapbox引擎。
- en: Note
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Before using the Mapbox renderer, it is recommended to get an API key from
    the Mapbox site at this location: ([https://www.mapbox.com/help/how-access-tokens-work](https://www.mapbox.com/help/how-access-tokens-work)).
    However, if you don''t have one, a default key will be provided by PixieDust.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Mapbox渲染器之前，建议从Mapbox网站获取API密钥，网址如下：([https://www.mapbox.com/help/how-access-tokens-work](https://www.mapbox.com/help/how-access-tokens-work))。不过，如果没有密钥，PixieDust将提供一个默认密钥。
- en: 'To create a Map chart, let''s use the *Million-dollar home sales in NE Mass*
    dataset, as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建一个地图图表，下面我们使用*东北马萨诸塞百万美元住宅销售*数据集：
- en: '[PRE21]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'First, select **Map** in the chart drop-down button, then in the options dialog,
    select `LONGITUDE` and `LATITUDE` as the keys and enter the Mapbox access token
    in the provided input. You can add multiples fields in the **Values** area, and
    they will be displayed as tooltips on the map:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在图表下拉菜单中选择**Map**，然后在选项对话框中，选择`LONGITUDE`和`LATITUDE`作为键，并在提供的输入框中输入Mapbox访问令牌。你可以在**Values**区域添加多个字段，它们将作为工具提示显示在地图上：
- en: '![Display – a simple interactive API for data visualization](img/B09699_02_26.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![显示 – 一个简单的交互式数据可视化API](img/B09699_02_26.jpg)'
- en: Options dialog for Mapbox charts
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: Mapbox图表的选项对话框
- en: 'When clicking the **OK** button, you''ll get an interactive map that you can
    customize using the style (simple, choropleth, or density map), color, and basemap (light, satellite,
    dark, and outdoors) options:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 当点击**OK**按钮时，你将获得一个交互式地图，你可以使用样式（简单、分区图或密度图）、颜色和底图（亮色、卫星图、暗色和户外）选项来自定义该地图：
- en: '![Display – a simple interactive API for data visualization](img/B09699_02_27.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![显示 – 一个简单的交互式数据可视化API](img/B09699_02_27.jpg)'
- en: Interactive Mapbox visualization
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 交互式Mapbox可视化
- en: 'Each chart type has its own set of contextual options, which are self-explanatory,
    and I encourage you at this point to play with each and every one of them. If
    you find issues or have enhancement ideas, you can always create a new issue on
    GitHub at [https://github.com/ibm-watson-data-lab/pixiedust/issues](https://github.com/ibm-watson-data-lab/pixiedust/issues)
    or, better yet, submit a pull request with your code changes (there''s more information
    on how to do that here: [https://help.github.com/articles/creating-a-pull-request](https://help.github.com/articles/creating-a-pull-request)).'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 每种图表类型都有自己的一套上下文选项，这些选项不难理解，在此我鼓励你尝试每一个选项。如果遇到问题或有改进的想法，你可以随时在GitHub上创建一个新问题，网址为[https://github.com/ibm-watson-data-lab/pixiedust/issues](https://github.com/ibm-watson-data-lab/pixiedust/issues)，或者更好的是，提交一个包含代码更改的拉取请求（关于如何做这件事的更多信息可以在这里找到：[https://help.github.com/articles/creating-a-pull-request](https://help.github.com/articles/creating-a-pull-request)）。
- en: 'To avoid reconfiguring the chart every time the cell runs, PixieDust stores
    the chart options as a JSON object in the cell metadata, which is eventually saved
    in the Notebook. You can manually inspect this data by selecting the **View**
    | **Cell Toolbar** | **Edit Metadata** menu, as shown in the following screenshot:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免每次单元格运行时重新配置图表，PixieDust将图表选项存储为JSON对象在单元格元数据中，并最终保存到Notebook中。你可以通过选择**View**
    | **Cell Toolbar** | **Edit Metadata**菜单手动检查这些数据，如下所示的截图：
- en: '![Display – a simple interactive API for data visualization](img/B09699_02_28.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![显示 – 一个简单的交互式数据可视化API](img/B09699_02_28.jpg)'
- en: Show Edit Metadata button
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 显示编辑元数据按钮
- en: 'An **Edit Metadata** button will be shown at the top of the cell, which, when
    clicked on, displays the PixieDust configuration:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**Edit Metadata**按钮将显示在单元格顶部，点击该按钮后会显示PixieDust的配置：
- en: '![Display – a simple interactive API for data visualization](img/B09699_02_29.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![显示 – 一个简单的交互式数据可视化API](img/B09699_02_29.jpg)'
- en: Edit Cell Metadata dialog
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑单元格元数据对话框
- en: This JSON configuration will be important when we discuss PixieApps in the next section.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在下一节讨论PixieApps时，这个JSON配置将变得非常重要。
- en: Filtering
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过滤
- en: 'To better explore data, PixieDust also provides a built-in, simple graphical
    interface that lets you quickly filter the data being visualized. You can quickly
    invoke the filter by clicking on the filter toggle button in the top-level menu.
    To keep things simple, the filter only supports building predicates based on one
    column only, which is sufficient in most cases to validate simple hypotheses (based
    on feedback, this feature may be enhanced in the future to support multiple predicates).
    The filter UI will automatically let you select the column to filter on and, based
    on its type, will show different options:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地探索数据，PixieDust 还提供了一个内置的简单图形界面，可以让你快速筛选正在可视化的数据。你可以通过点击顶级菜单中的筛选切换按钮快速调出筛选器。为了简化操作，筛选器只支持基于单一列构建谓词，这在大多数情况下足以验证简单假设（根据反馈，未来可能会增强此功能，支持多个谓词）。筛选器的
    UI 会自动让你选择要筛选的列，并根据其类型显示不同的选项：
- en: '**Numerical type**: The user can select a mathematical comparator and enter
    a value for the operand. For convenience, the UI will also show statistical values
    related to the chosen column, which can be used when picking the operand value:![Filtering](img/B09699_02_30.jpg)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数值类型**：用户可以选择一个数学比较符并输入操作数的值。为了方便，UI 还会显示与所选列相关的统计值，这些值可以在选择操作数时使用：![筛选](img/B09699_02_30.jpg)'
- en: Filter on the mpg numerical column of the cars data set
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对汽车数据集中的 mpg 数值列进行筛选
- en: '**String type**: The user can enter an expression to match the column value,
    which can be either a regular expression or a plain string. For convenience, the UI also
    shows basic help on how to build a regular expression:'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**字符串类型**：用户可以输入一个表达式来匹配列值，可以是正则表达式或普通字符串。为了方便，UI 还会显示有关如何构建正则表达式的基本帮助：'
- en: '![Filtering](img/B09699_02_31.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![筛选](img/B09699_02_31.jpg)'
- en: Filter on the name String type of the cars dataset
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 对汽车数据集中的 name 字符串类型列进行筛选
- en: When clicking on the **Apply** button, the current visualization is updated
    to reflect the filter configuration. It is important to note that the filter applies
    to the whole cell and not only to the current visualization. Therefore, it will
    continue to apply when switching between chart types. The filter configuration
    is also saved in the cell metadata, so it will be preserved when saving the Notebook
    and rerunning the cell.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 点击 **应用** 按钮时，当前的可视化将更新，以反映筛选器的配置。需要注意的是，筛选器适用于整个单元格，而不仅仅是当前的可视化。因此，在切换图表类型时，筛选器仍然会继续应用。筛选器配置也会保存在单元格元数据中，因此在保存笔记本并重新运行单元格时，筛选器配置会被保留。
- en: 'For example, the following screenshot visualizes the `cars` dataset as a bar
    chart showing only the rows with `mpg` greater than `23,` which, according to
    the statistics box, is the mean for the dataset, and clustered by years. In the
    options dialog, we select the `mpg` column as the key and `origin` as the value:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下截图将 `cars` 数据集可视化为一个柱状图，显示 `mpg` 大于 `23` 的行，根据统计框，23 是数据集的均值，并按年份聚集。在选项对话框中，我们选择
    `mpg` 列作为键，`origin` 作为值：
- en: '![Filtering](img/B09699_02_32.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![筛选](img/B09699_02_32.jpg)'
- en: Filtered bar chart for the cars dataset
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 筛选后的汽车数据集柱状图
- en: 'To summarize, in this section, we''ve discussed how PixieDust can help with
    three difficult and time-consuming data science tasks: data loading, data wrangling,
    and data visualization. Next, we are going to see how PixieDust can help increase
    collaboration between data scientists and developers.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，在这一节中，我们讨论了 PixieDust 如何帮助解决三项复杂且耗时的数据科学任务：数据加载、数据清洗和数据可视化。接下来，我们将看到 PixieDust
    如何帮助增强数据科学家与开发人员之间的协作。
- en: Bridging the gap between developers and data scientists with PixieApps
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PixieApps 弥合开发人员和数据科学家之间的鸿沟
- en: Solving hard data problems is only part of the mission given to data science
    teams. They also need to make sure that data science results get properly operationalized
    to deliver business value to the organization. Operationalizing data analytics
    is very much use case - dependent. It could mean, for example, creating a dashboard
    that synthesizes insights for decision makers or integrating a machine learning
    model, such as a recommendation engine, into a web application.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 解决难度较大的数据问题只是数据科学团队任务的一部分。他们还需要确保数据科学结果能正确地投入实际应用，为组织创造商业价值。数据分析的操作化非常依赖于使用案例。例如，这可能意味着创建一个仪表板，用于为决策者整合见解，或者将一个机器学习模型（如推荐引擎）集成到一个网页应用中。
- en: In most cases, this is where data science meets software engineering (or as
    some would say, *where the rubber meets the road*). Sustained collaboration between
    the teams—instead of a one-time handoff—is key to a successful completion of the
    task. More often than not, they also have to grapple with different languages
    and platforms, leading to significant code rewrites by the software engineering
    team.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，这就是数据科学与软件工程相遇的地方（或者有人会说，*关键时刻*）。团队之间的持续合作——而不是一次性的交接——是任务成功完成的关键。往往他们还需要应对不同的编程语言和平台，导致软件工程团队进行大量的代码重写。
- en: We experienced it firsthand in our *Sentiment analysis of Twitter hashtags*
    project when we needed to build a real-time dashboard to visualize the results.
    The data analytics was written in Python using pandas, Apache Spark, and a few
    plotting libraries such as Matplotlib and Bokeh, while the dashboard was written
    in Node.js ([https://nodejs.org](https://nodejs.org)) and D3 ([https://d3js.org](https://d3js.org)).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*Twitter标签情感分析*项目中亲身体验到了这一点，当时我们需要构建一个实时仪表盘来可视化结果。数据分析部分是用Python编写的，使用了pandas、Apache
    Spark和一些绘图库，如Matplotlib和Bokeh，而仪表盘则是用Node.js([https://nodejs.org](https://nodejs.org))和D3([https://d3js.org](https://d3js.org))编写的。
- en: We also needed to build a data interface between the analytics and the dashboard
    and, since we needed the system to be real-time, we chose to use Apache Kafka
    to stream events formatted with the analytics results.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要在分析和仪表盘之间构建数据接口，而且由于我们需要系统是实时的，我们选择使用Apache Kafka来流式传输格式化的分析结果事件。
- en: 'The following diagram generalizes an approach that I call the **hand-off pattern**
    where the data science team builds the analytics and deploys the results in a
    data interface layer. The results are then consumed by the application. The data
    layer is usually handled by the data engineer, which is one of the roles we discussed
    in [Chapter 1](ch01.xhtml "Chapter 1. Programming and Data Science – A New Toolset"),
    *Programming and Data Science – A New Toolset*:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示概括了一种我称之为**交接模式**的方法，在这种模式下，数据科学团队构建分析并将结果部署在数据接口层中。然后，应用程序将使用这些结果。数据层通常由数据工程师处理，这也是我们在[第一章](ch01.xhtml
    "第一章：编程与数据科学——一套新工具")中讨论的角色之一，*编程与数据科学——一套新工具*：
- en: '![Bridging the gap between developers and data scientists with PixieApps](img/B09699_02_33.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![通过PixieApps弥合开发者与数据科学家的差距](img/B09699_02_33.jpg)'
- en: Hand-off between data science and engineering
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学与工程之间的交接
- en: The problem with this hand-off pattern is that it is not conducive to rapid
    iteration. Any changes in the data layer need to be synchronized with the software
    engineering team to avoid breaking the application. The idea behind PixieApps
    is to build the application while staying as close as possible to the data science
    environment, which is, in our case, the Jupyter Notebook. With this approach,
    the analytics are directly called from the PixieApp, which runs embedded in the
    Jupyter Notebook, hence making it easy for data scientists and developers to collaborate
    and iterate to make rapid improvements.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 这种交接模式的问题在于，它不利于快速迭代。数据层的任何更改都需要与软件工程团队进行同步，以避免破坏应用程序。PixieApps的理念是，在构建应用程序的同时，尽量保持与数据科学环境的接近，而在我们的案例中，数据科学环境就是Jupyter
    Notebook。通过这种方式，分析结果直接从PixieApp中调用，PixieApp嵌入在Jupyter Notebook中运行，因此数据科学家和开发人员可以轻松合作并迭代，从而实现快速改进。
- en: PixieApp defines a simple programming model for building single-page applications with
    direct access to the IPython Notebook Kernel (which is the Python backend process
    running the Notebook code). In essence, a PixieApp is a Python class that encapsulates
    both the presentation and business logic. The presentation is composed of a set
    of special methods called routes that return an arbitrary HTML fragment. Each
    PixieApp has a default route that returns the HTML fragment for the starting page.
    Developers can use custom HTML attributes to invoke other routes and dynamically
    update all or part of the page. A route may, for example, invoke a machine learning
    algorithm created from within the Notebook or generate a chart using the PixieDust
    display framework.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: PixieApp定义了一个简单的编程模型，用于构建具有直接访问IPython Notebook内核（即运行Notebook代码的Python后台进程）的单页面应用程序。本质上，PixieApp是一个Python类，封装了展示和业务逻辑。展示部分由一组特殊的方法组成，称为路由，这些方法返回任意的HTML片段。每个PixieApp都有一个默认路由，返回启动页面的HTML片段。开发人员可以使用自定义HTML属性来调用其他路由并动态更新页面的全部或部分内容。例如，一个路由可以调用一个从Notebook中创建的机器学习算法，或者使用PixieDust显示框架生成图表。
- en: 'The following diagram shows the high-level architecture of how PixieApps interact with
    the Jupyter Notebook client frontend and the IPython Kernel:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了PixieApps如何与Jupyter Notebook客户端前端和IPython内核交互的高层架构：
- en: '![Bridging the gap between developers and data scientists with PixieApps](img/B09699_02_34.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![通过PixieApps缩小开发人员和数据科学家之间的差距](img/B09699_02_34.jpg)'
- en: PixieApp interaction with the Jupyter Kernel
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: PixieApp与Jupyter内核的交互
- en: 'As a preview of what a PixieApp looks like, here''s a *hello world* sample
    application that has one button showing a bar chart for the cars DataFrame we
    created in the previous section:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 作为PixieApp外观的预览，下面是一个*hello world*示例应用程序，具有一个按钮，显示我们在前一节中创建的汽车DataFrame的条形图：
- en: '[PRE22]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'When the preceding code runs in a Notebook cell, we get the following results:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 当上面的代码在Notebook单元格中运行时，我们会得到以下结果：
- en: '![Bridging the gap between developers and data scientists with PixieApps](img/B09699_02_35.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![通过PixieApps缩小开发人员和数据科学家之间的差距](img/B09699_02_35.jpg)'
- en: Hello World PixieApp
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: Hello World PixieApp
- en: You probably have a lot of questions about the preceding code, but don't worry.
    In the next chapters, we'll cover all the PixieApp technical details, including
    how to use them in end-to-end pipelines.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能对上面的代码有很多疑问，但不用担心。在接下来的章节中，我们将涵盖所有关于PixieApp的技术细节，包括如何在端到端的管道中使用它们。
- en: Architecture for operationalizing data science analytics
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作化数据科学分析的架构
- en: 'In the previous section, we saw how PixieApps combined with the PixieDust display
    framework offer an easy way to build powerful dashboards that connect directly
    with your data analytics, allowing for rapid iterations between the algorithms
    and the user interface. This is great for rapid prototyping, but Notebooks are
    not suitable to be used in a production environment where the target persona is
    the line of business user. One obvious solution would be to rewrite the PixieApp
    using a traditional three tiers web application architecture, for example, as
    follows:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们展示了PixieApps与PixieDust显示框架结合，提供了一种便捷的方法来构建强大的仪表板，直接连接到您的数据分析，允许算法和用户界面之间的快速迭代。这非常适合快速原型设计，但Notebook不适合用于生产环境，其中目标用户是业务线用户。一个明显的解决方案是使用传统的三层Web应用架构重写PixieApp，例如，如下所示：
- en: React ([https://reactjs.org](https://reactjs.org)) for the presentation layer
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于展示层的React ([https://reactjs.org](https://reactjs.org))
- en: Node.js for the web layer
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Web层的Node.js
- en: A data access library targeted at the web analytics layer for machine learning
    scoring or running any other analytic jobs
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个面向机器学习评分或运行其他分析任务的Web分析层的数据访问库
- en: However, this would provide only a marginal improvement over the existing process,
    which would consist only, in this case, of the ability to do iterative implementation
    with the PixieApp.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这只会比现有流程提供微小的改进，在这种情况下，现有流程仅包含通过PixieApp进行迭代实现的能力。
- en: A much better solution would be to directly deploy and run PixieApps as web
    applications, including the analytics in the surrounding Notebook and, while we're at
    it, without any code change.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的解决方案是直接将PixieApps作为Web应用进行部署和运行，包括将分析嵌入周围的Notebook中，并且在此过程中，无需任何代码更改。
- en: 'Using this model, Jupyter Notebooks would become the central tool for a simplified
    development life cycle, as shown in the following diagram:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种模型，Jupyter Notebooks 将成为简化开发生命周期的核心工具，如下图所示：
- en: '![Architecture for operationalizing data science analytics](img/B09699_02_36.jpg)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![用于实现数据科学分析的架构](img/B09699_02_36.jpg)'
- en: Data science pipeline development life cycle
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学流水线开发生命周期
- en: Data scientists use a Python Notebook to load, enrich, and analyze data and
    create analytics (machine learning models, statistics, and so on)
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家使用 Python Notebook 来加载、丰富和分析数据，并创建分析（机器学习模型、统计分析等）
- en: From the same Notebook, developers create a PixieApp to operationalize these
    analytics
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在同一个 Notebook 中，开发人员创建 PixieApp 来实现这些分析。
- en: Once ready, developers publish the PixieApp as a web application, where it can
    be easily consumed interactively by line-of-business users without the need to
    access Notebooks
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦准备好，开发人员将 PixieApp 发布为 Web 应用，业务用户可以轻松地通过交互方式使用它，而无需访问 Notebooks。
- en: 'PixieDust provides an implementation of this solution with the PixieGateway
    component. PixieGateway is a web application server responsible for loading and running
    PixieApps. It is built on top of the Jupyter Kernel Gateway ([https://github.com/jupyter/kernel_gateway](https://github.com/jupyter/kernel_gateway)),
    which itself is built on top of the Tornado web framework, and therefore follows
    an architecture as shown in the following diagram:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: PixieDust 提供了一个实现该解决方案的组件 PixieGateway。PixieGateway 是一个 Web 应用服务器，负责加载和运行 PixieApps。它建立在
    Jupyter 内核网关之上（[https://github.com/jupyter/kernel_gateway](https://github.com/jupyter/kernel_gateway)），而
    Jupyter 内核网关本身是建立在 Tornado Web 框架之上的，因此遵循如下所示的架构：
- en: '![Architecture for operationalizing data science analytics](img/B09699_02_37.jpg)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![用于实现数据科学分析的架构](img/B09699_02_37.jpg)'
- en: PixieGateway architecture diagram
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: PixieGateway 架构图
- en: The PixieApp is published into the PixieGateway server directly from the Notebook
    and a URL is generated. Behind the scene, PixieGateway allocates a Jupyter Kernel
    to run the PixieApp. Based on configuration, the PixieApp could share the kernel
    instance with other apps or have a dedicated kernel based on needs. The PixieGateway
    middleware can scale horizontally by managing the lifecycle of multiple kernels
    instances, which themselves can either be local to the server or remote on a cluster.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PixieApp 直接从 Notebook 发布到 PixieGateway 服务器，并生成一个 URL。在后台，PixieGateway 为 PixieApp
    分配一个 Jupyter 内核来运行。根据配置，PixieApp 可以与其他应用共享内核实例，或者根据需求拥有专用内核。PixieGateway 中间件可以通过管理多个内核实例的生命周期进行横向扩展，这些内核实例可以是本地服务器上的，或者是集群上的远程内核。
- en: Note
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: Remote kernels must be Jupyter Kernel Gateways.'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**注意**：远程内核必须是 Jupyter 内核网关。'
- en: Using the publishing wizard, the user can optionally define security for the application.
    Multiple options are available including Basic Authentication, OAuth 2.0, and
    Bearer Token.
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用发布向导，用户可以选择性地为应用定义安全性。提供多种选项，包括基本认证、OAuth 2.0 和 Bearer Token。
- en: The line of business users accesses the app from their browser using the URL from
    step 1.
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 业务用户通过浏览器使用第一步生成的 URL 访问应用。
- en: PixieGateway provides a comprehensive admin console for managing the server
    including configuring the applications, configuring and monitoring kernels, access
    to the logs for troubleshooting, and so on.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PixieGateway 提供了一个全面的管理控制台，用于管理服务器，包括配置应用程序、配置和监控内核、访问日志进行故障排除等。
- en: The PixieGateway manages sessions for each active user and dispatches requests
    to the appropriate kernels for execution using the IPython messaging protocol
    ([http://jupyter-client.readthedocs.io/en/latest/messaging.html](http://jupyter-client.readthedocs.io/en/latest/messaging.html))
    over WebSocket or ZeroMQ depending on whether the Kernel is local or remote.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PixieGateway 为每个活跃用户管理会话，并使用 IPython 消息协议（[http://jupyter-client.readthedocs.io/en/latest/messaging.html](http://jupyter-client.readthedocs.io/en/latest/messaging.html)）通过
    WebSocket 或 ZeroMQ 调度请求到相应的内核进行执行，具体取决于内核是本地的还是远程的。
- en: 'When productizing your analytics, this solution provides a major improvement
    over the classic three-tier web application architecture because it collapses
    the web and the data tier into one **web analytics tiers,** as shown in the following
    diagram:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在将分析产品化时，这种解决方案相比经典的三层 Web 应用架构提供了显著的改进，因为它将 Web 层和数据层合并为一个**Web 分析层**，如下图所示：
- en: '![Architecture for operationalizing data science analytics](img/B09699_02_38.jpg)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![用于实现数据科学分析的架构](img/B09699_02_38.jpg)'
- en: Comparison between classic three tiers and PixieGateway web architecture
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 经典三层与 PixieGateway 网络架构的比较
- en: In the classic three-tier architecture, developers have to maintain multiple
    REST endpoints that invoke the analytics in the data tier and massage the data
    to comply with the presentation tier requirements for correctly displaying the
    data. As a result, a lot of engineering has to be added to these endpoints, increasing
    the cost of development and code maintenance. In contrast, in the PixieGateway
    two-tier architecture, developers do not have to worry about creating endpoints
    because the server is responsible for dispatching the requests to the appropriate
    kernel using built-in generic endpoints. Explained another way, the PixieApp Python
    methods automatically become endpoints for the presentation tier without any code
    change. This model is conducive to rapid iterations since any change in the Python
    code is directly reflected in the application after republishing.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在经典的三层架构中，开发人员必须维护多个 REST 接口，这些接口调用数据层的分析功能，并对数据进行处理，以满足展示层的要求，从而正确显示数据。因此，必须在这些接口中添加大量工程工作，增加了开发和代码维护的成本。相比之下，在
    PixieGateway 的两层架构中，开发人员不需要担心创建接口，因为服务器负责通过内置的通用接口将请求分发到适当的内核。换句话说，PixieApp 的
    Python 方法会自动成为展示层的接口，而无需任何代码更改。这种模型有利于快速迭代，因为 Python 代码的任何变化都能在重新发布后直接反映到应用程序中。
- en: PixieApps are great to rapidly build single-page applications and dashboards.
    However, you may also want to generate simpler one-page reports and share them
    with your users. To that end, PixieGateway also lets you share charts generated
    by the `display()` API using the **Share** button, resulting in a URL linking
    to a web page containing the chart. In turn, a user can embed the chart into a
    website or a blog post by copying and pasting the code generated for the page.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: PixieApps 非常适合快速构建单页面应用和仪表板。然而，你可能还希望生成更简单的一页报告并与用户分享。为此，PixieGateway 还允许你通过
    **共享** 按钮共享由 `display()` API 生成的图表，生成一个链接到包含图表的网页的 URL。反过来，用户可以通过复制并粘贴为该页面生成的代码，将图表嵌入到网站或博客文章中。
- en: Note
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注释
- en: '**Note**: We''ll cover PixieGateway in details in [Chapter 4](ch04.xhtml "Chapter 4. Publish
    your Data Analysis to the Web - the PixieApp Tool"), *Publish your Data Analysis
    to the Web - the PixieApp Tool*, including how to install a new instance both
    locally and on the cloud.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '**注**：我们将在[第 4 章](ch04.xhtml "第 4 章：将数据分析发布到 Web - PixieApp 工具")中详细介绍 PixieGateway，*将数据分析发布到
    Web - PixieApp 工具*，包括如何在本地和云端安装新实例。'
- en: 'To demonstrate this capability, let''s use the cars DataFrame created earlier:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示此功能，我们使用之前创建的车辆 DataFrame：
- en: '![Architecture for operationalizing data science analytics](img/B09699_02_39.jpg)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![操作化数据科学分析的架构](img/B09699_02_39.jpg)'
- en: Share Chart dialog
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 分享图表对话框
- en: 'If sharing is successful, then the next page will show the generated URL and
    the code snippet to embed into a web application or blog post:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 如果共享成功，下一页将显示生成的 URL 和嵌入到网页或博客文章中的代码片段：
- en: '![Architecture for operationalizing data science analytics](img/B09699_02_40.jpg)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![操作化数据科学分析的架构](img/B09699_02_40.jpg)'
- en: Confirmation of a shared chart
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 确认共享图表
- en: 'Clicking on the link will take you to the page:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 点击链接将会带你到该页面：
- en: '![Architecture for operationalizing data science analytics](img/B09699_02_41.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![操作化数据科学分析的架构](img/B09699_02_41.jpg)'
- en: Display chart as a web page
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 将图表显示为网页
- en: Summary
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we discussed the reasons why our data science tooling strategy
    was centered around Python and Jupyter Notebook. We also introduced the PixieDust
    capabilities that improve user productivity with features such as the following:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了为什么我们的数据科学工具策略以 Python 和 Jupyter Notebook 为中心。我们还介绍了 PixieDust 的功能，通过以下特点提高用户生产力：
- en: Data loading and cleaning
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据加载与清洗
- en: Data visualization and exploration without any coding
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无需编码即可进行数据可视化和探索
- en: A simple programming model based on HTML and CSS, called PixieApp, for building
    tools and dashboards that interact directly with the Notebook
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个基于 HTML 和 CSS 的简单编程模型，称为 PixieApp，用于构建与 Notebook 直接交互的工具和仪表板
- en: A point and click mechanism to publish charts and PixieApp directly to the web
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种点选机制，将图表和 PixieApp 直接发布到网页
- en: In the next chapter, we'll do a deep dive on the PixieApp programming model,
    discussing every aspect of the APIs with numerous code samples.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨 PixieApp 编程模型，讨论 API 的各个方面，并附上大量代码示例。
