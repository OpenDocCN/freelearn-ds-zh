- en: Chapter 4. Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章 分类
- en: '|   | *"It is a truth universally acknowledged, that a single man in possession
    of a good fortune, must be in want of a wife."* |   |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '|   | *“世人皆知，一个拥有财富的单身汉，一定渴望拥有一位妻子。”* |   |'
- en: '|   | --*Jane Austen, Pride and Prejudice* |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|   | --*简·奥斯汀，《傲慢与偏见》* |'
- en: In the previous chapter, we learned how to make numeric predictions using linear
    regression. The model we built was able to learn how the features of Olympic swimmers
    related to their weight and we were able to use the model to make a weight prediction
    for a new swimmer. As with all regression techniques, our output was a number.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章，我们学习了如何使用线性回归进行数值预测。我们建立的模型能够学习奥林匹克游泳运动员的特征与体重之间的关系，并且我们能够利用这个模型为新的游泳运动员预测体重。与所有回归技术一样，我们的输出是一个数值。
- en: Not all predictions demand a numeric solution, though—sometimes we want our
    predictions to be items. For example, we may want to predict which candidate a
    voter will back in an election. Or we may want to know which of several products
    a customer is likely to buy. In these cases, the outcome is a selection from one
    of a number of possible discrete options. We call these options classes, and models
    we'll build in this chapter are classifiers.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并不是所有的预测都需要数值解答——有时我们希望预测的是项目。例如，我们可能希望预测选民在选举中支持哪位候选人。或者我们可能想知道顾客可能购买哪一款产品。在这些情况下，结果是从若干个离散的选项中做出的选择。我们称这些选项为类别，而我们将在本章构建的模型是分类器。
- en: We'll learn about several different types of classifier and compare their performance
    on a sample dataset—the list of passengers from the Titanic. Prediction and classification
    are intimately connected to theories of probability and information, and so we'll
    cover these in more detail too. We'll begin the chapter with ways of measuring
    relative probabilities between groups and move then on to applying statistical
    significance testing to the groups themselves.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习几种不同类型的分类器，并比较它们在一个样本数据集上的表现——泰坦尼克号的乘客名单。预测和分类与概率论和信息理论紧密相关，因此我们也将更详细地讨论这些内容。我们将从衡量不同组之间的相对概率开始，然后转向对这些组进行统计显著性测试。
- en: About the data
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于数据
- en: This chapter will make use of data about the passengers on the Titanic, which
    famously sank on her maiden voyage in 1912 after hitting an iceberg. The survival
    rates of passengers were strongly affected by a variety of factors, including
    class and sex.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将使用关于泰坦尼克号乘客的数据，泰坦尼克号在1912年首航时因撞上冰山而沉没。乘客的生还率受多种因素的强烈影响，包括舱位和性别。
- en: The dataset is derived from a painstakingly compiled dataset produced by Michael
    A. Findlay. For more information about how the data was derived, including links
    to original sources, consult the book's wiki at [http://wiki.clojuredatascience.com](http://wiki.clojuredatascience.com).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集来自于由Michael A. Findlay精心编制的一个数据集。如需了解有关数据来源的更多信息，包括原始来源的链接，请参阅本书的维基页面：[http://wiki.clojuredatascience.com](http://wiki.clojuredatascience.com)。
- en: Note
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The example code for this chapter is available from Packt Publishing's website
    or from [https://github.com/clojuredatascience/ch4-classification](https://github.com/clojuredatascience/ch4-classification).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的示例代码可以从Packt Publishing的网站或[https://github.com/clojuredatascience/ch4-classification](https://github.com/clojuredatascience/ch4-classification)获取。
- en: The data is small enough to have been included together with the source code
    in the data directory.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据量足够小，因此它与源代码一起包含在数据目录中。
- en: Inspecting the data
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查数据
- en: We encountered categorical variables in the previous chapter as the dichotomous
    variable "sex" in the athlete dataset. That dataset also contained many other
    categorical variables including "sport", "event", and "country".
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们遇到了类别变量，例如运动员数据集中的二元变量“性别”。该数据集还包含许多其他类别变量，包括“运动”、“项目”和“国家”。
- en: 'Let''s take a look at the Titanic dataset (using the `clojure.java.io` library
    to access the file resource and the `incanter.io` library to read it in):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看泰坦尼克号数据集（使用`clojure.java.io`库来访问文件资源，并使用`incanter.io`库来读取数据）：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding code generates the following table:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了以下表格：
- en: '![Inspecting the data](img/7180OS_04_100.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![检查数据](img/7180OS_04_100.jpg)'
- en: The Titanic dataset includes categorical variables too. For example—**:sex**,
    **:pclass** (the passenger class), and **:embarked** (a letter signifying the
    port of boarding). These are all string values, taking categories such as **female**,
    **first**, and **C**, but classes don't always have to be string values. Columns
    such as **:ticket**, **:boat**, and **:body** can be thought of as containing
    categorical variables too. Despite having numeric values, they are simply labels
    that have been applied to things.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Titanic 数据集也包含类别变量。例如，**:sex**、**:pclass**（乘客等级）和**:embarked**（表示登船港口的字母）。这些都是字符串值，取值如
    **female**、**first** 和 **C**，但是类别不一定总是字符串值。像 **:ticket**、**:boat** 和 **:body**
    这样的列也可以视为包含类别变量。尽管它们具有数字值，但它们仅仅是被应用于事物的标签。
- en: Note
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A categorical variable is one that can take on only a discrete number of values.
    This is in contrast to a continuous variable that can take on any value within
    its range.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 类别变量是指只能取离散值的变量。这与连续变量不同，后者可以在其范围内取任何值。
- en: Other numbers representing counts are not so easy to define. The field **:sibsp**
    reports how many companions (spouse or siblings) were traveling with a passenger.
    These are counts, and their units are people. But they could just as easily represent
    labels, with **0** standing for "a passenger with no companions" and **1** "a
    passenger with one companion", and so on. There are only a small set of labels,
    and so the field's representation as a number is largely convenience. In other
    words, we could choose to represent **:sibsp** (and **:parch**—a count of related
    parents and children) as either categorical or numerical features.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 其他代表计数的数字并不那么容易定义。字段 **:sibsp** 报告乘客随行的伙伴（配偶或兄弟姐妹）数量。这些是计数，单位是人。但它们也可以很容易地表示为标签，其中
    **0** 代表“没有伙伴的乘客”，**1** 代表“有一个伙伴的乘客”，以此类推。标签的集合很小，因此该字段作为数字的表示主要是为了方便。换句话说，我们可以选择将
    **:sibsp**（以及 **:parch** —— 计数相关父母和孩子）表示为类别特征或数值特征。
- en: Since categorical variables don't make sense on the number line, we can't plot
    a chart showing how these numbers relate to each other. We can construct a frequency
    table, though, showing how the counts of passengers in each of the groups are
    distributed. Since there are two sets of two variables, there are four groups
    in total.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于类别变量在数值轴上没有意义，我们无法绘制一张图表来显示这些数字之间的关系。然而，我们可以构建一个频率表，展示每个组中乘客的计数是如何分布的。由于有两组两个变量，所以总共有四个组。
- en: 'The data can be summarized using Incanter core''s `$rollup` function:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以使用 Incanter 核心的 `$rollup` 函数进行汇总：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Incanter's `$rollup` requires that we provide three arguments—a function with
    which to "roll up" a group of rows, a column to roll up, and the columns whose
    unique values define the groups of interest. Any function that reduces a sequence
    to a single value can be used as a rollup function, but some are so common we
    can supply the keywords `:min`, `:max`, `:sum`, `:count`, and `:mean` instead.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Incanter 的 `$rollup` 要求我们提供三个参数——一个函数用于“汇总”一组行，一个要汇总的列，以及定义感兴趣组的唯一值的列。任何将序列减少为单一值的函数都可以作为汇总函数，但有些函数非常常见，我们可以使用关键字
    `:min`、`:max`、`:sum`、`:count` 和 `:mean` 来代替。
- en: 'The example generates the following table:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例生成了如下表格：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This chart represents the frequencies of passengers falling into the various
    groups "males who perished", "females who survived", and so on. There are several
    ways of making sense of frequency counts like this; let's start with the most
    common.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图表表示了乘客在各个组别中的频率，例如“死亡男性”、“幸存女性”等。对于这样的频率计数，有几种方式可以理解；我们从最常见的一种开始。
- en: Comparisons with relative risk and odds
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与相对风险和几率的比较
- en: 'The preceding Incanter dataset is an easily comprehensible representation of
    our data, but to extract the numbers for each of the groups individually we''ll
    want to store the data in a more readily accessible data structure. Let''s write
    a function to convert the dataset to a series of nested maps:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的 Incanter 数据集是我们数据的一个易于理解的表示，但为了提取每个组的单独数据，我们需要将数据存储在更易于访问的数据结构中。让我们写一个函数，将数据集转换为一系列嵌套的映射：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'For example, we can use the `frequency-map` function as follows to calculate
    a nested map of `:sex` and `:survived`:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以使用 `frequency-map` 函数，如下所示，计算 `:sex` 和 `:survived` 的嵌套映射：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'More generally, given any dataset and sequence of columns, this will make it
    easier to pull out just the counts we''re interested in. We''re going to be comparing
    the survival rates of males and females, so let''s use Clojure''s `get-in` function
    to extract the number of fatalities for men and women as well as the overall counts
    of men and women:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地，给定任何数据集和列序列，这将使我们更容易提取出我们感兴趣的计数。我们将比较男性和女性的生存率，所以我们使用 Clojure 的 `get-in`
    函数来提取男性和女性的死亡人数，以及男性和女性的总人数：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'From these numbers, we can calculate simple ratios. Relative risk is a ratio
    of probabilities of an event occurring in two separate groups:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些数字中，我们可以计算简单的比率。相对风险是两组中事件发生概率的比值：
- en: '![Comparisons with relative risk and odds](img/7180OS_04_01.jpg)![Comparisons
    with relative risk and odds](img/7180OS_04_02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![与相对风险和赔率的比较](img/7180OS_04_01.jpg)![与相对风险和赔率的比较](img/7180OS_04_02.jpg)'
- en: 'Where *P(event)* is the probability of the event occurring. The risk of perishing
    on the Titanic as a male was *682* divided by *843*; the risk of perishing on
    the Titanic as a female was *127* divided by *466*:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*P(event)* 是事件发生的概率。作为男性，在泰坦尼克号上遇难的风险是*682*除以*843*；作为女性，在泰坦尼克号上遇难的风险是*127*除以*466*：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In other words, the risk of perishing on the Titanic was almost three times
    higher if you were a man. The relative risk is often used in healthcare to show
    how one's chances of developing an illness are affected by some other factor.
    A relative risk of one means that there is no difference in risk between the groups.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，如果你是男性，那么在泰坦尼克号上遇难的风险几乎是女性的三倍。相对风险通常用于医疗领域，用来展示某个因素如何影响一个人患病的几率。相对风险为一意味着两组之间的风险没有差异。
- en: 'In contrast, the odds ratio can be either positive or negative and measures
    the extent to which being in a group raises your odds of some other attribute.
    As with any correlation, no causation is implied. Both attributes could of course
    be linked by a third property—their mutual cause:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，赔率比可以是正数或负数，衡量的是在某一组中，某一特征的概率增加的程度。和任何相关性一样，这并不意味着存在因果关系。两个属性当然可以通过第三个因素——它们的共同原因——关联起来：
- en: '![Comparisons with relative risk and odds](img/7180OS_04_03.jpg)![Comparisons
    with relative risk and odds](img/7180OS_04_04.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![与相对风险和赔率的比较](img/7180OS_04_03.jpg)![与相对风险和赔率的比较](img/7180OS_04_04.jpg)'
- en: 'The odds of perishing as a male are *682*:*161* and the odds of perishing as
    a female are *127*:*339*. The odds ratio is simply the ratio of the two:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 作为男性遇难的赔率是*682*:*161*，作为女性遇难的赔率是*127*:*339*。赔率比就是这两者的比值：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This example shows how the odds ratio is sensitive to stating relative positions,
    and can generate much larger numbers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子展示了赔率比如何对相对位置的陈述敏感，并且可能产生更大的数字。
- en: Tip
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: When presented with ratios, make sure you're aware whether they're relative-risk
    or odds ratios. While the two approaches appear similar, they output results over
    very different ranges.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在面对比率时，确保你清楚它们是相对风险比（relative-risk）还是赔率比（odds ratio）。虽然这两种方法看起来相似，但它们的输出结果在不同的范围内。
- en: Compare the two equations for relative risk and odds ratio. The numerators are
    the same in each case but for risk the denominator is all females, whereas with
    the odds ratio it is females who survived.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 比较相对风险和赔率比的两个公式。在每种情况下，分子是相同的，但对于风险而言，分母是所有女性，而对于赔率比来说，分母是幸存的女性。
- en: The standard error of a proportion
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比例的标准误差
- en: It's clear that the proportion of women surviving the Titanic is much greater
    than the proportion of men. But, as with the dwell time differences we encountered
    in [Chapter 2](ch02.xhtml "Chapter 2. Inference"), *Inference*, we should ask
    ourselves whether these differences could have occurred due to chance alone.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，女性在泰坦尼克号上幸存的比例远高于男性。但正如我们在[第 2 章](ch02.xhtml "第 2 章. 推断") *推断* 中遇到的停留时间差异一样，我们应该问自己，这些差异是否可能仅仅是由于偶然因素导致的。
- en: We have seen in previous chapters how to construct confidence intervals around
    statistics based on the sample's standard error. The standard error is based on
    the sample's variance, but what is the variance of a proportion? No matter how
    many samples we take, only one proportion will be generated—the proportion in
    the overall sample.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前几章中已经看到，如何根据样本的标准误差构建统计量的置信区间。标准误差是基于样本的方差计算的，但比例的方差是多少呢？无论我们取多少样本，生成的比例只有一个——即总体样本中的比例。
- en: Clearly a proportion is still subject to some sort of variance. When we flip
    a fair coin 10 times we would expect to get roughly five heads, but there's it's
    not impossible we'd get ten heads in a row.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，比例仍然会受到某种程度的方差影响。当我们将一枚公平的硬币抛掷10次时，我们预期大约会得到五次正面，但并不是不可能出现连续十次正面。
- en: Estimation using bootstrapping
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用引导法的估算
- en: In [Chapter 2](ch02.xhtml "Chapter 2. Inference"), *Inference*, we learned about
    bootstrapping statistics such as the mean and we saw how bootstrapping can be
    a useful way of estimating parameters through simulation. Let's use bootstrapping
    to estimate the standard error of the proportion of female passengers surviving
    the Titanic.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](ch02.xhtml "Chapter 2. Inference")，*推断*中，我们学习了引导统计量，如均值，并看到了引导法如何通过模拟估算参数。让我们使用引导法来估算泰坦尼克号女性乘客幸存比例的标准误差。
- en: 'We can represent the 466 female passengers as a sequence of zeros and ones.
    Zero could represent a passenger who perished, and one a passenger who survived.
    This is a convenient representation because it means the sum of the whole sequence
    equals the total number of passengers who survived. By taking repeated random
    samples of 466 elements from this sequence of 466 zeros and ones, and taking the
    sum each time, we can get an estimate of the variance in the proportion:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将466名女性乘客表示为一个零和一的序列。零可以表示一位遇难的乘客，一则表示一位幸存的乘客。这是一种方便的表示方式，因为这意味着整个序列的和等于幸存乘客的总数。通过从这个由466个零和一组成的序列中反复随机抽取466个元素，并计算每次的总和，我们可以估算比例的方差：
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The preceding code generates the following histogram:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下直方图：
- en: '![Estimation using bootstrapping](img/7180OS_04_110.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![使用引导法估算](img/7180OS_04_110.jpg)'
- en: 'The histogram appears to show a normal distribution with a mean of 339—the
    measured number of female survivors. The standard deviation of this distribution
    is the standard error of the sampled survivors and we can calculate it simply
    from the bootstrapped samples like so:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图似乎显示了一个均值为339的正态分布——即测得的女性幸存者数量。这个分布的标准差是采样幸存者的标准误差，我们可以通过简单地从引导样本中计算得出：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Your standard deviation may be slightly different, depending on chance variation
    in the bootstrapped sample. It should be very close, though.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你的标准差可能会略有不同，具体取决于引导样本中的偶然变化。不过，它应该非常接近。
- en: The units of standard deviation are people—female passengers—so to figure out
    the standard error of the proportion we have to divide this through by the total
    number of passengers in our sample, 466\. This yields a standard error of the
    proportion of 0.021.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 标准差的单位是人——女性乘客——因此，为了计算比例的标准误差，我们必须将其除以样本中的总乘客人数，即466人。这样得到的比例标准误差是0.021。
- en: The binomial distribution
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二项分布
- en: The preceding histogram looks a great deal like a normal distribution, but in
    fact it is a binomial distribution. The two distributions are very similar, but
    the binomial distribution is used to model cases where we want to determine how
    many times a binary event is expected to occur.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的直方图看起来非常像正态分布，但实际上它是一个二项分布。这两种分布非常相似，但二项分布用于建模我们希望确定二元事件发生次数的情况。
- en: 'Let''s plot both the binomial and the normal distribution on a histogram to
    see how they compare:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将二项分布和正态分布同时绘制在直方图上，以便比较它们的差异：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding code generates the following chart:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下图表：
- en: '![The binomial distribution](img/7180OS_04_120.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![二项分布](img/7180OS_04_120.jpg)'
- en: Notice how in the preceding chart the line corresponding to the binomial distribution
    is jagged—it represents discrete counts of things rather than a continuous value
    such as the normal distribution.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在前面的图表中，与二项分布对应的线是锯齿形的——它表示的是离散的计数，而不是像正态分布那样的连续值。
- en: The standard error of a proportion formula
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比例的标准误差公式
- en: 'We have calculated the standard error empirically and found it to equal 0.021,
    using only the proportion of female survivors and the total number of female passengers.
    Although it''s been instructive to see what the standard error of the proportion
    is actually measuring, there is a formula that allows us to get there in one step:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过经验计算出了标准误差，并发现其值为0.021，仅使用了女性幸存者的比例和女性乘客的总数。尽管看到比例的标准误差实际上测量的内容很有启发性，但有一个公式可以让我们一步到位地得到这个结果：
- en: '![The standard error of a proportion formula](img/7180OS_04_05.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![比例的标准误差公式](img/7180OS_04_05.jpg)'
- en: 'Substituting in the counts of female survivors gives us the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 将女性幸存者的计数代入公式后，我们得到如下结果：
- en: '![The standard error of a proportion formula](img/7180OS_04_06.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![比例的标准误差公式](img/7180OS_04_06.jpg)'
- en: Fortunately, this number closely matches the standard error we calculated through
    bootstrapping. It's not exact, of course, since our bootstrapping calculation
    has its own sampling error.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这个数字与我们通过自助法（bootstrapping）计算得出的标准误差非常接近。当然，这不是完全一样的，因为我们的自助法计算有自己的抽样误差。
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The equation for the standard error of a proportion gives us an important insight—the
    value of *p(1 - p)* is greatest when *p* is close to 0.5\. This means that the
    greatest standard error in a proportion is when the proportion is close to a half.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 比例的标准误差公式为我们提供了一个重要的见解——当*p*接近0.5时，*p(1 - p)*的值最大。这意味着，当比例接近一半时，比例的标准误差最大。
- en: If this seems surprising to you, consider this—when the proportion is 50 percent,
    the variation in the sample is greatest. Like a fair coin toss, we have no way
    of predicting what the next value will be. As the proportion increases (or decreases)
    within the sample, the data becomes increasingly homogenous. As a result, the
    variation decreases, and so the standard error decreases accordingly.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这让你感到惊讶，可以考虑这一点——当比例为50%时，样本中的变异性最大。就像公平的掷硬币一样，我们无法预测下一个值会是什么。当样本中的比例增大（或减小）时，数据变得越来越同质。因此，变异性减少，从而标准误差也相应减少。
- en: Significance testing proportions
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 显著性检验比例
- en: 'Let''s return to the question of whether the measured differences in male or
    female fatality rates could be due to chance alone. As in [Chapter 2](ch02.xhtml
    "Chapter 2. Inference"), *Inference*, our *z*-test is simply the difference in
    proportions divided by the pooled standard error:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到问题：男女死亡率的差异是否仅仅是偶然的结果。如同[第2章](ch02.xhtml "第2章 推断")中所述，*推断*，我们的*z*检验实际上是将比例的差异除以合并的标准误差：
- en: '![Significance testing proportions](img/7180OS_04_07.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![显著性检验比例](img/7180OS_04_07.jpg)'
- en: In the preceding formula, *p*[1] denotes the proportion of women who survived,
    that is, *339/466 = 0.73*. And *p*[2] denotes the proportion of men who survived,
    that is, *161/843 = 0.19*.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的公式中，*p*[1]表示幸存女性的比例，即*p*339/466 = 0.73*。而*p*[2]表示幸存男性的比例，即*p*161/843 = 0.19*。
- en: 'To calculate the *z*-statistic, we need to pool our standard errors for the
    two proportions. Our proportions measure the survival rates of males and females
    respectively, so the pooled standard error is simply the standard error of the
    males and females combined, or the total survival rate overall, as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算*z*统计量，我们需要合并两个比例的标准误差。我们的比例分别衡量了男性和女性的生还率，因此合并的标准误差实际上就是男性和女性的标准误差之和，或整体的总生还率，计算公式如下：
- en: '![Significance testing proportions](img/7180OS_04_08.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![显著性检验比例](img/7180OS_04_08.jpg)'
- en: 'Substituting the values into the equation for the *z*-statistic:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 将数值代入*z*统计量的公式：
- en: '![Significance testing proportions](img/7180OS_04_09.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![显著性检验比例](img/7180OS_04_09.jpg)'
- en: 'Using a *z*-score means we''ll use the normal distribution to look up the *p*-value:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 使用*z*分数意味着我们将使用正态分布查找*p*-值：
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As we have a one-tailed test, the *p*-value is the probability that the *z*-score
    is less than 39.95\. The response is zero, corresponding to a very, very significant
    result. This allows us to reject the null hypothesis and conclude that the difference
    between survival rates between men and women was certainly not down to chance
    alone.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们进行的是单尾检验，*p*-值是*z*分数小于39.95的概率。答案为零，表示这是一个非常非常显著的结果。这使我们能够拒绝零假设，并得出结论：男女之间的生还率差异显然不仅仅是偶然的结果。
- en: Adjusting standard errors for large samples
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整大样本的标准误差
- en: You may be wondering why we're talking about standard errors at all. The data
    we have on passengers on the Titanic is not a sample of a wider population. It
    is the population. There was only one Titanic and only one fateful journey.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会好奇，为什么我们要讨论标准误差。我们关于泰坦尼克号乘客的数据并不是来自一个更大人群的样本，它就是整个样本。泰坦尼克号只有一艘，而且只有一次命运多舛的航行。
- en: While this is true in one sense, there are many ways in which the Titanic disaster
    could have occurred. If the "women and children first" instructions had not been
    followed or had been followed more universally, a different set of results would
    have been obtained. If there had been enough lifeboats for everyone, or the evacuation
    process had run more smoothly, then this would have been represented in the outcome
    too.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然从某种意义上讲这是正确的，但泰坦尼克号灾难发生的方式有很多种。如果没有遵循“妇女和儿童优先”的指示，或者更普遍地遵循了这些指示，结果可能会有所不同。如果每个人都有足够的救生艇，或者疏散过程更顺利，那么这些因素也会体现在结果中。
- en: Standard error and significance testing allows us to treat the disaster as one
    of an infinite number of potential similar disasters and determine whether the
    observed differences are likely to have been systemic or purely coincidental.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 标准误差和显著性检验使我们能够将灾难视为无数潜在相似灾难之一，并确定观察到的差异是否可能是系统性的，还是纯粹的巧合。
- en: 'That said, sometimes we are more interested in how confident we can be that
    our samples are representative of a finite, quantified population. Where samples
    begin to measure more than about 10 percent of the population, we can adjust the
    standard error downwards to account for the decreased uncertainty:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，有时我们更关心的是我们对样本是否能够代表有限的、量化的人群的信心。随着样本开始测量总体的10%以上时，我们可以通过调整标准误差来降低不确定性：
- en: '![Adjusting standard errors for large samples](img/7180OS_04_10.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![为大样本调整标准误差](img/7180OS_04_10.jpg)'
- en: 'This can be written in Clojure as:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以用 Clojure 编写如下：
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Where *N* is the size of the overall population. As the sample size increases
    relative to the size of the population, *(N - n)* tends towards zero. If you sample
    the entire population, then any difference in proportion—however small—is going
    to be judged significant.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*N* 是总体人口的大小。当样本量相对于总体人口的大小增加时，*(N - n)* 会趋近于零。如果你采样了整个总体，那么无论比例差异多么微小，都会被判断为显著的。'
- en: Chi-squared multiple significance testing
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卡方检验的多重显著性检验
- en: Not all categories are dichotomous (such as male and female, survived and perished).
    Although we would expect categorical variables to have a finite number of categories,
    there is no hard upper limit on the number of categories a particular attribute
    can have.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有类别都是二元的（例如男性和女性，生还和遇难）。虽然我们期望类别变量有有限数量的类别，但对于特定属性的类别数并没有硬性上限。
- en: We could use other categorical variables to separate out the passengers on the
    Titanic, such as the class in which they were traveling. There were three class
    levels on the Titanic, and the `frequency-table` function we constructed at the
    beginning of this chapter is already able to handle multiple classes.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用其他类别变量来区分泰坦尼克号上的乘客，例如他们乘坐的舱位。泰坦尼克号有三个舱位等级，而我们在本章开头构建的 `frequency-table`
    函数已经能够处理多个舱位。
- en: '[PRE14]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This code generates the following frequency table:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成了以下的频率表：
- en: '[PRE15]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: These three classes give us an additional way to cut our data on survival rates.
    As the number of classes increases, it becomes harder to read patterns in the
    frequency table, so let's visualize it.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个舱位为我们提供了一个额外的方式来分析生还率数据。随着舱位数量的增加，在频率表中识别模式变得更加困难，因此我们可以将其可视化。
- en: Visualizing the categories
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化类别
- en: Although they were originally devised to represent proportions, pie charts are
    generally not a good way to represent parts of a whole. People have a difficult
    time visually comparing the areas of slices of a circle. Representing quantities
    linearly, as with a stacked bar chart, is nearly always a better approach. Not
    only are the areas easier to interpret but they're easier to compare side by side.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管饼图最初是为了表示比例而设计的，但通常不是表示部分与整体关系的好方式。人们很难在视觉上比较圆形切片的面积。将数量线性表示，如堆叠柱状图，几乎总是更好的方法。不仅面积更容易解释，而且它们更容易并排比较。
- en: 'We can visualize our data as a stacked bar chart:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将数据可视化为堆叠柱状图：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The preceding code generates the following chart:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下图表：
- en: '![Visualizing the categories](img/7180OS_04_130.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![可视化类别](img/7180OS_04_130.jpg)'
- en: The data clearly shows a difference in both the number of passengers who perished,
    and the proportion of passengers who perished, most visible between first and
    third class. We'd like to determine if this difference is significant.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清楚地显示了乘客死亡人数和比例之间的差异，尤其是在头等舱和三等舱之间最为明显。我们想确定这种差异是否显著。
- en: We could perform a *z*-test between each pair of proportions but, as we learned
    in [Chapter 2](ch02.xhtml "Chapter 2. Inference"), *Inference*, this is much more
    likely to lead to Type I errors and cause us to find a significant result where,
    in fact, there is none.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在每对比例之间执行*z*检验，但正如我们在[第2章](ch02.xhtml "Chapter 2. Inference")学到的那样，这很可能导致Ⅰ型错误，并导致我们在事实上没有显著结果时找到显著结果。
- en: The problem of multiple-category significance testing may seem to call for the
    *F*-test but the *F*-test is based on the ratio of variance of some continuous
    variable within and between groups. What we'd like, therefore, is a similar test
    that cares only about the relative proportion between groups. This is the premise
    on which the *X*² test is based.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 多类别显著性测试的问题似乎需要进行*F*检验，但*F*检验基于某些连续变量在组内和组间方差的比率。因此，我们需要的是一个类似的测试，它只关心组之间的相对比例。这是*X*²检验的基础。
- en: The chi-squared test
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卡方检验
- en: Pronounced *kai square*, the *X*² test is a statistical test applied to sets
    of categorical data to evaluate how likely it is that any observed difference
    between proportions of those categories in the sets arose by chance.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 发音为*kai square*，*X*²检验是应用于分类数据集的统计检验，用于评估观察到的不同类别比例之间差异可能是由于偶然因素引起的概率。
- en: When performing a *X*² test, therefore, our null hypothesis is that the observed
    difference in proportions between groups is simply the result of chance variation.
    We can think of this as an independence test between two categorical variables.
    If category *A* is the passenger class and category *B* is whether they survived
    or not, the null hypothesis is that passenger class and survival rate are independent
    of each other. The alternate hypothesis is that the categories are not independent—that
    the passenger class and survival are related to each other in some way.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在进行*X*²检验时，我们的零假设是组间观察到的比例差异仅仅是由于偶然变异所导致的结果。我们可以将其视为两个分类变量之间的独立性检验。如果类别*A*是乘客等级，类别*B*是是否存活，则零假设是乘客等级和生存率彼此独立。备择假设是这些类别不独立——乘客等级和生存率在某种程度上相关。
- en: 'The *X*² statistic is calculated by comparing the observed frequency counts
    from the sample to a table of frequencies calculated under the assumption of independence.
    This frequency table is an estimation of what the data would have looked like
    had the categories been independent. We can calculate the frequency table assuming
    independence in the following way, using the row, column, and grand totals:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*X*²统计量是通过将样本的观察频率与根据独立性假设计算的频率表进行比较而计算的。这个频率表是估计数据如果类别独立会是什么样子的。我们可以通过以下方式计算假设独立的频率表，使用行、列和总计：'
- en: '|   | Survived | Perished | Total |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|   | 生存 | 未生存 | 总计 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| First Class | *323*500/1309 = 123.4* | *323*809/1309 = 199.6* | *323* |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 一等舱 | *323*500/1309 = 123.4* | *323*809/1309 = 199.6* | *323* |'
- en: '| Second Class | *277*500/1309 = 105.8* | *277*809/1309 = 171.2* | *277* |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 二等舱 | *277*500/1309 = 105.8* | *277*809/1309 = 171.2* | *277* |'
- en: '| Third Class | *709*500/1309 = 270.8* | *709*809/1309 = 438.2* | *709* |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 三等舱 | *709*500/1309 = 270.8* | *709*809/1309 = 438.2* | *709* |'
- en: '| Total | *500* | *809* | *1,309* |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | *500* | *809* | *1,309* |'
- en: A simple formula calculates each cell value using only the totals for each row
    and column, and assumes an even distribution amongst cells. This is our table
    of expected frequencies.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的公式仅使用每行和每列的总数计算每个单元格的值，并假设在单元格之间有均匀分布。这是我们的预期频率表。
- en: '[PRE17]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To demonstrate a statistically significant difference between the survival rates
    by class, we'll need to show that the difference between the frequencies assuming
    independence and the observed frequencies is unlikely to have arisen through chance
    alone.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明不同乘客等级的生存率之间的统计显著差异，我们需要表明假设独立和观察频率之间的差异不太可能仅仅是由于偶然因素引起的。
- en: The chi-squared statistic
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卡方统计量
- en: 'The *X*²statistic simply measures how far the actual frequencies differ from
    those calculated under the assumption of independence:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*X*²统计量简单地衡量了实际频率与假设独立情况下计算的频率之间的差异：'
- en: '![The chi-squared statistic](img/7180OS_04_11.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![卡方统计量](img/7180OS_04_11.jpg)'
- en: '*F*[ij] is the expected frequency assuming independence for categories *i*
    and *j*, and *f*[ij] is the observed frequency for categories *i* and *j*. We
    therefore need to fetch the observed frequencies for our data. We can calculate
    this in Clojure as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '*F*[ij] 是假设类别 *i* 和 *j* 独立时的预期频率，而 *f*[ij] 是类别 *i* 和 *j* 的观察频率。因此，我们需要获取数据的观察频率。我们可以在
    Clojure 中如下计算：'
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As with the `expected-frequencies` function earlier, the `observed-frequencies`
    function returns a sequence of frequency counts for each combination of categories.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的 `expected-frequencies` 函数一样，`observed-frequencies` 函数返回每一对类别组合的频率计数序列。
- en: '[PRE19]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This sequence—and the sequence of expected values from the previous example—give
    us all we need to calculate the *X*² statistic:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个序列——以及前面示例中预期值的序列——为我们提供了计算 *X*² 统计量所需的所有信息：
- en: '[PRE20]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now that we have our test statistic, we'll need to look this up in the relevant
    distribution to determine if the result is significant. Unsurprisingly, the distribution
    we refer to is the *X*² distribution.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了检验统计量，我们需要查找相关的分布，以确定结果是否显著。毫不奇怪，我们参照的分布是 *X*² 分布。
- en: The chi-squared test
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卡方检验
- en: 'The *X*²distribution is paramaterized by one degree of freedom: the product
    of each of the category counts less one:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*X*² 分布由一个自由度参数化：每个类别计数减去 1 的乘积：'
- en: '![The chi-squared test](img/7180OS_04_12.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![卡方检验](img/7180OS_04_12.jpg)'
- en: Here, *a* is the number of categories for attribute *A* and *b* is the number
    of categories for attribute *B*. For our Titanic data, *a* is *3* and *b* is *2*,
    so our degrees of freedom parameter is *2*.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*a* 是属性 *A* 的类别数量，*b* 是属性 *B* 的类别数量。对于我们的泰坦尼克号数据，*a* 是 *3*，*b* 是 *2*，所以我们的自由度参数是
    *2*。
- en: 'Our *X*² test simply needs to view our *X*² statistic against the *X*² cumulative
    distribution function (CDF). Let''s do this now:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 *X*² 检验只需要将我们的 *X*² 统计量与 *X*² 累积分布函数（CDF）进行对比。我们现在来做这个：
- en: '[PRE21]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This is an absolutely tiny number, and is as close to zero as makes no difference
    so we can comfortably reject the null hypothesis at any significance level. In
    other words, we can be absolutely certain that the observed difference is not
    the result of a chance sampling error.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个极其小的数字，接近于零，可以认为它没有差别，因此我们可以在任何显著性水平下放心地拒绝原假设。换句话说，我们可以完全确信观察到的差异不是偶然抽样误差的结果。
- en: 'Although it is useful to see the *X*² conducted by hand, the Incanter stats
    namespace has a function, `chisq-test`, for conducting the *X*² test in one step.
    To use it we simply need to supply our original table of observations as a matrix:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管手动进行 *X*² 检验很有用，但 Incanter stats 命名空间有一个函数 `chisq-test`，可以一步完成 *X*² 检验。使用这个函数，我们只需要将原始的观察表作为矩阵提供给它：
- en: '[PRE22]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In preceding the code, we calculated a frequency-table from the Titanic data
    and then ordered the contents, using `i/$order`, so that we get a table like this:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们从泰坦尼克号数据中计算了一个频率表，并使用 `i/$order` 对其内容进行排序，这样我们就得到了像这样的表格：
- en: '[PRE23]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We take the count column and convert it into a matrix of three columns using
    `(i/matrix frequencies 3)`:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们取计数列，并使用 `(i/matrix frequencies 3)` 将其转换为一个包含三列的矩阵：
- en: '[PRE24]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This matrix is the only input required by Incanter's `s/chisq-test` function.
    Run the example and you'll see the response is a map containing keys `:X-sq`,
    the *X*² statistic, and `:p-value`, the result of the test, amongst many others.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这个矩阵是 Incanter 的 `s/chisq-test` 函数所需的唯一输入。运行示例，你将看到响应是一个包含键 `:X-sq`（*X*² 统计量）和
    `:p-value`（检验结果）等的映射。
- en: We have established that the categories of class and survived, and gender and
    survived are certainly not independent. This is analogous to discovering a correlation
    between variables—height, sex, and weight—in the previous chapter.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经确定类别 "是否幸存" 和 "性别" 之间的关系绝对不是独立的。这类似于在上一章中发现变量——身高、性别和体重——之间的相关性。
- en: Now, as then, the next step is to use the dependence between the variables to
    make predictions. Whereas in the previous chapter our output was a predicted number—the
    weight—in this chapter our output will be a class—a prediction about whether the
    passenger survived or not. Assigning items to their expected class based on other
    attributes is the process of classification.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，接下来的步骤是利用变量之间的依赖关系进行预测。在上一章中，我们的输出是一个预测数字——权重，而在这一章中，我们的输出将是一个类别——关于乘客是否幸存的预测。根据其他属性将项目分配到其预期类别的过程就是分类。
- en: Classification with logistic regression
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用逻辑回归进行分类
- en: 'In the previous chapter, we saw how linear regression produces a predicted
    value, *ŷ*, from an input vector *x* and a vector of coefficients *β*:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章，我们看到线性回归如何从输入向量*x*和系数向量*β*中生成预测值*ŷ*：
- en: '![Classification with logistic regression](img/7180OS_04_13.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![使用逻辑回归进行分类](img/7180OS_04_13.jpg)'
- en: 'Here, *ŷ* can be any real number. Logistic regression proceeds in a very similar
    way, but adjusts the prediction to guarantee an answer only between zero and one:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*ŷ*可以是任何实数。逻辑回归的过程非常类似，但它调整预测值，确保结果仅在零和一之间。
- en: '![Classification with logistic regression](img/7180OS_04_14.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![使用逻辑回归进行分类](img/7180OS_04_14.jpg)'
- en: 'Zero and one represent two different classes. The change is a simple one; we
    simply wrap the prediction in a function *g* that constrains the output between
    zero and one:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 零和一代表两种不同的类别。这个变化非常简单；我们只是将预测值包装在一个函数*g*中，该函数将输出限制在零和一之间：
- en: '![Classification with logistic regression](img/7180OS_04_15.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![使用逻辑回归进行分类](img/7180OS_04_15.jpg)'
- en: Where *g* is called the **sigmoid** **function**. This seemingly minor change
    is enough to transform linear regression into logistic regression and turn real-valued
    predictions into classes.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*g*被称为**Sigmoid** **函数**。这个看似微小的变化足以将线性回归转变为逻辑回归，并将实数值预测转化为类别。
- en: The sigmoid function
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sigmoid函数
- en: 'The sigmoid function is also referred to as the *logistic function* and is
    shown next:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid函数也被称为*逻辑函数*，如图所示：
- en: '![The sigmoid function](img/7180OS_04_16.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![Sigmoid函数](img/7180OS_04_16.jpg)'
- en: For positive inputs, the logistic function rises quickly to one while, for negative
    inputs, it falls quickly to zero. These outputs correspond to the predicted classes.
    For values close to zero, the logistic function returns values close to **0.5**.
    This corresponds to increased uncertainty about the correct output class.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于正输入，逻辑函数快速上升至一，而对于负输入，它会迅速下降至零。这些输出对应着预测的类别。对于接近零的值，逻辑函数返回接近**0.5**的值，这意味着对正确输出类别的判断不确定性增大。
- en: '![The sigmoid function](img/7180OS_04_140.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![Sigmoid函数](img/7180OS_04_140.jpg)'
- en: 'Combining the formulae we have seen already gives rise to the following complete
    definition of the logistic hypothesis:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 结合我们已经看到的公式，得出以下完整的逻辑假设定义：
- en: '![The sigmoid function](img/7180OS_04_17.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![Sigmoid函数](img/7180OS_04_17.jpg)'
- en: 'As with linear regression, the parameter vector *β* contains the coefficients
    that we''re seeking to learn, and *x* is our vector of input features. We can
    express this in Clojure with the following higher-order function. Given a vector
    of coefficients, this function returns a function that will calculate *ŷ* for
    a given *x*:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性回归一样，参数向量*β*包含我们要学习的系数，*x*是我们的输入特征向量。我们可以用Clojure表达这一点，使用以下的高阶函数。给定一个系数向量，这个函数返回一个函数，该函数将为给定的*x*计算*ŷ*：
- en: '[PRE25]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'If the logistic function is given a *β* of `[0]`, then the feature is discounted
    as having any predictive power. The function will output `0.5`, corresponding
    to complete uncertainty, for any input *x*:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果逻辑函数给定的*β*为`[0]`，那么该特征将被认为没有任何预测能力。对于任何输入*x*，该函数将输出`0.5`，对应完全的不确定性：
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: However, if values other than zero are provided as coefficients, the sigmoid
    function can return values other than `0.5`. A positive *β* will result in a greater
    probability of a positive class given a positive *x*, whereas a negative *β* will
    correspond to a greater probability of a negative class given a positive *x*.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果提供了非零的系数，Sigmoid函数可能会返回`0.5`以外的值。正的*β*会使得给定正的*x*时，正类的概率增大，而负的*β*会使得给定正的*x*时，负类的概率增大。
- en: '[PRE27]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Since values above `0.5` correspond to a positive class and values less than
    `0.5` correspond to a negative class, the sigmoid function output can simply be
    rounded to the nearest integer to get the output class. This would result in values
    of exactly `0.5` being classified as the positive class.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大于`0.5`的值对应正类，小于`0.5`的值对应负类，Sigmoid函数的输出可以简单地四舍五入到最接近的整数，从而获得输出类别。这样，恰好为`0.5`的值会被分类为正类。
- en: Now that we have a `sigmoid-function` that can return class predictions, we
    need to learn the parameters *β* which yield the best predictions *ŷ*. In the
    previous chapter, we saw two methods for calculating the coefficients for a linear
    model—calculating the slope and intercept using covariance, and the normal equation
    using matrices. In both cases the equations were able to find a linear solution
    that minimized the least-squares estimates of our model.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个`sigmoid-function`可以返回类别预测，我们需要学习参数*β*，以产生最佳预测*ŷ*。在前一章中，我们看到了两种计算线性模型系数的方法——使用协方差计算斜率和截距，以及使用矩阵的正规方程。在这两种情况下，方程都能找到一个线性解，以最小化我们模型的最小二乘估计。
- en: The squared error was an appropriate function to use for our linear model, but
    it doesn't translate well to classification where classes are measured only between
    zero and one. We need an alternative method of determining how incorrect our predictions
    are.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 平方误差是我们线性模型适合的适当函数，但在分类问题中，类别只在零和一之间测量，它不能很好地转化为确定我们预测不正确程度的方法。我们需要一种替代方法。
- en: The logistic regression cost function
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归成本函数
- en: As with linear regression, the logistic regression algorithm must learn from
    data. The `cost` function is a way to let the algorithm know how well, or poorly,
    it's doing.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性回归类似，逻辑回归算法必须从数据中学习。`cost`函数是让算法知道其表现如何的一种方式，好或坏。
- en: 'The following is the `cost` function for logistic regression, which imposes
    a different cost depending on whether the output class is supposed to be zero
    or one. The cost for a single training example is calculated like so:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是逻辑回归的`cost`函数，它根据输出类别是否应为零或一施加不同的成本。单个训练示例的成本计算如下：
- en: '![The logistic regression cost function](img/7180OS_04_18.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归成本函数](img/7180OS_04_18.jpg)'
- en: This pair of functions captures the intuition that, if *ŷ* = 0 but *y* = 1,
    then the model should be penalized by a very large cost. Symmetrically, the model
    should also be heavily penalized if *ŷ* = 1 and *y* = 0\. Where the model closely
    agrees with the data, the cost falls steeply towards zero.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这对函数捕捉到这样的直觉，即如果*ŷ* = 0，但*y* = 1，则模型应受到非常大的惩罚成本。对称地，如果*ŷ* = 1，而*y* = 0，则模型也应受到严重惩罚。当模型与数据高度一致时，成本急剧下降至零。
- en: 'This is the cost for an individual training point. To combine the individual
    costs and calculate an overall cost for a given vector of coefficients and a set
    of training data, we can simply take the average across all the training examples:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这是单个训练点的成本。要结合个别成本并计算给定系数向量和一组训练数据的总体成本，我们可以简单地取所有训练示例的平均值：
- en: '![The logistic regression cost function](img/7180OS_04_19.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归成本函数](img/7180OS_04_19.jpg)'
- en: 'This can be represented in Clojure as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在Clojure中可以表示为：
- en: '[PRE28]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Now that we have a `cost` function that can quantify how incorrect our predictions
    are, the next step is to make use of this information to figure out better predictions.
    The very best classifier will be the one with the lowest overall cost, since by
    definition its predicted classes will be closest to the true classes. The method
    by which we can incrementally improve our cost is called **gradient descent**.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个`cost`函数，可以量化我们预测不正确的程度，下一步是利用这些信息来找出更好的预测。最佳分类器将是总体成本最低的分类器，因为根据定义，其预测类将最接近真实类。我们可以通过所谓的**梯度下降**方法逐步改进我们的成本。
- en: Parameter optimization with gradient descent
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用梯度下降进行参数优化
- en: The cost function, also called the **loss function**, is the function that calculates
    the error of the model based on our coefficients. Different parameters will generate
    different costs for the same dataset, and we can visualize how the cost function
    changes with respect to the parameters on a graph.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 成本函数，也称为**损失函数**，是根据我们的系数计算模型误差的函数。不同的参数将为相同的数据集生成不同的成本，我们可以在图表上可视化成本函数随参数变化的情况。
- en: '![Parameter optimization with gradient descent](img/7180OS_04_150.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![使用梯度下降进行参数优化](img/7180OS_04_150.jpg)'
- en: The preceding chart shows a representation of a cost function for a two-parameter
    model. The cost is plotted on the *y* axis (higher values correspond to a higher
    cost) and the two parameters are plotted on the *x* and *z* axes, respectively.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表显示了两参数模型的成本函数表示。成本在*y*轴上绘制（较高的值对应较高的成本），两个参数分别在*x*轴和*z*轴上绘制。
- en: The best parameters are the ones that minimize the cost function, corresponding
    to the parameters at the point identified as the "Global minimum". We don't know
    ahead of time what these parameters will be, but we can make an initial, arbitrary
    guess. These parameters are the ones identified by the point "P".
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳参数是那些最小化成本函数的参数，对应于被标记为“全局最小值”的点。我们无法提前知道这些参数是什么，但可以进行初步的任意猜测。这些参数对应于点“P”。
- en: Gradient descent is an algorithm that iteratively improves on the initial condition
    by following the gradient downhill towards the minimum value. When the algorithm
    can't descend any further, the minimum cost has been found. The parameters at
    this point correspond to our best estimate for the parameters that minimize the
    cost function.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一种通过沿着梯度向下迭代改进初始条件的算法，直到找到最小值。当算法无法进一步下降时，最小成本就找到了。此时的参数对应于我们对于最小化成本函数的最佳估计。
- en: Gradient descent with Incanter
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有Incanter的梯度下降
- en: Incanter provides the ability to run gradient descent with the function `minimize`
    in the `incanter.optimize` namespace. Mathematical optimization is the general
    term for a series of techniques that aim to find the best available solution to
    some set of constraints. The `incanter.optimize` namespace contains functions
    for calculating the parameters that will minimize or maximize the value of any
    arbitrary function.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Incanter提供了使用`incanter.optimize`命名空间中的`minimize`函数运行梯度下降的功能。数学优化是指一系列旨在找到某组约束条件下最佳解决方案的技术的总称。`incanter.optimize`命名空间包含了用于计算能最小化或最大化任意函数值的参数的函数。
- en: 'For example, the following code finds the minimum value of `f` given a starting
    position of `10`. Since `f` is *x*², the input that will produce the minimum value
    is `0`:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下代码在给定初始位置`10`的情况下找到`f`的最小值。由于`f`是*x*²，产生最小值的输入是`0`：
- en: '[PRE29]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Indeed, if you run the example you should get an answer very close to zero.
    You are very unlikely to get exactly zero though because gradient descent tends
    to provide only approximate answers—Incanter's `minimize` function accepts a tolerance
    argument `:tol` that defaults to 0.00001\. If the result differs by less than
    this amount between iterations, then the equation is said to have converged. The
    function also accepts a `:max-iter` argument, the maximum number of steps to take
    before returning an answer, irrespective of convergence.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，如果你运行这个例子，你应该得到一个非常接近零的答案。然而，由于梯度下降往往只提供近似答案，你不太可能得到准确的零—Incanter的`minimize`函数接受一个容差参数`:tol`，默认为0.00001。如果结果在迭代之间的差异小于这个值，则表示方程已经收敛。该函数还接受一个`:max-iter`参数，即在返回答案之前最多执行的步数，不考虑是否已收敛。
- en: Convexity
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 凸性
- en: 'Gradient descent is not always guaranteed to find the lowest possible cost
    for all equations. For example, the answer may find what is called a "local minimum",
    which represents the lowest cost in the vicinity of the initial guess but doesn''t
    represent the best overall solution to the problem. This is illustrated in the
    following illustration:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降并不总能确保找到所有方程的最低成本。例如，结果可能找到所谓的“局部最小值”，它表示初始猜测附近的最低成本，但并不代表问题的最佳整体解决方案。以下图示说明了这一点：
- en: '![Convexity](img/7180OS_04_160.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![凸性](img/7180OS_04_160.jpg)'
- en: If the initial position corresponds to either of the points labeled **C** on
    the graph, then the algorithm will converge to a local minimum. Gradient descent
    will have found a minimum, but it is not the best overall solution. Only initial
    guesses within the range **A** to **B** will converge on the global minimum.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果初始位置对应于图中标记为**C**的点，则算法将收敛到局部最小值。梯度下降会找到一个最小值，但这不是最佳的整体解决方案。只有初始猜测位于**A**到**B**的范围内，才会收敛到全局最小值。
- en: It is therefore possible that gradient descent will converge to different answers
    depending on its initialization. For gradient descent to guarantee the optimal
    solution, the equation to optimize needs to be a convex equation. This means that
    there is a single global minimum and no local minima.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，梯度下降可能会根据其初始化收敛到不同的答案。为了确保找到最优解，梯度下降要求优化的方程必须是凸的。这意味着方程只有一个全局最小值，且没有局部最小值。
- en: 'For example, there is no global minimum of the `sin` function. The result we
    calculate for the minimum will depend strongly on our starting conditions:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`sin`函数没有全局最小值。我们计算出的最小值将强烈依赖于我们的初始条件：
- en: '[PRE30]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Fortunately, logistic regression is a convex function. This means that gradient
    descent will be able to determine the values of our coefficients corresponding
    to the global minimum irrespective of our starting position.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，逻辑回归是一个凸函数。这意味着无论我们从哪里开始，梯度下降都能确定对应全局最小值的系数值。
- en: Implementing logistic regression with Incanter
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Incanter 实现逻辑回归
- en: 'We can define a logistic regression function with Incanter''s `minimize` function
    as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下方式使用 Incanter 的 `minimize` 函数来定义逻辑回归函数：
- en: '[PRE31]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The `cost-fn` accepts a matrix of coefficients. We create a classifier from
    the coefficients using the `sigmoid-function` previously defined, and a sequence
    of predictions, `y-hats`, based on the input data. Finally, we can calculate and
    return the `logistic-cost` value based on the provided coefficients.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '`cost-fn` 接受一个系数矩阵。我们使用之前定义的 `sigmoid-function` 从系数创建分类器，并基于输入数据生成一系列预测值 `y-hats`。最后，我们可以基于提供的系数计算并返回
    `logistic-cost` 值。'
- en: To perform logistic regression, we minimize the logistic `cost-fn` by selecting
    the optimal parameters to the `sigmoid-function`. Since we have to start somewhere,
    our initial coefficients are simply `0.0` for each parameter.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行逻辑回归，我们通过选择最优参数来最小化逻辑 `cost-fn`，并传递给 `sigmoid-function`。由于我们必须从某个地方开始，我们的初始系数就是每个参数的
    `0.0`。
- en: The `minimize` function expects to receive an input in numeric form. Like the
    athlete data in the previous chapter, we have to convert our Titanic data into
    a feature matrix and create dummy variables for our categorical data.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`minimize` 函数期望接收数字形式的输入。像上一章的运动员数据一样，我们需要将 Titanic 数据转换为特征矩阵，并为类别数据创建虚拟变量。'
- en: Creating a feature matrix
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建特征矩阵
- en: Let's define a function, `add-dummy`, that will create a dummy variable for
    a given column. Where the value in the input column equals a particular value,
    the dummy column will contain a `1`. Where the value in the input column does
    not contain that value, the dummy column will be `0`.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个函数 `add-dummy`，它将为给定的列创建一个虚拟变量。当输入列中的值等于某个特定值时，虚拟列将包含 `1`。当输入列中的值不等于该值时，虚拟列将为
    `0`。
- en: '[PRE32]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This simple function makes it very straightforward to convert our Titanic data
    to a feature matrix:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的函数使得将 Titanic 数据转换为特征矩阵变得非常简单：
- en: '[PRE33]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Our output matrix will entirely consist of zeros and ones. The first element
    in the feature matrix is the dummy variable determining survival. This is our
    class label. `0` corresponds to perishing and `1` corresponds to survival. The
    second is a `bias` term, which always contains the value `1.0`.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的输出矩阵将完全由零和一组成。特征矩阵的第一个元素是决定生存的虚拟变量。这是我们的类标签。`0` 代表死亡，`1` 代表生存。第二个是 `bias`
    项，始终包含值 `1.0`。
- en: 'With our `matrix-dataset` and `logistic-regression` functions defined, running
    logistic regression is as simple as this:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了我们的 `matrix-dataset` 和 `logistic-regression` 函数后，运行逻辑回归就像这样简单：
- en: '[PRE34]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We''re providing `0` to Incanter''s `i/$` function to select the first column
    of the matrix (the classes), and [`:not 0`] to select everything else (the features):'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为 Incanter 的 `i/$` 函数提供 `0`，以选择矩阵的第一列（类），并使用 [`:not 0`] 来选择其他所有项（特征）：
- en: '[PRE35]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: If you run this example, you'll find that it returns a vector of numbers. This
    vector corresponds to the best estimates for the coefficients of the logistic
    model.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行这个例子，你会发现它返回一个数字向量。这个向量对应于逻辑回归模型系数的最佳估计值。
- en: Evaluating the logistic regression classifier
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估逻辑回归分类器
- en: 'The vector calculated in the previous section contains the coefficients of
    our logistic model. We can make predictions with them by passing them to our `sigmoid-function`
    like this:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一部分计算的向量包含了我们逻辑回归模型的系数。我们可以通过将这些系数传递给我们的 `sigmoid-function` 来进行预测，如下所示：
- en: '[PRE36]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'You can see that the classifier is not doing a perfect job—it''s confused by
    some of the classes. In the first ten results, it''s getting four classes incorrect,
    which is only just better than chance. Let''s see what proportion of classes was
    correctly identified over the entire dataset:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到分类器并没有做得完美——它对一些类感到困惑。在前十个结果中，它将四个类预测错误，这只比随机猜测稍好一点。让我们看看在整个数据集中正确识别的类的比例：
- en: '[PRE37]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In the preceding code we train a classifier as before, and simply map over the
    entire dataset looking for predictions that equal observed classes. We use Clojure
    core's `frequencies` function to provide a simple count of the number of times
    the classes are equal.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们像以前一样训练一个分类器，然后简单地遍历整个数据集，查找预测结果与观察到的类别是否相同。我们使用 Clojure 核心的 `frequencies`
    函数来提供一个简单的计数，统计类别相等的次数。
- en: Predicting the correct outcome 1,021 times out of 1,309 equates to 78 percent
    correct. Our classifier is definitely performing better than chance.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在 1,309 次预测中，正确预测 1,021 次意味着 78%的正确率。我们的分类器显然比随机猜测要好。
- en: The confusion matrix
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: While percent correct is a simple measure to calculate and comprehend, it's
    vulnerable to situations where a classifier systematically under- or over-represents
    a given class. As an extreme example, consider a classifier that always classifies
    passengers as having perished. On our Titanic dataset such a classifier would
    appear to be 68 percent correct, but it would perform terribly on an alternative
    dataset where most of the passengers survived.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然正确率是一个简单的计算和理解的度量，但它容易受到分类器系统性地低估或高估某个类别的影响。作为极端例子，考虑一个始终将乘客归类为已死亡的分类器。在我们的
    Titanic 数据集中，这样的分类器会显示出68%的正确率，但在一个大部分乘客都生还的替代数据集中，它的表现将会非常糟糕。
- en: 'A `confusion-matrix` function shows how many misclassified items there are
    in the training set, split into true positives, true negatives, false positives,
    and false negatives. The confusion matrix has a row for each category of the input
    and a column for each category of the model. We can create one like this in Clojure:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `confusion-matrix` 函数展示了训练集中的误分类项，按照真正例、真反例、假正例和假反例进行划分。混淆矩阵的每一行代表输入类别，每一列代表模型类别。我们可以在
    Clojure 中这样创建它：
- en: '[PRE38]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We can then run our confusion matrix on the results of our logistic regression
    like so:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以像这样在我们的逻辑回归结果上运行混淆矩阵：
- en: '[PRE39]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'which returns the following matrix:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回以下矩阵：
- en: '[PRE40]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We can see how the model returned `682` true negatives and `339` true positives,
    adding up to the 1,021 correctly predicted results. The confusion matrix for a
    good model will be dominated by counts along the diagonal, with much smaller numbers
    in the off-diagonal positions. A perfect classifier would have zero in all off-diagonal
    cells.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到模型返回了 `682` 个真正例和 `339` 个真反例，总计 1,021 次正确预测。一个优秀模型的混淆矩阵将主要集中在对角线上，非对角线位置的数字会小得多。一个完美的分类器将在所有非对角线的单元格中显示零。
- en: The kappa statistic
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kappa 统计量
- en: The kappa statistic can be used for comparing two pairs of classes to see how
    well the classes agree. It is more robust that simply looking at percentage agreement
    because the equation aims to account for the possibility that some of the agreement
    has occurred simply due to chance alone.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: kappa 统计量可以用来比较两组类别之间的匹配度，以查看它们的相符程度。它比仅仅查看百分比一致性更为稳健，因为该公式旨在考虑某些一致性可能仅仅是由于偶然发生的可能性。
- en: The kappa statistic models how often each class occurs in each sequence and
    factors this into the calculation. For example, if I correctly guess the result
    of a coin toss 50 percent of the time, but I always guess heads, the kappa statistic
    will be zero. This is because the agreement is no more than could be expected
    by chance.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: kappa 统计量模型计算每个类别在每个序列中出现的频率，并将其纳入计算中。例如，如果我在每次抛硬币时猜中正反面各50%的概率，但我总是猜正面，那么 kappa
    统计量的值将为零。这是因为一致性并没有超出偶然可能发生的范围。
- en: 'To calculate the kappa statistic we need to know two things:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算 kappa 统计量，我们需要知道两件事：
- en: '*p(a)*: This is the probability of actual observed agreement'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p(a)*：这是实际观察到的一致性概率。'
- en: '*p(e)*: This is the probability of expected agreement'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p(e)*：这是预期一致性的概率。'
- en: The value of *p(a)* is the percentage agreement we calculated previously to
    be 78 percent. It's the sum of true positives and true negatives divided by the
    size of the sample.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '*p(a)* 的值是我们之前计算出的78%的百分比一致性。它是正确的正例和正确的负例的总和除以样本的大小。'
- en: To calculate the value of *p(e)* we need to know both the proportion of negative
    classes present in the data, and the proportion of negative classes predicted
    by our model. The proportion of negative classes in our data is ![The kappa statistic](img/7180OS_04_20.jpg),
    or 62 percent. This is the probability of perishing in the Titanic disaster overall.
    The proportion of negative classes in our model can be calculated from the confusion
    matrix as ![The kappa statistic](img/7180OS_04_21.jpg), or 64 percent.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算 *p(e)* 的值，我们需要知道数据中负类的比例，以及我们模型预测的负类比例。数据中负类的比例是 ![The kappa statistic](img/7180OS_04_20.jpg)，即
    62%。这是泰坦尼克号灾难中的整体死亡概率。模型中的负类比例可以通过混淆矩阵计算得出，为 ![The kappa statistic](img/7180OS_04_21.jpg)，即
    64%。
- en: The probability that the data and model might agree by chance, *p(e)*, is the
    probability that the model and the data both have a negative class ![The kappa
    statistic](img/7180OS_04_22.jpg) plus the probability that both the data and the
    model have a positive class ![The kappa statistic](img/7180OS_04_23.jpg). Therefore
    the probability of random agreement *p(e)* is about 53 percent.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 数据和模型可能偶然一致的概率，*p(e)*，是指模型和数据同时为负类的概率 ![The kappa statistic](img/7180OS_04_22.jpg)
    加上数据和模型同时为正类的概率 ![The kappa statistic](img/7180OS_04_23.jpg)。因此，随机一致的概率 *p(e)*
    约为 53%。
- en: 'The preceding information is all we need to calculate the kappa statistic:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 上述信息就是我们计算 kappa 统计量所需的全部内容：
- en: '![The kappa statistic](img/7180OS_04_24.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![The kappa statistic](img/7180OS_04_24.jpg)'
- en: 'Substituting in the values we just calculated yields:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 代入我们刚刚计算的值，得到：
- en: '![The kappa statistic](img/7180OS_04_25.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![The kappa statistic](img/7180OS_04_25.jpg)'
- en: 'We can calculate this in Clojure as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 Clojure 中按如下方式计算：
- en: '[PRE41]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Values of kappa range between 0 and 1, with 1 corresponding to complete agreement
    across both output classes. Complete agreement for only one output class is undefined
    with kappa—if I guess the result of a coin toss correctly 100 percent of the time,
    but the coin always comes up heads, there is no way of knowing that the coin was
    a fair coin.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Kappa 值的范围在 0 到 1 之间，1 表示两个输出类别完全一致。仅对一个输出类别完全一致时，kappa 值是未定义的——比如如果我每次都猜对抛硬币的结果
    100%，但硬币每次都显示正面，那么我们无法知道硬币是否公正。
- en: Probability
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率
- en: 'We have encountered probability in several guises so far in this book: as *p*-values,
    confidence intervals, and most recently as the output of logistic regression where
    the result can be considered as the probability of the output class being positive.
    The probabilities we calculated for the kappa statistic were the result of adding
    up counts and dividing by totals. The probability of agreement, for example, was
    calculated as the number of times the model and the data agreed divided by the
    number of samples. This way of calculating probabilities is referred to as **frequentist**,
    because it is concerned with the rates at which things happen.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在本书中以不同的方式遇到了概率：作为 *p* 值、置信区间，以及最近作为逻辑回归的输出，其中结果可以视为输出类别为正类的概率。我们为 kappa
    统计量计算的概率是通过将计数加总并除以总数得到的。例如，一致的概率是通过将模型和数据一致的次数除以样本数来计算的。这种计算概率的方法被称为 **频率主义**，因为它关注的是事件发生的频率。
- en: 'An output of `1.0` from logistic regression (pre-rounding) corresponds to the
    certainty that the input is in the positive class; an output of `0.0` corresponds
    to the certainty that the input isn''t in the positive class. An output of `0.5`
    corresponds to complete uncertainty about the output class. For example, if *ŷ
    = 0.7* the probability of *y = 1* is 70 percent. We can write this in the following
    way:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归输出为 `1.0`（未四舍五入）表示输入属于正类的确定性；输出为 `0.0` 表示输入不属于正类的确定性；输出为 `0.5` 表示对输出类别完全不确定。例如，如果
    *ŷ = 0.7*，则 *y = 1* 的概率为 70%。我们可以用以下方式表示：
- en: '![Probability](img/7180OS_04_26.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![Probability](img/7180OS_04_26.jpg)'
- en: We say *y-hat equals the probability that y equals one given x, parameterized
    by beta*. This new notation expresses the fact that our prediction, *ŷ*, is informed
    by inputs including *x* and *β*. The values contained in these vectors affect
    our calculation of the output probability, and correspondingly our prediction
    for *y*.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们说 *y-hat 等于在给定 x 和由 β 参数化的情况下，y 等于 1 的概率*。这个新符号表示我们的预测 *ŷ* 是由输入 *x* 和 *β*
    等信息决定的。这些向量中的值会影响我们对输出概率的计算，从而影响我们对 *y* 的预测。
- en: An alternative to the frequentist view of probability is **Bayesian view**.
    The Bayesian conception of probability incorporates a prior belief into the probability
    calculation. To illustrate the difference, let's look again at the example of
    tossing a coin.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 频率学派的概率观念的替代方法是**贝叶斯观点**。贝叶斯的概率观念将先验信念纳入概率计算。为了说明两者的不同，我们再次来看抛硬币的例子。
- en: Let's imagine that a coin is tossed 14 times in a row and comes up as heads
    10 times. You're asked to bet whether it will land heads on the next two throws.
    Would you take the bet?
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 假设抛硬币14次，其中正面朝上出现10次。现在要求你赌下两次抛掷是否会出现正面，你会下注吗？
- en: To a frequentist, the probability of the coin landing heads for two consecutive
    further throws is ![Probability](img/7180OS_04_27.jpg). This is marginally better
    than 50 percent, so it makes sense to take the bet.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 对频率学派来说，硬币连续两次正面朝上的概率是![Probability](img/7180OS_04_27.jpg)。这略高于50%，因此下注是有道理的。
- en: A Bayesian would frame the problem differently. With a prior belief that the
    coin is fair, how well does the data fit this belief? The standard error of the
    proportion over 14 throws is 0.12\. The difference between ![Probability](img/7180OS_04_28.jpg)
    and ![Probability](img/7180OS_04_29.jpg) divided by the standard error is approximately
    1.77, corresponding to a *p*-value of about 0.08\. There's simply not enough evidence
    to reject the theory that the coin is fair. If the coin were fair, then the probability
    of getting two consecutive heads is ![Probability](img/7180OS_04_30.jpg) and we
    would likely lose the bet.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯学派会以不同的方式来框定问题。假设我们有一个认为硬币是公平的先验信念，那么数据与这一信念的契合程度如何？14次抛掷的标准误差是0.12。![Probability](img/7180OS_04_28.jpg)与![Probability](img/7180OS_04_29.jpg)之差除以标准误差约为1.77，对应的*p*值大约是0.08。证据不足以拒绝硬币公平的理论。如果硬币是公平的，那么连续两次出现正面的概率是![Probability](img/7180OS_04_30.jpg)，我们很可能会输掉这场赌局。
- en: Note
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: In the 18^(th) Century, Pierre-Simon Laplace posited "What is the probability
    the sun will rise tomorrow?" to illustrate the difficulty of using probability
    theory to evaluate the plausibility of statements.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在18世纪，皮埃尔-西蒙·拉普拉斯提出了“太阳明天会升起的概率是多少？”这个问题，旨在说明用概率论来评估陈述的可信度的困难。
- en: The Bayesian view of probability gives rise to a very useful theorem called
    **Bayes theorem**.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯的概率观念引出了一个非常有用的定理——**贝叶斯定理**。
- en: Bayes theorem
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 贝叶斯定理
- en: 'The logistic regression equation we presented in the previous section is an
    example of conditional probability:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节中介绍的逻辑回归方程就是条件概率的一个例子：
- en: '![Bayes theorem](img/7180OS_04_26.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/7180OS_04_26.jpg)'
- en: The probability of our prediction *ŷ* is determined by the values *x* and *β*.
    A conditional probability is the likelihood of one thing given another thing we
    already know about. For example, we have already considered questions such as
    the "probability of survival given that the passenger was female".
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的预测*ŷ*的概率由* x *和* β *的值决定。条件概率是已知某个事实时，另一件事发生的可能性。例如，我们已经考虑过“假设乘客为女性时，生还的概率”这类问题。
- en: 'Assuming we are interested in *x*, *y*, and *z*, the basic notation for probability
    is as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们对*x*、*y*和*z*感兴趣，概率的基本符号表示如下：
- en: '![Bayes theorem](img/7180OS_04_31.jpg): This is the probability of *A* occurring'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![贝叶斯定理](img/7180OS_04_31.jpg)：这是*A*发生的概率'
- en: '![Bayes theorem](img/7180OS_04_32.jpg): This is the joint probability of both
    *A* and *B* occurring'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![贝叶斯定理](img/7180OS_04_32.jpg)：这是*A*和*B*同时发生的联合概率'
- en: '![Bayes theorem](img/7180OS_04_33.jpg): This is the probability of *A* or *B*
    occurring'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![贝叶斯定理](img/7180OS_04_33.jpg)：这是*A*或*B*发生的概率'
- en: '![Bayes theorem](img/7180OS_04_80.jpg): This is the probability of *A* occurring
    given *B* has occurred'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![贝叶斯定理](img/7180OS_04_80.jpg)：这是在*B*已发生的条件下，*A*发生的概率'
- en: '![Bayes theorem](img/7180OS_04_81.jpg): This is the probability of both *A*
    and *B* occurring given that *C* has occurred'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![贝叶斯定理](img/7180OS_04_81.jpg)：这是在*C*已发生的条件下，*A*和*B*同时发生的概率'
- en: 'The relationship between the preceding variables is expressed in the following
    formula:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 前述变量之间的关系可以通过以下公式表示：
- en: '![Bayes theorem](img/7180OS_04_34.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/7180OS_04_34.jpg)'
- en: 'Using this, we can solve for ![Bayes theorem](img/7180OS_04_80.jpg) assuming
    ![Bayes theorem](img/7180OS_04_35.jpg) to get what is called Bayes theorem:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个方法，我们可以通过![贝叶斯定理](img/7180OS_04_80.jpg)来求解，假设![贝叶斯定理](img/7180OS_04_35.jpg)，从而得到所谓的贝叶斯定理：
- en: '![Bayes theorem](img/7180OS_04_36.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/7180OS_04_36.jpg)'
- en: We read this as "the probability of *A* given *B* is equal to the probability
    of *B*, given *A*, times the probability of *A* all over the probability of *B*".
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样理解：“在给定 *B* 的情况下，*A* 的概率等于在给定 *A* 的情况下 *B* 的概率，乘以 *A* 的概率，再除以 *B* 的概率”。
- en: '![Bayes theorem](img/7180OS_04_31.jpg) is the prior probability: the initial
    degree of belief in *A*.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '![贝叶斯定理](img/7180OS_04_31.jpg) 是先验概率：对 *A* 的初始信念程度。'
- en: '![Bayes theorem](img/7180OS_04_80.jpg) is the conditional probability—the degree
    of belief in *A* having taken *B* into account.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '![贝叶斯定理](img/7180OS_04_80.jpg) 是条件概率——在考虑了 *B* 的情况下，对 *A* 的信念程度。'
- en: The quotient ![Bayes theorem](img/7180OS_04_37.jpg) represents the support that
    *B* provides for *A*.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 商数 ![贝叶斯定理](img/7180OS_04_37.jpg) 表示 *B* 对 *A* 提供的支持。
- en: 'Bayes theorem can appear intimidating and abstract, so let''s see an example
    of why it''s useful. Let''s say we''re testing for disease that has infected 1
    percent of the population. We have a highly sensitive and specific test that is
    not quite perfect:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理可能看起来令人生畏且抽象，因此我们来看看一个实际应用它的例子。假设我们正在检测一种已经感染了 1% 人口的疾病。我们有一种高灵敏度且高特异性的测试，虽然它不是完美的：
- en: 99 percent of sick patients test positive
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 99% 的生病病人检测结果为阳性
- en: 99 percent of healthy patients test negative
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 99% 的健康病人测试结果为阴性
- en: Given that a patient tests positive, what is the probability that the patient
    is actually sick?
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一位病人检测结果为阳性，那么这位病人实际上生病的概率是多少？
- en: The preceding bullet points appear to imply that a positive test means a 99
    percent chance of being sick, but this fails to take into account how rare the
    disease is in the population. Since the probability of being infected (the prior)
    is so small, this hugely decreases your chances of actually having the disease
    even if you test positive.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的要点似乎暗示着，阳性测试意味着有 99% 的机会患病，但这并没有考虑到这种疾病在整体人口中的稀有性。由于感染的概率（先验概率）非常小，即使你测试为阳性，你实际患病的概率也会大大降低。
- en: 'Let''s work through the numbers with 10,000 representative people. That would
    mean that 100 are sick, but 9,900 are healthy. If we applied the test to all 10,000
    people we would find 99 sick people testing sick (true positives), but 99 healthy
    people, testing sick (false positives) as well. If you test positive, the chances
    of actually having the disease are ![Bayes theorem](img/7180OS_04_38.jpg), or
    50 percent:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 10,000 名代表性的人群来计算这些数字。这样 100 人是生病的，9,900 人是健康的。如果我们对这 10,000 人进行测试，我们会发现
    99 名生病的人检测为阳性（真正阳性），但是也有 99 名健康的人检测为阳性（假阳性）。如果你测试为阳性，那么实际上患病的概率是 ![贝叶斯定理](img/7180OS_04_38.jpg)，即
    50%：
- en: '![Bayes theorem](img/7180OS_04_170.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/7180OS_04_170.jpg)'
- en: 'We can calculate the same example using Bayes rule. Let *y* to refer to "sick"
    and *x* refer to the event "+" for a positive result:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用贝叶斯定理来计算这个例子。让 *y* 表示“生病”，*x* 表示阳性结果事件“+”：
- en: '![Bayes theorem](img/7180OS_04_40.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/7180OS_04_40.jpg)'
- en: In other words, although a positive test has vastly increased your chances of
    having the disease (up from 1 percent in the population), you still only have
    even odds of actually being sick—nowhere near the 99 percent implied by the test
    accuracy alone.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，尽管阳性测试极大地增加了你得病的可能性（从人口中 1% 的概率增加到了 99%），但你实际上生病的机会依然只有 50%——远低于测试准确度所暗示的
    99%。
- en: The previous example provides neat numbers for us to work through, let's run
    the example on the Titanic data now.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的例子给出了清晰的数字，我们现在来运行泰坦尼克号数据的例子。
- en: 'The probability of surviving given you are female is equal to the probability
    of being female given you survived multiplied by the probability of surviving
    all divided by the probability of being a woman on the Titanic:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在已知你是女性的情况下生存的概率等于在你生存的前提下是女性的概率，乘以生存的概率，再除以泰坦尼克号上女性的概率：
- en: '![Bayes theorem](img/7180OS_04_41.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/7180OS_04_41.jpg)'
- en: 'Let''s remind ourselves of the contingency table from earlier:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下之前的列联表：
- en: '[PRE42]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '*P(survival|female)*is the posterior, the degree of belief in survival given
    the evidence. This is the value we are trying to calculate.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '*P(survival|female)* 是后验概率，即在已知证据的情况下对生存的信念程度。这正是我们要计算的值。'
- en: '*P(female|survival)* is the conditional probability of being female, given
    survival:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '*P(female|survival)* 是在已知生存的情况下为女性的条件概率：'
- en: '![Bayes theorem](img/7180OS_04_42.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/7180OS_04_42.jpg)'
- en: '*P(survival)* is the prior, the initial degree of belief in survival:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '*P(survival)* 是先验概率，即对生存的初始信念程度：'
- en: '![Bayes theorem](img/7180OS_04_43.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/7180OS_04_43.jpg)'
- en: '*P(female)* is the evidence:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '*P(female)* 是证据：'
- en: '![Bayes theorem](img/7180OS_04_44.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/7180OS_04_44.jpg)'
- en: 'Substituting these proportions into Bayes rule:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些比例代入贝叶斯法则：
- en: '![Bayes theorem](img/7180OS_04_45.jpg)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/7180OS_04_45.jpg)'
- en: Using Bayes rule we have calculated that the probability of survival, given
    being female, is ![Bayes theorem](img/7180OS_04_46.jpg) or 76 percent.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 使用贝叶斯法则，我们计算出，在已知为女性的情况下，生存概率为![贝叶斯定理](img/7180OS_04_46.jpg)，即76%。
- en: 'Notice that we could have calculated this value from the contingency table
    too, by looking up the proportion of survivors out of the total females: ![Bayes
    theorem](img/7180OS_04_47.jpg). The reason for the popularity of Bayes rule is
    that it gives us a way of calculating this probability where no such contingency
    table exists.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们也可以通过查找总女性中的幸存者比例来计算这个值：![贝叶斯定理](img/7180OS_04_47.jpg)。贝叶斯法则之所以受欢迎，是因为它提供了一种计算这种概率的方法，即使没有相应的列联表。
- en: Bayes theorem with multiple predictors
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有多个预测因子的贝叶斯定理
- en: As an example of how we can use Bayes rule without a full contingency table,
    let's use the example of a third-class male. What's the probability of survival
    for third-class male passengers?
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个例子，说明如何在没有完整列联表的情况下使用贝叶斯法则，我们以第三等级男性为例。第三等级男性乘客的生存概率是多少？
- en: 'Let''s write out Bayes rule for this new question:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为这个新问题写出贝叶斯法则：
- en: '![Bayes theorem with multiple predictors](img/7180OS_04_48.jpg)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![带有多个预测因子的贝叶斯定理](img/7180OS_04_48.jpg)'
- en: 'Next, we have two contingency tables:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有两个列联表：
- en: '[PRE43]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '"Third-class male" is not a category in any of our contingency tables that
    we can simply look up. However, by using Bayes theorem we can calculate it like
    this:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '"第三等级男性"不是我们任何列联表中的一个类别，无法简单查找。然而，通过使用贝叶斯定理，我们可以这样计算它：'
- en: The posterior probability we're seeking is *P(survive|male,third)*.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在寻找的后验概率是*P(幸存|男性,第三等级)*。
- en: The prior probability of survival is the same as before:![Bayes theorem with
    multiple predictors](img/7180OS_04_49.jpg) or about 0.38.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 生存的先验概率与之前相同：![带有多个预测因子的贝叶斯定理](img/7180OS_04_49.jpg)，大约为0.38。
- en: 'The conditional probability is ![Bayes theorem with multiple predictors](img/7180OS_04_50.jpg).
    This is the same as ![Bayes theorem with multiple predictors](img/7180OS_04_51.jpg).
    In other words, we can multiply the two probabilities together:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率是![带有多个预测因子的贝叶斯定理](img/7180OS_04_50.jpg)。这与![带有多个预测因子的贝叶斯定理](img/7180OS_04_51.jpg)相同。换句话说，我们可以将这两个概率相乘：
- en: '![Bayes theorem with multiple predictors](img/7180OS_04_52.jpg)![Bayes theorem
    with multiple predictors](img/7180OS_04_53.jpg)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![带有多个预测因子的贝叶斯定理](img/7180OS_04_52.jpg)![带有多个预测因子的贝叶斯定理](img/7180OS_04_53.jpg)'
- en: 'The evidence is the probability of being both male and in third class ![Bayes
    theorem with multiple predictors](img/7180OS_04_54.jpg):'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 证据是既是男性又是第三等级的概率：![带有多个预测因子的贝叶斯定理](img/7180OS_04_54.jpg)：
- en: '![Bayes theorem with multiple predictors](img/7180OS_04_55.jpg)![Bayes theorem
    with multiple predictors](img/7180OS_04_56.jpg)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![带有多个预测因子的贝叶斯定理](img/7180OS_04_55.jpg)![带有多个预测因子的贝叶斯定理](img/7180OS_04_56.jpg)'
- en: 'Putting this all together:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 将这一切综合起来：
- en: '![Bayes theorem with multiple predictors](img/7180OS_04_57.jpg)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![带有多个预测因子的贝叶斯定理](img/7180OS_04_57.jpg)'
- en: In actual fact, there were 75 surviving third class males out of 493 in total,
    giving a true survival rate of 15 percent. Bayes Theorem has allowed us to calculate
    the true answer very closely, without the use of a complete contingency table.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在总共493名第三等级男性中，有75名幸存，真实的生存率为15%。贝叶斯定理使我们能够在没有完整列联表的情况下，精确计算出真实答案。
- en: Naive Bayes classification
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类
- en: The reason that the answer we arrived at using Bayes theorem and the actual
    result differ slightly is that by using Bayes rule we made an assumption when
    calculating ![Naive Bayes classification](img/7180OS_04_54.jpg) that the probability
    of being male, and the probability of being in third class, are independent. In
    the next section, we'll use Bayes theorem to produce a naive Bayes classifier.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过贝叶斯定理得到的答案与实际结果略有不同，是因为在计算![朴素贝叶斯分类](img/7180OS_04_54.jpg)时，我们假设男性的概率和处于第三等级的概率是独立的。在下一部分，我们将使用贝叶斯定理生成一个朴素贝叶斯分类器。
- en: Note
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The reason this algorithm is called naive is because it assumes all variables
    are independent. We know this is often not the case, and there are interaction
    effects between variables. For example, we might know that combinations of parameters
    make a certain class very much more likely—for example, being both male and in
    third class.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法被称为朴素的原因是它假设所有变量都是独立的。我们知道，这通常并非如此，变量之间存在交互效应。例如，我们可能知道一些参数组合使得某个类别的可能性大大增加——例如，既是男性又在第三类。
- en: 'Let''s look at how we might use Bayes rule for a classifier. The Bayes theorem
    for two possible classes, survive and perish, are shown as follows for a male
    in third class:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用贝叶斯规则进行分类器的设计。对于第三类男性，生存与死亡这两个可能类别的贝叶斯定理如下所示：
- en: '![Naive Bayes classification](img/7180OS_04_58.jpg)![Naive Bayes classification](img/7180OS_04_59.jpg)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![朴素贝叶斯分类](img/7180OS_04_58.jpg)![朴素贝叶斯分类](img/7180OS_04_59.jpg)'
- en: The most likely class will be the one with the greatest posterior probability.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 最可能的类别是具有最大后验概率的类别。
- en: '![Naive Bayes classification](img/7180OS_04_54.jpg) appears as the common factor
    for both classes. If we were to relax the requirements of Bayes theorem a little
    so that it didn''t have to return probabilities, we could remove the common factor
    to arrive at the following:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '![朴素贝叶斯分类](img/7180OS_04_54.jpg) 在两个类别中作为共同因子出现。如果我们稍微放宽贝叶斯定理的要求，使其不一定返回概率，我们就可以去掉共同因子，得到以下结果：'
- en: '![Naive Bayes classification](img/7180OS_04_61.jpg)![Naive Bayes classification](img/7180OS_04_62.jpg)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![朴素贝叶斯分类](img/7180OS_04_61.jpg)![朴素贝叶斯分类](img/7180OS_04_62.jpg)'
- en: We have simply removed the denominator from the right hand side of both equations.
    Since we are no longer calculating probabilities, the equals sign has become ![Naive
    Bayes classification](img/7180OS_04_63.jpg), meaning "is proportional to".
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅仅从两个方程式的右侧去除了分母。由于我们不再计算概率，因此等号变成了 ![朴素贝叶斯分类](img/7180OS_04_63.jpg)，表示“与……成比例”。
- en: 'Putting the values from our previous table of data into the equations yields:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们之前数据表中的值代入方程中得到：
- en: '![Naive Bayes classification](img/7180OS_04_64.jpg)![Naive Bayes classification](img/7180OS_04_65.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![朴素贝叶斯分类](img/7180OS_04_64.jpg)![朴素贝叶斯分类](img/7180OS_04_65.jpg)'
- en: We can instantly see that we are not calculating probabilities because the two
    classes do not add up to one. This doesn't matter for our classifier since we
    were only going to select the class associated with the highest value anyway.
    Unfortunately for our third-class male, our naive Bayes model predicts that he
    will perish.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 我们立刻可以看到，我们并没有计算概率，因为这两个类别的和并不等于1。对于我们的分类器来说，这无关紧要，因为我们本来就只会选择与最大值对应的类别。不幸的是，对于我们的第三类男性，朴素贝叶斯模型预测他将死亡。
- en: 'Let''s do the equivalent calculation for a first class female:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为一等舱女性做等效的计算：
- en: '![Naive Bayes classification](img/7180OS_04_66.jpg)![Naive Bayes classification](img/7180OS_04_67.jpg)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![朴素贝叶斯分类](img/7180OS_04_66.jpg)![朴素贝叶斯分类](img/7180OS_04_67.jpg)'
- en: Fortunately for our first class female, the model predicts that she will survive.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，对于我们的一等舱女性，模型预测她将会生还。
- en: A Bayes classifier is a combination of the Bayes probability model combined
    with a decision rule (which class to choose). The decision rule described earlier
    is the maximum a posteriori rule, or MAP rule.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯分类器是贝叶斯概率模型与决策规则（选择哪个类别）的结合体。前面描述的决策规则是最大后验规则，或称MAP规则。
- en: Implementing a naive Bayes classifier
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现朴素贝叶斯分类器
- en: 'Fortunately, implementing a naive Bayes model in code is much easier than understanding
    the mathematics. The first step is simply to calculate the number of examples
    corresponding to each value of each feature for each class. The following code
    keeps a count of the number of times each parameter is seen for each class label:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，在代码中实现朴素贝叶斯模型要比理解其数学原理容易得多。第一步是简单地计算每个类别对应的每个特征值的示例数量。以下代码记录了每个类别标签下，每个参数出现的次数：
- en: '[PRE44]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The label is the attribute corresponding to the class (for example, in our Titanic
    data "survived" is the label corresponding to our classes true and false), and
    parameters are the sequence of attributes corresponding to the features (sex and
    class).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 标签是对应类别的属性（例如，在我们的泰坦尼克数据中，“survived”是与真和假类别对应的标签），而参数是与特征（性别和舱位）对应的属性序列。
- en: 'It can be used like so:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以像这样使用：
- en: '[PRE45]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'This example yields the following Bayes model:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子产生了以下的贝叶斯模型：
- en: '[PRE46]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The model is simply a two-level hierarchy implemented as nested maps. At the
    top level are our two classes—`"n"` and `"y"`, corresponding to "perished" and
    "survived", respectively. For each class we have a map of predictors—`:pclass`
    and `:sex`. Each key corresponds to a map of possible values and counts. As well
    as a map of predictors, each class has a count `:n`.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型只是一个两级层次结构，通过嵌套映射实现。在顶层是我们的两个类——`"n"`和`"y"`，分别对应“遇难”和“生还”。对于每个类，我们有一个预测变量的映射——`:pclass`和`:sex`。每个键对应一个可能值和计数的映射。除了预测变量的映射外，每个类还有一个计数`:n`。
- en: 'Now that we have calculated our Bayes model, we can implement our MAP decision
    rule. The following is a function that calculates the conditional probability
    of a provided class. For example, ![Implementing a naive Bayes classifier](img/7180OS_04_68.jpg):'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经计算出了贝叶斯模型，我们可以实现我们的MAP决策规则。以下是一个计算提供类的条件概率的函数。例如，![实现朴素贝叶斯分类器](img/7180OS_04_68.jpg)：
- en: '[PRE47]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Given a particular `class-attr`, the preceding code will calculate the posterior
    probability of the class, given the observations. Having implemented the earlier
    code, the classifier simply needs to return the class corresponding to the maximum
    posterior probability:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个特定的`class-attr`，上面的代码将根据观测结果计算该类的后验概率。实现了早期的代码后，分类器只需要返回具有最大后验概率的类：
- en: '[PRE48]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The preceding code calculates the probability of the test input against each
    of the model's classes. The returned class is simply the one with the highest
    posterior probability.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码计算了测试输入在每个模型类上的概率。返回的类是具有最高后验概率的那个类。
- en: Evaluating the naive Bayes classifier
  id: totrans-359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估朴素贝叶斯分类器
- en: 'Now that we have written two complementary functions, `bayes-classifier` and
    `bayes-classify`, we can use our model to make predictions. Let''s train our model
    on the Titanic dataset and check its predictions for the third-class male and
    first-class female that we''ve already calculated:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经编写了两个互补的函数，`bayes-classifier`和`bayes-classify`，我们可以使用我们的模型来进行预测。让我们在泰坦尼克号数据集上训练模型，并检查我们之前计算的第三等级男性和头等舱女性的预测结果：
- en: '[PRE49]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'It''s a good start—our classifier is in agreement with the outcomes we''ve
    calculated by hand. Let''s take a look at the percent correct for the naive Bayes
    classifier:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的开始——我们的分类器与我们手动计算的结果一致。让我们来看看朴素贝叶斯分类器的正确率：
- en: '[PRE50]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: By replicating our test over the entire dataset and comparing outputs, we can
    see how often our classifier got the correct answer. 78 percent is the same percent
    correct we got using our logistic regression classifier. For such a simple model,
    naive Bayes is performing remarkably well.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在整个数据集上重复我们的测试并比较输出，我们可以看到分类器正确回答的频率。78%的正确率与我们使用逻辑回归分类器得到的正确率相同。对于这么一个简单的模型，朴素贝叶斯表现得相当不错。
- en: 'We can calculate a confusion matrix:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计算一个混淆矩阵：
- en: '[PRE51]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The preceding code generates the following matrix:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下矩阵：
- en: '[PRE52]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This confusion matrix is identical to the one we obtained previously from logistic
    regression. Despite taking very different approaches, they have both been able
    to classify the dataset to the same degree of accuracy.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 这个混淆矩阵与我们之前从逻辑回归中获得的完全相同。尽管采用了非常不同的方法，但它们都能够以相同的准确度对数据集进行分类。
- en: Comparing the logistic regression and naive Bayes approaches
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比较逻辑回归和朴素贝叶斯方法
- en: Although they have performed equally well on our small Titanic dataset, the
    two methods of classification are generally suited to different tasks.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它们在我们的小型泰坦尼克号数据集上表现相同，但这两种分类方法通常适用于不同的任务。
- en: In spite of being conceptually a simpler classifier as compared to logistic
    regression, naive Bayes can often outperform it in cases where either data is
    scarce or the number of parameters is very large. Because of naive Bayes' ability
    to deal with a very large number of features, it is often employed for problems
    such as automatic medical diagnosis or in spam classification. In spam classification,
    features could run into the tens or hundreds of thousands, with each word representing
    a feature that can help identify whether the message is spam or not.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在概念上，朴素贝叶斯分类器比逻辑回归更简单，但在数据稀缺或参数数量非常大的情况下，朴素贝叶斯往往能超越逻辑回归。由于朴素贝叶斯能够处理非常大量的特征，它通常用于自动医疗诊断或垃圾邮件分类等问题。在垃圾邮件分类中，特征可能多达数万甚至数十万，每个单词都代表一个特征，有助于识别消息是否为垃圾邮件。
- en: However, a drawback of naive Bayes is its assumption of independence—in problem
    domains where this assumption is not valid, other classifiers can outperform naive
    Bayes. With a lot of data, logistic regression is able to learn more sophisticated
    models and classify potentially more accurately than naive Bayes is able to.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，朴素贝叶斯的一个缺点是它假设特征之间是独立的——在这种假设不成立的问题领域，其他分类器可能会超越朴素贝叶斯。对于大量数据，逻辑回归能够学习到更复杂的模型，并且可能比朴素贝叶斯更准确地进行分类。
- en: There is another method that—while simple and relatively straightforward to
    model—is able to learn more sophisticated relationships amongst parameters. This
    method is the decision tree.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种方法——虽然简单且相对直观易建模——却能学习到参数之间更复杂的关系。这种方法就是决策树。
- en: Decision trees
  id: totrans-375
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树
- en: The third method of classification we'll look at in this chapter is the decision
    tree. A decision tree models the process of classification as a series of tests
    that checks the value of a particular attribute or attributes of the item to be
    classified. It can be thought of as similar to a flowchart, with each test being
    a branch in the flow. The process continues, testing and branching, until a leaf
    node is reached. The leaf node will represent the most likely class for the item.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将探讨的第三种分类方法是决策树。决策树将分类过程建模为一系列测试，检查待分类物品某个或多个属性的值。它可以被视为类似于流程图，每个测试是流程中的一个分支。这个过程继续进行，不断测试和分支，直到到达叶节点。叶节点代表该物品最可能的分类。
- en: Decision trees share some similarities with both logistic regression and naive
    Bayes. Although the classifier can support categorical variables without dummy
    coding, it is also able to model complex dependencies between variables through
    repeated branching.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树与逻辑回归和朴素贝叶斯有一些相似之处。尽管分类器可以支持类别变量而无需虚拟编码，但它同样能够通过反复分支来建模变量之间的复杂依赖关系。
- en: In the old-fashioned parlor game *Twenty Questions*, one person, the "answerer",
    chooses an object but does not reveal their choice to the others. All other players
    are "questioners" and take turns to ask questions that aim to guess the object
    the answerer has thought of. Each question can only be answered with a simple
    "yes" or "no". The challenge for the questioners is to guess the object the answerer
    was thinking of in only 20 questions, and to pick questions that reveal the most
    amount of information about the object the answerer is thinking of. This is not
    an easy task—ask questions that are too broad and you do not gain much information
    through the answer. Ask questions that are too specific and you will not reach
    an answer in only 20 steps.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在老式的猜谜游戏《二十个问题》中，一个人，称为“回答者”，选择一个物品，但不向其他人透露他们选择的是什么。其他所有玩家是“提问者”，轮流提出问题，目的是猜出回答者心中想到的物品。每个问题只能用简单的“是”或“否”回答。提问者的挑战是在仅有20个问题的情况下，猜出回答者心中所想的物品，并提出能够提供最多信息的问题。这不是一件容易的事——问得太笼统，你从答案中获得的信息就会很少；问得太具体，你将无法在20个问题内找到答案。
- en: Unsurprisingly, these concerns also appear in decision tree classification.
    Information is something that is quantifiable, and decision trees aim to ask questions
    that are likely to yield the biggest information gain.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 毋庸置疑，这些问题在决策树分类中也会出现。信息是可以量化的，而决策树的目标是提出那些可能带来最大信息增益的问题。
- en: Information
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信息
- en: Imagine that I pick a random card from a normal deck of 52 playing cards. Your
    challenge is to guess what card I have picked. But first, I offer to answer one
    question with a "yes" or a "no". Which question would you rather ask?
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我从一副52张扑克牌中随机抽取一张卡牌。你的挑战是猜测我抽到了哪张卡牌。但首先，我将回答一个可以用“是”或“否”回答的问题。你想问什么问题？
- en: Is it red? (a Heart or a Diamond)
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是红色的吗？（红心或方块）
- en: Is it a picture card? (a Jack, Queen, or King)
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是面牌吗？（杰克、皇后或国王）
- en: We will explore this challenge in detail over the coming pages. Take a moment
    to consider your question.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的页面中详细探讨这个问题。请花点时间思考你的问题。
- en: There are 26 red cards in a deck, so the probability of a random red card being
    chosen is ![Information](img/7180OS_04_29.jpg). There are 12 picture cards in
    a deck so the probability of a picture card being randomly chosen is ![Information](img/7180OS_04_69.jpg).
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 一副扑克牌中有26张红色卡牌，因此随机抽到一张红色卡牌的概率是 ![Information](img/7180OS_04_29.jpg)。一副扑克牌中有12张面牌，因此随机抽到一张面牌的概率是
    ![Information](img/7180OS_04_69.jpg)。
- en: 'The information *I* associated with a single event is:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 我与单个事件相关联的信息是：
- en: '![Information](img/7180OS_04_70.jpg)'
  id: totrans-387
  prefs: []
  type: TYPE_IMG
  zh: '![信息](img/7180OS_04_70.jpg)'
- en: 'Incanter has a `log2` function that enables us to calculate information like
    this:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: Incanter有一个`log2`函数，使我们能够像这样计算信息：
- en: '[PRE53]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Here, `log2` is the log to base 2\. Therefore:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`log2`是以2为底的对数。因此：
- en: '![Information](img/7180OS_04_71.jpg)![Information](img/7180OS_04_72.jpg)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
  zh: '![信息](img/7180OS_04_71.jpg)![信息](img/7180OS_04_72.jpg)'
- en: Since a picture card has the lower probability, it also carries the highest
    information value. If we know the card is a picture card, there are only 12 cards
    it could possibly be. If we know the card is red, then 26 possibilities still
    remain.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图画牌的概率较低，它也承载了最高的信息值。如果我们知道卡片是图画牌，那么它可能是的卡片只有12张。如果我们知道卡片是红色的，那么仍然剩下26种可能性。
- en: Information is usually measured in bits. The information content of knowing
    the card is red carries only one bit of information. A computer bit can only represent
    a zero or a one. One bit is enough to contain a simple 50/50 split. Knowing that
    the card is a picture card offers two bits of information. This appears to suggest
    that the best question to ask therefore is "Is it a picture card?". An affirmative
    answer will carry with it a lot of information.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 信息通常以比特为单位进行度量。知道一张卡片是红色的，其信息量仅为一个比特。计算机中的比特只能表示零或一。一个比特足以包含一个简单的50/50分割。知道卡片是图画牌则提供了两个比特的信息。这似乎表明最好的问题是“它是图画牌吗？”一个肯定的答案将包含大量的信息。
- en: But look what happens if we find out the answer to the question is "no". What's
    the information content of finding out that the card I've chosen is not a picture
    card?
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果我们发现答案是“不是图画牌”会发生什么呢？找出我选择的卡片不是图画牌的信息量是多少？
- en: '![Information](img/7180OS_04_73.jpg)![Information](img/7180OS_04_74.jpg)'
  id: totrans-395
  prefs: []
  type: TYPE_IMG
  zh: '![信息](img/7180OS_04_73.jpg)![信息](img/7180OS_04_74.jpg)'
- en: It appears that now we could be better off asking whether the card is red, since
    the information content is greater. Finding out our card is not a picture card
    still leaves 36 possibilities remaining. We clearly don't know in advance whether
    the answer will be "yes" or "no", so how can we go about choosing the best question?
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们现在可以问卡片是否是红色的，因为信息量更大。发现我们的卡片不是图画牌，仍然会剩下36种可能性。我们显然无法预知答案会是“是”还是“不是”，那么我们该如何选择最好的问题呢？
- en: Entropy
  id: totrans-397
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 熵
- en: Entropy is a measure of uncertainty. By calculating the entropy we can strike
    a balance between information content over all possible responses.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 熵是衡量不确定性的一个指标。通过计算熵，我们可以在所有可能的响应中取得信息内容的平衡。
- en: Note
  id: totrans-399
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The concept of entropy was introduced by Rudolf Clausius in the mid-nineteenth
    century as part of the emerging science of thermodynamics to help explain how
    part of the functional energy of combustion engines was lost due to heat dissipation.
    In this chapter we talk about Shannon Entropy, which comes from Claude Shannon's
    work on information theory in the mid-twentieth century. The two concepts are
    closely related, despite hailing from different corners of science in very different
    contexts.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 熵的概念是由鲁道夫·克劳修斯在十九世纪中期提出的，作为热力学新兴科学的一部分，用来解释燃烧引擎的一部分功能能量如何由于热量散失而丧失。在本章中，我们讨论的是香农熵，它来自克劳德·香农在二十世纪中期关于信息论的工作。这两个概念虽然来自科学的不同领域和背景，但它们是密切相关的。
- en: 'Entropy, *H*, can be calculated in the following way:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 熵，*H*，可以通过以下方式计算：
- en: '![Entropy](img/7180OS_04_75.jpg)'
  id: totrans-402
  prefs: []
  type: TYPE_IMG
  zh: '![熵](img/7180OS_04_75.jpg)'
- en: Here, *P(x)*is the probability of *x* occurring and *I(P(x))*is the information
    content of *x*.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*P(x)*是*x*发生的概率，*I(P(x))*是*x*的信息量。
- en: 'For example, let''s compare the entropy of a pack of cards where each class
    is simply "red" and "not red". We know the information content of "red" is 1 and
    the probability is ![Entropy](img/7180OS_04_29.jpg). The same is true for "not
    red", so the entropy is the following sum:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们比较一副牌的熵，其中每一类简单地分为“红色”和“非红色”。我们知道“红色”的信息量为1，概率为![熵](img/7180OS_04_29.jpg)。对于“非红色”也是如此，因此熵是以下和：
- en: '![Entropy](img/7180OS_04_76.jpg)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![熵](img/7180OS_04_76.jpg)'
- en: 'Splitting the pack in this way yields an entropy of 1\. What about splitting
    the pack into "picture" and "not picture" cards? The information content of "picture"
    is 2.12 and the probability is ![Entropy](img/7180OS_04_69.jpg). The information
    content of "not picture" is 0.38 and the probability is ![Entropy](img/7180OS_04_77.jpg):'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式分割牌组的熵为1。那么，如果将牌组分为“图画牌”和“非图画牌”呢？“图画牌”的信息量是2.12，概率是![熵](img/7180OS_04_69.jpg)。“非图画牌”的信息量是0.38，概率是![熵](img/7180OS_04_77.jpg)：
- en: '![Entropy](img/7180OS_04_78.jpg)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![熵](img/7180OS_04_78.jpg)'
- en: 'If we imagine the deck of cards as a sequence of classes, positive and negative,
    we can calculate the entropy for our two decks using Clojure:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们把扑克牌的牌面看作一系列的类别（正类和负类），我们可以使用Clojure计算两个牌堆的熵值：
- en: '[PRE54]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Entropy is a measure of uncertainty. The lower entropy by splitting the deck
    into "picture" and "not picture" groups shows us that asking whether or not the
    card is a picture is the best question to ask. It remains the best question to
    have asked even if we discover that my card is not a picture card, because the
    amount of uncertainty remaining in the deck is lower. Entropy does not just apply
    to sequences of numbers, but to any sequence.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 熵是衡量不确定性的指标。通过将牌堆分成“人物卡”和“非人物卡”两组，熵值下降，说明询问卡片是否是人物卡是最好的问题。即使我们发现我的卡片不是人物卡，仍然是最好的问题，因为牌堆中的不确定性减少了。熵不仅仅适用于数字序列，也适用于任何序列。
- en: '[PRE55]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: is lower than
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 小于
- en: '[PRE56]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: This in spite of their equal length, because there is more consistency amongst
    the letters.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它们长度相等，但因为字母间有更多的一致性，熵较低。
- en: Information gain
  id: totrans-415
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**信息增益**'
- en: Entropy has indicated to us that the best question to ask—the one that will
    decrease the entropy of our deck of cards most—is whether or not the card is a
    picture card.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 熵告诉我们最好的问题——也就是能够最大程度减少牌堆熵值的问题——是询问卡片是否为人物卡。
- en: 'In general, we can use entropy to tell us whether a grouping is a good grouping
    or not using the theory of information gain. To illustrate this, let''s return
    to our Titanic survivors. Let''s assume that I''ve picked a passenger at random
    and you have to guess whether or not they survived. This time, before you answer,
    I offer to tell you one of two things:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，我们可以利用熵来判断某个分组是否合适，方法是使用**信息增益**的理论。为了说明这一点，回到泰坦尼克号生还者的例子。假设我随机选择了一名乘客，你需要猜测他是否生还。这次，在你回答之前，我会告诉你以下两件事之一：
- en: Their sex (male or female)
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们的性别（男性或女性）
- en: The class they were traveling in (first, second, or third)
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们所坐的舱位（头等舱、二等舱或三等舱）
- en: Which would you rather know?
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 你更愿意知道什么？
- en: It might appear at first that the best question to ask is which class they were
    travelling in. This will divide the passengers into three groups and, as we saw
    with the playing cards, smaller groups are better. Don't forget, though, that
    the objective is to guess the survival of the passenger. To determine the best
    question to ask we need to know which question gives us the highest information
    gain.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始可能看起来最好的问题是问乘客是坐在哪一等舱。这样可以将乘客分成三组，正如我们在扑克牌中看到的那样，更小的组别效果更好。但不要忘记，目标是猜测乘客的生存情况。为了确定最好的问题，我们需要知道哪个问题能给我们带来最大的**信息增益**。
- en: Information gain is measured as the difference between entropy before and after
    we learn the new information. Let's calculate the information gain when we learn
    that the passenger is male. First, let's calculate the baseline entropy of the
    survival rates for all passengers.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: '**信息增益**的计算方式是，学习到新信息前后的熵值之差。让我们计算一下当我们得知乘客是男性时的信息增益。首先，计算所有乘客的生存率基线熵。'
- en: 'We can use our existing entropy calculation and pass it the sequence of survival
    classes:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用现有的熵计算方法，并传递生存类别的序列：
- en: '[PRE57]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'This is a high entropy. We already know that an entropy of 1.0 indicates a
    50/50 split, yet we also know that survival on the Titanic was around 38 percent.
    The reason for this apparent discrepancy is that entropy does not change linearly,
    but rises quickly towards 1 as illustrated in the following graph:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个高熵值。我们已经知道，熵值为1.0表示50/50的分配，但我们也知道，泰坦尼克号的生还率大约是38%。这种明显的差异是因为熵并不是线性变化的，而是如以下图示那样快速接近1：
- en: '![Information gain](img/7180OS_04_180.jpg)'
  id: totrans-426
  prefs: []
  type: TYPE_IMG
  zh: '![信息增益](img/7180OS_04_180.jpg)'
- en: 'Next, let''s consider the entropy of survival when split by sex. Now we have
    two groups to calculate entropy for: males and females. The combined entropy is
    the weighted average of the two groups. We can calculate the weighted average
    for an arbitrary number of groups in Clojure by using the following function:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，考虑按性别划分的生存熵。现在我们有两个组来计算熵：男性和女性。总熵是这两个组的加权平均值。我们可以通过使用以下函数在Clojure中计算任意数量组的加权平均值：
- en: '[PRE58]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: We can see that the weighted entropy for the survival classes that have been
    grouped by sex is lower than the 0.96 we obtained from the passengers as a whole.
    Therefore our information gain is *0.96 - 0.75 = 0.21* bits.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，按性别分组的生存类别的加权熵低于我们从所有乘客中获得的0.96。因此，我们的信息增益为*0.96 - 0.75 = 0.21*比特。
- en: 'We can easily express the gain as a Clojure function based on the `entropy`
    and `weighted-entropy` functions that we''ve just defined:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松地将增益表示为一个基于我们刚刚定义的`entropy`和`weighted-entropy`函数的Clojure函数：
- en: '[PRE59]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Let''s use this to calculate the gain if we group the passengers by their class,
    instead:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用这个方法来计算如果我们按乘客类别分组时的增益：
- en: '[PRE60]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: The information gain for passenger class is 0.07, and for sex is 0.21\. Therefore,
    when classifying survival rates, knowing the passenger's sex is much more useful
    than the class they were traveling in.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 乘客类别的信息增益是0.07，性别的信息增益是0.21。因此，在分类生存率时，知道乘客的性别比他们的旅行舱位更有用。
- en: Using information gain to identify the best predictor
  id: totrans-435
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用信息增益来识别最佳预测器
- en: 'Using the functions we have just defined, we can construct an effective tree
    classifier. We''ll want a general purpose way to calculate the information gain
    for a specific predictor attribute, given an output class. In the preceding example,
    the predictor was `:pclass` and the class attribute was `:survived`, but we can
    make a generic function that will accept these keywords as the arguments `class-attr`
    and `predictor`:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们刚刚定义的函数，我们可以构建一个有效的树分类器。我们希望有一种通用的方法来计算给定输出类别的特定预测属性的信息增益。在前面的例子中，预测器是`:pclass`，类别属性是`:survived`，但是我们可以编写一个通用函数，接受这些关键词作为参数`class-attr`和`predictor`：
- en: '[PRE61]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Next, we''ll want a way to calculate the best predictor for a given set of
    rows. We can simply map the preceding function over all the desired predictors
    and return the predictor corresponding to the highest gain:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要一种方法来计算给定一组行的最佳预测器。我们可以简单地将前面的函数映射到所有期望的预测器，并返回增益最高的预测器：
- en: '[PRE62]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Let''s test this function by asking which of the predictors `:sex` and `:pclass`
    is the best predictor:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过询问`:sex`和`:pclass`哪个预测器是最好的预测器来测试这个函数：
- en: '[PRE63]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Reassuringly, we're getting the same answer as before. Decision trees allow
    us to apply this logic recursively to build a tree structure that chooses the
    best question to ask at each branch, based solely on the data in that branch.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 令人放心的是，我们得到了与之前相同的答案。决策树允许我们递归地应用这种逻辑，构建一个树结构，在每个分支上基于该分支中的数据选择最好的问题。
- en: Recursively building a decision tree
  id: totrans-443
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 递归地构建决策树
- en: By applying the functions we have written recursively to the data, we can build
    up a data structure that represents the best category split at each level of the
    tree. First, let's define a function that will return the **modal** (most common)
    class, given a sequence of data. When our decision tree reaches a point at which
    it can't split the data any more (either because the entropy is zero or because
    there are no remaining predictors left on which to split), we'll return the modal
    class.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 通过递归地将我们编写的函数应用于数据，我们可以构建一个数据结构，表示树中每一层的最佳类别划分。首先，让我们定义一个函数，给定一个数据序列时返回**众数**（最常见的）类别。当我们的决策树到达无法再划分数据的点时（因为熵为零或没有剩余的预测器可以划分数据），我们将返回众数类别。
- en: '[PRE64]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: With that simple function in place, we're ready to construct the decision tree.
    This is implemented as a recursive function. Given a class attribute, a sequence
    of predictors, and a sequence of values, we build a sequence of available classes
    by mapping the `class-attr` over our `xs`. If the entropy is zero, then all the
    classes are the same, so we simply return the first.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个简单的函数，我们准备构建决策树。这个过程实现为一个递归函数。给定一个类别属性、一组预测器和一组值，我们通过将`class-attr`映射到我们的`xs`上来构建可用类别的序列。如果熵为零，则所有类别相同，因此我们只返回第一个类别。
- en: If the classes are not identical in our group, then we need to pick a predictor
    to branch on. We use our `best-predictor` function to select the predictor associated
    with the highest information gain. We remove this from our list of predictors
    (there's no point in trying to use the same predictor twice), and construct a
    `tree-branch` function. This is a partial recursive call to `decision-tree` with
    the remaining predictors.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们组中的类别不相同，则需要选择一个预测器来进行分支。我们使用`best-predictor`函数选择与最高信息增益相关联的预测器。我们将其从预测器列表中移除（没有必要重复使用相同的预测器），并构造一个`tree-branch`函数。这是对剩余预测器的`decision-tree`部分递归调用。
- en: 'Finally, we group our data on the `best-predictor`, and call our partially
    applied `tree-branch` function on each group. This causes the whole process to
    repeat again, but this time only on the subset of data defined by `group-by`.
    The return value is wrapped in a vector, together with the predictor:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们将数据按`best-predictor`分组，并对每个组调用部分应用的`tree-branch`函数。这会导致整个过程再次重复，但这次只在`group-by`定义的数据子集上进行。返回值被封装在一个向量中，连同预测器一起：
- en: '[PRE65]'
  id: totrans-449
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Let's visualize the output of this function for the predictors `:sex` and `:pclass`.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们可视化该函数对`:sex`和`:pclass`预测器的输出。
- en: '[PRE66]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: We can see how the decision tree is represented as a vector. The first element
    of the vector is the predictor that's being used to branch the tree. The second
    element is a map containing the attributes of this predictor as keys `"male"`
    and `"female"` with values corresponding to a further branch on `:pclass`.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，决策树是如何以向量的形式表示的。向量的第一个元素是用于分支树的预测器。第二个元素是一个包含该预测器属性的映射，其键为`"male"`和`"female"`，对应的值进一步分支到`:pclass`。
- en: 'To see how we can build up arbitrarily deep trees using this function, let''s
    add a further predictor `:age`. Unfortunately, the tree classifier we''ve built
    is only able to deal with categorical data, so let''s split the age continuous
    variable into three simple categories: `unknown`, `child`, and `adult`.'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示如何使用此函数构建任意深度的树，让我们添加一个额外的预测器`:age`。不幸的是，我们构建的树分类器只能处理分类数据，因此我们将年龄这一连续变量分为三个简单类别：`unknown`、`child`和`adult`。
- en: '[PRE67]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'This code yields the following tree:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成了如下的树：
- en: '[PRE68]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Notice how the best overall predictor is still the sex of the passenger, as
    before. However, if the sex is male, age is the next most informative predictor.
    On the other hand, if the sex is female, passenger class is the most informative
    predictor. Because of the recursive nature of the tree, each branch is able to
    determine the best predictor only for the data in that particular branch of the
    tree.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，最优的总体预测器仍然是乘客的性别，和之前一样。然而，如果性别是男性，那么年龄是下一个最具信息量的预测器。另一方面，如果性别是女性，那么乘客等级是最具信息量的预测器。由于树的递归特性，每个分支只能为该树的特定分支中的数据确定最佳预测器。
- en: Using the decision tree for classification
  id: totrans-458
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用决策树进行分类
- en: With the data structure returned from the decision-tree function, we have all
    the information we require to classify passengers into their most likely class.
    Our classifier will also be implemented recursively. If a vector has been passed
    in as the model, we know it will contain two elements—the predictor and the branches.
    We destructure the predictor and branches from the model and then determine the
    branch our test is on. To do this, we simply get the value of the predictor from
    the test with `(get test predictor)`. The branch we want will be the one corresponding
    to this value.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 使用从决策树函数返回的数据结构，我们拥有分类乘客到最可能类别所需的所有信息。我们的分类器也将是递归实现的。如果传入的是向量模型，我们知道它将包含两个元素——预测器和分支。我们从模型中解构出预测器和分支，然后确定我们的测试位于哪个分支上。为此，我们只需使用`(get
    test predictor)`从测试中获取预测器的值。我们需要的分支将是与该值对应的分支。
- en: 'Once we have the branch, we need to call `tree-classify` again on the branch.
    Because we''re in the tail position (no further logic is applied after the `if`)
    we can call `recur`, allowing the Clojure compiler to optimize our recursive function
    call:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了分支，我们需要再次在该分支上调用`tree-classify`。因为我们处于尾部位置（在`if`之后没有进一步的逻辑应用），所以可以调用`recur`，允许Clojure编译器优化我们的递归函数调用：
- en: '[PRE69]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: We continue to call tree-classify recursively until `(vector? model)` returns
    false. At this point we will have traversed the full depth of the decision tree
    and reached a leaf node. At this point the `model` argument contains the predicted
    class, so we simply return it.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续递归调用`tree-classify`，直到`(vector? model)`返回false为止。此时，我们将已经遍历了决策树的全部深度并达到了叶节点。此时，`model`参数包含了预测的类别，因此我们直接返回它。
- en: '[PRE70]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The decision tree predicts that the young male from second class will survive.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树预测来自二等舱的年轻男性将会生还。
- en: Evaluating the decision tree classifier
  id: totrans-465
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估决策树分类器
- en: 'As before, we can calculate our confusion matrix and kappa statistic:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 和之前一样，我们可以计算我们的混淆矩阵和卡帕统计量：
- en: '[PRE71]'
  id: totrans-467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The confusion matrix looks like this:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵如下所示：
- en: '[PRE72]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'We can immediately see that the classifier is generating a lot of false negatives:
    `219`. Let''s calculate the kappa statistic:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以立即看到，分类器产生了大量的假阴性：`219`。让我们计算卡帕统计量：
- en: '[PRE73]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Our tree classifier isn''t performing nearly as well as others we have tried.
    One way we could try to improve the accuracy is to increase the number of predictors
    we''re using. Rather than use crude categories for age, let''s use the actual
    data for age as a feature. This will allow our classifier to better distinguish
    between our passengers. While we''re at it, let''s add the fare too:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的树形分类器的表现远不如我们尝试过的其他分类器。我们可以尝试提高准确度的一种方法是增加我们使用的预测变量的数量。与其使用粗略的年龄分类，不如直接使用年龄的实际数据作为特征。这将使我们的分类器能够更好地区分乘客。顺便提一下，我们还可以加入票价信息：
- en: '[PRE74]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Great! We've made fantastic progress; our new model is the best yet. By adding
    more granular predictors, we've built a model that's able to predict with a very
    high degree of accuracy.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！我们取得了令人惊叹的进展；我们的新模型是迄今为止最好的。通过增加更精细的预测变量，我们构建了一个能够以非常高的准确度进行预测的模型。
- en: Before we celebrate too much, though, we should think carefully about how general
    our model is. The purpose of building a classifier is usually to make predictions
    about new data. This means that it should perform well on data that it's never
    seen before. The model we've just built has a significant problem. To understand
    what it is, we'll turn to the library clj-ml, which contains a variety of functions
    for training and testing classifiers.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们过于庆祝之前，我们应该仔细考虑我们的模型的通用性。构建分类器的目的是通常是对新数据进行预测。这意味着它应该能够在之前未见过的数据上表现良好。我们刚刚构建的模型存在一个显著问题。为了理解它，我们将转向clj-ml库，库中包含了多种用于训练和测试分类器的函数。
- en: Classification with clj-ml
  id: totrans-476
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用clj-ml进行分类
- en: While building our own versions of logistic regression, naive Bayes, and decision
    trees has provided a valuable opportunity to talk about the theory behind them,
    Clojure gives us several libraries for building classifiers. One of the better
    supported is the clj-ml library.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然构建我们自己的逻辑回归、朴素贝叶斯和决策树模型为我们提供了一个讨论其背后理论的宝贵机会，但Clojure为我们提供了几个构建分类器的库。其中支持较好的一个是clj-ml库。
- en: The clj-ml library is currently maintained by Josua Eckroth and is documented
    on his GitHub page at [https://github.com/joshuaeckroth/clj-ml](https://github.com/joshuaeckroth/clj-ml).
    The library provides Clojure interfaces for running linear regression described
    in the previous chapter, as well as classification with logistic regression, naive
    Bayes, decision trees, and other algorithms.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: clj-ml库目前由Josua Eckroth维护，并在他的GitHub页面上有文档：[https://github.com/joshuaeckroth/clj-ml](https://github.com/joshuaeckroth/clj-ml)。该库为运行上一章中描述的线性回归以及使用逻辑回归、朴素贝叶斯、决策树和其他算法的分类提供了Clojure接口。
- en: Note
  id: totrans-479
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The underlying implementation for most machine learning functionality in clj-ml
    is provided by the Java machine learning library `Weka`. **Waikato Environment
    for Knowledge Analysis** (**Weka**), an open source machine learning project released
    and maintained primarily by the Machine Learning Group at the University of Waikato,
    New Zealand ([http://www.cs.waikato.ac.nz/ml/](http://www.cs.waikato.ac.nz/ml/)).
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: clj-ml中大多数机器学习功能的底层实现是由Java机器学习库`Weka`提供的。**Waikato知识分析环境**（**Weka**）是一个开源的机器学习项目，主要由新西兰怀卡托大学的机器学习小组发布和维护（[http://www.cs.waikato.ac.nz/ml/](http://www.cs.waikato.ac.nz/ml/)）。
- en: Loading data with clj-ml
  id: totrans-481
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用clj-ml加载数据
- en: 'Because of its specialized support for machine learning algorithms, clj-ml
    provides functions for creating datasets that identify the classes and attributes
    of a dataset. The function `clj-ml.data/make-dataset` allows us to create a dataset
    that can be passed to Weka''s classifiers. In the following code, we include `clj-ml.data`
    as `mld`:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它对机器学习算法的专业支持，clj-ml 提供了用于创建数据集的函数，这些函数可以识别数据集的类和属性。`clj-ml.data/make-dataset`
    函数允许我们创建一个数据集，并将其传递给 Weka 的分类器。在以下代码中，我们将 `clj-ml.data` 引入为 `mld`：
- en: '[PRE75]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '`mld/make-dataset` expects to receive the name of the dataset, a vector of
    attributes, a dataset as a sequence of row vectors, and an optional map of further
    settings. The attributes identify the column names and, in the case of categorical
    variables, also enumerate all the possible categories. Categorical variables,
    for example `:survived`, are passed as a map `{:survived ["y" "n"]}`, whereas
    continuous variables such as `:age` and `:fare` are passed as straightforward
    keywords. The dataset must be provided as a sequence of row vectors. To construct
    this, we''re simply using Incanter''s `i/$` function and calling `i/to-vect` on
    the results.'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '`mld/make-dataset` 期望接收数据集的名称、一个属性向量、作为行向量序列的数据集，以及一个可选的设置映射。属性用于标识列名，并且在分类变量的情况下，还会列举所有可能的类别。例如，像
    `:survived` 这样的分类变量将以一个映射 `{:survived ["y" "n"]}` 的形式传入，而像 `:age` 和 `:fare` 这样的连续变量将以直接的关键词传入。数据集必须作为行向量序列提供。为了构建这个，我们只是简单地使用
    Incanter 的 `i/$` 函数，并对结果调用 `i/to-vect`。'
- en: Note
  id: totrans-485
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: While `make-dataset` is a flexible way to create datasets from arbitrary data
    sources, `clj-ml.io` provides a `load-instances` function that loads data from
    a variety of sources such as CSV or Attribute-Relation File Format (ARFF) files
    and the MongoDB database.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `make-dataset` 是一种灵活的方式，用于从任意数据源创建数据集，但 `clj-ml.io` 提供了一个 `load-instances`
    函数，可以从各种来源加载数据，例如 CSV 文件、属性-关系文件格式（ARFF）文件和 MongoDB 数据库。
- en: With our dataset in a format that clj-ml understands, it's time to train a classifier.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据集转换为 clj-ml 能理解的格式后，是时候训练一个分类器了。
- en: Building a decision tree in clj-ml
  id: totrans-488
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 clj-ml 中构建决策树
- en: 'Clj-ml implements a large variety of classifiers, and all are accessible through
    the `cl/make-classifier` function. We pass two keyword arguments to the constructor:
    the classifier type and an algorithm to use. For example, let''s look at the `:decision-tree`,
    `:c45` algorithm. The **C4.5 algorithm** was devised by Ross Quinlan and builds
    a tree classifier based on information entropy in the same way as our very own
    `tree-classifier` function from earlier in the chapter. C4.5 extends the classifier
    we built in a couple of ways:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: Clj-ml 实现了多种分类器，所有这些分类器都可以通过 `cl/make-classifier` 函数访问。我们向构造函数传递两个关键词参数：分类器类型和要使用的算法。例如，看看
    `:decision-tree` 和 `:c45` 算法。**C4.5 算法**是由 Ross Quinlan 提出的，它基于信息熵构建树形分类器，方式与我们在本章早些时候实现的
    `tree-classifier` 函数相同。C4.5 在我们构建的分类器基础上做了几项扩展：
- en: Where none of the predictors provide any information gain, C4.5 creates a decision
    node higher up the tree using the expected value of the class
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当没有任何预测变量提供信息增益时，C4.5 会在树的上方创建一个决策节点，并使用该类别的期望值。
- en: If a previously-unseen class is encountered, C4.5 will create a decision node
    higher up the tree with the expected value of the class
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果遇到一个先前未见过的类别，C4.5 将在树的上方创建一个决策节点，并使用该类别的期望值。
- en: 'We can create a decision tree in clj-ml with the following code:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用以下代码在 clj-ml 中创建一个决策树：
- en: '[PRE76]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The preceding code returns the following information:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码返回以下信息：
- en: '[PRE77]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Notice how we don't need to explicitly provide the class and predictor attributes
    while training our classifier or using it for prediction. The Weka dataset already
    contains the information about the class attribute of each instance, and the classifier
    will use all the attributes it can to arrive at a prediction. In spite of this,
    the results still aren't as good as we were getting before. The reason is that
    Weka's implementation of decision trees is refusing to over-fit the data.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在训练我们的分类器或使用它进行预测时，我们无需显式提供类别和预测属性。Weka 数据集已经包含了每个实例的类别属性信息，分类器将使用它能够获取的所有属性来做出预测。尽管如此，结果仍然不如我们之前得到的那么好。原因在于，Weka
    的决策树实现拒绝对数据过度拟合。
- en: Bias and variance
  id: totrans-497
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差与方差
- en: Overfitting is a problem that occurs with machine learning algorithms that are
    able to generate very accurate results on a training dataset but fail to generalize
    very well from what they've learned. We say that models which have overfit the
    data have very high variance. When we trained our decision tree on data that included
    the numeric age of passengers, we were overfitting the data.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合是机器学习算法中常见的问题，虽然算法能够在训练数据集上产生非常准确的结果，但却无法很好地从所学知识中推广到新的数据。我们说，过拟合数据的模型具有非常高的方差。当我们在包含乘客年龄这一数值数据的情况下训练我们的决策树时，我们就出现了过拟合。
- en: Conversely, certain models may have very high bias. This is a situation where
    the model has a strong tendency towards a certain outcome irrespective of the
    training examples to the contrary. Recall our example of a classifier that always
    predicts that a survivor will perish. This classifier would perform well on dataset
    with low survivor rates, but very poorly otherwise.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，某些模型可能会有非常高的偏差。这是一种模型强烈倾向于某一特定结果的情况，无论训练示例如何与之相反。回想一下我们的例子——一个总是预测幸存者会死亡的分类器。这个分类器在幸存者比例较低的数据集上表现良好，但在其他数据集上表现则很差。
- en: In the case of high bias, the model is unlikely to perform well on diverse inputs
    at the training stage. In the case of high variance, the model is unlikely to
    perform well on data that differs from that which it was trained on.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 在高偏差的情况下，模型在训练阶段很可能无法在多样化的输入上表现良好；在高方差的情况下，模型在与训练数据不同的数据上也很可能表现不佳。
- en: Note
  id: totrans-501
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Like the balance to be struck between Type I and Type II errors in hypothesis
    testing, balancing bias and variance is critical for producing good results from
    machine learning.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在假设检验中需要平衡第一类错误和第二类错误一样，在机器学习中平衡偏差和方差对于获得良好的结果至关重要。
- en: If we have too many features, the learned hypothesis may fit the training set
    very well but fail to generalize to new examples very well.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有太多的特征，学习到的假设可能会非常好地拟合训练集，但却无法很好地推广到新的样本。
- en: Overfitting
  id: totrans-504
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过拟合
- en: The secret to identifying overfitting, then, is to test the classifier on examples
    that it has not been trained on. If the classifier performs poorly on these examples
    then there is a possibility that the model is overfitting.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，识别过拟合的关键在于对分类器进行未见过的样本测试。如果分类器在这些示例上表现不佳，则可能存在过拟合的情况。
- en: 'The usual approach is to divide the dataset into two groups: a training set
    and a test set. The training set is used to train the classifier, and the test
    set is used to determine whether the classifier is able to generalize well from
    what it has learned.'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的做法是将数据集分为两组：训练集和测试集。训练集用于训练分类器，而测试集用于判断分类器是否能够很好地从已学的知识中进行推广。
- en: 'The test set should be large enough that it will be a representative sample
    from the dataset, but should still leave the majority of records for training.
    Test sets are often around 10-30 percent of the overall dataset. Let''s use `clj-ml.data/do-split-dataset`
    to return two sets of instances. The smaller will be our test set and the larger
    will be our training set:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集应该足够大，以确保它能够代表数据集中的样本，但仍然应保留大部分记录用于训练。测试集通常占整个数据集的10%到30%。让我们使用`clj-ml.data/do-split-dataset`返回两个实例集。较小的将是我们的测试集，较大的将是我们的训练集：
- en: '[PRE78]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: If you compare this kappa statistic to the previous one, you'll see that actually
    our accuracy has improved on unseen data. Whilst this appears to suggest our classifier
    is not overfitting our training set, it doesn't seem very realistic that our classifier
    should be able to make better predictions for new data than the data we've actually
    told it about.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将这个Kappa统计量与之前的进行比较，你会看到其实我们的准确率在未见过的数据上有所提高。虽然这看起来表明我们的分类器没有过拟合训练集，但它似乎并不现实，因为我们的分类器竟然能对新数据做出比我们提供给它的训练数据更准确的预测。
- en: 'This suggests that we may have been fortunate with the values that were returned
    in our test set. Perhaps this just happened to contain some of the easier-to-classify
    passengers compared to the training set. Let''s see what happens if we take the
    test set from the final 30 percent instead:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明我们可能在测试集中运气很好。也许测试集恰好包含了一些相对容易分类的乘客，而这些乘客在训练集中并不常见。让我们看看如果我们从最后的30%数据中取测试集会发生什么：
- en: '[PRE79]'
  id: totrans-511
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: The classifier is struggling on test data from the final 30 percent of the dataset.
    To get a fair reflection of the actual performance of the classifier overall,
    therefore, we'll want to make sure we test it on several random subsets of the
    data to even out the classifier's performance.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器在数据集最后30%的测试数据上表现不佳。因此，为了公平地反映分类器的整体实际表现，我们需要确保在数据的多个随机子集上进行测试，以平衡分类器的表现。
- en: Cross-validation
  id: totrans-513
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证
- en: 'The process of splitting a dataset into complementary subsets of training and
    test data is called cross-validation. To reduce the variability in output we''ve
    just seen, with a lower error rate on the test set compared to the training set,
    it''s usual to run multiple rounds of cross-validation on different partitions
    of the data. By averaging the results of all runs we get a much more accurate
    picture of the model''s true accuracy. This is such a common practice that clj-ml
    includes a function for just this purpose:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集划分为互补的训练数据和测试数据的过程称为交叉验证。为了减少我们刚才看到的输出中的波动——即在测试集上比在训练集上的误差率更低——通常会在数据的不同划分上运行多轮交叉验证。通过对所有运行结果进行平均，我们能够更准确地了解模型的真实准确性。这是一个如此常见的做法，以至于clj-ml包含了一个专门用于此目的的函数：
- en: '[PRE80]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'In the preceding code, we make use of `cl/classifier-evaluate` to run 10 cross-validations
    on our dataset. The result is returned as a map with useful information about
    the model performance—for example, a confusion matrix and a list of summary statistics—including
    the kappa statistic we''ve been tracking so far. We print out the confusion matrix
    and the summary string that clj-ml provides, as follows:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用`cl/classifier-evaluate`对我们的数据集进行10次交叉验证。结果会以一个映射的形式返回，包含有关模型性能的有用信息——例如，混淆矩阵和一系列总结统计数据——包括我们一直在追踪的kappa统计值。我们打印出clj-ml提供的混淆矩阵和总结字符串，如下所示：
- en: '[PRE81]'
  id: totrans-517
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: The kappa after 10 cross-validations is 0.56, only slightly lower than our model
    validated against the training data. This seems about as high as we will be able
    to get.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 经过10次交叉验证后的kappa值为0.56，仅比我们在训练数据上验证的模型稍低。这似乎是我们能达到的最高水平。
- en: Addressing high bias
  id: totrans-519
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决高偏差
- en: Whereas overfitting can be caused by including too many features in our model—such
    as when we included age as a categorical variable in our decision tree—high bias
    can be caused by other factors including not having enough data.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合可能是由于在模型中包含了过多特征造成的——例如，当我们在决策树中将年龄作为分类变量时——而高偏差则可能由其他因素引起，包括数据量不足。
- en: One simple way of increasing the accuracy of the model is to ensure that there
    are no missing values in the training set. Missing values are necessarily discarded
    by the model, limiting the number of training examples from which the model can
    learn. With a relatively small dataset such as this, each example can have a material
    effect on the outcome, and there are numerous age values and one fare value missing
    from the dataset.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 提高模型准确性的一个简单方法是确保训练集中的缺失值被处理掉。模型会丢弃缺失的值，这限制了模型可以学习的训练样本数量。像这样的相对较小的数据集中的每一个样本都可能对结果产生实质性的影响，并且数据集中有多个年龄值和一个票价值缺失。
- en: We could simply substitute the mean value for a missing value in numeric columns.
    This is a reasonable default value and a fair tradeoff—in return for slightly
    lowering the variance of the field, we are potentially gaining several more training
    examples.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以简单地用数值列中的均值替代缺失值。这是一个合理的默认值，且是一种公平的折衷——通过略微降低字段的方差，我们有可能获得更多的训练样本。
- en: Clj-ml contains numerous filters in the `clj-ml.filters` namespace that are
    able to alter the dataset in some way. A useful filter is `:replace-missing-values`,
    which will substitute any missing numeric values with the means from the dataset.
    For categorical data, the modal category is substituted.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: clj-ml在`clj-ml.filters`命名空间中包含了众多能够以某种方式修改数据集的过滤器。一个有用的过滤器是`:replace-missing-values`，它会将任何缺失的数值替换为数据集中的均值。对于分类数据，则会替换为众数类别。
- en: '[PRE82]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Simply plugging the missing values in the age column has nudged our kappa statistic
    upwards. Our model is currently struggling to distinguish between passengers with
    different survival outcomes and more information may help the algorithm determine
    the correct class. Whilst we could return to the data and pull in all of the remaining
    fields, it's also possible to construct new features out of existing features.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅通过填补年龄列中的缺失值，就能使我们的kappa统计量有所提高。我们的模型目前在区分具有不同生存结果的乘客时遇到困难，更多的信息可能有助于算法确定正确的类别。虽然我们可以回到数据中并补充所有剩余字段，但也可以通过现有特征构造新特征。
- en: Note
  id: totrans-526
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For numeric values, another way of increasing the number of parameters is to
    include polynomial versions of the values as features. For example we could create
    features for age² and age³ simply by squaring or cubing the existing age value.
    While these may appear to add no new information to the model, polynomials scale
    differently and provide alternative features for the model to learn from.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数值型特征，增加参数的另一种方式是将这些数值的多项式版本作为特征。例如，我们可以通过对现有的年龄值进行平方或立方，来创建年龄²和年龄³的特征。尽管这些可能看起来不会为模型提供新信息，但多项式的缩放方式不同，能够为模型提供不同的特征供其学习。
- en: The final way we'll look at for balancing bias and variance is to combine the
    output from multiple models.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用来平衡偏差和方差的最终方法是将多个模型的输出结合起来。
- en: Ensemble learning and random forests
  id: totrans-529
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成学习与随机森林
- en: Ensemble learning combines the output from multiple models to obtain a better
    prediction than could be obtained with any of the models individually. The principle
    is that the combined accuracy of many weak learners is greater than any of the
    weak learners taken individually.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 集成学习将多个模型的输出结合起来，从而获得比任何单一模型更好的预测结果。其原理是，许多弱学习者的组合准确率大于任何单个弱学习者的准确率。
- en: Random forests is an ensemble learning algorithm devised and trademarked by
    Leo Breiman and Adele Cutler. It combines multiple decision trees into one large
    forest learner. Each tree is trained on the data using a subset of the available
    features, meaning that each tree will have a slightly different view of the data
    and is capable of generating a different prediction from that of its peers.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是由Leo Breiman和Adele Cutler设计并注册商标的集成学习算法。它将多个决策树组合成一个大型森林学习器。每棵树使用可用特征的子集来训练数据，这意味着每棵树对数据的理解略有不同，且能生成与同伴不同的预测。
- en: Creating a Random Forest in clj-ml simply requires that we alter the arguments
    to `cl/make-classifier` to `:decision-tree`, `:random-forest`.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 在clj-ml中创建一个随机森林只需要改变`cl/make-classifier`的参数，将其设置为`:decision-tree`和`:random-forest`。
- en: Bagging and boosting
  id: totrans-533
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 装袋与提升
- en: Bagging and boosting are two opposing techniques for creating ensemble models.
    Boosting is the name for a general technique of building an ensemble by training
    each new model to emphasize correct the classification of training examples that
    previous models weren't able to correctly classify. It is a **meta-algorithm**.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 装袋和提升是两种相对的集成模型创建技术。提升是通过训练每个新模型来强调正确分类那些之前模型未能正确分类的训练样本，从而构建集成的通用技术。它是一种**元算法**。
- en: Note
  id: totrans-535
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: One of the most popular boosting algorithms is **AdaBoost**, a portmanteau of
    "adaptive boosting". As long as each model performs slightly better than random
    guessing, the combined output can be shown to converge to a strong learner.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 最流行的提升算法之一是**AdaBoost**，它是“自适应提升”的缩写。只要每个模型的表现略好于随机猜测，组合后的输出就能证明收敛到一个强学习者。
- en: Bagging is a portmanteau of "bootstrap aggregating" and is the name of another
    meta-algorithm that is usually applied to decision tree learners but can be applied
    to other learners too. In cases where a single tree might overfit the training
    data, bagging helps reduce the variance of the combined model. It does this by
    sampling the training data with replacement, just as with our bootstrapped standard
    error at the beginning of the chapter. As a result, each model in the ensemble
    has a differently incomplete view of the world, making it less likely that the
    combined model will learn an overly specific hypothesis on the training data.
    Random forests is an example of a bagging algorithm.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging是“自助聚合”（bootstrap aggregating）的缩写，是一种常用于决策树学习器的元算法，但也可以应用于其他学习器。在单棵树可能会过拟合训练数据的情况下，bagging有助于减少组合模型的方差。它通过带替代地抽样训练数据来实现这一点，就像我们在本章开头使用的自助标准误一样。因此，集成中的每个模型对世界的理解都是不完全的，这使得组合模型更不容易在训练数据上学习到过于具体的假设。随机森林就是一种bagging算法的例子。
- en: '[PRE83]'
  id: totrans-538
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: With the random forests classifier, you should observe a kappa of around 0.55,
    slightly lower than the decision tree we have been optimizing. The random forest
    implementation has sacrificed some of the variance of the model.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 使用随机森林分类器时，你应该观察到一个大约为0.55的卡帕值，略低于我们一直在优化的决策树。随机森林的实现牺牲了一些模型的方差。
- en: Whilst this might seem disappointing, it is actually part of the reason for
    random forests' appeal. Their ability to strike a balance between bias and variance
    makes them flexible and general-purpose classifiers suitable for a wide variety
    of problems.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这可能看起来令人失望，但实际上这正是随机森林受欢迎的原因之一。它们在偏差和方差之间取得平衡的能力，使它们成为灵活且通用的分类器，适用于各种问题。
- en: Saving the classifier to a file
  id: totrans-541
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保存分类器到文件
- en: 'Finally, we can write out our classifier to a file using `clj-ml.utils/serialize-to-file`:'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用`clj-ml.utils/serialize-to-file`将分类器写入文件：
- en: '[PRE84]'
  id: totrans-543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: At some point later, we can load up our trained classifier using the `clj-ml.utils/deserialize-from-file`
    and immediately begin classifying new data.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 在稍后的某个时刻，我们可以使用`clj-ml.utils/deserialize-from-file`加载已训练的分类器，并立即开始对新数据进行分类。
- en: Summary
  id: totrans-545
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we've learned about how to make use of categorical variables
    to group data into classes.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何利用分类变量将数据分组为类别。
- en: 'We''ve seen how quantify the difference between groups using the odds ratio
    and relative risk, and how to perform statistical significance tests on groups
    using the *X*² test. We''ve learned about how to build machine learning models
    suitable for the task of classification with a variety of techniques: logistic
    regression, naive Bayes, decision trees, and random forests, and several methods
    of evaluating them; the confusion matrix and the kappa statistic. We also learned
    about the opposing dangers of high bias and of overfitting in machine learning,
    and how to ensure that your model is not overfitting by making use of cross-validation.
    Finally, we''ve seen how the clj-ml library can help to prepare data and to build
    many different types of classifiers and save them for future use.'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学习了如何使用赔率比和相对风险量化组间差异，并且如何使用*X*²检验对组进行统计显著性检验。我们了解了如何构建适合分类任务的机器学习模型，使用了多种技术：逻辑回归、朴素贝叶斯、决策树和随机森林，并学习了几种评估方法；混淆矩阵和卡帕统计量。我们还了解了机器学习中高偏差和过拟合的相对风险，以及如何通过交叉验证来确保你的模型没有过拟合。最后，我们看到了clj-ml库如何帮助准备数据、构建多种类型的分类器，并将它们保存以备将来使用。
- en: In the next chapter, we'll learn about how to adapt some of the techniques we've
    learned about so far to the task of processing very large datasets that exceed
    the storage and processing capabilities of any single computer—so-called **Big
    Data**. We'll see how one of the techniques we encountered in this chapter, gradient
    descent, turns out to be particularly amenable to parameter optimization on a
    very large scale.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习如何将目前为止学到的一些技术应用于处理超出任何单一计算机存储和处理能力的大型数据集——所谓的**大数据**。我们将看到，本章中我们遇到的技术之一——梯度下降——特别适用于大规模参数优化。
