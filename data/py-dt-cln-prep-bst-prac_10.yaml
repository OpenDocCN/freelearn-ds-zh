- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Handling Categorical Features
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理分类特征
- en: Handling categorical features involves representing and processing information
    that isn’t inherently numerical. **Categorical features** are attributes that
    can take on a limited, fixed number of values or categories, and they often define
    distinct categories or groups within a dataset, such as types of products, genres
    of books, or customer segments. Effectively managing categorical data is crucial
    because most **machine learning** (**ML**) algorithms require numerical inputs.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 处理分类特征涉及表示和处理那些本质上不是数值的信息。**分类特征**是可以取有限且固定数量值或类别的属性，它们通常定义数据集中的不同类别或组，例如产品类型、书籍类型或客户群体。有效地管理分类数据至关重要，因为大多数**机器学习**（**ML**）算法要求输入为数值。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Label encoding
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签编码
- en: One-hot encoding
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一热编码
- en: Target encoding (mean encoding)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标编码（均值编码）
- en: Frequency encoding
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频率编码
- en: Binary encoding
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二进制编码
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The complete code for this chapter can be found in the following GitHub repository:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的完整代码可以在以下GitHub仓库中找到：
- en: '[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter10](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter10)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter10](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter10)'
- en: 'Let''s install the necessary libraries we will use in this chapter:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们安装本章将使用的必要库：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Label encoding
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标签编码
- en: '**Label encoding** is a technique for handling categorical data by converting
    each category into a unique integer. It’s suitable for categorical features with
    ordinal relationships, where there is a clear ranking or order among the categories.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**标签编码**是一种处理分类数据的技术，通过将每个类别转换为唯一的整数。它适用于具有顺序关系的分类特征，即类别之间有明确的排名或顺序。'
- en: For example, when dealing with educational levels such as “high school,” “bachelor’s,”
    “master’s,” and “Ph.D.,” label encoding can be used because there’s a clear order
    from the least to most advanced level of education.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当处理“高中”、“学士”、“硕士”和“博士”等教育水平时，可以使用标签编码，因为这些教育水平有一个从最低到最高的明确顺序。
- en: Use case – employee performance analysis
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用例 —— 员工绩效分析
- en: A **Human Resources** (**HR**) department wants to analyze employee performance
    data to understand the relationship between employee ratings and other factors
    such as salary, years of experience, and department. They plan to use ML to predict
    employee ratings based on these factors.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**人力资源**（**HR**）部门希望分析员工绩效数据，以了解员工评分与薪资、工作年限和部门等其他因素之间的关系。他们计划使用机器学习根据这些因素预测员工评分。'
- en: The data
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: 'Let’s have a quick look at the data we have available for the performance analysis:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速浏览一下用于绩效分析的数据：
- en: '`Employee Rating`: Categorical feature with `Poor`, `Satisfactory`, `Good`,
    and `Excellent` values'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Employee Rating`：具有`Poor`、`Satisfactory`、`Good`和`Excellent`值的分类特征'
- en: '`Salary`: Numeric feature representing employee salaries'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Salary`：表示员工薪资的数值特征'
- en: '`Years of Experience`: Numeric feature indicating the number of years an employee
    has worked'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Years of Experience`：表示员工工作年限的数值特征'
- en: '`Department`: Categorical feature specifying the department in which the employee
    works'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Department`：表示员工所在部门的分类特征'
- en: 'Let’s have a look at the original DataFrame before the encoding:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看一下编码前的原始数据框：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Having understood the data, we can move to the objective of the use case.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解了数据之后，我们可以进入用例的目标。
- en: Objective of the use case
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用例目标
- en: 'The use case’s objective is to encode the `Employee Rating` feature using label
    encoding to prepare the data for ML analysis. Let’s see how we can do this using
    scikit-learn the complete code can be found at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/1a.label_encoding.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/1a.label_encoding.py):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 该用例的目标是使用标签编码对`Employee Rating`特征进行编码，以便准备数据进行机器学习分析。让我们看看如何使用scikit-learn来完成这项工作，完整代码可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/1a.label_encoding.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/1a.label_encoding.py)找到：
- en: 'Let’s import the required libraries:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入所需的库：
- en: '[PRE2]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s create a sample dataset and turn it into a DataFrame:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个示例数据集并将其转化为 DataFrame：
- en: '[PRE3]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Initialize a `LabelEncoder` class:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化 `LabelEncoder` 类：
- en: '[PRE4]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Apply label encoding to the `Employee` `Rating` column:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对 `员工评级` 列应用标签编码：
- en: '[PRE5]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Let’s have a look at the encoded output we created.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们创建的编码输出。
- en: Encoded output
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码后的输出
- en: In this use case, label encoding is applied to the `Employee Rating` feature
    to convert it into numeric values while preserving the ordinal relationship. The
    following table shows the output of the encoding operation.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个用例中，应用标签编码对`员工评级`特征进行转换，将其转换为数字值，同时保留序数关系。下表显示了编码操作的输出结果。
- en: '|  | `Employee Rating` | `Salary` | `Years` `of Experience` | `Department`
    | `Employee` `Rating (Encoded)` |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | `员工评级` | `薪资` | `工作经验年限` | `部门` | `员工评级（编码后）` |'
- en: '| `1` | `Poor` | `35000` | `2` | `HR` | `2` |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `1` | `差` | `35000` | `2` | `人力资源` | `2` |'
- en: '| `2` | `Good` | `50000` | `5` | `IT` | `1` |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `2` | `好` | `50000` | `5` | `信息技术` | `1` |'
- en: '| `3` | `Satisfactory` | `42000` | `3` | `FINANCE` | `3` |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `3` | `满意` | `42000` | `3` | `财务` | `3` |'
- en: '| `4` | `Excellent` | `60000` | `8` | `IT` | `0` |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `4` | `优秀` | `60000` | `8` | `信息技术` | `0` |'
- en: '| `5` | `Good` | `52000` | `6` | `MARKETING` | `1` |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `5` | `好` | `52000` | `6` | `市场营销` | `1` |'
- en: Table 10.1 – Output dataset after label encoding
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10.1 – 标签编码后的输出数据集
- en: 'As you can see, an `Employee Rating (Encoded)` feature has been added, and
    all the items are now numeric. Let’s have a look at the distribution graphs for
    the encoded column:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，已添加了一个`员工评级（编码后）`特征，所有项目现在都变成了数字。让我们看一下编码列的分布图：
- en: '![Figure 10.1 – Distribution before and after the encoding](img/B19801_10_1.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.1 – 编码前后的分布](img/B19801_10_1.jpg)'
- en: Figure 10.1 – Distribution before and after the encoding
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – 编码前后的分布
- en: As we can see, there are no changes in the distribution before and after encoding.
    Label encoding converts categorical labels into numerical values *while preserving
    the original data distribution*. It simply assigns unique integer values to each
    category *without altering their frequency*. However, visually, the labels on
    the *x* axis will change from categorical values to numerical values, but the
    counts (or frequencies) of each label will remain the same.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，编码前后的分布没有变化。标签编码将类别标签转换为数值，*同时保留原始数据分布*。它只是为每个类别分配了唯一的整数值，*并未改变其频率*。然而，在视觉上，*x*
    轴上的标签将从类别值变为数字值，但每个标签的计数（或频率）将保持不变。
- en: Note
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If the data is shuffled or the order of the categories changes between different
    runs of the encoder, the encoded values might differ. This is because the assignment
    of integers to categories can depend on the order in which they appear. Also,
    if you initialize a new instance of the label encoder each time, the mapping of
    categories to integers might vary as well. For consistent results, you should
    fit the encoder once and then use it for transforming data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据被打乱或在不同的编码器运行之间类别的顺序发生变化，编码后的值可能会不同。这是因为将整数分配给类别可能依赖于它们出现的顺序。此外，如果每次都初始化一个新的标签编码器实例，类别与整数之间的映射可能也会发生变化。为了确保结果一致，应该在第一次拟合编码器后使用它来进行数据转换。
- en: The encoded values can then be used as input features for an ML model to predict
    employee ratings based on salary, years of experience, and department. Let’s now
    discuss some things to keep in mind when encoding features with a label encoder.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 编码后的值可以作为机器学习模型的输入特征，用于根据薪资、工作经验和部门预测员工评级。现在，让我们讨论在使用标签编码器编码特征时需要注意的一些事项。
- en: Considerations for label encoding
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标签编码的注意事项
- en: 'When performing label encoding, especially on large datasets, there are several
    important considerations to keep in mind. Ensure that categorical features have
    a meaningful order. If there’s no natural order among the categories, label encoding
    might not be appropriate. Label encoding assigns *integer values to categories
    based on alphabetical order*. This introduces a potential issue if the categories
    do not have an inherent order, but the model might interpret the numerical values
    as ordered. For example, `Poor`, `Good`, and `Excellent` might be encoded as `2`,
    `1`, and `0`, respectively, but `Poor` is not inherently greater than `Good`.
    This is exactly what happened in the use case presented previously. What we could
    have done to ensure that the label encoding reflects the correct ordinal order
    (that is, `Poor` < `Satisfactory` < `Good` < `Excellent`) was to manually set
    the order by specifying the desired mapping, as shown next the complete code can
    be found at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/1b.label_encoding_forced.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/1b.label_encoding_forced.py):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行标签编码时，尤其是在处理大型数据集时，有几个重要的注意事项。确保类别特征具有有意义的顺序。如果类别之间没有自然的顺序，标签编码可能不适用。标签编码将*整数值分配给类别，基于字母顺序*。如果类别没有固有的顺序，可能会引发问题，模型可能会将数字值视为有序。例如，`Poor`、`Good`和`Excellent`可能会被编码为`2`、`1`和`0`，但`Poor`并不比`Good`大。正如前面提到的用例中所发生的那样。为了确保标签编码反映正确的顺序（即`Poor`
    < `Satisfactory` < `Good` < `Excellent`），我们可以通过手动设置顺序并指定所需的映射来解决这个问题，完整的代码可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/1b.label_encoding_forced.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/1b.label_encoding_forced.py)找到：
- en: 'Define the correct order of categories with prefixes:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义具有前缀的类别的正确顺序：
- en: '[PRE6]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Map the `Employee Rating` column to the prefixed categories:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Employee Rating`列映射到带前缀的类别：
- en: '[PRE7]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The resulting DataFrame is presented as follows:'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成的DataFrame如下所示：
- en: '[PRE8]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Always keep consistency in mind when encoding *across training and test datasets*.
    The encoder should be fitted *on the training data* and used to transform both
    training and test datasets. This prevents issues where unseen categories in the
    test set lead to errors or incorrect encoding. Follow the next steps as best practice:'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在编码时，始终保持一致性，尤其是*在训练集和测试集之间*。编码器应该*在训练数据上拟合*，并用于转换训练集和测试集。这可以防止在测试集中出现未见过的类别，从而导致错误或编码不正确。按照以下步骤作为最佳实践：
- en: 'Apply label encoding to the `Employee` `Rating` column:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对`Employee` `Rating`列应用标签编码：
- en: '[PRE9]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Save the encoder:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存编码器：
- en: '[PRE10]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Load the encoder (in another script or session):'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载编码器（在另一个脚本或会话中）：
- en: '[PRE11]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Transform the new data:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换新数据：
- en: '[PRE12]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The last point to mention, important when dealing with large datasets, is that
    label encoding is generally more memory-efficient than one-hot encoding, which
    can create many binary columns.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一项要提到的重点是，在处理大型数据集时，标签编码通常比独热编码更节省内存，后者可能会创建许多二进制列。
- en: While label encoding is a straightforward approach for converting categorical
    data into numerical form, it can inadvertently introduce ordinal relationships
    between categories that don’t inherently exist. To avoid this issue and ensure
    that each category is treated independently, one-hot encoding is often a more
    suitable method.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然标签编码是一种将类别数据转换为数值形式的简单方法，但它可能会无意中在类别之间引入不存在的顺序关系。为了避免这个问题，并确保每个类别被独立处理，独热编码通常是更合适的方法。
- en: One-hot encoding
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 独热编码
- en: '**One-hot encoding** is a technique used to convert categorical data into a
    binary matrix (1s and 0s). Each category is transformed into a new column, and
    a 1 is placed in the column corresponding to the category present for each observation,
    while all other columns get a 0\. This method is particularly useful when dealing
    with categorical data where there is **no ordinal relationship** **among categories**.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**独热编码**是一种将类别数据转换为二进制矩阵（1和0）的技术。每个类别都被转换为一个新列，并且在对应类别的列中放置1，而所有其他列则放置0。该方法在处理**没有类别间顺序关系**的类别数据时特别有用。'
- en: When to use one-hot encoding
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用独热编码
- en: 'One-hot encoding is suitable for categorical data that lacks a natural order
    or ranking among categories. Here are some scenarios where it is appropriate:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一热编码适用于缺乏自然顺序或类别排名的类别数据。以下是一些适用的场景：
- en: '**Nominal categorical data**: When dealing with nominal data, where categories
    are distinct and have no inherent order.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**名义类别数据**：处理名义数据时，类别是独立的，并且没有固有的顺序。'
- en: '**Algorithms that don’t handle ordinal data**: Some ML algorithms (for example,
    decision trees and random forests) are not designed to handle ordinal data correctly.
    One-hot encoding ensures that each category is treated as a separate entity.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不处理序列数据的算法**：一些机器学习算法（例如，决策树和随机森林）并非专门设计来正确处理序列数据。一热编码确保每个类别都被视为独立的实体。'
- en: '**Preventing misinterpretation**: To prevent a model from assuming any ordinal
    relationship that doesn’t exist, one-hot encoding is used to represent categorical
    data as binary values.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**防止误解**：为了防止模型假设不存在的序列关系，采用一热编码（one-hot encoding）将类别数据表示为二进制值。'
- en: Next, let’s look at a use case where we can use one-hot encoding.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看一下可以使用一热编码的用例。
- en: Use case – customer churn prediction
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用例 – 客户流失预测
- en: A telecommunications company is experiencing high customer churn and wants to
    build an ML model to predict which customers are likely to leave their service.
    They have collected data on customer demographics, contract details, and services
    used.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一家电信公司正在经历较高的客户流失率，想要构建一个机器学习模型，预测哪些客户可能会离开其服务。他们收集了有关客户人口统计、合同详情和使用的服务的数据。
- en: The data
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: 'Let’s have a quick look at the data we have available for the analysis:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速查看一下可用于分析的数据：
- en: '`Contract Type`: Categorical feature with `Month-to-Month`, `One Year`, and
    `Two` `Year` values'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`合同类型`：具有`月度`、`一年`和`两年`等值的类别特征'
- en: '`Internet Service`: Categorical feature with `DSL`, `Fiber Optic`, and `No
    Internet` `Service` values'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`互联网服务`：具有`DSL`、`光纤`和`无互联网`服务等值的类别特征'
- en: '`Payment Method`: Categorical feature with `Electronic Check`, `Mailed Check`,
    `Bank Transfer`, and `Credit` `Card` values'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`支付方式`：具有`电子支票`、`邮寄支票`、`银行转账`和`信用卡`等值的类别特征'
- en: 'Let’s have a look at the sample data for the use case:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下用于此用例的示例数据：
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Having understood the data, we can move to the objective of the use case.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了数据后，我们可以进入用例的目标部分。
- en: Objective of the use case
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用例目标
- en: 'The objective of the use case is to encode the categorical features using one-hot
    encoding to prepare the data for ML analysis. The code for this example can be
    found here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/2.one_hot_encoding.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/2.one_hot_encoding.py).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 用例的目标是使用一热编码对类别特征进行编码，为机器学习分析准备数据。此示例的代码可以在这里找到：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/2.one_hot_encoding.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/2.one_hot_encoding.py)。
- en: 'Follow the next steps:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 请按以下步骤操作：
- en: 'Initialize a `OneHotEncoder` class:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化`OneHotEncoder`类：
- en: '[PRE14]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Fit and transform the categorical columns:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合并转换类别列：
- en: '[PRE15]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a new DataFrame with the one-hot encoded columns:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含一热编码列的新DataFrame：
- en: '[PRE16]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Concatenate the one-hot encoded DataFrame with the original DataFrame:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将一热编码后的DataFrame与原始DataFrame进行连接：
- en: '[PRE17]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Drop the original categorical columns as they are now encoded:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除原始类别列，因为它们现在已经编码：
- en: '[PRE18]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Let’s have a look at the encoded output we created.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下我们创建的编码输出。
- en: Encoded output
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码输出
- en: In this use case, we are preparing customer data for a churn prediction model.
    Categorical features such as `Contract Type`, `Internet Service`, and `Payment
    Method` are one-hot encoded to convert them into binary representations suitable
    for ML. These encoded features can be used to train a predictive model that helps
    the telecommunications company identify customers at risk of churning and take
    proactive measures to retain them.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个用例中，我们正在为客户流失预测模型准备客户数据。类别特征如`合同类型`、`互联网服务`和`支付方式`被一热编码，转换为适合机器学习的二进制表示。这些编码后的特征可以用来训练预测模型，帮助电信公司识别有流失风险的客户，并采取主动措施留住他们。
- en: 'Let’s see with some plots how the distribution of the features changes when
    we are applying the encoding. Let’s have a look at the original distribution before
    the encoding first:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一些图表看看应用编码时特征分布的变化。首先来看一下编码前的原始分布：
- en: '![Figure 10.2 – Distribution before the one-hot encoding](img/B19801_10_2.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.2 – 独热编码前的分布](img/B19801_10_2.jpg)'
- en: Figure 10.2 – Distribution before the one-hot encoding
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 独热编码前的分布
- en: 'After encoding, each value of the categorical variables is turned into a unique
    column, showcasing binary values (0 or 1) reflecting the presence of that category
    in each row of the dataset. Let’s see the distribution graphs for the `Contract`
    `Type` column:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 编码后，每个类别变量的值会被转化为一个独特的列，展示二进制值（0或1），反映该类别在数据集每一行中的存在情况。让我们看看`Contract` `Type`列的分布图：
- en: '![Figure 10.3 – Distribution after the one-hot encoding for the Contract Type
    feature](img/B19801_10_3.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.3 – 独热编码后合同类型特征的分布](img/B19801_10_3.jpg)'
- en: Figure 10.3 – Distribution after the one-hot encoding for the Contract Type
    feature
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – 独热编码后合同类型特征的分布
- en: Note
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Visualizing the original categorical data helps understand the data distribution
    and identify any imbalances. Visualizing the encoded columns ensures that the
    transformation has been applied correctly. Each binary column should only have
    values of 0 or 1.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化原始类别数据有助于理解数据分布并识别任何不平衡情况。可视化编码后的列可以确保转换已正确应用。每个二进制列应仅包含0或1的值。
- en: Let’s now discuss some things to keep in mind when encoding features with a
    one-hot encoder.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们讨论一些在使用独热编码器编码特征时需要注意的事项。
- en: Considerations for one-hot encoding
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 独热编码的注意事项
- en: 'When performing one-hot encoding, especially on large datasets, there are several
    important considerations to keep in mind:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行独热编码时，特别是在大数据集上，有几个重要的注意事项需要牢记：
- en: One-hot encoding can significantly increase the dimensionality of your dataset,
    especially when you have many categories. This can lead to the “curse of dimensionality,”
    which can be problematic for some algorithms.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独热编码会显著增加数据集的维度，尤其是在类别较多的情况下。这可能导致“维度灾难”，对于某些算法来说可能是个问题。
- en: '**Collinearity**: Since each category is represented as a separate binary column,
    there can be collinearity between these columns. This means some columns might
    be highly correlated, which can affect the performance of linear models.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共线性**：由于每个类别都表示为一个单独的二进制列，这些列之间可能会存在共线性。这意味着某些列可能高度相关，这可能会影响线性模型的性能。'
- en: '**Handling missing values**: Decide how to handle missing values in categorical
    features before applying one-hot encoding. You may choose to create a separate
    column for missing values or use imputation techniques.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理缺失值**：在应用独热编码之前，决定如何处理类别特征中的缺失值。你可以选择为缺失值创建一个单独的列，或者使用插补技术。'
- en: Handling one-hot encoding on large datasets can be challenging due to the increase
    in the number of features and the potential for high memory usage. Process the
    data in smaller batches if the dataset is too large to fit into memory.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大数据集上进行独热编码可能会很具挑战性，因为特征数量的增加和潜在的高内存使用。若数据集过大无法放入内存，可将数据分批处理。
- en: Moving from one-hot encoding to target encoding can be particularly beneficial
    when dealing with high-cardinality categorical features. Let’s explore target
    encoding in more detail.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 从独热编码转向目标编码，特别是在处理高基数类别特征时，可以特别有益。让我们更详细地探讨目标编码。
- en: Target encoding (mean encoding)
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标编码（均值编码）
- en: '**Target encoding**, also known as **mean encoding**, is a technique used for
    encoding categorical features by replacing each category with the **mean** of
    the target variable (or another relevant aggregation function) for that category.
    This method is particularly useful for classification tasks when dealing with
    **high-cardinality categorical features**, where one-hot encoding would result
    in a significant increase in dimensionality.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标编码**，也称为**均值编码**，是一种通过将每个类别替换为该类别对应的目标变量的**均值**（或其他相关聚合函数）来编码类别特征的方法。此方法对于处理**高基数类别特征**的分类任务特别有用，而使用独热编码会导致维度的大幅增加。'
- en: In more detail, target encoding replaces categorical values with the mean (or
    other aggregation metric) of the target variable for each category. It leverages
    the relationship between the categorical feature and the target variable to encode
    the information.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，目标编码将类别值替换为每个类别的目标变量的均值（或其他聚合度量）。它利用类别特征和目标变量之间的关系来编码信息。
- en: When to use target encoding
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么时候使用目标编码
- en: When you have categorical features with many unique categories, using one-hot
    encoding might lead to a high-dimensional dataset. Target encoding can be an effective
    alternative in such cases.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的特征是类别型并且有很多独特的类别时，使用独热编码可能会导致数据集的维度过高。在这种情况下，目标编码可以是一个有效的替代方案。
- en: If there’s a strong relationship between the categorical feature and the target
    variable, target encoding can capture this relationship and potentially improve
    predictive power.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果类别特征与目标变量之间存在强关系，目标编码能够捕捉到这种关系，并可能提高预测能力。
- en: You can also use target encoding when you have memory constraints and need to
    reduce the dimensionality of your dataset, as target encoding doesn’t create additional
    columns.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有内存限制并且需要降低数据集的维度时，你也可以使用目标编码，因为目标编码不会创建额外的列。
- en: Use case – sales prediction for retail stores
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用例 – 零售商店的销售预测
- en: A retail chain with multiple stores wants to build an ML model to predict daily
    sales for each store. They have collected data on various features, including
    the `Store Type` feature, which has a high cardinality. Instead of using one-hot
    encoding, which would result in a large number of features, the retail chain decides
    to use target encoding to encode the `Store` `Type` feature.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一家拥有多个商店的零售连锁店希望建立一个机器学习模型，以预测每个商店的日销售额。他们收集了关于多个特征的数据，其中包括具有高基数的 `Store Type`
    特征。为了避免使用独热编码（这会导致特征数量过多），零售连锁决定使用目标编码来编码 `Store` `Type` 特征。
- en: The data
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: 'Let’s have a quick look at the data we have available for the analysis:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速查看一下可用于分析的数据：
- en: '`Store Type`: The type of store (categorical variable with `Type A`, `Type
    B`, `Type C`, and `Type` `D` values)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`商店类型`: 商店的类型（具有 `Type A`、`Type B`、`Type C` 和 `Type D` 值的类别变量）'
- en: '`Number of Employees`: The number of employees working at the store (integer
    variable)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`员工数量`: 商店的员工数量（整数变量）'
- en: '`Advertising Budget`: The budget allocated for advertising by the store (continuous
    variable in dollars)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`广告预算`: 商店为广告分配的预算（以美元为单位的连续变量）'
- en: '`Daily Sales`: The sales made by the store in a day (target variable in dollars)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`日销售额`: 商店一天内的销售额（以美元为单位的目标变量）'
- en: 'Let’s have a look at a sample of the data for the use case:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个用例的数据样本：
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Having understood the data, we can move to the objective of the use case.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 理解了数据之后，我们可以继续进行该用例的目标。
- en: Objective of the use case
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用例目标
- en: 'The use case’s objective is to encode the categorical features using target
    encoding to prepare the data for ML modeling. Let’s see how we can do this using
    scikit-learn. The code for this example can be found here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/3.target_encoding.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/3.target_encoding.py).'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 该用例的目标是使用目标编码来编码类别特征，以准备数据进行机器学习建模。让我们看看如何使用 scikit-learn 来完成这一操作。这个示例的代码可以在这里找到：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/3.target_encoding.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/3.target_encoding.py)。
- en: 'Make sure you have installed and imported the libraries mentioned in the *Technical
    requirements* section at the beginning of the chapter. Once that is done, let’s
    begin:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已经安装并导入了在章节开头的 *技术要求* 部分中提到的库。完成这些后，我们开始吧：
- en: 'Let’s create a synthetic dataset of sample size 1000:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个样本大小为1000的合成数据集：
- en: '[PRE20]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Generate some random data:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成一些随机数据：
- en: '[PRE21]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Put the data into a DataFrame:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据放入 DataFrame：
- en: '[PRE22]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Define a target variable and features:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义目标变量和特征：
- en: '[PRE23]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Split the data into training and testing sets:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集和测试集：
- en: '[PRE24]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Initialize a `TargetEncoder` class:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个 `TargetEncoder` 类：
- en: '[PRE25]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Fit and transform on the training data:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上进行拟合和转换：
- en: '[PRE26]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'In the code provided on GitHub for this section, we are using the data and
    the encoded feature to train a random forest regressor model and calculate validation
    metrics. If you are interested, explore the code file here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/3.target_encoding.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/3.target_encoding.py).'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在GitHub提供的本节代码中，我们使用数据和编码特征来训练随机森林回归模型并计算验证指标。如果你有兴趣，可以在这里查看代码文件：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/3.target_encoding.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/3.target_encoding.py)。
- en: This encoding technique helps capture the relationship between different store
    types and daily sales, so let’s have a look at the encoded output.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这种编码技术有助于捕捉不同商店类型与每日销售之间的关系，因此，让我们来看一下编码后的输出。
- en: Encoded output
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码后的输出
- en: 'Let’s have a look at the encoded data:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下编码后的数据：
- en: '[PRE27]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let’s focus on the `Store Type` column, which is now encoded into numerical
    values. We can see the difference in more detail before and after the encoding
    in the following graphs:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重点关注现在已被编码为数值的 `Store Type` 列。我们可以通过以下图表更详细地查看编码前后的差异：
- en: '![Figure 10.4 – Distribution of store type before and after the encoding](img/B19801_10_4.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.4 – 编码前后商店类型的分布](img/B19801_10_4.jpg)'
- en: Figure 10.4 – Distribution of store type before and after the encoding
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 – 编码前后商店类型的分布
- en: Target encoding can be advantageous in this scenario as it efficiently encodes
    the categorical feature, making it suitable for regression tasks such as sales
    prediction while avoiding the dimensionality issues associated with one-hot encoding.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，目标编码具有优势，因为它能有效地对类别特征进行编码，使其适用于回归任务（例如销售预测），同时避免了与独热编码相关的维度问题。
- en: Let’s now discuss some things to keep in mind when encoding features with a
    target encoder.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们讨论一些在使用目标编码器编码特征时需要注意的事项。
- en: Considerations for target encoding
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目标编码的注意事项
- en: 'When performing target encoding, especially on large datasets, there are several
    important considerations to keep in mind:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在对大数据集执行目标编码时，有几个重要事项需要注意：
- en: '**Overfitting**: Target encoding can lead to overfitting if not applied carefully
    or if some categories have only a few samples. To mitigate this, techniques such
    as smoothing or adding regularization terms are often used.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合**：如果目标编码没有谨慎应用，或者某些类别只有少量样本，可能会导致过拟合。为了缓解这种情况，通常会使用平滑或添加正则化项等技术。'
- en: '**Smoothing (regularization)**: Smoothing involves blending the mean of the
    target variable for each category with a global mean. This reduces the impact
    of extreme values or noise in the training data. The formula for smoothed target
    encoding is often the following:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平滑（正则化）**：平滑涉及将每个类别的目标变量的均值与全局均值进行混合。这可以减少训练数据中极端值或噪声的影响。平滑目标编码的公式通常如下所示：'
- en: smoothed_mean =(n*category_mean+m*global_mean)/(n+m)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 平滑均值 = (n * 类别均值 + m * 全局均值) / (n + m)
- en: 'Here, we have the following:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有以下内容：
- en: '*n* is the number of observations in the category.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*n* 是类别中的观察值数量。'
- en: '*m* is a hyperparameter that controls the strength of smoothing.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*m* 是一个超参数，用于控制平滑的强度。'
- en: Adjusting the value of *m* allows you to control the level of regularization.
    Smaller values of *m* give more weight to the category’s actual mean, while larger
    values give more weight to the global mean.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 调整 *m* 的值可以控制正则化的水平。较小的 *m* 值给予类别实际均值更多的权重，而较大的 *m* 值则给予全局均值更多的权重。
- en: '**Cross-validation**: Perform target encoding within each fold of a cross-validation
    scheme. This helps ensure that the encoding is based on a portion of the data
    independent of the one being predicted. Cross-validation can provide a more reliable
    estimate of the target variable’s distribution for each category.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交叉验证**：在交叉验证的每个折叠内执行目标编码。这有助于确保编码基于一个独立于被预测数据的部分数据。交叉验证可以为每个类别提供更可靠的目标变量分布估计。'
- en: '**Leave-one-out encoding**: In this approach, you compute the mean of the target
    variable for a category excluding the current observation. It can be more robust
    to overfitting because it considers the effect of the category without including
    the target value of the instance being encoded.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**留一法编码**：在这种方法中，你计算排除当前观察的类别的目标变量的均值。它可能更抗过拟合，因为它考虑了类别的效应，但不包括正在编码的实例的目标值。'
- en: '**Adding noise**: Introducing a small amount of random noise to the encoded
    values can help reduce overfitting. This is often referred to as **Bayesian**
    **target encoding**.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**添加噪声**：向编码值中引入少量随机噪声有助于减少过拟合。这通常被称为**贝叶斯目标编码**。'
- en: Be cautious of data leakage. It’s crucial to calculate the mean on the training
    dataset only and apply the same encoding to the validation and test datasets.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要注意数据泄露问题。在训练数据集上计算均值至关重要，并将相同编码应用于验证和测试数据集。
- en: '**Compute encoding statistics on training data only**: Calculate the encoding
    statistics (for example, mean) based solely on the training dataset. This ensures
    that the model is trained on unbiased information.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅在训练数据上计算编码统计信息**：仅基于训练数据集计算编码统计信息（例如均值）。这确保模型在无偏信息上训练。'
- en: '**Apply the same encoding to all datasets**: Once you’ve calculated the encoding
    statistics on the training data, use the same encoding when preprocessing the
    validation and test datasets. Do not recalculate the statistics separately for
    these datasets.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用相同的编码到所有数据集**：一旦在训练数据上计算了编码统计信息，预处理验证和测试数据集时应使用相同的编码。不要单独为这些数据集重新计算统计信息。'
- en: While target encoding can improve model performance, it may reduce the interpretability
    of your model, as the original categorical values are lost.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然目标编码可以提高模型性能，但可能会降低模型的可解释性，因为丢失了原始的分类值。
- en: After exploring target encoding, another effective technique for handling high-cardinality
    categorical features is frequency encoding. Frequency encoding replaces each category
    with its frequency or count in the dataset, which can help capture the inherent
    importance of each category and maintain the overall distribution of the data.
    Let’s deep dive into frequency encoding and its advantages in processing categorical
    variables.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索目标编码之后，处理高基数分类特征的另一种有效技术是频率编码。频率编码用数据集中每个类别的频率或计数替换每个类别，这有助于捕捉每个类别的固有重要性并维持数据的整体分布。让我们深入了解频率编码及其在处理分类变量中的优势。
- en: Frequency encoding
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 频率编码
- en: '**Frequency encoding**, also known as **count encoding**, is a technique used
    for encoding categorical features by replacing each category with its corresponding
    frequency or count in the dataset. In this encoding method, the more frequent
    a category is, the higher its encoded value. Frequency encoding can be a valuable
    tool in certain situations where the frequency of occurrence of a category carries
    valuable information.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**频率编码**，也称为**计数编码**，是一种通过在数据集中用每个类别的频率或计数替换每个类别的技术。在这种编码方法中，类别出现的频率越高，其编码值就越高。在某些情况下，频率编码可以是一种有价值的工具，因为类别出现的频率携带了有价值的信息。'
- en: When to use frequency encoding
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用频率编码
- en: 'Frequency encoding can be considered in the following scenarios:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 可以考虑在以下情况下使用频率编码：
- en: '**Informative frequency**: The frequency or count of categories is informative
    and has a direct or indirect relationship with the target variable. For example,
    in a customer churn prediction problem, the frequency of product purchases by
    a customer may correlate with their likelihood to churn.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息频率**：类别的频率或计数具有信息量，与目标变量直接或间接相关。例如，在客户流失预测问题中，客户购买产品的频率可能与其流失的可能性相关。'
- en: '**Efficiency**: You need an efficient encoding method that requires minimal
    computational resources and memory compared to one-hot encoding.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：您需要一种高效的编码方法，相比独热编码，它需要较少的计算资源和内存。'
- en: This encoding method often works well with tree-based models such as decision
    trees, random forests, and gradient boosting, as these models can effectively
    capture the relationship between the encoded frequency and the target variable.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这种编码方法通常与基于树的模型（如决策树、随机森林和梯度提升树）配合良好，因为这些模型能有效捕捉编码频率与目标变量之间的关系。
- en: Use case – customer product preference analysis
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用例 - 客户产品偏好分析
- en: A retail company wants to analyze customer product preferences based on their
    purchase history. They have a dataset with information about customer purchases,
    including the product category they buy the most.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一家零售公司希望基于顾客的购买历史分析顾客的产品偏好。他们拥有一个包含顾客购买信息的数据集，其中包括他们最常购买的产品类别。
- en: The data
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: In this example, we will use frequency encoding on the `Product Category` feature
    to determine the most frequently purchased product categories by customers. This
    encoding method allows the retail company to analyze customer preferences and
    understand how to optimize product recommendations or marketing strategies based
    on popular product categories.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将对`产品类别`特征使用频率编码，以确定顾客最常购买的产品类别。这种编码方法可以帮助零售公司分析顾客偏好，并了解如何根据热门产品类别优化产品推荐或营销策略。
- en: 'Let’s have a look at the sample dataset:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下样本数据集：
- en: '[PRE28]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Having understood the data, we can move to the objective of the use case.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解了数据之后，我们可以进入用例的目标部分。
- en: Objective of the use case
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用例的目标
- en: 'The use case’s objective is to encode the categorical features using frequency
    encoding to prepare the data for ML modeling. Let’s see how we can do that using
    scikit-learn:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 该用例的目标是使用频率编码对类别特征进行编码，以便为机器学习建模准备数据。让我们看看如何使用 scikit-learn 实现这一目标：
- en: 'Let’s create a sample dataset:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个样本数据集：
- en: '[PRE29]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Define features:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义特征：
- en: '[PRE30]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Split the data into training and testing sets:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集和测试集：
- en: '[PRE31]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Initialize a `CountEncoder` class for `Product Category`:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个`CountEncoder`类，用于`产品类别`：
- en: '[PRE32]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Fit and transform the training data:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合并转换训练数据：
- en: '[PRE33]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The company wants to encode this categorical feature using frequency encoding
    to understand which product categories are most frequently purchased. Let’s have
    a look at the encoded data.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 该公司希望使用频率编码对这个类别特征进行编码，以了解哪些产品类别是顾客最常购买的。让我们来看一下编码后的数据。
- en: Encoded output
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码后的输出
- en: 'Let’s have a look at the encoded data:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下编码后的数据：
- en: '[PRE34]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let’s focus on the `Product Category` feature, which is now encoded into numerical
    values based on frequency. We can see the difference in more detail before and
    after the encoding on the following graphs:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重点关注`产品类别`特征，它现在根据频率被编码成数值。我们可以通过以下图表更详细地查看编码前后的差异：
- en: '![Figure 10.5 – Distribution of Product Category before and after the encoding](img/B19801_10_5.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.5 – 编码前后产品类别的分布](img/B19801_10_5.jpg)'
- en: Figure 10.5 – Distribution of Product Category before and after the encoding
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 – 编码前后产品类别的分布
- en: The first subplot shows the distribution of `Product Category` in the training
    set before encoding. The second subplot shows the distribution of the encoded
    `Product Category` feature in the training set after encoding. As we can see,
    each category in the `Product Category` column is replaced by the **frequency
    count** of that category within the training set.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个子图展示了编码前训练集中`产品类别`的分布。第二个子图展示了编码后训练集中编码的`产品类别`特征的分布。正如我们所看到的，`产品类别`列中的每个类别都被该类别在训练集中的**频率计数**所替代。
- en: Note
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Frequency encoding preserves information about the prevalence of each category
    in the dataset.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 频率编码保留了数据集中每个类别的出现频率信息。
- en: Let’s now discuss some things to keep in mind when encoding features with a
    frequency encoder.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们讨论一些在使用频率编码器进行特征编码时需要注意的事项。
- en: Considerations for frequency encoding
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 频率编码的注意事项
- en: 'When performing frequency encoding, there are several important considerations
    to keep in mind:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行频率编码时，有几个重要的注意事项需要记住：
- en: Frequency encoding can lead to overfitting, especially if the dataset is small
    or if there are categories with very few observations. This is because the model
    might learn to rely too heavily on the frequency counts, which may not generalize
    well to new data.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频率编码可能会导致过拟合，尤其是在数据集较小或某些类别观察样本很少的情况下。这是因为模型可能会过度依赖频率计数，而这些计数在新数据上可能无法很好地泛化。
- en: When two or more categories have the same frequency, they will end up with the
    same encoded value. This can be a limitation if those categories have different
    effects on the target variable.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当两个或多个类别具有相同的频率时，它们将得到相同的编码值。如果这些类别对目标变量有不同的影响，这可能会成为一个限制。
- en: Frequency encoding is generally not suitable for linear models, as it does not
    create a linear relationship between the encoded values and the target variable.
    It may be necessary to normalize the encoded values to a similar scale, especially
    if you’re using linear models that are sensitive to feature scaling.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频率编码通常不适用于线性模型，因为它不会在编码值和目标变量之间创建线性关系。如果你使用的是对特征缩放敏感的线性模型，可能需要对编码值进行归一化处理，使它们具有相似的尺度。
- en: Overall, frequency encoding is straightforward to implement and does not expand
    the feature space, unlike one-hot encoding, making it efficient for handling high-cardinality
    features without creating many new columns.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，频率编码实现简单，不像独热编码那样扩展特征空间，因此在处理高基数特征时非常高效，不会创建过多的新列。
- en: While frequency encoding offers simplicity and efficiency for handling high-cardinality
    features, another effective technique is binary encoding. Binary encoding represents
    categories as binary numbers, providing a more compact representation than one-hot
    encoding and preserving ordinal relationships. Let’s explore how binary encoding
    can further enhance the processing of categorical variables.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然频率编码在处理高基数特征时提供了简便和高效的方法，但另一种有效的技术是二进制编码。二进制编码将类别表示为二进制数字，提供比独热编码更紧凑的表示方式，并且保留了有序关系。让我们探讨一下二进制编码如何进一步增强类别变量的处理。
- en: Binary encoding
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二进制编码
- en: '**Binary encoding** is a technique used for encoding categorical features by
    converting each category into binary code. Each unique category is represented
    by a unique binary pattern, where each digit (0 or 1) in the pattern corresponds
    to the presence or absence of that category. Binary encoding is particularly useful
    for handling high-cardinality categorical features while reducing dimensionality.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '**二进制编码**是一种通过将每个类别转换为二进制代码来编码类别特征的技术。每个独特的类别都由一个独特的二进制模式表示，其中模式中的每个数字（0或1）对应于该类别的存在或缺失。二进制编码在处理高基数类别特征的同时减少维度，非常有用。'
- en: When to use binary encoding
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用二进制编码
- en: 'Binary encoding can be considered in the following scenarios:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下情况下，可以考虑使用二进制编码：
- en: '**Dimensionality reduction**: You want to reduce the dimensionality of the
    dataset while still capturing information contained within the categorical feature.
    Binary encoding is particularly useful in this scenario.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降维**：你希望在减少数据集维度的同时，仍然能够保留类别特征中的信息。在这种情况下，二进制编码特别有用。'
- en: '**Efficiency**: You need an efficient encoding method that results in a compact
    representation of categorical data and can be easily processed by ML algorithms.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效性**：你需要一种高效的编码方法，能够以紧凑的方式表示类别数据，并且易于被机器学习算法处理。'
- en: Let’s look at a use case.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下一个使用场景。
- en: Use case – customer subscription prediction
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用场景 —— 客户订阅预测
- en: A subscription-based service provider wants to predict whether customers will
    subscribe to a premium plan based on various features, including the `Country`
    feature, which has a high cardinality. Binary encoding will be used to efficiently
    encode the `Country` feature.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 一个订阅服务提供商希望根据各种特征预测客户是否会订阅高级计划，其中包括具有高基数的`国家`特征。二进制编码将被用来高效地编码`国家`特征。
- en: The data
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: 'Let’s have a look at the sample dataset:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下样本数据集：
- en: '`Country`: This categorical feature represents the country of the customers.
    It helps to understand if the location influences the subscription status.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`国家`：这个类别特征表示客户所在的国家。它有助于了解地理位置是否会影响订阅状态。'
- en: '`Age`: This numerical feature represents the age of the customers. Age can
    be a significant factor in determining the likelihood of a customer subscribing
    to a service.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`年龄`：这个数值特征表示客户的年龄。年龄在确定客户是否订阅某项服务的可能性中可能是一个重要因素。'
- en: '`Income`: This numerical feature represents the annual income of the customers.
    Income can indicate the financial capability of the customers to subscribe to
    a service.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`收入`：这个数值特征表示客户的年收入。收入可以反映客户是否有经济能力订阅某项服务。'
- en: '`Subscription`: This binary target variable indicates whether a customer has
    subscribed to a service. This is the target variable that we want to predict using
    the other features.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`订阅`：这个二进制目标变量表示客户是否订阅了服务。我们希望通过其他特征来预测这个目标变量。'
- en: 'Let’s have a look at a sample of the data for the use case:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下该使用场景的数据样本：
- en: '[PRE35]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The distribution of `Country` can be seen in the following plot:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '`国家`的分布可以在以下图表中看到：'
- en: '![Figure 10.6 – Distribution of Country before and after the encoding](img/B19801_10_6.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.6 – 编码前后国家分布](img/B19801_10_6.jpg)'
- en: Figure 10.6 – Distribution of Country before and after the encoding
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 – 编码前后国家分布
- en: Objective of the use case
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用例目标
- en: 'The goal of this analysis is to predict the Subscription status of customers
    based on their country, age, and income. We use binary encoding for the `Country`
    feature to convert it from a categorical variable to a numerical format that can
    be used in the ML algorithm. The code for this use case can be found here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/5.binary_encoding.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/5.binary_encoding.py).'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 本分析的目标是根据客户的国家、年龄和收入预测订阅状态。我们对`Country`特征使用二进制编码，将其从分类变量转换为可以在机器学习算法中使用的数值格式。此用例的代码可以在这里找到：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/5.binary_encoding.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter10/5.binary_encoding.py)。
- en: 'Follow the next steps:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照以下步骤操作：
- en: 'Let’s create a sample dataset:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个示例数据集：
- en: '[PRE36]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Apply binary encoding to the `Country` feature:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对`Country`特征应用二进制编码：
- en: '[PRE37]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Display the encoded DataFrame:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示编码后的数据框：
- en: '[PRE38]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Let’s have a look at the encoded data.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下编码后的数据。
- en: Encoded output
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码输出
- en: 'In this example, binary encoding is applied to the `Country` feature, as we
    can see in the following output:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，应用了二进制编码到`Country`特征，正如我们在以下输出中看到的：
- en: '[PRE39]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'As we can see from the encoded output, the binary digits are split into separate
    columns. Let’s also have a look at the changes in the distribution after the encoding:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们从编码输出中看到的，二进制数字被拆分成了单独的列。让我们也来看一下编码后分布的变化：
- en: '![Figure 10.7 – Distribution of Country encoded feature](img/B19801_10_7.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.7 – 国家编码特征分布](img/B19801_10_7.jpg)'
- en: Figure 10.7 – Distribution of Country encoded feature
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7 – 国家编码特征分布
- en: Let’s now discuss some things to keep in mind when encoding features with a
    binary encoder.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们讨论在使用二进制编码器进行特征编码时需要注意的一些事项。
- en: Considerations for binary encoding
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二进制编码的注意事项
- en: 'When performing binary encoding, there are several important considerations
    to keep in mind:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行二进制编码时，需要考虑几个重要事项：
- en: Binary encoding doesn’t provide direct interpretability for encoded features.
    The encoded binary patterns may not have a clear meaning, unlike one-hot encoding,
    where each binary feature corresponds to a specific category.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二进制编码没有提供直接的可解释性。与每个二进制特征对应一个特定类别的独热编码不同，编码后的二进制模式可能没有明确的意义。
- en: The binary representation can become complex for categories with very high cardinality
    as the number of binary digits increases logarithmically with the number of categories.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于具有非常高基数的类别，二进制表示可能变得复杂，因为二进制数字的数量会随着类别数量的增加而对数增加。
- en: Some ML algorithms, particularly linear models, may not work well with binary-encoded
    features. Careful evaluation of algorithm compatibility is necessary.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些机器学习算法，特别是线性模型，可能不适用于二进制编码特征。需要仔细评估算法的兼容性。
- en: Now that we’ve explored the nuances of the different encoding methods, let’s
    transition to summarizing their key differences and considerations for practical
    application in ML workflows.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了不同编码方法的细节，让我们转向总结它们的主要区别以及在机器学习工作流中的实际应用考虑事项。
- en: Summary
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Throughout this chapter, we explored various techniques for encoding categorical
    variables essential for ML tasks. Label encoding, which assigns unique integers
    to each category, is straightforward but may inadvertently impose ordinality where
    none exists. One-hot encoding transforms each category into a binary feature,
    maintaining categorical independence but potentially leading to high-dimensional
    datasets. Binary encoding condenses categorical values into binary representations,
    balancing interpretability, and efficiency particularly well for high-cardinality
    datasets. Frequency encoding replaces categories with their occurrence frequencies,
    capturing valuable information about distributional patterns. Target encoding
    incorporates target variable statistics into categorical encoding, enhancing predictive
    power while requiring careful handling to avoid data leakage.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了用于编码分类变量的各种技术，这些技术对于机器学习任务至关重要。标签编码为每个类别分配唯一的整数，方法简单明了，但可能会不自觉地赋予没有顺序关系的类别以顺序性。独热编码将每个类别转换为二进制特征，保持了类别的独立性，但可能会导致高维数据集。二进制编码将分类值压缩成二进制表示，平衡了可解释性和效率，尤其适用于高基数数据集。频率编码通过用类别的出现频率替换类别，捕捉了关于分布模式的有价值信息。目标编码将目标变量的统计信息融入到分类编码中，提高了预测能力，但需要谨慎处理以避免数据泄漏。
- en: 'Let’s summarize our learning in the following table:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在下表中总结我们的学习：
- en: '| Encoding Method | High Cardinality | Preserves Ordinal Information | Collisions
    | Interpretability | Good for | Not Good for |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 编码方法 | 高基数 | 保留顺序信息 | 冲突 | 可解释性 | 适用于 | 不适用于 |'
- en: '| Label encoding | Good | Yes | No | Moderate | Tree-based models | Linear
    models |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 标签编码 | 好 | 是 | 否 | 中等 | 基于树的模型 | 线性模型 |'
- en: '| One-hot encoding | Poor | No | No | High | Linear models, **neural** **networks**
    (**NNs**) | High-cardinality features |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 独热编码 | 差 | 否 | 否 | 高 | 线性模型，**神经** **网络**（**NNs**） | 高基数特征 |'
- en: '| Target encoding | Good | No | Possible | Low | Most algorithms | Small datasets
    (risk of overfitting) |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 目标编码 | 好 | 否 | 可能 | 低 | 大多数算法 | 小数据集（存在过拟合风险） |'
- en: '| Frequency encoding | Good | No | Possible | Moderate | Tree-based models
    | Linear models |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 频率编码 | 好 | 否 | 可能 | 中等 | 基于树的模型 | 线性模型 |'
- en: '| Binary encoding | Good | Partially | Possible | Low | Tree-based models |
    Linear models |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 二进制编码 | 好 | 部分 | 可能 | 低 | 基于树的模型 | 线性模型 |'
- en: Table 10.2 – Comparison of all the encoding techniques
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.2 – 所有编码技术的比较
- en: Each method offers distinct advantages depending on the dataset’s characteristics
    and the specific requirements of the modeling task. In the next chapter, we will
    shift focus to the considerations and methodologies involved in analyzing time
    series data. Time series data introduces temporal dependencies that require specialized
    techniques for feature engineering, as we will expand upon in the next chapter.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 每种方法根据数据集的特点和建模任务的具体要求提供不同的优势。在下一章中，我们将重点讨论分析时间序列数据时需要考虑的问题和方法。时间序列数据引入了时间依赖性，要求使用专门的特征工程技术，正如我们在下一章中将要展开的内容。
