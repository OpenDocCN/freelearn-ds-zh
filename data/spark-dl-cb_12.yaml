- en: Creating a Movie Recommendation Engine with Keras
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Keras创建电影推荐引擎
- en: 'The following recipes will be covered in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下配方：
- en: Downloading MovieLens datasets
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载MovieLens数据集
- en: Manipulating and merging the MovieLens datasets
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作和合并MovieLens数据集
- en: Exploring the MovieLens datasets
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索MovieLens数据集
- en: Preparing dataset for the deep learning pipeline
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为深度学习流水线准备数据集
- en: Applying the deep learning pipeline with Keras
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Keras应用深度学习流水线
- en: Evaluating the recommendation engine's accuracy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估推荐引擎的准确性
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In 2006, a small DVD rental company set out to make their recommendation engine
    10% better. That company was Netflix and The Netflix Prize was worth $1M. This
    competition attracted many engineers and scientists from some of the largest tech
    companies around the world. The recommendation engine for the winning participant
    was built with machine learning. Netflix is now one of the leading tech giants
    when it comes to streaming data and recommending to its customers what they should
    watch next.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 2006年，一家小型DVD租赁公司着手使他们的推荐引擎提高10%。那家公司是Netflix，Netflix奖值100万美元。这场比赛吸引了来自世界各地一些最大科技公司的许多工程师和科学家。获胜参与者的推荐引擎是通过机器学习构建的。Netflix现在是流媒体数据和向其客户推荐下一步应该观看的内容方面的领先科技巨头之一。
- en: Ratings are everywhere these days, no matter what you are doing. If you are
    looking for a recommendation to go out to eat at a new restaurant, to order some
    clothing online, to watch a new movie at your local theater, or to watch a new
    series on television or online, there is most likely a website or a mobile application
    that will give you some type of rating along with feedback on the product or service
    you are looking to purchase. It is because of this immediate increase in feedback
    that recommendation algorithms have become more in demand over the last couple
    of years. This chapter will focus on building a movie recommendation engine for
    users, using the deep learning library Keras.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，评分随处可见，无论你在做什么。如果你正在寻找去新餐馆吃饭的建议，在线订购服装，观看当地影院的新电影，或者在电视或在线上观看新系列，很可能有一个网站或移动应用会给你一些类型的评分以及对你要购买的产品或服务的反馈。正是因为这种反馈的迅速增加，推荐算法在过去几年变得更加受欢迎。本章将专注于使用深度学习库Keras为用户构建电影推荐引擎。
- en: Downloading MovieLens datasets
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载MovieLens数据集
- en: There is a great research lab center that began in 1992 in Minneapolis, MN called
    **GroupLens**, whichfocuses on recommendation engines and has graciously put together
    millions of rows of data over several years from the MovieLens website. We will
    use its dataset as our data source for training our recommendation engine model.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个伟大的研究实验室，它始于1992年，位于明尼阿波利斯，明尼苏达州，名为**GroupLens**，专注于推荐引擎，并且慷慨地从MovieLens网站上收集了数百万行数据。我们将使用它的数据集作为我们推荐引擎模型的数据来源。
- en: Getting ready
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The MovieLens dataset is housed and maintained by GroupLens on the following
    website:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: MovieLens数据集存放在GroupLens的以下网站上：
- en: '[https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/).'
- en: 'It is important to note that the dataset we will use will come directly from
    their website and not from a third-party intermediary or repository. Additionally,
    there are two different datasets that are available for us to query:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，我们将使用的数据集将直接来自他们的网站，而不是来自第三方中介或存储库。此外，有两个不同的数据集可供我们查询：
- en: Recommended for new research
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐用于新研究
- en: Recommended for education and development
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐用于教育和开发
- en: 'The purpose of using this dataset is purely for educational purposes, so we
    will download the data from the education and development section of the website.
    The educational data still contains a significant number of rows for our model,
    as it contains 100,000 ratings, as seen in the following screenshot:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个数据集的目的纯粹是为了教育目的，因此我们将从网站的教育和开发部分下载数据。教育数据仍然包含大量行数，因为它包含了10万个评分，如下截图所示：
- en: '![](img/00349.jpeg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00349.jpeg)'
- en: Additionally, this dataset has information regarding over 600 anonymous users
    collected over a period of several years between 1/9/1995 and 3/31/2015\. The
    dataset was last updated in October 2017.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该数据集包含了在1995年1月9日至2015年3月31日期间收集的600多个匿名用户的信息。该数据集最后更新于2017年10月。
- en: 'F Maxwell Harper and Joseph A Konstan, 2015\. *The MovieLens Datasets: History
    and Context*. ACM **Transactions on Interactive Intelligent Systems** (**TiiS**)
    5, 4, Article 19 (December 2015), 19 pages. DOI: [http://dx.doi.org/10.1145/2827872](http://dx.doi.org/10.1145/2827872)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 'F Maxwell Harper和Joseph A Konstan，2015年。*The MovieLens Datasets: History and
    Context*。ACM **交互智能系统交易** (**TiiS**) 5, 4, Article 19 (2015年12月)，19页。DOI: [http://dx.doi.org/10.1145/2827872](http://dx.doi.org/10.1145/2827872)'
- en: How to do it...
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'This section will cover downloading and unzipping the MovieLens dataset:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将涵盖下载和解压MovieLens数据集：
- en: Download the research version of the smaller MovieLens dataset, which is available
    for public download at the following website: [https://grouplens.org/datasets/movielens/latest/](https://grouplens.org/datasets/movielens/latest/).
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载较小的MovieLens数据集的研究版本，可在以下网站公开下载：[https://grouplens.org/datasets/movielens/latest/](https://grouplens.org/datasets/movielens/latest/).
- en: 'Download the `ZIP` file called `ml-latest-small.zip` to one of our local folders,
    as seen in in the following screenshot:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载名为`ml-latest-small.zip`的`ZIP`文件到我们的一个本地文件夹中，如下截图所示：
- en: '![](img/00350.jpeg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00350.jpeg)'
- en: 'When `ml-latest-small.zip` is downloaded and unzipped, the following four files
    should be extracted:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当下载并解压`ml-latest-small.zip`后，应提取以下四个文件：
- en: '`links.csv`'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`links.csv`'
- en: '`movies.csv`'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`movies.csv`'
- en: '`ratings.csv`'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ratings.csv`'
- en: '``tags.csv``'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '``tags.csv``'
- en: 'Execute the following script to begin our `SparkSession`:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本开始我们的`SparkSession`：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Confirm the following six files are available for access by executing the following
    script:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本确认以下六个文件可供访问：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Load each dataset into a Spark dataframe using the following script:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将每个数据集加载到Spark数据框中：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Confirm the row counts for each dataset by executing the following script:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本来确认每个数据集的行数：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How it works...
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'This section will focus on explaining the fields in each of the datasets available
    in the MovieLens 100K dataset. Take a look at these steps:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍MovieLens 100K数据集中每个数据集中的字段。请看以下步骤：
- en: 'The datasets are all available in the zipped file, `ml-latest-small.zip`, where
    the `ratings.csv` dataset will serve as the pseudo-fact table of our data, since
    it has transactions for each movie that is rated. The dataset, `ratings`, has
    the four column names shown in the following screenshot:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些数据集都包含在压缩文件`ml-latest-small.zip`中，其中`ratings.csv`数据集将作为我们的数据的伪事实表，因为它包含了每部电影的交易。数据集`ratings`中有四个列名，如下截图所示：
- en: '![](img/00351.jpeg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00351.jpeg)'
- en: 'The dataset shows the rating selected by each userId over the course of their
    time, from the earliest rating to the latest rating. The range of a rating can
    vary from 0.5 to 5.0 stars, as seen by `userId = 1` in the following screenshot:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该数据集显示了每个用户在其时间内选择的评分，从最早的评分到最新的评分。评分的范围可以从0.5到5.0星，如下截图中的`userId = 1`所示：
- en: '![](img/00352.jpeg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00352.jpeg)'
- en: 'The `tags` dataset contains a tag column that contains a specific word or phrase
    used by that user to describe a specific movieId at a specific timestamp. As can
    be seen in the following screenshot, userId 15 was not particularly fond of Sandra
    Bulluck in one of her movies:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`tags`数据集包含一个标签列，其中包含用户用于描述特定电影ID的特定单词或短语。如下截图所示，用户15对桑德拉·布洛克在她的一部电影中并不特别喜欢：'
- en: '![](img/00353.jpeg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00353.jpeg)'
- en: 'The `movies` dataset is primarily a lookup table for the genre of films that
    have ratings. There are 19 unique genres that can be associated with a film; however,
    it is important to note that a film can be affiliated with more than one genre
    at a time, as seen in the following screenshot:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`movies`数据集主要是电影类型的查找表。有19种唯一的类型可以与电影相关联；但是，重要的是要注意，一部电影可以同时与多种类型相关联，如下截图所示：'
- en: '![](img/00354.jpeg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00354.jpeg)'
- en: 'The final dataset is the `links` dataset, which also functions as a lookup
    table. It connects movies from MovieLens to data available for those same movies
    on popular film database sites such as [http://www.imdb.com](http://www.imdb.com),
    as well as [https://www.themoviedb.org](https://www.themoviedb.org). Links to
    IMDB are under the column called imdbId, and links to the MovieDB are under the
    column called tmdbId, as seen in the following screenshot:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个数据集是`links`数据集，它也充当查找表。它将MovieLens中的电影与流行电影数据库网站（如[http://www.imdb.com](http://www.imdb.com)和[https://www.themoviedb.org](https://www.themoviedb.org)）上可用的数据连接起来。IMDB的链接在名为imdbId的列下，而MovieDB的链接在名为tmdbId的列下，如下截图所示：
- en: '![](img/00355.jpeg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00355.jpeg)'
- en: 'Before we finish, it is always a good idea to confirm that we are truly experiencing
    the expected row counts from all of the datasets. This helps to ensure that we
    did not encounter any issues with uploading the files to the notebook. We should
    expect to see around 100k rows for the ratings dataset, as seen in the following
    screenshot:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在完成之前，确认我们确实从所有数据集中获得了预期的行数总是一个好主意。这有助于确保我们在将文件上传到笔记本时没有遇到任何问题。我们应该期望在`ratings`数据集中看到大约10万行，如下截图所示：
- en: '![](img/00356.jpeg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00356.jpeg)'
- en: There's more...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'While we are not going to use the 20 million-row dataset version of MovieLens
    for this chapter, you could elect to use it for this recommendation engine. You
    will still have the same four datasets, but with much more data, especially for
    the `ratings` dataset. If you choose to go with this approach, the full zipped
    dataset can be downloaded from the following website:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们不会在本章中使用MovieLens的2000万行数据集版本，但您可以选择在此推荐引擎中使用它。您仍将拥有相同的四个数据集，但`ratings`数据集的数据量将更大。如果选择这种方法，完整的压缩数据集可以从以下网站下载：
- en: '[http://files.grouplens.org/datasets/movielens/ml-latest.zip](http://files.grouplens.org/datasets/movielens/ml-latest.zip)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://files.grouplens.org/datasets/movielens/ml-latest.zip](http://files.grouplens.org/datasets/movielens/ml-latest.zip)'
- en: See also
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about the metadata behind the MovieLens dataset used in this
    chapter, visit the following website:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解本章中使用的MovieLens数据集背后的元数据，请访问以下网站：
- en: '[http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html)'
- en: 'To learn more about the history and context of the MovieLens dataset used in
    this chapter, visit the following website:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解本章中使用的MovieLens数据集的历史和背景，请访问以下网站：
- en: '[https://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context](https://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context](https://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context)'
- en: 'To learn more about *The Netflix Prize*, visit the following website:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关*Netflix奖*的更多信息，请访问以下网站：
- en: '[https://www.netflixprize.com/](https://www.netflixprize.com/)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.netflixprize.com/](https://www.netflixprize.com/)'
- en: Manipulating and merging the MovieLens datasets
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作和合并MovieLens数据集
- en: We currently have four separate datasets that we are working with, but ultimately
    we would like to get it down to a single dataset. This chapter will focus on pairing
    down our datasets to one.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们目前有四个不同的数据集，但最终我们希望将其减少到一个数据集。本章将重点介绍如何将我们的数据集减少到一个。
- en: Getting ready
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: This section will not require any import of PySpark libraries but a background
    in SQL joins will come in handy, as we will explore multiple approaches to joining
    dataframes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本节不需要导入PySpark库，但了解SQL连接将很有帮助，因为我们将探索多种连接数据框的方法。
- en: How to do it...
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'This section will walk through the following steps for joining dataframes in
    PySpark:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍在PySpark中连接数据框的以下步骤：
- en: 'Execute the following script to rename all field names in `ratings`, by appending
    a `_1` to the end of the name:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本将`ratings`中的所有字段名重命名，将“_1”附加到名称的末尾：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Execute the following script to `inner join` the `movies` dataset to the `ratings`
    dataset, creating a new table called `temp1`:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本将`movies`数据集与`ratings`数据集进行`内连接`，创建一个名为`temp1`的新表：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Execute the following script to inner join the `temp1` dataset to the `links`
    dataset, creating a new table called `temp2`:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本将`temp1`数据集与`links`数据集进行内连接，创建一个名为`temp2`的新表：
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create our final combined dataset, `mainDF`, by left-joining `temp2` to `tags`
    using the following script:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过左连接`temp2`与`tags`，创建我们的最终组合数据集`mainDF`，使用以下脚本：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Select only the columns needed for our final `mainDF` dataset by executing
    the following script:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本，仅选择我们最终`mainDF`数据集所需的列：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works...
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'This section will walk through our design process for joining tables together
    as well as which final columns will be kept:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍我们连接表的设计过程，以及将保留哪些最终列：
- en: 'As was mentioned in the previous section, the ratings dataframe will serve
    as our fact table, since it contains all the main transactions of ratings for
    each user over time. The columns in ratings will be used in each subsequent join
    with the other three tables, and to maintain a uniqueness of the columns, we will
    attach a _1 to the end of each column name, as seen in the following screenshot:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前一节所述，评分数据框将作为我们的事实表，因为它包含每个用户随时间的所有主要评分交易。评分中的列将在与其他三个表的每个后续连接中使用，并且为了保持列的唯一性，我们将在每个列名的末尾附加“_1”，如下图所示：
- en: '![](img/00357.jpeg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00357.jpeg)'
- en: 'We can now join the three lookup tables to the ratings table. The first two
    joins to ratings are inner joins, as the row counts for temp1 and temp2 are still
    100,004 rows. The third join to ratings from tags needs to be an outer join to
    avoid dropping rows. Additionally, the join needs to be applied to both movieId
    as well as userId, as a tag is unique to both a specific user and a specific movie
    at any given time. The row counts for the three tables temp1, temp2, and mainDF
    can be seen in the following screenshot:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以将三个查找表与评分表进行连接。前两个与评分的连接是内连接，因为temp1和temp2的行数仍然是100,004行。从tags到评分的第三个连接需要是外连接，以避免丢失行。此外，连接需要应用于movieId和userId，因为标签在任何给定时间都是唯一的，对于特定用户和特定电影。三个表temp1、temp2和mainDF的行数可以在下图中看到：
- en: '![](img/00358.jpeg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00358.jpeg)'
- en: 'Often times when working with joins between datasets, we encounter three types
    of joins: inner, left, and right. An inner join will only produce a result set
    when both join keys are available from dataset 1 and dataset 2\. A left join will
    produce all of the rows from dataset 1 and only the rows with matching keys from
    dataset 2\. A right join will produce all of the rows from dataset 2 and only
    the rows from the matching keys from dataset 1\. Later on in this section, we
    will explore SQL joins within Spark.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数据集之间的连接时，通常会遇到三种类型的连接：内连接、左连接和右连接。内连接只在数据集1和数据集2的连接键都可用时才产生结果集。左连接将产生数据集1的所有行，以及数据集2中匹配键的行。右连接将产生数据集2的所有行，以及数据集1中匹配键的行。在本节的后面，我们将探讨Spark中的SQL连接。
- en: 'It is interesting to note that our newly created dataset, mainDF, has 100,441
    rows, instead of the 100,004 rows that are in the original dataset for ratings,
    as well as temp1 and temp2\. There are 437 ratings that have more than one tag
    associated with them. Additionally, we can see that the majority of ratings_1 have
    a null tag value affiliated with them, as seen in the following screenshot:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有趣的是，我们新创建的数据集mainDF有100,441行，而不是原始评分数据集中的100,004行，以及temp1和temp2。有437个评分有多个标签与之关联。此外，我们可以看到大多数ratings_1都有一个空的tag值与之关联，如下图所示：
- en: '![](img/00359.jpeg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00359.jpeg)'
- en: 'We have accumulated additional duplicative columns that will no longer be needed.
    There are 14 columns in total, as seen in the following screenshot:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们积累了不再需要的额外重复列。总共有14列，如下图所示：
- en: '![](img/00360.jpeg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00360.jpeg)'
- en: 'Additionally, we have determined that the tags field is relatively useless
    as it has over 99k null values. Therefore, we will use the `select()` function
    on the dataframe to pull in only the eight columns that we will use for our recommendation
    engine. We can then confirm that our final new dataframe, mainDF, has the correct
    amount of rows, 100,004, as seen in the following screenshot:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另外，我们已经确定tags字段相对无用，因为有超过99k个空值。因此，我们将使用数据框架上的`select()`函数，只提取我们推荐引擎所需的八列。然后，我们可以确认我们的最终新数据框`mainDF`有正确的行数，即100,004行，如下截图所示：
- en: '![](img/00361.jpeg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00361.jpeg)'
- en: There's more...
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'While we did do our joins using functions within a Spark dataframe using PySpark,
    we could have also done it by registering the dataframes as temporary tables and
    then joining them using `sqlContext.sql()`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们使用PySpark在Spark数据框架中使用函数进行了连接，但我们也可以通过将数据框注册为临时表，然后使用`sqlContext.sql()`进行连接：
- en: 'First, we would register each of our datasets as temporary views using `creatorReplaceTempView()`,
    as seen in the following script:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将使用`creatorReplaceTempView()`将每个数据集注册为临时视图，如下脚本所示：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we would write our SQL script just as we would do with any other relational
    database using the `sqlContext.sql()` function, as seen in the following script:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将编写我们的SQL脚本，就像我们在任何其他关系数据库中所做的那样，使用`sqlContext.sql()`函数，如下脚本所示：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, we can profile the new dataframe, mainDF_SQL, and observe that it
    looks the same as our other dataframe, mainDF, while also keeping the exact same
    row count, as seen in the following screenshot:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以对新数据框mainDF_SQL进行分析，并观察它看起来与我们的其他数据框mainDF相同，同时保持完全相同的行数，如下图所示：
- en: '![](img/00362.jpeg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00362.jpeg)'
- en: See also
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about SQL programming within Spark, visit the following website:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关Spark中SQL编程的更多信息，请访问以下网站：
- en: '[https://spark.apache.org/docs/latest/sql-programming-guide.html](https://spark.apache.org/docs/latest/sql-programming-guide.html)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/latest/sql-programming-guide.html](https://spark.apache.org/docs/latest/sql-programming-guide.html)'
- en: Exploring the MovieLens datasets
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索MovieLens数据集
- en: Before any modeling takes place, it is important to get familiar with the source
    dataset and perform some exploratory data analysis.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行任何建模之前，熟悉源数据集并进行一些探索性数据分析是很重要的。
- en: Getting ready
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will import the following library to assist with visualizing and exploring
    the MovieLens dataset: `matplotlib`.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将导入以下库来帮助可视化和探索MovieLens数据集：`matplotlib`。
- en: How to do it...
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'This section will walk through the steps to analyze the movie ratings in the
    MovieLens database:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍分析MovieLens数据库中电影评分的步骤：
- en: 'Retrieve some summary statistics on the `rating_1` column by executing the
    following script:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本，检索`rating_1`列的一些摘要统计：
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Build a histogram of the distribution of ratings by executing the following
    script:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本构建评分分布的直方图：
- en: '[PRE12]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Execute the following script to view the values of the histogram in a spreadsheet
    dataframe:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本以在电子表格数据框中查看直方图的值：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'A unique count of user selections of ratings can be stored as a dataframe, `userId_frequency`,
    by executing the following script:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本，可以将用户对评分的唯一计数存储为数据框`userId_frequency`：
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Plot a histogram of `userID_frequency` using the following script:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本绘制`userID_frequency`的直方图：
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: How it works...
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'This section will discuss how the ratings and user activities are distributed
    in the MovieLens database. Take a look at these steps:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将讨论MovieLens数据库中评分和用户活动的分布。请查看以下步骤：
- en: 'We can see that the average movie rating made by a user is approximately 3.5,
    as seen in the following screenshot:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到用户平均电影评分约为3.5，如下截图所示：
- en: '![](img/00363.jpeg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00363.jpeg)'
- en: 'Even though the average rating is 3.54, we can see that the histogram shows
    that the median rating is 4, which indicates that the user ratings are heavily
    skewed towards higher ratings, as seen in the following screenshot:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽管平均评分为3.54，但我们可以看到直方图显示中位数评分为4，这表明用户评分严重偏向较高的评分，如下截图所示：
- en: '![](img/00364.jpeg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00364.jpeg)'
- en: 'Another look at the data behind the histogram shows that users select 4.0 most
    frequently, followed by 3.0, and then 5.0\. Additionally, it is interesting to
    note that users are more likely to give ratings that are at the 0.0 level and
    not at the 0.5 level, as seen in the following screenshot:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直方图背后的数据再次显示，用户最频繁选择4.0，其次是3.0，然后是5.0。此外，有趣的是用户更有可能给出0.0级别的评分，而不是0.5级别的评分，如下截图所示：
- en: '![](img/00365.jpeg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00365.jpeg)'
- en: 'We can look at the distribution of user selection of ratings and see that some
    users are very active in expressing their opinions on the films they''ve seen.
    This is the case with anonymous user 547 who has posted 2391 ratings, as seen
    in the following screenshot:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以查看用户对评分的分布，并且看到一些用户非常活跃地表达对他们所看电影的意见。例如，匿名用户547发布了2391条评分，如下截图所示：
- en: '![](img/00366.jpeg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00366.jpeg)'
- en: 'However, when we look at the distribution of users making rating selections,
    we do see that while there are some instances of users making over a thousand
    selections on their own, the overwhelming majority of users have made less than
    250 selections, as seen in the following screenshot:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然而，当我们查看用户进行评分选择的分布时，我们确实看到，虽然有一些用户单独进行了一千多次选择，但绝大多数用户的选择次数少于250次，如下截图所示：
- en: '![](img/00367.jpeg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00367.jpeg)'
- en: The distribution of the histogram is the previous screenshot is in a long-tail
    format which indicates that the majority of the occurrences are away from the
    center of the histogram. This is an indication that the overwhelming majority
    of ratings are defined by a few users.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上一个截图中直方图的分布呈现长尾格式，表明大多数发生在直方图中心之外。这表明绝大多数评分是由少数用户定义的。
- en: There's more...
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: There are features that the `pyspark` dataframe that are similar to those of
    the `pandas` dataframe and can perform some summary statistics on specific columns.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyspark`数据框中有一些类似于`pandas`数据框的特性，并且可以对特定列执行一些摘要统计。'
- en: 'In `pandas`, we perform summary statistics using the following script: `dataframe[''column''].describe()`.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在`pandas`中，我们使用以下脚本执行摘要统计：`dataframe['column'].describe()`。
- en: 'In `pyspark`, we perform summary statistics using the following script: `dataframe.describe(''column'').show()`.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在`pyspark`中，我们使用以下脚本执行摘要统计：`dataframe.describe('column').show()`。
- en: See also
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about the `describe()` function in PySpark, visit the following
    website:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解PySpark中`describe()`函数的更多信息，请访问以下网站：
- en: '[http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe](http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe](http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe)'
- en: Preparing dataset for the deep learning pipeline
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为深度学习流水线准备数据集
- en: We are now ready to prepare our dataset to be fed into the deep learning model
    that we will build in Keras.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备将我们的数据集准备好，以便输入到我们将在Keras中构建的深度学习模型中。
- en: Getting ready
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'While preparing the dataset for `Keras` we will import the following libraries
    into our notebook:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在为`Keras`准备数据集时，我们将在笔记本中导入以下库：
- en: '`import pyspark.sql.functions as F`'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import pyspark.sql.functions as F`'
- en: '`import numpy as np`'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import numpy as np`'
- en: '`from pyspark.ml.feature import StringIndexer`'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from pyspark.ml.feature import StringIndexer`'
- en: '`import keras.utils`'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import keras.utils`'
- en: How to do it...
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'This section walks through the following steps to prepare the dataset for the
    deep learning pipeline:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍准备数据集用于深度学习流水线的以下步骤：
- en: 'Execute the following script to clean up the column names:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本清理列名：
- en: '[PRE16]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `rating` column is currently divided into 0.5 increments. Tweak the ratings
    to be rounded to a whole integer using the following script:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “评分”列目前被分为0.5的增量。使用以下脚本调整评分，使其四舍五入为整数：
- en: '[PRE17]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Convert the `genres` column from a string to an index with a name of `genreCount`
    based on the frequency of the `genres` labels as seen in the following script:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据“流派”标签的频率，将“流派”列从字符串转换为名为genreCount的索引，如下脚本所示：
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Pair down our dataframe using the following script:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本简化我们的数据框：
- en: '[PRE19]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Split `mainDF` into a training and testing set for model-training purposes,
    using the following script:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将mainDF分割为用于模型训练的训练集和测试集：
- en: '[PRE20]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Convert our two Spark dataframes, `trainDF` and `testDF`, into four `numpy`
    arrays for consumption within our deep learning model using the following script:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将我们的两个Spark数据框trainDF和testDF转换为四个numpy数组，以便在我们的深度学习模型中使用：
- en: '[PRE21]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Convert both `ytrain_array` and `ytest_array` into one-hot encoded labels,
    `ytrain_OHE` and `ytest_OHE`, using the following script:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将ytrain_array和ytest_array转换为独热编码标签ytrain_OHE和ytest_OHE：
- en: '[PRE22]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How it works...
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'This section explains how we prepare the dataset for the deep learning pipeline:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释我们如何准备数据集用于深度学习流水线：
- en: 'For ease of use inside the deep learning pipeline, it is best to clean up the
    column names and the order of the columns before the pipeline receives the data.
    After renaming the column headers, we can view the updated columns, as seen in
    the following script:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在深度学习流水线内使用时，最好在流水线接收数据之前清理列名和列的顺序。重命名列标题后，我们可以查看更新后的列，如下脚本所示：
- en: '![](img/00368.jpeg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00368.jpeg)'
- en: A bit of manipulation is performed on the `ratings` column to round up values
    of 0.5 increments to the next-highest whole number. This will assist when we are
    doing our multi-class classification within Keras to group `ratings` into six
    categories, instead of 11 categories.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对“评分”列进行一些操作，将0.5增量的值四舍五入为下一个最接近的整数。这将有助于我们在Keras中进行多类分类时，将“评分”分为六个类别，而不是11个类别。
- en: 'To consume the movie genre types into the deep learning model within, we need
    to convert the string values of `genres` into a numeric label. The most frequent
    genres type will get a value of 0, and the values increase for the next most frequent-
    type. In the following screenshot, we can see that Good Will Hunting has two genres
    associated with it (Drama | Romance), and that is the fourth most-frequent genreCount,
    with a value of 3.0:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了在深度学习模型中使用电影流派类型，我们需要将“流派”的字符串值转换为数字标签。最常见的流派类型将获得值0，下一个最常见的类型将增加值。在以下截图中，我们可以看到Good
    Will Hunting有两种与之关联的流派（Drama | Romance），这是第四种最常见的genreCount，值为3.0：
- en: '![](img/00369.jpeg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00369.jpeg)'
- en: 'The genres column is no longer needed for the deep model, as it will be replaced
    by the genreCount column, as seen in the following screenshot:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 流派列对于深度模型不再需要，因为它将被genreCount列替换，如下截图所示：
- en: '![](img/00370.jpeg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00370.jpeg)'
- en: 'Our main dataframe, mainDF, is split into a trainDF and testDF for modeling,
    training, and evaluation purposes, using an 80/20 split. The row count for all
    three dataframes can be seen in the following screenshot:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的主数据框mainDF被分成trainDF和testDF，用于建模、训练和评估，采用80/20的分割。所有三个数据框的行数可以在以下截图中看到：
- en: '![](img/00371.jpeg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00371.jpeg)'
- en: 'Data is passed into a Keras deep learning model, using matrices instead of
    dataframes. Therefore, our training and testing dataframes are converted into
    numpy arrays and split out into *x* and *y*. The features selected for `xtrain_array`
    and `xtest_array` are userid, movieid, and genreCount. These are the only features
    that will we will use to determine what a potential rating will be for a user.
    We are dropping `imdbid` and `tmdbid`, as they are directly tied to the `movieid`
    and therefore will not provide any additional value. `timestamp` will be removed
    to filter out any bias associated with frequency of voting. Finally, `ytest_array`
    and `ytrain_array` will contain the label value for rating. The `shape` of all
    four arrays can be seen in the following screenshot:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据被传递到Keras深度学习模型中，使用矩阵而不是数据框。因此，我们的训练和测试数据框被转换为numpy数组，并分为x和y。选择用于xtrain_array和xtest_array的特征是userid、movieid和genreCount。这些是我们用来确定用户可能评分的唯一特征。我们放弃了imdbid和tmdbid，因为它们直接与movieid相关，因此不会提供任何额外的价值。时间戳将被删除以过滤掉与投票频率相关的任何偏见。最后，ytest_array和ytrain_array将包含评分的标签值。所有四个数组的形状可以在以下截图中看到：
- en: '![](img/00372.jpeg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00372.jpeg)'
- en: There's more...
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'While `ytrain_array` and `ytest_array` are both labels in a matrix format,
    they are not ideally encoded for deep learning. Since this is technically a classification
    model that we are building we need to encode our labels in a manner for them to
    be understood by the model. This means that our ratings of 0 through 5 should
    be encoded as 0 or 1 values, based on their value elements. Therefore, if a rating
    received the highest value of 5, it should be encoded as [0,0,0,0,0,1]. The first
    position is reserved for 0, and the sixth position is reserved for 1, indicating
    a value of 5\. We can make this conversion using `keras.utils` and convert our
    categorical variables to one-hot encoded variables. In doing this, the shape of
    our training label is converted from (80146,1) to (80146,6) as seen in the following
    screenshot:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`ytrain_array`和`ytest_array`都是矩阵格式的标签，但它们并不是理想的深度学习编码。由于我们正在构建的是一个分类模型，我们需要以一种能够被模型理解的方式对标签进行编码。这意味着我们的0到5的评分应该根据它们的值元素被编码为0或1值。因此，如果一个评分获得了最高值5，它应该被编码为[0,0,0,0,0,1]。第一个位置保留给0，第六个位置保留给1，表示值为5。我们可以使用`keras.utils`进行此转换，并将我们的分类变量转换为独热编码变量。通过这样做，我们的训练标签的形状从(80146,1)转换为(80146,6)，如下面的屏幕截图所示：
- en: '![](img/00373.jpeg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00373.jpeg)'
- en: See also
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: To learn more about `keras.utils` visit the following website: [https://keras.io/utils/](https://keras.io/utils/)
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关`keras.utils`的更多信息，请访问以下网站：[https://keras.io/utils/](https://keras.io/utils/)
- en: Applying the deep learning model with Keras
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Keras应用深度学习模型
- en: At this point, we are ready to apply Keras to our data.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们已经准备好将Keras应用于我们的数据。
- en: Getting ready
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will be using the following from Keras:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Keras中的以下内容：
- en: '`from keras.models import Sequential`'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from keras.models import Sequential`'
- en: '`from keras.layers import Dense, Activation`'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from keras.layers import Dense, Activation`'
- en: How to do it...
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'This section walks through the following steps to apply a deep learning model,
    using Keras on our dataset:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将通过以下步骤介绍如何在数据集上应用Keras进行深度学习模型：
- en: 'Import the following libraries to build a `Sequential` model from `keras`,
    using the following script:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`keras`中导入以下库以构建`Sequential`模型，使用以下脚本：
- en: '[PRE23]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Configure the `Sequential` model from `keras`, using the following script:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本配置`keras`中的`Sequential`模型：
- en: '[PRE24]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We `fit` and train the model and store the results to a variable called `accuracy_history`,
    using the following script:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们`fit`和训练模型，并将结果存储到名为`accuracy_history`的变量中，使用以下脚本：
- en: '[PRE25]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: How it works...
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: This section explains the configuration of the Keras model that is applied to
    the dataset to predict a rating based on the features selected.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了应用于数据集的Keras模型的配置，以基于所选特征预测评分。
- en: In Keras, a `Sequential` model is simply a linear combination of layers, which
    are the following: `Dense` is used to define the layer types to a fully-connected
    layer within a deep neural network. Finally, `Activation` is used to convert the
    inputs from the features into an output that can be used as a prediction. There
    are many types of activation functions that can be used in a neural network; however,
    for this chapter, we will go with `relu` and `softmax`.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Keras中，`Sequential`模型只是层的线性组合，包括以下内容：`Dense`用于在深度神经网络中定义全连接层的层类型。最后，`Activation`用于将特征的输入转换为可以用作预测的输出。在神经网络中可以使用许多类型的激活函数；但是，在本章中，我们将使用`relu`和`softmax`。
- en: 'The `Sequential` model is configured to include three `Dense` layers:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Sequential`模型配置为包括三个`Dense`层：'
- en: The first layer has `input_dim` set to the number of features from `xtrain_array`.
    The `shape` feature pulls in the value of 3, using `xtrain_array.shape[1]`. Additionally,
    the first layer is set to have `32` neurons in the first layer of the neural network.
    Finally, the three input parameters are activated using the `relu` activation
    function. Only the first layer requires an explicit definition of the input dimensions.
    This is not required in subsequent layers, as they will be able to infer the number
    of dimensions from the previous layer.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一层的`input_dim`设置为`xtrain_array`中的特征数量。`shape`特征拉取值为3，使用`xtrain_array.shape[1]`。此外，第一层设置为神经网络的第一层有`32`个神经元。最后，三个输入参数使用`relu`激活函数激活。只有第一层需要显式定义输入维度。在后续层中不需要，因为它们将能够从前一层推断出维度的数量。
- en: The second layer in the `Sequential` model has `10` neurons in the neural network
    along with an activation function set to `relu`. Rectified linear units are used
    early on in the neural network process because they are effective during the training
    process. This is due to the simplicity of the equation as any value less than
    0 is thrown out, which is not the case with other activation functions.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Sequential`模型中的第二层在神经网络中有`10`个神经元，并且激活函数设置为`relu`。在神经网络过程中早期使用修正线性单元是有效的，因为它们在训练过程中是有效的。这是因为方程的简单性，任何小于0的值都被舍弃，而其他激活函数则不是这样。'
- en: The third and final layer of the `Sequential` model requires six outputs based
    on every possible scenario of a rating from 0 to 5\. This requires setting the
    output to the value of `ytrain_OHE.shape[1]`. The output is generated using a
    `softmax` function which is often the case at the end of a neural network, as
    it is very useful for classification purposes. At this point, we are looking to
    classify a value between 0 and 5.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Sequential`模型的第三层需要根据从0到5的每种可能的评分情况生成六个输出。这需要将输出设置为`ytrain_OHE.shape[1]`的值。输出使用`softmax`函数生成，这在神经网络的末端通常是这样，因为它对分类非常有用。此时，我们正在寻找对0到5之间的值进行分类。'
- en: Once the layers are specified, we must `compile` the model.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦层被指定，我们必须`compile`模型。
- en: We optimize the model using `adam`, which stands for **Adaptive Moment Estimation**.
    Optimizers are great for configuring the learning rate of the gradient descent
    that the model uses to tweak and update the weights of the neural network. `adam`
    is a popular optimizer, as it is said to combine some of the best features from
    other common optimizers.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`adam`来优化模型，它代表**自适应矩估计**。优化器非常适合配置模型用于调整和更新神经网络权重的梯度下降的学习率。`adam`是一种流行的优化器，据说它结合了其他常见优化器的一些最佳特性。
- en: Our loss function is set to `categorical_crossentroy`, which is often used when
    looking to predict a multi-class classification. The loss function evaluates the
    performance of the model as it is being trained.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的损失函数设置为`categorical_crossentroy`，通常用于预测多类分类时使用。损失函数评估模型在训练过程中的性能。
- en: 'We train the model using the training features, `xtrain_array`, and the training
    labels `ytrain_OHE`. The model is trained over 20 epochs, each time with a batch_size
    set to 32\. The model output for `accuracy` and `loss` over each epoch are captured
    in a variable called `accuracy_history` and can be viewed as seen in the following
    screenshot:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用训练特征`xtrain_array`和训练标签`ytrain_OHE`来训练模型。模型在20个时期内进行训练，每次批量大小设置为32。每个时期的模型输出`accuracy`和`loss`都被记录在一个名为`accuracy_history`的变量中，可以在以下截图中查看：
- en: '![](img/00374.jpeg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00374.jpeg)'
- en: There's more...
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'While we can print out the loss and accuracy scores over each epoch, it is
    always better to visualize both outputs over each of the 20 epochs. We can plot
    both by using the following script:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以在每个时期打印出损失和准确度分数，但最好是在每个20个时期内可视化这两个输出。我们可以使用以下脚本绘制两者：
- en: '[PRE26]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output of the script can be seen in the following screenshot:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本的输出可以在以下截图中看到：
- en: '![](img/00375.jpeg)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00375.jpeg)'
- en: It appears that after the second epoch, both the loss and accuracy are stabilized
    in the model.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来在第二个时期之后，模型的损失和准确度都稳定下来了。
- en: See also
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: To learn more about getting started with the `Sequential` model from `keras`,
    visit the following website: [https://keras.io/getting-started/sequential-model-guide/](https://keras.io/getting-started/sequential-model-guide/).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关使用`keras`中的`Sequential`模型入门的更多信息，请访问以下网站：[https://keras.io/getting-started/sequential-model-guide/](https://keras.io/getting-started/sequential-model-guide/)。
- en: Evaluating the recommendation engine's accuracy
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估推荐引擎的准确性
- en: We can now calculate the accuracy rate of our deep learning model built on Keras.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以计算我们基于Keras构建的深度学习模型的准确率。
- en: Getting ready
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Evaluating a `Sequential` model for accuracy requires using the `model.evaluate()`
    function within Keras.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 评估`Sequential`模型的准确性需要使用Keras中的`model.evaluate()`函数。
- en: How to do it...
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We can simply calculate the accuracy score, `accuracy_rate`, by executing the
    following script:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过执行以下脚本简单地计算准确度分数`accuracy_rate`：
- en: '[PRE27]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: How it works...
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Our model performance is based on evaluating our test features, `xtest_array`,
    with our test labels, `ytest_OHE`. We can use `model.evaluate()` and set the `batch_size`
    for evaluation at `128` elements. We can see that our accuracy is around 39%,
    as seen in the following screenshot:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型性能是基于评估我们的测试特征`xtest_array`和测试标签`ytest_OHE`。我们可以使用`model.evaluate()`并将`batch_size`设置为`128`来进行评估。我们可以看到我们的准确度约为39%，如以下截图所示：
- en: '![](img/00376.jpeg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00376.jpeg)'
- en: This means that we are able to determine the rating by a user between 0 and
    5 and at nearly a 39% accuracy rate.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们能够以近39%的准确率确定用户对0到5之间的评分。
- en: See also
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about model performance with Keras metrics, visit the following
    website:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关Keras指标的模型性能的更多信息，请访问以下网站：
- en: '[https://keras.io/metrics/](https://keras.io/metrics/)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://keras.io/metrics/](https://keras.io/metrics/)'
