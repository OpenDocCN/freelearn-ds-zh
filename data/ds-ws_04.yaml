- en: 4\. Multiclass Classification with RandomForest
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 使用随机森林进行多类分类
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter will show you how to train a multiclass classifier using the Random
    Forest algorithm. You will also see how to evaluate the performance of multiclass
    models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将展示如何使用随机森林算法训练一个多类分类器。你还将看到如何评估多类模型的性能。
- en: By the end of the chapter, you will be able to implement a Random Forest classifier,
    as well as tune hyperparameters in order to improve model performance.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你将能够实现一个随机森林分类器，并调节超参数以提高模型性能。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In the previous chapter, you saw how to build a binary classifier using the
    famous **Logistic Regression** algorithm. A binary classifier can only take two
    different values for its response variables, such as 0 and 1 or yes and no. A
    multiclass classification task is just an extension. Its response variable can
    have more than two different values.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了如何使用著名的**逻辑回归**算法构建一个二分类器。二分类器只能为其响应变量取两个不同的值，如0和1或是与否。多类分类任务则是二分类的扩展，其响应变量可以有超过两个不同的值。
- en: 'In the data science industry, quite often you will face multiclass classification
    problems. For example, if you were working for Netflix or any other streaming
    platform, you would have to build a model that could predict the user rating for
    a movie based on key attributes such as genre, duration, or cast. A potential
    list of rating values may be: *Hate it*, *Dislike it*, *Neutral*, *Like* *it*,
    *Love it*. The objective of the model would be to predict the right rating from
    those five possible values.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学行业中，你经常会遇到多类分类问题。例如，如果你为Netflix或任何其他流媒体平台工作，你需要构建一个模型，能够根据关键属性如类型、时长或演员来预测电影的用户评分。可能的评分值列表包括：*讨厌*、*不喜欢*、*中立*、*喜欢*、*非常喜欢*。该模型的目标是从这五个可能值中预测正确的评分。
- en: 'Multiclass classification doesn''t always mean the response variable will be
    text. In some datasets, the target variable may be encoded into a numerical form.
    Taking the same example as discussed, the rating may be coded from 1 to 5: 1 for
    *Hate it*, 2 for *Dislike it*, 3 for *Neutral*, and so on. So, it is important
    to understand the meaning of this response variable first before jumping to the
    conclusion that this is a regression problem.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类并不总是意味着响应变量是文本。在某些数据集中，目标变量可能已被编码成数字形式。以之前讨论的示例为例，评分可能会从1到5编码：1表示*讨厌*，2表示*不喜欢*，3表示*中立*，以此类推。因此，在断定这是回归问题之前，首先理解该响应变量的含义非常重要。
- en: In the next section, we will be looking at training our first Random Forest
    classifier.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将学习如何训练第一个随机森林分类器。
- en: Training a Random Forest Classifier
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练一个随机森林分类器
- en: In this chapter, we will use the Random Forest algorithm for multiclass classification.
    There are other algorithms on the market, but Random Forest is probably one of
    the most popular for such types of projects.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用随机森林算法进行多类分类。市场上有其他算法，但随机森林可能是最受欢迎的算法之一，尤其适用于此类项目。
- en: The Random Forest methodology was first proposed in 1995 by Tin Kam Ho but it
    was first developed by Leo Breiman in 2001.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林方法最早由Tin Kam Ho于1995年提出，但它是在2001年由Leo Breiman首次发展的。
- en: So Random Forest is not really a recent algorithm per se. It has been in use
    for almost two decades already. But its popularity hasn't faded, thanks to its
    performance and simplicity.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，随机森林并不是一种最近的算法。它已经使用了近二十年。但由于其优异的性能和简洁性，它的受欢迎程度并没有消退。
- en: For the examples in this chapter, we will be using a dataset called "Activity
    Recognition system based on Multisensor data." It was originally shared by *F.
    Palumbo, C. Gallicchio, R. Pucci, and A. Micheli, Human activity recognition using
    multisensor data fusion based on Reservoir Computing, Journal of Ambient Intelligence
    and Smart Environments, 2016, 8 (2), pp. 87-107*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的示例中，我们将使用一个名为“基于多传感器数据的活动识别系统”的数据集。该数据集最初由*F. Palumbo, C. Gallicchio, R.
    Pucci, 和 A. Micheli, 《基于水库计算的多传感器数据融合的人类活动识别》，《环境智能与智能环境杂志》，2016年，第8卷第2期，第87-107页*分享。
- en: Note
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The complete dataset can be found here: [https://packt.live/3a5FI1s](https://packt.live/3a5FI1s%20)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的数据集可以在这里找到：[https://packt.live/3a5FI1s](https://packt.live/3a5FI1s%20)
- en: Let's see how we can train a Random Forest classifier on this dataset. First,
    we need to load the data from the GitHub repository using `pandas` and then we
    will print its first five rows using the `head()` method.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在这个数据集上训练一个随机森林分类器。首先，我们需要使用`pandas`从GitHub仓库加载数据，然后使用`head()`方法打印出数据集的前五行。
- en: Note
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: All the example code given outside of Exercises in this chapter relates to this
    Activity Recognition dataset. It is recommended that all code from these examples
    is entered and run in a single Google Colab Notebook, and kept separate from your
    Exercise Notebooks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中所有练习外的示例代码都与这个活动识别数据集相关。建议将所有这些示例中的代码输入并运行在一个单独的Google Colab笔记本中，并与练习笔记本分开。
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output will be as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 4.1: First five rows of the dataset'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.1：数据集的前五行'
- en: '](img/B15019_04_01.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_01.jpg)'
- en: 'Figure 4.1: First five rows of the dataset'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：数据集的前五行
- en: 'Each row represents an activity that was performed by a person and the name
    of the activity is stored in the `Activity` column. There are seven different
    activities in this variable: `bending1`, `bending2`, `cycling`, `lying`, `sitting`,
    `standing`, and `Walking`. The other six columns are different measurements taken
    from sensor data.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 每一行代表一个人执行的活动，活动的名称存储在`Activity`列中。这个变量中有七种不同的活动：`bending1`、`bending2`、`cycling`、`lying`、`sitting`、`standing`和`Walking`。其他六列是从传感器数据中获取的不同测量值。
- en: 'In this example, you will accurately predict the target variable (`''Activity''`)
    from the features (the six other columns) using Random Forest. For example, for
    the first row of the preceding example, the model will receive the following features
    as input and will predict the `''bending1''` class:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，您将通过随机森林模型准确地预测目标变量（`'Activity'`），其特征是六个其他列。例如，对于前面的示例中的第一行，模型将接收以下特征作为输入，并预测`'bending1'`类别：
- en: '![Figure 4.2: Features for the first row of the dataset'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.2：数据集第一行的特征'
- en: '](img/B15019_04_02.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_02.jpg)'
- en: 'Figure 4.2: Features for the first row of the dataset'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2：数据集第一行的特征
- en: 'But before that, we need to do a bit of data preparation. The `sklearn` package
    (we will use it to train Random Forest model) requires the target variable and
    the features to be separated. So, we need to extract the response variable using
    the `.pop()` method from `pandas`. The `.pop()` method extracts the specified
    column and removes it from the DataFrame:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 但在此之前，我们需要做一些数据准备工作。`sklearn`包（我们将用它来训练随机森林模型）要求目标变量和特征变量分开。因此，我们需要使用`.pop()`方法从`pandas`中提取响应变量。`.pop()`方法提取指定的列并将其从数据框中删除：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now the response variable is contained in the variable called `target` and all
    the features are in the DataFrame called `df`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，响应变量包含在名为`target`的变量中，所有特征存储在名为`df`的数据框中。
- en: Now we are going to split the dataset into training and testing sets. The model
    uses the training set to learn relevant parameters in predicting the response
    variable. The test set is used to check whether a model can accurately predict
    unseen data. We say the model is overfitting when it has learned the patterns
    relevant only to the training set and makes incorrect predictions about the testing
    set. In this case, the model performance will be much higher for the training
    set compared to the testing one. Ideally, we want to have a very similar level
    of performance for the training and testing sets. This topic will be covered in
    more depth in *Chapter 7*, *The Generalization of Machine Learning Models*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将数据集分割为训练集和测试集。模型使用训练集来学习预测响应变量的相关参数。测试集用于检查模型是否能够准确预测未见过的数据。当模型只学习了与训练集相关的模式，并且对测试集做出了不正确的预测时，我们称模型发生了过拟合。在这种情况下，模型在训练集上的表现会明显高于测试集。理想情况下，我们希望训练集和测试集的表现水平非常相似。这个话题将在*第七章*《机器学习模型的泛化》中深入讨论。
- en: 'The `sklearn` package provides a function called `train_test_split()` to randomly
    split the dataset into two different sets. We need to specify the following parameters
    for this function: the feature and target variables, the ratio of the testing
    set (`test_size`), and `random_state` in order to get reproducible results if
    we have to run the code again:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn`包提供了一个名为`train_test_split()`的函数，用于随机地将数据集分割成两个不同的子集。我们需要为此函数指定以下参数：特征变量和目标变量、测试集的比例（`test_size`）以及`random_state`，以便在需要重新运行代码时获得可重复的结果：'
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'There are four different outputs to the `train_test_split()` function: the
    features for the training set, the target variable for the training set, the features
    for the testing set, and its target variable.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_test_split()`函数有四个不同的输出：训练集的特征、训练集的目标变量、测试集的特征和测试集的目标变量。'
- en: 'Now that we have got our training and testing sets, we are ready for modeling.
    Let''s first import the `RandomForestClassifier` class from `sklearn.ensemble`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了训练集和测试集，可以开始建模了。让我们首先从`sklearn.ensemble`导入`RandomForestClassifier`类：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we can instantiate the Random Forest classifier with some hyperparameters.
    Remember from *Chapter 1, Introduction to Data Science in Python*, a hyperparameter
    is a type of parameter the model can''t learn but is set by data scientists to
    tune the model''s learning process. This topic will be covered more in depth in
    *Chapter 8, Hyperparameter Tuning*. For now, we will just specify the `random_state`
    value. We will walk you through some of the key hyperparameters in the following
    sections:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用一些超参数实例化随机森林分类器。请记住，在*第1章，Python中的数据科学入门*中提到，超参数是模型无法学习的参数，而是由数据科学家设置的，用来调整模型的学习过程。这个主题将在*第8章，超参数调优*中进行更深入的讲解。现在，我们只需指定`random_state`值。在接下来的章节中，我们将介绍一些关键的超参数：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The next step is to train (also called fit) the model with the training data.
    During this step, the model will try to learn the relationship between the response
    variable and the independent variables and save the parameters learned. We need
    to specify the features and target variables as parameters:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用训练数据对模型进行训练（也叫做拟合）。在此过程中，模型将尝试学习响应变量与自变量之间的关系，并保存学到的参数。我们需要将特征和目标变量作为参数指定：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output will be as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.3: Logs of the trained RandomForest'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.3：训练后的随机森林日志'
- en: '](img/B15019_04_03.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_03.jpg)'
- en: 'Figure 4.3: Logs of the trained RandomForest'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3：训练后的随机森林日志
- en: 'Now that the model has completed its training, we can use the parameters it
    learned to make predictions on the input data we will provide. In the following
    example, we are using the features from the training set:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经完成训练，我们可以使用它学到的参数对我们将提供的输入数据进行预测。在以下示例中，我们使用的是来自训练集的特征：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now we can print these predictions:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以打印这些预测结果：
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output will be as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.4: Predictions of the RandomForest algorithm on the training set'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.4：随机森林算法在训练集上的预测结果'
- en: '](img/B15019_04_04.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_04.jpg)'
- en: 'Figure 4.4: Predictions of the RandomForest algorithm on the training set'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4：随机森林算法在训练集上的预测结果
- en: This output shows us the model predicted, respectively, the values `lying`,
    `bending1`, and `cycling` for the first three observations and `cycling`, `bending1`,
    and `standing` for the last three observations. Python, by default, truncates
    the output for a long list of values. This is why it shows only six values here.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 该输出显示了模型分别预测了前3个观测值为`lying`、`bending1`和`cycling`，以及最后3个观测值为`cycling`、`bending1`和`standing`。默认情况下，Python会截断长列表的输出，这就是为什么这里只显示了六个值。
- en: These are basically the key steps required for training a Random Forest classifier.
    This was quite straightforward, right? Training a machine learning model is incredibly
    easy but getting meaningful and accurate results is where the challenges lie.
    In the next section, we will learn how to assess the performance of a trained
    model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基本上就是训练随机森林分类器所需的关键步骤。这相当简单，对吧？训练机器学习模型非常容易，但获取有意义且准确的结果才是挑战所在。在下一节中，我们将学习如何评估已训练模型的性能。
- en: Evaluating the Model's Performance
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型的性能
- en: Now that we know how to train a Random Forest classifier, it is time to check
    whether we did a good job or not. What we want is to get a model that makes extremely
    accurate predictions, so we need to assess its performance using some kind of
    metric.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经知道如何训练随机森林分类器，接下来就该检查我们是否做得好。我们想要得到一个可以做出极其准确预测的模型，因此我们需要使用某种度量来评估其性能。
- en: For a classification problem, multiple metrics can be used to assess the model's
    predictive power, such as F1 score, precision, recall, or ROC AUC. Each of them
    has its own specificity and depending on the projects and datasets, you may use
    one or another.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类问题，可以使用多种度量来评估模型的预测能力，例如F1分数、精确度、召回率或ROC AUC。每种度量有其特定的应用场景，具体使用哪一种取决于项目和数据集。
- en: 'In this chapter, we will use a metric called **accuracy score**. It calculates
    the ratio between the number of correct predictions and the total number of predictions
    made by the model:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用一个叫做**准确度评分**的度量标准。它计算正确预测的数量与模型所做预测总数之间的比例：
- en: '![Figure 4.5: Formula for accuracy score'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.5：准确度评分公式'
- en: '](img/B15019_04_05.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_05.jpg)'
- en: 'Figure 4.5: Formula for accuracy score'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5：准确度评分公式
- en: 'For instance, if your model made 950 correct predictions out of 1,000 cases,
    then the accuracy score would be 950/1000 = 0.95\. This would mean that your model
    was 95% accurate on that dataset. The `sklearn` package provides a function to
    calculate this score automatically and it is called `accuracy_score()`. We need
    to import it first:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你的模型在 1000 个案例中做出了 950 个正确预测，那么准确度评分就是 950/1000 = 0.95。 这意味着你的模型在该数据集上的准确度为
    95%。`sklearn` 包提供了一个函数来自动计算这个评分，称为 `accuracy_score()`。我们需要先导入它：
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, we just need to provide the list of predictions for some observations
    and the corresponding true value for the target variable. Using the previous example,
    we will use the `y_train` and `preds` variables, which respectively contain the
    response variable (also known as the target) for the training set and the corresponding
    predictions made by the Random Forest model. We will reuse the predictions from
    the previous section – `preds`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们只需要提供一些观测值的预测列表和对应的目标变量的真实值。使用之前的例子，我们将使用 `y_train` 和 `preds` 变量，分别包含训练集的响应变量（也称为目标）和
    Random Forest 模型所做的相应预测。我们将重用前一节的预测——`preds`：
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output will be as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.6: Accuracy score on the training set'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.6：训练集上的准确度评分'
- en: '](img/B15019_04_06.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_06.jpg)'
- en: 'Figure 4.6: Accuracy score on the training set'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6：训练集上的准确度评分
- en: We achieved an accuracy score of 0.988 on our training data. This means we accurately
    predicted more than `98%` of these cases. Unfortunately, this doesn't mean you
    will be able to achieve such a high score for new, unseen data. Your model may
    have just learned the patterns that are only relevant to this training set, and
    in that case, the model will overfit.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在训练数据上取得了 0.988 的准确度评分。这意味着我们准确地预测了超过`98%`的情况。不幸的是，这并不意味着你可以在新的、未见过的数据上达到如此高的评分。你的模型可能只是学习到了与该训练集相关的模式，在这种情况下，模型会发生过拟合。
- en: 'If we take the analogy of a student learning a subject for a semester, they
    could memorize by heart all the textbook exercises but when given a similar but
    unseen exercise, they wouldn''t be able to solve it. Ideally, the student should
    understand the underlying concepts of the subject and be able to apply that learning
    to any similar exercises. This is exactly the same for our model: we want it to
    learn the generic patterns that will help it to make accurate predictions even
    on unseen data.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以学生学习某个学科一个学期为类比，他们可能能背诵课本上的所有习题，但当给出一个类似但未见过的习题时，他们却无法解答。理想情况下，学生应该理解该学科的基本概念，并能够将这些知识应用到任何类似的习题中。这与我们的模型完全相同：我们希望它学习到有助于在未见数据上做出准确预测的通用模式。
- en: But how can we assess the performance of a model for unseen data? Is there a
    way to get that kind of assessment? The answer to these questions is yes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何评估模型在未见数据上的表现呢？有没有一种方法可以进行这种评估？这些问题的答案是肯定的。
- en: 'Remember, in the last section, we split the dataset into training and testing
    sets. We used the training set to fit the model and assess its predictive power
    on it. But it hasn''t seen the observations from the testing set at all, so we
    can use it to assess whether our model is capable of generalizing unseen data.
    Let''s calculate the accuracy score for the testing set:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在上一节中，我们将数据集分为训练集和测试集。我们使用训练集来拟合模型并评估其在该数据集上的预测能力。但它根本没有见过测试集中的观测数据，所以我们可以用它来评估我们的模型是否能够对未见数据进行泛化。让我们计算测试集的准确度评分：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output will be as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.7: Accuracy score on the testing set'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.7：测试集上的准确度评分'
- en: '](img/B15019_04_07.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_07.jpg)'
- en: 'Figure 4.7: Accuracy score on the testing set'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7：测试集上的准确度评分
- en: OK. Now the accuracy has dropped drastically to `0.77`. The difference between
    the training and testing sets is quite big. This tells us our model is actually
    overfitting and learned only the patterns relevant to the training set. In an
    ideal case, the performance of your model should be equal or very close to equal
    for those two sets.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。现在准确率已经大幅下降到`0.77`。训练集和测试集之间的差距相当大。这告诉我们我们的模型实际上是过拟合了，只学到了与训练集相关的模式。在理想情况下，模型在这两个集上的表现应该相等或非常接近。
- en: In the next sections, we will look at tuning some Random Forest hyperparameters
    in order to reduce overfitting.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将调整一些随机森林的超参数，以减少过拟合。
- en: 'Exercise 4.01: Building a Model for Classifying Animal Type and Assessing Its
    Performance'
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习4.01：构建分类动物类型的模型并评估其表现
- en: 'In this exercise, we will train a Random Forest classifier to predict the type
    of an animal based on its attributes and check its accuracy score:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将训练一个随机森林分类器，根据动物的属性预测其类型，并检查其准确度评分：
- en: Note
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 注：
- en: 'The dataset we will be using is the Zoo Data Set shared by Richard S. Forsyth:
    [https://packt.live/36DpRVK](https://packt.live/36DpRVK). The CSV version of this
    dataset can be found here: [https://packt.live/37RWGhF](https://packt.live/37RWGhF).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的数据集是由Richard S. Forsyth共享的动物园数据集：[https://packt.live/36DpRVK](https://packt.live/36DpRVK)。该数据集的CSV版本可以在这里找到：[https://packt.live/37RWGhF](https://packt.live/37RWGhF)。
- en: Open a new Colab notebook.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Colab笔记本。
- en: 'Import the `pandas` package:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`包：
- en: '[PRE11]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Create a variable called `file_url` that contains the URL of the dataset:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`file_url`的变量，包含数据集的URL：
- en: '[PRE12]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Load the dataset into a DataFrame using the `.read_csv()` method from pandas:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`的`.read_csv()`方法将数据集加载到数据框中：
- en: '[PRE13]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Print the first five rows of the DataFrame:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印数据框的前五行：
- en: '[PRE14]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You should get the following output:'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.8: First five rows of the DataFrame'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.8：数据框的前五行'
- en: '](img/B15019_04_08.jpg)'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_08.jpg)'
- en: 'Figure 4.8: First five rows of the DataFrame'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.8：数据框的前五行
- en: We will be using the `type` column as our target variable. We will need to remove
    the `animal` column from the DataFrame and only use the remaining columns as features.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将使用`type`列作为我们的目标变量。我们需要从数据框中移除`animal`列，只使用其余的列作为特征。
- en: 'Remove the `''animal''` column using the `.drop()` method from `pandas` and
    specify the `columns=''animal''` and `inplace=True` parameters (to directly update
    the original DataFrame):'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`的`.drop()`方法删除`'animal'`列，并指定`columns='animal'`和`inplace=True`参数（直接更新原始数据框）：
- en: '[PRE15]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Extract the `''type''` column using the `.pop()` method from `pandas`:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`的`.pop()`方法提取`'type'`列：
- en: '[PRE16]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Print the first five rows of the updated DataFrame:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印更新后的数据框的前五行：
- en: '[PRE17]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You should get the following output:'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.9: First five rows of the DataFrame'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.9：数据框的前五行'
- en: '](img/B15019_04_09.jpg)'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_09.jpg)'
- en: 'Figure 4.9: First five rows of the DataFrame'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.9：数据框的前五行
- en: 'Import the `train_test_split` function from `sklearn.model_selection`:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn.model_selection`导入`train_test_split`函数：
- en: '[PRE18]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Split the dataset into training and testing sets with the `df`, `y`, `test_size=0.4`,
    and `random_state=188` parameters:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`df`、`y`、`test_size=0.4`和`random_state=188`参数将数据集分成训练集和测试集：
- en: '[PRE19]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Import `RandomForestClassifier` from `sklearn.ensemble`:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn.ensemble`导入`RandomForestClassifier`：
- en: '[PRE20]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Instantiate the `RandomForestClassifier` object with `random_state` equal to
    `42`. Set the `n-estimators` value to an initial default value of `10`. We'll
    discuss later how changing this value affects the result.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`random_state`等于`42`实例化`RandomForestClassifier`对象。将`n_estimators`值设置为初始默认值`10`。我们稍后将讨论更改此值如何影响结果。
- en: '[PRE21]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Fit `RandomForestClassifier` with the training set:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练集拟合`RandomForestClassifier`：
- en: '[PRE22]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You should get the following output:'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.10: Logs of RandomForestClassifier'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.10：RandomForestClassifier的日志'
- en: '](img/B15019_04_10.jpg)'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_10.jpg)'
- en: 'Figure 4.10: Logs of RandomForestClassifier'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.10：RandomForestClassifier的日志
- en: 'Predict the outcome of the training set with the `.predict()`method, save the
    results in a variable called ''`train_preds`'', and print its value:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.predict()`方法预测训练集的结果，将结果保存在一个名为`train_preds`的变量中，并打印其值：
- en: '[PRE23]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You should get the following output:'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.11: Predictions on the training set'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.11：训练集上的预测结果'
- en: '](img/B15019_04_11.jpg)'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_11.jpg)'
- en: 'Figure 4.11: Predictions on the training set'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.11：训练集上的预测结果
- en: 'Import the `accuracy_score` function from `sklearn.metrics`:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn.metrics`导入`accuracy_score`函数：
- en: '[PRE24]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Calculate the accuracy score on the training set, save the result in a variable
    called `train_acc`, and print its value:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集上的准确率，将结果保存到名为`train_acc`的变量中，并打印其值：
- en: '[PRE25]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You should get the following output:'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该得到以下输出：
- en: '![Figure 4.12: Accuracy score on the training set'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.12: 训练集上的准确率'
- en: '](img/B15019_04_12.jpg)'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_12.jpg)'
- en: 'Figure 4.12: Accuracy score on the training set'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 4.12: 训练集上的准确率'
- en: Our model achieved an accuracy of `1` on the training set, which means it perfectly
    predicted the target variable on all of those observations. Let's check the performance
    on the testing set.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的模型在训练集上的准确率为`1`，这意味着它在所有观察值上都完美地预测了目标变量。现在让我们查看在测试集上的表现。
- en: 'Predict the outcome of the testing set with the `.predict()` method and save
    the results into a variable called `test_preds`:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.predict()`方法预测测试集的结果，并将结果保存到一个名为`test_preds`的变量中：
- en: '[PRE26]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Calculate the accuracy score on the testing set, save the result in a variable
    called `test_acc`, and print its value:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算测试集上的准确率，将结果保存到名为`test_acc`的变量中，并打印其值：
- en: '[PRE27]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You should get the following output:'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该得到以下输出：
- en: '![Figure 4.13: Accuracy score on the testing set'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.13: 测试集上的准确率'
- en: '](img/B15019_04_13.jpg)'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_13.jpg)'
- en: 'Figure 4.13: Accuracy score on the testing set'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4.13: 测试集上的准确率'
- en: In this exercise, we trained a RandomForest to predict the type of animals based
    on their key attributes. Our model achieved a perfect accuracy score of `1` on
    the training set but only `0.88` on the testing set. This means our model is overfitting
    and is not general enough. The ideal situation would be for the model to achieve
    a very similar, high-accuracy score on both the training and testing sets.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们训练了一个随机森林模型来预测动物的种类，基于它们的关键属性。我们的模型在训练集上的准确率达到了完美的`1`，但在测试集上的准确率只有`0.88`。这意味着我们的模型发生了过拟合，缺乏足够的泛化能力。理想的情况是，模型在训练集和测试集上的准确率应非常相似且较高。
- en: Note
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Q4jpQK](https://packt.live/2Q4jpQK).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看这一特定部分的源代码，请参考 [https://packt.live/2Q4jpQK](https://packt.live/2Q4jpQK)。
- en: You can also run this example online at [https://packt.live/3h6JieL](https://packt.live/3h6JieL).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，网址是 [https://packt.live/3h6JieL](https://packt.live/3h6JieL)。
- en: Number of Trees Estimator
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 树的数量估计器
- en: Now that we know how to fit a Random Forest classifier and assess its performance,
    it is time to dig into the details. In the coming sections, we will learn how
    to tune some of the most important hyperparameters for this algorithm. As mentioned
    in *Chapter 1, Introduction to Data Science in Python*, hyperparameters are parameters
    that are not learned automatically by machine learning algorithms. Their values
    have to be set by data scientists. These hyperparameters can have a huge impact
    on the performance of a model, its ability to generalize to unseen data, and the
    time taken to learn patterns from the data.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道如何拟合一个随机森林分类器并评估其性能，是时候深入探讨细节了。在接下来的章节中，我们将学习如何调整一些对该算法非常重要的超参数。如*第一章：Python中的数据科学简介*所述，超参数是机器学习算法无法自动学习的参数。它们的值必须由数据科学家设置。这些超参数对模型的性能、其对未见数据的泛化能力以及从数据中学习模式所需的时间有着巨大影响。
- en: The first hyperparameter you will look at in this section is called `n_estimators`.
    This hyperparameter is responsible for defining the number of trees that will
    be trained by the `RandomForest` algorithm.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将首先关注一个名为`n_estimators`的超参数。这个超参数负责定义`RandomForest`算法将训练的树的数量。
- en: Before looking at how to tune this hyperparameter, we need to understand what
    a tree is and why it is so important for the `RandomForest` algorithm.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看如何调整这个超参数之前，我们需要了解什么是树以及它为什么对`RandomForest`算法如此重要。
- en: A tree is a logical graph that maps a decision and its outcomes at each of its
    nodes. Simply speaking, it is a series of yes/no (or true/false) questions that
    lead to different outcomes.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一棵树是一个逻辑图，它在每个节点处映射一个决策及其结果。简单来说，它是一系列是/否（或真/假）的问题，指向不同的结果。
- en: 'A leaf is a special type of node where the model will make a prediction. There
    will be no split after a leaf. A single node split of a tree may look like this:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 叶子是一个特殊类型的节点，模型将在此处进行预测。叶子之后不会再进行分裂。一个树的单节点分裂可能如下所示：
- en: '![Figure 4.14: Example of a single tree node'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.14: 单一树节点的示例'
- en: '](img/B15019_04_14.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_14.jpg)'
- en: 'Figure 4.14: Example of a single tree node'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4.14: 单一树节点的示例'
- en: A tree node is composed of a question and two outcomes depending on whether
    the condition defined by the question is met or not. In the preceding example,
    the question is `is avg_rss12 > 41?` If the answer is yes, the outcome is the
    `bending_1` leaf and if not, it will be the `sitting` leaf.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 一棵树的节点由一个问题和两个结果组成，取决于问题定义的条件是否满足。在前面的例子中，问题是 `avg_rss12 > 41?` 如果答案是“是”，结果就是
    `bending_1` 叶子，如果答案是否定的，那么结果就是 `sitting` 叶子。
- en: 'A tree is just a series of nodes and leaves combined together:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一棵树就是由一系列节点和叶子组成：
- en: '![Figure 4.15: Example of a tree'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.15：树的示例](img/B15019_04_15.jpg)'
- en: '](img/B15019_04_15.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_15.jpg)'
- en: 'Figure 4.15: Example of a tree'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15：树的示例
- en: 'In the preceding example, the tree is composed of three nodes with different
    questions. Now, for an observation to be predicted as `sitting`, it will need
    to meet the conditions: `avg_rss13 <= 41`, `var_rss > 0.7`, and `avg_rss13 <=
    16.25`.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，这棵树由三个具有不同问题的节点组成。现在，为了预测一个观察值为 `sitting`，它需要满足以下条件：`avg_rss13 <= 41`，`var_rss
    > 0.7`，和 `avg_rss13 <= 16.25`。
- en: The `RandomForest` algorithm will build this kind of tree based on the training
    data it sees. We will not go through the mathematical details about how it defines
    the split for each node but, basically, it will go through every column of the
    dataset and see which split value will best help to separate the data into two
    groups of similar classes. Taking the preceding example, the first node with the
    `avg_rss13 > 41` condition will help to get the group of data on the left-hand
    side with mostly the `bending_1` class. The `RandomForest` algorithm usually builds
    several of this kind of tree and this is the reason why it is called a forest.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`RandomForest` 算法将根据它看到的训练数据构建这种类型的树。我们不会详细讨论它如何定义每个节点的分割，但基本上，它会遍历数据集的每一列，看看哪个分割值能最好地帮助将数据分为两个相似类别的组。以前面的例子为例，带有
    `avg_rss13 > 41` 条件的第一个节点有助于将左侧的数据分组，其中大多数属于 `bending_1` 类别。`RandomForest` 算法通常会构建多个这种类型的树，这也是它被称为森林的原因。'
- en: As you may have guessed now, the `n_estimators` hyperparameter is used to specify
    the number of trees the `RandomForest` algorithm will build. For example (as in
    the previous exercise), say we ask it to build 10 trees. For a given observation,
    it will ask each tree to make a prediction. Then, it will average those predictions
    and use the result as the final prediction for this input. For instance, if, out
    of 10 trees, 8 of them predict the outcome `sitting`, then the `RandomForest`
    algorithm will use this outcome as the final prediction.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如你现在可能已经猜到，`n_estimators` 超参数用于指定 `RandomForest` 算法将构建的树的数量。例如（如前面的练习中所示），假设我们要求它构建
    10 棵树。对于给定的观察，它将让每棵树进行预测。然后，它会对这些预测结果求平均，并将结果作为该输入的最终预测。例如，如果在 10 棵树中，有 8 棵预测结果为
    `sitting`，那么 `RandomForest` 算法将使用这个结果作为最终预测。
- en: Note
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you don''t pass in a specific `n_estimators` hyperparameter, it will use
    the default value. The default depends on the version of scikit-learn you''re
    using. In early versions, the default value is 10\. From version 0.22 onwards,
    the default is 100\. You can find out which version you are using by executing
    the following code:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有传入特定的 `n_estimators` 超参数，它将使用默认值。默认值取决于你使用的 scikit-learn 版本。在早期版本中，默认值为
    10。在 0.22 版本及以后，默认值为 100。你可以通过执行以下代码来查看你使用的版本：
- en: '`import sklearn`'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`import sklearn`'
- en: '`sklearn.__version__`'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.__version__`'
- en: 'For more information, see here: [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息，请参见：[https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
- en: 'In general, the higher the number of trees is, the better the performance you
    will get. Let''s see what happens with `n_estimators = 2` on the Activity Recognition
    dataset:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 通常来说，树的数量越多，性能越好。让我们看看 `n_estimators = 2` 时在活动识别数据集上的表现：
- en: '[PRE28]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output will be as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 4.16: Accuracy of RandomForest with n_estimators = 2'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.16：`n_estimators = 2` 时 RandomForest 的准确率](img/B15019_04_16.jpg)'
- en: '](img/B15019_04_16.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_16.jpg)'
- en: 'Figure 4.16: Accuracy of RandomForest with n_estimators = 2'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.16：`n_estimators = 2` 时 RandomForest 的准确率
- en: 'As expected, the accuracy is significantly lower than the previous example
    with `n_estimators = 10`. Let''s now try with `50` trees:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，准确度明显低于前面 `n_estimators = 10` 的例子。现在让我们试试 `50` 棵树：
- en: '[PRE29]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output will be as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 4.17: Accuracy of RandomForest with n_estimators = 50'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.17：n_estimators=50的随机森林准确度'
- en: '](img/B15019_04_17.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_17.jpg)'
- en: 'Figure 4.17: Accuracy of RandomForest with n_estimators = 50'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.17：n_estimators=50的随机森林准确度
- en: With `n_estimators = 50`, we respectively gained `1%` and `2%` on the accuracy
    scored for the training and testing sets, which is great. But the main drawback
    of increasing the number of trees is that it requires more computational power.
    So, it will take more time to train a model. In a real project, you will need
    to find the right balance between performance and training duration.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`n_estimators=50`时，我们在训练集和测试集的准确度上分别提高了`1%`和`2%`，这非常好。但增加树木数量的主要缺点是需要更多的计算能力。因此，训练模型的时间会更长。在实际项目中，你需要找到性能与训练时长之间的最佳平衡。
- en: 'Exercise 4.02: Tuning n_estimators to Reduce Overfitting'
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.02：调整n_estimators以减少过拟合
- en: 'In this exercise, we will train a Random Forest classifier to predict the type
    of an animal based on its attributes and will try two different values for the
    `n_estimators` hyperparameter:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将训练一个随机森林分类器，基于动物的属性预测其类型，并尝试`n_estimators`超参数的两个不同值：
- en: We will be using the same zoo dataset as in the previous exercise.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与之前练习相同的动物园数据集。
- en: Open a new Colab notebook.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Colab笔记本。
- en: 'Import the `pandas` package, `train_test_split`, `RandomForestClassifier`,
    and `accuracy_score` from `sklearn`:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`包，`train_test_split`，`RandomForestClassifier`，和`accuracy_score`从`sklearn`中：
- en: '[PRE30]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Create a variable called `file_url` that contains the URL to the dataset:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`file_url`的变量，包含数据集的URL：
- en: '[PRE31]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Load the dataset into a DataFrame using the `.read_csv()` method from `pandas`:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.read_csv()`方法从`pandas`加载数据集到DataFrame中：
- en: '[PRE32]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Remove the `animal` column using `.drop()` and then extract the `type` target
    variable into a new variable called `y` using `.pop()`:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.drop()`删除`animal`列，然后使用`.pop()`将`type`目标变量提取到一个新变量`y`中：
- en: '[PRE33]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Split the data into training and testing sets with `train_test_split()` and
    the `test_size=0.4` and `random_state=188` parameters:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split()`将数据分为训练集和测试集，并设置`test_size=0.4`和`random_state=188`参数：
- en: '[PRE34]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Instantiate `RandomForestClassifier` with `random_state=42` and `n_estimators=1`,
    and then fit the model with the training set:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`random_state=42`和`n_estimators=1`实例化`RandomForestClassifier`，然后用训练集拟合模型：
- en: '[PRE35]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'You should get the following output:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会得到以下输出：
- en: '![Figure 4.18: Logs of RandomForestClassifier'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.18：随机森林分类器的日志'
- en: '](img/B15019_04_18.jpg)'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_18.jpg)'
- en: 'Figure 4.18: Logs of RandomForestClassifier'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.18：随机森林分类器的日志
- en: 'Make predictions on the training and testing sets with `.predict()` and save
    the results into two new variables called `train_preds` and `test_preds`:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量`train_preds`和`test_preds`中：
- en: '[PRE36]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Calculate the accuracy score for the training and testing sets and save the
    results in two new variables called `train_acc` and `test_acc`:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集和测试集的准确度分数，并将结果保存到两个新变量`train_acc`和`test_acc`中：
- en: '[PRE37]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Print the accuracy scores: `train_acc` and `test_acc`:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印准确度分数：`train_acc`和`test_acc`：
- en: '[PRE38]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'You should get the following output:'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会得到以下输出：
- en: '![Figure 4.19: Accuracy scores for the training and testing sets'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.19：训练集和测试集的准确度分数'
- en: '](img/B15019_04_19.jpg)'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_19.jpg)'
- en: 'Figure 4.19: Accuracy scores for the training and testing sets'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.19：训练集和测试集的准确度分数
- en: The accuracy score decreased for both the training and testing sets. But now
    the difference is smaller compared to the results from *Exercise 4.01*, *Building
    a Model for Classifying Animal Type and Assessing Its Performance*.
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练集和测试集的准确度分数都有所下降。但现在，与*练习4.01*《构建动物分类模型并评估其性能》中的结果相比，二者之间的差异较小。
- en: 'Instantiate another `RandomForestClassifier` with `random_state=42` and `n_estimators=30`,
    and then fit the model with the training set:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`random_state=42`和`n_estimators=30`实例化另一个`RandomForestClassifier`，然后用训练集拟合模型：
- en: '[PRE39]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'You should get the following output:'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会得到以下输出：
- en: '![Figure 4.20: Logs of RandomForest with n_estimators = 30'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.20：n_estimators=30的随机森林日志'
- en: '](img/B15019_04_20.jpg)'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_20.jpg)'
- en: 'Figure 4.20: Logs of RandomForest with n_estimators = 30'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.20：n_estimators=30的随机森林日志
- en: 'Make predictions on the training and testing sets with `.predict()` and save
    the results into two new variables called `train_preds2` and `test_preds2`:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量`train_preds2`和`test_preds2`中：
- en: '[PRE40]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Calculate the accuracy score for the training and testing sets and save the
    results in two new variables called `train_acc2` and `test_acc2`:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集和测试集的准确率，并将结果保存到名为`train_acc2`和`test_acc2`的两个新变量中：
- en: '[PRE41]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Print the accuracy scores: `train_acc` and `test_acc`:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印准确率：`train_acc`和`test_acc`：
- en: '[PRE42]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'You should get the following output:'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会得到以下输出：
- en: '![Figure 4.21: Accuracy scores for the training and testing sets'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.21：训练集和测试集的准确率]'
- en: '](img/B15019_04_21.jpg)'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_21.jpg)'
- en: 'Figure 4.21: Accuracy scores for the training and testing sets'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.21：训练集和测试集的准确率
- en: This output shows us the model is overfitting less compared to the results from
    the previous step and still has a very high-performance level for the training
    set.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出显示了我们的模型比前一步的结果有了更少的过拟合，并且在训练集上的性能仍然非常高。
- en: 'In the previous exercise, we achieved an accuracy score of `1` for the training
    set and `0.88` for the testing one. In this exercise, we trained two additional
    Random Forest models with `n_estimators = 1` and `30`. The model with the lowest
    number of trees has the lowest accuracy: `0.92` (training) and `0.8` (testing).
    On the other hand, increasing the number of trees to `30`, we achieved a higher
    accuracy: `1` and `0.9`. Our model is overfitting slightly less now. It is not
    perfect, but it is a good start.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个练习中，我们在训练集上获得了准确率`1`，在测试集上获得了`0.88`。在这个练习中，我们训练了两个额外的随机森林模型，分别设置了`n_estimators
    = 1`和`30`。树木数量最少的模型准确率最低：`0.92`（训练）和`0.8`（测试）。另一方面，将树木数量增加到`30`时，我们达到了更高的准确率：`1`和`0.9`。我们的模型现在过拟合稍微少了些。它并不完美，但这是一个不错的开始。
- en: Note
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/322x8gz](https://packt.live/322x8gz).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该部分的源代码，请参考[https://packt.live/322x8gz](https://packt.live/322x8gz)。
- en: You can also run this example online at [https://packt.live/313gUV8](https://packt.live/313gUV8).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，访问[https://packt.live/313gUV8](https://packt.live/313gUV8)。
- en: Maximum Depth
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大深度
- en: In the previous section, we learned how Random Forest builds multiple trees
    to make predictions. Increasing the number of trees does improve model performance
    but it usually doesn't help much to decrease the risk of overfitting. Our model
    in the previous example is still performing much better on the training set (data
    it has already seen) than on the testing set (unseen data).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们学习了随机森林如何构建多棵树来进行预测。增加树木数量确实能提高模型的性能，但通常对于减少过拟合的风险帮助不大。我们在上一个示例中的模型在训练集（已经看到的数据）上的表现仍然远远优于在测试集（未见过的数据）上的表现。
- en: So, we are not confident enough yet to say the model will perform well in production.
    There are different hyperparameters that can help to lower the risk of overfitting
    for Random Forest and one of them is called `max_depth`.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们还不能完全确定模型在生产环境中的表现如何。有多种超参数可以帮助减少随机森林的过拟合风险，其中之一就是`max_depth`。
- en: This hyperparameter defines the depth of the trees built by Random Forest. Basically,
    it tells Random Forest model, how many nodes (questions) it can create before
    making predictions. But how will that help to reduce overfitting, you may ask.
    Well, let's say you built a single tree and set the `max_depth` hyperparameter
    to `50`. This would mean that there would be some cases where you could ask 49
    different questions (the value `c` includes the final leaf node) before making
    a prediction. So, the logic would be `IF X1 > value1 AND X2 > value2 AND X1 <=
    value3 AND … AND X3 > value49 THEN predict class A`.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这个超参数定义了随机森林构建的树的深度。基本上，它告诉随机森林模型，在做出预测之前，最多可以创建多少个节点（问题）。但你可能会问，这样如何帮助减少过拟合呢？嗯，假设你构建了一棵树，并将`max_depth`超参数设置为`50`。这意味着在做出预测之前，你可以提出49个不同的问题（值`c`包括最终的叶子节点）。所以，逻辑是：`IF
    X1 > value1 AND X2 > value2 AND X1 <= value3 AND … AND X3 > value49 THEN predict
    class A`。
- en: As you can imagine, this is a very specific rule. In the end, it may apply to
    only a few observations in the training set, with this case appearing very infrequently.
    Therefore, your model would be overfitting. By default, the value of this `max_depth`
    parameter is `None`, which means there is no limit set for the depth of the trees.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，这是一条非常特定的规则。最终，它可能仅适用于训练集中的少数几个观测值，这种情况发生得非常少。因此，你的模型会出现过拟合。默认情况下，`max_depth`参数的值是`None`，这意味着树的深度没有设置限制。
- en: 'What you really want is to find some rules that are generic enough to be applied
    to bigger groups of observations. This is why it is recommended to not create
    deep trees with Random Forest. Let''s try several values for this hyperparameter
    on the Activity Recognition dataset: `3`, `10`, and `50`:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 你真正想要的是找到一些足够通用的规则，能够应用于更大范围的观察数据。这就是为什么建议不要在随机森林中创建过深的树。我们在活动识别数据集上尝试几个不同的`max_depth`超参数值：`3`、`10`和`50`：
- en: '[PRE43]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'You should get the following output:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.22: Accuracy scores for the training and testing sets and a max_depth
    of 3'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.22：训练集和测试集的准确率，`max_depth = 3`'
- en: '](img/B15019_04_22.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_22.jpg)'
- en: 'Figure 4.22: Accuracy scores for the training and testing sets and a max_depth
    of 3'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.22：训练集和测试集的准确率，`max_depth = 3`
- en: 'For a `max_depth` of `3`, we got extremely similar results for the training
    and testing sets but the overall performance decreased drastically to `0.61`.
    Our model is not overfitting anymore, but it is now underfitting; that is, it
    is not predicting the target variable very well (only in `61%` of cases). Let''s
    increase `max_depth` to `10`:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`max_depth = 3`，训练集和测试集的结果非常相似，但整体性能急剧下降至`0.61`。我们的模型不再过拟合，但现在出现了欠拟合；也就是说，它没有很好地预测目标变量（仅在`61%`的情况下预测正确）。让我们将`max_depth`增加到`10`：
- en: '[PRE44]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![Figure 4.23: Accuracy scores for the training and testing sets and a max_depth
    of 10'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.23：训练集和测试集的准确率，`max_depth = 10`'
- en: '](img/B15019_04_23.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_23.jpg)'
- en: 'Figure 4.23: Accuracy scores for the training and testing sets and a max_depth
    of 10'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.23：训练集和测试集的准确率，`max_depth = 10`
- en: 'The accuracy of the training set increased and is relatively close to the testing
    set. We are starting to get some good results, but the model is still slightly
    overfitting. Now we will see the results for `max_depth = 50`:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集的准确率有所提升，并且与测试集相对接近。我们开始获得一些良好的结果，但模型仍然略微过拟合。接下来，我们将看到`max_depth = 50`的结果：
- en: '[PRE45]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output will be as follows:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 4.24: Accuracy scores for the training and testing sets and a max_depth
    of 50'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.24：训练集和测试集的准确率，`max_depth = 50`'
- en: '](img/B15019_04_24.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_24.jpg)'
- en: 'Figure 4.24: Accuracy scores for the training and testing sets and a max_depth
    of 50'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.24：训练集和测试集的准确率，`max_depth = 50`
- en: The accuracy jumped to `0.99` for the training set but it didn't improve much
    for the testing set. So, the model is overfitting with `max_depth = 50`. It seems
    the sweet spot to get good predictions and not much overfitting is around `10`
    for the `max_depth` hyperparameter in this dataset.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集的准确率跃升至`0.99`，但测试集的表现提升不大。因此，模型在`max_depth = 50`时出现了过拟合。看起来在这个数据集上，要获得较好的预测效果并避免过拟合的最佳位置是在`max_depth`为`10`时。
- en: 'Exercise 4.03: Tuning max_depth to Reduce Overfitting'
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.03：调整`max_depth`以减少过拟合
- en: 'In this exercise, we will keep tuning our RandomForest classifier that predicts
    animal type by trying two different values for the `max_depth` hyperparameter:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将继续调整我们的随机森林分类器，该分类器通过尝试两种不同的`max_depth`超参数值来预测动物类型：
- en: We will be using the same zoo dataset as in the previous exercise.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与上一练习中相同的动物园数据集。
- en: Open a new Colab notebook.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Colab笔记本。
- en: 'Import the `pandas` package, `train_test_split`, `RandomForestClassifier`,
    and `accuracy_score` from `sklearn`:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`包、`train_test_split`、`RandomForestClassifier`和`accuracy_score`，这些都来自`sklearn`：
- en: '[PRE46]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Create a variable called `file_url` that contains the URL to the dataset:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`file_url`的变量，包含数据集的URL：
- en: '[PRE47]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Load the dataset into a DataFrame using the `.read_csv()` method from `pandas`:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`的`.read_csv()`方法将数据集加载到一个DataFrame中：
- en: '[PRE48]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Remove the `animal` column using `.drop()` and then extract the `type` target
    variable into a new variable called `y` using `.pop()`:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.drop()`删除`animal`列，然后使用`.pop()`将`type`目标变量提取到一个名为`y`的新变量中：
- en: '[PRE49]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Split the data into training and testing sets with `train_test_split()` and
    the parameters `test_size=0.4` and `random_state=188`:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split()`将数据分为训练集和测试集，参数为`test_size=0.4`和`random_state=188`：
- en: '[PRE50]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Instantiate `RandomForestClassifier` with `random_state=42`, `n_estimators=30`,
    and `max_depth=5`, and then fit the model with the training set:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`random_state=42`、`n_estimators=30`和`max_depth=5`实例化`RandomForestClassifier`，然后使用训练集拟合模型：
- en: '[PRE51]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'You should get the following output:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.25: Logs of RandomForest'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.25：随机森林日志'
- en: '](img/B15019_04_25.jpg)'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_25.jpg)'
- en: 'Figure 4.25: Logs of RandomForest'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.25：随机森林日志
- en: 'Make predictions on the training and testing sets with `.predict()` and save
    the results into two new variables called `train_preds` and `test_preds`:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.predict()`对训练集和测试集进行预测，并将结果保存在两个新变量中，分别命名为`train_preds`和`test_preds`：
- en: '[PRE52]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Calculate the accuracy score for the training and testing sets and save the
    results in two new variables called `train_acc` and `test_acc`:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集和测试集的准确度分数，并将结果保存在两个新变量中，分别命名为`train_acc`和`test_acc`：
- en: '[PRE53]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Print the accuracy scores: `train_acc` and `test_acc`:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印准确度分数：`train_acc`和`test_acc`：
- en: '[PRE54]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'You should get the following output:'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.26: Accuracy scores for the training and testing sets'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.26：训练集和测试集的准确度分数'
- en: '](img/B15019_04_26.jpg)'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_26.jpg)'
- en: 'Figure 4.26: Accuracy scores for the training and testing sets'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.26：训练集和测试集的准确度分数
- en: We got the exact same accuracy scores as for the best result we obtained in
    the previous exercise. This value for the `max_depth` hyperparameter hasn't impacted
    the model's performance.
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们得到的准确度分数与在之前的练习中获得的最佳结果完全相同。对于`max_depth`超参数的这个值并没有影响模型的表现。
- en: 'Instantiate another `RandomForestClassifier` with `random_state=42`, `n_estimators=30`,
    and `max_depth=2`, and then fit the model with the training set:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化另一个`RandomForestClassifier`，并设置`random_state=42`、`n_estimators=30`和`max_depth=2`，然后使用训练集拟合模型：
- en: '[PRE55]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'You should get the following output:'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.27: Logs of RandomForestClassifier with max_depth = 2'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.27：max_depth = 2时，RandomForestClassifier的日志'
- en: '](img/B15019_04_27.jpg)'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_27.jpg)'
- en: 'Figure 4.27: Logs of RandomForestClassifier with max_depth = 2'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.27：max_depth = 2时，RandomForestClassifier的日志
- en: 'Make predictions on the training and testing sets with `.predict()` and save
    the results into two new variables called `train_preds2` and `test_preds2`:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.predict()`对训练集和测试集进行预测，并将结果保存在两个新变量中，分别命名为`train_preds2`和`test_preds2`：
- en: '[PRE56]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Calculate the accuracy scores for the training and testing sets and save the
    results in two new variables called `train_acc2` and `test_acc2`:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集和测试集的准确度分数，并将结果保存在两个新变量中，分别命名为`train_acc2`和`test_acc2`：
- en: '[PRE57]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Print the accuracy scores: `train_acc` and `test_acc`:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印准确度分数：`train_acc`和`test_acc`：
- en: '[PRE58]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'You should get the following output:'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.28: Accuracy scores for training and testing sets'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.28：训练集和测试集的准确度分数'
- en: '](img/B15019_04_28.jpg)'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_28.jpg)'
- en: 'Figure 4.28: Accuracy scores for training and testing sets'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.28：训练集和测试集的准确度分数
- en: You learned how to tune the `max_depth` hyperparameter in this exercise. Reducing
    its value to `2` decreased the accuracy score for the training set to 0.9 but
    it also helped to reduce the overfitting for the training and testing set (0.83),
    so we will keep this value as the optimal one and proceed to the next step.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 你在这个练习中学会了如何调整`max_depth`超参数。将其值减少到`2`使得训练集的准确度分数降至0.9，但也有助于减少训练集和测试集的过拟合（0.83），因此我们将保持这个值作为最优值，并继续下一步。
- en: Note
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31YXkIY](https://packt.live/31YXkIY).
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问这一特定部分的源代码，请参考[https://packt.live/31YXkIY](https://packt.live/31YXkIY)。
- en: You can also run this example online at [https://packt.live/2CCkxYX](https://packt.live/2CCkxYX).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，链接为[https://packt.live/2CCkxYX](https://packt.live/2CCkxYX)。
- en: Minimum Sample in Leaf
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 叶节点的最小样本数
- en: 'Previously, we learned how to reduce or increase the depth of trees in Random
    Forest and saw how it can affect its performance and tendency to overfit or not.
    Now we will go through another important hyperparameter: `min_samples_leaf`.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们学习了如何减少或增加随机森林中的树的深度，并观察了它如何影响性能以及是否会发生过拟合。现在，我们将介绍另一个重要的超参数：`min_samples_leaf`。
- en: 'This hyperparameter, as its name implies, is related to the leaf nodes of the
    trees. We saw earlier that the `RandomForest` algorithm builds nodes that will
    clearly separate observations into two different groups. If we look at the tree
    example in *Figure 4.15*, the top node is splitting data into two groups: the
    left-hand group contains mainly observations for the `bending_1` class and the
    right-hand group can be from any class. This sounds like a reasonable split but
    are we sure it is not increasing the risk of overfitting? For instance, what if
    this split leads to only one observation falling on the left-hand side? This rule
    would be very specific (applying to only one single case) and we can''t say it
    is generic enough for unseen data. It may be an edge case in the training set
    that will never happen again.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 这个超参数顾名思义，与树的叶节点有关。我们之前看到，`RandomForest`算法会构建节点，清晰地将观测值分成两个不同的组。如果我们看看*图 4.15*中的树示例，顶节点将数据分成两组：左侧组主要包含`bending_1`类别的观测值，而右侧组则可能来自任何类别。这看起来像是一个合理的划分，但我们能确定它不会增加过拟合的风险吗？例如，如果这个划分导致只有一个观测值落在左侧呢？这个规则会非常具体（仅适用于一个单一的情况），我们不能说它对未见数据具有足够的泛化性。它可能是训练集中的一个极端情况，未来永远不会再发生。
- en: 'It would be great if we could let the model know to not create such specific
    rules that happen quite infrequently. Luckily, `RandomForest` has such a hyperparameter
    and, you guessed it, it is `min_samples_leaf`. This hyperparameter will specify
    the minimum number of observations (or samples) that will have to fall under a
    leaf node to be considered in the tree. For instance, if we set `min_samples_leaf`
    to `3`, then `RandomForest` will only consider a split that leads to at least
    three observations on both the left and right leaf nodes. If this condition is
    not met for a split, the model will not consider it and will exclude it from the
    tree. The default value in `sklearn` for this hyperparameter is `1`. Let''s try
    to find the optimal value for `min_samples_leaf` for the Activity Recognition
    dataset:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能让模型知道不要创建那些发生频率很低的特定规则就好了。幸运的是，`RandomForest`有一个这样的超参数，没错，它就是`min_samples_leaf`。这个超参数指定了在树中要考虑的叶节点下必须有至少多少个观测值（或样本）。例如，如果我们将`min_samples_leaf`设置为`3`，那么`RandomForest`只会考虑那些左叶节点和右叶节点上至少有三个观测值的划分。如果这个条件没有满足，模型就不会考虑这个划分，并将其从树中排除。`sklearn`中这个超参数的默认值是`1`。让我们尝试为活动识别数据集找到`min_samples_leaf`的最佳值：
- en: '[PRE59]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The output will be as follows:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 4.29: Accuracy scores for the training and testing sets for min_samples_leaf=3'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.29：`min_samples_leaf=3` 时训练集和测试集的准确度得分'
- en: '](img/B15019_04_29.jpg)'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_29.jpg)'
- en: 'Figure 4.29: Accuracy scores for the training and testing sets for min_samples_leaf=3'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.29：`min_samples_leaf=3` 时训练集和测试集的准确度得分
- en: 'With `min_samples_leaf=3`, the accuracy for both the training and testing sets
    didn''t change much compared to the best model we found in the previous section.
    Let''s try increasing it to `10`:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 当`min_samples_leaf=3`时，训练集和测试集的准确度与我们在前一部分找到的最佳模型相比变化不大。我们来试试将其增大到`10`：
- en: '[PRE60]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The output will be as follows:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 4.30: Accuracy scores for the training and testing sets for min_samples_leaf=10'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.30：`min_samples_leaf=10` 时训练集和测试集的准确度得分'
- en: '](img/B15019_04_30.jpg)'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_30.jpg)'
- en: 'Figure 4.30: Accuracy scores for the training and testing sets for min_samples_leaf=10'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.30：`min_samples_leaf=10` 时训练集和测试集的准确度得分
- en: 'Now the accuracy of the training set dropped a bit but increased for the testing
    set and their difference is smaller now. So, our model is overfitting less. Let''s
    try another value for this hyperparameter – `25`:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练集的准确度稍微下降了，但测试集的准确度增加了，而且它们之间的差距变小了。因此，我们的模型过拟合的情况减少了。让我们再试试这个超参数的另一个值——`25`：
- en: '[PRE61]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The output will be as follows:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 4.31: Accuracy scores for the training and testing sets for min_samples_leaf=25'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.31：`min_samples_leaf=25` 时训练集和测试集的准确度得分'
- en: '](img/B15019_04_31.jpg)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_31.jpg)'
- en: 'Figure 4.31: Accuracy scores for the training and testing sets for min_samples_leaf=25'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.31：`min_samples_leaf=25` 时训练集和测试集的准确度得分
- en: Both accuracies for the training and testing sets decreased but they are quite
    close to each other now. So, we will keep this value (`25`) as the optimal one
    for this dataset as the performance is still OK and we are not overfitting too
    much.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集和测试集的准确度都下降了，但它们现在非常接近。所以，我们将`25`作为这个数据集的最佳值，因为性能仍然可以接受，而且我们没有过度拟合。
- en: 'When choosing the optimal value for this hyperparameter, you need to be careful:
    a value that''s too low will increase the chance of the model overfitting, but
    on the other hand, setting a very high value will lead to underfitting (the model
    will not accurately predict the right outcome).'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择该超参数的最佳值时，你需要小心：一个过低的值会增加模型过拟合的可能性，但另一方面，设置一个非常高的值会导致欠拟合（模型无法准确预测正确的结果）。
- en: For instance, if you have a dataset of `1000` rows, if you set `min_samples_leaf`
    to `400`, then the model will not be able to find good splits to predict `5` different
    classes. In this case, the model can only create one single split and the model
    will only be able to predict two different classes instead of `5`. It is good
    practice to start with low values first and then progressively increase them until
    you reach satisfactory performance.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你有一个`1000`行的数据集，如果将`min_samples_leaf`设置为`400`，那么模型将无法找到适合预测`5`个不同类别的良好切分。在这种情况下，模型只能创建一个单一的切分，并且只能预测两个类别，而不是`5`个类别。最佳实践是先从较低的值开始，然后逐步增加，直到达到令人满意的性能。
- en: 'Exercise 4.04: Tuning min_samples_leaf'
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.04：调整min_samples_leaf
- en: 'In this exercise, we will keep tuning our Random Forest classifier that predicts
    animal type by trying two different values for the `min_samples_leaf` hyperparameter:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将继续调整我们的随机森林分类器，通过尝试`min_samples_leaf`超参数的两个不同值来预测动物类型：
- en: We will be using the same zoo dataset as in the previous exercise.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与前一个练习中相同的动物园数据集。
- en: Open a new Colab notebook.
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Colab笔记本。
- en: 'Import the `pandas` package, `train_test_split`, `RandomForestClassifier`,
    and `accuracy_score` from `sklearn`:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`包、`train_test_split`、`RandomForestClassifier`和`accuracy_score`从`sklearn`：
- en: '[PRE62]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Create a variable called `file_url` that contains the URL to the dataset:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`file_url`的变量，包含数据集的URL：
- en: '[PRE63]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Load the dataset into a DataFrame using the `.read_csv()` method from `pandas`:'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`的`.read_csv()`方法将数据集加载到DataFrame中：
- en: '[PRE64]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Remove the `animal` column using `.drop()` and then extract the `type` target
    variable into a new variable called `y` using `.pop()`:'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.drop()`移除`animal`列，然后使用`.pop()`将`type`目标变量提取到一个新变量`y`中：
- en: '[PRE65]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Split the data into training and testing sets with `train_test_split()` and
    the parameters `test_size=0.4` and `random_state=188`:'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split()`将数据分割为训练集和测试集，参数设置为`test_size=0.4`和`random_state=188`：
- en: '[PRE66]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Instantiate `RandomForestClassifier` with `random_state=42`, `n_estimators=30`,
    `max_depth=2`, and `min_samples_leaf=3`, and then fit the model with the training
    set:'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`random_state=42`、`n_estimators=30`、`max_depth=2`和`min_samples_leaf=3`实例化`RandomForestClassifier`，然后用训练集拟合模型：
- en: '[PRE67]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'You should get the following output:'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.32: Logs of RandomForest'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.32：随机森林日志](img/B15019_04_32.jpg)'
- en: '](img/B15019_04_32.jpg)'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_32.jpg)'
- en: 'Figure 4.32: Logs of RandomForest'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.32：随机森林日志
- en: 'Make predictions on the training and testing sets with `.predict()` and save
    the results into two new variables called `train_preds` and `test_preds`:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量`train_preds`和`test_preds`中：
- en: '[PRE68]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Calculate the accuracy score for the training and testing sets and save the
    results in two new variables called `train_acc` and `test_acc`:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集和测试集的准确度评分，并将结果保存在两个新变量`train_acc`和`test_acc`中：
- en: '[PRE69]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Print the accuracy score – `train_acc` and `test_acc`:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印准确度评分——`train_acc`和`test_acc`：
- en: '[PRE70]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'You should get the following output:'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.33: Accuracy scores for the training and testing sets'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.33：训练集和测试集的准确度评分](img/B15019_04_33.jpg)'
- en: '](img/B15019_04_33.jpg)'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_33.jpg)'
- en: 'Figure 4.33: Accuracy scores for the training and testing sets'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.33：训练集和测试集的准确度评分
- en: The accuracy score decreased for both the training and testing sets compared
    to the best result we got in the previous exercise. Now the difference between
    the training and testing sets' accuracy scores is much smaller so our model is
    overfitting less.
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与我们在前一个练习中得到的最佳结果相比，训练集和测试集的准确度评分都有所下降。现在，训练集和测试集的准确度评分差距要小得多，说明我们的模型过拟合的情况较少。
- en: 'Instantiate another `RandomForestClassifier` with `random_state=42`, `n_estimators=30`,
    `max_depth=2`, and `min_samples_leaf=7`, and then fit the model with the training
    set:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`random_state=42`、`n_estimators=30`、`max_depth=2`和`min_samples_leaf=7`实例化另一个`RandomForestClassifier`，然后用训练集拟合模型：
- en: '[PRE71]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'You should get the following output:'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.34: Logs of RandomForest with max_depth=2'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.34：max_depth=2的随机森林日志](img/B15019_04_34.jpg)'
- en: '](img/B15019_04_34.jpg)'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_34.jpg)'
- en: 'Figure 4.34: Logs of RandomForest with max_depth=2'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.34：max_depth=2的随机森林日志
- en: 'Make predictions on the training and testing sets with `.predict()` and save
    the results into two new variables called `train_preds2` and `test_preds2`:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量中，分别命名为`train_preds2`和`test_preds2`：
- en: '[PRE72]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Calculate the accuracy score for the training and testing sets and save the
    results in two new variables called `train_acc2` and `test_acc2`:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集和测试集的准确率得分，并将结果保存在两个新变量中，分别命名为`train_acc2`和`test_acc2`：
- en: '[PRE73]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Print the accuracy scores: `train_acc` and `test_acc`:'
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印准确率得分：`train_acc`和`test_acc`：
- en: '[PRE74]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'You should get the following output:'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.35: Accuracy scores for the training and testing sets'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.35：训练集和测试集的准确率得分'
- en: '](img/B15019_04_35.jpg)'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_35.jpg)'
- en: 'Figure 4.35: Accuracy scores for the training and testing sets'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.35：训练集和测试集的准确率得分
- en: Increasing the value of `min_samples_leaf` to `7` has led the model to not overfit
    anymore. We got extremely similar accuracy scores for the training and testing
    sets, at around `0.8`. We will choose this value as the optimal one for `min_samples_leaf`
    for this dataset.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 将`min_samples_leaf`的值增加到`7`后，模型不再出现过拟合现象。我们得到了非常相似的训练集和测试集准确率得分，大约为`0.8`。我们将选择这个值作为该数据集的`min_samples_leaf`的最优值。
- en: Note
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3kUYVZa](https://packt.live/3kUYVZa).
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问这一部分的源代码，请参考[https://packt.live/3kUYVZa](https://packt.live/3kUYVZa)。
- en: You can also run this example online at [https://packt.live/348bv0W](https://packt.live/348bv0W).
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在网上运行这个示例：[https://packt.live/348bv0W](https://packt.live/348bv0W)。
- en: Maximum Features
  id: totrans-387
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大特征数
- en: 'We are getting close to the end of this chapter. You have already learned how
    to tune several of the most important hyperparameters for RandomForest. In this
    section, we will present you with another extremely important one: `max_features`.'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经接近本章的结尾。你已经学习了如何调整`RandomForest`中最重要的几个超参数。在这一部分，我们将向你介绍另一个非常重要的参数：`max_features`。
- en: 'Earlier, we learned that `RandomForest` builds multiple trees and takes the
    average to make predictions. This is why it is called a forest, but we haven''t
    really discussed the "random" part yet. Going through this chapter, you may have
    asked yourself: how does building multiple trees help to get better predictions,
    and won''t all the trees look the same given that the input data is the same?'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们了解了`RandomForest`如何构建多棵树并取平均值来进行预测。这就是为什么它被称为森林，但我们还没有真正讨论“随机”部分。通过本章的内容，你可能会问自己：构建多棵树如何帮助得到更好的预测结果？而且如果输入数据相同，所有的树难道不会看起来一样吗？
- en: Before answering these questions, let's use the analogy of a court trial. In
    some countries, the final decision of a trial is either made by a judge or a jury.
    A judge is a person who knows the law in detail and can decide whether a person
    has broken the law or not. On the other hand, a jury is composed of people from
    different backgrounds who don't know each other or any of the parties involved
    in the trial and have limited knowledge of the legal system. In this case, we
    are asking random people who are not expert in the law to decide the outcome of
    a case. This sounds very risky at first. The risk of one person making the wrong
    decision is very high. But in fact, the risk of 10 or 20 people all making the
    wrong decision is relatively low.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在回答这些问题之前，我们可以通过类比法来理解。某些国家，审判的最终决定是由法官或陪审团做出的。法官是精通法律的人，能决定一个人是否违反了法律。另一方面，陪审团由不同背景的人组成，他们彼此不认识，也不认识案件的当事人，而且对法律体系的了解有限。在这种情况下，我们让一些非法律专家来决定案件的结果，乍一听起来似乎很冒险。一个人做出错误判断的风险很高，但事实上，10或20个人都做出错误判断的风险相对较低。
- en: 'But there is one condition that needs to be met for this to work: randomness.
    If all the people in the jury come from the same background, work in the same
    industry, or live in the same area, they may share the same way of thinking and
    make similar decisions. For instance, if a group of people were raised in a community
    where you only drink hot chocolate at breakfast and one day you ask them if it
    is OK to drink coffee at breakfast, they would all say no.'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 但有一个条件需要满足才能使这种方法有效：随机性。如果陪审团中的所有人都来自相同的背景、在相同的行业工作或生活在相同的地区，他们可能会有相同的思维方式并做出相似的决定。例如，如果一群人在一个只喝热巧克力作为早餐的社区长大，某天你问他们早上喝咖啡是否合适，他们都会说不行。
- en: 'On the other hand, say you got another group of people from different backgrounds
    with different habits: some drink coffee, others tea, a few drink orange juice,
    and so on. If you asked them the same question, you would end up with the majority
    of them saying yes. Because we randomly picked these people, they have less bias
    as a group, and this therefore lowers the risk of them making a wrong decision.'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，假设你有另一组来自不同背景、拥有不同习惯的人：有些人喝咖啡，有些人喝茶，还有一些人喝橙汁，等等。如果你问他们相同的问题，你最终会发现大多数人都会回答“是”。因为我们随机挑选了这些人，他们作为一个群体的偏差较小，因此降低了他们做出错误决策的风险。
- en: 'RandomForest actually applies the same logic: it builds a number of trees independently
    of each other by randomly sampling the data. A tree may see `60%` of the training
    data, another one `70%`, and so on. By doing so, there is a high chance that the
    trees are absolutely different from each other and don''t share the same bias.
    This is the secret of RandomForest: building multiple random trees leads to higher
    accuracy.'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: RandomForest 实际上应用了相同的逻辑：通过随机抽样数据，独立地构建多个树。一个树可能看到`60%`的训练数据，另一个树看到`70%`，依此类推。通过这种方式，树之间有很大的可能性是完全不同的，并且不会共享相同的偏差。这就是
    RandomForest 的秘密：构建多个随机树可以提高准确性。
- en: 'But it is not the only way RandomForest creates randomness. It does so also
    by randomly sampling columns. Each tree will only see a subset of the features
    rather than all of them. And this is exactly what the `max_features` hyperparameter
    is for: it will set the maximum number of features a tree is allowed to see.'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不是 RandomForest 创建随机性的唯一方式。它还通过随机抽样列来实现这一点。每棵树只会看到特征的子集，而不是所有的特征。这正是`max_features`超参数的作用：它设置了每棵树可以看到的最大特征数。
- en: 'In `sklearn`, you can specify the value of this hyperparameter as:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在`sklearn`中，你可以通过以下方式指定该超参数的值：
- en: The maximum number of features, as an integer.
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大特征数，作为一个整数。
- en: A ratio, as the percentage of allowed features.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个比率，作为允许特征的百分比。
- en: The `sqrt` function (the default value in `sklearn`, which stands for square
    root), which will use the square root of the number of features as the maximum
    value. If, for a dataset, there are `25` features, its square root will be `5`
    and this will be the value for `max_features`.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sqrt`函数（`sklearn`中的默认值，表示平方根），它将使用特征数量的平方根作为最大值。如果数据集有`25`个特征，则它的平方根为`5`，这将是`max_features`的值。'
- en: The `log2` function, which will use the log base, `2`, of the number of features
    as the maximum value. If, for a dataset, there are eight features, its `log2`
    will be `3` and this will be the value for `max_features`.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log2`函数，它将使用特征数量的以 2 为底的对数作为最大值。如果数据集有 8 个特征，则其`log2`为`3`，这将是`max_features`的值。'
- en: The `None` value, which means Random Forest will use all the features available.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`None`值表示 RandomForest 将使用所有可用特征。'
- en: 'Let''s try three different values on the activity dataset. First, we will specify
    the maximum number of features as two:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在活动数据集上尝试三个不同的值。首先，我们将最大特征数指定为 2：
- en: '[PRE75]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The output will be as follows:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.36: Accuracy scores for the training and testing sets for max_features=2'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.36：max_features=2 时训练集和测试集的准确性得分'
- en: '](img/B15019_04_36.jpg)'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_36.jpg)'
- en: 'Figure 4.36: Accuracy scores for the training and testing sets for max_features=2'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.36：max_features=2 时训练集和测试集的准确性得分
- en: 'We got results similar to those of the best model we trained in the previous
    section. This is not really surprising as we were using the default value of `max_features`
    at that time, which is `sqrt`. The square root of `2` equals `1.45`, which is
    quite close to `2`. This time, let''s try with the ratio `0.7`:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了类似于之前训练的最佳模型的结果。这并不令人惊讶，因为当时我们使用的是`max_features`的默认值，即`sqrt`。`2`的平方根等于`1.45`，与`2`相当接近。这次，我们尝试使用比率`0.7`：
- en: '[PRE76]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The output will be as follows:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.37: Accuracy scores for the training and testing sets for max_features=0.7'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.37：max_features=0.7 时训练集和测试集的准确性得分'
- en: '](img/B15019_04_37.jpg)'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_37.jpg)'
- en: 'Figure 4.37: Accuracy scores for the training and testing sets for max_features=0.7'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.37：max_features=0.7 时训练集和测试集的准确性得分
- en: 'With this ratio, both accuracy scores increased for the training and testing
    sets and the difference between them is less. Our model is overfitting less now
    and has slightly improved its predictive power. Let''s give it a shot with the
    `log2` option:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个比例，训练集和测试集的准确率都提高了，并且它们之间的差距更小。我们的模型现在过拟合较少，预测能力稍有提升。让我们尝试使用 `log2` 选项：
- en: '[PRE77]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The output will be as follows:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.38: Accuracy scores for the training and testing sets for max_features=''log2'''
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.38：max_features=''log2'' 时训练集和测试集的准确率'
- en: '](img/B15019_04_38.jpg)'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_38.jpg)'
- en: 'Figure 4.38: Accuracy scores for the training and testing sets for max_features=''log2'''
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.38：max_features='log2' 时训练集和测试集的准确率
- en: We got similar results as for the default value (`sqrt`) and `2`. Again, this
    is normal as the `log2` of `6` equals `2.58`. So, the optimal value we found for
    the `max_features` hyperparameter is `0.7` for this dataset.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了与默认值（`sqrt`）和 `2` 相似的结果。同样，这是正常的，因为 `6` 的 `log2` 等于 `2.58`。所以，我们为这个数据集找到的
    `max_features` 超参数的最佳值是 `0.7`。
- en: 'Exercise 4.05: Tuning max_features'
  id: totrans-420
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.05：调整 max_features
- en: 'In this exercise, we will keep tuning our RandomForest classifier that predicts
    animal type by trying two different values for the `max_features` hyperparameter:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将继续调整我们的随机森林分类器，通过尝试 `max_features` 超参数的两个不同值来预测动物类型：
- en: We will be using the same zoo dataset as in the previous exercise.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与前一个练习相同的动物园数据集。
- en: Open a new Colab notebook.
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Colab 笔记本。
- en: 'Import the `pandas` package, `train_test_split`, `RandomForestClassifier`,
    and `accuracy_score` from `sklearn`:'
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas` 包，`train_test_split`，`RandomForestClassifier` 和 `accuracy_score`
    从 `sklearn`：
- en: '[PRE78]'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Create a variable called `file_url` that contains the URL to the dataset:'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `file_url` 的变量，其中包含数据集的 URL：
- en: '[PRE79]'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Load the dataset into a DataFrame using the `.read_csv()` method from `pandas`:'
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.read_csv()` 方法从 `pandas` 将数据集加载到 DataFrame 中：
- en: '[PRE80]'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Remove the `animal` column using `.drop()` and then extract the `type` target
    variable into a new variable called `y` using `.pop()`:'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.drop()` 删除 `animal` 列，然后使用 `.pop()` 提取 `type` 目标变量，并将其存储到一个名为 `y` 的新变量中：
- en: '[PRE81]'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Split the data into training and testing sets with `train_test_split()` and
    the parameters `test_size=0.4` and `random_state=188`:'
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `train_test_split()` 将数据集拆分为训练集和测试集，参数为 `test_size=0.4` 和 `random_state=188`：
- en: '[PRE82]'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Instantiate `RandomForestClassifier` with `random_state=42`, `n_estimators=30`,
    `max_depth=2`, `min_samples_leaf=7`, and `max_features=10`, and then fit the model
    with the training set:'
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化 `RandomForestClassifier`，参数为 `random_state=42`，`n_estimators=30`，`max_depth=2`，`min_samples_leaf=7`，`max_features=10`，然后用训练集拟合模型：
- en: '[PRE83]'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'You should get the following output:'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.39: Logs of RandomForest'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.39：随机森林的日志'
- en: '](img/B15019_04_39.jpg)'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_39.jpg)'
- en: 'Figure 4.39: Logs of RandomForest'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.39：随机森林的日志
- en: 'Make predictions on the training and testing sets with `.predict()` and save
    the results into two new variables called `train_preds` and `test_preds`:'
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.predict()` 对训练集和测试集进行预测，并将结果保存到两个名为 `train_preds` 和 `test_preds` 的新变量中：
- en: '[PRE84]'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Calculate the accuracy scores for the training and testing sets and save the
    results in two new variables called `train_acc` and `test_acc`:'
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集和测试集的准确率，并将结果保存在两个名为 `train_acc` 和 `test_acc` 的新变量中：
- en: '[PRE85]'
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Print the accuracy scores: `train_acc` and `test_acc`:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印准确率分数：`train_acc` 和 `test_acc`：
- en: '[PRE86]'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'You should get the following output:'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.40: Accuracy scores for the training and testing sets'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.40：训练集和测试集的准确率'
- en: '](img/B15019_04_40.jpg)'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_40.jpg)'
- en: 'Figure 4.40: Accuracy scores for the training and testing sets'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.40：训练集和测试集的准确率
- en: 'Instantiate another `RandomForestClassifier` with `random_state=42`, `n_estimators=30`,
    `max_depth=2`, `min_samples_leaf=7`, and `max_features=0.2`, and then fit the
    model with the training set:'
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化另一个 `RandomForestClassifier`，参数为 `random_state=42`，`n_estimators=30`，`max_depth=2`，`min_samples_leaf=7`，`max_features=0.2`，然后用训练集来拟合模型：
- en: '[PRE87]'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'You should get the following output:'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.41: Logs of RandomForest with max_features = 0.2'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.41：max_features = 0.2 时随机森林的日志'
- en: '](img/B15019_04_41.jpg)'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_41.jpg)'
- en: 'Figure 4.41: Logs of RandomForest with max_features = 0.2'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.41：max_features = 0.2 时随机森林的日志
- en: 'Make predictions on the training and testing sets with `.predict()` and save
    the results into two new variables called `train_preds2` and `test_preds2`:'
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.predict()` 对训练集和测试集进行预测，并将结果保存到两个名为 `train_preds2` 和 `test_preds2` 的新变量中：
- en: '[PRE88]'
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Calculate the accuracy score for the training and testing sets and save the
    results in two new variables called `train_acc2` and `test_acc2`:'
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集和测试集的准确率，并将结果保存在两个新变量中，分别命名为`train_acc2`和`test_acc2`：
- en: '[PRE89]'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Print the accuracy scores: `train_acc` and `test_acc`:'
  id: totrans-460
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印准确率评分：`train_acc` 和 `test_acc`：
- en: '[PRE90]'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'You should get the following output:'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 4.42: Accuracy scores for the training and testing sets'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.42：训练集和测试集的准确率评分'
- en: '](img/B15019_04_42.jpg)'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_04_42.jpg)'
- en: 'Figure 4.42: Accuracy scores for the training and testing sets'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.42：训练集和测试集的准确率评分
- en: 'The values `10` and `0.2`, which we tried in this exercise for the `max_features`
    hyperparameter, did improve the accuracy of the training set but not the testing
    set. With these values, the model starts to overfit again. The optimal value for
    `max_features` is the default value (`sqrt`) for this dataset. In the end, we
    succeeded in building a model with a 0.8 accuracy score that is not overfitting.
    This is a pretty good result given the fact the dataset wasn''t big: we got only
    `6` features and `41759` observations.'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们尝试的`max_features`超参数的值`10`和`0.2`确实提高了训练集的准确率，但对测试集没有影响。使用这些值，模型开始出现过拟合。对于这个数据集，`max_features`的最佳值是默认值（`sqrt`）。最终，我们成功构建了一个准确率为0.8且没有过拟合的模型。考虑到数据集并不大，我们只有`6`个特征和`41759`个观察值，这已经是一个相当不错的结果。
- en: Note
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3g8nTk7](https://packt.live/3g8nTk7).
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/3g8nTk7](https://packt.live/3g8nTk7)。
- en: You can also run this example online at [https://packt.live/324quGv](https://packt.live/324quGv).
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在此在线运行此示例：[https://packt.live/324quGv](https://packt.live/324quGv)。
- en: 'Activity 4.01: Train a Random Forest Classifier on the ISOLET Dataset'
  id: totrans-470
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 4.01：在ISOLET数据集上训练一个随机森林分类器
- en: You are working for a technology company and they are planning to launch a new
    voice assistant product. You have been tasked with building a classification model
    that will recognize the letters spelled out by a user based on the signal frequencies
    captured. Each sound can be captured and represented as a signal composed of multiple
    frequencies.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 你正在为一家科技公司工作，该公司计划推出一款新的语音助手产品。你被分配到建立一个分类模型，识别用户根据信号频率拼写的字母。每个声音可以被捕获并表示为由多个频率组成的信号。
- en: Note
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'This activity uses the ISOLET dataset, taken from the UCI Machine Learning
    Repository from the following link: [https://packt.live/2QFOawy](https://packt.live/2QFOawy).'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动使用ISOLET数据集，来自UCI机器学习库，链接如下：[https://packt.live/2QFOawy](https://packt.live/2QFOawy)。
- en: 'The CSV version of this dataset can be found here: [https://packt.live/36DWHpi](https://packt.live/36DWHpi).'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集的CSV版本可以在此处找到：[https://packt.live/36DWHpi](https://packt.live/36DWHpi)。
- en: 'The following steps will help you to complete this activity:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成此活动：
- en: Download and load the dataset using `.read_csv()` from `pandas`.
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`中的`.read_csv()`下载并加载数据集。
- en: Extract the response variable using `.pop()` from `pandas`.
  id: totrans-477
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`中的`.pop()`提取响应变量。
- en: Split the dataset into training and test sets using `train_test_split()` from
    `sklearn.model_selection`.
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`sklearn.model_selection`中的`train_test_split()`将数据集拆分为训练集和测试集。
- en: Create a function that will instantiate and fit a `RandomForestClassifier` using
    `.fit()` from `sklearn.ensemble`.
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，使用`sklearn.ensemble`中的`.fit()`实例化并拟合`RandomForestClassifier`。
- en: Create a function that will predict the outcome for the training and testing
    sets using `.predict()`.
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，使用`.predict()`为训练集和测试集预测结果。
- en: Create a function that will print the accuracy score for the training and testing
    sets using `accuracy_score()` from `sklearn.metrics`.
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，使用`sklearn.metrics`中的`accuracy_score()`打印训练集和测试集的准确率。
- en: 'Train and get the accuracy score for a range of different hyperparameters.
    Here are some options you can try:'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一系列不同的超参数值下训练并获取准确率。以下是你可以尝试的一些选项：
- en: '`n_estimators = 20` and `50`'
  id: totrans-483
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_estimators = 20` 和 `50`'
- en: '`max_depth = 5` and `10`'
  id: totrans-484
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_depth = 5` 和 `10`'
- en: '`min_samples_leaf = 10` and `50`'
  id: totrans-485
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_samples_leaf = 10` 和 `50`'
- en: '`max_features = 0.5` and `0.3`'
  id: totrans-486
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_features = 0.5` 和 `0.3`'
- en: Select the best hyperparameter value.
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择最佳超参数值。
- en: 'These are the accuracy scores for the best model we trained:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们训练的最佳模型的准确率评分：
- en: '![Figure 4.43: Accuracy scores for the Random Forest classifier'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.43：随机森林分类器的准确率评分'
- en: '](img/B15019_04_43.jpg)'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_04_43.jpg)'
- en: 'Figure 4.43: Accuracy scores for the Random Forest classifier'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.43：随机森林分类器的准确率评分
- en: Note
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The solution to the activity can be found here: [https://packt.live/2GbJloz](https://packt.live/2GbJloz).'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 活动的解决方案可以在这里找到：[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。
- en: Summary
  id: totrans-494
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'We have finally reached the end of this chapter on multiclass classification
    with Random Forest. We learned that multiclass classification is an extension
    of binary classification: instead of predicting only two classes, target variables
    can have many more values. We saw how we can train a Random Forest model in just
    a few lines of code and assess its performance by calculating the accuracy score
    for the training and testing sets. Finally, we learned how to tune some of its
    most important hyperparameters: `n_estimators`, `max_depth`, `min_samples_leaf`,
    and `max_features`. We also saw how their values can have a significant impact
    on the predictive power of a model but also on its ability to generalize to unseen
    data.'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于结束了关于随机森林的多类分类章节。我们学到了，多类分类是二分类的扩展：它不仅仅是预测两个类别，目标变量可以有更多的值。我们看到，只需几行代码就能训练一个随机森林模型，并通过计算训练集和测试集的准确度来评估其性能。最后，我们了解了如何调整一些最重要的超参数：`n_estimators`、`max_depth`、`min_samples_leaf`
    和 `max_features`。我们还看到，它们的值对模型的预测能力以及对未见数据的泛化能力有着显著的影响。
- en: In real projects, it is extremely important to choose a valid testing set. This
    is your final proxy before putting a model into production so you really want
    it to reflect the types of data you think it will receive in the future. For instance,
    if your dataset has a date field, you can use the last few weeks or months as
    your testing set and everything before that date as the training set. If you don't
    choose the testing set properly, you may end up with a very good model that seems
    to not overfit but once in production, it will generate incorrect results. The
    problem doesn't come from the model but from the fact the testing set was chosen
    poorly.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际项目中，选择一个有效的测试集是极其重要的。这是你在将模型投入生产前的最终验证，因此你希望它能够真实反映你认为未来模型可能接收到的数据类型。例如，如果你的数据集有一个日期字段，你可以将过去几周或几个月的数据作为测试集，而在此日期之前的数据作为训练集。如果你没有正确选择测试集，你可能最终得到一个看似没有过拟合的优秀模型，但一旦投入生产，它就会生成错误的结果。问题并不在于模型本身，而在于测试集选择不当。
- en: 'In some projects, you may see that the dataset is split into three different
    sets: training, validation, and testing. The validation set can be used to tune
    the hyperparameters and once you are confident enough, you can test your model
    on the testing set. As mentioned earlier, we don''t want the model to see too
    much of the testing set but hyperparameter tuning requires you to run a model
    several times until you find the optimal values. This is the reason why most data
    scientists create a validation set for this purpose and only use the testing set
    a handful of times. This will be explained in more depth in *Chapter 7, The Generalization
    of Machine Learning Models*.'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些项目中，你可能会看到数据集被拆分为三个不同的集合：训练集、验证集和测试集。验证集可以用来调整超参数，一旦你足够自信，就可以在测试集上测试你的模型。如前所述，我们不希望模型看到过多的测试集数据，但超参数调整需要你多次运行模型，直到找到最优值。这也是为什么大多数数据科学家为此目的创建了验证集，并且仅在少数情况下使用测试集。这将在*第七章，机器学习模型的泛化*中更深入地解释。
- en: In the next chapter, you will be introduced to unsupervised learning and will
    learn how to build a clustering model with the k-means algorithm.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将接触到无监督学习，并学习如何使用 k-means 算法构建聚类模型。
