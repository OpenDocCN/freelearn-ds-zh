- en: Chapter 5. Storm High Availability and Failover
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。Storm高可用性和故障转移
- en: This chapter takes you to the next level in your journey through Storm, where
    we get you acquainted with the integration of Storm with other necessary components
    in the ecosystem. We will cover the concepts of high availability and reliability,
    practically.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将带您进入Storm的旅程的下一个级别，在这里我们将让您熟悉Storm与生态系统中其他必要组件的集成。我们将实际涵盖高可用性和可靠性的概念。
- en: This chapter is the next step in understanding the clustered mode setup of Storm
    and its associated components. We will understand the various configurations in
    Storm and Zookeeper and the concept behind them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是理解Storm及其相关组件的集群模式设置的下一步。我们将了解Storm和Zookeeper中的各种配置以及它们背后的概念。
- en: 'The topics that will be covered in this chapter are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Setting up RabbitMQ (single instance and clustered mode)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置RabbitMQ（单实例和集群模式）
- en: Developing the AMQP spout to integrate Storm and RabbitMQ
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发AMQP喷流以集成Storm和RabbitMQ
- en: Creating a RabbitMQ feeder component
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建RabbitMQ饲料器组件
- en: Building high availability for RabbitMQ and the Storm cluster
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为RabbitMQ和Storm集群构建高可用性
- en: The Storm schedulers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storm调度程序
- en: By the end of this chapter, you will be able to set up and understand RabbitMQ
    and integrate Storm with RabbitMQ. Also, you will be able to test high availability
    and guaranteed processing of the Storm cluster.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章结束时，您将能够设置和理解RabbitMQ，并将Storm与RabbitMQ集成。此外，您将能够测试Storm集群的高可用性和可靠处理。
- en: An overview of RabbitMQ
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RabbitMQ概述
- en: The punch line that goes for RabbitMQ is *Messaging that just works*.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ的要点是*消息传递只是起作用*。
- en: RabbitMQ is one of the most widely used implementations of the AMQP messaging
    protocol that provides a platform for message receipt and delivery. This in-memory
    queue also has the capacity to hold and retain messages till they are consumed
    by a consumer. This flexible brokering system is very easy to use and works on
    most of the operating systems such as windows, UNIX, and so on.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ是AMQP消息协议最广泛使用的实现之一，它提供了一个用于接收和传递消息的平台。这个内存队列还有能力保存和保留消息，直到它们被消费者消耗。这种灵活的代理系统非常易于使用，并且适用于大多数操作系统，如Windows、UNIX等。
- en: 'RabbitMQ is an implementation of the **Advanced Message Queuing Protocol**
    (**AMQP**). As depicted in the following figure, the vital components of RabbitMQ
    are **exchange** and **Queue**:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ是**高级消息队列协议**（**AMQP**）的实现。如下图所示，RabbitMQ的关键组件是**交换**和**队列**：
- en: '![An overview of RabbitMQ](img/00039.jpeg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![RabbitMQ概述](img/00039.jpeg)'
- en: The publisher and the consumer are two essential actors; the former generates
    the messages and publishes them to the exchange, which in turn (depending upon
    its type) publishes the message from the publisher to the queue and from the queue
    to the consumer, who picks up the message.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 发布者和消费者是两个重要的角色；前者生成消息并将其发布到交换，后者根据其类型将消息从发布者发布到队列，然后从队列发布到消费者，消费者接收消息。
- en: The point to note is that here the publisher interacts with the exchange and
    not the queue. There are various kinds of exchanges that RabbitMQ supports such
    as direct, fanout, topic, and so on. The task of the exchange is to route the
    message to one or more queues depending upon the type of exchange and the routing
    key associated with the message. So if it's a direct exchange, the message will
    be delivered to one queue bound to the exchange with the routing key matching
    the one in the message. If it's a fanout exchange, then the message is delivered
    to all the queues bound to the exchange, and the routing is totally ignored.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这里的发布者与交换进行交互，而不是队列。RabbitMQ支持各种类型的交换，如直接、扇出、主题等。交换的任务是根据交换的类型和与消息关联的路由键，将消息路由到一个或多个队列。因此，如果是直接交换，消息将被传递到与交换绑定的一个队列，其路由键与消息中的路由键匹配。如果是扇出交换，那么消息将被传递到与交换绑定的所有队列，路由完全被忽略。
- en: Installing the RabbitMQ cluster
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装RabbitMQ集群
- en: RabbitMQ is a messaging broker—an intermediary for messaging. It gives your
    applications a common platform to send and receive messages, and your messages
    a safe place to live until they are received.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ是一个消息代理-消息的中间人。它为您的应用程序提供了一个发送和接收消息的共同平台，并为您的消息提供了一个安全的存放处，直到它们被接收。
- en: Prerequisites for the setup of RabbitMQ
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置RabbitMQ的先决条件
- en: 'Make sure you have taken care of the fact that short names are also included
    in the `/etc/hosts` file as shown in the following code:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您已经注意到短名称也包括在`/etc/hosts`文件中，如下面的代码所示：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Short names in `/etc/hosts` are mandatory because in a RabbitMQ cluster, the
    internode communication happens using these short names.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在RabbitMQ集群中，`/etc/hosts`中的短名称是强制性的，因为节点间的通信是使用这些短名称进行的。
- en: 'For example, we have two machines in our cluster with the following mentioned
    IPs and hostnames; this information is used by the RabbitMQ daemons while starting
    the cluster:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们的集群中有两台机器，具有以下提到的IP和主机名；RabbitMQ守护程序在启动集群时使用这些信息：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If the short names are not set, you will see this error: **System NOT running
    to use fully qualified hostnames**.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未设置短名称，您将看到此错误：**系统未运行以使用完全限定的主机名**。
- en: Setting up a RabbitMQ server
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置RabbitMQ服务器
- en: 'Ubuntu ships with RabbitMQ but it''s often not the latest version. The latest
    version can be retrieved from RabbitMQ''s Debian repository. The following shell
    script should be run for the RabbitMQ installation on Ubuntu:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Ubuntu附带了RabbitMQ，但通常不是最新版本。最新版本可以从RabbitMQ的Debian存储库中检索。应在Ubuntu上运行以下shell脚本以安装RabbitMQ：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Testing the RabbitMQ server
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试RabbitMQ服务器
- en: 'The following steps will get you the commands that are to be executed on the
    Ubuntu terminal to start the RabbitMQ server and test it. They are as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将为您提供在Ubuntu终端上执行的命令，以启动RabbitMQ服务器并对其进行测试。它们如下：
- en: 'Start the RabbitMQ server by running the following command on the shell:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在shell上运行以下命令启动RabbitMQ服务器：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Testing the RabbitMQ server](img/00040.jpeg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![测试RabbitMQ服务器](img/00040.jpeg)'
- en: 'Check the server status by running the following command:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令检查服务器状态：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Testing the RabbitMQ server](img/00041.jpeg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![测试RabbitMQ服务器](img/00041.jpeg)'
- en: 'On each RabbitMQ instance, to enable the RabbitMQ management console, execute
    the following command and restart the RabbitMQ server running on that instance,
    by using the following command:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个RabbitMQ实例上，要启用RabbitMQ管理控制台，请执行以下命令，并使用以下命令重新启动该实例上运行的RabbitMQ服务器：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To enable the RabbitMQ plugins, navigate to `/usr/lib/rabbitmq/bin` and execute
    the following command on both nodes and restart them:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要启用RabbitMQ插件，请转到`/usr/lib/rabbitmq/bin`并在两个节点上执行以下命令，然后重新启动它们：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Startup, shutdown, and error logs are created under the `/var/log/rabbitmq`
    directory.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动、关闭和错误日志将在`/var/log/rabbitmq`目录下创建。
- en: Creating a RabbitMQ cluster
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建RabbitMQ集群
- en: 'Here are the steps that you need to execute to set up a two (or more) node
    RabbitMQ cluster:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是设置两个（或更多）节点RabbitMQ集群所需执行的步骤：
- en: 'Considering `rmq-flc-1` and `rmq-flc-2` are the short hostnames of the two
    instances, we will start standalone RabbitMQ servers on both instances using the
    command:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑到`rmq-flc-1`和`rmq-flc-2`是两个实例的短主机名，我们将使用以下命令在两个实例上启动独立的RabbitMQ服务器：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'On `rmq-flc-2`, we will stop the RabbitMQ application, reset the node, join
    the cluster, and restart the RabbitMQ application using the following commands
    (all this is being done while the RabbitMQ server is up and running on `rmq-flc-1`):'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`rmq-flc-2`上，我们将停止RabbitMQ应用程序，重置节点，加入集群，并使用以下命令重新启动RabbitMQ应用程序（所有这些都是在`rmq-flc-1`上的RabbitMQ服务器正在运行时完成的）：
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Check the cluster status by running the following command on any of the machines:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在任何一台机器上运行以下命令来检查集群状态：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The following output should be seen:![Creating a RabbitMQ cluster](img/00042.jpeg)
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应该看到以下输出：![创建RabbitMQ集群](img/00042.jpeg)
- en: The cluster is set up successfully.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群已成功设置。
- en: 'The cluster can be accessed at `http:/` `/<hostip>:15672` (username: `guest`,
    password: `guest`), if the UI is enabled.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用了UI，可以在`http:/` `/<hostip>:15672`（用户名：`guest`，密码：`guest`）访问集群。
- en: Enabling the RabbitMQ UI
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启用RabbitMQ UI
- en: 'Perform the following steps to enable the RabbitMQ UI:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以启用RabbitMQ UI：
- en: 'Execute the following command:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下命令：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding command will result in the following output:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述命令将产生以下输出：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Repeat the preceding steps on all nodes of the cluster.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在集群的所有节点上重复前面的步骤。
- en: 'Restart each node using the following command:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令重新启动每个节点：
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Access the UI using the `http:``//<hostip>:15672` link. The default username
    and password is `guest`.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`http:``//<hostip>:15672`链接访问UI。默认用户名和密码是`guest`。
- en: Creating mirror queues for high availability
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为高可用性创建镜像队列
- en: In this section, we talk about a special kind of queues that guarantee high
    availability over the RabbitMQ default queues. By default, the queues that we
    create are located on a single node based on the order in which they are declared,
    and this can become the single point of failure. Let's look at an example. I have
    a cluster of two RabbitMQ nodes, `rabbit1` and `rabbit2`, and I declare one exchange
    over my cluster, say, `myrabbitxchange`. Let's say by the order of execution,
    the queue is created in `rabbit1`. Now if `rabbit1` goes down, then the queue
    is gone and the clients will not be able to publish to it.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论一种特殊类型的队列，它保证了RabbitMQ默认队列的高可用性。默认情况下，我们创建的队列位于单个节点上，根据它们声明的顺序，这可能成为单点故障。让我们看一个例子。我有一个由两个RabbitMQ节点`rabbit1`和`rabbit2`组成的集群，并在我的集群上声明了一个交换机，比如`myrabbitxchange`。假设按照执行顺序，在`rabbit1`上创建了队列。现在，如果`rabbit1`宕机，那么队列就消失了，客户端将无法发布到它。
- en: 'Thus to avoid situations, we need highly available queues; they are called
    mirrored queues, which are replicated on all the nodes in the cluster. Mirrored
    queues have one master and multiple slaves, the oldest one is the master and if
    it''s not available, the oldest amongst the available nodes becomes the master.
    Messages are published to all slaves. This enhances the availability but doesn''t
    distribute the load. To create the mirror queues, use the following steps:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了避免情况，我们需要高可用性队列；它们被称为镜像队列，在集群中的所有节点上都有副本。镜像队列有一个主节点和多个从节点，最老的节点是主节点，如果它不可用，则可用节点中最老的节点成为主节点。消息被发布到所有从节点。这增强了可用性，但不会分配负载。要创建镜像队列，请使用以下步骤：
- en: Mirroring can be enabled by adding a policy using the web UI. Go to the **Admin**
    tab and select **Policies** and click on **Add policy**.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以通过使用Web UI添加策略来启用镜像。转到**管理**选项卡，选择**策略**，然后单击**添加策略**。
- en: Specify policy **Name**, **Pattern**, **Definition**, and click on **Add Policy**,
    as shown in the following screenshot:![Creating mirror queues for high availability](img/00043.jpeg)
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定策略**名称**、**模式**、**定义**，然后单击**添加策略**，如下面的截图所示：![为高可用性创建镜像队列](img/00043.jpeg)
- en: Integrating Storm with RabbitMQ
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Storm与RabbitMQ集成
- en: Now that we have installed Storm, the next step will be to integrate RabbitMQ
    with Storm, for which we will have to create a custom spout called the RabbitMQ
    spout. This spout will read the messages from the specified queue; thus, it will
    furnish the role of a consumer, and then push these messages to a downstream topology.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经安装了Storm，下一步将是将RabbitMQ与Storm集成，为此我们将不得不创建一个名为RabbitMQ spout的自定义spout。这个spout将从指定队列中读取消息；因此，它将提供一个消费者的角色，然后将这些消息推送到下游拓扑。
- en: 'Here is how the spout code will look:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是spout代码的样子：
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'AMQP Maven dependency that will be required to be introduced in the project
    `pom.xml`, as shown in the following code:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 需要在项目`pom.xml`中引入AMQP Maven依赖项，如下所示：
- en: '[PRE14]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Creating a RabbitMQ feeder component
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建RabbitMQ饲料器组件
- en: 'Now that we have installed the RabbitMQ cluster, all we need is to develop
    a publisher component that will publish the messages to RabbitMQ. This will be
    a simple Java component that will mimic the live feed to RabbitMQ. The basic code
    snippet for this is as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经安装了RabbitMQ集群，我们所需要做的就是开发一个发布者组件，它将把消息发布到RabbitMQ。这将是一个简单的Java组件，模拟向RabbitMQ发布实时数据。这个组件的基本代码片段如下：
- en: '[PRE15]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Wiring the topology for the AMQP spout
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为AMQP spout连接拓扑
- en: Now we have the clustered queue setup ready, the AMQP spout in place, and the
    feeder component in place; let's put the last and final piece in place, that's
    the overall integration of the Storm topology.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了集群队列设置，放置了AMQP spout和feeder组件；让我们放置最后一个部分，即Storm拓扑的整体集成。
- en: Let's use our `WordCount` topology again and instead of `RandomSentenceSpout`
    we will use `AMQPRecvSpout`, which we designed in the previous section, *Integrating
    Storm with RabbitMQ*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次使用我们的`WordCount`拓扑，而不是`RandomSentenceSpout`，我们将使用在上一节中设计的`AMQPRecvSpout`，*将Storm与RabbitMQ集成*。
- en: 'The following code chunk needs to be modified:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 需要修改以下代码块：
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Building high availability of components
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建组件的高可用性
- en: Now we are at an opportune juncture to look for high availability of various
    components in the cluster. We will do this as a series of exercises wherein we
    assume that each component is installed in the clustered mode and more than one
    instance of it exists in the ecosystem.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们正处于寻找集群中各个组件的高可用性的合适时机。我们将通过一系列练习来完成这一点，假设每个组件都以集群模式安装，并且在生态系统中存在多个实例。
- en: 'The high availability of RabbitMQ can be checked only after you have a mirrored
    queue in place. Let''s assume:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在设置了镜像队列之后，才能检查RabbitMQ的高可用性。假设：
- en: 'We have two nodes in the RabbitMQ cluster: node1 and node2'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在RabbitMQ集群中有两个节点：node1和node2
- en: '`MyExchange` is the name of the exchange that is created for the purpose of
    this exercise'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MyExchange`是为此练习创建的交换的名称'
- en: '`MyQueue` is a mirrored queue that is created for this exercise'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MyQueue`是为此练习创建的镜像队列'
- en: 'Next, we will just run the `fixedEmitter` code we created in the *Creating
    a RabbitMQ feeder component* section. Now perform the Litmus test:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将运行我们在*创建RabbitMQ feeder组件*部分创建的`fixedEmitter`代码。现在进行Litmus测试：
- en: Let's assume the queue `MyQueue` has 100 messages
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设队列`MyQueue`有100条消息
- en: Now bring down node2 (this means, one node on the cluster is down)
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在关闭node2（这意味着集群中的一个节点宕机）
- en: All the 100 messages will be retained and will be visible on the console; node1
    fills in when there is an absence of node2
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有100条消息将被保留，并且在控制台上可见；当node2缺席时，node1填充。
- en: This behavior ensures that services are not disrupted even if a node in the
    cluster goes down.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这种行为确保即使集群中的一个节点宕机，服务也不会中断。
- en: High availability of the Storm cluster
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Storm集群的高可用性
- en: 'Now let''s see the demonstration of a failover or high availability in Storm.
    The Storm framework is built in such a way that it can continue to execute as
    long as:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一下Storm中故障转移或高可用性的演示。Storm框架的构建方式使其可以继续执行，只要：
- en: It has the required number of Zookeeper connections
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它具有所需数量的Zookeeper连接
- en: It has the required number of workers on one or more supervisors
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它具有所需数量的工作进程在一个或多个监督者上
- en: 'So what do the preceding statements actually mean? Well, let''s understand
    this with an example. Let''s say I am executing the `WordCount` topology on a
    Storm cluster. This cluster has the following configuration:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 那么前面的陈述实际上是什么意思呢？好吧，让我们通过一个例子来理解。假设我在Storm集群上执行`WordCount`拓扑。这个集群的配置如下：
- en: There are two Storm supervisors with four workers on each Storm supervisor,
    so a total eight workers in the cluster
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有两个Storm监督者，每个Storm监督者有四个工作进程，所以集群中总共有八个工作进程
- en: There are three Zookeeper nodes (max connections 30), so in total 30*2*3=180
    connections
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有三个Zookeeper节点（最大连接数30），所以总共有30*2*3=180个连接
- en: A topology is allocated with three workers
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个拓扑分配了三个工作进程
- en: 'Let''s assume when we submit this topology onto the cluster, the tasks and
    processes are spawned as shown in the following screenshot:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 假设当我们将这个拓扑提交到集群时，任务和进程会像下面的截图所示一样生成：
- en: '![High availability of the Storm cluster](img/00044.jpeg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![Storm集群的高可用性](img/00044.jpeg)'
- en: 'The preceding figure depicts the cluster diagrammatically and the gray workers
    are the ones that are allocated to the topology. Now we are all set to try out
    the high availability test for Storm and Zookeeper. The tests for Storm and Zookeeper
    are as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 上图以图表方式描述了集群，灰色的工作进程是分配给拓扑的。现在我们已经准备好尝试Storm和Zookeeper的高可用性测试。Storm和Zookeeper的测试如下：
- en: '**Test 1** (all components are up and the topology is running): Kill the Nimbus
    node after the topology is submitted; you will notice that the topology will continue
    to execute normally.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试1**（所有组件都正常运行）：在提交拓扑后关闭Nimbus节点；您会注意到拓扑将继续正常执行。'
- en: '**Test 2** (all components are up and the topology is running): Kill one Zookeeper
    node and you will notice that the topology will continue to execute normally,
    because two of the other available Zookeepers have sufficient resources in terms
    of connections that can keep the Storm cluster up and running.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试2**（所有组件都正常运行）：关闭一个Zookeeper节点，您会注意到拓扑将继续正常执行，因为其他两个可用的Zookeeper有足够的资源来保持Storm集群正常运行。'
- en: '**Test 3** (all components are up and the topology is running): Kill two Zookeeper
    nodes and you will notice that the topology will continue to execute normally,
    because one of the other two available Zookeepers have sufficient resources in
    terms of connections that they can keep the Storm cluster up and running.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试3**（所有组件都正常运行）：关闭两个Zookeeper节点，您会注意到拓扑将继续正常执行，因为其他两个可用的Zookeeper有足够的资源来保持Storm集群正常运行。'
- en: '**Test 4** (all components are up and the topology is running): Kill supervisor
    2; now we have one of the gray workers on this node. So when this node goes down,
    the gray worker dies, and then because the second supervisor is not available
    it''s spawned again, this time on supervisor 1\. So all workers of the topology
    will be executing on one single supervisor now, but the system will continue to
    perform with limited resources but will not fail.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试4**（所有组件都正常运行，拓扑正在运行）：杀死监督者2；现在这个节点上有一个灰色的工作节点。因此当这个节点宕机时，灰色的工作节点会死掉，然后因为第二个监督者不可用，它会再次生成，这次在监督者1上。因此，拓扑的所有工作节点现在将在一个单独的监督者上执行，但系统将继续以有限的资源执行，但不会失败。'
- en: Guaranteed processing of the Storm cluster
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Storm集群的保证处理
- en: The next topic to discuss in this section is to see *Storm's guaranteed message
    processing in action*. We discussed this concept in previous chapters, but to
    understand it practically, I didn't go into depth because I wanted to introduce
    you all to the AMQP spout first. Now let's go back to the example we discussed
    in [Chapter 2](part0020_split_000.html#page "Chapter 2. Getting Started with Your
    First Topology"), *Getting Started with Your First Topology*.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讨论的下一个主题是看*Storm的保证消息处理如何运作*。我们在之前的章节中讨论过这个概念，但为了实际理解它，我没有深入讨论，因为我想先向大家介绍AMQP
    spout。现在让我们回到我们在[第2章](part0020_split_000.html#page "第2章. 开始你的第一个拓扑")中讨论的例子，*开始你的第一个拓扑*。
- en: 'Now as depicted in the following figure, the dash arrow flow shows that the
    events that fail to process are re-queued to the queue:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如下图所示，虚线箭头流显示未能处理的事件被重新排队到队列中：
- en: '![Guaranteed processing of the Storm cluster](img/00045.jpeg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![Storm集群的保证处理](img/00045.jpeg)'
- en: Now let's tweak our `wordCount` topology a bit where we had added `AMQPRecvSpout`
    to fail the events, and see where they actually show up. Let's assume I used `FixedEmitter`
    to emit 10 events into the queue. Now I tweak my `wordCount` bolt and induce artificial
    sleep for five minutes in the execute method, so that every event is held there
    for 300 seconds (using `Thread.sleep(300)`). This will lead to its timeout as
    the default event timeout is 60 seconds.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们稍微调整一下我们的`wordCount`拓扑，我们在其中添加了`AMQPRecvSpout`来使事件失败，并看看它们实际上出现在哪里。假设我使用`FixedEmitter`向队列中发出10个事件。现在我调整我的`wordCount`
    bolt，并在执行方法中引入人为的休眠，使每个事件在那里停留五分钟（使用`Thread.sleep(300)`）。这将导致它的超时，因为默认事件超时时间为60秒。
- en: Now when you run the topology, you will be able to see the events being re-queued
    back to RabbitMQ using the UI.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在当你运行拓扑时，你将能够看到事件通过UI重新排队回RabbitMQ。
- en: The Storm isolation scheduler
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Storm隔离调度程序
- en: The Storm isolation scheduler was released in Storm Version 0.8.2\. This was
    a very handy feature that is very actively being used ever since its release,
    in the case of the shared Storm cluster. Let's understand its working and capability
    through an example; say, we have a four supervisor node Storm cluster with four
    slots each, so in total I have 16 slots. Now I want to employ three Storm topologies
    here, say, Topo1, Topo2, and Topo3; each has four workers allocated to it.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Storm隔离调度程序是在Storm版本0.8.2中发布的。自从发布以来，这是一个非常方便的功能，非常积极地被使用，特别是在共享Storm集群的情况下。让我们通过一个例子来了解它的工作和能力；假设我们有一个由四个监督者节点组成的Storm集群，每个节点有四个插槽，所以总共有16个插槽。现在我想在这里使用三个Storm拓扑，比如Topo1、Topo2和Topo3；每个拓扑都分配了四个工作节点。
- en: 'So by probable default, the scheduling behavior of the Storm distribution will
    be as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，按照可能的默认设置，Storm分发的调度行为将如下所示：
- en: '|   | Supervisor 1 | Supervisor 2 | Supervisor 3 | Supervisor 4 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|   | 监督者1 | 监督者2 | 监督者3 | 监督者4 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **Topo1** | Worker 1 | Worker 2 | Worker 3 | Worker 4 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| **Topo1** | Worker 1 | Worker 2 | Worker 3 | Worker 4 |'
- en: '| **Topo2** | Worker 2 | Worker 1 | Worker 1 | Worker 1 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| **Topo2** | Worker 2 | Worker 1 | Worker 1 | Worker 1 |'
- en: '| **Topo3** | Worker 3 | Worker 3 | Worker 2 | Worker 2 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| **Topo3** | Worker 3 | Worker 3 | Worker 2 | Worker 2 |'
- en: Storm will respect load distribution and will spawn one worker of each topology
    on each node.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Storm将尊重负载分配，并在每个节点上生成每个拓扑的一个工作节点。
- en: Now let's tweak the scenario a bit and introduce a requirement that Topo1 is
    a very resource-intensive topology. (I want to dedicate one supervisor entirely
    to this one so that I save on network hops.) This could be attained by the use
    of the isolation scheduler.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们稍微调整一下情景，并引入一个要求，即Topo1是一个非常资源密集型的拓扑结构。（我想要将一个监督者完全专门用于这个，这样我就可以节省网络跳数。）这可以通过使用隔离调度程序来实现。
- en: 'We will have to make the following entry in the `storm.yaml` file of each Storm
    node in the cluster (Nimbus and supervisor):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在集群中每个Storm节点（Nimbus和监督者）的`storm.yaml`文件中进行以下条目的设置：
- en: '[PRE17]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The cluster is required to be restarted for this setting to take effect. This
    setting means that we have dedicated two supervisor nodes to Topo1 and it will
    be no longer be shared with other topologies being submitted to the cluster. This
    will also ensure a viable solution to multitenancy problems encountered in production.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 需要重新启动集群才能使此设置生效。这个设置意味着我们已经将两个监督者节点专门用于Topo1，并且它将不再与提交到集群的其他拓扑共享。这也将确保在生产中遇到的多租户问题有一个可行的解决方案。
- en: 'The other two supervisors will be shared amongst Topo2 and Topo3\. The probable
    distribution will be as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 其他两个监督者将被Topo2和Topo3共享。可能的分配将如下所示：
- en: '|   | Supervisor 1 | Supervisor 2 | Supervisor 3 | Supervisor 4 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|   | 监督者1 | 监督者2 | 监督者3 | 监督者4 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **Topo1** | Worker 1Worker 2 | Worker 1Worker 2 |   |   |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| **Topo1** | Worker 1Worker 2 | Worker 1Worker 2 |   |   |'
- en: '| **Topo2** |   |   | Worker 1Worker 2 | Worker 1Worker 2 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| **Topo2** |   |   | Worker 1Worker 2 | Worker 1Worker 2 |'
- en: '| **Topo3** |   |   | Worker 3Worker 4 | Worker 3Worker 4 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| **Topo3** |   |   | Worker 3Worker 4 | Worker 3Worker 4 |'
- en: So, as evident from the preceding table, Topo1 will be isolated to Supervisor1
    and 2 while Top2 and Topo3 will share the remaining eight slots on the Supervisor3
    and 4.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从上表可以明显看出，Topo1将被隔离到监督者1和2，而Top2和Topo3将共享监督者3和4上的其余八个插槽。
- en: Quiz time
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测验时间
- en: 'Q.1 State whether the following sentences are true or false:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Q.1 判断以下句子是真是假：
- en: AMQP is a STOMP protocol.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AMQP是STOMP协议。
- en: RabbitMQ is not fail-safe.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RabbitMQ不是故障安全的。
- en: An AMQP client is required to publish to RabbitMQ.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要AMQP客户端来发布到RabbitMQ。
- en: A mirrored queue can recover from the failure of nodes in a cluster.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 镜像队列可以从集群中节点的故障中恢复。
- en: 'Q.2 Fill in the blanks:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Q.2 填空：
- en: _______________ is the exchange where messages are delivered based on the routing
    key.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: _______________ 是根据路由键传递消息的交换机。
- en: _______________ is the exchange where messages are broadcasted.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: _______________ 是消息被广播的交换机。
- en: The ___________ is an implementation of the Storm spout on the AMQP consumer
    protocol.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: _______________ 是AMQP消费者协议上Storm spout的实现。
- en: 'Q.3 Execute the `WordCount` topology on a three node Storm cluster (one nimbus
    and two supervisor nodes) clubbed with a two node RabbitMQ cluster:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Q.3 在一个三节点的Storm集群（一个nimbus和两个supervisor节点）上执行`WordCount`拓扑，与一个两节点的RabbitMQ集群结合在一起：
- en: Try out various failure scenarios mentioned in the *Building high availability
    of components* section
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试各种在*构建组件的高可用性*部分提到的故障场景
- en: Induce an artificial delay in message processing to calibrate the guaranteed
    processing of the Storm topology
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在消息处理中引入人工延迟，以校准Storm拓扑的保证处理
- en: Summary
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you have understood the RabbitMQ implementation of the AMQP
    protocol. We completed the cluster setup and integrated the output of the Storm
    topology with the queues. We also explored and practically tested the scenarios
    of high availability and reliability for both RabbitMQ and Storm. We closed the
    chapter by touching upon the Storm schedulers. In the next chapter, we will get
    acquainted with Storm persistence using Cassandra.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您已经了解了AMQP协议的RabbitMQ实现。我们完成了集群设置，并将Storm拓扑的输出与队列集成在一起。我们还探索并实际测试了RabbitMQ和Storm的高可用性和可靠性场景。我们通过涉及Storm调度器来结束了本章。在下一章中，我们将了解使用Cassandra的Storm持久化。
