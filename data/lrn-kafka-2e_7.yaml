- en: Chapter 7. Operationalizing Kafka
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章。Kafka的操作
- en: In this last chapter, we will be exploring tools available for Kafka cluster
    administration and Kafka topic administration. Additionally, we will also be discussing
    in brief Kafka cluster mirroring and Kafka's integration with third-party tools.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后，我们将探讨用于Kafka集群管理和Kafka主题管理的工具。此外，我们还将简要讨论Kafka集群镜像和Kafka与第三方工具的集成。
- en: 'The main focus areas for this chapter are as follows:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要重点领域如下：
- en: Kafka administration tools
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka管理工具
- en: Kafka cluster mirroring
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka集群镜像
- en: Integration with other tools
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他工具的集成
- en: Kafka administration tools
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kafka管理工具
- en: There are a number of tools or utilities provided by Kafka 0.8.x to administrate
    features such as cluster management, topic tools, cluster mirroring, and so on.
    Let's have a quick look at these tools.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 0.8.x提供了许多用于管理集群、主题工具、集群镜像等功能的工具或实用程序。让我们快速看一下这些工具。
- en: Kafka cluster tools
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kafka集群工具
- en: Cluster management is one of the prime responsibilities of the Kafka administrator.
    Once the cluster is started successfully, it needs to be maintained for activities
    such as server shutdown, leader balancing, replication, cluster mirroring, and
    expanding Kafka clusters. Let's talk about these in detail.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 集群管理是Kafka管理员的主要责任之一。一旦集群成功启动，就需要对其进行维护，以进行服务器关闭、领导平衡、复制、集群镜像和扩展Kafka集群等活动。让我们详细讨论这些。
- en: As we have learned from Kafka's design, in replication multiple partitions can
    have replicated data, and out of these multiple replicas, one replica acts as
    a lead, and the rest of the replicas act as in-sync followers of the lead replica.
    In the event of non-availability of a lead replica, maybe due to broker shutdown,
    a new lead replica needs to be selected.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们从Kafka的设计中了解到，在复制中，多个分区可以具有复制的数据，而在这些多个副本中，一个副本充当领导，其余的副本充当领导副本的同步跟随者。在领导副本不可用的情况下，可能是由于代理关闭，需要选择新的领导副本。
- en: For scenarios such as shutting down the Kafka broker for maintenance activity,
    election of the new leader is done sequentially, and this causes significant read/write
    operations for Zookeeper. In any big cluster with many topics/partitions, sequential
    election of lead replicas causes delay in availability.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像关闭Kafka代理进行维护活动这样的场景，新领导的选举是顺序进行的，这会导致Zookeeper的大量读/写操作。在具有许多主题/分区的大集群中，领导副本的顺序选举会导致可用性延迟。
- en: To ensure high availability, Kafka provides tools for a controlled shutdown
    of Kafka brokers. If the broker has the lead partition shut down, this tool transfers
    the leadership proactively to other in-sync replicas on another broker. If there
    is no in-sync replica available, the tool will fail to shut down the broker in
    order to ensure no data is lost.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保高可用性，Kafka提供了用于受控关闭Kafka代理的工具。如果代理具有领导分区关闭，此工具将主动将领导权转移到另一个代理上的其他同步副本。如果没有可用的同步副本，该工具将无法关闭代理，以确保不会丢失数据。
- en: 'The following is the format for using this tool:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用此工具的格式：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The ZooKeeper host and the broker ID that need to be shut down are mandatory
    parameters. We can also specify optional parameters, the number of retries (`--num.retries,
    default value 0`) and the retry interval in milliseconds (`--retry.interval.ms,
    default value 1000`) with a controlled shutdown tool.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 需要关闭的ZooKeeper主机和代理ID是必需的参数。我们还可以指定可选参数，重试次数（`--num.retries，默认值0`）和重试间隔（以毫秒为单位，`--retry.interval.ms，默认值1000`）。
- en: 'When a server is stopped gracefully, it will sync all its logs automatically
    to disk to avoid any log recovery whenever it is restarted again, as log recovery
    is a time-consuming activity. Before shutting down, it also migrates the leader
    partitions on the server to other replicas. This ensures minimal downtime for
    each partition (up to a few milliseconds). Controlled shutdown of a server also
    needs to be enabled as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当服务器正常停止时，它将自动将所有日志同步到磁盘，以避免在重新启动时进行任何日志恢复，因为日志恢复是一项耗时的活动。在关闭之前，它还将领导分区迁移到其他副本。这确保了每个分区的最小停机时间（最多几毫秒）。还需要启用服务器的受控关闭，如下所示：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Next, in any big Kafka cluster with many brokers, topics, and partitions, Kafka
    ensures that the preferred/lead replicas for partitions are equally distributed
    among the brokers. However, if a shutdown (controlled as well) or broker failure
    happens, this equal distribution of lead replicas might get imbalanced within
    the cluster.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在任何具有许多代理、主题和分区的大型Kafka集群中，Kafka确保分区的首选/领导副本在代理之间均匀分布。但是，如果发生关闭（受控或非受控）或代理故障，领导副本的均衡分布可能会在集群内失衡。
- en: Kafka provides a tool that is used to maintain a balanced distribution of lead
    replicas within the Kafka cluster across available brokers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka提供了一个工具，用于在Kafka集群中的可用代理之间维护平衡的领导副本分布。
- en: 'The following is the format for using this tool:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用此工具的格式：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This tool updates the ZooKeeper path with the list of topic partitions whose
    leader needs to be moved to the preferred replica list. Once the list is updated,
    the controller retrieves the list of preferred topic partitions from ZooKeeper
    asynchronously and, for each topic partition, controller verifies whether the
    preferred replica is the leader. If controller finds that the preferred replica
    is not the leader and is not present in the ISR list, it raises a request to the
    broker to make the preferred replica the leader for the partition to create a
    balanced distribution. If the preferred replica is not in the ISR list, the controller
    fails the operation to avoid any data loss. For this tool, the list of topic partitions
    in a JSON file format can also be provided as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此工具使用主题分区列表更新ZooKeeper路径，其中需要将领导者移动到首选副本列表。更新列表后，控制器会异步从ZooKeeper检索首选主题分区列表，并对于每个主题分区，控制器验证首选副本是否为领导者。如果控制器发现首选副本不是领导者并且不在ISR列表中，则会向代理发出请求，以使首选副本成为分区的领导者，以创建平衡的分布。如果首选副本不在ISR列表中，控制器将失败操作以避免任何数据丢失。对于此工具，还可以提供JSON文件格式的主题分区列表，如下所示：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following is the format of the `topicPartitionList.json` file:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`topicPartitionList.json`文件的格式：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Adding servers
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加服务器
- en: In order to add servers to a Kafka cluster, a unique broker ID needs to be assigned
    to the new server to set up/start Kafka on the new servers. This way of adding
    a new server does not automatically assign any data partitions. Hence, a newly
    added server will not perform any work unless existing partitions are migrated
    to the server or new topics are created.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要向Kafka集群添加服务器，需要为新服务器分配一个唯一的代理ID，以在新服务器上设置/启动Kafka。这种添加新服务器的方式不会自动分配任何数据分区。因此，除非将现有分区迁移到服务器或创建新主题，否则新添加的服务器将不执行任何工作。
- en: 'The migration process for existing partitions is initiated manually by the
    Kafka administrator, as admin has to find out which topics or partitions should
    be moved. Once the partitions are identified by the administrator, the partition
    reassignment tool (`bin/kafka-reassign-partitions.sh`) is used to move partitions
    across brokers, which takes care of everything. As a migration process, Kafka
    will make this newly added server a follower of the partition it is migrating.
    This allows the new server to fully replicate the existing data in that partition.
    Once the new server has fully replicated the partition''s contents and has become
    a part of the in-sync replica, one of the existing replicas will delete the partition''s
    data. The partition reassignment tool (`kafka-reassign-partitions.sh`) runs in
    three different modes:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现有分区的迁移过程由Kafka管理员手动启动，因为管理员必须找出应移动哪些主题或分区。一旦管理员确定了分区，就会使用分区重新分配工具（`bin/kafka-reassign-partitions.sh`）将分区移动到代理之间，该工具会处理一切。作为迁移过程，Kafka将使新添加的服务器成为正在迁移的分区的追随者。这允许新服务器完全复制该分区中的现有数据。一旦新服务器完全复制了分区的内容并成为同步副本的一部分，现有副本将删除分区的数据。分区重新分配工具（`kafka-reassign-partitions.sh`）以三种不同的模式运行：
- en: '`--generate`: In this mode, the tool generates a candidate reassignment to
    move all partitions of the specified topics to the new server based on the list
    of topics and brokers shared with the tool'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--generate`：在此模式下，工具根据与工具共享的主题和代理列表生成候选重新分配，以将指定主题的所有分区移动到新服务器'
- en: '--execute: In this mode, the tool starts the reassignment of partitions based
    on the user-provided reassignment plan specified with the `--reassignment-json-file`
    option'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --execute：在此模式下，工具根据用户提供的重新分配计划启动分区的重新分配，该计划由`--reassignment-json-file`选项指定
- en: '`--verify`: In this mode, the tool verifies the status (completed successfully/failed/in
    progress) of the reassignment for all partitions listed during the last `--execute`'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--verify`：在此模式下，工具验证上次`--execute`期间列出的所有分区的重新分配状态（成功完成/失败/进行中）'
- en: The partition reassignment tool can be used to move selected topics from the
    current set of brokers to newly added brokers (servers). Administrator should
    provide a list of topics to be moved to the new server and a target list of new
    broker IDs. This tool evenly distributes all partitions of a given topic across
    the new brokers and also moves the replicas for all partitions for the input list
    of topics.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 分区重新分配工具可用于将选定的主题从当前一组代理移动到新添加的代理（服务器）。管理员应提供要移动到新服务器的主题列表以及新代理ID的目标列表。该工具均匀分布给定主题的所有分区到新代理，并将输入主题列表的所有分区的副本移动到新代理。
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding command generates the assignment (`new-topic-reassignment.json`)
    plan to move all partitions for topics `kafkatopic` and `kafkatopic1` to the new
    set of brokers having IDs `4` and `5`. At the end of this move, all partitions
    for topics `foo1` and `foo2` will only exist on brokers `5` and `6`. To initiate
    the assignment, the `kafka-reassign-partitions.sh` tool is used:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令生成了分配（`new-topic-reassignment.json`）计划，将主题`kafkatopic`和`kafkatopic1`的所有分区移动到具有ID`4`和`5`的新一组代理中。在此移动结束时，主题`foo1`和`foo2`的所有分区将仅存在于代理`5`和`6`上。要启动分配，使用`kafka-reassign-partitions.sh`工具：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This tool can also be used to selectively move the partitions from the existing
    broker to the new broker:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此工具还可以用于有选择地将分区从现有代理移动到新代理：
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding command selectively moves some replicas for certain partitions
    to the new server. Once the reassignment is done, the operation can be verified:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令有选择地将某些分区的副本移动到新服务器。重新分配完成后，可以验证操作：
- en: '[PRE8]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To decommission any server from the Kafka cluster, the admin has to move the
    replica for all partitions hosted on the broker (server) to be decommissioned,
    to the remaining brokers with even distribution. The `kafka-reassign-partitions.sh`
    tool can also be used to increase the replication factor of the partition as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要从Kafka集群中停用任何服务器，管理员必须将托管在要停用的代理（服务器）上的所有分区的副本移动到剩余的代理中，以实现均匀分布。`kafka-reassign-partitions.sh`工具还可用于增加分区的复制因子，如下所示：
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The preceding command assumes that partition `0` of the `kafkatopic` topic has
    replication factor `1` that existed on broker 2; and now it increases the replication
    factor from `1` to `2` and also creates the new replica on broker 3.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令假设`kafkatopic`主题的分区`0`具有复制因子`1`，存在于broker 2；现在将复制因子从`1`增加到`2`，并在broker 3上创建新的副本。
- en: Kafka topic tools
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kafka主题工具
- en: By default, Kafka creates topics with a default number of partitions and replication
    factors (the default value is `1` for both). But, in real-life scenarios, we may
    need to define the number of partitions and replication factors more than once.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Kafka使用默认的分区数和复制因子创建主题（默认值为`1`）。但是，在实际场景中，我们可能需要多次定义分区数和复制因子。
- en: 'The following is the command to create a topic with specific parameters:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用特定参数创建主题的命令：
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the preceding command, the replication factor controls how many servers will
    replicate each message published by the message producer. For example, replication
    factor `3` means that up to two servers can fail before access is lost to the
    data. The partition count that enables parallelism for consumers reflects the
    number of logs the topic will be sharded into. Here, each partition must fit entirely
    on a single server. For example, if 10 partitions are defined for a topic, the
    full data set will be handled by no more than 10 servers excluding replicas.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述命令中，复制因子控制每个消息生产者发布的消息将由多少服务器复制。例如，复制因子`3`表示在丢失数据访问之前最多可以有两台服务器故障。启用消费者并行处理的分区计数反映了主题将被分片成的日志数量。在这里，每个分区必须完全适合单个服务器。例如，如果为一个主题定义了10个分区，则完整数据集将由不超过10台服务器处理，不包括副本。
- en: 'The Kafka topic utility `kafka-topics.sh` can also be used to alter the Kafka
    topic as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka主题实用程序`kafka-topics.sh`也可以用于修改Kafka主题，如下所示：
- en: '[PRE11]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the preceding command, 10 more partitions are added to the Kafka topic created
    in the previous example. Currently Kafka does not support reducing the number
    of partitions or changing the replication factor for topics. To delete the Kafka
    topic, the following command is used:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述命令中，Kafka主题的分区增加了10个。目前，Kafka不支持减少主题的分区数或更改复制因子。要删除Kafka主题，使用以下命令：
- en: '[PRE12]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Using the `kafka-topics.sh` Kafka topic utility, configuration can also be
    added to the Kafka topic as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`kafka-topics.sh` Kafka主题实用程序，也可以添加配置到Kafka主题，如下所示：
- en: '[PRE13]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To remove configuration from the Kafka topic, use the following command:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要从Kafka主题中删除配置，请使用以下命令：
- en: '[PRE14]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Kafka also provides a utility to search for the list of topics within the Kafka
    server. The List Topic tool provides a listing of topics and information about
    their partitions, replicas, or leaders by querying Zookeeper.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka还提供了一个实用程序来搜索Kafka服务器中的主题列表。列表主题工具通过查询Zookeeper提供主题列表和有关它们的分区、副本或领导者的信息。
- en: 'The following command obtains a list of topics:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令获取主题列表：
- en: '[PRE15]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'On execution of the preceding command, you should get the output shown in the
    following screenshot:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行上述命令时，您应该会得到以下截图中显示的输出：
- en: '![Kafka topic tools](img/3090OS_07_01.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![Kafka主题工具](img/3090OS_07_01.jpg)'
- en: 'The preceding console output shows that we can get information about the topic
    and partitions that have replicated data. The output from the previous screenshot
    can be explained as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 上述控制台输出显示，我们可以获取有关主题和复制数据的分区的信息。前面截图的输出可以解释如下：
- en: '`leader`: This is a randomly selected node for a specific portion of the partitions
    and is responsible for all reads and writes for this partition'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leader`：这是特定部分分区的随机选择节点，负责该分区的所有读写操作'
- en: '`replicas`: This represents the list of nodes that holds the log for a specified
    partition'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`replicas`：这代表保存指定分区日志的节点列表'
- en: '`isr`: This represents the subset of the in-sync replicas'' list that is currently
    alive and in sync with the leader'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`isr`：这代表当前活着并与领导者同步的同步副本列表的子集'
- en: Note that `kafkatopic` has two partitions (partitions `0` and `1`) with three
    replications, whereas `othertopic` has just one partition with two replications.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`kafkatopic`有两个分区（分区`0`和`1`）和三个副本，而`othertopic`只有一个分区和两个副本。
- en: 'While getting a list of Kafka topics, two optional arguments can also be provided
    as: `under-replicated-partitions` and `unavailable-partitions`. The `under-replicated-partitions`
    argument is used to get details of those topics/partitions that have replicas
    that are under-replicated. The `unavailable-partitions` argument is used to get
    details of those topics/partitions whose leader is not available.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在获取Kafka主题列表时，还可以提供两个可选参数：`under-replicated-partitions`和`unavailable-partitions`。`under-replicated-partitions`参数用于获取那些具有副本未复制的主题/分区的详细信息。`unavailable-partitions`参数用于获取那些领导者不可用的主题/分区的详细信息。
- en: Kafka cluster mirroring
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kafka集群镜像
- en: The Kafka mirroring feature is used to create a replication of an existing cluster—for
    example, replicating an active datacenter into a passive datacenter. Kafka provides
    a mirror maker tool for mirroring the source cluster into a target cluster.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka镜像功能用于创建现有集群的副本，例如，将活动数据中心复制到被动数据中心。Kafka提供了一个镜像制造工具，用于将源集群镜像到目标集群。
- en: 'The following diagram depicts the mirroring tool placement in architectural
    form:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了架构形式中镜像工具的放置：
- en: '![Kafka cluster mirroring](img/3090OS_07_02.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![Kafka集群镜像](img/3090OS_07_02.jpg)'
- en: In this architecture, the job of the mirror tool is to consume the messages
    from the source cluster and republish them on the target cluster using the embedded
    producer. A similar approach is used by the Kafka migration tool to migrate from
    the 0.7.x Kafka cluster to the 0.8.x Kafka cluster.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种架构中，镜像工具的作用是从源集群消费消息，并使用内嵌的生产者将它们重新发布到目标集群。Kafka迁移工具也使用类似的方法，从0.7.x Kafka集群迁移到0.8.x
    Kafka集群。
- en: 'To mirror the source cluster, bring up the target cluster and start the MirrorMaker
    processes as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了镜像源集群，启动目标集群并按以下方式启动MirrorMaker进程：
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The minimum parameters required to start the MirrorMaker tool successfully are
    one or more consumer configurations, a producer configuration, and either a whitelist
    or a blacklist as standard Java regex patterns—for example, mirroring two topics
    named `A` and `B` using `--whitelist 'A|B'` or mirroring all topics using `--whitelist
    '*'`. The `--blacklist` configuration can also be used as standard Java regex
    patterns to specify what to exclude while mirroring. It also requires the consumer
    of the mirror tool to connect to the source cluster's ZooKeeper, the producer
    to the mirror cluster's ZooKeeper, or the `broker.list` parameter.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 成功启动MirrorMaker工具所需的最小参数是一个或多个消费者配置、一个生产者配置，以及一个白名单或黑名单作为标准的Java正则表达式模式——例如，使用`--whitelist
    'A|B'`来镜像名为`A`和`B`的两个主题，或者使用`--whitelist '*'`来镜像所有主题。`--blacklist`配置也可以作为标准的Java正则表达式模式来指定在镜像时要排除的内容。它还需要镜像工具的消费者连接到源集群的ZooKeeper，生产者连接到镜像集群的ZooKeeper，或者`broker.list`参数。
- en: For high throughput, an asynchronous embedded producer configured in blocking
    mode is used. This ensures that messages will not be lost and the blocking producer
    will wait till the messages are written to the target cluster if the producer's
    queue is full. The producer's queue being full consistently indicates that the
    MirrorMaker is bottle-necked on republishing messages to the target mirror cluster
    and/or flushing messages to disk. The `--num.producers` option can also be used
    to represent a producer pool in the MirrorMaker to increase throughput as multiple
    producer requests can be handled by multiple consumption streams of the target
    cluster. The `--num.streams` option specifies the number of mirror consumer threads
    to create.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现高吞吐量，使用配置为阻塞模式的异步嵌入式生产者。这确保了消息不会丢失，并且阻塞生产者会等待，直到消息被写入目标集群，如果生产者的队列已满。生产者的队列一直满表示MirrorMaker在重新发布消息到目标镜像集群和/或将消息刷新到磁盘上受到了瓶颈的影响。`--num.producers`选项也可以用于在MirrorMaker中表示生产者池，以增加吞吐量，因为多个生产者请求可以由目标集群的多个消费流处理。`--num.streams`选项指定要创建的镜像消费者线程的数量。
- en: Mirroring is often used in cross data center scenarios and, in general, a high
    value is used for the socket buffer size (`socket.buffersize`) on the MirrorMaker's
    consumer configuration and `socket.send.buffer` on the source cluster broker configuration.
    Also, the MirrorMaker consumer's fetch size (`fetch.size`) should be higher than
    the consumer's socket buffer size. If `broker.list` is used in the producer configuration
    along with the hardware load balancer, configuration for the number of retry attempts
    on producer failures can also be provided.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 镜像通常用于跨数据中心的场景，并且通常在MirrorMaker的消费者配置上使用较高的套接字缓冲区大小（`socket.buffersize`）和源集群代理配置上的`socket.send.buffer`。此外，MirrorMaker消费者的获取大小（`fetch.size`）应该高于消费者的套接字缓冲区大小。如果在生产者配置中使用了`broker.list`以及硬件负载均衡器，还可以提供有关生产者故障重试尝试次数的配置。
- en: 'Kafka also provides tools to check the position of the consumer while mirroring
    or in general. This tool shows the position of all the consumers in a consumer
    group and how far behind the end of the log consumers are; it indicates how well
    cluster mirroring is performing. This tool can be used as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka还提供了用于检查镜像或一般情况下消费者位置的工具。该工具显示消费者组中所有消费者的位置以及消费者在日志末尾之后的距离；它指示集群镜像的执行情况。该工具可以按以下方式使用：
- en: '[PRE17]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Here the `--zkconnect` argument points to the source cluster's ZooKeeper (for
    example, the source data center). The `--topic` parameter is an optional parameter
    and, if the topic is not specified, then the tool prints information for all topics
    under the specified consumer group.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的`--zkconnect`参数指向源集群的ZooKeeper（例如，源数据中心）。`--topic`参数是一个可选参数，如果未指定主题，则工具将打印指定消费者组下所有主题的信息。
- en: Integration with other tools
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与其他工具的集成
- en: This section discusses the contributions by many contributors providing integration
    with Apache Kafka for various needs such as logging, packaging, cloud integration,
    and Hadoop integration.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讨论了许多贡献者的贡献，为Apache Kafka提供了与日志记录、打包、云集成和Hadoop集成等各种需求的集成。
- en: 'Camus ([https://github.com/linkedin/camus](https://github.com/linkedin/camus))
    which provides a pipeline from Kafka to HDFS. Under this project, a single MapReduce
    job performs the following steps to load data to HDFS in a distributed manner:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Camus ([https://github.com/linkedin/camus](https://github.com/linkedin/camus))提供了从Kafka到HDFS的管道。在这个项目下，一个单独的MapReduce作业执行以下步骤以分布式方式将数据加载到HDFS中：
- en: As a first step, it discovers the latest topics and partition offsets from ZooKeeper.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为第一步，它从ZooKeeper中发现最新的主题和分区偏移量。
- en: Each task in the MapReduce job fetches events from the Kafka broker and commits
    the pulled data along with the audit count to the output folders.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MapReduce作业中的每个任务从Kafka代理中获取事件，并将拉取的数据以及审核计数提交到输出文件夹。
- en: After the completion of the job, final offsets are written to HDFS and can be
    further consumed by subsequent MapReduce jobs.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作业完成后，最终偏移量被写入HDFS，并可以由后续的MapReduce作业进一步消费。
- en: Information about the consumed messages is also updated in the Kafka cluster.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有关已消费消息的信息也会更新到Kafka集群中。
- en: 'Some other useful contributions are:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一些其他有用的贡献包括：
- en: Automated deployment and configuration of Kafka and ZooKeeper on Amazon ([https://github.com/nathanmarz/kafka-deploy](https://github.com/nathanmarz/kafka-deploy))
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在亚马逊上自动部署和配置Kafka和ZooKeeper ([https://github.com/nathanmarz/kafka-deploy](https://github.com/nathanmarz/kafka-deploy))
- en: A logging utility ([https://github.com/leandrosilva/klogd2](https://github.com/leandrosilva/klogd2))
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个日志实用程序 ([https://github.com/leandrosilva/klogd2](https://github.com/leandrosilva/klogd2))
- en: A REST service for Mozilla Metrics ([https://github.com/mozilla-metrics/bagheera](https://github.com/mozilla-metrics/bagheera))
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mozilla Metrics的REST服务 ([https://github.com/mozilla-metrics/bagheera](https://github.com/mozilla-metrics/bagheera))
- en: Apache Camel-Kafka integration ([https://github.com/BreizhBeans/camel-kafka/wiki](https://github.com/BreizhBeans/camel-kafka/wiki))
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Camel-Kafka集成（[https://github.com/BreizhBeans/camel-kafka/wiki](https://github.com/BreizhBeans/camel-kafka/wiki)）
- en: Note
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For a detailed list of Kafka ecosystem tools, please refer to [https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem](https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Kafka生态系统工具的详细列表，请参阅[https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem](https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem)。
- en: Summary
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have added some more information about Kafka, such as its
    administrator tools, its integration, and Kafka non-Java clients.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们添加了关于Kafka的更多信息，比如它的管理员工具、集成以及Kafka非Java客户端。
- en: During this complete journey through Apache Kafka, we have touched upon many
    important facts about Kafka. You have learned the reason why Kafka was developed,
    its installation procedures, and its support for different types of clusters.
    We also explored the Kafka's design approach, and wrote a few basic producers
    and consumers.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次完整的Apache Kafka之旅中，我们触及了许多关于Kafka的重要事实。您已经了解了Kafka开发的原因、安装程序以及对不同类型集群的支持。我们还探讨了Kafka的设计方法，并编写了一些基本的生产者和消费者。
- en: Finally, we discussed Kafka's integration with technologies such as Hadoop and
    Storm.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们讨论了Kafka与Hadoop和Storm等技术的集成。
- en: The journey of evolution never ends.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 进化之旅永无止境。
