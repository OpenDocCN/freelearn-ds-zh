- en: Pipeline APIs for Spark ML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark ML的管道API
- en: In this chapter, you will learn the basics of ML pipelines and how they can
    be used in a variety of contexts. The pipeline is made up of several components.
    ML pipelines leverage the Spark platform and machine learning to provide key features
    for making the construction of large-scale learning pipelines simple.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习ML管道的基础知识以及它们如何在各种情境中使用。管道由几个组件组成。ML管道利用Spark平台和机器学习提供关键功能，使大规模学习管道的构建变得简单。
- en: Introduction to pipelines
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道介绍
- en: The pipeline API was introduced in Spark 1.2 and is inspired by scikit-learn.
    The concept of pipelines is to facilitate the creation, tuning, and inspection
    of ML workflows.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 管道API是在Spark 1.2中引入的，受到了scikit-learn的启发。管道的概念是为了便于创建、调整和检查ML工作流。
- en: ML pipelines provide a set of high-level APIs built on top of DataFrames that
    help users create and tune practical machine learning pipelines. Multiple algorithms
    from Spark machine learning can be combined into a single pipeline.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ML管道提供了一组建立在DataFrame之上的高级API，帮助用户创建和调整实用的机器学习管道。Spark机器学习中的多种算法可以组合成一个单一的管道。
- en: An ML pipeline normally involves a sequence of data pre-processing, feature
    extraction, model fitting, and validation stages.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ML管道通常涉及一系列数据预处理、特征提取、模型拟合和验证阶段。
- en: Let's take an example of text classification, where documents go through preprocessing
    stages, such as tokenization, segmentation and cleaning, extraction of feature
    vectors, and training a classification model with cross-validation. Many steps
    involving pre-processing and algorithms can be tied together using the pipeline.
    The pipeline typically sits above the ML library, orchestrating the workflow.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以文本分类为例，其中文档经过预处理阶段，如标记化、分割和清理，提取特征向量，并使用交叉验证训练分类模型。许多涉及预处理和算法的步骤可以使用管道连接在一起。管道通常位于ML库之上，编排工作流程。
- en: DataFrames
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据帧
- en: The Spark pipeline is defined by a sequence of stages where each stage is either
    a transformer or an estimator. These stages are run in order, and the input DataFrame
    is transformed as it passes through each stage.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Spark管道由一系列阶段定义，每个阶段都是一个转换器或估计器。这些阶段按顺序运行，输入DataFrame在通过每个阶段时进行转换。
- en: A DataFrame is a basic data structure or tensor that flows through the pipeline.
    A DataFrame is represented by a dataset of rows, and supports many types, such
    as numeric, string, binary, boolean, datetime, and so on.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame是通过管道流动的基本数据结构或张量。DataFrame由一系列行的数据集表示，并支持许多类型，如数值、字符串、二进制、布尔、日期时间等。
- en: Pipeline components
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道组件
- en: An ML pipeline or an ML workflow is a sequence of transformers and estimators
    arranged to fit a pipeline model to an input dataset.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ML管道或ML工作流是一系列转换器和估计器，安排成将管道模型拟合到输入数据集的顺序。
- en: Transformers
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换器
- en: A transformer is an abstraction that includes feature transformers and learned
    models. The transformer implements the `transform()` method, which converts one
    DataFrame to another.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 转换器是一个包括特征转换器和学习模型的抽象。转换器实现了`transform()`方法，将一个DataFrame转换为另一个DataFrame。
- en: A feature transformer takes a DataFrame, reads the text, maps it to a new column,
    and outputs a new DataFrame.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 特征转换器接收一个DataFrame，读取文本，将其映射到一个新列，并输出一个新的DataFrame。
- en: A learning model takes a DataFrame, reads the column containing feature vectors,
    predicts the label for each feature vector, and outputs a new DataFrame with the
     predicted labels.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 学习模型接收一个DataFrame，读取包含特征向量的列，预测每个特征向量的标签，并输出一个包含预测标签的新DataFrame。
- en: 'Custom transformers are required to follow the following steps:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义转换器需要遵循以下步骤：
- en: Implement the `transform` method.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现`transform`方法。
- en: Specify inputCol and outputCol.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定inputCol和outputCol。
- en: Accept `DataFrame` as input and return `DataFrame` as output.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接受`DataFrame`作为输入，并返回`DataFrame`作为输出。
- en: 'In nutshell, the **transformer**: `DataFrame =[transform]=> DataFrame`.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，**转换器**：`DataFrame =[transform]=> DataFrame`。
- en: Estimators
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估计器
- en: An estimator is an abstraction of a learning algorithm that fits a model on
    a dataset.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 估计器是对在数据集上拟合模型的学习算法的抽象。
- en: An estimator implements a `fit()` method that takes a DataFrame and produces
    a model. An example of a learning algorithm is `LogisticRegression`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 估计器实现了一个`fit()`方法，该方法接收一个DataFrame并生成一个模型。学习算法的一个例子是`LogisticRegression`。
- en: 'In a nutshell, the **estimator** is: `DataFrame =[fit]=> Model`.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，**估计器**是：`DataFrame =[fit]=> Model`。
- en: 'In the following example, `PipelineComponentExample` introduces the concepts
    of transformers and estimators:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，`PipelineComponentExample`介绍了转换器和估计器的概念：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You will see the following output:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下输出：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Code listing:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单：
- en: '[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/textclassifier/PipelineComponentExample.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/textclassifier/PipelineComponentExample.scala)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/textclassifier/PipelineComponentExample.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/textclassifier/PipelineComponentExample.scala)'
- en: How pipelines work
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道的工作原理
- en: We run a sequence of algorithms to process and learn from a given dataset. For
    example, in text classification, we split each document into words and convert
    the words into a numerical feature vector. Finally, we learn a predictive model
    using this feature vector and labels.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们运行一系列算法来处理和学习给定的数据集。例如，在文本分类中，我们将每个文档分割成单词，并将单词转换为数值特征向量。最后，我们使用这个特征向量和标签学习一个预测模型。
- en: Spark ML represents such a workflow as a pipeline, which consists of a sequence
    of PipelineStages (transformers and estimators) to be run in a particular order.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML将这样的工作流程表示为一个管道，它由一系列PipelineStages（转换器和估计器）组成，按特定顺序运行。
- en: Each stage in *PipelineStages* is one of the components, either a transformer
    or an estimator. The stages are run in a particular order while the input DataFrame
    flows through the stages.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*PipelineStages*中的每个阶段都是组件之一，可以是转换器或估计器。在输入DataFrame通过阶段流动时，阶段按特定顺序运行。'
- en: The following images are taken from [https://spark.apache.org/docs/latest/ml-pipeline.html#dataframe](https://spark.apache.org/docs/latest/ml-pipeline.html#dataframe).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片来自[https://spark.apache.org/docs/latest/ml-pipeline.html#dataframe](https://spark.apache.org/docs/latest/ml-pipeline.html#dataframe)。
- en: 'In the following figure, the** dp**Text document pipeline demonstrates the
    document workflow where Tokenizer, Hashing, and Logistic Regression are the components
    of the pipeline. The `Pipeline.fit()` method shows how the raw text gets transformed
    through the pipeline:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，**dp**文档管道演示了文档工作流程，其中Tokenizer、Hashing和Logistic Regression是管道的组件。`Pipeline.fit()`方法显示了原始文本如何通过管道进行转换：
- en: '![](img/image_12_001.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_001.png)'
- en: When the `Pipeline.fit()` method is called, at the first stage, the raw text
    is tokenized into words using the **Tokenizer** transformer, and in the second
    stage, words are converted to the feature vector using the term frequency transformer.
    In the final stage, the `fit()` method is called on the **Estimator Logistic Regression**
    to get the **Logistic Regression Model** (PipelineModel) over the feature vectors.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当调用`Pipeline.fit()`方法时，在第一个阶段，原始文本使用**Tokenizer**转换器被标记为单词，然后在第二个阶段，单词使用词频转换器转换为特征向量。在最后一个阶段，对**Estimator
    Logistic Regression**调用`fit()`方法以获得特征向量上的**Logistic Regression Model**（PipelineModel）。
- en: 'The Pipeline is an estimator, and after `fit()` is run it, produces a PipelineModel,
    which is a transformer:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 管道是一个估计器，在运行`fit()`之后，它会产生一个PipelineModel，这是一个转换器：
- en: '![](img/image_12_002.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_002.png)'
- en: '`PipelineModels.transform` method is called on test data and predictions are
    made as shown.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试数据上调用`PipelineModels.transform`方法并进行预测。
- en: Pipelines can be linear that is, stages are specified as ordered array or non-linear
    where the data flow forms a **directed acyclic graph** (**DAG**). Pipelines and
    PipelineModels instead perform runtime checking before actually running the pipeline.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 管道可以是线性的，即阶段被指定为有序数组，也可以是非线性的，其中数据流形成**有向无环图**（**DAG**）。管道和PipelineModels在实际运行管道之前执行运行时检查。
- en: 'The DAG pipeline example is shown here:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: DAG管道示例如下：
- en: '![](img/image_12_003.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_003.png)'
- en: 'The following example `TextClassificationPipeline` introduces the concepts
    of transformers and estimators:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例`TextClassificationPipeline`介绍了转换器和估计器的概念：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You will see the following output:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下输出：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Code listing: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/textclassifier/TextClassificationPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/textclassifier/TextClassificationPipeline.scala)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单：[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/textclassifier/TextClassificationPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/textclassifier/TextClassificationPipeline.scala)
- en: Machine learning pipeline with an example
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带有示例的机器学习管道
- en: As discussed in the previous sections, one of the biggest features in the new
    ML library is the introduction of the pipeline. Pipelines provide a high-level
    abstraction of the machine learning flow and greatly simplify the complete workflow.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前几节讨论的那样，新的ML库中最大的特性之一是引入了管道。管道提供了机器学习流程的高级抽象，并极大简化了整个工作流程。
- en: We will demonstrate the process of creating a pipeline in Spark using the `StumbleUpon`
    dataset.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示在Spark中使用`StumbleUpon`数据集创建管道的过程。
- en: The dataset used here can be downloaded from [http://www.kaggle.com/c/stumbleupon/data](http://www.kaggle.com/c/stumbleupon/data).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此处使用的数据集可以从[http://www.kaggle.com/c/stumbleupon/data](http://www.kaggle.com/c/stumbleupon/data)下载。
- en: Download the training data (`train.tsv`)--you will need to accept the terms
    and conditions before downloading the dataset. You can find more information about
    the competition at [http://www.kaggle.com/c/stumbleupon](http://www.kaggle.com/c/stumbleupon).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下载训练数据（`train.tsv`）--您需要在下载数据集之前接受条款和条件。您可以在[http://www.kaggle.com/c/stumbleupon](http://www.kaggle.com/c/stumbleupon)找到有关比赛的更多信息。
- en: 'Here is a glimpse of the `StumbleUpon` dataset stored as a temporary table
    using Spark SQLContext:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是将`StumbleUpon`数据集存储为Spark SQLContext临时表的一瞥：
- en: '![](img/image_12_004.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_004.png)'
- en: 'Here is a visualization of the `StumbleUpon` dataset:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`StumbleUpon`数据集的可视化：
- en: '![](img/image_12_005.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_005.png)'
- en: StumbleUponExecutor
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: StumbleUponExecutor
- en: 'The `StumbleUponExecutor` object can be used to choose and run the respective
    classification model, for example, to run `LogisiticRegression` and execute the
    logistic regression pipeline or set the program argument as `LR`. For other commands,
    refer to the following code snippet:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`StumbleUponExecutor`对象可用于选择和运行相应的分类模型，例如运行`LogisiticRegression`并执行逻辑回归管道，或将程序参数设置为`LR`。有关其他命令，请参阅以下代码片段：'
- en: 'Before we proceed, a few words on the Logistic Regression estimator. Logistic
    Regression works for classification problems where classes are nearly linearly
    separable. It searches for a single linear decision boundary in the feature space.
    There are two types of logistic regression estimators available in Spark: binomial
    logistic regression estimators to predict a binary outcome, and multinomial logistic
    regression estimators to predict a multiclass outcome.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，先简要介绍一下逻辑回归估计器。逻辑回归适用于类别几乎是线性可分的分类问题。它在特征空间中寻找单一的线性决策边界。Spark中有两种类型的逻辑回归估计器：二项逻辑回归估计器用于预测二元结果，多项逻辑回归估计器用于预测多类结果。
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Code listing: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/StumbleUponExecutor.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/StumbleUponExecutor.scala)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单：[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/StumbleUponExecutor.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/StumbleUponExecutor.scala)
- en: '**Decision Tree Pipeline: **Pipeline uses a decision tree estimator to classify
    the StumbleUpon dataset as part of the ML workflow.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策树管道：**管道使用决策树估计器对StumbleUpon数据集进行分类，作为ML工作流的一部分。'
- en: 'A decision tree estimator in Spark essentially partitions the feature space
    into half-spaces using axis-aligned linear decision boundaries. The effect is
    that we have a non-linear decision boundary, possibly more than one:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark中，决策树估计器基本上使用轴对齐的线性决策边界将特征空间划分为半空间。效果是我们有一个非线性决策边界，可能不止一个：
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You will see the following output displayed:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下输出显示：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Code listing: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/DecisionTreePipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/DecisionTreePipeline.scala)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单：[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/DecisionTreePipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/DecisionTreePipeline.scala)
- en: 'The visualization of predicted data in a 2-dimensional scatter plot is shown
    here:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显示了2维散点图中预测数据的可视化：
- en: '![](img/image_12_006.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_006.png)'
- en: 'The visualization of the actual data in a 2 dimensional scatter plot is shown
    here:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显示了2维散点图中实际数据的可视化：
- en: '![](img/image_12_007.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_007.png)'
- en: '**Naive Bayes Pipeline: **Pipeline uses a naive bayes estimator to classify
    the StumbleUpon dataset as part of the ML workflow.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**朴素贝叶斯管道：**管道使用朴素贝叶斯估计器对StumbleUpon数据集进行分类，作为ML工作流的一部分。'
- en: 'A Naive Bayes estimator considers the presence of a particular feature in a
    class to be unrelated to the presence of any other feature. The Naive Bayes model
    is simple to build and especially useful for very large data sets:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯估计器认为类中特定特征的存在与任何其他特征的存在无关。朴素贝叶斯模型易于构建，特别适用于非常大的数据集：
- en: '[PRE7]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You will see the following output displayed:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下输出显示：
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Code listing: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/NaiveBayesPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/NaiveBayesPipeline.scala)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单：[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/NaiveBayesPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/NaiveBayesPipeline.scala)
- en: 'A visualization of the predicted data in a 2-dimensional scatter plot is shown
    here:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显示了2维散点图中预测数据的可视化：
- en: '![](img/image_12_008.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_008.png)'
- en: 'A visualization of the actual data in a 2 dimensional scatter plot is shown
    here:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显示了2维散点图中实际数据的可视化：
- en: '![](img/image_12_009.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_009.png)'
- en: '**Gradient Boosted Pipeline : **Pipeline uses Gradient Boosted Tree estimator
    to classify StumbleUpon dataset as part of ML workflow.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**梯度提升管道：**管道使用梯度提升树估计器对StumbleUpon数据集进行分类，作为ML工作流的一部分。'
- en: A Gradient Boosted Tree Estimator is a machine learning method for regression
    and classification problems. Both **Gradient-Boosted Trees** (**GBTs**) and Random
    Forests are algorithms for learning ensembles of trees. GBTs iteratively train
    decision trees to minimize a loss function. spark.mllib supports GBTs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度提升树估计器是用于回归和分类问题的机器学习方法。**梯度提升树**（GBTs）和随机森林都是学习树集成的算法。GBTs迭代训练决策树以最小化损失函数。spark.mllib支持GBTs。
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You will see the following output displayed:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下输出显示：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Code listing: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/GradientBoostedTreePipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/GradientBoostedTreePipeline.scala)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单：[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/GradientBoostedTreePipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_12/2.0.0/spark-ai-apps/src/main/scala/org/stumbleuponclassifier/GradientBoostedTreePipeline.scala)
- en: 'Visualization of predictions in a 2-dimensional scatter plot is shown in the
    here:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显示了2维散点图中预测的可视化：
- en: '![](img/image_12_010.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_010.png)'
- en: 'Visualization of actual data in 2 dimensional scatter plot is shown in the
    following:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下显示了2维散点图中实际数据的可视化：
- en: '![](img/image_12_011.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_011.png)'
- en: Summary
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the basics of Spark ML Pipeline and its components.
    We saw how to train models on input DataFrame and how to evaluate their performance
    using standard metrics and measures while running them through spark ML pipeline
    APIs. We explored how to apply some of the techniques like transformers and estimators.
    Finally, we investigated the pipeline API by applying different algorithms on
    the StumbleUpon dataset from Kaggle.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了Spark ML Pipeline及其组件的基础知识。我们看到如何在输入DataFrame上训练模型，以及如何通过运行它们通过spark
    ML管道API来评估它们的性能，使用标准指标和度量标准。我们探讨了如何应用一些技术，如转换器和估计器。最后，我们通过在Kaggle的StumbleUpon数据集上应用不同的算法来调查管道API。
- en: Machine Learning is the rising star in the industry. It has certainly addressed
    many business problems and use cases. We hope that our readers will find new and
    innovative ways to make these approaches more powerful and extend the journey
    to understand the principles that hold learning and intelligence. For further
    practice and reading on Machine Learning and Spark refer [https://www.kaggle.com](https://www.kaggle.com)
    and [https://databricks.com/spark/](https://databricks.com/spark/) respectively.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是行业中的新星。它确实解决了许多业务问题和用例。我们希望我们的读者能够找到新的创新方式，使这些方法更加强大，并延伸了解支撑学习和智能的原则的旅程。有关机器学习和Spark的进一步练习和阅读，请参考[https://www.kaggle.com](https://www.kaggle.com)和[https://databricks.com/spark/](https://databricks.com/spark/)。
