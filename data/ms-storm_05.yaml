- en: Trident Topology and Uses
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Trident拓扑和用途
- en: 'In the previous chapter, we covered an overview of Trident. In this chapter,
    we are going to cover the development of a Trident topology. Here are the important
    points we are going to cover in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了Trident的概述。在本章中，我们将介绍Trident拓扑的开发。以下是本章将要涵盖的重点：
- en: The Trident `groupBy` operation
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident `groupBy`操作
- en: Non-transactional topology
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非事务拓扑
- en: Trident hello world topology
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident hello world拓扑
- en: Trident state
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident状态
- en: Distributed RPC
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式RPC
- en: When to use Trident
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 何时使用Trident
- en: Trident groupBy operation
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Trident groupBy操作
- en: The `groupBy` operation doesn't involve any repartitioning. The `groupBy` operation
    converts the input stream into a grouped stream. The main function of the `groupBy`
    operation is to modify the behavior of subsequent aggregate functions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '`groupBy`操作不涉及任何重分区。`groupBy`操作将输入流转换为分组流。`groupBy`操作的主要功能是修改后续聚合函数的行为。'
- en: '![](img/00037.gif)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00037.gif)'
- en: groupBy before partitionAggregate
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在分区聚合之前进行分组
- en: If the `groupBy` operation is used before a `partitionAggregate`, then the `partitionAggregate`
    will run the `aggregate` on each group created within the partition.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在`partitionAggregate`之前使用`groupBy`操作，则`partitionAggregate`将在分区内创建的每个组上运行`aggregate`。
- en: groupBy before aggregate
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在聚合之前进行分组
- en: If the `groupBy` operation is used before an `aggregate`, then input tuples
    is first repartition and then perform the `aggregate` operation on each group.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在`aggregate`之前使用`groupBy`操作，则首先对输入元组进行重分区，然后对每个组执行`aggregate`操作。
- en: Non-transactional topology
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非事务拓扑
- en: 'In non-transactional topology, a spout emits a batch of tuples and doesn''t
    guarantee what''s in each batch. With a processing mechanism, we can divide the
    pipeline into two categories:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在非事务拓扑中，spout发出一批元组，并不保证每个批次中有什么。通过处理机制，我们可以将管道分为两类：
- en: '**At-most-once-processing**: In this type of topology, failed tuples are not
    retried. Hence, the spout does not wait for an acknowledgment.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**至多一次处理**：在这种类型的拓扑中，失败的元组不会被重试。因此，spout不会等待确认。'
- en: '**At-least-once-processing**: Failed tuples are retried in the processing pipeline.
    Hence, this type of topology guarantees that every tuple that enters the processing
    pipeline must be processed at least once.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**至少一次处理**：处理管道中的失败元组将被重试。因此，这种类型的拓扑保证进入处理管道的每个元组至少被处理一次。'
- en: We can write a non-transactional spout by implementing the `org.apache.storm.trident.spout.IBatchSpout`
    interface.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过实现`org.apache.storm.trident.spout.IBatchSpout`接口来编写一个非事务spout。
- en: 'This example shows how we can write a Trident spout:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子展示了如何编写一个Trident spout：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `FakeTweetSpout` class implements the `org.apache.storm.trident.spout.IBatchSpout`
    interface. The construct of `FakeTweetSpout(intbatchSize)` takes `batchSize` as
    an argument. If `batchSize` is `3`, then every batch emitted by `FakeTweetSpout`
    class contains three tuples. The `recordGenerator` method contains logic to generate
    the fake tweet. Here is the sample fake tweet:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`FakeTweetSpout`类实现了`org.apache.storm.trident.spout.IBatchSpout`接口。`FakeTweetSpout(intbatchSize)`的构造以`batchSize`作为参数。如果`batchSize`为`3`，则`FakeTweetSpout`类发出的每个批次包含三个元组。`recordGenerator`方法包含生成虚假推文的逻辑。以下是示例虚假推文：'
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `getOutputFields` method returns two fields, `text` and `Country`. The `emitBatch(long
    batchId, TridentCollector collector)` method uses the `batchSize` variable to
    decide the number of tuples in each batch and emits a batch into the processing
    pipeline.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`getOutputFields`方法返回两个字段，`text`和`Country`。`emitBatch(long batchId, TridentCollector
    collector)`方法使用`batchSize`变量来决定每个批次中的元组数量，并将一批发出到处理管道中。'
- en: The `batchesMap` collection contains `batchId` as a key and the batch of tuples
    as a value. All the batches emitted by `emitBatch(long batchId, TridentCollector
    collector)` will be added into `batchesMap`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`batchesMap`集合包含`batchId`作为键和元组批次作为值。`emitBatch(long batchId, TridentCollector
    collector)`发出的所有批次将被添加到`batchesMap`中。'
- en: The `ack(long batchId)` method receives `batchId` as an acknowledgment, and
    will remove the corresponding batch from `batchesMap`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`ack(long batchId)`方法接收`batchId`作为确认，并将从`batchesMap`中删除相应的批次。'
- en: Trident hello world topology
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Trident hello world拓扑
- en: 'This section explains how we can write a Trident hello world topology. Perform
    the following steps to create Trident hello world topology:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了如何编写Trident hello world拓扑。执行以下步骤创建Trident hello world拓扑：
- en: Create a Maven project by using `com.stormadvance` as the `groupId` and `storm_trident`
    as the `artifactId`.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`com.stormadvance`作为`groupId`和`storm_trident`作为`artifactId`创建一个Maven项目。
- en: 'Add the following dependencies and repositories to the `pom.xml` file:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下依赖项和存储库添加到`pom.xml`文件中：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create a `TridentUtility` class in a `com.stormadvance.storm_trident` package.
    This class contains the Trident filter and function that we are going to use in
    the Trident hello world example:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.storm_trident`包中创建一个`TridentUtility`类。这个类包含我们将在Trident hello
    world示例中使用的Trident过滤器和函数：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `TridentUtility` class contains three inner classes: `Split`, `TweetFilter`,
    and `Print`.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`TridentUtility`类包含三个内部类：`Split`、`TweetFilter`和`Print`。'
- en: The `Split` class extends the `org.apache.storm.trident.operation.BaseFunction`
    class and contains the `execute(TridentTuple tuple, TridentCollector collector)`
    method. The `execute()` method takes comma-separated values as input, splits the
    input value, and emits multiple tuples as output.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`Split`类扩展了`org.apache.storm.trident.operation.BaseFunction`类，并包含`execute(TridentTuple
    tuple, TridentCollector collector)`方法。`execute()`方法以逗号分隔的值作为输入，拆分输入值，并将多个元组作为输出发出。'
- en: The `TweetFilter` class extends the `org.apache.storm.trident.operation.BaseFilter`
    class and contains the `isKeep(TridentTuple tuple)` method. The `isKeep()` method
    takes a tuple as its input and checks whether the input tuple contains the value
    `#FIFA` in the `text` field or not. If the tuple contains `#FIFA` in the `text`
    field, then the method returns true. Otherwise, it returns false.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`TweetFilter`类扩展了`org.apache.storm.trident.operation.BaseFilter`类，并包含`isKeep(TridentTuple
    tuple)`方法。`isKeep()`方法以元组作为输入，并检查输入元组的`text`字段是否包含值`#FIFA`。如果元组的`text`字段包含`#FIFA`，则该方法返回true。否则，返回false。'
- en: The `Print` class extends the `org.apache.storm.trident.operation.BaseFilter`
    class and contains the `isKeep(TridentTuple tuple)` method. The `isKeep()` method
    prints the input tuple and returns true.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`Print`类扩展了`org.apache.storm.trident.operation.BaseFilter`类，并包含`isKeep(TridentTuple
    tuple)`方法。`isKeep()`方法打印输入元组并返回true。'
- en: 'Create a `TridentHelloWorldTopology` class in a `com.stormadvance.storm_trident`
    package. This class defines the hello world Trident topology:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.storm_trident`包中创建一个`TridentHelloWorldTopology`类。该类定义了hello
    world Trident拓扑：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let's understand the code line by line. Firstly, we are creating an object of
    the `TridentTopology` class for defining the Trident computation.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐行理解代码。首先，我们创建了一个`TridentTopology`类的对象来定义Trident计算。
- en: The `TridentTopology` contains a method called `newStream()`, which will take
    an input source as an argument. In this example, we are using `FakeTweetSpout`
    created in the non-transactional topology section as an input source. Like Storm,
    Trident also maintains the state of each input source in ZooKeeper. Here, the
    `FakeTweetSpout` string specifies the node in ZooKeeper where Trident maintains
    the metadata.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`TridentTopology`包含一个名为`newStream()`的方法，该方法将以输入源作为参数。在本例中，我们使用在非事务性拓扑部分创建的`FakeTweetSpout`作为输入源。与Storm一样，Trident也在ZooKeeper中维护每个输入源的状态。在这里，`FakeTweetSpout`字符串指定了Trident在ZooKeeper中维护元数据的节点。'
- en: The spout emits a stream that has two fields, `text` and `Country`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 喷口发出一个具有两个字段`text`和`Country`的流。
- en: We are repartitioning the batch of tuples emitted by the input source using
    the `shuffle` operation. The next line of the topology definition applies `TweetFilter`
    on each tuple. `TweetFilter` filters out all those tuples that do not contain
    the `#FIFA` keyword.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用`shuffle`操作重新分区输入源发出的元组批量。拓扑定义的下一行对每个元组应用`TweetFilter`。`TweetFilter`过滤掉所有不包含`#FIFA`关键字的元组。
- en: The output of `TweetFilter` is grouped by the `Country` field. Then, we applied
    the `Count` aggregator to count the tweets for each country. Finally, we are applying
    a `Print` filter to print the output of the `aggregate` method.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`TweetFilter`的输出按`Country`字段分组。然后，我们应用`Count`聚合器来计算每个国家的推文数量。最后，我们应用`Print`过滤器来打印`aggregate`方法的输出。'
- en: 'Here is the console output of the `TridentHelloWorldTopology` class:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`TridentHelloWorldTopology`类的控制台输出：
- en: '![](img/00038.jpeg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00038.jpeg)'
- en: 'Here is a diagram that shows the execution of the hello world Trident topology:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是显示hello world Trident拓扑执行的图表：
- en: '![](img/00039.gif)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00039.gif)'
- en: Trident state
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Trident状态
- en: Trident provides an abstraction for reading from and writing results to stateful
    sources. We can maintain the state either internally to the topology (memory),
    or we can store it in external sources (Memcached or Cassandra).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Trident提供了一个从有状态源读取和写入结果的抽象。我们可以将状态维护在拓扑内部（内存）或者存储在外部源（Memcached或Cassandra）中。
- en: 'Let''s consider that we are maintaining the output of the preceding hello world
    Trident topology in a database. Every time you process the tuple, the count of
    country present in a tuple is increased in the database. We can''t achieve exactly-once
    processing by only maintaining a count in the database. The reason is that if
    any tuple failed during processing, then the failed tuple is retried. This gives
    us a problem while updating the state, because we are not sure whether the state
    of this tuple was updated previously or not. If the tuple has failed before updating
    the state, then retrying the tuple will increase the count in the database and
    make the state consistent. But if the tuple has failed after updating the state,
    then retrying the same tuple will again increase the count in the database and
    make the state inconsistent. Hence, by only maintaining a count in the database,
    we have no idea whether or not this tuple has been processed before. We need more
    details to take the right decision. We need to follow these steps to achieve the
    exactly-once processing semantics:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一下，我们正在将之前的hello world Trident拓扑的输出保存在数据库中。每次处理元组时，元组中的国家计数都会在数据库中增加。我们无法通过仅在数据库中维护计数来实现精确一次的处理。原因是，如果在处理过程中任何元组失败，那么失败的元组将会重试。这给我们带来了一个问题，因为我们不确定这个元组的状态是否已经更新过。如果元组在更新状态之前失败，那么重试元组将会增加数据库中的计数并使状态一致。但如果元组在更新状态之后失败，那么重试相同的元组将再次增加数据库中的计数并使状态不一致。因此，仅通过在数据库中维护计数，我们无法确定这个元组是否已经被处理过。我们需要更多的细节来做出正确的决定。我们需要按照以下步骤来实现精确一次的处理语义：
- en: Process the tuples in small batches.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以小批量处理元组。
- en: Assign a unique ID to each batch (transactional ID). If the batch is retried,
    it is given the same unique ID.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个批次分配一个唯一ID（事务ID）。如果批次重试，它将获得相同的唯一ID。
- en: The state updates are ordered among batches. For example, the state update of
    batch 2 would not be possible until the state updates for batch 1 have completed.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 批量之间的状态更新是有序的。例如，批量2的状态更新在批量1的状态更新完成之前是不可能的。
- en: If we create a topology by using the preceding three semantics, then we can
    easily take a decision whether the tuple is processed before or not.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用上述三种语义创建一个拓扑，那么我们可以轻松地判断元组是否已经被处理过。
- en: Distributed RPC
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式RPC
- en: Distributed RPC is used to query on and retrieve results from Trident topology
    on the fly. Storm has an in-built distributed RPC server. The distributed RPC
    server receives the RPC request from the client and passes it to the Storm topology.
    The topology processes the request and sends the result to the distributed RPC
    server, which is redirected by the distributed RPC server to the client.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式RPC用于即时查询和检索Trident拓扑的结果。Storm有一个内置的分布式RPC服务器。分布式RPC服务器接收来自客户端的RPC请求，并将其传递给Storm拓扑。拓扑处理请求并将结果发送到分布式RPC服务器，然后由分布式RPC服务器重定向到客户端。
- en: 'We can configure the distributed RPC server by using the following properties
    in the `storm.yaml` file:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在`storm.yaml`文件中使用以下属性来配置分布式RPC服务器：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, `nimbus-node` is the IP of the distributed RPC server.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`nimbus-node`是分布式RPC服务器的IP。
- en: 'Now, run this command on the `nimbus-node` machine to start the distributed
    RPC server:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在`nimbus-node`机器上运行以下命令以启动分布式RPC服务器：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s assume we are storing the count aggregation of hello world Trident topology
    in a database and want to retrieve the count for a given country on the fly. We
    would need to use the distributed RPC feature to achieve this. This example shows
    how we can incorporate the distributed RPC in the hello world Trident topology
    created in the previous section:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在将hello world Trident拓扑的计数聚合存储在数据库中，并且想要即时检索给定国家的计数。我们需要使用分布式RPC功能来实现这一点。这个例子展示了如何在前一节创建的hello
    world Trident拓扑中整合分布式RPC：
- en: 'We are creating a `DistributedRPC` class that contains a `buildTopology()`
    method:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在创建一个包含`buildTopology()`方法的`DistributedRPC`类：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let's understand the code line by line.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐行理解这段代码。
- en: We are using `FakeTweetSpout` as an input source and the `TridentTopology` class
    to define the Trident computation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`FakeTweetSpout`作为输入源，并使用`TridentTopology`类来定义Trident计算。
- en: 'In the next line, we are using the `persistentAggregate` function to represent
    the count aggregation of all the batches emitted. `MemoryMapState.Factory()` is
    used to maintain the count state. The `persistentAggregate` function knows how
    to store and update the aggregation in the source state:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一行中，我们使用`persistentAggregate`函数来表示所有批次的计数聚合。`MemoryMapState.Factory()`用于维护计数状态。`persistentAggregate`函数知道如何在源状态中存储和更新聚合：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The memory database stores the country name as a key and the aggregation count
    as a value, as shown here:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 内存数据库将国家名称存储为键，聚合计数存储为值，如下所示：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `persistentAggregate` transforms the stream into a Trident `State` object.
    In this case, the Trident `State` object represents the count of each country
    so far.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`persistentAggregate`将流转换为Trident `State`对象。在这种情况下，Trident `State`对象表示迄今为止每个国家的计数。'
- en: 'The next part of the topology defines a distributed query to get the count
    of each country on the fly. The distributed RPC query takes as input a comma-separated
    list of countries and returns the count of the each country. Here is the piece
    of code that defines the distributed query portion:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑的下一部分定义了一个分布式查询，以即时获取每个国家的计数。分布式RPC查询以逗号分隔的国家列表作为输入，并返回每个国家的计数。以下是定义分布式查询部分的代码片段：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `Split` function is used to split the comma-separated list of countries.
    We have used a `stateQuery()` method to query the Trident `State` object that
    is defined in the first part of the topology. The `stateQuery()` takes in source
    of state--in this case, the countries count computed by the first part of the
    topology and a function for querying this function. We are using a `MapGet()`
    function, which gets the count for each country. Finally, the count of each country
    is returned as the query output.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`Split`函数用于拆分逗号分隔的国家列表。我们使用了`stateQuery()`方法来查询拓扑的第一部分中定义的Trident `State`对象。`stateQuery()`接受状态源（在本例中是拓扑的第一部分计算出的国家计数）和用于查询此函数的函数。我们使用了`MapGet()`函数，用于获取每个国家的计数。最后，每个国家的计数作为查询输出返回。'
- en: 'Here is the piece of code that shows how we can pass input to a local distributed
    RPC:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一段代码，展示了我们如何将输入传递给本地分布式RPC：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We have created an instance of `backtype.storm.LocalDRPC` to simulate the distributed
    RPC.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经创建了一个`backtype.storm.LocalDRPC`的实例来模拟分布式RPC。
- en: 'If you are running the distributed RPC server, then we need to create an instance
    of a distributed RPC client to execute the query. Here is the piece of code that
    shows how we can pass input to the distributed RPC server:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果正在运行分布式RPC服务器，则需要创建分布式RPC客户端的实例来执行查询。以下是展示如何将输入传递给分布式RPC服务器的代码片段：
- en: '[PRE12]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The Trident distributed RPC query executes like a normal RPC query, except these
    queries are run in parallel.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Trident分布式RPC查询的执行方式类似于普通的RPC查询，只是这些查询是并行运行的。
- en: 'Here is the console output of the `DistributedRPC` class:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`DistributedRPC`类的控制台输出：
- en: '![](img/00040.jpeg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00040.jpeg)'
- en: When to use Trident
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用Trident
- en: It is very easy to achieve exactly-once processing using Trident topology and
    Trident meant for the same. On the other hand, it would be difficult to achieve
    the exactly-once processing in the case of vanilla Storm. Hence, Trident will
    be useful for that use case where we have require exactly-once processing.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Trident拓扑非常容易实现精确一次处理，Trident也是为此而设计的。另一方面，在普通的Storm中实现精确一次处理会比较困难。因此，Trident将对需要精确一次处理的用例非常有用。
- en: Trident is not fit for all use cases, especially for high-performance use cases,
    because Trident adds complexity on Storm and manages the state.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Trident并不适用于所有用例，特别是高性能用例，因为Trident会增加Storm的复杂性并管理状态。
- en: Summary
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we mainly concentrated on the Trident sample topology, the
    Trident `groupBy` operation, and the non-transactional topology. We also covered
    how we can query on the fly on a Trident topology using distributed RPC.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们主要集中在Trident示例拓扑、Trident `groupBy`操作和非事务性拓扑上。我们还介绍了如何使用分布式RPC即时查询Trident拓扑。
- en: In the next chapter, we will cover the different types of Storm scheduler.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍不同类型的Storm调度程序。
