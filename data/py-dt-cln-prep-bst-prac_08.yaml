- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Detecting and Handling Missing Values and Outliers
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测和处理缺失值与离群值
- en: This chapter discusses the techniques of handling missing values and outliers,
    two critical challenges that can significantly impact the integrity and accuracy
    of our data products. We will explore a wide range of techniques to identify and
    manage these data irregularities, ranging from statistical methods to advanced
    machine learning models. Through practical examples and real-world datasets, we
    will present strategies to tackle these issues head-on, ensuring that our analyses
    are robust, reliable, and capable of generating meaningful insights.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了处理缺失值和离群值的技术，这两个问题是数据分析中两个关键挑战，可能会显著影响我们数据产品的完整性和准确性。我们将探讨从统计方法到先进机器学习模型的广泛技术，以识别和管理这些数据异常。通过实践示例和真实数据集，我们将提出应对这些问题的策略，确保我们的分析具有稳健性、可靠性，并能够生成有意义的洞察。
- en: 'The key points for the chapter are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的关键点如下：
- en: Detecting and handling missing data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测和处理缺失数据
- en: Detecting univariate and multivariate outliers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测单变量和多变量离群值
- en: Handling univariate and multivariate outliers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理单变量和多变量离群值
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You can find all the code for the chapter in the link that follows:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下链接中找到本章的所有代码：
- en: '[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter08](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter08)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter08](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter08)'
- en: 'The different code files follow the names of the different parts of the chapters.
    Let''s install the following library:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的代码文件对应章节的不同部分。让我们安装以下库：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Detecting missing data
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测缺失数据
- en: 'Missing data is a common and inevitable issue in real-world datasets. It occurs
    when one or more values are absent in a particular observation or record. This
    data gap can greatly impact the validity and reliability of any analysis or model
    built with those data. As we say in the data world: *garbage in, garbage out*,
    meaning that if your data is not correct, then the models or analysis created
    with that data will not be correct either.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据是现实世界数据集中的常见且不可避免的问题。它发生在某个观察或记录中缺少一个或多个值。这种数据缺失可能会严重影响任何基于这些数据构建的分析或模型的有效性和可靠性。正如我们在数据领域所说：*垃圾进，垃圾出*，意味着如果你的数据不正确，那么基于这些数据创建的模型或分析也不会正确。
- en: 'In the following parts, we will use a scenario to demonstrate how to detect
    missing data and how the different imputation methods work. The scenario is the
    following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将通过一个场景来演示如何检测缺失数据以及不同的填补方法是如何工作的。这个场景如下：
- en: '*Imagine you are analyzing a dataset containing information about students,
    including their ages and test scores. However, due to various reasons, some ages
    and test scores* *are missing.*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设你正在分析一个包含学生信息的数据集，包括他们的年龄和测试分数。然而，由于各种原因，一些年龄和测试分数* *是缺失的。*'
- en: The code for this section can be found at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/1.detect_missing_data.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/1.detect_missing_data.py).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的代码可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/1.detect_missing_data.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/1.detect_missing_data.py)找到。
- en: 'In this script, we create the data that we will use across the chapter. Let’s
    start with the import statements:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个脚本中，我们创建了整个章节中将使用的数据。让我们从导入语句开始：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s generate student data with missing ages and test scores. This dictionary
    data contains two keys, `Age` and `Test_Score`, each with a list of values. Some
    of these values are `None`, indicating missing data:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们生成一些缺失年龄和测试分数的学生数据。这个字典数据包含两个键，`Age` 和 `Test_Score`，每个键都有一个值列表。其中一些值为 `None`，表示缺失的数据：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The first five rows of the dataset are as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的前五行如下：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As we can see, there are NaN values in both columns of the dataset. To understand
    the extent of the missing values in the dataset, let’s count how many we have
    across the whole DataFrame:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，数据集的两列中都有 NaN 值。为了了解数据集中缺失值的程度，让我们统计一下整个 DataFrame 中有多少缺失值：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `df.isnull()` method creates a `missing_values` DataFrame of the same shape
    as `df`, where each cell is `True` if the corresponding cell in `df` is `None`
    (missing value) and `False` otherwise, as shown:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`df.isnull()` 方法会创建一个与 `df` 形状相同的 `missing_values` DataFrame，其中每个单元格如果对应的 `df`
    单元格是 `None`（缺失值），则为 `True`，否则为 `False`，如图所示：'
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the previous DataFrame, any cell that contained a `NaN` value is now replaced
    with `True`. Having the data in that format helps us calculate how many `NaN`
    values we have:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的 DataFrame 中，任何包含 `NaN` 值的单元格现在都被替换为 `True`。以这种格式存储数据有助于我们计算出有多少个 `NaN`
    值：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `missing_values.any(axis=1)` argument checks each row to see whether it
    contains any missing values, returning a Series of `True` or `False` for each
    row. Then the `.sum()` counts the number of `True` values in this Series, giving
    the number of rows with at least one missing value:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`missing_values.any(axis=1)` 参数检查每一行是否包含缺失值，返回一个 `True` 或 `False` 的 Series
    来表示每一行。然后 `.sum()` 统计这个 Series 中 `True` 的个数，从而得出至少有一个缺失值的行数：'
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now we know how much data is missing from our dataset. The next goal of this
    exercise is to find the best imputation method to fill those.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道数据集中缺失了多少数据。这个练习的下一个目标是找到最好的填补方法来补充这些缺失值。
- en: Handling missing data
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理缺失数据
- en: 'Addressing missing data involves making careful decisions to minimize its impact
    on analyses and models. The most common strategies include the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失数据涉及做出谨慎的决策，以最小化其对分析和模型的影响。最常见的策略包括以下几种：
- en: Removing records with missing values
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除包含缺失值的记录
- en: Filling in missing values using various techniques such as mean, median, mode
    imputation, or more advanced methods such as regression-based imputation or k-nearest
    neighbors imputation
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用各种技术来填补缺失值，比如均值、中位数、众数填补，或更先进的方法，如基于回归的填补或k-近邻填补
- en: Introducing binary indicator variables to flag missing data; this can inform
    models about the presence of missing values
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引入二进制指示变量来标记缺失数据；这可以告诉模型哪些值是缺失的
- en: Leveraging subject matter expertise to understand the reasons for missing data
    and make informed decisions about how to handle it
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用主题领域的专业知识来理解缺失数据的原因，并做出有关如何处理缺失值的明智决策
- en: Let’s deep dive into each of these methods and observe in detail the results
    on the dataset presented in the previous part.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入研究这些方法，并详细观察它们在前面部分中展示的数据集上的结果。
- en: Deletion of missing data
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除缺失数据
- en: One approach to handling missing data is to simply remove records (rows) that
    contain missing values. It is a quick and simple strategy, and is generally more
    suitable when the percentage of missing data is *low* and the missing data appears
    in random places.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失数据的一种方法是简单地删除包含缺失值的记录（行）。这是一种快捷且简单的策略，通常在缺失数据的百分比较*低*且缺失数据随机分布时更为合适。
- en: Before we start deleting data, we need to understand our dataset a bit better.
    Continuing on the data created in the previous example, let’s print the descriptive
    statistics first before we start deleting data points. The code for this part
    can be found at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/2.delete_missing_data.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/2.delete_missing_data.py).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始删除数据之前，我们需要更好地了解我们的数据集。继续使用之前示例中的数据，我们先打印描述性统计信息，再开始删除数据点。该部分的代码可以在 [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/2.delete_missing_data.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/2.delete_missing_data.py)
    找到。
- en: Note
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To keep the chapter to a nice number of pages, we have only presented the key
    code snippets. To see all the examples, please go to the repository.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使本章的篇幅适中，我们仅展示了关键的代码片段。要查看所有示例，请访问仓库。
- en: 'To create the descriptive statistics, we can simply call the `.describe()`
    method in pandas:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成描述性统计，我们可以直接调用 pandas 中的 `.describe()` 方法：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The descriptive statistics are presented here:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了描述性统计信息：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Let’s also create the distribution plots for each column of the dataset.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也为数据集的每一列创建分布图。
- en: '![Figure 8.1 – Distribution of features before any alteration](img/B19801_08_1.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1 – 变动前特征的分布](img/B19801_08_1.jpg)'
- en: Figure 8.1 – Distribution of features before any alteration
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – 变动前特征的分布
- en: With this analysis done, we can get some key insights into the dataset. For
    `Age`, with a count of 20, the average age is approximately 33.7 years, with a
    standard deviation of 18.9 years, showing moderate variability. Ages range from
    18 to 90 years, with the middle 50% of ages falling between 21.75 and 38.5 years.
    For `Test_Score`, based on 19 values, the mean score is around 65.8, with a higher
    standard deviation of 27.9, indicating more variability in scores. Test scores
    range from 5 to 94, with the **Interquartile Range** (**IQR**) spanning from 54
    to 87.5.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此分析后，我们可以获得一些关于数据集的关键见解。对于`年龄`，数据量为20，平均年龄大约为33.7岁，标准差为18.9岁，显示出中等程度的变异性。年龄范围从18岁到90岁，年龄的中间50%落在21.75岁到38.5岁之间。对于`测试分数`，基于19个值，均值约为65.8，标准差为27.9，显示出较高的变异性。测试分数范围从5到94分，**四分位差**（**IQR**）从54到87.5。
- en: 'Now, let’s have a look at how to delete the missing data. Let’s pay attention
    to how the dataset changes:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何删除缺失数据。让我们关注数据集的变化：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let’s explore the distribution of the features after the data deletion:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索数据删除后的特征分布：
- en: '![Figure 8.2 – Distribution of features after the data deletion](img/B19801_08_2.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2 – 数据删除后的特征分布](img/B19801_08_2.jpg)'
- en: Figure 8.2 – Distribution of features after the data deletion
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – 数据删除后的特征分布
- en: 'Let’s also have a look at the summary statistics for the altered dataset:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一下修改后的数据集的总结统计：
- en: '[PRE11]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Having seen the descriptive statistics for both datasets, the observed changes
    are presented here:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 看到两个数据集的描述性统计后，观察到的变化如下：
- en: '**Count change**: The count of observations has decreased from 20 to 16 for
    both, age and test scores, after deleting rows with missing values.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计数变化**：删除缺失值的行后，年龄和测试分数的观测数量都从20减少到16。'
- en: '**Mean change**: The mean age has increased from 33.75 to 36.50, while the
    mean test score has slightly decreased from 65.89 to 65.50\. This change reflects
    the values present in the remaining dataset after the deletion.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均值变化**：平均年龄从33.75增加到36.50，而平均测试分数略微下降，从65.89降至65.50。这一变化反映了删除数据后剩余数据集中的值。'
- en: '**Standard deviation change**: The standard deviation for age has increased
    from 18.90 to 20.11, indicating a greater spread in age, while the standard deviation
    for test scores has decreased from 27.99 to 26.61.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准差变化**：年龄的标准差从18.90增加到20.11，表明年龄的分布范围更广，而测试分数的标准差则从27.99降至26.61。'
- en: '**Minimum and maximum values**: The minimum age remains the same at 18, but
    the minimum test score remains at 5\. The maximum values for both age and test
    scores have slightly changed, with the maximum test score decreasing from 94 to
    92.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最小值和最大值**：最小年龄保持不变，仍为18岁，而最小测试分数保持为5分。年龄和测试分数的最大值都有轻微变化，测试分数的最大值从94降至92。'
- en: '**Percentile changes**: The percentile values (25%, 50%, 75%) have shifted
    due to the altered dataset:'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**百分位变化**：由于数据集的变化，百分位值（25%、50%、75%）发生了变化：'
- en: The 25th percentile for age has increased from 21.75 to 23.75, and for test
    scores, from 54.00 to 56.00.
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄的第25百分位从21.75增加到23.75，测试分数的第25百分位从54.00增加到56.00。
- en: The median (50th percentile) for age has increased from 27.50 to 32.00, while
    for test scores, it decreased slightly from 75.00 to 74.50.
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄的中位数（第50百分位）从27.50增加到32.00，而测试分数的中位数从75.00略微下降到74.50。
- en: The 75th percentile for age has increased from 38.50 to 40.25, while for test
    scores, it decreased from 87.50 to 85.50.
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄的第75百分位从38.50增加到40.25，而测试分数的第75百分位从87.50降至85.50。
- en: The deletion of rows with missing values has led to a smaller dataset, and the
    remaining data now has *different statistical properties*. This method is suitable
    when the missing values are deemed to be a small proportion of the dataset and
    removing them does not significantly impact the data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 删除缺失值的行导致数据集变小，剩余数据现在具有*不同的统计特性*。当缺失值占数据集的比例较小且删除它们对数据没有显著影响时，这种方法是适用的。
- en: What is a small proportion though?
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么算是一个小比例呢？
- en: A common rule of thumb is that if less than 5% of the data is missing, it is
    often considered a small proportion, and deletion might not significantly impact
    the analysis. The significance of the change caused by deleting data points can
    be assessed by comparing the results of analyses with and without the missing
    data. If the results are consistent, the deletion might not be significant.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的经验法则是，如果数据缺失少于5%，通常认为缺失比例较小，删除这些数据可能不会对分析产生重大影响。通过比较有缺失数据和无缺失数据的分析结果，可以评估删除数据所造成的变化的显著性。如果结果一致，删除可能就不那么重要。
- en: In these cases of substantial missing data, other imputation methods or advanced
    techniques may be more appropriate as we will explore in the next part.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些缺失数据较为严重的情况下，我们将在下一部分探讨其他填充方法或更高级的技术，可能会更为适用。
- en: Imputation of missing data
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺失数据的填充
- en: Imputation is often used when removing missing records would result in significant
    information loss. Imputation involves filling in missing values with estimated
    or calculated values. Common imputation methods include mean, median, and mode
    imputation, or using more advanced techniques.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 填充通常用于当删除缺失记录会导致显著信息丢失的情况。填充是指用估算或计算出的值替代缺失值。常见的填充方法包括均值填充、中位数填充和众数填充，或使用更高级的技术。
- en: Let’s have a look at the different imputation methods for our scenario.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看针对我们场景的不同填充方法。
- en: Mean imputation
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 均值填充
- en: Mean imputation fills missing values with *the mean of the observed values*
    in the variable. It is a very simple method, and it does not introduce bias when
    the values missing are completely random. However, this method is sensitive to
    outliers, and it may distort the distribution of the feature. You can find the
    code for this part in the repo at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/3.mean_imputation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/3.mean_imputation.py).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 均值填充将缺失值替换为*观察到的值的均值*。这是一种非常简单的方法，当缺失值完全随机时，它不会引入偏差。然而，该方法对异常值敏感，并且可能会扭曲特征的分布。你可以在这个[链接](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/3.mean_imputation.py)找到相关代码。
- en: 'Let’s see the code example for mean imputation. For this example, we will use
    the same dataset as explained before:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看均值填充的代码示例。在这个示例中，我们将使用之前解释过的相同数据集：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding line fills any missing values in the `Age` column with the mean
    of the `Age` column from the original `df` DataFrame. The `df[''Age''].mean()`
    argument calculates the mean of the `Age` column, and rounds this mean to the
    nearest whole number. The `fillna()` method then replaces any `NaN` values in
    the `Age` column with this rounded mean. The `inplace=True` argument ensures that
    the changes are made directly in `df_mean_imputed` without creating a new DataFrame:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 前一行将`Age`列中的任何缺失值填充为原始`df`数据框中`Age`列的均值。`df['Age'].mean()`参数计算`Age`列的均值，并将该均值四舍五入到最接近的整数。然后，`fillna()`方法使用这个四舍五入后的均值替换`Age`列中的任何`NaN`值。`inplace=True`参数确保更改直接在`df_mean_imputed`中进行，而不会创建新的数据框。
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Similarly, the preceding line fills any missing values in the `Test_Score` column
    of `df_mean_imputed` with the mean of the `Test_Score` column from the original
    `df` DataFrame.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，前一行将`df_mean_imputed`中`Test_Score`列的任何缺失值填充为原始`df`数据框中`Test_Score`列的均值。
- en: 'Let’s have a look at the dataset after the imputation:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下填充后的数据集：
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As we can see, the rounded mean has replaced all the `NaN` values for the age
    feature, whereas the absolute mean (abs mean) has replaced the `NaN` values for
    the `Test_Score` column. We rounded up the mean for the `Age` column to make sure
    it represents something meaningful.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，四舍五入后的均值已替代了年龄特征中的所有`NaN`值，而绝对均值（abs mean）则替代了`Test_Score`列中的`NaN`值。我们对`Age`列的均值进行了四舍五入，以确保它表示的是有意义的内容。
- en: 'The updated distributions are presented here:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示的是更新后的分布：
- en: '![Figure 8.3 – Distribution of features after mean imputation](img/B19801_08_3.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图8.3 – 均值填充后的特征分布](img/B19801_08_3.jpg)'
- en: Figure 8.3 – Distribution of features after mean imputation
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 – 均值填充后的特征分布
- en: 'We can see from the graphs that the distributions have slightly changed for
    both of the variables. Let’s have a look at the descriptive statistics of the
    imputed dataset:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中可以看到，两个变量的分布都有些微变化。让我们来看看填补数据集的描述性统计：
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Having seen the descriptive statistics for both datasets, the observed changes
    are as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看了两个数据集的描述性统计后，观察到的变化如下：
- en: '`Age` and `Test_Score` increased from 20 to 24 after the imputation, indicating
    that missing values were successfully imputed.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Age`和`Test_Score`在填补后从20增加到24，表示缺失值已经成功填补。'
- en: '**Mean and median changes**: The mean age remained stable, increasing slightly
    from 33.75 to 33.79\. The mean test score stayed the same at 65.89\. The median
    age increased from 27.50 to 33.00, reflecting the changes in the distribution
    of ages. The median test score slightly decreased from 75.00 to 66.95.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均值和中位数的变化**：均值年龄保持稳定，略微从33.75增加到33.79。均值测试分数保持在65.89不变。中位数年龄从27.50增加到33.00，反映了年龄分布的变化。中位数测试分数略微从75.00下降到66.95。'
- en: '`Age` decreased from 18.90 to 17.18, indicating reduced variability in ages
    after imputation. The standard deviation for `Test_Score` also decreased from
    27.99 to 24.76, reflecting less variability in test scores.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Age`从18.90下降到17.18，表明填补后的年龄变异性减小。`Test_Score`的标准差也从27.99下降到24.76，反映出测试分数的变异性减少。'
- en: '`Age` increased from 21.75 to 22.75, and Q1 for `Test_Score` increased from
    54.00 to 58.75\. The `Age` slightly decreased from 38.50 to 35.75, and Q3 for
    `Test_Score` remained relatively stable, decreasing slightly from 87.50 to 85.50.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Age`从21.75增加到22.75，`Test_Score`的Q1从54.00增加到58.75。`Age`从38.50略微下降到35.75，而`Test_Score`的Q3则保持相对稳定，从87.50略微下降到85.50。'
- en: The mean imputation maintained the overall mean values and increased the dataset
    size by filling in missing values. However, it has reduced the variability (as
    indicated by the decreased standard deviation for `Age` and `Test_Score`) and
    altered the distribution of the data (particularly in the quartiles). These changes
    are typical of mean imputation, as it tends ot underestimate variability and smooth
    out differences in the data, which can impact certain analyses that are sensitive
    to data distribution.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 均值填补保持了整体均值，并通过填补缺失值增加了数据集的大小。然而，它减少了变异性（如`Age`和`Test_Score`的标准差减少所示），并改变了数据的分布（尤其是在四分位数上）。这些变化是均值填补的典型特征，因为它倾向于低估变异性并平滑数据中的差异，这可能会影响某些对数据分布敏感的分析。
- en: Now let’s move on to the median imputation to see how this affects the dataset.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续进行中位数填补，看看它如何影响数据集。
- en: Median imputation
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 中位数填补
- en: Median imputation fills the missing values with the median, the middle value
    of the dataset when it is ordered. Median imputation is robust in the presence
    of outliers and can be a good choice when the distribution is skewed. It can preserve
    the shape of the distribution unless dealing with complex distribution. The code
    for this part can be found at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/4.median_imputation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/4.median_imputation.py).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 中位数填补通过填补缺失值为数据集的中位数，即将数据按顺序排列后的中间值。中位数填补在存在离群值时更为稳健，且在数据分布偏斜时是一个不错的选择。它能够保持分布的形状，除非遇到复杂的分布。相关代码可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/4.median_imputation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/4.median_imputation.py)找到。
- en: 'Let’s have a look at the code example for the median imputation:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下中位数填补的代码示例：
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This following line fills any missing values in the `Age` column of the `df_median_imputed`
    DataFrame with the median of the `Age` column from the original `df` DataFrame.
    The `df[''Age''].median()` argument calculates the median (the middle value) of
    the `Age` column). The `fillna()` method then replaces any `NaN` values in the
    `Age` column with this median. The `inplace=True` argument ensures that the changes
    are made directly within `df_median_imputed`, without creating a new DataFrame:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码行将`df_median_imputed`数据框中`Age`列的缺失值填补为原始`df`数据框中`Age`列的中位数。`df['Age'].median()`参数计算`Age`列的中位数（即中间值）。然后，`fillna()`方法将`Age`列中的任何`NaN`值替换为这个中位数。`inplace=True`参数确保更改直接应用到`df_median_imputed`中，而不创建新的数据框：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Similarly, the following line fills any missing values in `Test_Score`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，以下行填充了 `Test_Score` 中的任何缺失值：
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let’s have a look at the dataset after median imputation:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看经过中位数填充后的数据集：
- en: '[PRE19]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As we can see, the median has replaced all the `NaN` values for the `Age` feature
    (27.5) and for the `Test_Score` column (75). The updated distributions are as
    follows.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，中位数填充已替换了 `Age` 特征（27.5）和 `Test_Score` 列（75）中的所有 `NaN` 值。更新后的分布如下。
- en: '![Figure 8.4 – Distribution of features after median imputation](img/B19801_08_4.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – 中位数填充后的特征分布](img/B19801_08_4.jpg)'
- en: Figure 8.4 – Distribution of features after median imputation
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 中位数填充后的特征分布
- en: 'We can see from the graphs that the distributions have slightly changed for
    both of the variables. Let’s have a look at the descriptive statistics of the
    imputed dataset:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从图表中可以看到，这两个变量的分布略有变化。让我们看看填充后数据集的描述性统计：
- en: '[PRE20]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Having seen the descriptive statistics for both datasets, the observed changes
    are presented here:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看了两个数据集的描述性统计后，观察到的变化在这里呈现：
- en: '`Age` and `Test_Score` increased from 20 (for age) and 19 (for test score)
    to 24 for both variables after median imputation, indicating that missing values
    were successfully imputed.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Age` 和 `Test_Score` 在经过中位数填充后分别从 20（年龄）和 19（测试分数）增加到 24，表明缺失值已成功填充。'
- en: '**Mean changes**: The mean age decreased from 33.75 to 32.71 after imputation.
    The mean test score increased slightly from 65.89 to 67.79\. These changes reflect
    the nature of the data remaining after the imputation.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均值变化**：填充后，均值年龄从 33.75 降低到 32.71，均值测试分数略微增加，从 65.89 增加到 67.79。这些变化反映了填充后数据的特性。'
- en: '`Age` decreased from 18.90 to 17.35, indicating a reduction in variability
    for age. The standard deviation for `Test_Score` also decreased from 27.99 to
    25.05, reflecting less variability in the test scores after imputation.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Age` 从 18.90 降低到 17.35，表明年龄的变异性有所减小。`Test_Score` 的标准差也从 27.99 降低到 25.05，反映出在填充后测试成绩的变异性较小。'
- en: '`Age` increased slightly from 21.75 to 22.75, and the Q1 for `Test_Score` increased
    from 54.00 to 58.75\. Q3 (75%) for `Age` decreased from 38.50 to 35.75, and Q3
    for `Test_Score` decreased slightly from 87.50 to 85.50.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Age` 从 21.75 稍微增加到 22.75，而 `Test_Score` 的 Q1 从 54.00 增加到 58.75。`Age` 的 Q3（75%）从
    38.50 降低到 35.75，`Test_Score` 的 Q3 也略微减少，从 87.50 降低到 85.50。'
- en: '`Age` remained stable at 27.50, while the median for `Test_Score` also remained
    stable at 75.00 highlighting the central tendency of the data was preserved after
    imputation.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Age` 保持稳定在 27.50，而 `Test_Score` 的中位数也保持在 75.00，突出了填充后数据的中央趋势得到了保持。'
- en: Median imputation has successfully filled in the missing values while preserving
    the median for both `Age` and `Test_Score`. It resulted in a slight change in
    the mean and reduced variability, which is typical of median imputation. The central
    tendency (median) was maintained, which is a key advantage of median imputation,
    especially in skewed distributions. But it also reduces the spread of the data
    which may be relevant for certain types of analysis.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 中位数填充成功地填补了缺失值，同时保持了 `Age` 和 `Test_Score` 的中位数。这导致均值发生了轻微变化并减少了变异性，这是中位数填充的典型特征。中央趋势（中位数）得到了保持，这是中位数填充的一个重要优势，特别是在偏斜分布的情况下。但它也减少了数据的分布，这对某些类型的分析可能具有影响。
- en: In the next part, we will use what we learned so far on the imputation. We will
    also add an extra step, which involves marking where the missing values exist
    in the dataset for later reference.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将使用到目前为止学到的关于填充的内容。我们还将增加一个额外的步骤，即标记数据集中缺失值所在的位置，供后续参考。
- en: Creating indicator variables
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建指示变量
- en: Indicator variable imputation, also known as flag or dummy variable imputation,
    involves creating a binary indicator variable that flags whether an observation
    has a missing value in a particular variable. This separate dummy variable takes
    the value of 1 for missing values and 0 for observed values. Indicator variable
    imputation can be useful when there is a pattern to the missing values, and you
    want to explicitly model and capture the missingness. Remember here that *we are
    adding a completely new variable, creating a higher dimensional dataset*. After
    we build the indicator variables, *whose role is to remind us which values were
    imputed and which were not*, we go ahead and impute the dataset with any method
    we want such as median or mean.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 指标变量补全，也叫标志变量或虚拟变量补全，涉及创建一个二进制指标变量，标记某个观测值在特定变量中是否缺失。这个单独的虚拟变量在缺失值时取值为 1，在观察到的值时取值为
    0。当缺失值存在某种模式时，指标变量补全很有用，它能帮助你明确建模并捕捉缺失值的情况。记住，*我们是在添加一个全新的变量，创建了一个更高维的数据集*。在创建完指标变量后，*它们的作用是提醒我们哪些值是被补全的，哪些值不是*，然后我们可以使用任意方法（例如中位数或均值）补全数据集。
- en: 'Let’s see the code example for this imputation method. As always, you can see
    the full code in the repository:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这种补全方法的代码示例。和往常一样，你可以在仓库中看到完整的代码：
- en: '[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/5.indicator_imputation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/5.indicator_imputation.py)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/5.indicator_imputation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/5.indicator_imputation.py)'
- en: 'Also, remember that we are using exactly the same DataFrame across the chapter,
    so we have skipped the DataFrame creation here:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，记住我们在整章中使用的是完全相同的数据框，因此这里省略了数据框的创建部分：
- en: '[PRE21]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The code creates new columns in the `df` DataFrame that indicate whether a value
    is missing (`NaN`) in the `Age` and `Test_Score` columns. `df['Age'].isnull()`
    checks each value in the `Age` column to see whether it is `NaN` (missing). It
    returns a Boolean series where `True` indicates a missing value, and `False` indicates
    a non-missing value. The `.astype(int)` method converts the Boolean series into
    an integer series where `True` becomes `1` (indicating a missing value) and `False`
    becomes `0` (indicating no missing value). The `df['Age_missing']` DataFrame stores
    this integer series in a new column named `Age_missing`.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码在 `df` 数据框中创建了新列，用以指示 `Age` 和 `Test_Score` 列中是否有缺失值（`NaN`）。`df['Age'].isnull()`
    检查 `Age` 列中的每个值是否为 `NaN`（缺失）。它返回一个布尔型的序列，其中 `True` 表示缺失值，`False` 表示非缺失值。`.astype(int)`
    方法将布尔型序列转换为整数型序列，`True` 变为 1（表示缺失值），`False` 变为 0（表示非缺失值）。`df['Age_missing']` 数据框将这个整数序列存储在一个名为
    `Age_missing` 的新列中。
- en: 'Similarly, `df[''Test_Score_missing'']` is created to indicate missing values
    in the `Test_Score` column:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，`df['Test_Score_missing']` 是用来指示 `Test_Score` 列中的缺失值：
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This code fills in the missing values in the `Age` and `Test_Score` columns
    of the `df_imputed` DataFrame with the mean of the respective columns, as we learned
    in the previous part. Let’s have a look at the dataset after the indicator variable
    imputation:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将 `df_imputed` 数据框中 `Age` 和 `Test_Score` 列中的缺失值填充为各自列的均值，就像我们在前一部分学习的那样。让我们看看经过指标变量补全后的数据集：
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As you can see from the imputed dataset, we added two indicator variables (`Age_missing`
    and `Test_Score_missing`) that take the value of 1 if the corresponding variable
    is missing and 0 otherwise. So, we mainly flag *which values from the original
    rows* *were imputed*.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 从补全后的数据集可以看出，我们添加了两个指标变量（`Age_missing` 和 `Test_Score_missing`），如果对应的变量缺失，则其值为
    1，否则为 0。所以，我们主要标记了*哪些原始行的值* *是被补全的*。
- en: 'Let’s see how the distribution of the indicator variables looks:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看指标变量的分布情况：
- en: '![Figure 8.5 – Distribution of indicator variables](img/B19801_08_5.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.5 – 指标变量的分布](img/B19801_08_5.jpg)'
- en: Figure 8.5 – Distribution of indicator variables
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – 指标变量的分布
- en: 'Now, let’s explore the relationship between the indicator variables and other
    features in your dataset by building some box plots:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过构建一些箱型图来探索指标变量与数据集中其他特征之间的关系：
- en: '[PRE24]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The created box plots can be seen in *Figure 8**.6*:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 创建的箱型图可以在*图 8.6*中看到：
- en: '![Figure 8.6 – Box plots comparing the relationship between indicator variables
    and the rest of the features](img/B19801_08_6.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6 – 箱型图比较指示变量与其他特征之间的关系](img/B19801_08_6.jpg)'
- en: Figure 8.6 – Box plots comparing the relationship between indicator variables
    and the rest of the features
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – 箱型图比较指示变量与其他特征之间的关系
- en: Reminder – how to read the box plots
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 – 如何读取箱型图
- en: '**Box extent**: The box in a box plot represents the IQR, which contains the
    central 50% of the data. Values within the box are considered typical or within
    the normal range.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**箱体范围**：箱型图中的箱体表示四分位距（IQR），其中包含数据的中心 50%。箱内的值被视为典型值或正常范围内的值。'
- en: '**Whiskers**: Whiskers extend from the box and show the range of typical values.
    Outliers are often defined as values outside a certain multiple (e.g., 1.5 times)
    of the IQR.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**胡须**：胡须从箱体延伸，显示典型值的范围。异常值通常定义为超出某一倍数（例如 1.5 倍）四分位距（IQR）的值。'
- en: '**Outliers**: Individual data points beyond the whiskers are considered potential
    outliers. Outliers are plotted as individual points or asterisks.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**异常值**：超出胡须之外的个别数据点被视为潜在的异常值。异常值通常以单独的点或星号表示。'
- en: '**Suspected outliers**: Sometimes, points just beyond the whiskers may be plotted
    as suspected outliers, marked separately to indicate they are potential outliers
    but not extreme.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**疑似异常值**：有时，位于胡须之外的点可能被标记为疑似异常值，单独标记以表明它们是潜在的异常值，但并非极端值。'
- en: Back to our example, the box plot of `Test_Score` by `Age Missing` shows that
    when the age is missing in the data, the mean of `Test_Score` is around 80 and
    the distribution values are between 55 and 85\. When `Age` is not missing, the
    mean is around 65, with most of the values being around 60 and 80, with some outliers
    around 20\. Now, when the score is missing, the mean age of the students is around
    20, whereas for the students with scores, the mean age is around 35.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的例子，`Test_Score` 按 `Age Missing` 的箱型图显示，当数据中的年龄缺失时，`Test_Score` 的均值大约为 80，分布值介于
    55 到 85 之间。当 `Age` 不缺失时，均值大约为 65，大部分值集中在 60 和 80 之间，少数异常值集中在 20 附近。现在，当分数缺失时，学生的平均年龄约为
    20，而有分数的学生的平均年龄约为 35。
- en: Note
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When building predictive models, include the indicator variables as additional
    features to capture the impact of missing values on the target variable. Evaluate
    the performance of models with and without the indicator variables to assess their
    contribution.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建预测模型时，将指示变量作为附加特征以捕捉缺失值对目标变量的影响。评估包含和不包含指示变量的模型表现，以评估它们的贡献。
- en: Comparison between imputation methods
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插补方法的比较
- en: The following table provides a guide for selecting the appropriate imputation
    method based on the data’s characteristics and objectives of the task at hand.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格提供了根据数据特征和任务目标选择合适插补方法的指南。
- en: Remember that there is no one-size-fits-all solution!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，没有一种方法适用于所有情况！
- en: '| **Imputation method** | **Use cases** | **Pros** | **Cons** |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| **插补方法** | **使用场景** | **优点** | **缺点** |'
- en: '| **Mean imputation** | Normally distributed dataMissing values are MCAR or
    MAR | Simple and easy to implementPreserves the mean of the distribution | Sensitive
    to outliersMay distort the distribution if missingness is not random |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| **均值插补** | 正态分布数据，缺失值为 MCAR 或 MAR | 简单易行，保留分布的均值 | 对异常值敏感，若缺失不是随机的，可能扭曲分布
    |'
- en: '| **Median imputation** | Skewed or non-normally distributed dataPresence of
    outliers | Robust to outliersPreserves the median of the distribution | Ignores
    potential relationships between variablesMay be less precise for non-skewed data
    |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| **中位数插补** | 偏斜或非正态分布数据，存在异常值 | 对异常值具有鲁棒性，保留分布的中位数 | 忽略变量之间的潜在关系，可能对非偏斜数据精度较低
    |'
- en: '| **Indicator** **variable imputation** | Systematic pattern in missing data
    | Captures missingness pattern | Increases dimensionality Assumes meaningful missingness
    pattern, which may not always be the case |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| **指示变量插补** | 缺失数据中的系统性模式 | 捕捉缺失模式 | 增加维度性 假设缺失模式有意义，但这并不总是成立 |'
- en: '| **Deletion** **of rows** | MCAR or MAR missingness mechanismPresence of outliers
    | Preserves the existing data structureCan be effective when missingness is random
    | Reduces the sample sizeMay lead to biased results if missingness is not completely
    random |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| **删除行** | MCAR 或 MAR 缺失机制，存在异常值 | 保留现有数据结构，当缺失是随机时有效 | 减少样本量，如果缺失不是完全随机，可能导致偏倚结果
    |'
- en: Table 8.1 – Comparison between the various imputation methods
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8.1 – 各种填补方法的比较
- en: In the examples provided, we consistently applied the same imputation method
    to each column of the dataset. However, as demonstrated, our analysis and considerations
    were tailored to each column individually. This implies that we have the flexibility
    to tailor our imputation strategy to the specific characteristics and requirements
    of *each column*. As a practical exercise, take some time to experiment with different
    imputation methods for various columns in your dataset and observe how these choices
    impact your results.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在提供的示例中，我们一致地对数据集的每一列应用了相同的填补方法。然而，正如我们所展示的那样，我们的分析和考虑是针对每一列单独量身定制的。这意味着我们可以根据*每一列*的具体特征和需求来定制填补策略。作为一个实际练习，花些时间尝试为数据集中的不同列使用不同的填补方法，并观察这些选择如何影响你的结果。
- en: To build on the foundation we’ve established with our imputation strategies,
    it’s essential to recognize that data cleaning doesn’t stop with handling missing
    values. Another critical aspect of data preprocessing is identifying and managing
    outliers. In the next part, we will dive deeper into detecting and handling outliers,
    ensuring our dataset is as accurate and reliable as possible.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在我们已经建立的填补策略基础上进一步发展，必须认识到数据清理不仅仅是处理缺失值。数据预处理的另一个关键方面是识别和管理离群值。在接下来的部分，我们将深入探讨如何检测和处理离群值，确保我们的数据集尽可能准确和可靠。
- en: Detecting and handling outliers
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测和处理离群值
- en: Outliers are data points that significantly deviate from the general pattern
    or trend shown by most of the data points in a dataset. They lie at an unusually
    distant location from the center of the data distribution and can have a significant
    impact on statistical analyses, visualizations, and model performance. Defining
    outliers involves recognizing data points that do not conform to the expected
    behavior of the data and understanding the context in which they occur.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 离群值是指在数据集中与大多数数据点显示的总体模式或趋势显著偏离的数据点。它们位于数据分布中心异常远的位置，并且可能对统计分析、可视化和模型性能产生重大影响。定义离群值包括识别那些不符合数据预期行为的数据点，并理解它们发生的背景。
- en: Impact of outliers
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 离群值的影响
- en: Outliers, while often a small fraction of a dataset, wield a disproportionate
    influence that can disrupt the integrity of a dataset. Their presence has the
    potential to distort statistical summaries, mislead visualizations, and negatively
    impact the performance of models.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 离群值虽然通常只占数据集的一小部分，但它们对数据集的影响不成比例，可能会破坏数据集的完整性。它们的存在可能会扭曲统计总结、误导可视化，并对模型的性能产生负面影响。
- en: 'Let’s go deeper into the various ways in which outliers distort the truth:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨离群值如何扭曲事实：
- en: '**Distorted summary statistics**: Outliers can significantly skew summary statistics,
    giving a misleading impression of the central tendencies of the data:'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扭曲的统计汇总**：离群值可能会显著扭曲统计汇总，给出数据中心趋势的误导性印象：'
- en: '**Mean and median**: The mean, a common measure of central tendency, can be
    greatly affected by outliers. An outlier with a value much higher or lower than
    the rest can pull the mean in its direction. On the other hand, the median is
    determined by the middle value of a sorted dataset. It effectively serves as the
    central point that divides the data into two equal halves, making it less susceptible
    to the influence of extreme values.'
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均值和中位数**：均值作为一种常见的集中趋势测量，可能会受到离群值的极大影响。一个远高于或低于其他数据点的离群值可能会将均值拉向它。另一方面，中位数是通过排序数据集中的中间值来确定的。它有效地作为数据的中心点，将数据分为两等部分，因此不容易受到极端值的影响。'
- en: '**Variance and standard deviation**: Outliers can inflate the variance and
    standard deviation, making the data appear more spread out than it actually is.
    This can misrepresent the variability of the majority of the data.'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方差和标准差**：离群值可能会膨胀方差和标准差，使数据看起来比实际更为分散。这可能会误导数据的大多数变异性。'
- en: '**Misleading visualizations**: Outliers can distort the scale and shape of
    visualizations, leading to misinterpretation:'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**误导性的可视化**：离群值可能会扭曲可视化的尺度和形状，导致误解：'
- en: '**Box plots**: Outliers can cause box plots to extend excessively, making the
    bulk of the data appear compressed. This can make the distribution seem less spread
    out than it actually is.'
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**箱型图**：离群值可能会导致箱型图过度延伸，使数据的大部分看起来被压缩。这可能会使分布看起来不如实际情况那样分散。'
- en: '**Histograms**: Outliers might lead to the creation of bins that capture only
    a few extreme values, causing other bins to seem disproportionately small and
    the distribution shape to be distorted.'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直方图**：异常值可能导致创建仅包含少数极端值的区间，导致其他区间显得不成比例地小，且分布形态被扭曲。'
- en: '**Influence on model performance**: Outliers can negatively affect the performance
    of predictive models:'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对模型性能的影响**：异常值可能会对预测模型的性能产生负面影响：'
- en: '**Regression**: Outliers can heavily influence the slope and intercept of the
    regression line, leading to models that are overly influenced by extreme values.'
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**：异常值可能会严重影响回归线的斜率和截距，从而导致模型过度受到极端值的影响。'
- en: '**Clustering**: Outliers can affect the centroids and boundaries of clusters,
    potentially leading to the creation of clusters that do not accurately represent
    the data distribution.'
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**：异常值可能会影响聚类的中心点和边界，可能导致创建无法准确表示数据分布的聚类。'
- en: Outliers can be categorized based on dimensions as univariate versus multivariate.
    In the next section, we will use the example presented in the first part to see
    how we can handle the univariate outliers.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值可以根据维度分为单变量异常值和多变量异常值。在下一节中，我们将使用第一部分中的示例，看看如何处理单变量异常值。
- en: Identifying univariate outliers
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别单变量异常值
- en: Univariate outliers occur when an extreme value is observed in a single variable,
    regardless of the values of other variables. They are detected based on the distribution
    of a single variable and are often identified using visualizations or statistical
    methods such as Z-score or IQR.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 单变量异常值发生在单个变量中观察到极端值时，与其他变量的值无关。它们基于单个变量的分布进行检测，通常使用可视化或统计方法（如Z分数或四分位距）来识别。
- en: In the next part, we will build one of the most common visualizations to identify
    outliers.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分中，我们将构建最常见的可视化图形之一，用于识别异常值。
- en: Classic visualizations for identifying outliers
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别异常值的经典可视化方法
- en: Before going deeper into the statistical methods to identify outliers, there
    are a couple of easy visualizations we could build to spot them. The data example
    we have been using so far will still be used for this part; you can find the full
    code at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/6.outliers_visualisation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/6.outliers_visualisation.py).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入讨论识别异常值的统计方法之前，我们可以先创建一些简单的可视化图形来帮助识别它们。我们一直使用的数据示例仍然适用于这一部分，你可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/6.outliers_visualisation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/6.outliers_visualisation.py)找到完整的代码。
- en: 'Let’s start with the first visualization, the box plot, where outliers are
    depicted as dots on the left or right of the whisker. The following code snippet
    creates the box plots for each variable:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从第一个可视化图——箱线图开始，其中异常值表现为箱须两侧的点。以下代码片段为每个变量创建箱线图：
- en: '[PRE25]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The created box plots are presented as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 创建的箱线图如下所示：
- en: '![Figure 8.7 – Box plots to spot outliers](img/B19801_08_7.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.7 – 箱线图用来识别异常值](img/B19801_08_7.jpg)'
- en: Figure 8.7 – Box plots to spot outliers
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – 箱线图用来识别异常值
- en: In our example, we can see that the `Age` feature has some clear outliers.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们可以看到`Age`特征有一些明显的异常值。
- en: 'Another classic plot is the violin chart, as shown in *Figure 8**.8*. Violin
    plots are a powerful visualization tool that combines aspects of box plots and
    kernel density plots. To create the violin plots, run the following code snippet:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个经典的图形是小提琴图，如*图 8.8*所示。小提琴图是一种强大的可视化工具，结合了箱线图和核密度图的特点。要创建小提琴图，请运行以下代码片段：
- en: '[PRE26]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The created violin plots are as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 创建的小提琴图如下所示：
- en: '![Figure 8.8 – Violin plots to spot outliers](img/B19801_08_8.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.8 – 小提琴图用来识别异常值](img/B19801_08_8.jpg)'
- en: Figure 8.8 – Violin plots to spot outliers
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 – 小提琴图用来识别异常值
- en: 'Reminder – how to read the violin plots:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 – 如何阅读小提琴图：
- en: '**Width of the violin**: The width of the violin represents the density of
    the data at different values. A wider section indicates a higher density of data
    points at that specific value, meaning a higher probability that members of the
    population will have the given value; the skinnier sections represent a lower
    probability.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '**小提琴的宽度**：小提琴的宽度表示数据在不同值处的密度。较宽的部分表示在特定值处数据点的密度较高，意味着该值在总体中出现的概率较高；而较窄的部分表示概率较低。'
- en: '**Box-and-whisker elements**: Inside the violin, you may see a box-and-whisker
    plot, similar to what you would see in a traditional box plot. The box represents
    the IQR, and the median is usually displayed as a horizontal line inside the box.
    Whiskers extend from the box to indicate the range of the data.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '**箱线图元素**：在小提琴图内，你可能会看到一个类似于传统箱线图的箱线图。箱子表示IQR（四分位距），而中位数通常以一条水平线显示在箱内。胡须从箱子延伸，表示数据的范围。'
- en: '**Kernel Density Estimation** (**KDE**): The entire shape of the violin is
    a mirrored representation of the KDE. The KDE provides a smooth representation
    of the data distribution, allowing you to see peaks and valleys in the data.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**核密度估计**（**KDE**）：小提琴图的整体形状是KDE的镜像表示。KDE提供了数据分布的平滑表示，帮助你观察数据的峰值和谷值。'
- en: '**Outliers**: Outliers may be visible as points beyond the ends of the whiskers
    or outside the overall shape of the violin.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '**异常值**：异常值可能表现为超出胡须末端的点，或超出小提琴整体形状的点。'
- en: Now having seen these charts, we are starting to form some hypotheses about
    the existence of outliers specifically in the `Age` column. The next step is to
    use some statistical methods to validate these hypotheses starting with the Z-score
    method.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看过这些图表，开始对`Age`列中异常值的存在形成一些假设。下一步是使用一些统计方法验证这些假设，首先从Z分数方法开始。
- en: Z-score method
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Z分数方法
- en: 'The Z-score method is a statistical technique used to identify univariate outliers
    in a dataset by measuring how far individual data points deviate from the mean
    in terms of standard deviations. The Z-score for a data point is calculated using
    the following formula:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Z分数方法是一种统计技术，通过衡量单个数据点相对于均值的标准差偏离程度，用于识别数据集中的单变量异常值。数据点的Z分数使用以下公式计算：
- en: Z = (X − Mean) / Standard Deviation
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Z = (X − Mean) / Standard Deviation
- en: Here, *X* is the data point, *Mean* is the average of the dataset, and *Standard
    Deviation* quantifies the dispersion of the data.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*X*是数据点，*Mean*是数据集的平均值，*Standard Deviation*量化数据的离散程度。
- en: Typically, a threshold Z-score is chosen to determine outliers. Commonly used
    thresholds are *Z > 3* or *Z <− 3*, indicating that data points deviating more
    than three standard deviations from the mean are considered outliers.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，选择一个阈值Z分数来确定异常值。常用的阈值是*Z > 3*或*Z < −3*，表示偏离均值超过三个标准差的数据点被视为异常值。
- en: Let’s go back to our code example to calculate the Z-score for the `Age` and
    `Test_Score` columns. We will continue with the example we started before. You
    can find the full code at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/7.identify_univariate_outliers.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/7.identify_univariate_outliers.py).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到之前的代码示例，计算`Age`和`Test_Score`列的Z分数。我们将继续之前开始的示例。你可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/7.identify_univariate_outliers.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/7.identify_univariate_outliers.py)找到完整的代码。
- en: 'Let’s calculate the Z-score:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算Z分数：
- en: '[PRE27]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The `stats.zscore(df[''Age''].dropna())` function calculates the Z-scores for
    the `Age` column. A Z-score represents how many standard deviations a data point
    is from the mean. The `dropna()` function is used to exclude `NaN` values before
    calculating the Z-scores:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`stats.zscore(df[''Age''].dropna())`函数计算`Age`列的Z分数。Z分数表示一个数据点距离均值多少个标准差。`dropna()`函数用于在计算Z分数之前排除`NaN`值：'
- en: '[PRE28]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `np.abs()` function takes the absolute value of the Z-scores. This is done
    because Z-scores can be negative (indicating a value below the mean) or positive
    (indicating a value above the mean). By using the absolute value, we’re only concerned
    with the magnitude of deviation from the mean, regardless of direction.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`np.abs()`函数用于计算Z分数的绝对值。这是因为Z分数可以为负（表示值低于均值）或为正（表示值高于均值）。通过使用绝对值，我们只关注偏离均值的大小，而不考虑方向。'
- en: '[PRE29]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '`np.where(z_scores_age > z_threshold)[0]` identifies the indices of the data
    points in the `Age` column that have Z-scores greater than the threshold of `3`.
    The `[0]` at the end is used to extract the indices as an array. The `outliers_age`
    and `outliers_test_score` variables store the indices of the outlier data points
    in the `Age` and `Test_Score` columns, respectively.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '`np.where(z_scores_age > z_threshold)[0]`识别`年龄`列中Z-score大于`3`的那些数据点的索引。最后的`[0]`用于提取索引作为数组。`outliers_age`和`outliers_test_score`变量分别存储`年龄`和`测试成绩`列中的异常值数据点索引。'
- en: If we plot the Z-scores for each observation and feature of the data, we can
    start spotting some outliers already.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们绘制每个观察值和特征的Z-scores，就可以开始发现一些异常值了。
- en: '![Figure 8.9 – Outlier detection with Z-score](img/B19801_08_9.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![图8.9 – 使用Z-score进行异常值检测](img/B19801_08_9.jpg)'
- en: Figure 8.9 – Outlier detection with Z-score
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9 – 使用Z-score进行异常值检测
- en: In these scatter plots of Z-scores, each point represents the Z-score of an
    individual data point. The red dashed line indicates the chosen Z-score threshold
    (in this case, `3`). Outliers are identified as points above this threshold. As
    we can see, in `Age`, there is an outlier clearly captured.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些Z-score的散点图中，每个点代表一个数据点的Z-score。红色虚线表示所选的Z-score阈值（在此案例中为`3`）。异常值被标识为高于此阈值的点。如我们所见，在`年龄`上，清晰地捕捉到了一个异常值。
- en: How to choose the right threshold for the z score?
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 如何选择合适的Z-score阈值？
- en: 'A Z-score tells you how many standard deviations a data point is from the mean.
    In a normal distribution, the following is true:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Z-score告诉你一个数据点距离均值有多少个标准差。在正态分布中，以下是成立的：
- en: Approximately 68% of data falls within *one standard deviation* of the mean.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大约68%的数据落在均值的*一个标准差*范围内。
- en: Approximately 95% of data falls within *two* *standard deviations*
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大约95%的数据落在*两个* *标准差*内。
- en: Approximately 99.7% of data falls within *three* *standard deviations*
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大约99.7%的数据落在*三个* *标准差*内。
- en: This means that a Z-score threshold of `3` is often used because it captures
    values that are *extremely far from the mean*, identifying the most extreme outliers.
    In a perfectly normal distribution, only 0.3% of data points will have a Z-score
    greater than 3 or less than -3\. This makes it a reasonable threshold for detecting
    outliers that are unlikely to be part of the normal data distribution.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着`3`的Z-score阈值通常被使用，因为它捕捉到的是*极度偏离均值*的值，识别出最极端的异常值。在完美的正态分布中，只有0.3%的数据点会有Z-score大于3或小于-3。这使得它成为检测不太可能属于正常数据分布的异常值的合理阈值。
- en: Now, apart from the Z-score, another common method is the IQR, which we will
    discuss in the following part.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，除了Z-score，另一种常见的方法是IQR，我们将在接下来的部分讨论这一方法。
- en: IQR method
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IQR方法
- en: The IQR is a measure of statistical dispersion, representing the range between
    Q1 and Q3 in a dataset. The IQR is a robust measure of *spread* because it is
    less sensitive to outliers. At this point, it is clear that the IQR is based on
    quartiles. Quartiles divide the dataset into segments, and since Q1 and Q3 are
    less sensitive to extreme values, the IQR is not heavily influenced by outliers.
    On the other hand, standard deviation is influenced by each data point’s deviation
    from the mean. Outliers with large deviations can disproportionately impact the
    standard deviation.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: IQR是统计离散度的一个衡量标准，表示数据集中Q1和Q3之间的范围。IQR是一种稳健的*离散度*衡量方式，因为它对异常值的敏感性较低。此时，可以清楚地看出IQR是基于四分位数的。四分位数将数据集分为几个区间，由于Q1和Q3对极端值不那么敏感，因此IQR不容易受到异常值的影响。另一方面，标准差会受到每个数据点与均值偏差的影响。偏差较大的异常值会对标准差产生不成比例的影响。
- en: Reminder – how to calculate the IQR
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 – 如何计算IQR
- en: '**Calculate Q1 (25th percentile)**: Identify the value below which 25% of the
    data falls.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算Q1（25百分位数）**：确定数据中有25%落在其下方的值。'
- en: '**Calculate Q3 (75th percentile)**: Identify the value below which 75% of the
    data falls.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算Q3（75百分位数）**：确定数据中有75%落在其下方的值。'
- en: '**Calculate IQR**: IQR = Q3 - Q1.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算IQR**：IQR = Q3 - Q1。'
- en: 'To identify potential outliers using IQR, do the following:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 使用IQR识别潜在的异常值，请按以下步骤操作：
- en: 'Calculate the lower and upper bounds as follows: Lower Bound = Q1 - 1.5 * IQR,
    Upper Bound = Q3 + 1.5 * IQR.'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式计算上下界：下界 = Q1 - 1.5 * IQR，上界 = Q3 + 1.5 * IQR。
- en: Any data point outside the lower and upper bounds is considered a potential
    outlier.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任何低于或高于上下界的数据点都被视为潜在的异常值。
- en: It’s important to note that the choice of the multiplier (in this case, `1.5`)
    is somewhat arbitrary but has been widely adopted in practice. Adjusting this
    multiplier can make the method more or less sensitive to potential outliers. For
    example, using a larger multiplier would result in broader boundaries, potentially
    identifying more data points as potential outliers, while a smaller multiplier
    would make the method less sensitive.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，乘数的选择（在本例中为`1.5`）是有些任意的，但在实际中已经广泛采用。调整这个乘数可以使得该方法对潜在离群值的敏感度更高或更低。例如，使用更大的乘数会导致边界更广，可能会识别出更多的潜在离群值，而较小的乘数则会使该方法对离群值的敏感度降低。
- en: 'We’ll be using the same script as before, which can be found at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/7.identify_univariate_outliers.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/7.identify_univariate_outliers.py).
    Let’s have a look at how to calculate the IQR and identify the outliers:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用之前的脚本，脚本可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/7.identify_univariate_outliers.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/7.identify_univariate_outliers.py)找到。让我们看看如何计算IQR并识别离群值：
- en: '[PRE30]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This code defines a function to identify outliers in any column of a DataFrame
    using the IQR method. It calculates the IQR, sets upper and lower bounds for normal
    data, and then filters out the rows where the values in the column fall outside
    these bounds.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码定义了一个函数，用于通过IQR方法识别DataFrame中任何列的离群值。它计算IQR，设定正常数据的上下限，然后过滤出那些列中的值落在这些边界之外的行。
- en: 'Then, let’s identify and print outliers for `Age`:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们来识别并打印`Age`（年龄）列中的离群值：
- en: '[PRE31]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Identify and print outliers for `Test_Score`:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 识别并打印`Test_Score`（考试成绩）列中的离群值：
- en: '[PRE32]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'After running this code, we can see in the print statement the identified outliers/rows
    based on the `Age` column:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这段代码后，我们可以在打印语句中看到基于`Age`列识别出的离群值/行：
- en: '[PRE33]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: As discussed, the simplicity of the IQR, as well as its robustness to outliers,
    contributes to its popularity in various analytical scenarios. However, it comes
    with certain drawbacks. One limitation is the loss of information, as IQR only
    considers the central 50% of the dataset, disregarding the entire range. Additionally,
    IQR’s sensitivity to sample size, especially in smaller datasets, can affect its
    accuracy in reflecting the true spread of the data.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，IQR（四分位距）的简便性以及其对离群值的稳健性使其在各种分析场景中非常受欢迎。然而，它也有一定的缺点。一个限制是信息的丢失，因为IQR仅考虑数据集的中央50%，忽略了整个范围。此外，IQR对样本大小的敏感性，尤其是在较小的数据集里，可能会影响其反映数据真实分布的准确性。
- en: Finally, we will quickly discuss leveraging domain knowledge to identify outliers.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将简要讨论如何利用领域知识来识别离群值。
- en: Domain knowledge
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 领域知识
- en: To better understand the use of domain knowledge in outlier detection, let’s
    use the test scores example. Suppose the dataset represents student test scores,
    and based on educational standards, test scores are expected to fall within a
    range of 0 to 100\. Any score outside this range could be considered an outlier.
    By leveraging domain knowledge in education, we can set these boundaries to identify
    potential outliers. For instance, if a test score is recorded as 120, it would
    likely be flagged as an outlier because it exceeds the maximum possible score
    of 100\. Similarly, negative scores or scores below 0 would be considered outliers.
    Integrating domain knowledge in this manner allows us to establish meaningful
    thresholds for outlier detection, ensuring that the analysis aligns with the expected
    norms within the educational context.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解领域知识在离群值检测中的应用，我们以考试成绩为例。假设数据集代表的是学生的考试成绩，并且根据教育标准，考试成绩应该落在0到100的范围内。任何超出此范围的成绩都可以被认为是离群值。通过利用教育领域的知识，我们可以设定这些边界来识别潜在的离群值。例如，如果某个成绩记录为120，那么它很可能会被标记为离群值，因为它超出了最高分100的范围。同样，负数的成绩或低于0的成绩也会被视为离群值。以这种方式整合领域知识，使我们能够为离群值检测设定有意义的阈值，确保分析符合教育领域中的预期规范。
- en: Handling univariate outliers
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理单变量离群值
- en: Handling univariate outliers refers to the process of identifying, assessing,
    and managing data points in individual variables that deviate significantly from
    the typical patterns or distribution of the dataset. The goal is to mitigate the
    impact of these extreme values on data products.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 处理单变量异常值是指识别、评估和管理那些显著偏离数据集典型模式或分布的个别变量数据点的过程。其目的是减少这些极端值对数据产品的影响。
- en: There are several approaches to handling univariate outliers. We will start
    with deletions, always working on the example presented at the beginning of the
    chapter.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 处理单变量异常值有几种方法。我们将从删除开始，始终使用本章开头的示例进行操作。
- en: Deletion of outliers
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 删除异常值
- en: Deleting outliers refers to the process of removing data points in a dataset
    that are considered unusually extreme or deviant from the overall pattern of the
    data. The deletion of outliers comes with trade-offs. On the one hand, it is the
    simplest way to deal with extreme values. On the other hand, it leads to a reduction
    in the sample size and potential loss of valuable information. Additionally, if
    outliers are not genuine errors but rather reflect legitimate variability in the
    data, their removal can introduce bias.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 删除异常值是指从数据集中移除那些被认为异常极端或偏离数据整体模式的数据点。删除异常值有其利弊。一方面，这是处理极端值的最简单方法；另一方面，它会导致样本量的减少，并可能丧失宝贵的信息。此外，如果异常值不是错误数据，而是反映数据的合理波动，删除它们可能会引入偏差。
- en: Back to our example, after having imputed the missing data with the mean and
    calculated the IQRs, we dropped the outliers that passed the outlier threshold.
    Let’s see the code that performs these steps; you can also find it in the repository
    at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/8.handle_univariate_outliers_deletions.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/8.handle_univariate_outliers_deletions.py).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的示例，在使用均值填充缺失数据并计算IQR之后，我们删除了超过异常值阈值的异常值。让我们来看一下执行这些步骤的代码；你也可以在仓库中找到它：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/8.handle_univariate_outliers_deletions.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/8.handle_univariate_outliers_deletions.py)。
- en: 'Let’s calculate the IQR and use it to set lower and upper bounds for what is
    considered a normal range of data:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算IQR并利用它来设定正常数据范围的上下界限：
- en: '[PRE34]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let’s define the lower and upper outlier bounds. Any value outside this range
    is flagged as an outlier:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义下限和上限异常值界限。任何超出此范围的值都将被标记为异常值：
- en: '[PRE35]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The last line filters the DataFrame (`df`) to include only rows where the `Test_Score`
    values fall within the calculated lower and upper bounds:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一行过滤了DataFrame（`df`），仅保留`Test_Score`值在计算出的下限和上限之间的行：
- en: '[PRE36]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: In the following charts, we can see the updated distribution charts, after the
    removal of the outliers.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图表中，我们可以看到删除异常值后的更新分布图：
- en: '![Figure 8.10 – Distribution charts after deletion of outliers](img/B19801_08_10.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.10 – 删除异常值后的分布图](img/B19801_08_10.jpg)'
- en: Figure 8.10 – Distribution charts after deletion of outliers
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10 – 删除异常值后的分布图
- en: 'Let’s have a look at the descriptive statistics after the outlier deletion:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看删除异常值后的描述性统计数据：
- en: '[PRE37]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The changes observed after the deletion of outliers are described as follows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 删除异常值后观察到的变化如下所示：
- en: '**Mean age change**: The mean age, after deleting outliers, decreased slightly
    from 33.75 to approximately 29.27\. This reduction suggests that the removed outliers
    were older individuals.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均年龄变化**：删除异常值后，平均年龄从33.75略微下降至约29.27。这一变化表明，删除的异常值是年龄较大的个体。'
- en: '**Standard deviation change for age**: The standard deviation for age decreased
    from 17.18 to 8.16, indicating that the spread of ages became slightly narrower
    after outlier removal, which were likely contributing to greater variability in
    the original dataset.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**年龄标准差变化**：年龄的标准差从17.18降至8.16，表明删除异常值后年龄的分布略微变窄，可能是因为原数据中的异常值导致了较大的变异性。'
- en: '**Minimum and maximum age values**: The minimum age remained the same, at 18,
    while the maximum age decreased from 90 to 45, indicating that older individuals
    (potential outliers) were removed during outlier handling.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最小和最大年龄值**：最小年龄保持不变，仍为18岁，而最大年龄从90岁降至45岁，表明在处理异常值时，年龄较大的个体（潜在的异常值）被移除。'
- en: '**Mean test score change**: The mean test score increased slightly from 65.89
    to 71.20 after removing outliers, suggesting that the deleted outliers were lower
    test scores that were pulling down the original mean.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均测试成绩变化**：在删除异常值后，平均测试成绩从65.89轻微上升至71.20，表明被删除的异常值是低分，拉低了原始的均值。'
- en: '**Standard deviation change for test scores**: The standard deviation decreased
    from 24.76 to 17.79, indicating a narrower spread of test scores.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试成绩的标准差变化**：标准差从24.76降至17.79，表明测试成绩的分布变得更为集中。'
- en: '**Minimum and maximum test scores**: The minimum test score increased from
    5.00 to 20.00, while the maximum test scores remained the same at 94.00\. This
    indicates that extremely low scores were removed as part of the outlier handling.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最低和最高测试成绩**：最低测试成绩从5.00上升到20.00，而最高测试成绩保持不变，为94.00。这表明极低的分数在处理异常值时被移除。'
- en: The removal of outliers led to a decrease in both – the mean age and standard
    deviation, as well as a slight increase in the mean test score. While removing
    outliers can improve data quality, especially when the outliers are due to data
    entry errors or measurement inaccuracies, it also reduces the dataset’s variability.
    If the outliers represent true variability in the population, removing them could
    distort the overall picture of the data. Therefore, careful consideration should
    be given to whether the outliers represent genuine data points or errors.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 删除异常值导致了均值和标准差的下降，同时平均测试成绩略有上升。虽然删除异常值可以提高数据质量，尤其是当异常值由于数据输入错误或测量不准确时，但它也会减少数据集的变异性。如果异常值代表了总体中的真实变异性，删除它们可能会扭曲数据的整体情况。因此，必须谨慎考虑异常值是否为真实数据点或错误数据。
- en: Note
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Some statistical models assume normality and can be sensitive to outliers. Removing
    outliers may help meet the assumptions of certain models. So before deleting,
    you need to better understand the problem you are solving and the techniques to
    be used.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 一些统计模型假设数据符合正态分布，因此可能对异常值非常敏感。删除异常值有助于满足某些模型的假设。因此，在删除之前，你需要更好地理解你正在解决的问题以及要使用的技术。
- en: There are other ways to deal with outliers in case you don’t want to drop them
    completely from the data. In the next part, we will discuss the trimming and winsorizing
    of outliers.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不想完全删除数据中的异常值，还有其他方法可以处理它们。在接下来的部分，我们将讨论异常值的修剪和温莎化处理。
- en: Trimming
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 修剪
- en: 'Trimming involves removing a certain percentage of data from both ends of a
    distribution and then calculating the mean. For the trimming, we need to define
    a trimming fraction, which represents the proportion of data to be trimmed from
    *both tails of the distribution* when calculating the trimmed mean. It is used
    to exclude a certain percentage of extreme values (outliers) from the calculation
    of the mean. The trimming fraction is a value between 0 and 0.5, where the following
    is true:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 修剪是指从分布的两端删除一定比例的数据，然后计算均值。对于修剪，我们需要定义修剪比例，这个比例表示在计算修剪后的均值时，从*分布的两端*去除的数据比例。它用于排除一定比例的极端值（异常值）在均值计算中的影响。修剪比例的值介于0和0.5之间，满足以下条件：
- en: 0 means no trimming (include all data points)
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示不进行修剪（包括所有数据点）
- en: 0.1 means trim 10% of data from each tail
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0.1表示从每个尾部修剪10%的数据
- en: 0.2 means trim 20% of data from each tail
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0.2表示从每个尾部修剪20%的数据
- en: 0.5 means trim 50% of data from each tail (exclude the most extreme values)
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0.5表示从每个尾部修剪50%的数据（排除最极端的值）
- en: 'In our given scenario, our analysis indicates that the `Age` column exhibits
    the most significant outliers. In response, we have decided to trim our dataset
    by excluding the top and bottom percentiles specific to the `Age` column. The
    following example code demonstrates this trimming process. We are still working
    on the same dataset so we will skip the creation of the DataFrame here. However,
    you can see the whole code at the following link: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/9.trimming.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/9.trimming.py).'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，分析表明`Age`列存在最显著的异常值。为此，我们决定通过排除`Age`列中最上面和最下面的百分位数来修剪数据集。以下示例代码演示了这一修剪过程。我们仍在使用相同的数据集，因此这里跳过了DataFrame的创建。不过，你可以在以下链接查看完整代码：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/9.trimming.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/9.trimming.py)。
- en: 'Let’s have a look at the following code snippet that creates a new DataFrame
    (`df_trimmed`), which includes only the rows where the `Age` value is between
    the 10th and 90th percentiles. This effectively drops the lowest 10% and highest
    10% of values in the `Age` column:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看下面的代码片段，它创建了一个新的数据框（`df_trimmed`），只包括`Age`（年龄）值位于第10百分位和第90百分位之间的行。这实际上去除了`Age`列中最低的10%和最高的10%的值：
- en: '[PRE38]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let’s now calculate the trimmed mean for each column:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来计算每一列的修剪均值：
- en: '[PRE39]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: After trimming the data, the last line calculates the mean for each column in
    the `df_trimmed` DataFrame. The mean calculated after trimming the data is known
    as the *trimmed mean*. It represents the average value of the central 80% of the
    data, excluding the most extreme 20% (10% from each side).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在修剪数据后，最后一行计算了`df_trimmed`数据框中每列的均值。修剪后计算的均值被称为*修剪均值*。它表示去除最极端的20%（每侧10%）后的中央80%数据的平均值。
- en: Note
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Keep in mind that the trimming fraction is a way to balance the robustness of
    the trimmed mean against the amount of data excluded. You may need to experiment
    with different fractions to find a suitable balance for your data.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，修剪比例是平衡修剪均值的稳健性与排除数据量之间的一个方式。你可能需要尝试不同的比例，以找到适合你数据的平衡点。
- en: 'Let’s have a look at the updated distribution after the trimming:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看修剪后的更新分布：
- en: '![Figure 8.11 – Distribution charts after trimming of outliers at 10% threshold](img/B19801_08_11.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.11 – 在 10% 阈值下去除异常值后的分布图](img/B19801_08_11.jpg)'
- en: Figure 8.11 – Distribution charts after trimming of outliers at 10% threshold
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11 – 在 10% 阈值下去除异常值后的分布图
- en: 'Let’s also have a look at the updated statistics of the data:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也来看看更新后的数据统计信息：
- en: '[PRE40]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: In the original dataset, the `Age` column displayed a mean of 33.75 with a standard
    deviation of 17.18, while the trimmed data exhibited a higher mean of 30.22 and
    a much lower standard deviation of 6.76\. The minimum age value increased from
    18 to 20 in the trimmed data, indicating the removal of lower outliers. The maximum
    age value decreased from 90 to 41, suggesting the exclusion of higher outliers.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始数据集中，`Age`列的均值为33.75，标准差为17.18，而修剪后的数据表现为更高的均值30.22，且标准差大幅降低至6.76。修剪数据中的最低年龄值从18增加到20，表明去除了低值异常值。最高年龄值从90下降到41，表明排除了高值异常值。
- en: For the `Test_Score` column, the mean in the original dataset was 65.89, and
    the standard deviation was 24.76\. In the trimmed data, the mean increased to
    69.31, and the standard deviation decreased to 18.80 indicating a narrower spread
    of test scores. The minimum test score increased from 5 to 20, indicating the
    removal of lower outliers, while the maximum test score stayed at 94.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`Test_Score`（测试分数）列，原始数据集中的均值为65.89，标准差为24.76。在修剪后的数据中，均值上升至69.31，标准差下降至18.80，表明测试分数的分布范围变窄。最低测试分数从5增加到20，表明去除了低值异常值，而最高测试分数保持在94不变。
- en: Overall, the deletion of outliers led to changes in the central tendency (mean)
    and the spread (standard deviation) of the data for both `Age` and `Test_Score`.
    This indicates that the trimmed dataset has become more concentrated around the
    middle values, with extreme values removed.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，去除异常值导致了数据的集中趋势（均值）和分布范围（标准差）发生变化，`Age`（年龄）和`Test_Score`（测试分数）均如此。这表明修剪后的数据集变得更加集中在中间值周围，极端值被移除。
- en: Remember!
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 记住！
- en: While trimming can help in reducing the influence of extreme values, it also
    involves discarding a portion of the data. This may result in information loss,
    and the trimmed variable may not fully represent the original dataset.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然修剪有助于减少极端值的影响，但它也意味着丢弃一部分数据。这可能导致信息丢失，而修剪后的变量可能无法完全代表原始数据集。
- en: In the next section, we will present a slightly different way to deal with the
    outlier called **winsorizing**.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将介绍一种稍微不同的处理异常值的方法，叫做**温莎化**。
- en: Winsorizing
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 温莎化
- en: Instead of removing extreme values outright as with trimming, winsorizing involves
    *replacing them with less extreme values*. The extreme values are replaced with
    values closer to the center of the distribution, often at a specified percentile.
    Winsorizing can be useful when you want to *retain the size of your dataset* and
    helps preserve the overall shape of the data distribution.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 与直接去除极端值的修剪不同，winsorizing（温莎化）是通过*用较不极端的值替代它们*。极端值被替换为接近分布中心的值，通常是在指定的百分位数。温莎化在你希望*保留数据集的大小*并帮助保持数据分布的整体形态时非常有用。
- en: 'Let’s go back to our example use case and have a look at the code. You can
    find the full code at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/10.winsorizing.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/10.winsorizing.py):'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的示例用例，看看代码。你可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/10.winsorizing.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/10.winsorizing.py)找到完整的代码：
- en: '[PRE41]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '`winsorizing_fraction` is set to `0.1`, representing the proportion of data
    to be adjusted at each end of the distribution. It is specified as a percentage,
    and its value typically ranges between 0 and 50%. The process of coming up with
    the winsorizing fraction involves considering the desired amount of influence
    you want to reduce from extreme values. A common choice is to winsorize a certain
    percentage from both tails, such as 5% or 10%.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '`winsorizing_fraction`设置为`0.1`，表示在数据分布的两端调整的数据比例。它以百分比的形式表示，值通常在0和50%之间。确定Winsor
    化比例的过程涉及考虑你希望减少极端值的影响程度。一个常见的选择是将两端的某个百分比进行Winsor 化，例如5%或10%。'
- en: 'Another thing to know here is that the winsorizing process is performed at
    each column *separately and independently of the others*. Remember: we are dealing
    with outliers in a *univariate* way here:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还需要了解的一点是，Winsor 化过程是针对每一列*单独且独立地进行的*。记住：我们在这里以*单变量*的方式处理离群值：
- en: '[PRE42]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The `limits=[winsorizing_fraction, winsorizing_fraction]` argument specifies
    the proportion of data to be winsorized from each end of the distribution. Here,
    10% from the lower end and 10% from the upper end are adjusted. Extreme values
    (the lowest 10% and highest 10%) are replaced with the nearest values within the
    specified limits, thereby reducing their influence on statistical measures.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '`limits=[winsorizing_fraction, winsorizing_fraction]`参数指定了从分布两端Winsor 化的数据比例。这里从下端和上端各调整10%。极端值（最低的10%和最高的10%）将被替换为指定范围内的最近值，从而减少它们对统计量的影响。'
- en: 'Here, the updated distributions after the winsorizing are presented:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了Winsor 化后的更新分布：
- en: '![Figure 8.12 – Distribution charts after winsorizing of outliers](img/B19801_08_12.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.12 – 经 Winsor 化后的离群值分布图](img/B19801_08_12.jpg)'
- en: Figure 8.12 – Distribution charts after winsorizing of outliers
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12 – 经 Winsor 化后的离群值分布图
- en: 'Let’s also have a look at the updated statistics of the data:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看数据的更新统计信息：
- en: '[PRE43]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The mean for the `Age` column decreased from 33.75 to 30.67 after winsorizing,
    indicating a shift toward lower values as extreme high values were adjusted. The
    standard deviation also decreased significantly from 17.18 to 8.86, suggesting
    reduced variability in the dataset. The minimum value increased slightly from
    18 to 19, and the maximum value decreased from 90 to 45, reflecting the capping
    of extreme values.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '`Age`列的均值从33.75降至30.67，表明由于极端高值被调整，数据分布向较低值偏移。标准差也从17.18显著降低至8.86，说明数据集的变异性减少。最小值从18略微增加到19，最大值从90降至45，反映了极端值的限制。'
- en: As for `Test_Score`, the mean remained the same at 65.89 after winsorizing.
    The standard deviation stayed constant at 24.76, indicating that variability in
    test scores was not affected by the winsorizing process. The maximum value stayed
    the same at 94, showing no changes to the upper extreme values.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 至于`Test_Score`，Winsor 化后均值保持在65.89，标准差保持在24.76，表明测试分数的变异性未受Winsor 化过程的影响。最大值保持不变，依然为94，显示上端极端值没有发生变化。
- en: Overall, winsorizing the `Age` column resulted in a more concentrated distribution
    of values, as evidenced by the decreased standard deviation. Winsorizing successfully
    reduced the impact of extreme values in the `Age` column, making the data more
    focused around the middle range. For `Test_Score`, winsorizing did not affect
    the distribution, likely because the extreme values were already within the accepted
    range.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，对`Age`列进行Winsor 化后，数据的分布变得更加集中，标准差的减小也证明了这一点。Winsor 化成功地减少了极端值在`Age`列中的影响，使数据更加集中于中间范围。对于`Test_Score`列，Winsor
    化并未对分布产生影响，可能是因为极端值已经在接受范围内。
- en: Next, we will explore how we can apply mathematical transformations to the data
    to minimize the effect of the outliers.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨如何通过数学变换来最小化离群值的影响。
- en: Data transformation
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据变换
- en: Applying mathematical transformations such as logarithm or square root is a
    common technique to handle skewed data or stabilize variance.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 应用对数或平方根等数学变换是处理偏斜数据或稳定方差的常见技术。
- en: Reminder
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒
- en: Skewness is a measure of the asymmetry in a distribution. A positive skewness
    indicates a distribution with a tail on the right side, while a negative skewness
    indicates a tail on the left side.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 偏度是分布不对称的度量。正偏度表示分布有右尾，而负偏度表示分布有左尾。
- en: When data is right-skewed (positive skewness), meaning that most of the data
    points are concentrated on the left side with a few larger values on the right
    side, applying a logarithmic transformation compresses larger values, making the
    distribution more symmetric and closer to a normal distribution.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据右偏（正偏度）时，即大部分数据点集中在左侧，右侧有少数较大值时，应用对数变换会压缩较大值，使分布更对称，更接近正态分布。
- en: Similar to logarithmic transformation, square root transformation is used to
    mitigate the impact of larger values and make the distribution more symmetric.
    It is particularly effective when the right tail of the distribution contains
    extreme values.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于对数变换，平方根变换用于减少较大值的影响，并使分布更对称。当分布的右尾包含极端值时，特别有效。
- en: Another thing to note is that when the variance of the data increases with the
    mean (heteroscedasticity), logarithmic and square root transformation can compress
    the larger values, reducing the impact of extreme values and stabilizing the variance.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 另一点需要注意的是，当数据的方差随均值增加（异方差性）时，对数和平方根变换可以压缩较大值，减少极端值的影响，并稳定方差。
- en: Let’s go back to our example and perform a log transformation on both columns
    of our dataset. As always, you can find the full code at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/11.data_transformation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/11.data_transformation.py).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们的例子，并对数据集的两列进行对数变换。如往常一样，你可以在 [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/11.data_transformation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/11.data_transformation.py)
    找到完整的代码。
- en: 'Let’s apply a logarithmic transformation to `Age` and `Test_Score`:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对 `Age` 和 `Test_Score` 应用对数变换：
- en: '[PRE44]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '`np.log1p` is a NumPy function that computes the natural logarithm of *1 +
    x* for each value in the `Age` and `Test_Score` columns. The `log1p` function
    is used instead of the simple logarithm (`np.log`) to handle zero and negative
    values in a dataset without errors. It’s particularly useful when dealing with
    data that includes zero values or very small numbers. The transformation reduces
    skewness and can make the distribution more normal, which is useful for various
    statistical techniques that assume normally distributed data.'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '`np.log1p` 是 NumPy 中的一个函数，用于计算 `Age` 和 `Test_Score` 列中每个值的 *1 + x* 的自然对数。`log1p`
    函数用于处理数据集中的零值和负值，而不会出现错误，相比简单的对数函数 (`np.log`) 更为实用。在处理包含零值或非常小数值的数据时特别有用。这种变换可以减小偏斜度，并使分布更接近正态分布，这对于各种假设数据正态分布的统计技术非常有用。'
- en: More transformations implemented
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 更多变换的实施
- en: In the code, you’ll find both logarithmic and root transformations applied to
    the data. Take some time to explore and understand the differences between these
    two methods. Evaluate which transformation better suits your data by considering
    how each affects the distribution and variance of your dataset.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，你会发现对数据应用了对数和平方根变换。花些时间探索和理解这两种方法之间的差异。通过考虑每种变换对数据分布和方差的影响，评估哪种变换更适合你的数据。
- en: 'The updated distributions are presented in the following plot after log transforming
    the `Age` column and applying a square root transformation to the `Test_Score`
    column:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 更新后的分布在以下图表中展示，其中对 `Age` 列进行了对数变换，对 `Test_Score` 列进行了平方根变换：
- en: '![Figure 8.13 – Distribution charts after log and square route transformation](img/B19801_08_13.jpg)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.13 – 对数和平方根变换后的分布图](img/B19801_08_13.jpg)'
- en: Figure 8.13 – Distribution charts after log and square route transformation
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13 – 对数和平方根变换后的分布图
- en: 'Let’s also have a look at the updated statistics of the data:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也来看一下数据的更新统计信息：
- en: '[PRE45]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The descriptive statistics illustrate the impact of applying logarithmic transformation
    to the `Age` variable and square root transformation to the `Test_Score` variable.
    Before the transformations, the original dataset displayed a right-skewed distribution
    for `Age` with a mean of 33.75 and a wide standard deviation of 17.18\. `Test_Score`
    had a mean of 65.89, ranging from 5 to 94, with a high standard deviation of 24.76,
    indicating a large spread in the test scores.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 描述性统计显示了对`Age`变量进行对数转换和对`Test_Score`变量进行平方根转换的影响。在转换之前，原始数据集中的`Age`呈右偏分布，均值为33.75，标准差较大，为17.18。`Test_Score`的均值为65.89，范围从5到94，标准差为24.76，表明测试成绩分布较广。
- en: 'After applying the transformations, the distributions of both variables were
    visibly altered:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用了转换后，两个变量的分布明显发生了变化：
- en: The logarithmic transformation on `Age` reduced the spread of values, bringing
    the standard deviation down to 0.40 as compared to the original 17.18\. The transformed
    values now range from 2.94 to 4.51, showing a compression of extreme values.
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对`Age`进行对数转换后，值的分布被压缩，标准差从原始的17.18降至0.40。转换后的值范围从2.94到4.51，显示出极端值的压缩。
- en: For `Test_Score`, the logarithmic transformation resulted in a much more evenly
    distributed set of values, with the standard deviation decreasing from 24.76 to
    0.69\. The values became more compact and symmetric, ranging from 1.79 to 4.55.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`Test_Score`，对数据进行对数转换后，值的分布变得更加均匀，标准差从24.76降低到0.69。数据变得更加紧凑且对称，范围从1.79到4.55。
- en: The transformations had a clear leveling effect on both variables, reducing
    skewness and variability. This is evident in the reduction of standard deviations
    and narrower ranges, making the data more symmetric and closer to a normal distribution.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 这些转换对两个变量产生了明显的平滑效应，减少了偏斜度和变异性。这一点从标准差的减少和范围的缩小可以看出，使得数据更加对称，接近正态分布。
- en: However, it’s important to note that transformations, especially logarithmic
    ones, compress the scale of values and may affect interpretability. While they
    can help meet the assumptions of statistical methods by reducing skewness and
    heteroscedasticity, the transformed data may be less intuitive to understand compared
    to the original scale. Despite this, such transformations are often useful when
    preparing data for regression models or other analyses that assume normally distributed
    data.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，转换，特别是对数转换，会压缩数值的尺度，可能影响可解释性。虽然它们通过减少偏斜度和异方差性，有助于满足统计方法的假设，但转换后的数据可能比原始数据尺度更难以理解。尽管如此，这种转换在准备回归模型或其他假设数据呈正态分布的分析时，仍然非常有用。
- en: Note
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Keep in mind that log transformation is not suitable for data that contains
    zero or negative values, as the logarithm is undefined for such values.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，对数转换不适用于包含零或负值的数据，因为对数在这些值上是未定义的。
- en: To conclude this section of the chapter, we have compiled a summary table with
    the various methods discussed for handling outliers. This table highlights the
    optimal scenarios to employ each technique and provides an overview of their respective
    pros and cons.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的这一部分最后，我们汇总了一个表格，概述了处理异常值时使用的各种方法。该表格突出了每种技术的最佳使用场景，并提供了它们各自的优缺点概览。
- en: '| **Technique** | **When to** **use it** | **Pros** | **Cons** |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| **技术** | **何时使用** | **优点** | **缺点** |'
- en: '| **Trimming** | Mild outliers, preserving overall data structure | Retains
    majority of the dataset, maintains data integrity | Reduces sample size, may impact
    representativeness, arbitrary choice of trimming percentage |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| **修剪** | 轻度异常值，保留整体数据结构 | 保留大部分数据集，保持数据完整性 | 减少样本量，可能影响代表性，修剪百分比的选择可能带有随意性
    |'
- en: '| **Winsorizing** | Moderate outliers, preserving overall data | Preserves
    data distribution, mitigates the impact of extreme values | Alters data values;
    may distort distribution; requires specifying trimming limits |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| **温莎化** | 中度异常值，保留整体数据 | 保持数据分布，减轻极端值的影响 | 改变数据值；可能扭曲分布；需要指定修剪的限度 |'
- en: '| **Deleting Data** | Severe outliers | Removes the influence of extreme values,
    simplifies analysis | Reduces sample size, potential loss of information; may
    bias results toward a central tendency |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| **删除数据** | 严重异常值 | 移除极端值的影响，简化分析 | 减少样本量，可能丧失信息；可能使结果偏向中心趋势 |'
- en: '| **Transformation** | Skewed or non-normal distributions | Stabilizes variance,
    makes the data more symmetric and amenable to traditional statistical techniques
    | Interpretation challenges, results may be less intuitive, choice of transformation
    method is subjective |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| **变换** | 偏斜或非正态分布 | 稳定方差，使数据更对称，适应传统统计技术 | 解释挑战，结果可能不太直观，变换方法的选择是主观的 |'
- en: Table 8.2 – Summary of the univariate methods to deal with outliers
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8.2 – 单变量方法处理异常值的总结
- en: After exploring various techniques for addressing univariate outliers, ranging
    from simpler to more complex methods, the upcoming section will deep dive into
    the different statistical measures that are generally preferable when working
    with data containing outliers.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在探讨了各种处理单变量异常值的技术后，包括从简单到复杂的方法，接下来的部分将深入探讨在处理含有异常值的数据时，一般更为偏好的不同统计量。
- en: Robust statistics
  id: totrans-347
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 稳健统计
- en: Using robust statistical measures such as median and **Median Absolute Deviation**
    (**MAD**) instead of mean and standard deviation can reduce the influence of outliers.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 使用如中位数和**中位数绝对偏差**（**MAD**）等稳健的统计量而非均值和标准差，可以减少异常值的影响。
- en: When dealing with datasets that contain outliers or skewed distributions, choosing
    robust statistical measures becomes crucial for obtaining accurate and representative
    summaries of the data. The use of robust measures, such as the median and MAD,
    proves advantageous in scenarios where the presence of extreme values could impact
    traditional measures such as the mean and standard deviation. The median, being
    the middle value when data is ordered, is less sensitive to outliers, providing
    a more reliable measure of central tendency. Additionally, MAD, which assesses
    the spread of data while being robust to outliers, further ensures a more accurate
    representation of the dataset’s variability.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理包含异常值或偏斜分布的数据集时，选择稳健的统计量对于获取准确且具有代表性的总结至关重要。使用稳健的量度，如中位数和 MAD，在极端值可能影响传统量度（如均值和标准差）的场景中证明了其优势。中位数是排序后数据的中间值，它对异常值不那么敏感，提供了一个更可靠的集中趋势测量。此外，MAD
    评估数据的分布，并且对异常值具有稳健性，从而进一步确保数据集变异性的更准确表示。
- en: MAD
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: MAD
- en: MAD is a measure of statistical dispersion that quantifies the dispersion or
    spread of a dataset. It is calculated as the median of the absolute differences
    between each data point and the median of the dataset.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: MAD 是一种衡量统计离散度的指标，用于量化数据集的离散程度或分布。它是通过计算每个数据点与数据集的中位数之间的绝对差的中位数来得出的。
- en: 'This table summarizes the key considerations, pros, and cons of using median
    and MAD versus mean and standard deviation:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 该表总结了使用中位数和 MAD 与使用均值和标准差时的关键考虑因素、优缺点：
- en: '| **Criteria** | **Median** **and MAD** | **Mean and** **standard deviation**
    |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| **标准** | **中位数** **和 MAD** | **均值和** **标准差** |'
- en: '| **When** **to use** | Presence of outliers | Normal or symmetric distributions
    |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| **何时使用** | 异常值的存在 | 正态或对称分布 |'
- en: '| Skewed distributions | Precision in measurement |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 偏斜分布 | 测量的精确性 |'
- en: '| **Pros** | Robustness against outliers | Efficiency for normal distributions
    |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| **优点** | 对异常值的稳健性 | 对正态分布的效率 |'
- en: '| Applicability to skewed data | Ease of interpretation |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 对偏斜数据的适用性 | 解释的简便性 |'
- en: '| **Cons** | Loss of sensitivity without outliers | Sensitivity to outliers
    |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| **缺点** | 没有异常值时缺乏敏感性 | 对异常值敏感 |'
- en: '| Not robust in the presence of outliers |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 在存在异常值的情况下不稳健 |'
- en: '| **Considerations** | Useful when the central tendency needs stability | Suitable
    for datasets with minimal or no outliers |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| **考虑因素** | 当需要稳定的集中趋势时很有用 | 适用于极端值最少或没有极端值的数据集 |'
- en: '| Provides precise measures in a normal distribution |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 提供在正态分布中的精确度量 |'
- en: Table 8.3 – Which statistical methods work better with outliers
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8.3 – 哪些统计方法在处理异常值时更有效
- en: In the next section of this chapter, we will discuss how to identify multivariate
    outliers.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 本章接下来的部分将讨论如何识别多变量异常值。
- en: Identifying multivariate outliers
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别多变量异常值
- en: Multivariate outliers occur when an observation is extreme in the context of
    multiple variables simultaneously. These outliers cannot be detected by analyzing
    individual variables alone; rather, they require consideration of interactions
    between variables. Detecting multivariate outliers involves assessing data points
    in higher dimensional space. In the following parts, we will outline different
    methods to identify multivariate outliers, along with code examples for each.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 多元离群值发生在一个观测值在多个变量的上下文中同时是极端的。这些离群值不能仅通过分析单个变量来检测；相反，它们需要考虑变量之间的相互作用。检测多元离群值涉及在更高维空间中评估数据点。在接下来的部分中，我们将概述不同的方法来识别多元离群值，并为每种方法提供代码示例。
- en: Mahalanobis distance
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 马哈拉诺比斯距离
- en: Mahalanobis distance is a statistical measure used to identify outliers in multivariate
    data. It accounts for the correlation between variables and calculates the distance
    of each data point from the mean of the dataset in a scaled space. This distance
    is then compared to a threshold to identify observations that deviate significantly
    from the multivariate mean.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 马哈拉诺比斯距离是一种统计量，用于识别多元数据中的离群值。它考虑了变量之间的相关性，并计算每个数据点与数据集均值在缩放空间中的距离。然后，将这个距离与一个阈值进行比较，以识别那些显著偏离多元均值的观测值。
- en: 'For this example, we have created a new dataset with some multivariate student
    data so that we can showcase the technique in the best way possible. The code
    can be fully seen in the repository at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/12.mahalanobis_distance.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/12.mahalanobis_distance.py).
    The key steps of the process are as follows:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们创建了一个新的数据集，包含一些多元学生数据，以便我们可以以最佳方式展示这一技术。完整代码可以在仓库中查看：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/12.mahalanobis_distance.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/12.mahalanobis_distance.py)。该过程的关键步骤如下：
- en: 'Let’s import the required libraries first:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先导入所需的库：
- en: '[PRE46]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let’s generate multivariate student data:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们生成多元学生数据：
- en: '[PRE47]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: We generate a dataset of 100 samples from a multivariate normal distribution
    with a specified mean vector of `[0, 0]` and a covariance matrix of `[[1, 0.5],
    [``0.5, 1]]`.
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们从一个多元正态分布中生成了100个样本，指定均值向量为`[0, 0]`，协方差矩阵为`[[1, 0.5], [0.5, 1]]`。
- en: 'Let’s introduce outliers and create the DataFrame:'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们引入离群值并创建数据框：
- en: '[PRE48]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The following function calculates the Mahalanobis distance for each data point
    based on the mean and the inverse of the covariance matrix:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下函数根据均值和协方差矩阵的逆计算每个数据点的马哈拉诺比斯距离：
- en: '[PRE49]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The mean, covariance matrix, and inverse covariance matrix are calculated for
    the dataset:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算数据集的均值、协方差矩阵和协方差矩阵的逆：
- en: '[PRE50]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Mahalanobis distance is calculated for each data point and added as a new column
    in the DataFrame:'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个数据点计算马哈拉诺比斯距离，并将其作为新列添加到数据框中：
- en: '[PRE51]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Set a significance level for outlier detection:'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置离群值检测的显著性水平：
- en: '[PRE52]'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: The significance level (`alpha`) represents the probability of rejecting the
    null hypothesis when it is true, which in this context is the probability of incorrectly
    identifying a data point as an outlier. A common choice for `alpha` is `0.01`,
    meaning there is a 1% chance of mistakenly classifying a normal data point as
    an outlier. A lower `alpha` value makes the outlier detection more conservative,
    reducing false positives (normal points labeled as outliers). Conversely, a higher
    `alpha` value makes it more permissive, potentially identifying more points as
    outliers but increasing the chance of false positives.
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 显著性水平（`alpha`）表示在零假设为真的情况下拒绝它的概率，在本上下文中，它指的是错误地将数据点识别为离群值的概率。`alpha`常见的选择值为`0.01`，意味着错误地将正常数据点归类为离群值的概率为1%。较低的`alpha`值使得离群值检测更加保守，减少假阳性（正常点被标记为离群值）。相反，较高的`alpha`值使检测更加宽松，可能会识别出更多的离群值，但增加了假阳性的机会。
- en: 'Next, we set the chi-squared threshold:'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们设置卡方阈值：
- en: '[PRE53]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The chi-squared threshold is a critical value from the chi-squared distribution
    used to define the cutoff for outlier detection. The `chi2.ppf` function computes
    the percentile point function (inverse of the cumulative distribution function)
    for the chi-squared distribution. The degrees of freedom is equal to the number
    of features or variables used in the Mahalanobis distance calculation. In this
    case, it’s `2` (for X1 and X2). The chi-squared threshold is used to determine
    the cutoff value beyond which Mahalanobis distances are considered excessively
    high, indicating that the corresponding data points are outliers. For example,
    with `alpha = 0.01`, you are finding the threshold above which only 1% of the
    data points are expected to fall, assuming the data is normally distributed.
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 卡方阈值是从卡方分布中得到的临界值，用于定义异常值检测的截止点。`chi2.ppf`函数计算卡方分布的百分位点函数（累积分布函数的反函数）。自由度等于马氏距离计算中使用的特征或变量的数量。在这种情况下，是`2`（对于X1和X2）。卡方阈值用于确定超过该值的马氏距离被认为过高，表示相应的数据点是异常值。例如，使用`alpha
    = 0.01`时，表示你正在寻找一个阈值，超过该阈值的只有1%的数据点，假设数据是正态分布的。
- en: 'This step involves comparing each data point’s Mahalanobis distance against
    the chi-squared threshold to determine whether it is an outlier:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这一步涉及将每个数据点的马氏距离与卡方阈值进行比较，以确定它是否为异常值：
- en: '[PRE54]'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Data points with distances greater than the threshold are flagged as outliers
    and separated from the rest of the data.
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 距离大于阈值的数据点被标记为异常值，并与其余数据分开。
- en: 'Let’s now visualize the outliers:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们来可视化异常值：
- en: '[PRE55]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'In the following chart, we can see all the data points projected in a 3D space
    and we can see the outliers marked with *x*:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图表中，我们可以看到所有数据点在3D空间中的投影，并且可以看到标记为*x*的异常值：
- en: '![Figure 8.14 – Data plotted with Mahalanobis distance](img/B19801_08_14.jpg)'
  id: totrans-394
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.14 – 使用马氏距离绘制的数据](img/B19801_08_14.jpg)'
- en: Figure 8.14 – Data plotted with Mahalanobis distance
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.14 – 使用马氏距离绘制的数据
- en: Note
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Run the visualization on your laptop to be able to see this space and move around
    it in a 3D view; it’s cool!
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的笔记本电脑上运行可视化程序，以便能够看到这个空间并在3D视图中移动，挺酷的！
- en: As you can see from the 3D plot, it is very clear to spot the outliers in our
    data. Mahalanobis distance is most effective when dealing with datasets that involve
    multiple variables as it takes both the means and covariances among variables
    into account and allows identifying outliers that may not be apparent when looking
    at individual variables. In situations where variables have different units or
    scales, Mahalanobis distance can normalize the distances across variables, providing
    a more meaningful measure of outliers. Unlike univariate methods, Mahalanobis
    distance is sensitive to relationships among variables. It captures how far each
    data point is from the center of the data distribution, considering correlations
    between variables.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 从3D图中可以看出，数据中的异常值非常容易识别。马氏距离在处理涉及多个变量的数据集时最为有效，因为它考虑了变量之间的均值和协方差，并能够识别在单个变量中可能无法显现的异常值。在变量具有不同单位或尺度的情况下，马氏距离可以规范化变量间的距离，从而提供更有意义的异常值度量。与单变量方法不同，马氏距离对变量之间的关系非常敏感。它捕捉每个数据点与数据分布中心的距离，同时考虑了变量之间的相关性。
- en: In the next section of the multivariate part, we will discuss how clustering
    methods can help us detect outliers.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在多变量部分的下一节中，我们将讨论聚类方法如何帮助我们检测异常值。
- en: Clustering techniques
  id: totrans-400
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚类技术
- en: Clustering methods such as k-means or hierarchical clustering can be used to
    group similar data points. Points that do not belong to any cluster or form small
    clusters might be considered multivariate outliers.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类方法，如k-means或层次聚类，可以用于将相似的数据点分组。那些不属于任何聚类或形成小聚类的数据点，可能会被视为多变量异常值。
- en: One popular method for outlier detection using clustering is the **Density-Based
    Spatial Clustering of Applications with Noise** (**DBSACN**) algorithm. DBSCAN
    can identify clusters of dense data points and classify outliers as noise. DBSCAN
    is advantageous because it *doesn’t require specifying the number of clusters
    beforehand* and can effectively identify outliers based on density. It’s a relatively
    simple yet powerful method for outlier detection, especially in cases where clusters
    may not be well-separated or when outliers form isolated points.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的异常值检测方法是使用**基于密度的空间聚类应用与噪声**（**DBSCAN**）算法。DBSCAN 可以识别密集的数据点簇，并将异常值分类为噪声。DBSCAN
    的优势在于它*不需要事先指定聚类的数量*，并且能够基于密度有效地识别异常值。它是一个相对简单但功能强大的异常值检测方法，尤其在聚类可能不完全分离或异常值形成孤立点的情况下表现良好。
- en: 'Let’s deep dive into the code for the DBSCAN. As always, you can find the full
    code in the repository at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/13.clustering.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/13.clustering.py):'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解 DBSCAN 的代码。与往常一样，你可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/13.clustering.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/13.clustering.py)的代码库中找到完整的代码：
- en: 'Let’s import the libraries:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入所需的库：
- en: '[PRE56]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Let’s generate the example data for this method. The dataset consists of 100
    samples from a multivariate normal distribution with a mean vector of `[0, 0]`
    and a covariance matrix of `[[1, 0.5], [0.5, 1]]`. This creates a cluster of points
    that are normally distributed around the origin with some correlation between
    the features:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们生成用于该方法的示例数据集。数据集由 100 个样本组成，来自一个多元正态分布，均值向量为`[0, 0]`，协方差矩阵为`[[1, 0.5], [0.5,
    1]]`。这将创建一个围绕原点的正态分布点簇，其中各特征之间存在一定的相关性：
- en: '[PRE57]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Let’s turn the data into a DataFrame:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将数据转换为 DataFrame：
- en: '[PRE58]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Standardize the data by removing the mean and scaling to unit variance. `StandardScaler`
    from `sklearn.preprocessing` is used to fit and transform the data. Standardizing
    ensures that all features contribute equally to distance calculations by scaling
    them to have a mean of 0 and a standard deviation of 1\. This is especially important
    for distance-based algorithms such as DBSCAN:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过去除均值并缩放到单位方差来标准化数据。`sklearn.preprocessing`中的`StandardScaler`用于拟合和转换数据。标准化确保所有特征在距离计算中贡献相等，通过将它们缩放到均值为
    0、标准差为 1 来实现。这对于基于距离的算法（如 DBSCAN）尤其重要：
- en: '[PRE59]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Apply DBSCAN for outlier detection. `eps=0.4` sets the maximum distance between
    points to be considered in the same neighborhood, and `min_samples=5` specifies
    the minimum number of points required to form a dense region. DBSCAN is a clustering
    algorithm that can identify outliers as points that do not belong to any cluster.
    Points labeled `-1` by DBSCAN are considered outliers. The choice of `eps` and
    `min_samples` parameters can significantly impact the detection of outliers, and
    these values might need tuning based on the specific dataset:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用 DBSCAN 进行异常值检测。`eps=0.4` 设置了被视为同一邻域的点之间的最大距离，`min_samples=5` 指定了形成密集区域所需的最小点数。DBSCAN
    是一种聚类算法，可以识别不属于任何簇的异常值。DBSCAN 将标记为 `-1` 的点视为异常值。`eps` 和 `min_samples` 参数的选择会显著影响异常值的检测，这些值可能需要根据具体数据集进行调优：
- en: '[PRE60]'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'In the following chart, we have plotted all data points in a 2D space and can
    see the outliers on the right side of the graph:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们将所有数据点绘制在二维空间中，可以看到图表右侧的异常值：
- en: '![Figure 8.15 – DBSCAN clustering for outlier detection](img/B19801_08_15.jpg)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.15 – 基于 DBSCAN 的异常值检测聚类](img/B19801_08_15.jpg)'
- en: Figure 8.15 – DBSCAN clustering for outlier detection
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.15 – 基于 DBSCAN 的异常值检测聚类
- en: 'There is a key parameter that needs to be adjusted in DBSCAN: `eps`. The `eps`
    (epsilon) parameter essentially defines the radius around a data point, and all
    other data points within this radius are considered its neighbors.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DBSCAN 中有一个关键参数需要调整：`eps`。`eps`（epsilon）参数本质上定义了数据点周围的半径，所有位于该半径内的其他数据点都被视为该数据点的邻居。
- en: When performing DBSCAN clustering, the algorithm starts by selecting a data
    point and identifying all the data points that lie within a distance of `eps`
    from it. If the number of data points within this distance exceeds a specified
    threshold (`min_samples`), the selected data point is considered a core point,
    and all the points within its epsilon-neighborhood become part of the same cluster.
    The algorithm then recursively expands the cluster by finding the neighbors of
    the neighbors until no more points can be added.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行DBSCAN聚类时，算法首先选择一个数据点，并识别所有距离该点在`eps`范围内的数据点。如果在这个距离内的数据点数量超过指定的阈值（`min_samples`），则选中的数据点被视为核心点，所有在其epsilon邻域内的点将成为同一聚类的一部分。然后，算法通过递归地查找邻居的邻居，直到没有更多的点可以添加为止，从而扩展聚类。
- en: The choice of `eps` depends on the specific characteristics of the dataset and
    the desired granularity of clusters. It may require some experimentation and domain
    knowledge to find the appropriate value for `eps`.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '`eps`的选择取决于数据集的特定特征和所需的聚类粒度。它可能需要一些实验和领域知识来找到适合的`eps`值。'
- en: Employing k-means instead of DBSCAN offers a different approach. K-means is
    a centroid-based clustering algorithm that requires *pre-specifying the number
    of clusters*, making it essential to have prior knowledge or conduct exploratory
    analysis to determine an appropriate value for *k*. While it is sensitive to outliers,
    the simplicity and computational efficiency of k-means make it an attractive choice
    for certain scenarios. K-means may be well-suited when clusters are well-separated
    and have a relatively uniform structure. However, it is essential to be aware
    that k-means may struggle with irregularly shaped or overlapping clusters and
    can be influenced by outliers in its attempt to minimize the sum of squared distances.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 使用k-means代替DBSCAN提供了另一种方法。K-means是一种基于质心的聚类算法，需要*预先指定聚类数量*，因此必须有先验知识或进行探索性分析，以确定*k*的合适值。虽然它对异常值敏感，但k-means的简洁性和计算效率使其在某些场景中成为一个有吸引力的选择。当聚类之间分离良好并且具有相对均匀的结构时，k-means可能特别适用。然而，必须注意，k-means可能在处理不规则形状或重叠的聚类时表现不佳，并且在试图最小化平方距离和时，可能会受到异常值的影响。
- en: After having spotted the multivariate outliers, we need to decide how we are
    going to deal with those. This is the focus of the next part.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 发现多变量异常值后，我们需要决定如何处理这些异常值。这是下一部分的重点。
- en: Handling multivariate outliers
  id: totrans-422
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理多变量异常值
- en: Handling multivariate outliers involves addressing data points that deviate
    significantly in the context of multiple variables. In this part of the chapter,
    we will provide explanations and code examples for different methods to handle
    multivariate outliers.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 处理多变量异常值涉及到解决在多个变量背景下显著偏离的数据点。在本章的这一部分，我们将提供不同方法来处理多变量异常值的解释和代码示例。
- en: Multivariate trimming
  id: totrans-424
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多变量修剪
- en: This method involves limiting extreme values based on a combined assessment
    of the values across multiple variables. For example, the limits for trimming
    can be determined by considering the Mahalanobis distance, which accounts for
    correlations between variables. This technique is particularly useful when dealing
    with datasets containing outliers present across different variables. The idea
    is to preserve the overall structure of the data while mitigating the influence
    of extreme values across variables.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法涉及基于多个变量的综合评估来限制极端值。例如，修剪的限制可以通过考虑马哈拉诺比斯距离来确定，马哈拉诺比斯距离考虑了变量之间的相关性。这种技术在处理跨多个变量存在异常值的数据集时尤其有用。其思路是在减少极端值影响的同时，保留数据的整体结构。
- en: 'For this example, we are going to continue working on the data from the Mahalanobis
    distance example, and after we have calculated the Mahalanobis distance, we are
    going to drop the outliers passing the threshold. You can find the full code in
    the repository at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/14.multivariate_trimming.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/14.multivariate_trimming.py):'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将继续处理马哈拉诺比斯距离示例中的数据，在计算完马哈拉诺比斯距离后，我们将丢弃超过阈值的异常值。你可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/14.multivariate_trimming.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter08/14.multivariate_trimming.py)的代码库中找到完整代码：
- en: 'Let’s start by importing the libraries:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从导入库开始：
- en: '[PRE61]'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Let’s generate multivariate student data
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们生成多变量学生数据。
- en: '[PRE62]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Define the function to calculate the Mahalanobis distance, which measures how
    far a data point is from the mean of the distribution, taking into account the
    correlation between features:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义计算马氏距离的函数，该距离衡量数据点与分布均值的距离，考虑特征之间的相关性：
- en: '[PRE63]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Prepare the data for outlier detection:'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为异常值检测准备数据：
- en: '[PRE64]'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Calculate the Mahalanobis distance for each data point:'
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个数据点的马氏距离：
- en: '[PRE65]'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Set the threshold for outlier detection:'
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置异常值检测的阈值：
- en: '[PRE66]'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Filter the DataFrame to separate outliers from the rest of the data.
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤数据框，分离出异常值与其余数据。
- en: '[PRE67]'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Let’s present the distribution plots before the outlier handling.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理异常值之前，让我们先展示分布图。
- en: '![Figure 8.16 – Distribution charts with multivariate outliers](img/B19801_08_16.jpg)'
  id: totrans-442
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.16 – 包含多变量异常值的分布图](img/B19801_08_16.jpg)'
- en: Figure 8.16 – Distribution charts with multivariate outliers
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.16 – 包含多变量异常值的分布图
- en: 'The descriptive statistics of the original data are as follows:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据的描述性统计如下：
- en: '[PRE68]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'After having dropped the data that are considered multivariate outliers, we
    can observe the changes in the following distributions:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 在删除被认为是多变量异常值的数据后，我们可以观察到以下分布的变化：
- en: '![Figure 8.17 – Distribution charts after removing multivariate outliers](img/B19801_08_17.jpg)'
  id: totrans-447
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.17 – 移除多变量异常值后的分布图](img/B19801_08_17.jpg)'
- en: Figure 8.17 – Distribution charts after removing multivariate outliers
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.17 – 移除多变量异常值后的分布图
- en: 'Finally, let’s have a look at the updated descriptive statistics:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们来看看更新后的描述性统计：
- en: '[PRE69]'
  id: totrans-450
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Having trimmed the outliers, let’s discuss the changes observed in the data:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 在修剪掉异常值之后，让我们讨论数据中观察到的变化：
- en: The count of observations reduced from 102 to 100 after removing outliers, so
    we dropped two records
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除异常值后，观察的数量从102降至100，因此我们丢弃了两条记录。
- en: In the `X1` column, the mean decreased from 0.248 to 0.083, and the standard
    deviation reduced from 1.479 to 0.907
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`X1`列中，均值从0.248降至0.083，标准差从1.479降至0.907。
- en: In the `X2` column, the mean decreased from 0.281 to 0.117, and the standard
    deviation reduced from 1.459 to 0.881
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`X2`列中，均值从0.281降至0.117，标准差从1.459降至0.881。
- en: The maximum values for `X1` and `X2` were capped at 1.857815 and 2.679717, respectively,
    indicating the removal of extreme outliers
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X1`和`X2`的最大值分别被限制在1.857815和2.679717，表明极端异常值已被移除。'
- en: Overall, removing outliers has resulted in a dataset with reduced variability,
    particularly in terms of mean and standard deviation. Extreme values that could
    potentially skew the analysis have been mitigated.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，移除异常值后，数据集的变异性减小，尤其是在均值和标准差方面。极端值可能对分析产生偏差的风险已被减轻。
- en: Let’s summarize the key takeaways from this chapter.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结本章的关键要点。
- en: Summary
  id: totrans-458
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we deep-dived into handling missing values and outliers. We
    understood that missing values can distort our analyses and learned a range of
    imputation techniques, from simple mean imputation to advanced machine learning-based
    strategies. Similarly, we recognized that outliers could skew our results and
    deep-dived into methods to detect and manage them, both in univariate and multivariate
    contexts. By combining theory and practical examples, we gained a deeper understanding
    of the considerations, challenges, and strategies that go into ensuring the quality
    and reliability of our data.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了缺失值和异常值的处理。我们理解了缺失值如何扭曲我们的分析，并学习了从简单的均值插补到先进的基于机器学习的插补技术等多种插补方法。同样，我们认识到异常值可能会偏移我们的结果，并深入研究了在单变量和多变量背景下检测和管理异常值的方法。通过结合理论和实践示例，我们对确保数据质量和可靠性的考虑、挑战及策略有了更深入的理解。
- en: Armed with these insights, we can now move on to the next chapter, where we
    will discuss scaling, normalization, and standardization of features.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有这些见解后，我们现在可以进入下一章，讨论特征的缩放、归一化和标准化。
