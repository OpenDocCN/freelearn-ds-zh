- en: Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: In this chapter, we will cover one of the most popular and widely used deep
    neural networks—the **convolutional neural network** (**CNN**, also known as **ConvNet**).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一种最受欢迎且广泛使用的深度神经网络——**卷积神经网络**（**CNN**，也称为**ConvNet**）。
- en: It is this class of neural networks that is largely responsible for the incredible
    feats that have been accomplished in computer vision over the last few years,
    starting with AlexNet, created by Alex Krizhevsky, Geoffrey Hinton, and Ilya Sutskever, which
    outperformed all the other models in the 2012 **ImageNet Large Scale Visual Recognition
    Challenge** (**ILSVRC**), thus beginning the deep learning revolution.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正是这一类神经网络在过去几年里大大推动了计算机视觉领域的惊人进展，从由Alex Krizhevsky、Geoffrey Hinton和Ilya Sutskever创建的AlexNet开始，该模型在2012年**ImageNet大规模视觉识别挑战赛**（**ILSVRC**）中超越了所有其他模型，从而开启了深度学习的革命。
- en: ConvNets are a very powerful type of neural network for processing data. They
    have a grid-like topology (that is, there is a spatial correlation between neighboring
    points) and are tremendously useful in a variety of applications, such as facial
    recognition, self-driving cars, surveillance, natural language processing, time-series
    forecasting, and much more.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（ConvNets）是一种非常强大的神经网络类型，用于处理数据。它们具有网格状拓扑结构（即，相邻点之间存在空间关联），并且在各种应用中非常有用，例如人脸识别、自动驾驶汽车、监控、自然语言处理、时间序列预测等。
- en: We will start by introducing the basic building blocks of ConvNets and introduce
    some of the architectures used in practice, such as AlexNet, VGGNet, and Inception-v1,
    as well as exploring what makes them so powerful.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先介绍卷积神经网络的基本构建块，并介绍一些实际应用中使用的架构，例如AlexNet、VGGNet和Inception-v1，同时探索它们为何如此强大。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The inspiration behind ConvNets
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络的灵感来源
- en: Types of data used in ConvNets
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络中使用的数据类型
- en: Convolutions and pooling
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积和池化
- en: Working with the ConvNet architecture
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用卷积神经网络架构
- en: Training and optimization
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练与优化
- en: Exploring popular ConvNet architectures
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索流行的卷积神经网络架构
- en: The inspiration behind ConvNets
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络的灵感来源
- en: CNNs are a type of **artificial neural network** (**ANN**); they are loosely
    inspired by the concept that the human visual cortex processes images and allows
    our brains to recognize objects in the world and interact with them, which allows
    us to do a number of things, such as drive, play sports, read, watch movies, and
    so on.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）是一种**人工神经网络**（**ANN**）；它们受到人类视觉皮层处理图像并使我们的脑部能够识别世界中的物体并与之互动的概念启发，这使我们能够做许多事情，例如驾驶、打球、阅读、看电影等。
- en: It has been found that computations that somewhat resemble convolutions take
    place in our brains. Additionally, our brains possess both simple and complex
    cells. The simple cells pick up basic features, such as edges and curves, while
    the complex cells show spatial invariance, while also responding to the same cues
    as the simple cells.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 已经发现，类似卷积的计算过程在我们的大脑中发生。此外，我们的大脑中存在简单和复杂细胞。简单细胞捕捉基本特征，如边缘和曲线，而复杂细胞则表现出空间不变性，同时也响应与简单细胞相同的线索。
- en: Types of data used in ConvNets
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络中使用的数据类型
- en: CNNs work exceptionally well on visual tasks, such as object classification
    and object recognition in images and videos and pattern recognition in music,
    sound clips, and so on. They work effectively in these areas because they are
    able to exploit the structure of the data to learn about it. This means that we
    cannot alter the properties of the data. For example, images have a fixed structure
    and if we were to alter this, the image would no longer make sense. This differs
    from ANNs, where the ordering of feature vectors does not matter. Therefore, the
    data for CNNs is stored in multidimensional arrays.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络在视觉任务上表现出色，例如图像和视频中的物体分类与识别，以及音乐、音频片段中的模式识别等。它们在这些领域的效果良好，因为它们能够利用数据的结构进行学习。这意味着我们无法改变数据的属性。例如，图像具有固定结构，如果我们改变这一结构，图像将不再有意义。这与人工神经网络（ANN）不同，后者中特征向量的顺序不重要。因此，卷积神经网络的数据存储在多维数组中。
- en: In computers, images are in grayscale (black and white) or are colored (RGB),
    and videos (RGB-D) are made of up pixels. A pixel is the smallest unit of a digitized
    image that can be shown on a computer and holds values in the form of [0, 255].
    The pixel value represents its intensity.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机中，图像可以是灰度图像（黑白图像）或彩色图像（RGB），视频（RGB-D）由像素组成。像素是数字化图像中最小的单位，可以在计算机上显示，并且其值的范围为[0,
    255]。像素值表示其强度。
- en: 'If the pixel value is `0`, then it is black, if it is `128`, then it is gray,
    and if it is `255`, then it is white. We can see this in the following screenshot:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果像素值为`0`，则表示黑色；如果像素值为`128`，则表示灰色；如果像素值为`255`，则表示白色。我们可以在以下截图中看到这一点：
- en: '![](img/1da385c7-7e21-4267-8850-fd52ccd2d275.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1da385c7-7e21-4267-8850-fd52ccd2d275.png)'
- en: 'As we can see, grayscale images only require 1 byte of data, but colored images,
    on the other hand, are made up of three different values—red, blue, and green—since
    any color can be shown using a combination of these three colors. We can see the
    colorspace in the following diagram (refer to the color diagram from the graphic
    bundle):'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，灰度图像只需要1字节的数据，而彩色图像则由三种不同的值——红色、蓝色和绿色组成——因为任何颜色都可以通过这三种颜色的组合来显示。我们可以在以下图示中看到色彩空间（参见图形包中的色彩图）：
- en: '![](img/10f3ac5f-ca77-4c5b-8ef9-bf25960f2553.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10f3ac5f-ca77-4c5b-8ef9-bf25960f2553.jpg)'
- en: Depending on where in the cube we are, we clearly get a different color.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们在立方体中的位置，我们显然会得到不同的颜色。
- en: Instead of looking at it as a cube or varying color intensities, we can look
    at it as having three separate channels—red, blue, and green. Then, each pixel
    requires 3 bytes of storage.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其看作是拥有三个独立通道——红色、蓝色和绿色，而不是看作一个立方体或不同的颜色强度。那么，每个像素需要3字节的存储。
- en: Normally, we cannot see the individual pixels in the images and videos that
    we see on our monitors because they have a very high resolution. This can vary
    greatly, but the pixels are usually between several hundred to several thousands
    of **dots** (pixels) **per inch** (**dpi**).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们无法看到显示在显示器上的图像和视频中的单独像素，因为它们的分辨率非常高。这可以有很大的不同，但像素通常在每英寸几百到几千个**点**（像素）**每英寸**（**dpi**）之间。
- en: A bit (binary unit) is the fundamental unit of a computer and each bit can take
    on one of two values—0 or 1\. A single byte consists of 8 bits. In case you're
    wondering, the [0, 255] range comes from the pixel value being stored in 8 bits,
    (2⁸ – 1 = 255). However, we could also have a 16-bit data value. In colored images,
    we can have either 8-bit, 16-bit, 24-bit, or 30-bit values, but we usually use
    24-bit values since we have three colored pixels, RGB, and each has an 8-bit data
    value.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 位（binary unit）是计算机的基本单位，每个位可以取0或1两个值。一个字节由8个位组成。如果你想知道，[0, 255]范围来自像素值被存储为8位（2⁸
    - 1 = 255）。然而，我们也可以有一个16位数据值。在彩色图像中，我们可以使用8位、16位、24位或30位值，但通常使用24位值，因为我们有三种颜色的像素，RGB，每种颜色有8位的数据值。
- en: Suppose we have a grayscale image with a size of 512 × 512 × 1 (height × width
    × channel). We can store it in a two-dimensional tensor (matrix), [![](img/24029c06-3619-459a-a965-f4cd772d2ec1.png)],
    where each *i* and *j* value is a pixel with some intensity. To store this image
    on our disk, we need 512 × 512 = 262,144 bytes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个灰度图像，尺寸为512 × 512 × 1（高度 × 宽度 × 通道）。我们可以将其存储在一个二维张量（矩阵）中，[![](img/24029c06-3619-459a-a965-f4cd772d2ec1.png)]，其中每个*i*和*j*的值表示一个具有一定强度的像素。要将这个图像存储到磁盘上，我们需要512
    × 512 = 262,144字节。
- en: Now, suppose we have a colored image with a size of 512 × 512 × 3 (height ×
    width × channel). We can store it in a three-dimensional tensor, [![](img/b5ede4c4-93bb-41b5-9258-8274e0c9d967.png)], where
    each *i, j,* and *k* value is a colored pixel with some intensity. To store this
    image on our disk, we would need 512 × 512 × 3 = 786,432 bytes, which tells us
    that storing a colored image requires a lot more space and so a longer time to
    process.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们有一个尺寸为512 × 512 × 3（高度 × 宽度 × 通道）的彩色图像。我们可以将其存储在一个三维张量中，[![](img/b5ede4c4-93bb-41b5-9258-8274e0c9d967.png)]，其中每个*i,
    j,*和*k*的值表示一个具有一定强度的彩色像素。要将这个图像存储到我们的磁盘上，我们需要512 × 512 × 3 = 786,432字节，这说明存储彩色图像需要更多的空间，因此处理时间也更长。
- en: A colored video can be represented as a sequence of frames (images). We start
    by making the time discrete so that each frame is a fixed time step apart from
    the other. We can store a regular video (grayscale) in a three-dimensional array,
    where one axis represents the height of the frame, another represents the width,
    and the third represents the length of time.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 彩色视频可以表示为一系列帧（图像）。我们从将时间离散化开始，使得每帧之间有固定的时间间隔。我们可以将常规视频（灰度图像）存储在一个三维数组中，其中一个轴表示帧的高度，另一个表示宽度，第三个表示时间长度。
- en: We will learn, later in this chapter, that CNNs also work quite well for audio
    and time-series data because they are resistant to noise. We represent time-series
    data as a one-dimensional array, where the length of the array is time, which
    is what we convolve over.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章稍后学习到，CNNs对于音频和时间序列数据也非常有效，因为它们能抵抗噪声。我们将时间序列数据表示为一维数组，其中数组的长度表示时间，这正是我们进行卷积的对象。
- en: Convolutions and pooling
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积和池化
- en: In [Chapter 7](e1f37008-1ad5-49f6-a229-4d6249c2d7e3.xhtml), *Feedforward Neural
    Networks*, we saw how deep neural networks are built and how weights connect neurons
    in one layer to neurons in the previous or following layer. The layers in CNNs,
    however, are connected through a linear operation known as **convolution**, which
    is where their name comes from and what makes it such a powerful architecture
    for images.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](e1f37008-1ad5-49f6-a229-4d6249c2d7e3.xhtml)《前馈神经网络》中，我们看到深度神经网络是如何构建的，以及如何通过权重将一个层的神经元与前一层或后一层的神经元连接。然而，CNNs
    中的层是通过一种线性操作，即 **卷积**，来连接的，这也是它们名字的来源，也是它们在图像处理方面如此强大的原因。
- en: Here, we will go over the various kinds of convolution and pooling operations
    used in practice and what the effect of each is. But first, let's see what convolution
    actually is.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将介绍在实践中使用的各种卷积和池化操作，以及每种操作的效果。但首先，让我们看看卷积到底是什么。
- en: Two-dimensional convolutions
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二维卷积
- en: 'In mathematics, we write convolutions as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学中，我们将卷积表示为如下形式：
- en: '![](img/6f3cc0d7-eb91-47f5-a207-58f7836505e3.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f3cc0d7-eb91-47f5-a207-58f7836505e3.png)'
- en: What this means is that we have a function, *f*, which is our input and a function, *g*,
    which is our kernel. By convolving them, we receive an output (sometimes referred
    to as a feature map).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们有一个函数 *f* 作为输入，另一个函数 *g* 作为卷积核。通过对它们进行卷积，我们得到一个输出（有时称为特征图）。
- en: 'However, in CNNs, we usually use discrete convolutions, which are written as
    follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在卷积神经网络（CNNs）中，我们通常使用离散卷积，表示方式如下：
- en: '![](img/f90baffb-72db-4880-ba59-908c8c5c4ebf.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f90baffb-72db-4880-ba59-908c8c5c4ebf.png)'
- en: 'Let''s suppose we have a two-dimensional array with a height of 5 and a width
    of 5, and a two-dimensional kernel with a height of 3 and a width of 3\. Then,
    the convolution and its output will look as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个高度为 5，宽度为 5 的二维数组，以及一个高度为 3，宽度为 3 的二维卷积核。那么，卷积及其输出将如下所示：
- en: '![](img/6836f4cf-1327-431e-aef8-dd2804d3bd61.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6836f4cf-1327-431e-aef8-dd2804d3bd61.png)'
- en: Some of the values in the output matrix are left empty as an exercise for us
    to try the convolution by hand and get a better idea of how this operation works.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 输出矩阵中的一些值留空，作为我们手动尝试卷积操作的练习，帮助更好地理解此操作是如何工作的。
- en: As you can see, the kernel slides over the input and produces a feature map
    with a height of 3 and a width of 3\. This feature map tells us the degree to
    which the functions *f* and *g* overlap as one passes over the other. We can think
    of this as scanning the input for a certain pattern; in other words, the feature
    map is looking for the same pattern in different places of the input.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，卷积核滑过输入，生成一个高度为 3，宽度为 3 的特征图。这个特征图告诉我们函数 *f* 和 *g* 重叠的程度，即一个函数如何在另一个函数上滑动。我们可以把这看作是在输入中扫描某个模式；换句话说，特征图在不同位置查找相同的模式。
- en: To get a better understanding of how the kernel moves over the input, think
    of a typewriter. The convolution starts at the top left, applies element-wise
    multiplication and addition, then moves a step to the right and repeats until
    it reaches the rightmost position without going beyond the bounds of the input.
    It then moves down one row and repeats this process until it reaches the bottom-right
    position.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解卷积核是如何在输入上移动的，可以想象一下打字机。卷积从左上角开始，进行逐元素的乘法和加法，然后向右移动一步并重复此过程，直到到达最右侧的位置，且不越过输入的边界。接着，它向下一行移动，并重复这一过程，直到到达右下角的位置。
- en: 'Suppose that we now have a 3 × 3 two-dimensional tensor as input and apply
    to it a 2 × 2 kernel. It will look as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们现在有一个3 × 3的二维张量作为输入，并应用一个2 × 2的卷积核。结果如下所示：
- en: '![](img/1320d8f2-aa05-4358-a6ed-d5d6b17eb917.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1320d8f2-aa05-4358-a6ed-d5d6b17eb917.png)'
- en: 'We can mathematically write the individual outputs in the feature map as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将特征图中的每个输出数学地表示如下：
- en: '![](img/64ed160e-a6a9-4109-a7db-4df26903c1dc.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/64ed160e-a6a9-4109-a7db-4df26903c1dc.png)'
- en: 'Now, we can rewrite the preceding discrete convolution equation as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将前面的离散卷积公式重写如下：
- en: '![](img/c871a72c-972f-4146-ade9-88a00429107b.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c871a72c-972f-4146-ade9-88a00429107b.png)'
- en: This gives us a much clearer idea of what is happening.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我们对发生的事情有了更清晰的理解。
- en: From the preceding operation, we can tell that if we keep applying convolutions
    to feature maps, the height and width of each layer will decrease subsequently.
    So, sometimes, we may want to preserve the size of *I* after the convolution operation
    (especially if we are building a very deep CNN), in which case, we pad the outside
    of the matrix with zeros. What this does is it increases the size of the matrix
    before applying the convolution operation.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的操作可以看出，如果我们不断地对特征图进行卷积处理，每一层的高度和宽度会逐渐减小。所以，有时我们可能希望在卷积操作后保持*I*的大小（尤其是当我们构建一个非常深的卷积神经网络时），在这种情况下，我们可以在矩阵外部填充零。这样做是为了在应用卷积操作之前增大矩阵的大小。
- en: So, if *I* is an n × n array and our kernel is a k × k array and we want our
    feature map to be n × n as well, then we pad *I* once, turning it into an (n+2) ×
    (n+2) array. Now, after we convolve the two, the resulting feature map will have
    an n × n size.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果*I*是一个n × n的数组，而我们的卷积核是一个k × k的数组，并且我们希望我们的特征图也是n × n的，那么我们对*I*进行一次填充，将其变为(n+2)
    × (n+2)的数组。现在，经过卷积操作后，生成的特征图将是n × n的大小。
- en: 'The padding operation looks as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 填充操作如下所示：
- en: '![](img/5ef9913a-17ea-49e3-a233-af91c053c7a4.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ef9913a-17ea-49e3-a233-af91c053c7a4.png)'
- en: In practice, this is referred to as full padding. When we do not pad, we refer
    to it as zero padding.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这被称为全填充。当我们不进行填充时，我们称之为零填充。
- en: Should we want to reduce the size of the feature map, we can use a larger kernel
    or we can increase the stride size—each will give a different result. When the
    stride is 1, we slide our kernel as normal, one at a time. However, when we increase
    the stride to 2, the kernel hops two positions each time.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望减小特征图的大小，可以使用更大的卷积核或增加步幅大小——每种方式都会产生不同的结果。当步幅为1时，我们像往常一样每次滑动一个位置。然而，当步幅增加到2时，卷积核每次跳跃两个位置。
- en: 'Let''s use the preceding matrix we convolved and see what happens when we change
    the stride to 2:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用前面卷积过的矩阵，看看当我们将步幅设置为2时会发生什么：
- en: '![](img/6bfff6f5-8d59-48ad-a167-f482188a0c83.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6bfff6f5-8d59-48ad-a167-f482188a0c83.png)'
- en: 'Armed with this knowledge, we can calculate the resulting shape of the feature
    map using the following formula:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些知识，我们可以使用以下公式计算特征图的结果形状：
- en: '![](img/ee958e51-e175-4ebb-a789-e692c1a338ca.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee958e51-e175-4ebb-a789-e692c1a338ca.png)'
- en: Here, *I* is an n × n array, *K* is a k × k array, *p* is the padding, and *s* is
    the stride.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*I*是一个n × n的数组，*K*是一个k × k的数组，*p*是填充，*s*是步幅。
- en: Additionally, we can repeat this process as many times as we like, using different
    kernels and producing multiple feature maps. We then stack these outputs together
    and form a three-dimensional array of feature maps, which we call a layer.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以根据需要重复此过程，使用不同的卷积核并生成多个特征图。然后，我们将这些输出堆叠在一起，形成一个三维特征图阵列，我们称之为一层。
- en: For example, say we have an image with a size of 52 × 52 and a kernel with a
    size of 12 × 12 and a stride of 2\. We apply this to our input 15 times and stack
    the outputs together. We get a three-dimensional tensor with a size of [![](img/157eb44b-4df3-4910-820c-d2370dde3dbe.png)].
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有一个大小为52 × 52的图像，卷积核的大小为12 × 12，步幅为2。我们将其应用到输入上15次，并将输出堆叠在一起。我们得到一个大小为[![](img/157eb44b-4df3-4910-820c-d2370dde3dbe.png)]的三维张量。
- en: When we are building CNNs for real-world applications, it is more than likely
    that we will want to work with colored images. We saw previously that grayscale
    images can be expressed as two-dimensional tensors (matrices) and so the convolutions
    were two-dimensional as well. However, colored images, as we know, are made up
    of three channels stacked on top of each other—red, blue, and green. The image
    then has the [![](img/c3738393-3ec5-419c-a2c1-d9a3a4353195.png)] shape and so
    the associated convolution will also have the same shape. But interestingly, convolving
    a colored image with a three-dimensional convolution gives us a two-dimensional
    feature map.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们为实际应用构建卷积神经网络时，很可能需要处理彩色图像。我们之前看到，灰度图像可以表示为二维张量（矩阵），因此卷积也是二维的。然而，彩色图像由三个通道组成，分别是红色、蓝色和绿色。这三个通道堆叠在一起，图像具有[![](img/c3738393-3ec5-419c-a2c1-d9a3a4353195.png)]的形状，因此相关的卷积也将具有相同的形状。但有趣的是，对彩色图像进行三维卷积会得到一个二维的特征图。
- en: 'In the preceding example, we went over how to perform a convolution on a two-dimensional
    tensor, but colored images have three channels. So, what we are going to do is
    split the three channels and convolve over them individually, then sum their respective
    outputs together using an element-wise addition to produce a two-dimensional tensor.
    To get a better understanding of this, let''s assume we have an input with a size
    of 3 × 3 × 3, which we can split into three channels, as so:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们讲解了如何对二维张量进行卷积，但是彩色图像有三个通道。因此，我们要做的是将这三个通道分开，分别对它们进行卷积，然后使用逐元素加法将它们各自的输出加在一起，最终得到一个二维张量。为了更好地理解这个过程，假设我们的输入大小为3
    × 3 × 3，我们可以将其分成三个通道，如下所示：
- en: '![](img/23e495bd-09a5-4138-ba52-1c74fea82d3e.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/23e495bd-09a5-4138-ba52-1c74fea82d3e.png)'
- en: 'This tells us that *I[i,j] = R[i,j] + B[i,j] + G[i,j]*. Now that we have the
    channels separated, let''s convolve them with our 2 × 2 kernel. After convolving
    each channel with our kernel, we get the following outputs:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，*I[i,j] = R[i,j] + B[i,j] + G[i,j]*。现在我们已经将通道分开，让我们用2 × 2的卷积核分别对它们进行卷积。每个通道与卷积核进行卷积后，我们得到以下输出：
- en: 'The result after convolving the red channel is as follows:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对红色通道进行卷积后的结果如下：
- en: '![](img/c8f232b3-e6e4-4c5c-a4df-4db05de55c05.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c8f232b3-e6e4-4c5c-a4df-4db05de55c05.png)'
- en: 'The result after convolving the blue channel is as follows:'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对蓝色通道进行卷积后的结果如下：
- en: '![](img/ba7f6281-88c3-43dc-8333-e6c09a8a5910.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba7f6281-88c3-43dc-8333-e6c09a8a5910.png)'
- en: 'The result after convolving the green channel is as follows:'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对绿色通道进行卷积后的结果如下：
- en: '![](img/dcb251d7-d738-4461-92e7-65405cce8844.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dcb251d7-d738-4461-92e7-65405cce8844.png)'
- en: 'Should we want to go deeper, we can mathematically write out how each element
    of the output was calculated. This looks as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想更深入地了解，可以通过数学公式写出每个输出元素是如何计算的。公式如下：
- en: '![](img/6c806956-9ece-4590-addb-542f10016a1f.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6c806956-9ece-4590-addb-542f10016a1f.png)'
- en: We can think of this as applying a three-dimensional convolution to the input.
    It is important to make a note here that the depth of the kernel is the same as
    that of the image and so it moves just as the two-dimensional convolution operation
    does.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以把这看作是对输入应用三维卷积。这里需要注意的是，卷积核的深度与图像的深度相同，因此它的移动方式与二维卷积操作相同。
- en: Instead of applying a kernel separately to each channel, we apply a single three-dimensional
    kernel to the input at once and use element-wise multiplication and addition.
    We do so because this allows us to convolve over volumetric data.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们并不是单独对每个通道应用卷积核，而是一次性对输入应用一个三维卷积核，并使用逐元素相乘和相加。这样做的原因是它允许我们对体积数据进行卷积。
- en: Here, we applied 15 kernels with a size of 12 × 12 and a stride of 2 to an input
    with a size of 52 × 52, and the resulting output had a size of 21 × 21 × 15\.
    Now, to this output, we can apply a convolution with a size of 8 × 8 × 15\. So,
    the output from this operation will have a size of 14 × 14\. Of course, as before,
    we can stack multiple outputs together to form a layer.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们对一个大小为52 × 52的输入应用了15个大小为12 × 12，步长为2的卷积核，得到的输出大小为21 × 21 × 15。接下来，我们可以对这个输出应用大小为8
    × 8 × 15的卷积。这样，这次操作的输出大小将是14 × 14。当然，和之前一样，我们可以将多个输出堆叠在一起形成一个层。
- en: One-dimensional convolutions
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一维卷积
- en: Now that we know how convolutions work in two dimensions, it is time for us
    to see how they work in one dimension. We use these for time-series data, such
    as those associated with stock prices or audio data. In the preceding section, the
    kernel moved from the top left along the axis to the top right, then dropped one
    or more rows (depending on the stride). This process was repeated until it reached
    the bottom right of the grid.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了二维卷积的工作原理，是时候看看它们在一维中的工作方式了。我们将这些用于时间序列数据，例如与股票价格或音频数据相关的数据。在前面的章节中，卷积核从左上角沿着轴移动到右上角，然后跳过一行或多行（取决于步幅）。这一过程会重复，直到它到达网格的右下角。
- en: Here, we only convolve along the time axis—that is, the temporal dimension (from
    left to right). However, the effects of padding and stride still apply here as
    well.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只沿着时间轴进行卷积——也就是说，沿着时间维度（从左到右）。然而，填充和步幅的影响在这里依然适用。
- en: 'Let''s suppose we have the following data:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有以下数据：
- en: '![](img/4cb3d150-2f51-46c7-a762-3fc9f7ba4d33.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4cb3d150-2f51-46c7-a762-3fc9f7ba4d33.png)'
- en: 'We also have the following kernel with a size of 1 × 3 that we want to apply
    to it:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有以下一个大小为 1 × 3 的卷积核，我们希望将其应用到该数据上：
- en: '![](img/518e3c4f-a8c9-444f-8afa-81137b3c97ce.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/518e3c4f-a8c9-444f-8afa-81137b3c97ce.png)'
- en: 'Then, after convolving it with a stride of 2, we get the following output:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在使用步幅为 2 的卷积后，我们得到以下输出：
- en: '![](img/9fa27b86-9a7c-4d90-b737-6e13fb18657a.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9fa27b86-9a7c-4d90-b737-6e13fb18657a.png)'
- en: 'Interestingly, we can also apply one-dimensional convolutions to matrices (images).
    Let''s see how this works. Say we have a 4 × 4 input matrix and a 4 × 1 kernel.
    Then, the convolution will be carried out as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们还可以将一维卷积应用于矩阵（图像）。让我们看看它是如何工作的。假设我们有一个 4 × 4 的输入矩阵和一个 4 × 1 的卷积核。那么，卷积将按以下方式进行：
- en: '![](img/2e4f2a72-d175-4863-9fee-76a21df36236.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2e4f2a72-d175-4863-9fee-76a21df36236.png)'
- en: 'Let''s take a look under the hood and see how each of the outputs is calculated:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看每个输出是如何计算的：
- en: '![](img/39508250-614a-443b-83db-0a6cfd6398b1.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/39508250-614a-443b-83db-0a6cfd6398b1.png)'
- en: However, our kernel size could be larger as well, just as in the earlier case
    of two-dimensional convolutions.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的卷积核大小也可以更大，就像之前二维卷积的情况一样。
- en: 1 × 1 convolutions
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 × 1 卷积
- en: In the previous section, we covered two-dimensional convolutions on volumetric
    data and these convolutions were performed depth-wise (the depth of each convolution
    is the same as the depth of the input). This is essentially the same as multiplying
    the values along the depth of the channel with those of the kernel and then summing
    them together to get a single value.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们介绍了在体数据上进行的二维卷积，这些卷积是沿深度方向执行的（每个卷积的深度与输入的深度相同）。这实际上就像是将通道深度上的值与卷积核的值相乘，然后将它们相加得到一个单一的值。
- en: If we take the same input as previously with a shape of 21 × 21 × 15 and apply
    our 1 × 1 kernel, which has a 1 × 1 × 15 shape, our output will have a shape of
    21\. If we apply this operation 12 times, our output will then be 21 × 21 × 12\.
    We use these shapes because they can reduce the dimensionality of our data because
    applying kernels of a larger size is computationally more expensive.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们取之前相同的输入，形状为 21 × 21 × 15，并应用一个形状为 1 × 1 × 15 的 1 × 1 卷积核，那么我们的输出将是 21。如果我们应用此操作
    12 次，则输出将是 21 × 21 × 12。我们使用这些形状是因为它们可以减少数据的维度，因为应用更大大小的卷积核在计算上更为昂贵。
- en: Three-dimensional convolutions
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 三维卷积
- en: Now that we have a good idea of how two-dimensional convolutions work, it is
    time to move on to three-dimensional convolutions. But wait—didn't we just learn
    about three-dimensional convolutions? Kind of, but not really because, if you
    remember, they had the same depth as the volume we were convolving over and moved
    the same as the two-dimensional convolutions did—along the height and the width
    of the image.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对二维卷积的工作原理有了一个很好的了解，是时候继续探讨三维卷积了。但等一下——我们不是已经学习了三维卷积吗？有点，但不完全是，因为如果你记得的话，三维卷积的深度与我们正在卷积的体积相同，并且其移动方式与二维卷积相同——沿着图像的高度和宽度移动。
- en: Three-dimensional convolutions work a bit differently in that they convolve
    over the depth as well as the height and the width. This tells us that the depth
    of the kernel is smaller than the depth of the volume we want to convolve over,
    and at each step, it performs element-wise multiplication and addition, resulting
    in a single scalar value.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 三维卷积的工作方式稍有不同，它不仅在高度和宽度方向上进行卷积，还在深度方向上进行卷积。这意味着卷积核的深度小于我们希望卷积的体积的深度，在每一步，它都会进行逐元素的乘法和加法运算，最终得到一个标量值。
- en: If we have volumetric data with a size of 21 × 21 × 15 (as we did in the preceding
    section) and a three-dimensional kernel with a size of 5 × 5 × 5 that takes a
    stride of 1, then the output will have a size of 16 × 16 × 11.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个大小为 21 × 21 × 15 的体积数据（如前一部分所述），并且有一个大小为 5 × 5 × 5 的三维卷积核，步幅为 1，那么输出将会是
    16 × 16 × 11 的大小。
- en: 'Visually, this looks as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从视觉效果来看，结果如下：
- en: '![](img/26a7aa41-7e10-41df-81f6-6a83ca82ce97.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/26a7aa41-7e10-41df-81f6-6a83ca82ce97.png)'
- en: We can calculate the output shape of the three-dimensional convolution in a
    similar way to as we did earlier in the two-dimensional case.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像之前处理二维卷积那样，计算三维卷积的输出形状。
- en: This type of convolution is used frequently in tasks that require us to find
    relationships in 3D. This is particularly used in the task of three-dimensional
    object segmentation and detecting actions/motion in videos.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的卷积常用于需要我们在三维数据中寻找关系的任务。特别是在三维物体分割和视频中检测动作/运动的任务中使用较多。
- en: Separable convolutions
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可分离卷积
- en: Separable convolutions are a rather interesting type of convolution. They work
    on two-dimensional inputs and can be applied spatially or depthwise. The way this
    works is we decompose our k × k sized kernel into two smaller kernels with sizes
    of k × 1 and 1 × k. Instead of applying the k × k kernel, we would first apply
    the k × 1 kernel and then, to its output, the 1 × k kernel. The reason this is
    used is that it reduces the number of parameters in our network. With the original
    kernel, we would have had to carry out k² multiplications at each step, but with
    separable convolution, we only have to carry out 2,000 multiplications, which
    is a lot less.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 可分离卷积是一种非常有趣的卷积类型。它作用于二维输入，可以在空间或深度方向上应用。其原理是将我们的 k × k 大小的卷积核分解为两个较小的卷积核，分别为
    k × 1 和 1 × k。我们不再直接应用 k × k 卷积核，而是先应用 k × 1 卷积核，再对其输出应用 1 × k 卷积核。这样做的原因是它减少了网络中的参数数量。使用原始卷积核时，我们每一步需要进行
    k² 次乘法运算，但使用可分离卷积后，我们只需要进行 2,000 次乘法运算，减少了很多。
- en: 'Suppose we have a 3 × 3 kernel that we want to apply to a 6 × 6 input, as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个 3 × 3 的卷积核，想要将其应用于 6 × 6 的输入，具体如下：
- en: '![](img/12935ccd-895c-4c6b-aad6-a15e5998a486.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/12935ccd-895c-4c6b-aad6-a15e5998a486.png)'
- en: In the preceding convolution, our kernel will have to perform nine multiplications
    at each of the 16 positions before it produces our output. This is a total of
    144 multiplications.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述的卷积中，我们的卷积核需要在 16 个位置上执行每个 9 次的乘法运算，然后才会输出结果。总共需要进行 144 次乘法运算。
- en: 'Let''s see how the separable convolution differs and compare its results. We
    will first decompose our kernel into k × 1 and 1 × k kernels:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看可分离卷积是如何不同的，并对比其结果。我们首先将卷积核分解为 k × 1 和 1 × k 两个卷积核：
- en: '![](img/0f84a867-25e6-4fb6-9510-7cbf5a6bb5dc.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f84a867-25e6-4fb6-9510-7cbf5a6bb5dc.png)'
- en: 'We will apply the kernels to our input in two steps. This looks as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分两步将卷积核应用于输入。其效果如下：
- en: 'Step 1:'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步骤 1：
- en: '![](img/033ba50e-e669-4506-a68e-6f6ecac8bf2d.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/033ba50e-e669-4506-a68e-6f6ecac8bf2d.png)'
- en: 'Step 2:'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步骤 2：
- en: '![](img/190cfd2b-7ce7-424d-9eca-f2a3ba8e241a.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/190cfd2b-7ce7-424d-9eca-f2a3ba8e241a.png)'
- en: Here, [![](img/6f8912bd-31a5-40c1-a6ad-57f7115cfb6a.png)] is the output from
    the first convolution operation and [![](img/be166d15-8da9-4fad-bff5-1313c7ff2c9b.png)] is
    the output from the second. However, as you can see, we still get an output of
    the same size as before, but the number of multiplications that had to be carried
    out is fewer. The first convolution had to carry out three multiplications at
    each of the 24 positions for a total of 72 multiplications, and the second convolution
    also carried out three multiplications at each of the 16 positions for a total
    of 48 multiplications. By summing the total multiplications from both convolutions,
    we find that, together, they carried out 120 multiplications, which is fewer than
    the 144 that the k × k kernel had to do.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这里， [![](img/6f8912bd-31a5-40c1-a6ad-57f7115cfb6a.png)] 是第一次卷积操作的输出，[![](img/be166d15-8da9-4fad-bff5-1313c7ff2c9b.png)]
    是第二次卷积操作的输出。然而，正如你所看到的，我们仍然得到了与之前相同大小的输出，但进行的乘法运算数量减少了。第一次卷积在每个 24 个位置上进行三次乘法运算，总共进行了
    72 次乘法运算，第二次卷积也在每个 16 个位置上进行三次乘法运算，总共进行了 48 次乘法运算。通过将两次卷积的乘法总数相加，我们发现它们一共进行了 120
    次乘法运算，少于 k × k 卷积核需要进行的 144 次乘法。
- en: 'It is important to clarify that not every kernel is separable. As an example,
    let''s take a look at the Sobel filter and its decomposition:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 需要澄清的是，并不是每个卷积核都是可分的。举个例子，让我们看看 Sobel 滤波器及其分解：
- en: '![](img/f884c661-29cb-44dd-8db0-d041e99e42ae.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f884c661-29cb-44dd-8db0-d041e99e42ae.png)'
- en: What we just learned was spatially separable convolution. Using what we have
    learned so far, how do you think depth-wise convolution would work?
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚学到了空间可分卷积。基于我们目前所学的，你觉得深度卷积会如何工作呢？
- en: You should recall that when we went through two-dimensional convolutions, we
    introduced a three-dimensional kernel for colored images, where the depth was
    the same as the image. So, if we had an input of 8 × 8 × 3 and a kernel with a
    size of 3 × 3 × 3, we would get an output of 6 × 6 × 1\. However, in depth-wise
    separable convolutions, we split the 3 × 3 × 3 kernel into three kernels with
    a size of 3 × 3 × 1 each, which convolves one of the channels. After applying
    our kernels to our input, we have an output with a size of 6 × 6 × 3 and to this
    output, we will apply a kernel with a size of 1 × 1 × 3, which produces an output
    of 6 × 6 × 1.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该记得，当我们讲解二维卷积时，我们引入了一个三维卷积核来处理彩色图像，其中深度与图像的通道数相同。因此，如果输入是 8 × 8 × 3，而卷积核的大小是
    3 × 3 × 3，我们将得到一个大小为 6 × 6 × 1 的输出。然而，在深度可分卷积中，我们将 3 × 3 × 3 的卷积核拆分成三个 3 × 3 ×
    1 的卷积核，每个卷积核卷积其中一个通道。在将卷积核应用于输入后，我们得到的输出大小是 6 × 6 × 3，并且我们会在该输出上应用一个大小为 1 × 1
    × 3 的卷积核，从而得到一个大小为 6 × 6 × 1 的输出。
- en: If we want to increase the depth of the output to, say, 72, instead of applying
    72 3 × 3 × 3 kernels, we would apply 72 1 × 1 × 3 convolutions.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想将输出的深度增加到，比如说 72，那么我们不会应用 72 个 3 × 3 × 3 的卷积核，而是应用 72 个 1 × 1 × 3 的卷积。
- en: Let's compare the two and see which is more computationally efficient. The number
    of multiplications that had to take place in order to compute our 6 × 6 × 72 output
    using the 3 × 3 × 3 kernel is (3×3×3) × (6×6) × 72 = 69,984, which is a lot! To
    compute the same output using depth-wise separable convolution, the number of
    multiplications required is (3×3×1) × 3 × (6×6) + (1×1×3) × (6×6) × 72 = 8,748, which
    is a whole lot less and therefore a lot more efficient.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较一下两者，看看哪种计算方式更高效。使用 3 × 3 × 3 卷积核计算 6 × 6 × 72 的输出时，所需的乘法次数是 (3×3×3) ×
    (6×6) × 72 = 69,984，非常多！而使用深度可分卷积来计算相同的输出时，所需的乘法次数是 (3×3×1) × 3 × (6×6) + (1×1×3)
    × (6×6) × 72 = 8,748，少得多，因此效率更高。
- en: Transposed convolutions
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转置卷积
- en: We know that applying a convolution repeatedly to an image reduces its size,
    but what if we would like to go in the opposite direction; that is, go from the
    shape of the output to the shape of the input while still maintaining local connectivity.
    To do this, we use transposed convolution, which draws its name from matrix transposition
    (which you should remember from [Chapter 1](3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml),
    *Vector Calculus*).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，对图像反复应用卷积会减少图像的尺寸，但如果我们想要逆向操作，也就是从输出的形状恢复到输入的形状，同时保持局部连接性，该怎么做呢？为此，我们使用转置卷积，它的名字来源于矩阵转置（你应该记得在[第
    1 章](3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml)中讲解过的 *向量微积分*）。
- en: 'Let''s suppose we have a 4 × 4 input and a 3 × 3 kernel. Then, we can rewrite
    the kernel as a 4 × 16 matrix, which we can use for matrix multiplications to
    carry out our convolutions. This looks as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个 4 × 4 的输入和一个 3 × 3 的卷积核。然后，我们可以将卷积核重写为一个 4 × 16 的矩阵，用于矩阵乘法来进行卷积操作。其形式如下：
- en: '![](img/50b4e204-920b-482e-b971-b83636170cba.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/50b4e204-920b-482e-b971-b83636170cba.png)'
- en: If you look closely, you will notice that each row represents one convolution
    operation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细看，会发现每一行代表一次卷积操作。
- en: 'To use this matrix, we rewrite our input as a 16 × 1 column vector, which looks
    as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用这个矩阵，我们将输入重写为一个 16 × 1 的列向量，如下所示：
- en: '![](img/5d3796da-764b-4f47-80fd-c0168f14f008.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5d3796da-764b-4f47-80fd-c0168f14f008.png)'
- en: 'Then, we can multiply our convolution matrix and column vector to get a 4 ×
    1 column vector, which looks as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将卷积矩阵和列向量相乘，得到一个 4 × 1 的列向量，如下所示：
- en: '![](img/e064da92-100c-4165-9409-d19f95f0687b.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e064da92-100c-4165-9409-d19f95f0687b.png)'
- en: 'We can rewrite this in the following form:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其重写为以下形式：
- en: '![](img/54bf255f-341a-4a62-a119-ac4c12a150c4.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/54bf255f-341a-4a62-a119-ac4c12a150c4.png)'
- en: This is the same as what we saw in the previous section.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们在上一节中看到的相同。
- en: You might now be wondering what this has to do with transposed convolution.
    It's simple—we use the same concept as before, but now we use the transpose of
    the convolution matrix to work our way backward from the output to the input.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可能会想，这和转置卷积有什么关系呢？其实很简单——我们沿用之前的概念，不过这次我们使用卷积矩阵的转置来从输出反向推导回输入。
- en: 'Let''s take the preceding convolution matrix and transpose it so that it becomes
    a matrix with a size of 16 × 4:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们取上面的卷积矩阵并转置它，使其变为一个 16 × 4 的矩阵：
- en: '![](img/4aff7146-5d39-46b0-810c-0fcfd787e8a6.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4aff7146-5d39-46b0-810c-0fcfd787e8a6.png)'
- en: 'This time, the input vector we multiply with will be a 4 × 1 column vector:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们将要相乘的输入向量是一个 4 × 1 的列向量：
- en: '![](img/baf87720-d222-4e41-9ce1-e0782f5bc099.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/baf87720-d222-4e41-9ce1-e0782f5bc099.png)'
- en: 'We can multiply them and get a 16 × 1 output vector, as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将它们相乘，得到一个 16 × 1 的输出向量，如下所示：
- en: '![](img/f51138f2-763a-4e12-96d6-bb63271a7e5c.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f51138f2-763a-4e12-96d6-bb63271a7e5c.png)'
- en: 'We can rewrite our output vector into a 4 × 4 matrix, as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将输出向量重写为一个 4 × 4 的矩阵，如下所示：
- en: '![](img/0c0d08a3-38e4-444a-9c39-9b0193e8adf0.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0c0d08a3-38e4-444a-9c39-9b0193e8adf0.png)'
- en: Just like that, we can go from lower dimensional space to a higher dimensional
    space.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样，我们可以从低维空间转换到高维空间。
- en: It is important to note that the padding and stride that were applied to the
    convolution operation can be used in transposed convolution as well.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，应用于卷积操作的填充和步长也可以在转置卷积中使用。
- en: 'We can then calculate the size of the output using the following formula:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用以下公式计算输出的大小：
- en: '![](img/aede1fa8-2a1c-4af3-9286-0791d334eb78.png).'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/aede1fa8-2a1c-4af3-9286-0791d334eb78.png)。'
- en: Here, the input is n × n, the kernel is k × k, *p* is the pooling, and *s* is
    the stride.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，输入是 n × n，核是 k × k，*p* 是池化，*s* 是步长。
- en: Pooling
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化
- en: 'Another often-used operation in CNNs is known as **pooling** (**subsampling**
    or **downsampling**). This works somewhat like the convolution operation, except
    it reduces the size of the feature map by sliding a window across the feature
    map and either averages all the values inside each window at each step or outputs
    the maximum value. The pooling operation differs from convolution in that it does
    not have any parameters and so cannot be learned or tuned. We can calculate the
    size of the feature map after pooling, as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）中另一个常用的操作被称为 **池化**（**子采样** 或 **降采样**）。它的工作原理有点像卷积操作，不同的是它通过滑动窗口跨越特征图，并在每一步要么对窗口内的所有值取平均值，要么输出最大值，从而减小特征图的大小。池化操作与卷积的不同之处在于，它没有任何参数，因此不能学习或调优。我们可以计算池化后的特征图大小，如下所示：
- en: '![](img/b6adcfe2-2156-430a-af6c-6ab89adffc93.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b6adcfe2-2156-430a-af6c-6ab89adffc93.png)'
- en: Here, *I* is an n × n-shaped two-dimensional tensor, the pooling operation is
    an r × r-shaped two-dimensional tensor, and *s* is the stride.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*I* 是一个 n × n 形状的二维张量，池化操作是一个 r × r 形状的二维张量，而 *s* 是步长。
- en: 'Here is an example of maximum pooling with a stride of 1:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个步长为 1 的最大池化示例：
- en: '![](img/78461336-cf4f-4e84-902b-19c927bf5be2.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/78461336-cf4f-4e84-902b-19c927bf5be2.png)'
- en: 'Here is an example of average pooling with a stride of 2:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个步长为 2 的平均池化示例：
- en: '![](img/79a9a2f3-1ade-40b6-a9ad-b402405f7f61.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79a9a2f3-1ade-40b6-a9ad-b402405f7f61.png)'
- en: As a rule of thumb, it has been found that the maximum pooling operation performs
    better.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 一般经验法则发现，最大池化操作的表现更好。
- en: From this, you will probably notice that the output is quite different from
    the original and doesn't fully represent all the information. In fact, a lot of
    information has been lost. It is because of this that the pooling operation is
    used increasingly less in practice.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 从中，你可能会注意到输出与原始信息有很大不同，并且没有完全代表所有信息。事实上，很多信息已经丢失。正因为如此，池化操作在实际应用中越来越少使用。
- en: Global average pooling
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全局平均池化
- en: '**Global average pooling** is a variant of the pooling operation that we saw
    previously, where instead of sliding a subsampling kernel over the feature map,
    we just take the average of the entire feature map and output a single real value.
    Suppose we have a feature map with a size of 6 × 6 × 72. After applying this pooling
    operation, our output would have a size of 1 × 1 × 72.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**全局平均池化**是池化操作的一种变体，在这种操作中，我们不再像之前那样在特征图上滑动子采样内核，而是直接取整个特征图的平均值，输出一个单一的实数值。假设我们有一个大小为6×6×72的特征图，在应用这种池化操作后，输出的大小将为1×1×72。'
- en: This is generally used at the last layer, where, normally, we would apply the
    subsampling and feed the output into a fully connected layer; instead, this allows
    us to skip the fully connected layer and feed the output of the global average
    pool directly into our softmax for prediction.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法通常在最后一层使用，在通常情况下，我们会应用子采样，并将输出送入全连接层；而这种方法允许我们跳过全连接层，直接将全局平均池化的输出送入softmax进行预测。
- en: The advantage of using this is that it significantly removes the number of parameters
    we have to train in our network. Had we flattened the preceding feature map and
    fed it into a layer of 500 nodes, it would have 1.296 million parameters. This
    also has the added benefit of reducing overfitting to the training data and improving
    our classification prediction because the output is closer to the classes.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法的优点是显著减少了我们需要在网络中训练的参数数量。如果我们将前述特征图展开，并将其输入到一个500节点的层中，那么它将有129.6万个参数。它还具有减少过拟合训练数据的额外好处，并且由于输出更接近类别，能够提高分类预测的效果。
- en: Convolution and pooling size
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积和池化大小
- en: Now that we know the various types of convolution and pooling, it is time to
    talk about a very important topic associated with them—their size. As you have
    seen, when we applied a convolution to an image, the output was of a smaller size
    than the input. The output size is determined by the size of the kernel, the stride,
    and whether or not we have padding. These are very important things to keep in
    mind when architecting CNNs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了各种类型的卷积和池化，是时候讨论一个与它们相关的非常重要的话题——它们的大小。如你所见，当我们对图像应用卷积时，输出的大小比输入小。输出大小由内核的大小、步长以及是否有填充决定。这些都是在构建卷积神经网络时非常重要的因素。
- en: There are several sizes of convolutions that are used in practice, the most
    commonly used ones being 7 × 7, 5 × 5, and 3 × 3\. However, we can use other sizes
    as well, including—but not limited to—11 × 11, 13 × 13, 9 × 9, 17 × 17, and so
    on.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 实际应用中有几种常用的卷积大小，最常用的是7×7、5×5和3×3。但我们也可以使用其他大小，包括但不限于11×11、13×13、9×9、17×17等。
- en: In practice, we generally use larger convolutions with a larger stride to generate
    a feature map of a smaller size to reduce the computational constraint and default
    to using 3 × 3 and 5 × 5 kernels the most. This is because they are computationally
    more feasible. Generally, having a larger kernel will allow us to look at a larger
    space in the image and capture more relationships, but having multiple 3 × 3 kernels
    has proven to have a similar performance while being less computationally intensive,
    which we prefer.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，我们通常使用更大的卷积和更大的步长生成较小大小的特征图，以减少计算约束，并默认使用3×3和5×5的内核。这是因为它们在计算上更为可行。一般来说，使用更大的内核可以让我们观察图像中的更大区域并捕捉更多关系，但使用多个3×3内核已经证明能够提供类似的性能，并且计算负担较轻，因此我们更倾向于使用它们。
- en: Working with the ConvNet architecture
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ConvNet架构
- en: 'Now that we know all the different components that make up a ConvNet, we can
    put it all together and see how to construct a deep CNN. In this section, we will
    build a full architecture and observe how forward propagation works and how we
    decide the depth of the network, the number of kernels to apply, when and why
    to use pooling, and so on. But before we dive in, let''s explore some of the ways
    in which CNNs differ from FNNs. They are as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了构成卷积神经网络的不同组件，接下来我们将把它们结合起来，看看如何构建一个深度CNN。在本节中，我们将构建一个完整的架构，并观察前向传播如何工作，以及如何决定网络的深度、应用卷积核的数量、何时以及为什么使用池化等内容。但在我们深入探讨之前，先让我们探索一些CNN与FNN的区别。它们如下：
- en: The neurons in CNNs have local connectivity, which means that each neuron in
    a successive layer receives input from a small local group of pixels from an image,
    instead of receiving the entire image, as a **feedforward neural network** (**FNN**)
    would.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN中的神经元具有局部连接性，这意味着每个神经元在后续层接收来自图像中一小块局部像素的输入，而不是像**前馈神经网络**（**FNN**）那样接收整个图像。
- en: Each neuron in the layer of a CNN has the same weight parameters.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN中每一层的神经元具有相同的权重参数。
- en: The layers in CNNs can be normalized.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN中的各层可以进行归一化。
- en: CNNs are translation invariant, which allows us to detect the same object regardless
    of its position in the image.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN具有平移不变性，这使得我们能够检测图像中无论位置如何的相同物体。
- en: CNNs have fewer parameters because the convolution operation weighs the surrounding
    neurons and sums them into the neuron at the next layer, thereby smoothing the
    image.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN的参数较少，因为卷积操作对周围的神经元加权，并将它们加总到下一层的神经元，从而平滑图像。
- en: The activation functions typically used in CNNs are ReLU, PReLU, and ELU.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN中常用的激活函数有ReLU、PReLU和ELU。
- en: The CNN architecture isn't entirely dissimilar to the FNN architecture we saw
    earlier in this book, except instead of having fully connected layers, we have
    convolution layers that extract spatial relationships from the inputs and previous
    layers and learn features from the input at each layer.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: CNN架构与我们在本书早些时候看到的FNN架构并不完全不同，只是它不再使用全连接层，而是使用卷积层，从输入和前一层中提取空间关系，并在每一层学习输入特征。
- en: 'In general, what the architecture learns can be demonstrated with the following
    flow:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，架构所学习的内容可以通过以下流程展示：
- en: '![](img/3c0e85e6-9b65-4a93-833a-138c34cb6d23.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c0e85e6-9b65-4a93-833a-138c34cb6d23.png)'
- en: As you can see from the preceding flow, the features grow in complexity in the
    latter layers. What this means is that the earliest layers (those closest to the
    input layer) learn very basic features, such as edges and lines, textures, or
    how certain colors differentiate. The latter layers take in the feature map from
    the previous layer as input and learn more complex patterns from it. For example,
    if we create a facial recognition model, the earliest layer would learn the simplest possible lines,
    curves, and gradients. The next layer would take in the feature maps from the
    previous layer and use it to learn more complex features, such as hair and eyebrows.
    The layer after that would learn even more complex features, such as eyes, noses,
    ears, and so on.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 从之前的流程中可以看到，特征在后期层中逐渐变得复杂。这意味着最早的层（离输入层最近的层）学习的是非常基本的特征，比如边缘和线条、纹理，或者是某些颜色的区分。后续层将从前一层的特征图中获取输入，并从中学习更复杂的模式。例如，如果我们创建一个人脸识别模型，最早的层会学习最简单的线条、曲线和梯度。下一层会从前一层的特征图中获取输入，并利用它学习更复杂的特征，如头发和眉毛。接下来的一层会学习更复杂的特征，如眼睛、鼻子、耳朵等。
- en: 'We can see what a neural network learns in the following diagram:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下图中看到神经网络学习的内容：
- en: '![](img/c92639ed-dc49-4fbf-8c7a-ffd204e13fcd.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c92639ed-dc49-4fbf-8c7a-ffd204e13fcd.jpg)'
- en: 'CNNs, like FNNs, have a structure that we can use as a guide when we build
    our own applications. It typically looks as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: CNN像FNN一样，具有一个我们可以作为构建自己应用程序时的指南的结构。它通常如下所示：
- en: '![](img/f9bdcf87-5029-4b57-9328-a9e5edc6d4d0.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9bdcf87-5029-4b57-9328-a9e5edc6d4d0.png)'
- en: 'We are now going to break down one of the most popular CNN architectures, called
    AlexNet, which outperformed all other models in the ILSVRC in 2012 with 10% greater
    accuracy and kickstarted the deep learning revolution. It was created by Alex
    Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. We can see its architecture in
    the following diagram:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将分解一种最流行的CNN架构，叫做AlexNet，它在2012年ILSVRC中以比其他模型高10%的准确率获得了胜利，并启动了深度学习革命。它是由Alex
    Krizhevsky、Ilya Sutskever和Geoffrey Hinton创建的。我们可以在以下图中看到它的架构：
- en: '![](img/aee0ec8d-6d45-4d04-8920-11bfd4b53da6.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aee0ec8d-6d45-4d04-8920-11bfd4b53da6.png)'
- en: As you can see, the architecture contains eight trainable layers—five of which
    are convolutional layers and three of which are fully connected. The ImageNet
    dataset contains more than 15 million labeled images, but for ILSVRC, we have approximately
    1.2 million images in the training set, 50,000 images in the validation set, 150,000 images
    in the testing set, and nearly 1,000 images for each of the 1,000 classes that
    the images belong to. Each of the images was rescaled to 256 × 256 × 3 because
    they all varied in size, and from these rescaled images, the authors generated
    random crops with a size of 256 × 256 × 3. Additionally, the creators of AlexNet
    used ReLU activations instead of **tanh** because they found that it sped up the
    training by as much as six times without sacrificing accuracy.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，该架构包含八个可训练层，其中五个是卷积层，三个是全连接层。ImageNet 数据集包含超过1500万张标注图像，但对于 ILSVRC，我们的训练集约有120万张图像，验证集有5万张图像，测试集有15万张图像，且每个类别（共1000个类别）有近1000张图像。每张图像都被重缩放至256
    × 256 × 3，因为图像大小不同，经过缩放后，作者生成了大小为256 × 256 × 3的随机裁剪图像。此外，AlexNet的创建者使用了ReLU激活函数，而不是**tanh**，因为他们发现这样可以在不牺牲准确度的情况下，训练速度提高了六倍。
- en: 'The operations applied to the image at each layer and their sizes are as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层对图像应用的操作及其大小如下：
- en: '**Convolution layer 1**: 96 kernels of size 11 × 11 × 3 with a stride of 4\.
    This results in a layer with a size of 55 × 55 × 96.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 1**：96个大小为11 × 11 × 3的卷积核，步幅为4。结果得到的层大小为55 × 55 × 96。'
- en: '**Nonlinearity 1**: ReLU activation applied to the output from convolution
    layer 1.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性层 1**：对卷积层1的输出应用ReLU激活。'
- en: '**Subsampling layer 1**: Maximum pool with a size of 3 × 3 and a stride of
    2. This results in a layer with a size of 27 × 27 × 96.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**下采样层 1**：最大池化，大小为3 × 3，步幅为2。结果得到的层大小为27 × 27 × 96。'
- en: '**Convolution layer 2**: 256 kernels with a size of 5 × 5, a padding of 2,
    and a stride of 1\. This results in a layer with a size of 27 × 27 × 256.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 2**：256个大小为5 × 5的卷积核，填充为2，步幅为1。结果得到的层大小为27 × 27 × 256。'
- en: '**Nonlinearity 2**: ReLU activation applied to the output from convolution
    layer 2.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性层 2**：对卷积层2的输出应用ReLU激活。'
- en: '**Subsampling layer 2**: Maximum pool with a size of 3 × 3 and a stride of
    2\. This results in a layer with a size of 13 × 13 × 256.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**下采样层 2**：最大池化，大小为3 × 3，步幅为2。结果得到的层大小为13 × 13 × 256。'
- en: '**Convolution layer 3**: 384 kernels with a size of 3 × 3, a padding of 1,
    and a stride of 1\. This results in a layer of size 13 × 13 × 384.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 3**：384个大小为3 × 3的卷积核，填充为1，步幅为1。结果得到的层大小为13 × 13 × 384。'
- en: '**Nonlinearity 3**: ReLU activation applied to the output from convolution
    layer 3.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性层 3**：对卷积层3的输出应用ReLU激活。'
- en: '**Convolution layer 4**: 384 kernels of size 3 × 3 with a padding of 1 and
    a stride of 1\. This results in a layer with a size of 13 × 13 × 384.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 4**：384个大小为3 × 3的卷积核，填充为1，步幅为1。结果得到的层大小为13 × 13 × 384。'
- en: '**Nonlinearity 4**: ReLU activation applied to the output from convolution
    layer 4.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性层 4**：对卷积层4的输出应用ReLU激活。'
- en: '**Convolution layer 5**: 256 kernels with a size of 3 × 3, a padding of 1, and
    a stride of 1\. This results in a layer with a size of 13 × 13 × 256.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 5**：256个大小为3 × 3的卷积核，填充为1，步幅为1。结果得到的层大小为13 × 13 × 256。'
- en: '**Nonlinearity 5**: ReLU activation applied to the output from convolution
    layer 5.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性层 5**：对卷积层5的输出应用ReLU激活。'
- en: '**Subsampling layer 3**: Maximum pool with a size of 3 × 3 and a stride of
    2\. This results in a layer with a size of 6 × 6 × 256.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**下采样层 3**：最大池化，大小为3 × 3，步幅为2。结果得到的层大小为6 × 6 × 256。'
- en: '**Fully connected layer 1**: A fully connected layer with 4,096 neurons.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层 1**：一个包含4096个神经元的全连接层。'
- en: '**Nonlinearity 6**: ReLU activation applied to the output from fully connected
    layer 1.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性层 6**：对全连接层1的输出应用ReLU激活。'
- en: '**Fully connected layer 2**: A fully connected layer with 4,096 neurons.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层 2**：一个包含4096个神经元的全连接层。'
- en: '**Nonlinearity 7**: ReLU activation applied to the output from fully connected
    layer 2.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性层 7**：对全连接层2的输出应用ReLU激活。'
- en: '**Fully connected layer 3**: A fully connected layer with 1,000 neurons.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层 3**：一个包含1000个神经元的全连接层。'
- en: '**Nonlinearity 8**: ReLU activation applied to the output from fully connected
    layer 3.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性层 8**：对全连接层3的输出应用ReLU激活。'
- en: '**Output layer**: Softmax applied to the 1,000 neurons to calculate the probability
    of it being one of the classes.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出层**：Softmax应用于1,000个神经元，用来计算其属于某个类别的概率。'
- en: 'When building architectures, it is important to have an understanding of how
    many parameters are in the model. The formula we use to calculate the number of
    parameters at each layer is as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建架构时，理解模型中的参数数量是非常重要的。我们用来计算每层参数数量的公式如下：
- en: '![](img/93c029a3-1d12-4f7d-ba43-c300f4ec02e9.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](img/93c029a3-1d12-4f7d-ba43-c300f4ec02e9.png)'
- en: 'Let''s calculate the parameters of AlexNet. They are as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算一下AlexNet的参数。它们如下：
- en: '**Convolution layer 1**:11 x 11 x 3 x 96 = 34,848'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 1**：11 x 11 x 3 x 96 = 34,848'
- en: '**Convolution layer 2**: 5 x 5 x 96 x 256 = 614,400'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 2**：5 x 5 x 96 x 256 = 614,400'
- en: '**Convolution layer 3**: 3 x 3 x 256 x 384 = 884,736'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 3**：3 x 3 x 256 x 384 = 884,736'
- en: '**Convolution layer 4**:3 x 3 x 384 x 384 = 1,327,104'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 4**：3 x 3 x 384 x 384 = 1,327,104'
- en: '**Convolution layer 5**:3 x 3 x 384 x 256 = 884,736'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 5**：3 x 3 x 384 x 256 = 884,736'
- en: '**Fully connected layer 1**: 256 x 6 x 6 x 4096 = 37,748,736'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层 1**：256 x 6 x 6 x 4096 = 37,748,736'
- en: '**Fully connected layer 2**: 4096 x 4096 = 16,777,216'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层 2**：4096 x 4096 = 16,777,216'
- en: '**Fully connected layer 3**: 4096 x 1000 = 4,096,000'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层 3**：4096 x 1000 = 4,096,000'
- en: Now, if we sum the parameters together, we find that AlexNet has a total of
    62.3 million parameters. Roughly 6% of these parameters are from the convolution
    layers and the remaining 94% are from the fully connected layers. This should
    give you an idea of why CNNs are so effective and why we like them so much.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们将参数加总起来，就会发现AlexNet共有6230万个参数。大约6%的参数来自卷积层，剩余94%来自全连接层。这应该能让你明白为什么CNN如此有效，以及我们为什么如此喜爱它们。
- en: You may be wondering why we would use a CNN at all and why we wouldn't just
    use an FNN instead. Couldn't we just flatten the image into a fully connected
    layer and input every pixel into a single node? We could, but if we did, then
    our first layer would have 154,587 neurons and our overall network could have
    well over 1 million neurons and 500 million trainable parameters. This is massive
    and our network would likely underfit from not having enough training data. Additionally,
    FNNs do not have the translation-invariant property that CNNs have.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，为什么我们要使用CNN，而不直接使用FNN呢？难道不能将图像压平为一个全连接层，并将每个像素输入到一个节点吗？我们可以这样做，但如果这么做的话，我们的第一层将有154,587个神经元，整个网络的神经元数量可能会超过100万个，且可训练参数达到5亿。这是巨大的，我们的网络可能会因为没有足够的训练数据而欠拟合。此外，FNN并没有CNN所具备的平移不变性。
- en: Using the preceding parameters, let's see whether we can generalize the architecture
    so that we have a framework to follow for future CNNs that we want to build or
    to understand how other architectures we come across work. The first thing you
    should have realized in the preceding architecture is that the size of each successive
    feature map reduces while its depth increases. Also, you may have noticed that
    the depth is always divisible by 2, many times over, and usually, we use 32, 64,
    128, 256, 512, and so on in layers.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前述参数，让我们看看是否能将架构进行概括，从而为将来要构建的CNN提供一个框架，或者帮助我们理解遇到的其他架构如何工作。你在前述架构中应该已经意识到，每个后续特征图的大小在减小，而其深度在增加。此外，你可能还注意到深度总是能被2整除，很多时候我们在各层中使用32、64、128、256、512等等。
- en: Just as we saw with FNNs previously, the deeper we go, the better our accuracy
    is, but this doesn't come without its own problems. Larger networks are much harder
    to train and can either overfit or underfit to the training data. This could be
    a result of a combination of being too small, being too large, having too much
    training data, or having too little training data. There is still no fixed recipe
    for exactly how many layers to use in our CNN; it is very much down to trial and
    error and building up some intuition after building and training several architectures
    for a variety of tasks.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前在FNN中看到的那样，网络越深，准确率通常越高，但这并非没有问题。更大的网络训练起来要困难得多，可能会出现过拟合或欠拟合的情况。这可能是因为网络过小、过大、训练数据过多或过少造成的。目前还没有固定的方案来确定CNN中到底应该使用多少层；这更多依赖于反复试验和在为多种任务构建和训练多种架构后积累的直觉。
- en: Training and optimization
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练与优化
- en: Now that we've got that sorted, it's time for us to dive into the really fun
    stuff. How do we train these fantastic architectures? Do we need a completely
    new algorithm to facilitate our training and optimization? No! We can still use
    backpropagation and gradient descent to calculate the error, differentiate it
    with respect to the previous layers, and update the weights to get us as close
    to the global optima as possible.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经搞清楚了这些内容，是时候深入了解一些真正有趣的部分了。我们如何训练这些出色的架构？我们是否需要一个全新的算法来促进训练和优化？不！我们仍然可以使用反向传播和梯度下降来计算误差，对其在前一层的导数进行求解，然后更新权重，以便尽可能接近全局最优解。
- en: 'But before we go further, let''s go through how backpropagation works in CNNs,
    particularly with kernels. Let''s revisit the example we used earlier on in this
    chapter, where we convolved a 3 × 3 input with a 2 × 2 kernel, which looked as
    follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 但在继续之前，让我们回顾一下卷积神经网络中反向传播的工作原理，特别是卷积核的部分。让我们再看看本章早些时候使用的例子，我们用一个3×3的输入和一个2×2的卷积核进行卷积，效果如下：
- en: '![](img/552a9b5d-cb02-4941-85b3-546e048d2dfc.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/552a9b5d-cb02-4941-85b3-546e048d2dfc.png)'
- en: 'We expressed each element in the output matrix as follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将输出矩阵中的每个元素表示如下：
- en: '![](img/5221fee2-31c8-4d34-917b-6cb88b9695e8.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5221fee2-31c8-4d34-917b-6cb88b9695e8.png)'
- en: 'We should remember from [Chapter 7](e1f37008-1ad5-49f6-a229-4d6249c2d7e3.xhtml),
    *Feedforward Networks*, where we introduced backpropagation, that we take derivatives
    of the loss (error) with respect to the weights and biases at the layers and then
    use this as a guide to update the parameters to reduce the error of prediction
    from our network. In CNNs, however, we find the gradient of the error with respect
    to the kernel. Since our kernel has four elements, the derivatives look as follows:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该记得在[第7章](e1f37008-1ad5-49f6-a229-4d6249c2d7e3.xhtml)《前馈网络》中，我们介绍了反向传播，在那里我们对损失（误差）对权重和偏置的导数进行计算，并利用这些信息来更新参数，以减少网络预测误差。然而，在卷积神经网络中，我们找到的是误差对卷积核的梯度。由于我们的卷积核有四个元素，因此其导数如下所示：
- en: '![](img/0f8dd364-0e83-40c5-b695-b2e41e0f663b.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f8dd364-0e83-40c5-b695-b2e41e0f663b.png)'
- en: 'If we observe these equations carefully, which represent the output from the
    feedforward computation, we can see that by taking the partial derivative with
    respect to each kernel element, we get the respective input element, *I*[*i,j*],
    that it depends on. If we substitute this value back into the derivatives, we
    can simplify them to get the following:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们仔细观察这些方程，它们表示的是前馈计算的输出，我们可以看到，通过对每个卷积核元素求偏导数，我们得到了它所依赖的相应输入元素，*I*[*i,j*]。如果我们将这个值代回到导数中，我们可以简化它们，得到以下结果：
- en: '![](img/2bb73d1c-c3a5-49f0-8b28-150aaca071a3.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2bb73d1c-c3a5-49f0-8b28-150aaca071a3.png)'
- en: 'We can simplify this further by rewriting it as a convolution operation. This
    looks as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将其重新写为卷积操作来进一步简化，这看起来如下：
- en: '![](img/48db5231-90e5-4c4e-9004-0459790d4e6f.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](img/48db5231-90e5-4c4e-9004-0459790d4e6f.png)'
- en: 'But what if we wanted to find the derivative with respect to the input? Well,
    our Jacobian matrix would certainly look a bit different. We would have a 3 ×
    3 matrix since there are nine elements in the input matrix:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 那么如果我们想要找到输入的导数呢？嗯，我们的雅可比矩阵肯定会看起来有些不同。由于输入矩阵有九个元素，我们将得到一个3×3的矩阵：
- en: '![](img/6dc2a10a-0689-4fac-97dd-9b6e7024cd8f.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6dc2a10a-0689-4fac-97dd-9b6e7024cd8f.png)'
- en: We can verify this if we derive it ourselves by hand through the preceding equations,
    and I encourage you to try this out to get a good understanding of what's happening
    and why. However, let's now pay particular attention to the kernel we used. If
    we look carefully, it almost looks like the determinant, but that's not what it
    is. We just rotated (that is, transposed) the kernel by 180° so that we can compute
    the gradients.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过手动推导前面的方程式来验证这一点，我鼓励你尝试这样做，以更好地理解发生了什么以及为什么会这样。然而，现在让我们特别注意我们使用的卷积核。如果我们仔细观察，它几乎看起来像行列式，但它并不是。我们只是将卷积核旋转（即转置）了180°，这样我们就可以计算梯度。
- en: This is a much-simplified view of how backpropagation works in CNNs; we have
    left it simple because the rest works exactly as it did in FNNs.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这是卷积神经网络中反向传播工作原理的一个简化视图；我们之所以简化，是因为其余部分与前馈神经网络完全相同。
- en: Exploring popular ConvNet architectures
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索流行的卷积神经网络架构
- en: Now that we know how CNNs are built and trained, it is time to explore some
    of the popular architectures that are used and understand what makes them so powerful.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了卷积神经网络是如何构建和训练的，是时候探索一些常用的架构，了解它们为什么如此强大。
- en: VGG-16
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VGG-16
- en: The **VGG network** is a derivation of AlexNet that was created by Andrew Zisserman
    and Karen Simonyan at the **Visual Geometry Group** (**VGG**) at the University
    of Oxford in 2015\. This architecture is simpler than the one we saw earlier,
    but it gives us a much better framework to work with. VGGNet was also trained
    on the ImageNet dataset, except it takes images with a size of 224 × 224 × 3 that are
    sampled from the rescaled images in the dataset as input. You may have noticed
    that we have headed this section *VGG-16*—this is because the VGG network has
    16 layers. There are variants of this architecture that have 11, 13, and 19 layers.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '**VGG 网络**是 AlexNet 的一种变种，由 Andrew Zisserman 和 Karen Simonyan 于 2015 年在牛津大学的**视觉几何组**（**VGG**）创建。该架构比我们之前看到的更简单，但它为我们提供了一个更好的工作框架。VGGNet
    也在 ImageNet 数据集上进行了训练，不过它使用的是大小为 224 × 224 × 3 的图像，这些图像是从数据集中重新缩放后的图像中采样得到的。你可能已经注意到我们在本节中使用了*VGG-16*——这是因为
    VGG 网络有 16 层。这个架构还有 11 层、13 层和 19 层的变体。'
- en: We will first explore the basic building blocks of the network, known as VGG
    blocks. These blocks are made up of two to three convolutions, followed by a pooling
    layer. Each of the convolution layers throughout the network uses kernels with
    a size of 3 × 3 and a stride of 1; however, the number of kernels used in each
    block is the same but can vary from block to block. In the subsampling layer,
    we use a pooling with a size of 2 × 2, the same padding size, and a stride of
    2.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将探索网络的基本构建模块，即 VGG 块。这些模块由两到三个卷积层和一个池化层组成。网络中的每个卷积层都使用大小为 3 × 3 和步幅为 1 的卷积核；然而，每个模块中使用的卷积核数量是相同的，但可以在不同的模块之间有所不同。在子采样层中，我们使用大小为
    2 × 2 的池化层，采用相同的填充大小和步幅为 2。
- en: 'The entire network can be broken down into the following operations:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 整个网络可以分解为以下操作：
- en: '**Convolution layer 1**: 64 kernels with a size of 3 × 3, a stride of 1, and
    the same padding. This results in a layer with a size of 224 × 224 × 64.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 1**：64 个大小为 3 × 3 的卷积核，步幅为 1，采用相同的填充。这会生成一个大小为 224 × 224 × 64 的层。'
- en: '**Nonlinearity 1**: ReLU activation applied to the output from convolution
    layer 1.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性激活 1**：对卷积层 1 的输出应用 ReLU 激活函数。'
- en: '**Convolution layer 2**: 64 kernels with a size of 3 × 3, a stride of 1, and
    the same padding. This results in a layer with a size of 224 × 224 × 64.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 2**：64 个大小为 3 × 3 的卷积核，步幅为 1，采用相同的填充。这会生成一个大小为 224 × 224 × 64 的层。'
- en: '**Nonlinearity 2**: ReLU activation applied to the output from convolution
    layer 2.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性激活 2**：对卷积层 2 的输出应用 ReLU 激活函数。'
- en: '**Subsampling layer 1**: Maximum pool with a size of 2 × 2 and a stride of
    2\. This results in a layer with a size of 112 × 112 × 64.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子采样层 1**：大小为 2 × 2、步幅为 2 的最大池化层。这会生成一个大小为 112 × 112 × 64 的层。'
- en: '**Convolution layer 3**: 128 kernels with a size of 3 × 3, a stride of 1, and
    the same padding. This results in a layer with a size of 112 × 112 × 128.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 3**：128 个大小为 3 × 3 的卷积核，步幅为 1，采用相同的填充。这会生成一个大小为 112 × 112 × 128 的层。'
- en: '**Nonlinearity 3**: ReLU activation applied to the output from convolution
    layer 3.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性激活 3**：对卷积层 3 的输出应用 ReLU 激活函数。'
- en: '**Convolution layer 4**: 128 kernels with a size of 3 × 3, a stride of 1, and
    the same padding. This results in a layer with a size of 112 × 112 × 128.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 4**：128 个大小为 3 × 3 的卷积核，步幅为 1，采用相同的填充。这会生成一个大小为 112 × 112 × 128 的层。'
- en: '**Nonlinearity 4**: ReLU activation applied to the output from convolution
    layer 4.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性激活 4**：对卷积层 4 的输出应用 ReLU 激活函数。'
- en: '**Subsampling layer 2**: Maximum pool with a size of 2 × 2 and a stride of
    2\. This results in a layer with a size of 56 × 56 × 128.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子采样层 2**：大小为 2 × 2、步幅为 2 的最大池化层。这会生成一个大小为 56 × 56 × 128 的层。'
- en: '**Convolution layer 5**: 256 kernels with a size of 3 × 3, a stride of 1, and
    the same padding. This results in a layer with a size of 56 × 56 × 256.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 5**：256 个大小为 3 × 3 的卷积核，步幅为 1，采用相同的填充。这会生成一个大小为 56 × 56 × 256 的层。'
- en: '**Nonlinearity 5**: ReLU activation applied to the output from convolution
    layer 5.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性激活 5**：对卷积层 5 的输出应用 ReLU 激活函数。'
- en: '**Convolution layer 6**: 256 kernels with a size of 3 × 3, a stride of 1, and
    the same padding. This results in a layer with a size of 56 × 56 × 256.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 6**：256 个大小为 3 × 3 的卷积核，步幅为 1，采用相同的填充。这会生成一个大小为 56 × 56 × 256 的层。'
- en: '**Nonlinearity 6**: ReLU activation applied to the output from convolution
    layer 6.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性激活 6**：对卷积层 6 的输出应用 ReLU 激活函数。'
- en: '**Convolution layer 7**: 256 kernels with a size of 3 × 3, a stride of 1, and
    the same padding. This results in a layer with a size of 56 × 56 × 256.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 7**：256 个 3 × 3 的卷积核，步长为 1，采用相同的填充。结果生成一个大小为 56 × 56 × 256 的层。'
- en: '**Nonlinearity 7**: ReLU activation applied to the output from convolution
    layer 7.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性 7**：对卷积层 7 的输出应用 ReLU 激活函数。'
- en: '**Subsampling layer 3**: Maximum pool with a size of 2 × 2 and a stride of
    2. This results in a layer with a size of 28 × 28 × 256.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子采样层 3**：大小为 2 × 2、步长为 2 的最大池化。结果生成一个大小为 28 × 28 × 256 的层。'
- en: '**Convolution layer 8**: 512 kernels with a size of 3 × 3, a stride of 1, and
    the same padding. This results in a layer with a size of 28 × 28 × 512.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 8**：512 个 3 × 3 的卷积核，步长为 1，采用相同的填充。结果生成一个大小为 28 × 28 × 512 的层。'
- en: '**Nonlinearity 8**: ReLU activation applied to the output from convolution
    layer 8.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性 8**：对卷积层 8 的输出应用 ReLU 激活函数。'
- en: '**Convolution layer 9**: 512 kernels with a size of 3 × 3, a stride of 1, and
    the same padding. This results in a layer with a size of 28 × 28 × 512.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 9**：512 个 3 × 3 的卷积核，步长为 1，采用相同的填充。结果生成一个大小为 28 × 28 × 512 的层。'
- en: '**Nonlinearity 9**: ReLU activation applied to the output from convolution
    layer 9.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性 9**：对卷积层 9 的输出应用 ReLU 激活函数。'
- en: '**Convolution layer 10**: 512 kernels with a size of 3 × 3, a stride of 1,
    and the same padding. This results in a layer with a size of 28 × 28 × 512.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 10**：512 个 3 × 3 的卷积核，步长为 1，采用相同的填充。结果生成一个大小为 28 × 28 × 512 的层。'
- en: '**Nonlinearity 10**: ReLU activation applied to the output from convolution
    layer 10.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性 10**：对卷积层 10 的输出应用 ReLU 激活函数。'
- en: '**Subsampling layer 4**: Maximum pool with a size of 2 × 2 and a stride of
    2\. This results in a layer with a size of 14 × 14 × 512.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子采样层 4**：大小为 2 × 2、步长为 2 的最大池化。结果生成一个大小为 14 × 14 × 512 的层。'
- en: '**Convolution layer 11**: 512 kernels with a size of 3×3, a stride of 1, and
    the same padding. This results in a layer with a size of 14 × 14 × 512.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 11**：512 个 3 × 3 的卷积核，步长为 1，采用相同的填充。结果生成一个大小为 14 × 14 × 512 的层。'
- en: '**Nonlinearity 11**: ReLU activation applied to the output from convolution
    layer 11.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性 11**：对卷积层 11 的输出应用 ReLU 激活函数。'
- en: '**Convolution layer 12**: 512 kernels with a size of 3 × 3, a stride of 1,
    and the same padding. This results in a layer with a size of 14 × 14 × 512.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 12**：512 个 3 × 3 的卷积核，步长为 1，采用相同的填充。结果生成一个大小为 14 × 14 × 512 的层。'
- en: '**Nonlinearity 12**: ReLU activation applied to the output from convolution
    layer 12.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性 12**：对卷积层 12 的输出应用 ReLU 激活函数。'
- en: '**Convolution layer 13**: 512 kernels with a size of 3 × 3, a stride of 1,
    and the same padding. This results in a layer with a size of 14 × 14 × 512.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层 13**：512 个 3 × 3 的卷积核，步长为 1，采用相同的填充。结果生成一个大小为 14 × 14 × 512 的层。'
- en: '**Nonlinearity 13**: ReLU activation applied to the output from convolution
    layer 13.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性 13**：对卷积层 13 的输出应用 ReLU 激活函数。'
- en: '**Subsampling layer 5**: Maximum pool with a size of 2 × 2 and a stride of
    2\. This results in a layer with a size of 7 × 7 × 512.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子采样层 5**：大小为 2 × 2、步长为 2 的最大池化。结果生成一个大小为 7 × 7 × 512 的层。'
- en: '**Fully connected layer 1**: A fully connected layer with 4,096 neurons.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层 1**：一个包含 4,096 个神经元的全连接层。'
- en: '**Nonlinearity 14**: ReLU activation applied to the output from fully connected
    layer 1.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性 14**：对全连接层 1 的输出应用 ReLU 激活函数。'
- en: '**Fully connected layer 2**: A fully connected layer with 4,096 neurons.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层 2**：一个包含 4,096 个神经元的全连接层。'
- en: '**Nonlinearity 15**: ReLU activation applied to the output from fully connected
    layer 2.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性 15**：对全连接层 2 的输出应用 ReLU 激活函数。'
- en: '**Output layer**: Softmax applied to the 1,000 neurons to calculate the probability
    of it being one of the classes.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出层**：对 1,000 个神经元应用 Softmax，以计算其属于某一类别的概率。'
- en: This network placed runner up in the 2014 ILSVRC and has approximately 138 million
    trainable parameters. So, it is very difficult to train.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 该网络在 2014 年 ILSVRC 比赛中获得第二名，约有 1.38 亿个可训练参数。因此，它非常难以训练。
- en: Inception-v1
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Inception-v1
- en: The InceptionNet architecture (often referred to as **GoogLeNet**) placed first
    in the 2014 ILSVRC and achieved near-human performance at 93.3% accuracy. The
    name **inception** is a reference to the movie *Inception*, particularly to the
    need to go deeper (in terms of layers). This architecture is a little different
    from the ones we saw earlier in that it makes use of Inception modules instead
    of layers. Each Inception block contains filters of three different sizes—1 ×
    1, 3 × 3, and 5 × 5\. What this does is allow our network to capture sparse patterns
    through spatial information and variances at different scales, thereby allowing
    our network to learn even more complex information. However, previously, our networks
    consistently had a kernel of one size throughout the layer.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: InceptionNet架构（通常被称为**GoogLeNet**）在2014年ILSVRC中获得了第一名，并达到了近人类水平的93.3%准确率。**Inception**这个名称来源于电影*盗梦空间*，特别是指需要更深入（在层数方面）的含义。这个架构与我们之前看到的有些不同，它使用了Inception模块而非传统的层。每个Inception块包含三种不同大小的滤波器——1
    × 1、3 × 3和5 × 5。这样做的目的是让网络能够通过空间信息和不同尺度的变化捕捉稀疏模式，从而使网络能够学习到更复杂的信息。然而，以前我们的网络在整个层中始终使用相同大小的卷积核。
- en: 'The Inception module looks as follows:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: Inception模块如下所示：
- en: '![](img/09c99a97-16fa-4ba3-83dd-44c8fb973957.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![](img/09c99a97-16fa-4ba3-83dd-44c8fb973957.png)'
- en: As you can see, each block contains four parallel channels. The first channel
    contains a 1 × 1 kernel, the second channel contains a 1 × 1 kernel followed by
    a 3 × 3 kernel, the third channel contains a 1 × 1 kernel followed by a 5 × 5 kernel,
    and the fourth channel contains a 3 × 3 maximum pooling followed by a 1 × 1 kernel.
    The resulting feature maps are then concatenated and fed as input into the next
    block. The reason behind applying a 1 × 1 kernel before the larger kernels—such
    as the 3 × 3 and 5 × 5 kernels—is to reduce the dimensionality because larger
    kernels are more computationally expensive.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，每个块包含四个并行的通道。第一个通道包含一个1 × 1的卷积核，第二个通道包含一个1 × 1卷积核，后接一个3 × 3卷积核，第三个通道包含一个1
    × 1卷积核，后接一个5 × 5卷积核，第四个通道包含一个3 × 3的最大池化，后接一个1 × 1卷积核。得到的特征图会被拼接起来，作为输入传递到下一个块。应用1
    × 1卷积核在较大卷积核（如3 × 3和5 × 5卷积核）之前的原因是为了减少维度，因为较大的卷积核计算开销较大。
- en: This network takes in images with a size of 224 × 224, mean subtraction, and
    22 layers with trainable parameters (27 if you count the pooling layers).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这个网络输入的图像大小为224 × 224，进行均值减法，并包含22层可训练参数（如果包括池化层则为27层）。
- en: 'The details of the architecture are displayed in the following table:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 架构的详细信息如下表所示：
- en: '![](img/adc875f6-8f3d-41a8-9f25-ea716173ebd9.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![](img/adc875f6-8f3d-41a8-9f25-ea716173ebd9.png)'
- en: 'The network looks as follows:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 网络架构如下所示：
- en: '![](img/11606bdc-5356-48e3-a5e9-88e0ba694bb9.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![](img/11606bdc-5356-48e3-a5e9-88e0ba694bb9.png)'
- en: Interestingly, despite this being a much deeper network than AlexNet and VGG-16,
    there are a lot fewer parameters that we need to train because it uses kernels
    with smaller sizes, as well as depth reduction. Larger networks, as we know, do
    tend to perform better than shallower ones. The significance of this architecture
    is that despite being deep, it is relatively more simple to train that if it had
    many more parameters.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，尽管这个网络比AlexNet和VGG-16要深得多，但我们需要训练的参数却要少得多，因为它使用了较小尺寸的卷积核，并且进行了深度减少。我们知道，较大的网络通常比较浅的网络表现更好。这个架构的意义在于，尽管它很深，但训练起来相对简单，比如果它有更多的参数的话。
- en: Summary
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Congratulations! We have just finished learning about a powerful variant of
    neural networks known as CNNs, which are very effective in tasks relating to computer
    vision and time-series prediction. We will revisit CNNs later on in this book,
    but in the meantime, let's move on to the next chapter and learn about recurrent
    and recursive neural networks.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！我们刚刚学习了一个强大的神经网络变种——卷积神经网络（CNNs），它在与计算机视觉和时间序列预测相关的任务中非常有效。我们将在本书的后续章节中再次讨论CNN，但在此之前，让我们继续前进，学习递归神经网络和递归神经网络。
