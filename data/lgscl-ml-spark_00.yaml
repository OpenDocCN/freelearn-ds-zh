- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: Machine learning, at its core, is concerned with algorithms that transform raw
    data into information into actionable intelligence. This fact makes machine learning
    well suited to the predictive analytics of Big Data. Without machine learning,
    therefore, it would be nearly impossible to keep up with these massive streams
    of information altogether. Spark, which is relatively a new and emerging technology,
    provides big data engineers and data scientists a powerful response and a unified
    engine that is both faster and easy to use.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的核心是关注将原始数据转化为可操作智能的算法。这一事实使得机器学习非常适合于大数据的预测分析。因此，如果没有机器学习，要跟上这些大规模信息流几乎是不可能的。相对较新且新兴的技术Spark为大数据工程师和数据科学家提供了一个强大的响应和统一的引擎，既更快速又易于使用。
- en: This allows learners from numerous areas to solve their machine learning problems
    interactively and at much greater scale. The book is designed to enable data scientists,
    engineers, and researchers to develop and deploy their machine learning applications
    at scale so that they can learn how to handle large data clusters in data intensive
    environments to build powerful machine learning models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得来自多个领域的学习者能够以更大规模地交互解决他们的机器学习问题。本书旨在使数据科学家、工程师和研究人员能够开发和部署规模化的机器学习应用程序，以便他们学会如何在数据密集型环境中处理大数据集群，构建强大的机器学习模型。
- en: The contents of the books have been written in a bottom-up approach from Spark
    and ML basics, exploring data with feature engineering, building scalable ML pipelines,
    tuning and adapting them through for the new data and problem types, and finally,
    model building to deployment. To clarify more, we have provided the chapters outline
    in such a way that a new reader with a minimum of knowledge of machine learning
    and programming with Spark will be able to follow the examples and move towards
    some real-life machine learning problems and their solutions.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的内容是从Spark和ML基础开始以自下而上的方式编写的，探索了特征工程中的数据，构建可扩展的ML管道，通过调整和适应新的数据和问题类型，最终进行模型构建和部署。为了更清晰，我们以这样一种方式提供了章节大纲，以便具有最基本的机器学习和Spark编程知识的新读者能够跟随示例，并朝着一些真实的机器学习问题及其解决方案迈进。
- en: What this book covers
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容包括以下内容
- en: '[Chapter 1](part0014_split_000.html#DB7S2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 1. Introduction to Data Analytics with Spark"),* Introduction to Data
    Analytics with Spark*, this chapter covers Spark''s overview, its computing paradigm,
    installation, and help us get started with Spark. It will briefly describe the
    main components of Spark and focus on its new computing advancements with the
    Resilient Distributed Datasets (RDD) and Dataset. It will then focus on the Spark’s
    ecosystem of machine learning libraries. Installing, configuring, and packaging
    a simple machine learning application with Spark and Maven will be demonstrated
    before scaling up on Amazon EC2.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 第1章，*使用Spark进行数据分析简介*，本章介绍了Spark的概述、计算范式、安装，并帮助我们开始使用Spark。它将简要描述Spark的主要组件，并专注于其具有弹性分布式数据集（RDD）和数据集的新计算进展。然后，它将专注于Spark的机器学习库生态系统。在扩展到Amazon
    EC2之前，将演示使用Spark和Maven安装、配置和打包简单的机器学习应用程序。
- en: '[Chapter 2](part0023_split_000.html#LTSU2-5afe140a04e845e0842b44be7971e11a
    "Chapter 2. Machine Learning Best Practices"), *Machine Learning Best Practices*,
    provides a conceptual introduction to statistical machine learning (ML) techniques
    aiming to take a newcomer from a minimal knowledge of machine learning all the
    way to being a knowledgeable practitioner in a few steps. The second part of the
    chapter is focused on providing some recommendations for choosing the right machine
    learning algorithms depending on its application types and requirements. It will
    then go through some best practices when applying large-scale machine learning
    pipelines.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 第2章，*机器学习最佳实践*，提供了对统计机器学习（ML）技术的概念介绍，旨在带领新手从对机器学习的最基本知识到成为熟练的从业者。本章的第二部分侧重于为根据应用类型和要求选择合适的机器学习算法提供一些建议。然后，它将介绍应用大规模机器学习管道时的一些最佳实践。
- en: '[Chapter 3](part0031_split_000.html#TI1E2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 3. Understanding the Problem by Understanding the Data"), *Understanding
    the Problem by Understanding the Data*, covers in detail the Dataset and Resilient
    Distributed Dataset (RDD) APIs for working with structured data, aiming to provide
    a basic understanding of machine learning problems with the available data. By
    the end, you will be able to deal with basic and complex data manipulation with
    ease. Some comparisons will be made available with basic abstractions in Spark
    using RDD and Dataset-based data manipulation to show gains both in terms of programming
    and performance. In addition, we will guide you on the right track so that you
    will be able to use Spark to persist an RDD or data object in memory, allowing
    it to be reused efficiently across the parallel operations in the later stage.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 第3章，*通过了解数据来理解问题*，详细介绍了用于处理结构化数据的数据集和弹性分布式数据集（RDD）API，旨在提供对可用数据进行基本理解的机器学习问题。最后，您将能够轻松处理基本和复杂的数据操作。将提供使用RDD和基于数据集的数据操作的基本抽象的一些比较，以展示在编程和性能方面的收益。此外，我们将指导您走上正确的道路，以便您能够使用Spark将RDD或数据对象持久化在内存中，从而在后期的并行操作中有效地重复使用。
- en: '[Chapter 4](part0038_split_000.html#147LC2-5afe140a04e845e0842b44be7971e11a
    "Chapter 4. Extracting Knowledge through Feature Engineering"), *Extracting Knowledge
    through Feature Engineering*, explains that knowing the features that should be
    used to create a predictive model is not only vital but also a difficult question
    that may require deep knowledge of the problem domain to be examined. It is possible
    to automatically select those features in data that are most useful or most relevant
    for the problem someone is working on. Considering these questions, this chapter
    covers feature engineering in detail, explaining the reasons to apply it along
    with some best practices in feature engineering.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 《第4章》《通过特征工程提取知识》解释了了解应该用于创建预测模型的特征不仅至关重要，而且可能是一个需要深入了解问题领域的难题。可以自动选择数据中对某人正在处理的问题最有用或最相关的特征。考虑到这些问题，本章详细介绍了特征工程，解释了应用它的原因以及特征工程中的一些最佳实践。
- en: In addition to this, theoretical descriptions and examples of feature extraction,
    transformations, and selection applied to large-scale machine learning technique
    using both Spark MLlib and Spark ML APIs will be discussed.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，还将讨论应用于大规模机器学习技术的特征提取、转换和选择的理论描述和示例，使用Spark MLlib和Spark ML API。
- en: '[Chapter 5](part0043_split_000.html#190862-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 5.  Supervised and Unsupervised Learning by Examples"), *Supervised and
    Unsupervised Learning by Examples*, will provide the practical knowledge surrounding how
    to apply supervised and unsupervised techniques on the available data to new problems
    quickly and powerfully through some widely used examples based on the previous
    chapters. These examples will be demonstrated from the Spark perspective.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 《第5章》《通过示例进行监督和无监督学习》将提供围绕如何快速而有力地将监督和无监督技术应用于可用数据解决新问题的实际知识，这些知识是基于前几章的一些广泛使用的示例。这些示例将从Spark的角度进行演示。
- en: '[Chapter 6](part0049_split_000.html#1ENBI2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 6.  Building Scalable Machine Learning Pipelines"), *Building Scalable
    Machine Learning Pipelines*, explains that the ultimate goal of machine learning
    is to make a machine that can automatically build models from data without requiring
    tedious and time-consuming human involvement and interaction. Therefore, this
    chapter guides the readers through creating some practical and widely used machine
    learning pipelines and applications using Spark MLlib and Spark ML. Both APIs
    will be described in detail, and a baseline use case will also be covered for
    both. Then we will focus towards scaling up the ML application so that it can
    cope up with increasing data loads.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 《第6章》《构建可扩展的机器学习管道》解释了机器学习的最终目标是使机器能够在不需要繁琐和耗时的人工参与和交互的情况下自动从数据中构建模型。因此，本章将指导读者通过使用Spark
    MLlib和Spark ML创建一些实用和广泛使用的机器学习管道和应用。将详细描述这两个API，并且还将涵盖基线用例。然后，我们将专注于扩展ML应用程序，使其能够应对不断增加的数据负载。
- en: '[Chapter 7](part0059_split_000.html#1O8H62-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 7. Tuning Machine Learning Models"), *Tuning Machine Learning Models*,
    shows that tuning an algorithm or machine learning application can be simply thought
    of as a process by which one goes through and optimizes the parameters that impact
    the model in order to enable the algorithm to perform to its best. This chapter
    aims at guiding the reader through model tuning. It will cover the main techniques
    used to optimize an ML algorithm’s performance. Techniques will be explained both
    from the MLlib and Spark ML perspective. We will also show how to improve the
    performance of the ML models by tuning several parameters, such as hyperparameters,
    grid search parameters with MLlib and Spark ML, hypothesis testing, Random search
    parameter tuning, and Cross-validation.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 《第7章》《调整机器学习模型》表明，调整算法或机器学习应用可以简单地被视为一个过程，通过这个过程优化影响模型的参数，以使算法表现最佳。本章旨在指导读者进行模型调整。它将涵盖用于优化ML算法性能的主要技术。技术将从MLlib和Spark
    ML的角度进行解释。我们还将展示如何通过调整多个参数（如超参数、MLlib和Spark ML的网格搜索参数、假设检验、随机搜索参数调整和交叉验证）来改善ML模型的性能。
- en: '[Chapter 8](part0067_split_000.html#1VSLM1-5afe140a04e845e0842b44be7971e11a
    "Chapter 8.  Adapting Your Machine Learning Models"), *Adapting Your Machine Learning
    Models*, covers advanced machine learning techniques that will make algorithms
    adaptable to new data and problem types. It will mainly focus on batch/streaming
    architectures and on online learning algorithms using Spark streaming. The ultimate
    target is to bring dynamism to static machine learning models. Readers will also
    see how the machine learning algorithms learn incrementally from the data, that
    is, the models are updated each time the algorithm sees a new training instance.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 《第8章》《调整您的机器学习模型》涵盖了使算法适应新数据和问题类型的高级机器学习技术。它将主要关注批处理/流处理架构和使用Spark流处理的在线学习算法。最终目标是为静态机器学习模型带来动态性。读者还将看到机器学习算法如何逐渐从数据中学习，即每次算法看到新的训练实例时，模型都会更新。
- en: '[Chapter 9](part0073_split_000.html#25JP22-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 9.  Advanced Machine Learning with Streaming and Graph Data"), *Advanced
    Machine Learning with Streaming and Graph Data*, explains reader how to apply
    machine learning techniques, with the help of Spark MLlib and Spark ML, on streaming
    and graph data, for example, in topic modeling. The readers will be able to use
    available APIs to build real-time and predictive applications from streaming data
    sources such as Twitter. Through the Twitter data analysis, we will show how to
    perform large-scale social sentiment analysis. We will also show how to develop
    a large-scale movie recommendation system using Spark MLlib, which is an implicit
    part of social network analysis.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 第9章《使用流式和图形数据进行高级机器学习》解释了如何利用Spark MLlib和Spark ML等工具在流式和图形数据上应用机器学习技术，例如在主题建模中。读者将能够利用现有的API从流数据源（如Twitter）构建实时和预测性应用程序。通过Twitter数据分析，我们将展示如何进行大规模社交情感分析。我们还将展示如何使用Spark
    MLlib开发大规模电影推荐系统，这是社交网络分析的一个隐含部分。
- en: '[Chapter 10](part0079_split_000.html#2BASE2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 10.  Configuring and Working with External Libraries"), *Configuring
    and Working with External Libraries*, guides the reader on using external libraries
    to expand their data analysis. Examples will be given for deploying third-party
    packages or libraries for machine learning applications with Spark core and ML/MLlib.
    We will also discuss how to compile and use external libraries with the core libraries
    of Spark for time series. As promised, we will also discuss how to configure SparkR
    to improve exploratory data manipulation and operations.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第10章《配置和使用外部库》指导读者如何使用外部库来扩展他们的数据分析。将给出使用第三方包或库在Spark核心和ML/MLlib上进行机器学习应用的示例。我们还将讨论如何编译和使用外部库与Spark的核心库进行时间序列分析。如约定的，我们还将讨论如何配置SparkR以改进探索性数据操作。
- en: What you need for this book
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书所需内容
- en: '**Software requirements:**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**软件要求：**'
- en: 'Following software is required for chapters 1-8 and 10: Spark 2.0.0 (or higher),
    Hadoop 2.7 (or higher), Java (JDK and JRE) 1.7+/1.8+, Scala 2.11.x (or higher),
    Python 2.6+/3.4+, R 3.1+, and RStudio 0.99.879 (or higher) installed. Eclipse
    Mars or Luna (latest) can be used. Moreover, Maven Eclipse plugin (2.9 or higher),
    Maven compiler plugin for Eclipse (2.3.2 or higher) and Maven assembly plugin
    for Eclipse (2.4.1 or higher) are required. Most importantly, re-use the provided
    `pom.xml` file with Packt''s supplements and change the previously-mentioned version
    and APIs accordingly and everything will be sorted out.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 第1-8章和第10章需要以下软件：Spark 2.0.0（或更高版本）、Hadoop 2.7（或更高版本）、Java（JDK和JRE）1.7+/1.8+、Scala
    2.11.x（或更高版本）、Python 2.6+/3.4+、R 3.1+和已安装的RStudio 0.99.879（或更高版本）。可以使用Eclipse
    Mars或Luna（最新版本）。此外，还需要Maven Eclipse插件（2.9或更高版本）、用于Eclipse的Maven编译器插件（2.3.2或更高版本）和用于Eclipse的Maven汇编插件（2.4.1或更高版本）。最重要的是，重复使用Packt提供的`pom.xml`文件，并相应地更改先前提到的版本和API，一切都会得到解决。
- en: For [Chapter 9](part0073_split_000.html#25JP22-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 9.  Advanced Machine Learning with Streaming and Graph Data"), *Advanced
    Machine Learning with Streaming and Graph Data,* almost all the software required,
    mentioned previously, except for the Twitter data collection example, which will
    be shown in Spark 1.6.1\. Therefore, Spark 1.6.1 or 1.6.2 is required, along with
    the Maven-friendly `pom.xml` file.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第9章《使用流式和图形数据进行高级机器学习》，几乎所有先前提到的所需软件都是必需的，除了Twitter数据收集示例，该示例将在Spark 1.6.1中展示。因此，需要Spark
    1.6.1或1.6.2，以及友好的Maven `pom.xml`文件。
- en: '**Operating system requirements:  **'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**操作系统要求：**'
- en: Spark can be run on a number of operating systems including Windows, Mac OS,
    and LINUX. However, Linux distributions are preferable (including Debian, Ubuntu,
    Fedora, RHEL, CentOS and so on). To be more specific, for example, for Ubuntu
    it is recommended to have a 14.04/15.04 (LTS) 64-bit complete installation or
    VMWare player 12 or Virtual Box.  For Windows, Windows (XP/7/8/10) and for Mac
    OS X (10.4.7+) is recommended.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Spark可以在多个操作系统上运行，包括Windows、Mac OS和LINUX。然而，Linux发行版更可取（包括Debian、Ubuntu、Fedora、RHEL、CentOS等）。更具体地说，例如对于Ubuntu，建议使用14.04/15.04（LTS）64位完整安装或VMWare
    player 12或Virtual Box。对于Windows，建议使用Windows（XP/7/8/10），对于Mac OS X（10.4.7+）也是如此。
- en: '**Hardware requirements:**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**硬件要求：**'
- en: To work with Spark smoothly, a machine with at least a core i3 or core i5 processor
    is recommended.  However, to get the best results, core i7 would achieve faster
    data processing and scalability with at least 8 GB RAM (recommended) for a standalone
    mode and at least 32 GB RAM for a single VM, or higher for a cluster. Besides,
    enough storage to run heavy jobs (depending upon the data size you will be handling),
    and preferably at least 50 GB of free disk storage (for stand-alone and for SQL
    warehouse).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了顺利使用Spark，建议使用至少核心i3或核心i5处理器的计算机。然而，为了获得最佳结果，核心i7将实现更快的数据处理和可伸缩性，至少需要8GB RAM（建议）用于独立模式，至少需要32GB
    RAM用于单个VM，或者用于集群的更高内存。此外，需要足够的存储空间来运行繁重的任务（取决于您将处理的数据大小），最好至少有50GB的免费磁盘存储空间（用于独立和SQL仓库）。
- en: Who this book is for
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适合对象
- en: Python and R are two popular languages for data scientists due to the large
    number of modules or packages that are readily available to help them solve their
    data analytics problems. However, traditional uses of these tools are often limiting,
    as they process data on either a single machine or with main memory-based approaches
    where the movement of data becomes time-consuming, the analysis requires sampling,
    and moving from development to production environments requires extensive re-engineering. To
    address these issues, Spark provides data engineers and data scientists a powerful
    and unified engine that is both faster and easy to use. This allows you to solve
    their machine learning problems interactively and at much greater scale.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Python 和 R 是数据科学家常用的两种流行语言，因为有大量的模块或软件包可用来帮助他们解决数据分析问题。然而，这些工具的传统用法通常有限，因为它们在单台机器上处理数据，或者使用基于主存储器的方法处理数据，数据的移动变得耗时，分析需要抽样，并且从开发到生产环境的转换需要大量的重新设计。为了解决这些问题，Spark
    提供了一个强大且统一的引擎，既快速又易于使用，这使您能够以交互方式解决机器学习问题，并且规模更大。
- en: Therefore, if you are an academic, researcher, data science engineer, or even
    a big data engineer working with large and complex data sets. Furthermore, if
    you want to board your data processing pipelines and machine learning applications
    to scale up more quickly, this book would be a suitable companion to this journey.
    Moreover, Spark provides many language choices, including Scala, Java, and Python.
    This facility will definitely help you to lift your machine learning applications
    on top of Spark and reshape using any one of these programming languages with
    Spark.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果您是学术界人士、研究人员、数据科学工程师，甚至是处理大型和复杂数据集的大数据工程师。此外，如果您想要加速数据处理管道和机器学习应用的扩展，这本书将是您旅程中的合适伴侣。此外，Spark
    提供了许多语言选择，包括 Scala、Java 和 Python。这将帮助您将机器学习应用程序置于 Spark 之上，并使用这些编程语言之一进行重塑。
- en: You should be familiar with the basics of machine learning concepts at least.
    Knowledge of open source tools and frameworks such as Apache Spark and Hadoop-based
    MapReduce would be good, but is not essential. A solid background in statistics
    and computational mathematics is expected. In addition, knowledge of Scala, Python,
    and Java is advisable. However, if you are experienced with intermediate programming
    languages, this will help you to understand the discussions and examples demonstrated
    in this book.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该至少熟悉机器学习概念的基础知识。了解开源工具和框架，如 Apache Spark 和基于 Hadoop 的 MapReduce，会很有帮助，但并非必需。我们期望您具备扎实的统计学和计算数学背景。此外，了解
    Scala、Python 和 Java 是明智的。然而，如果您熟悉中级编程语言，这将有助于您理解本书中的讨论和示例。
- en: Conventions
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 约定
- en: In this book, you will find a number of styles of text that distinguish between
    different kinds of information. Here are some examples of these styles, and an
    explanation of their meaning.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，您会发现许多不同风格的文本，用以区分不同类型的信息。以下是一些这些风格的例子，以及它们的含义解释。
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input and Twitter handles are shown as follows: "We
    can include other contexts through the use of the `include` directive."'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '文本中的代码词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 句柄显示如下: "我们可以通过使用 `include`
    指令来包含其他上下文。"'
- en: 'A block of code for creating the Spark session in a Windows environment is
    set as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '在 Windows 环境中创建 Spark 会话的代码块设置如下:'
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Or creating simple RDD from the input dataset is set as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '或者从输入数据集创建简单的 RDD 设置如下:'
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '任何命令行输入或输出都以如下方式编写:'
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, in menus or dialogue boxes, for example, appear in the text like
    this: "Clicking the **Next** button moves you to the next screen".'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**新术语**和**重要单词**以粗体显示。您在屏幕上看到的单词、菜单或对话框中的单词等都会以这样的方式出现在文本中: "点击 **下一步** 按钮将您移动到下一个屏幕"。'
- en: Note
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Warnings or important notes appear in a box like this.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要说明会出现在这样的框中。
- en: Tip
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Tips and tricks appear like this.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和技巧会出现在这样。
- en: Reader feedback
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读者反馈
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book—what you liked or may have disliked. Reader feedback is important for
    us to develop titles that you really get the most out of.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。让我们知道您对这本书的看法——您喜欢或不喜欢的地方。读者的反馈对我们开发能让您真正受益的书籍至关重要。
- en: To send us general feedback, simply send an e-mail to feedback@packtpub.com,
    and mention the book title via the subject of your message.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要向我们发送一般反馈，只需发送电子邮件至 feedback@packtpub.com，并在消息主题中提及书名。
- en: If there is a topic that you have expertise in and you are interested in either
    writing or contributing to a book, see our author guide on [https://www.packtpub.com/books/info/packt/authors](https://www.packtpub.com/books/info/packt/authors).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在某个专题上有专业知识，并且有兴趣撰写或为书籍做出贡献，请参阅我们的作者指南 [https://www.packtpub.com/books/info/packt/authors](https://www.packtpub.com/books/info/packt/authors)。
- en: Customer support
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户支持
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您是 Packt 书籍的自豪所有者，我们有一些东西可以帮助您充分利用您的购买。
- en: Downloading the example code
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载示例代码
- en: You can download the example code files for all Packt books you have purchased
    from your account at [http://www.packtpub.com](http://www.packtpub.com). If you
    purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从您在 [http://www.packtpub.com](http://www.packtpub.com) 购买的所有 Packt 书籍中下载示例代码文件。如果您在其他地方购买了这本书，您可以访问
    [http://www.packtpub.com/support](http://www.packtpub.com/support) 并注册，文件将直接通过电子邮件发送给您。
- en: 'You can download the code files by following these steps:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '您可以按照以下步骤下载代码文件:'
- en: Log in or register to our website using your e-mail address and password.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您的电子邮件地址和密码登录或注册我们的网站。
- en: Hover the mouse pointer on the **SUPPORT** tab at the top.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将鼠标指针悬停在顶部的**支持**选项卡上。
- en: Click on **Code Downloads & Errata**.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载和勘误**。
- en: Enter the name of the book in the **Search** box.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**搜索**框中输入书名。
- en: Select the book for which you're looking to download the code files.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您要下载代码文件的书籍。
- en: Choose from the drop-down menu where you purchased this book from.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从下拉菜单中选择您购买这本书的地方。
- en: Click on **Code Download**.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载**。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 文件下载后，请确保使用最新版本的解压缩软件解压文件夹：
- en: WinRAR / 7-Zip for Windows
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WinRAR / 7-Zip for Windows
- en: Zipeg / iZip / UnRarX for Mac
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipeg / iZip / UnRarX for Mac
- en: 7-Zip / PeaZip for Linux
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7-Zip / PeaZip for Linux
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Large-Scale-Machine-Learning-with-Spark](https://github.com/PacktPublishing/Large-Scale-Machine-Learning-with-Spark).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 该书的代码包也托管在GitHub上，网址为[https://github.com/PacktPublishing/Large-Scale-Machine-Learning-with-Spark](https://github.com/PacktPublishing/Large-Scale-Machine-Learning-with-Spark)。我们还有其他丰富书籍和视频代码包可供下载，网址为[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)。快去看看吧！
- en: Errata
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 勘误
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books—maybe a mistake in the text
    or the code—we would be grateful if you would report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the errata submission form link, and entering
    the details of your errata. Once your errata are verified, your submission will
    be accepted and the errata will be uploaded on our website, or added to any list
    of existing errata, under the Errata section of that title. Any existing errata
    can be viewed by selecting your title from [http://www.packtpub.com/support](http://www.packtpub.com/support).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经尽一切努力确保内容的准确性，但错误还是会发生。如果您在我们的书中发现错误——可能是文本或代码中的错误——我们将不胜感激，如果您能向我们报告。通过这样做，您可以帮助其他读者避免挫败，并帮助我们改进本书的后续版本。如果您发现任何勘误，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)报告，选择您的书，点击勘误提交表单链接，并输入您的勘误详情。一旦您的勘误经过验证，您的提交将被接受，并且勘误将被上传到我们的网站上，或者添加到该标题的勘误部分的任何现有勘误列表中。您可以通过从[http://www.packtpub.com/support](http://www.packtpub.com/support)选择您的标题来查看任何现有的勘误。
- en: Piracy
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 盗版
- en: Piracy of copyright material on the Internet is an ongoing problem across all
    media. At Packt, we take the protection of our copyright and licenses very seriously.
    If you come across any illegal copies of our works, in any form, on the Internet,
    please provide us with the location address or website name immediately so that
    we can pursue a remedy.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上的版权盗版是所有媒体的持续问题。在Packt，我们非常重视保护我们的版权和许可。如果您在互联网上以任何形式发现我们作品的非法副本，请立即向我们提供位置地址或网站名称，以便我们采取补救措施。
- en: Please contact us at copyright@packtpub.com with a link to the suspected pirated
    material.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 请通过copyright@packtpub.com与我们联系，并提供涉嫌盗版材料的链接。
- en: We appreciate your help in protecting our authors, and our ability to bring
    you valuable content.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢您帮助保护我们的作者，以及我们提供有价值内容的能力。
- en: Questions
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You can contact us at questions@packtpub.com if you are having a problem with
    any aspect of the book, and we will do our best to address it.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在书的任何方面遇到问题，请通过questions@packtpub.com与我们联系，我们将尽力解决。
