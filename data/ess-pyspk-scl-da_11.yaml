- en: 'Chapter 9: Machine Learning Life Cycle Management'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章：机器学习生命周期管理
- en: In the previous chapters, we explored the basics of **scalable machine learning**
    using Apache Spark. Algorithms dealing with **supervised** and **unsupervised**
    learning were introduced and their implementation details were presented using
    **Apache Spark MLlib**. In real-world scenarios, it is not sufficient to just
    train one model. Instead, multiple versions of the same model must be built using
    the same dataset by varying the model parameters to get the best possible model.
    Also, the same model might not be suitable for all applications, so multiple models
    are trained. Thus, it is necessary to track various experiments, their parameters,
    their metrics, and the version of the data they were trained on. Furthermore,
    models often drift, meaning that their prediction power decreases due to changes
    in the environment, so they need to be monitored and retrained when necessary.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们探讨了使用**Apache Spark**进行**可扩展机器学习**的基础知识。介绍了处理**监督学习**和**无监督学习**的算法，并展示了如何使用**Apache
    Spark MLlib**实现这些算法。在现实世界中，仅训练一个模型是不够的。相反，必须通过调整模型参数，使用相同的数据集构建多个版本的同一模型，以获得最佳的模型。此外，同一个模型可能并不适用于所有应用，因此需要训练多个模型。因此，有必要跟踪各种实验、它们的参数、指标以及它们训练所用的数据版本。而且，模型通常会出现漂移，意味着它们的预测能力会因为环境变化而降低，因此需要进行监控并在必要时重新训练。
- en: This chapter will introduce the concepts of experiment tracking, model tuning,
    productionizing models, and model inferencing using offline and online techniques.
    This chapter will present these concepts using an end-to-end open source machine
    learning life cycle management tool called **MLflow**. Finally, we will look at
    the concept of continuous deployment for machine learning to automate the entire
    **machine learning** (**ML**) life cycle management process.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍实验跟踪、模型调优、模型生产化以及使用离线和在线技术进行模型推理的概念。本章将通过一个端到端的开源机器学习生命周期管理工具**MLflow**来展示这些概念。最后，我们将探讨机器学习的持续部署概念，以自动化整个**机器学习**（**ML**）生命周期管理过程。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将覆盖以下主要内容：
- en: Introduction to the ML life cycle
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习生命周期简介
- en: Tracking experiments with **MLflow**
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**MLflow**跟踪实验
- en: Tracking model versions using **MLflow Model Registry**
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**MLflow模型注册表**跟踪模型版本
- en: Model serving and inferencing
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型服务和推理
- en: Continuous deployment for ML
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的持续部署
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we will be using Databricks Community Edition to run our code
    ([https://community.cloud.databricks.com](https://community.cloud.databricks.com)).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将使用Databricks Community Edition来运行代码（[https://community.cloud.databricks.com](https://community.cloud.databricks.com)）。
- en: Sign-up instructions can be found at [https://databricks.com/try-databricks](https://databricks.com/try-databricks).
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注册说明可以在[https://databricks.com/try-databricks](https://databricks.com/try-databricks)找到。
- en: The code for this chapter can be downloaded from [https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/Chapter09](https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/Chapter09),
    while the datasets for this chapter can be found at [https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/data](https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/data).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的代码可以从[https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/Chapter09](https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/Chapter09)下载，而本章的数据集可以在[https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/data](https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/data)找到。
- en: 'We will also be using a managed MLflow that comes with Databricks Community
    Edition. Instructions for installing a standalone version of MLflow can be found
    here: [https://mlflow.org/docs/latest/quickstart.html](https://mlflow.org/docs/latest/quickstart.html).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用Databricks Community Edition提供的托管版MLflow。安装独立版MLflow的说明可以在这里找到：[https://mlflow.org/docs/latest/quickstart.html](https://mlflow.org/docs/latest/quickstart.html)。
- en: Introduction to the ML life cycle
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习生命周期简介
- en: 'The **ML life cycle** is a continuous process that a data science project follows.
    It contains four major stages, starting with data collection and preparation,
    model training, model evaluation, and finally model inferencing and monitoring.
    The ML process is a continuous one, where the cycle iterates between improving
    the data and constantly improving the model''s performance; or, rather, keeping
    it from degrading over time:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习生命周期**是数据科学项目所遵循的一个持续过程。它包含四个主要阶段，分别是数据收集与准备、模型训练、模型评估，最后是模型推理和监控。机器学习过程是一个持续的过程，生命周期在优化数据和不断提高模型性能之间反复迭代；或者说，防止模型性能随着时间的推移而下降：'
- en: '![Figure 9.1 – ML life cycle'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.1 – 机器学习生命周期'
- en: '](img/B16736_09_01.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16736_09_01.jpg)'
- en: Figure 9.1 – ML life cycle
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – 机器学习生命周期
- en: The previous diagram presents the continuous process of ML life cycle management,
    from data preparation to model development, and then from training to model deployment
    and monitoring. When model performance degrades due to either a change in the
    training data or the model code or changes in model parameters, the cyclic process
    starts all over again.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表展示了机器学习生命周期管理的持续过程，从数据准备到模型开发，然后从训练到模型部署和监控。当模型性能因训练数据的变化、模型代码的变化或模型参数的变化而下降时，循环过程将重新开始。
- en: Processes for data collection and preparation, cleansing, and consolidation,
    as well as techniques for training various ML models at scale, were introduced
    in the previous chapters. This chapter will introduce the remaining stages of
    the ML life cycle, including model evaluation and model inferencing and monitoring.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 前几章介绍了数据收集与准备、清洗和整合的过程，以及在大规模上训练各种机器学习模型的技术。本章将介绍机器学习生命周期的其余阶段，包括模型评估、模型推理和监控。
- en: This cyclic process of ML life cycle management helps you continuously refine
    your datasets and models and maintain model performance. The speed at which you
    can iterate through the ML life cycle determines how fast you can put the model
    to practical use, which determines the value of your data science project to businesses,
    as well as the cost associated with the data science project. Thus, it is important
    to make use of an ML life cycle management tool to streamline the entire ML process,
    derive the maximum value out of your data science project, and ensure that business
    users can derive tangible benefits from it. Several ML life cycle management tools
    exist today that can handle this task. *Pacyderm*, *Kubeflow*, *MLflow*, and *Metaflow*
    are a few of the available open source tools, while *AWS Sagemaker*, *Google Cloud
    AutoML*, and *Microsoft Azure ML* are all cloud-native services with full ML life
    cycle management support. In this chapter, we will explore MLflow as an ML life
    cycle management tool. The following sections will explore MLflow in greater detail.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习生命周期管理的这一循环过程帮助你不断优化数据集和模型，并保持模型的性能。你在机器学习生命周期中的迭代速度决定了你将模型投入实际应用的速度，从而决定了你的数据科学项目对企业的价值以及与数据科学项目相关的成本。因此，使用机器学习生命周期管理工具来简化整个机器学习过程、从数据科学项目中获取最大价值，并确保业务用户能够从中获得实际收益是至关重要的。目前存在多种机器学习生命周期管理工具可以处理这一任务。*Pacyderm*、*Kubeflow*、*MLflow*和*Metaflow*是一些开源工具，而*AWS
    Sagemaker*、*Google Cloud AutoML*和*Microsoft Azure ML*都是具有完整机器学习生命周期管理支持的云原生服务。本章将探索*MLflow*作为机器学习生命周期管理工具，接下来的章节将更详细地探讨*MLflow*。
- en: Introduction to MLflow
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLflow介绍
- en: In traditional software development, life cycle code is written to a given functional
    specification. However, in ML, the goal is to optimize a specific metric until
    you have achieved a desired level of accuracy. This process of optimizing a certain
    metric doesn't happen just once; it is a continuous process of experimentation
    and improvement. Moreover, in ML, the quality of the outcome not just depends
    on the quality of the code but also on other parameters, such as the data that's
    used for the ML training process and the parameters that are supplied to the training
    algorithm. The programming stack that's used by traditional ML also varies widely
    between different data scientists. Finally, ML models created in one environment
    are typically deployed in a different environment, so it is also important to
    ensure model portability and reproducibility. Thus, the entire ML life cycle is
    very iterative and involves multiple parameters, datasets, and various programming
    libraries.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统软件开发中，生命周期代码是按照给定的功能规格编写的。然而，在机器学习中，目标是优化特定的指标，直到达到所需的准确度。优化某一特定指标的过程不是一次性的，而是一个持续的实验和改进过程。此外，在机器学习中，结果的质量不仅仅依赖于代码的质量，还与其他参数有关，比如用于机器学习训练过程的数据以及提供给训练算法的参数。传统机器学习使用的编程堆栈在不同的数据科学家之间差异很大。最后，在一个环境中创建的机器学习模型通常会被部署到不同的环境中，因此确保模型的可移植性和可复现性也非常重要。因此，整个机器学习生命周期是非常迭代的，涉及多个参数、数据集和各种编程库。
- en: 'MLflow is an easy-to-use, modular, end-to-end ML life cycle management open
    source software, developed to solve the aforementioned challenges of the ML life
    cycle:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 是一款易于使用、模块化的端到端机器学习生命周期管理开源软件，旨在解决上述机器学习生命周期中的挑战：
- en: '![Figure 9.2 – ML life cycle with Mlflow'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.2 – 使用 MLflow 的机器学习生命周期'
- en: '](img/B16736_09_02.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16736_09_02.jpg)'
- en: Figure 9.2 – ML life cycle with Mlflow
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – 使用 MLflow 的机器学习生命周期
- en: 'MLflow consists of the following four components to solve the challenges of
    the ML life cycle, such as management experiment tracking, experiment reproducibility,
    model repositories, and model deployment:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 包含以下四个组件，用于解决机器学习生命周期中的挑战，如实验跟踪管理、实验可复现性、模型库和模型部署：
- en: MLflow Tracking
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow 跟踪
- en: MLflow Projects
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow 项目
- en: MLflow Model
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow 模型
- en: Model Registry
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型注册表
- en: Each of these components will be explored further in the following sections.
    You will learn how these components help solve your ML life cycle management challenges
    while looking at some code samples.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的章节将进一步探讨这些组件。你将学习这些组件如何帮助解决机器学习生命周期管理中的挑战，并查看一些代码示例。
- en: Tracking experiments with MLflow
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MLflow 跟踪实验
- en: In real life, building a single model is never sufficient. A typical model-building
    process requires iterating over the process several times, sometimes changing
    the model parameters and other times tweaking the training dataset, until the
    desired level of model accuracy is achieved. Sometimes, a model that's suitable
    for a certain use case might not be useful for another. This means that a typical
    data science process involves experimenting with several models to solve a single
    business problem and keeping track of all the datasets, model parameters, and
    model metrics for future reference. Traditionally, experiment tracking is done
    using rudimentary tools such as spreadsheets, but this slows down the time to
    production and is also a tedious process that's prone to mistakes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实中，构建单一模型是远远不够的。一个典型的模型构建过程需要多次迭代，有时需要改变模型参数，有时需要调整训练数据集，直到达到理想的模型准确度。有时，适合某个特定用例的模型在另一个场景中可能并不适用。这意味着一个典型的数据科学过程涉及对多个模型进行实验，以解决单一的业务问题，并记录所有数据集、模型参数和模型指标，以供未来参考。传统上，实验跟踪是通过使用简单的工具，如电子表格来完成的，但这会拖慢生产速度，而且是一个繁琐的过程，容易出错。
- en: 'The MLflow Tracking component solves this problem with its API and UI for logging
    ML experiments, including model parameters, model code, metrics, the output of
    the model training process, as well as any arbitrary artifacts associated with
    the experiment. Let''s learn how to install MLflow and track our experiments using
    the tracking server:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 跟踪组件通过其 API 和 UI 来解决这个问题，用于记录机器学习实验，包括模型参数、模型代码、指标、模型训练过程的输出，以及与实验相关的任何任意文档。让我们学习如何安装
    MLflow 并使用跟踪服务器跟踪实验：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The previous command will install MLflow in your Databricks notebook and restart
    the Python session.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将在你的 Databricks 笔记本中安装 MLflow 并重启 Python 会话。
- en: Note
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The previous command only installs the MLflow client libraries in your local
    Python session in your notebook. We will be using the managed MLflow that comes
    with Databricks Community Edition for the tracking server component. Instructions
    for configuring and running an MLflow Tracking server outside of Databricks can
    be found here: [https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded](https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令只会在您的本地Python会话中安装MLflow客户端库。我们将使用Databricks社区版提供的托管MLflow作为跟踪服务器组件。有关在Databricks之外配置和运行MLflow
    Tracking服务器的说明可以在这里找到：[https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded](https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded)。
- en: 'In the following code sample, we are building a simple regression model that
    we used in the previous chapters and use MLflow Tracking to track the experiment:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码示例中，我们正在构建一个简单的回归模型，该模型在之前的章节中使用过，并使用MLflow Tracking来跟踪实验：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the previous code example, we performed the following actions:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码示例中，我们执行了以下操作：
- en: First, we imported the relevant libraries. Here, we imported various MLflow
    client libraries and also imported the Spark-specific MLflow components via `mlflow.spark`.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们导入相关的库。在这里，我们导入了各种MLflow客户端库，还通过`mlflow.spark`导入了特定于Spark的MLflow组件。
- en: In this code sample, we built multiple regression models using the `pyspark.ml`
    libraries to perform these actions to measure the accuracy of our models.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个代码示例中，我们使用`pyspark.ml`库构建了多个回归模型来执行这些操作以衡量我们模型的准确性。
- en: 'Now, we need to initialize MLflow Tracking so that we can start tracking our
    experiments, as shown in the following code block:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要初始化MLflow Tracking，以便开始跟踪我们的实验，如下面的代码块所示：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we must initialize the training dataset, as shown in the following code
    block:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们必须初始化训练数据集，如下面的代码块所示：
- en: First, create a `retail_features` DataFrame out of the features Delta table
    that we created in the previous chapters. We must select the label and feature
    columns that are required for our model training from the DataFrame, which contains
    all the features that we extracted from the enriched retail transactional data.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，从我们在之前章节中创建的特征Delta表中创建一个`retail_features` DataFrame。我们必须从包含我们从丰富的零售交易数据中提取的所有特征的DataFrame中选择用于模型训练的标签和特征列。
- en: Now, we must randomly split the DataFrame containing the label and the feature
    columns into two separate DataFrames using the `randomSplit()` function. The training
    DataFrame is used for model training purposes, while the test DataFrame is preserved
    to check the accuracy of the model once a model has been trained.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，我们必须使用`randomSplit()`函数将包含标签和特征列的DataFrame随机拆分为两个单独的DataFrame。训练DataFrame用于模型训练目的，而测试DataFrame则保留用于在训练模型后检查模型准确性。
- en: 'At this point, we can get started with the experimentation process, as shown
    in the following code block:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以开始实验过程，如下面的代码块所示：
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the previous code block, we set our initial algorithm parameters and the
    MLflow Tracking server parameters:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们设置了我们的初始算法参数和MLflow Tracking服务器参数：
- en: We instantiated the `RegressionEvaluator` object, which passes the label column
    and uses RMSE as the accuracy metric. This is useful in calculating `rmse` on
    the label column during the cross-validation process.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们实例化了`RegressionEvaluator`对象，该对象传递标签列并使用RMSE作为准确性指标。这在交叉验证过程中计算标签列上的`rmse`时非常有用。
- en: Now that we are ready to start our experimentation, we configured our experiment
    with the MLflow Tracking server by providing the URI for the tracking server using
    the `mlflow.set_tracking_uri("databricks")` function.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在我们准备开始我们的实验，通过使用`mlflow.set_tracking_uri("databricks")`函数为MLflow Tracking服务器配置我们的实验。
- en: The MLflow Tracking server can track multiple experiments from multiple users
    from multiple sessions. Thus, you must provide your experiment with a unique name,
    which we can achieve using `mlflow.set_experiment("/Users/user_name/exp_name")`.
    The path specified for the experiment name needs to be a form of persistent storage,
    such as a local disk or a data lake location. In this case, we made use of the
    **Databricks filesystem** (**DBFS**).
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow Tracking服务器可以跟踪来自多个用户、多个会话的多个实验。因此，您必须为您的实验提供一个唯一的名称，我们可以使用`mlflow.set_experiment("/Users/user_name/exp_name")`来实现。指定给实验名称的路径需要是一种持久存储形式，比如本地磁盘或数据湖位置。在这种情况下，我们使用了**Databricks文件系统**（**DBFS**）。
- en: 'In the previous code block, we specified the URI as `databricks` because we
    intend to use the MLflow Tracking server that comes with Databricks Community
    Edition. You can specify the URI as `./mlruns` if you are running MLflow locally
    or provide the URI for your remote tracking server if you have set one up yourself.
    Instructions on how to set up your own tracking server can be found at [https://mlflow.org/docs/latest/tracking.html#mlflow-tracking-servers](https://mlflow.org/docs/latest/tracking.html#mlflow-tracking-servers):'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码块中，我们将URI指定为`databricks`，因为我们打算使用Databricks社区版自带的MLflow Tracking服务器。如果你在本地运行MLflow，可以将URI指定为`./mlruns`，或者如果你自己设置了远程跟踪服务器，可以提供远程服务器的URI。如何设置自己的跟踪服务器的说明请参见[https://mlflow.org/docs/latest/tracking.html#mlflow-tracking-servers](https://mlflow.org/docs/latest/tracking.html#mlflow-tracking-servers)：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now that we have initialized all the required objects for experimentation and
    configured experiment tracking with MLflow, we can start the training process:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经初始化了所有实验所需的对象，并通过MLflow配置了实验跟踪，我们可以开始训练过程：
- en: First, we must instantiate the `LinearRegression` model object with the `maxIter`
    parameter set to `10`.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们必须实例化`LinearRegression`模型对象，并将`maxIter`参数设置为`10`。
- en: Then, we must set up a parameter grid for the cross-validation process and specify
    a range of values for model parameters.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们必须为交叉验证过程设置参数网格，并为模型参数指定一系列值。
- en: Finally, we must configure the train-validation split process by initializing
    the `CrossValidator` object. We can do this by passing in the actual model object,
    the parameter grid object, and the evaluation objects as parameters.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们必须通过初始化`CrossValidator`对象来配置训练-验证拆分过程。我们可以通过将实际模型对象、参数网格对象和评估对象作为参数传递来完成此操作。
- en: 'More details on how the `CrossValidator` objects works will be provided in
    the following section. Now, we are ready to start the model training experimentation
    process, as shown in the following code block:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`CrossValidator`对象如何工作的更多细节将在接下来的章节中提供。现在，我们准备好开始模型训练实验过程，如下方代码块所示：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the previous code example, we invoked the MLflow Tracking server to start
    tracking our experiments:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码示例中，我们调用了MLflow Tracking服务器以开始跟踪我们的实验：
- en: Since we are using the cross-validation technique and have defined a parameter
    grid with a range of values, the `fit()` process builds multiple models instead
    of a single model and records the best model based on the specified accuracy metric.
    Since we would like to keep a record of all the models we've built in this process,
    we must invoke the MLflow Tracking service using the `mlflow.start_run()` method.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于我们使用的是交叉验证技术，并且已经定义了一个带有值范围的参数网格，`fit()`过程将构建多个模型，而不是单一模型，并根据指定的准确度指标记录最佳模型。由于我们希望记录在此过程中构建的所有模型，因此我们必须使用`mlflow.start_run()`方法调用MLflow
    Tracking服务。
- en: The metrics that were generated during the cross-validation process are logged
    to the MLflow Tracking server using the `mlflow.log_metric()` function. Within
    the Databricks managed MLflow environment, the model parameters are automatically
    logged when `CrossValidator` is used. However, model parameters can also be explicitly
    logged using the `mlflow.log_parameter()` function and any arbitrary artifacts
    such as graphs or charts can be logged using the `mlflow.log_artifact()` function.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在交叉验证过程中生成的度量值将使用`mlflow.log_metric()`函数记录到MLflow Tracking服务器。在Databricks管理的MLflow环境中，使用`CrossValidator`时，模型参数会自动记录。然而，也可以使用`mlflow.log_parameter()`函数显式记录模型参数，并且任何任意的工件，如图表或图像，可以使用`mlflow.log_artifact()`函数记录。
- en: '`CrossValidator` iterates over multiple models and generates the best model
    based on the specified accuracy metric. The best model that''s generated during
    this process is available as a `bestModel` object. This can be logged using the
    `mlflow.spark.log_model(spark_model=lr_model.bestModel, artifact_path=''best-model'')`
    command. Here, `artifact_path` denotes the path where the model is stored in the
    MLflow Tracking server.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CrossValidator`会遍历多个模型，并根据指定的准确度指标生成最佳模型。在此过程中生成的最佳模型作为`bestModel`对象可用。可以使用`mlflow.spark.log_model(spark_model=lr_model.bestModel,
    artifact_path=''best-model'')`命令记录该模型。这里，`artifact_path`表示模型在MLflow Tracking服务器中存储的路径。'
- en: 'The following screenshot shows the MLflow Tracking UI for the ML experiment
    that we just executed:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了我们刚刚执行的ML实验的MLflow Tracking界面：
- en: '![Figure 9.3 – MLflow Model tracking UI'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.3 – MLflow模型跟踪界面'
- en: '](img/B16736_09_03.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16736_09_03.jpg)'
- en: Figure 9.3 – MLflow Model tracking UI
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 – MLflow模型跟踪界面
- en: 'In the preceding screenshot, we can see that MLflow recorded the accuracy metrics
    and model parameters for each of the models we built during the **cross-validation**
    process as a single experiment. However, only the best model out of all the runs
    was recorded. Details of an individual run can be accessed by clicking on one
    of the runs, as shown in the following screenshot:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，我们可以看到，MLflow 记录了我们在 **交叉验证** 过程中为每个模型构建的准确度指标和模型参数，作为一个单独的实验。然而，只有所有运行中表现最好的模型被记录下来。可以通过点击其中一项运行来访问单个运行的详细信息，如以下截图所示：
- en: '![Figure 9.4 – Individual models being run from the MLflow Tracking UI'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.4 – 从 MLflow Tracking UI 运行的各个模型'
- en: '](img/B16736_09_4.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16736_09_4.jpg)'
- en: Figure 9.4 – Individual models being run from the MLflow Tracking UI
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 – 从 MLflow Tracking UI 运行的各个模型
- en: In the preceding screenshot, all the model parameters and metrics have been
    recorded in the MLflow Tracking UI, along with other metadata such as the model's
    run date and time, username, the source code version for this specific model run,
    the duration of the model's run, and the status of the model. This information
    is very useful in reproducing the experiment in the future or reproducing the
    same experiment in a different environment, so long as the same version of the
    data is available.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，所有的模型参数和指标都已记录在 MLflow Tracking UI 中，并附带其他元数据，如模型的运行日期和时间、用户名、此特定模型运行的源代码版本、模型运行的持续时间以及模型的状态。只要数据的相同版本可用，这些信息在未来重现实验或在不同环境中重现相同实验时非常有用。
- en: Tip
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: MLflow Tracking can also be used to track the version of the data that's being
    used for the experiment if the data is stored in a Delta table, as Delta provides
    built-in data versioning. This can be done by logging the Delta table's version
    as an arbitrary artifact to MLflow.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据存储在 Delta 表中，可以使用 MLflow Tracking 跟踪实验中使用的数据版本，因为 Delta 提供了内置的数据版本控制。可以通过将
    Delta 表的版本作为任意工件记录到 MLflow 来实现这一点。
- en: The `mlflow.` command in the previous code snippet specifies that we are using
    a Spark flavor of the MLflow Model. MLflow supports other flavors of models, as
    described in the following section.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`mlflow.` 命令在前面的代码片段中指定了我们使用的是 MLflow 模型的 Spark 版本。MLflow 支持其他类型的模型，如以下章节所述。'
- en: MLflow Model
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MLflow 模型
- en: 'MLflow Model is a general-purpose, portable model format that supports a variety
    of model flavors, ranging from simple Python pickle objects to scikit-learn, TensorFlow,
    PyTorch, MLeap, and other model formats, including Spark models in Parquet format.
    MLflow Models present abstractions that can be produced using a variety of common
    ML tools and then deployed to a variety of ML environments. MLflow Model provides
    models from popular ML frameworks in MLflow format. An MLflow Model has a standard
    directory structure that contains configuration files and a serialized model artifact.
    It also contains all the model evaluation dependencies for model portability and
    reproducibility in the form of a `conda` environment via the `conda.yaml` file:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 模型是一种通用的、可移植的模型格式，支持多种模型类型，从简单的 Python pickle 对象到 scikit-learn、TensorFlow、PyTorch、MLeap
    和其他模型格式，包括 Parquet 格式的 Spark 模型。MLflow 模型提供了可以使用各种常见机器学习工具生成的抽象模型，并可部署到各种机器学习环境中。MLflow
    模型以 MLflow 格式提供来自流行机器学习框架的模型。MLflow 模型具有标准的目录结构，其中包含配置文件和序列化的模型工件。它还包含所有模型评估依赖项，以
    `conda` 环境的形式通过 `conda.yaml` 文件提供模型的可移植性和可重现性。
- en: '![Figure 9.5 – MLflow Model'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.5 – MLflow 模型'
- en: '](img/B16736_09_5.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16736_09_5.jpg)'
- en: Figure 9.5 – MLflow Model
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 – MLflow 模型
- en: The preceding screenshot shows the structure of a typical MLflow Model. This
    standard model format creates a model flavor that can be understood by any downstream
    tool. Model flavors are used for deployment purposes to help us understand the
    models from any ML library, without having to integrate each tool with each library.
    MLflow supports many of the prominent model flavors that all its built-in deployment
    tools support, such as a simple Python function flavor that describes how to run
    the model as a Python function. For instance, in the previous code example, we
    stored our model as a Spark model, which can then be loaded as a **Spark** object
    or as a simple Python function that can be used in any Python application, even
    those that may not understand Spark at all.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图展示了一个典型的 MLflow 模型结构。这个标准模型格式创建了一个可以被任何下游工具理解的模型风味。模型风味用于部署目的，帮助我们理解来自任何机器学习库的模型，而无需将每个工具与每个库集成。MLflow
    支持许多它内建的部署工具支持的主要模型风味，例如描述如何将模型作为 Python 函数运行的简单 Python 函数风味。例如，在前面的代码示例中，我们将模型存储为一个
    Spark 模型，然后可以将其加载为 **Spark** 对象，或者作为一个简单的 Python 函数，在任何 Python 应用程序中使用，即使这些应用程序根本不理解
    Spark。
- en: ML model tuning
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML 模型调优
- en: Model tuning is an important aspect of the model building process, where the
    best model parameters are identified programmatically to achieve optimal model
    performance. This process of model selection by iteratively varying the model
    parameters is called *hyperparameter tuning*. A typical hyperparameter tuning
    process involves splitting the available data into multiple training and test
    datasets. Then, for each training dataset, a test pair iterates through a set
    of model parameters, called the parameter grid, and selects the model that yields
    the best performance among all the models that have been trained.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 模型调优是模型构建过程中一个重要的环节，通过编程识别最佳模型参数，以实现最佳模型性能。通过反复调整模型参数来选择模型的过程称为 *超参数调优*。典型的超参数调优过程包括将可用数据分割成多个训练集和测试集。然后，对于每个训练数据集，一个测试对会遍历一组模型参数，称为参数网格，并从所有训练过的模型中选择性能最佳的模型。
- en: Spark ML provides a `ParamGridbuilder` utility to help build the parameter grid,
    as well as the `CrossValidator` and `TrainValidationSplit` classes to handle model
    selection. `CrossValidator` performs model selection by splitting the dataset
    into a set of folds that are used as separate training and test dataset pairs,
    and each fold is used as the test set exactly once. The use of model tuning and
    selection using `ParamGridBuilder` and `CrossValidator` was presented in the code
    sample presented in the previous section. `TrainValidationSplit` is another popular
    technique for model selection that uses hyperparameter tuning. Details on its
    implementation in Apache Spark can be found on Spark's documentation page at [https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split](https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML 提供了一个 `ParamGridBuilder` 工具来帮助构建参数网格，以及 `CrossValidator` 和 `TrainValidationSplit`
    类来处理模型选择。`CrossValidator` 通过将数据集分割成一组折叠，将这些折叠作为独立的训练集和测试集对进行模型选择，每个折叠仅使用一次作为测试集。使用
    `ParamGridBuilder` 和 `CrossValidator` 进行模型调优和选择的示例已在前一节的代码示例中展示。`TrainValidationSplit`
    是另一种流行的超参数调优技术。有关其在 Apache Spark 中的实现细节，可以参阅 Spark 的文档页面 [https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split](https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split)。
- en: Now that we have learned how to perform model selection tuning using Apache
    Spark and how to track experiments using MLflow, the next step in ML life cycle
    management is storing the models and their versions in a central model repository
    for use later. We will explore this in the following section using **MLflow Model
    Registry**.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经学习了如何使用 Apache Spark 进行模型选择调优，以及如何使用 MLflow 跟踪实验，机器学习生命周期管理的下一步是将模型及其版本存储在中央模型仓库中，以便后续使用。在接下来的章节中，我们将使用
    **MLflow 模型注册表** 探索这一过程。
- en: Tracking model versions using MLflow Model Registry
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MLflow 模型注册表跟踪模型版本
- en: While the MLflow Tracking server lets you track all the attributes of your ML
    experiments, MLflow Model Registry provides a central model repository that lets
    you track all the aspects of your model life cycle. MLflow Model Registry consists
    of a user interface and APIs to track the model's version, lineage, stage transitions,
    annotations, and any developer comments. MLflow Model Registry also contains webhooks
    for CI/CD integrations and a model server for online model serving.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 MLflow 跟踪服务器可以让您跟踪所有机器学习实验的属性，MLflow 模型注册中心提供了一个集中式的模型存储库，让您跟踪模型生命周期的各个方面。MLflow
    模型注册中心包括一个用户界面和 API，用于跟踪模型的版本、血统、阶段过渡、注释以及任何开发者评论。MLflow 模型注册中心还包含用于 CI/CD 集成的
    Webhooks 和用于在线模型服务的模型服务器。
- en: MLflow Model Registry provides us with a way to track and organize the many
    ML models that are produced and used by businesses during development, testing,
    and production. Model Registry provides a secure way to share models by leveraging
    access control lists and provides a way to integrate with model governance and
    approval workflows. Model Registry also allows us to monitor ML deployments and
    their performance via its API.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 模型注册中心为我们提供了一种跟踪和组织在开发、测试和生产过程中由企业生成和使用的众多机器学习模型的方法。模型注册中心通过利用访问控制列表提供了一种安全的共享模型方式，并提供与模型治理和审批工作流集成的方法。模型注册中心还允许我们通过其
    API 监控 ML 部署及其性能。
- en: Tip
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Model Registry's access controls and the ability to set permissions on registered
    models are only available in the full version of Databricks. They are not available
    in the Community Edition of Databricks or the open source version of MLflow.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 模型注册中心的访问控制和设置已注册模型权限的功能仅在 Databricks 完整版中可用。它们在 Databricks 社区版或开源版本的 MLflow
    中不可用。
- en: 'Once a model has been logged to the Model Registry, you can add, modify, update,
    transition, or delete the model through the UI or the API, as shown in the following
    code sample:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型被记录到模型注册中心，您可以通过 UI 或 API 添加、修改、更新、过渡或删除模型，如下列代码示例所示：
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the previous code snippet, we did the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码片段中，我们执行了以下操作：
- en: First, we imported the relevant MLflow libraries and `MlflowClient`, an MLflow
    interface for accessing the MLflow Tracking server and Model Registry artifacts
    via Python. The client interface is invoked using the `MlflowClient()` method.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入了相关的 MLflow 库和 `MlflowClient`，它是一个通过 Python 访问 MLflow 跟踪服务器和模型注册中心工件的
    MLflow 接口。客户端接口通过 `MlflowClient()` 方法调用。
- en: Then, we constructed `model_uri` by providing the model, name, the model artifact
    location, and the `run_id` property from a tracked experiment. This information
    can be accessed via the MLflow Tracking server, either via the API or the UI.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们通过提供模型、名称、模型工件位置和来自已跟踪实验的 `run_id` 属性来构建 `model_uri`。这些信息可以通过 MLflow 跟踪服务器访问，无论是通过
    API 还是 UI。
- en: Since we had reconstructed the model URI from the tracking server, we registered
    the model to the Model Registry using the `register_model()` function. If the
    model doesn't already exist in the Model Registry, a new model with a version
    of **1** is registered instead.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们已经从跟踪服务器重建了模型 URI，我们通过 `register_model()` 函数将模型注册到模型注册中心。如果该模型尚未存在于模型注册中心，则会注册一个版本为**1**的新模型。
- en: Once the model was registered, we had the opportunity to add or update the model
    description using the `update_model_version()` method.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型注册完成，我们就可以通过 `update_model_version()` 方法添加或更新模型描述。
- en: During the life cycle of a model, it often evolves and needs to transition its
    stage, say from staging to production or the archival stage. This can be accomplished
    using the `transition_model_version_stage()` method.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模型的生命周期中，它通常会不断演变，并需要过渡其阶段，比如从暂存阶段到生产阶段或归档阶段。可以使用 `transition_model_version_stage()`
    方法来实现这一点。
- en: A registered model's version and stage can be listed using the `get_model_version()`
    method.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用 `get_model_version()` 方法列出已注册模型的版本和阶段。
- en: Finally, we loaded a specific version/stage of the model from the Model Registry
    using the `load_model()` method after constructing the model URI using the `models`
    keyword, the model's name, and its version or stage name.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用 `load_model()` 方法从模型注册中心加载特定版本/阶段的模型，在构建模型 URI 时使用了 `models` 关键字、模型名称及其版本或阶段名称。
- en: Model Registry also provides other handy functions for listing and searching
    through various versions of an individual registered model, as well as archiving
    and deleting registered models. References for those methods can be found at [https://www.mlflow.org/docs/latest/model-registry.html#model-registry-workflows](https://www.mlflow.org/docs/latest/model-registry.html#model-registry-workflows).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 模型注册表还提供了其他实用功能，用于列出和搜索个别已注册模型的不同版本，以及存档和删除已注册的模型。相关方法的参考资料可以在 [https://www.mlflow.org/docs/latest/model-registry.html#model-registry-workflows](https://www.mlflow.org/docs/latest/model-registry.html#model-registry-workflows)
    中找到。
- en: Important Note
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'Databricks Community Edition, which we will be using throughout this book,
    does not include Model Registry, so you will have to use the full version of Databricks
    to execute the preceding code sample. Alternatively, you can deploy your own MLflow
    Remote Tracking Server, along with a database-backed backend store outside of
    the Databricks environment, as described here: [https://mlflow.org/docs/latest/tracking.html#mlflow-tracking-servers](https://mlflow.org/docs/latest/tracking.html#mlflow-tracking-servers).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书中使用的 Databricks Community Edition 并不包含模型注册表，因此你需要使用 Databricks 的完整版来执行前面的代码示例。或者，你可以部署自己的
    MLflow 远程跟踪服务器，并在 Databricks 环境之外使用数据库支持的后端存储，具体方法可以参见：[https://mlflow.org/docs/latest/tracking.html#mlflow-tracking-servers](https://mlflow.org/docs/latest/tracking.html#mlflow-tracking-servers)。
- en: Now that you have learned how to store, version, and retrieve models using MLflow
    Model Registry, the next step of the ML life cycle is putting the trained, evaluated,
    and tuned models to practical use by leveraging them in business applications
    to draw inferences. We will discuss this in the next section.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何使用 MLflow 模型注册表存储、版本管理和检索模型，机器学习生命周期的下一步是将训练、评估和调优后的模型应用到实际业务中，通过它们来进行推理。我们将在下一节中讨论这一内容。
- en: Model serving and inferencing
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型服务与推理
- en: 'Model serving and inferencing is the most important step of the entire ML life
    cycle. This is where the models that have been build are deployed to business
    applications so that we can draw inferences from them. Model serving and inferencing
    can happen in two ways: using batch processing in offline mode or in real time
    in online mode.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 模型服务与推理是整个机器学习生命周期中最重要的步骤。这是将已构建的模型部署到业务应用程序中的阶段，以便我们能够从中得出推理。模型服务与推理可以通过两种方式进行：在离线模式下使用批处理，或者在在线模式下实时推理。
- en: Offline model inferencing
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 离线模型推理
- en: Offline model inferencing is the process of generating predictions from a ML
    model using batch processing. The batch processing inference jobs run periodically
    on a recurring schedule, producing predictions on a new set of fresh data every
    time. These predictions are then stored in a database or on the data lake and
    are consumed by business applications in an offline or asynchronous way. An example
    of batch inferencing would be data-driven customer segmentation being used by
    the marketing teams at an organization or a retailer predicting customer lifetime
    value. These use cases do not demand real-time predictions; batch inferencing
    can serve the purpose here.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 离线模型推理是指使用批处理生成来自机器学习模型的预测。批处理推理作业按预定时间表定期运行，每次都在一组新的数据上生成预测。这些预测会存储在数据库中或数据湖中，并以离线或异步的方式供业务应用程序使用。批处理推理的一个例子是由营销团队使用的数据驱动客户细分，或者零售商预测客户的生命周期价值。这些用例并不需要实时预测，批处理推理可以满足需求。
- en: 'In the case of Apache Spark, batch inferencing can take advantage of Spark''s
    scalability to produce predictions at scale on very large datasets, as demonstrated
    in the following code sample:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Apache Spark，批处理推理可以利用 Spark 的可扩展性，在非常大的数据集上大规模地进行预测，以下代码示例演示了这一点：
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the previous code block, we recreated the model URI using the model's name
    and the artifact location from the tracking server. Then, we created a Spark **user-defined
    function** (**UDF**) using the MLflow Python function model flavor from the Spark
    model stored on the tracking server. This Spark UDF can be used with a Spark DataFrame
    to produce inferences in a batch manner at scale. This piece of code can be scheduled
    as a job that runs periodically, and the predictions can be saved to a location
    on the data lake.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码块中，我们使用模型的名称和跟踪服务器中的工件位置重新创建了模型的 URI。然后，我们使用来自跟踪服务器中 Spark 模型的 MLflow
    Python 函数模型风格创建了一个 Spark **用户定义函数**（**UDF**）。这个 Spark UDF 可以与 Spark DataFrame
    一起使用，以批量方式进行大规模推理。这个代码片段可以作为定时任务定期执行，预测结果可以保存到数据湖中的某个位置。
- en: The Apache Spark framework can help us implement the complete ML life cycle,
    from model training to model inferencing, using a single, unified data processing
    framework. Spark can also be used to extend batch inferencing to near-real-time
    inferencing using Spark Structured Streaming. However, when it comes to ultra-low
    latency real-time model serving, Apache Spark is not suitable. We will explore
    this further in the next section.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 框架可以帮助我们实现完整的机器学习生命周期，从模型训练到模型推理，使用一个统一的数据处理框架。Spark 还可以通过 Spark
    Structured Streaming 将批量推理扩展到接近实时的推理。然而，在超低延迟实时模型服务方面，Apache Spark 并不适用。我们将在下一节进一步探讨这个问题。
- en: Online model inferencing
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线模型推理
- en: Online inference is the process of generating ML predictions in real time, either
    by embedding the inference code in the business application itself or by using
    ultra-low latency APIs. Unlike batch inferences, which are generated in bulk on
    a large dataset, real-time online inferences are typically generated on one observation
    at a time. Online inferencing can help with a new and novel application of ML
    by generating predictions in milliseconds to seconds instead of hours to days.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在线推理是指在实时生成机器学习预测的过程，可以通过将推理代码嵌入到业务应用程序中，或者使用超低延迟的 API 来实现。与批量推理不同，后者是在大数据集上批量生成的，实时在线推理通常是针对每次一个观察生成的。在线推理可以通过在毫秒到秒之间生成预测，而不是小时到天，帮助机器学习的全新应用。
- en: 'Consider the example of a mobile gaming application, where you want to show
    personalized promotions to a gamer based on their level or the type of game they
    are playing. Online inferencing can quickly collect user behavior data from the
    mobile app and either generate a predictive recommendation within the app itself
    or by using a low latency API server. This can, for example, help businesses generate
    personalized experiences in real time for their customers. While Apache Spark
    itself is not suitable for online inferencing, MLflow Model Registry includes
    a model serving component that can be activated using the following command:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个移动游戏应用为例，假设你想根据玩家的等级或他们所玩的游戏类型向他们展示个性化的促销。在线推理可以迅速从移动应用收集用户行为数据，并在应用内或通过低延迟
    API 服务器生成预测推荐。例如，这可以帮助企业为客户实时生成个性化的体验。尽管 Apache Spark 本身不适合在线推理，MLflow 模型注册中心包含一个可以激活的模型服务组件，使用以下命令进行启动：
- en: '[PRE8]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In the previous command, we invoked MLflow's built-in model server to serve
    the model that we previously registered with Model Registry. This model server
    makes a RESTful API available for external applications to communicate via HTTP
    with the model server, sends in a single observation called the payload, and receives
    a single prediction at a time.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的命令中，我们调用了 MLflow 内置的模型服务来为我们之前在模型注册中心注册的模型提供服务。这个模型服务提供了一个 RESTful API，外部应用程序可以通过
    HTTP 与模型服务进行通信，发送一个称为负载的单一观察，并一次性接收一个预测结果。
- en: Note
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: MLflow's model serving capabilities are not available in Databricks Community
    Edition, so the previous command will not execute if you are using that version.
    This feature can be used either in open source MLflow or Databrick's full version.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 的模型服务功能在 Databricks Community Edition 中不可用，因此如果你使用的是该版本，之前的命令将无法执行。此功能可以在开源的
    MLflow 或 Databricks 的完整版本中使用。
- en: MLflow's model serving feature is still in preview at the time of writing and
    has some limitations, such as a target throughput of 20 queries per second and
    a payload size limitation of 16 MB per request. Thus, this option is only recommended
    for low throughput, non-production applications. MLflow does offer integrations
    with other model serving platforms, however, such as **AWS Sagemaker**, **Azure
    ML**, and **Google Cloud AI**. Details of these integrations can be found in the
    respective cloud provider's documentation.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，MLflow的模型服务功能仍处于预览阶段，并且存在一些限制，如目标吞吐量为每秒20个查询，以及每次请求的有效载荷大小限制为16MB。因此，这个选项仅建议用于低吞吐量、非生产环境的应用。不过，MLflow确实提供与其他模型服务平台的集成，例如**AWS
    Sagemaker**、**Azure ML**和**Google Cloud AI**。有关这些集成的详细信息，请参阅各自云服务提供商的文档。
- en: Continuous delivery for ML
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的持续交付
- en: ML code, unlike traditional software code, is dynamic and is constantly affected
    by changes to the model code itself, the underlying training data, or the model
    parameters. Thus, ML model performance needs to be continuously monitored, and
    models need to be retrained and redeployed periodically to maintain the desired
    level of model performance. This process can be daunting and time-consuming and
    prone to mistakes when performed manually. However **Continuous Delivery for ML**
    (**CD4ML**) can help streamline and automate this process.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统软件代码不同，ML代码是动态的，并且不断受到模型代码本身、底层训练数据或模型参数变化的影响。因此，ML模型的性能需要持续监控，且模型需要定期重新训练和重新部署，以保持所期望的模型性能水平。这个过程如果手动进行，可能会很费时且容易出错。但**机器学习的持续交付**（**CD4ML**）可以帮助简化并自动化这个过程。
- en: CD4ML is derived from the software engineering principles of **continuous integration**
    and **continuous delivery** (**CI/CD**), which were developed to promote automation,
    quality, and discipline and help create a reliable and repeatable process that
    can release software into production. CD4ML builds on and adapts this CI/CD process
    to ML, where data teams produce artifacts related to the ML process, such as code
    data and models, in safe and small increments that can be reproduced and released
    reliably at any time.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: CD4ML来源于**持续集成**和**持续交付**（**CI/CD**）的 软件工程原则，这些原则旨在推动自动化、质量和纪律，帮助创建一个可靠且可重复的流程，使得软件能够顺利地投入生产。CD4ML在此基础上对CI/CD流程进行了扩展和调整，应用于机器学习（ML）领域，其中数据团队生成与ML过程相关的工件，如代码数据和模型，并以安全和小步长的方式逐步推进，这些工件可以在任何时候可靠地重复和发布。
- en: 'The CD4ML process involves a data scientist building a model and its parameters,
    source code, and the training data required. The next step is model evaluation
    and tuning. After an acceptable level of model accuracy has been achieved, the
    model needs to be productionized, and testing must be performed on the model.
    The final step is deploying and monitoring the model. If the model needs to be
    adjusted, the CD4ML pipeline should trigger the ML process so that it starts from
    the beginning. This ensures the continuous delivery occurs and that the latest
    code changes and models are pushed to the production environment. MLflow provides
    most of the components that are required to implement this CD4ML process, as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: CD4ML流程包括数据科学家构建模型及其参数、源代码和所需的训练数据。下一步是模型评估和调优。达到可接受的模型精度后，模型需要进行生产化，并对其进行测试。最后一步是部署和监控模型。如果模型需要调整，CD4ML管道应该触发ML过程，从头开始重新进行。这确保了持续交付的实现，并将最新的代码变更和模型推送到生产环境。MLflow提供了大部分实施此CD4ML过程所需的组件，如下所示：
- en: Firstly, the MLflow Tracking server can help you track the model training process,
    including all the training artifacts, along with the data version and the models
    that have been versioned and marked for testing or production using Model Registry.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，MLflow Tracking服务器可以帮助你跟踪模型训练过程，包括所有训练工件、数据版本以及已被版本控制并标记为测试或生产使用的模型，通过模型注册表进行管理。
- en: Then, the registered models can be annotated with custom tags, which helps encode
    a variety of information. This includes indicating the deployment mode of the
    model, whether it be batch or online mode, or the region where the model was deployed.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，已注册的模型可以用自定义标签进行注释，帮助编码多种信息。这包括指示模型的部署方式，无论是批处理模式还是在线模式，或是模型部署所在的区域。
- en: Comments can be added to models to specify test failures, model inaccuracies,
    or production deployment failure notes by data scientists, test engineers, and
    ML engineers to aid discussion between cross-functional teams.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家、测试工程师和 ML 工程师可以在模型中添加评论，指定测试失败、模型不准确或生产部署失败的备注，以帮助跨职能团队之间的讨论。
- en: Notifications can be pushed via webhooks within Model Registry to help invoke
    various actions and automated tests via external CI/CD tools. Actions can be triggered
    for events such as model creation, version change, adding new comments, and more.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以通过模型注册中的 Webhook 推送通知，帮助通过外部 CI/CD 工具触发各种操作和自动化测试。例如，模型创建、版本更改、添加新评论等事件都可以触发相应的操作。
- en: Finally, MLflow Projects helps package the entire model development workflow
    into a reusable, parameterized module.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，MLflow Projects 有助于将整个模型开发工作流打包成一个可重用、可参数化的模块。
- en: This way, by leveraging MLflow components such as the MLflow Tracking server,
    Model Registry, MLflow Projects, and its webhooks functionality, combined with
    a process automation server such as Jenkins, an entire CD4ML pipeline can be orchestrated.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用 MLflow 组件，例如 MLflow Tracking 服务器、模型注册、MLflow Projects 及其 Webhook 功能，再结合
    Jenkins 等过程自动化服务器，可以编排整个 CD4ML 流水线。
- en: Note
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'MLflow Model Registry''s webhooks feature is only available in the full version
    of Databricks; it''s not available in the Community Edition or open source MLflow.
    More information on MLflow Projects and their usage can be found here: [https://www.mlflow.org/docs/latest/projects.html](https://www.mlflow.org/docs/latest/projects.html).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow Model Registry 的 Webhook 功能仅在 Databricks 的完整版中可用，社区版或开源 MLflow 中无法使用。有关
    MLflow Projects 及其使用方法的更多信息，请访问：[https://www.mlflow.org/docs/latest/projects.html](https://www.mlflow.org/docs/latest/projects.html)。
- en: This way, MLflow, with its Model Tracking and Model Registry processes, can
    help streamline the entire CD4ML process, which would otherwise be a difficult
    process with a lot of manual steps, lack reproducibility, and cause errors and
    confusion among cross-functional teams.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，MLflow 通过其模型追踪和模型注册流程，可以帮助简化整个 CD4ML 流程，否则这一过程将非常复杂，涉及许多手动步骤，缺乏可重复性，并且容易导致跨职能团队之间的错误和混乱。
- en: Summary
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you were introduced to the end-to-end ML life cycle and the
    various steps involved in it. MLflow is a complete, end-to-end ML life cycle management
    tool. The MLflow Tracking component was presented, which is useful for streaming
    the ML experimentation process and helps you track all its attributes, including
    the data version, ML code, model parameters and metrics, and any other arbitrary
    artifacts. MLflow Model was introduced as a standards-based model format that
    provides model portability and reproducibility. MLflow Model Registry was also
    explored, which is a central model repository that supports the entire life cycle
    of a newly created model, from staging to production to archival. Model serving
    mechanisms, such as using batch and online processes, were also introduced. Finally,
    continuous delivery for ML was introduced. It is used to streamline the entire
    ML life cycle and automate the model life cycle using Model Registry features,
    such as the ability to transition model stages, a way to add comments and annotations,
    and using webhooks to help automate the model life cycle process via external
    orchestration tools.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了端到端的 ML 生命周期及其中涉及的各个步骤。MLflow 是一个完整的端到端 ML 生命周期管理工具。介绍了 MLflow Tracking
    组件，它对于流式处理 ML 实验过程非常有用，帮助你追踪所有的属性，包括数据版本、ML 代码、模型参数和指标，以及任何其他任意的工件。介绍了 MLflow
    Model 作为一种基于标准的模型格式，提供了模型的可移植性和可重复性。还介绍了 MLflow Model Registry，它是一个集中式的模型库，支持新创建的模型的整个生命周期，从暂存到生产再到归档。还介绍了模型服务机制，如使用批处理和在线处理。最后，介绍了
    ML 的持续交付，它用于简化整个 ML 生命周期，并通过 Model Registry 功能自动化模型生命周期过程，如模型阶段转换、添加评论和注释的方式，以及通过外部编排工具使用
    Webhook 来帮助自动化模型生命周期过程。
- en: So far in this book, you have acquired practical skills to perform data engineering
    and data science at scale. In the next chapter, we will focus on techniques for
    scaling out single-machine-based ML libraries based on standard Python.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经掌握了在大规模进行数据工程和数据科学的实用技能。在下一章，我们将重点介绍如何基于标准 Python 扩展单机 ML 库的技术。
