- en: Building a Regression Model with Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark构建回归模型
- en: In this chapter, we will build on what we covered in [Chapter 6](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml),
    *Building a Classification Model with Spark*. While classification models deal
    with outcomes that represent discrete classes, regression models are concerned
    with target variables that can take any real value. The underlying principle is
    very similar--we wish to find a model that maps input features to predicted target
    variables. Like classification, regression is also a form of supervised learning.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将继续探讨[第6章](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml)中涵盖的内容，*使用Spark构建分类模型*。虽然分类模型处理代表离散类别的结果，但回归模型涉及可以取任何实际值的目标变量。基本原理非常相似--我们希望找到一个将输入特征映射到预测目标变量的模型。与分类一样，回归也是一种监督学习形式。
- en: 'Regression models can be used to predict just about any variable of interest.
    A few examples include the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型可用于预测几乎任何感兴趣的变量。一些例子包括以下内容：
- en: Predicting stock returns and other economic variables
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测股票回报和其他经济变量
- en: Predicting loss amounts for loan defaults (this can be combined with a classification
    model that predicts the probability of default, while the regression model predicts
    the amount in the case of a default)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测贷款违约损失金额（这可以与预测违约概率的分类模型相结合，而回归模型则在违约情况下预测金额）
- en: Recommendations (the Alternating Least Squares factorization model from [Chapter
    5](d3bf76a8-26be-4db7-8310-b936d220407e.xhtml), *Building a Recommendation Engine
    with Spark*, uses linear regression in each iteration)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐（来自[第5章](d3bf76a8-26be-4db7-8310-b936d220407e.xhtml)的交替最小二乘因子化模型，*使用Spark构建推荐引擎*，在每次迭代中使用线性回归）
- en: Predicting **customer lifetime value** (**CLTV**) in a retail, mobile, or other
    business, based on user behavior and spending patterns
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于用户行为和消费模式，在零售、移动或其他业务中预测**客户终身价值**（**CLTV**）
- en: 'In the different sections of this chapter, we will do the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的不同部分，我们将做以下工作：
- en: Introduce the various types of regression models available in ML
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍ML中可用的各种回归模型
- en: Explore feature extraction and target variable transformation for regression
    models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索回归模型的特征提取和目标变量转换
- en: Train a number of regression models using ML
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ML训练多个回归模型
- en: See how to make predictions using the trained models
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看如何使用训练好的模型进行预测
- en: Investigate the impact on performance of various parameter settings for regression
    using cross-validation
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用交叉验证调查回归的各种参数设置对性能的影响
- en: Types of regression models
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归模型的类型
- en: The core idea of linear models (or generalized linear models) is that we model
    the predicted outcome of interest (often called the target or dependent variable)
    as a function of a simple linear predictor applied to the input variables (also
    referred to as features or independent variables).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型（或广义线性模型）的核心思想是，我们将感兴趣的预测结果（通常称为目标或因变量）建模为应用于输入变量（也称为特征或自变量）的简单线性预测器的函数。
- en: '*y = f(w^Tx)*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*y = f(w^Tx)*'
- en: Here, *y* is the target variable, *w* is the vector of parameters (known as
    the weight vector), and *x* is the vector of input features.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*y*是目标变量，*w*是参数向量（称为权重向量），*x*是输入特征向量。
- en: '*w^Tx* is the linear predictor (or vector dot product) of the weight vector
    *w* and feature vector *x*. To this linear predictor, we applied a function *f*
    (called the link function).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*w^Tx*是权重向量*w*和特征向量*x*的线性预测器（或向量点积）。对于这个线性预测器，我们应用了一个函数*f*（称为链接函数）。'
- en: Linear models can, in fact, be used for both classification and regression simply
    by changing the link function. Standard linear regression uses an identity link
    (that is, *y = w^Tx* directly), while binary classification uses alternative link
    functions as discussed here.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型实际上可以通过改变链接函数来用于分类和回归，标准线性回归使用恒等链接（即*y = w^Tx*直接），而二元分类使用其他链接函数，如本文所述。
- en: 'Spark''s ML library offers different regression models, which are as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的ML库提供了不同的回归模型，如下所示：
- en: Linear regression
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归
- en: Generalized linear regression
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广义线性回归
- en: Logistical regression
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Decision trees
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: Random forest regression
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林回归
- en: Gradient boosted trees
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度提升树
- en: Survival regression
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生存回归
- en: Isotonic regression
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等温回归
- en: Ridge regression
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 岭回归
- en: Regression models define the relationship between a dependent variable and one
    or more independent variables. It builds the best model that fits the values of
    independent variables or features.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型定义了因变量和一个或多个自变量之间的关系。它构建了最适合独立变量或特征值的模型。
- en: Linear regression unlike classification models such as support vector machines
    and logistic regression is used for predicting the value of a dependent variable
    with generalized value rather than predicting the exact class label.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 与支持向量机和逻辑回归等分类模型不同，线性回归用于预测具有广义值的因变量的值，而不是预测确切的类标签。
- en: Linear regression models are essentially the same as their classification counterparts,
    the only difference is that linear regression models use a different loss function,
    related link function, and decision function. Spark ML provides a standard least
    squares regression model (although other types of generalized linear models for
    regression are planned).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型本质上与其分类对应物相同，唯一的区别是线性回归模型使用不同的损失函数、相关链接函数和决策函数。Spark ML提供了标准的最小二乘回归模型（尽管计划使用其他类型的广义线性回归模型进行回归）。
- en: Least squares regression
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小二乘回归
- en: 'You might recall from [Chapter 6](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml),
    *Building a Classification Model with Spark*, that there are a variety of loss
    functions that can be applied to generalized linear models. The loss function
    used for least squares is the squared loss, which is defined as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得[第6章](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml)《使用Spark构建分类模型》中提到，广义线性模型可以应用各种损失函数。最小二乘法使用的损失函数是平方损失，定义如下：
- en: '*½ (w^Tx - y)²*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*½ (w^Tx - y)²*'
- en: Here, as for the classification setting, *y* is the target variable (this time,
    real valued), *w* is the weight vector, and *x* is the feature vector.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，与分类设置一样，*y*是目标变量（这次是实值），*w*是权重向量，*x*是特征向量。
- en: The related link function is the identity link, and the decision function is
    also the identity function, as generally, no thresholding is applied in regression.
    So, the model's prediction is simply *y = w^Tx*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 相关的链接函数是恒等链接，决策函数也是恒等函数，通常在回归中不会应用阈值。因此，模型的预测简单地是*y = w^Tx*。
- en: The standard least squares regression in ML library does not use regularization.
    Regularization is used to solve the problem of overfitting. Looking at the squared
    loss function, we can see that the loss applied to incorrectly predicted points
    will be magnified since the loss is squared. This means that least squares regression
    is susceptible to outliers in the dataset, and also to over-fitting. Generally,
    as for classification, we should apply some level of regularization in practice.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ML库中的标准最小二乘回归不使用正则化。正则化用于解决过拟合问题。观察平方损失函数，我们可以看到对于错误预测的点，损失会被放大，因为损失被平方了。这意味着最小二乘回归容易受到数据集中的异常值和过拟合的影响。通常，对于分类问题，我们应该在实践中应用一定程度的正则化。
- en: Linear regression with L2 regularization is commonly referred to as ridge regression,
    while applying L1 regularization is called the lasso.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 带有L2正则化的线性回归通常称为岭回归，而应用L1正则化称为套索。
- en: When the dataset is small, or the number of examples is fewer, the tendency
    of the model to over fit is very high, therefore, it is highly recommended to
    use regularizers like L1, L2, or elastic net.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据集较小或示例数量较少时，模型过拟合的倾向非常高，因此强烈建议使用L1、L2或弹性网络等正则化器。
- en: See the section on linear least squares in the Spark MLlib documentation at
    [http://spark.apache.org/docs/latest/mllib-linear-methods.html#linear-least-squares-lasso-and-ridge-regression](http://spark.apache.org/docs/latest/mllib-linear-methods.html#linear-least-squares-lasso-and-ridge-regression)
    for further information.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Spark MLlib文档中线性最小二乘法的部分，请参阅[http://spark.apache.org/docs/latest/mllib-linear-methods.html#linear-least-squares-lasso-and-ridge-regression](http://spark.apache.org/docs/latest/mllib-linear-methods.html#linear-least-squares-lasso-and-ridge-regression)以获取更多信息。
- en: Decision trees for regression
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归的决策树
- en: Just like using linear models for regression tasks involves changing the loss
    function used, using decision trees for regression involves changing the measure
    of the node impurity used. The impurity metric is called **variance**, and is
    defined in the same way as the squared loss for least squares linear regression.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 就像使用线性模型进行回归任务需要改变使用的损失函数一样，使用决策树进行回归需要改变使用的节点不纯度度量。不纯度度量称为**方差**，定义方式与最小二乘线性回归的平方损失相同。
- en: See the *MLlib - Decision Tree* section in the Spark documentation at [http://spark.apache.org/docs/latest/mllib-decision-tree.html](http://spark.apache.org/docs/latest/mllib-decision-tree.html)
    for further details on the decision tree algorithm and impurity measure for regression.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 有关决策树算法和回归不纯度度量的更多详细信息，请参阅Spark文档中的*MLlib - 决策树*部分[http://spark.apache.org/docs/latest/mllib-decision-tree.html](http://spark.apache.org/docs/latest/mllib-decision-tree.html)。
- en: 'Now, we will plot a simple example of a regression problem with only one input
    variable shown on the *x* axis and the target variable on the *y* axis. The linear
    model prediction function is shown by a red-dashed line, while the decision tree
    prediction function is shown by a green-dashed line. We can see that the decision
    tree allows a more complex, nonlinear model to be fitted to the data:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将绘制一个只有一个输入变量的回归问题的简单示例，横轴显示在*x*轴上，目标变量显示在*y*轴上。线性模型的预测函数由红色虚线表示，而决策树的预测函数由绿色虚线表示。我们可以看到决策树允许将更复杂、非线性的模型拟合到数据中：
- en: '![](img/image_07_001.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_001.png)'
- en: Evaluating the performance of regression models
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估回归模型的性能
- en: We saw in [Chapter 6](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml), *Building
    a Classification Model with Spark*, that evaluation methods for classification
    models typically focus on measurements related to predicted class memberships
    relative to the actual class memberships. These are binary outcomes (either the
    predicted class is correct or incorrect), and it is less important whether the
    model just barely predicted correctly or not; what we care most about is the number
    of correct and incorrect predictions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第6章](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml)《使用Spark构建分类模型》中看到，分类模型的评估方法通常侧重于与实际类成员关联的预测类成员相关的测量。这些是二元结果（预测类是否正确），模型是否刚好预测正确并不那么重要；我们最关心的是正确和错误预测的数量。
- en: When dealing with regression models, it is very unlikely that our model will
    precisely predict the target variable, because the target variable can take on
    any real value. However, we would naturally like to understand how far away our
    predicted values are from the true values, so will we utilize a metric that takes
    into account the overall deviation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理回归模型时，我们很少能够精确预测目标变量，因为目标变量可以取任意实值。然而，我们自然希望了解我们的预测值与真实值的偏差有多大，因此我们将利用一个考虑整体偏差的度量。
- en: Some of the standard evaluation metrics used to measure the performance of regression
    models include the **Mean Squared Error** (**MSE**) and **Root Mean Squared Error**
    (**RMSE**), the **Mean Absolute Error** (**MAE**), the R-squared coefficient,
    and many others.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 用于衡量回归模型性能的一些标准评估指标包括**均方误差**（**MSE**）和**均方根误差**（**RMSE**），**平均绝对误差**（**MAE**），R平方系数等等。
- en: Mean Squared Error and Root Mean Squared Error
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 均方误差和均方根误差
- en: 'MSE is the average of the squared error that is used as the loss function for
    least squares regression:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: MSE是用作最小二乘回归的损失函数的平方误差的平均值：
- en: '![](img/image_07_002.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_002.jpg)'
- en: It is the sum, over all the data points, of the square of the difference between
    the predicted and actual target variables, divided by the number of data points.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 它是所有数据点的预测值和实际目标变量之间差异的平方之和，除以数据点的数量。
- en: RMSE is the square root of MSE. MSE is measured in units that are the square
    of the target variable, while RMSE is measured in the same units as the target
    variable. Due to its formulation, MSE, just like the squared loss function that
    it derives from, effectively penalizes larger errors more severely.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: RMSE是MSE的平方根。MSE以目标变量的平方为单位进行测量，而RMSE以与目标变量相同的单位进行测量。由于其公式，MSE，就像它导出的平方损失函数一样，有效地严厉地惩罚更大的误差。
- en: In order to evaluate our predictions based on the mean of an error metric, we
    will first make predictions for each input feature vector in an RDD of `LabeledPoint`
    instances by computing the error for each record using a function that takes the
    prediction and true target value as inputs. This will return a `[Double]` RDD
    that contains the error values. We can then find the average using the mean method
    of RDDs that contain double values.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估基于误差度量的平均预测，我们将首先对`LabeledPoint`实例的RDD中的每个输入特征向量进行预测，通过使用一个函数计算每个记录的误差，该函数将预测值和真实目标值作为输入。这将返回一个包含误差值的`[Double]`
    RDD。然后我们可以使用包含双精度值的RDD的平均方法找到平均值。
- en: 'Let''s define our squared error function as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义我们的平方误差函数如下：
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Mean Absolute Error
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平均绝对误差
- en: 'MAE is the average of the absolute differences between the predicted and actual
    targets and is given as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: MAE是预测值和实际目标之间绝对差异的平均值，表示如下：
- en: '![](img/image_07_003.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_003.png)'
- en: MAE is similar in principle to MSE, but it does not punish large deviations
    as much.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: MAE在原则上类似于MSE，但它不像MSE那样严厉地惩罚大偏差。
- en: 'Our function to compute MAE is as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算MAE的函数如下：
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Root Mean Squared Log Error
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 均方根对数误差
- en: This measurement is not as widely used as MSE and MAE, but it is used as the
    metric for the Kaggle competition that uses the bike-sharing dataset. It is, effectively,
    the RMSE of the log-transformed predicted and target values. This measurement
    is useful when there is a wide range in the target variable, and you do not necessarily
    want to penalize large errors when the predicted and target values are themselves
    high. It is also effective when you care about percentage errors rather than the
    absolute value of errors.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这个测量并不像MSE和MAE那样被广泛使用，但它被用作使用自行车共享数据集的Kaggle竞赛的度量标准。实际上，它是对预测值和目标值进行对数变换后的RMSE。当目标变量的范围很大，并且在预测值和目标值本身很高时，您不一定希望惩罚大误差时，这个测量是有用的。当您关心百分比误差而不是绝对误差的值时，它也是有效的。
- en: The Kaggle competition evaluation page can be found at [https://www.kaggle.com/c/bike-sharing-demand/details/evaluation](https://www.kaggle.com/c/bike-sharing-demand/details/evaluation).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle竞赛评估页面可以在[https://www.kaggle.com/c/bike-sharing-demand/details/evaluation](https://www.kaggle.com/c/bike-sharing-demand/details/evaluation)找到。
- en: 'The function to compute RMSLE is shown here:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 计算RMSLE的函数如下所示：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The R-squared coefficient
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R平方系数
- en: The R-squared coefficient, also known as the coefficient of determination, is
    a measure of how well a model fits a dataset. It is commonly used in statistics.
    It measures the degree of variation in the target variable; this is explained
    by the variation in the input features. An R-squared coefficient generally takes
    a value between 0 and 1, where 1 equates to a perfect fit of the model.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: R平方系数，也称为确定系数，是衡量模型拟合数据集的程度的指标。它通常用于统计学。它衡量目标变量的变化程度;这是由输入特征的变化来解释的。R平方系数通常取0到1之间的值，其中1等于模型的完美拟合。
- en: Extracting the right features from your data
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据中提取正确的特征
- en: As the underlying models for regression are the same as those for the classification
    case, we can use the same approach to create input features. The only practical
    difference is that the target is now a real-valued variable as opposed to a categorical
    one. The `LabeledPoint` class in ML library already takes this into account, as
    the `label` field is of the `Double` type, so it can handle both cases.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于回归的基础模型与分类情况相同，我们可以使用相同的方法来创建输入特征。唯一的实际区别是目标现在是一个实值变量，而不是一个分类变量。ML库中的`LabeledPoint`类已经考虑到了这一点，因为`label`字段是`Double`类型，所以它可以处理这两种情况。
- en: Extracting features from the bike sharing dataset
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从自行车共享数据集中提取特征
- en: To illustrate the concepts in this chapter, we will be using the bike sharing
    dataset. This dataset contains hourly records of the number of bicycle rentals
    in the capital bike sharing system. It also contains variables related to date,
    time, weather, seasonal, and holiday information.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明本章中的概念，我们将使用自行车共享数据集。该数据集包含自行车共享系统中每小时自行车租赁数量的记录。它还包含与日期、时间、天气、季节和假日信息相关的变量。
- en: The dataset is available at [http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可在[http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)找到。
- en: Click on the Data Folder link, and then download the `Bike-Sharing-Dataset.zip`
    file.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 点击数据文件夹链接，然后下载`Bike-Sharing-Dataset.zip`文件。
- en: 'The bike sharing data was enriched with weather and seasonal data by Hadi Fanaee-T
    at the University of Porto and used in the following paper:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 自行车共享数据是由波尔图大学的Hadi Fanaee-T丰富了天气和季节数据，并在以下论文中使用：
- en: Fanaee-T, Hadi and Gama Joao, Event labeling combining ensemble detectors and
    background knowledge, *Progress in Artificial Intelligence*, pp. 1-15, Springer
    Berlin Heidelberg, 2013.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Fanaee-T，Hadi和Gama Joao，事件标签组合集成检测器和背景知识，*人工智能进展*，第1-15页，斯普林格柏林海德堡，2013年。
- en: The paper is available at [http://link.springer.com/article/10.1007%2Fs13748-013-0040-3](http://link.springer.com/article/10.1007%2Fs13748-013-0040-3).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文可在[http://link.springer.com/article/10.1007%2Fs13748-013-0040-3](http://link.springer.com/article/10.1007%2Fs13748-013-0040-3)找到。
- en: Once you have downloaded the `Bike-Sharing-Dataset.zip` file, unzip it. This
    will create a directory called `Bike-Sharing-Dataset`, which contains the `day.csv`,
    `hour.csv`, and the `Readme.txt` files.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你下载了`Bike-Sharing-Dataset.zip`文件，解压它。这将创建一个名为`Bike-Sharing-Dataset`的目录，其中包含`day.csv`、`hour.csv`和`Readme.txt`文件。
- en: 'The `Readme.txt` file contains information on the dataset, including the variable
    names and descriptions. Take a look at the file, and you will see that we have
    the following variables available:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`Readme.txt`文件包含有关数据集的信息，包括变量名称和描述。看一下文件，你会发现我们有以下可用的变量：'
- en: '`instant`: This is the record ID'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instant`：这是记录ID'
- en: '`dteday`: This is the raw date'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dteday`：这是原始日期'
- en: '`season`: This refers to the different seasons such as spring, summer, winter,
    and fall'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`season`：这指的是不同的季节，如春季、夏季、冬季和秋季'
- en: '`yr`: This is the year (2011 or 2012)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yr`：这是年份（2011或2012）'
- en: '`mnth`: This is the month of the year'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mnth`：这是一年中的月份'
- en: '`hr`: This is the hour of the day'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hr`：这是一天中的小时'
- en: '`holiday`: This shows whether the day was a holiday or not'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`holiday`：这显示这一天是否是假日'
- en: '`weekday`: This is the day of the week'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weekday`：这是一周的某一天'
- en: '`workingday`: This refers to whether the day was a working day or not'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`workingday`：这指的是这一天是否是工作日'
- en: '`weathersit`: This is a categorical variable that describes the weather at
    a particular time'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weathersit`：这是描述特定时间天气的分类变量'
- en: '`temp`: This is the normalized temperature'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temp`：这是标准化的温度'
- en: '`atemp`: This is the normalized apparent temperature'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`atemp`：这是标准化的体感温度'
- en: '`hum`: This is the normalized humidity'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hum`：这是标准化的湿度'
- en: '`windspeed`: This is the normalized wind speed'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 风速：这是标准化的风速
- en: '`cnt`: This is the target variable, that is, the count of bike rentals for
    that hour'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cnt`：这是目标变量，即该小时的自行车租赁次数'
- en: 'We will work with the hourly data contained in `hour.csv`. If you look at the
    first line of the dataset, you will see that it contains the column names as header.
    The following code snippet prints the header and the top 20 records:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`hour.csv`中包含的每小时数据。如果你看一下数据集的第一行，你会发现它包含列名作为标题。以下代码片段打印标题和前20条记录：
- en: '[PRE3]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding code snippet should output the following result:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段应该输出以下结果：
- en: '[PRE4]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](img/image_07_004.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_004.png)'
- en: We will be using Scala to demonstrate the examples in this chapter. The source
    code for the chapter can be found at the location [https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07](https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Scala来演示本章的示例。本章的源代码可以在以下位置找到[https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07](https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07)。
- en: 'We''ll start as usual by loading the dataset and inspecting it; from the previous
    dataframe, get the record count as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将像往常一样加载数据集并对其进行检查；从前一个数据框中获取记录计数如下：
- en: '[PRE5]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This should output the following result:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该输出以下结果：
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: So, we have `17,379` hourly records in our dataset. We have inspected the column
    names already. We will ignore the record ID and raw date columns. We will also
    ignore the `casual` and `registered` count target variables, and focus on the
    overall count variable, `cnt` (which is the sum of the other two counts). We are
    left with 12 variables. The first eight are categorical, while the last four are
    normalized real-valued variables.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们的数据集中有17,379条每小时的记录。我们已经检查了列名。我们将忽略记录ID和原始日期列。我们还将忽略“casual”和“registered”计数目标变量，并专注于总计变量“cnt”（这是其他两个计数的总和）。我们剩下12个变量。前8个是分类的，而最后4个是标准化的实值变量。
- en: '[PRE7]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This last bit of code should output the following result:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的最后一部分应该输出以下结果：
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'All the columns are casted to double; the following snippet shows how this
    is done:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 所有列都被转换为double；以下代码片段显示了如何做到这一点：
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding code should output the following result:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码应该输出以下结果：
- en: '[PRE10]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The bike sharing dataset is categorical in nature, and needs to be processed
    using **Vector Assembler** and **Vector Indexer** as described next:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 自行车共享数据集是分类的，需要使用**向量组装器**和**向量索引器**进行处理，如下所述：
- en: Vector Assembler is a transformer that combines a list of columns into a single
    vector column. It combines raw features into a feature vector in order to train
    ML models like linear regression and decision trees.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量组装器是一个转换器，它将一系列列组合成单个向量列。它将原始特征组合成特征向量，以便训练线性回归和决策树等ML模型。
- en: Vector Indexer indexes categorical features, passed from Vector Assembler in
    this case. It automatically decides which features are categorical, and converts
    actual values to category indices.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量索引器索引从向量组装器传递的分类特征。它会自动决定哪些特征是分类的，并将实际值转换为类别索引。
- en: In our case, all the columns in df2 except `label` are converted by `VectorAssembler`
    into `rawFeatures`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，df2中除了`label`之外的所有列都被`VectorAssembler`转换为`rawFeatures`。
- en: Given an input column of type `Vector` and a `param` called `maxCategories`,
    it decides which features should be categorical based on distinct values, where
    features with at most `maxCategories` are declared categorical.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 给定类型为`Vector`的输入列和名为`maxCategories`的`param`，它根据不同的值决定哪些特征应该是分类的，其中最多有`maxCategories`的特征被声明为分类的。
- en: '[PRE11]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The complete code-listing is available at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/BikeSharingExecutor.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/BikeSharingExecutor.scala).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码清单可在[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/BikeSharingExecutor.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/BikeSharingExecutor.scala)找到。
- en: Training and using regression models
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和使用回归模型
- en: Training for regression models follows the same procedure as for classification
    models. We simply pass the training data to the relevant train method.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型的训练遵循与分类模型相同的程序。我们只需将训练数据传递给相关的训练方法。
- en: BikeSharingExecutor
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BikeSharingExecutor
- en: 'The `BikeSharingExecutor` object can be used to choose and run the respective
    regression model, for example, to run `LinearRegression` and execute the linear
    regression pipeline, set the program argument as `LR_<type>`, where `type` is
    the data format; for other commands, refer to the following code snippet:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`BikeSharingExecutor`对象可用于选择和运行相应的回归模型，例如，要运行`LinearRegression`并执行线性回归管道，将程序参数设置为`LR_<type>`，其中`type`是数据格式；对于其他命令，请参考以下代码片段：'
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The code-listing can be found at this link:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单可在此链接找到：
- en: '[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/BikeSharingExecutor.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/BikeSharingExecutor.scala)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/BikeSharingExecutor.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/BikeSharingExecutor.scala)'
- en: Training a regression model on the bike sharing dataset
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在自行车共享数据集上训练回归模型
- en: Linear regression
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性回归
- en: Linear regression is the most commonly used algorithm. At the core of the regression
    analysis is the task of fitting a single line through a data plot. Linear equation
    is described by *y = c + b*x*, where *y* = estimated dependent, *c* = constant,
    *b* = regression coefficients, and *x* = independent variable.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是最常用的算法。回归分析的核心是通过数据图拟合一条直线的任务。线性方程式由*y = c + b*x*描述，其中*y* = 估计的因变量，*c*
    = 常数，*b* = 回归系数，*x* = 自变量。
- en: Let's train the bike sharing dataset by splitting it into 80% training and 20%
    testing, use `LinearRegression` with the regression evaluator from Spark to build
    the model, and get evaluation metrics around the test data. The `linearRegressionWithVectorFormat`
    method uses categorical data, whereas `linearRegressionWithSVMFormat` uses the
    `libsvm` format of the `Bike-sharing` dataset.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将自行车共享数据集分为80%的训练和20%的测试，使用Spark的回归评估器使用`LinearRegression`构建模型，并获得关于测试数据的评估指标。`linearRegressionWithVectorFormat`方法使用分类数据，而`linearRegressionWithSVMFormat`使用`Bike-sharing`数据集的`libsvm`格式。
- en: '[PRE13]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This preceding code should show the following output. Please note that residual
    stands for the expression Residuals: (label-predicted value)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码应该显示以下输出。请注意，残差代表表达式残差：（标签-预测值）
- en: '[PRE14]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The code-listing can be found at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/LinearRegressionPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/LinearRegressionPipeline.scala).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单可在[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/LinearRegressionPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/LinearRegressionPipeline.scala)找到。
- en: Generalized linear regression
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广义线性回归
- en: Linear regression follows a Gaussian distribution, whereas, **generalized linear
    models** (**GLMs**) are specifications of linear models where the response variable
    `Y` follows some distribution from the exponential family of distributions.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归遵循高斯分布，而**广义线性模型**（**GLM**）是线性模型的规范，其中响应变量`Y`遵循指数分布族中的某个分布。
- en: Let's train the bike sharing dataset by splitting it into 80 % training and
    20% testing, use `GeneralizedLinearRegression` with regression evaluator from
    Spark to build the model, and get evaluation metrics around the test data.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将自行车共享数据集分为80%的训练和20%的测试，使用Spark的回归评估器使用`GeneralizedLinearRegression`构建模型，并获得关于测试数据的评估指标。
- en: '[PRE15]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This should output the following result:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该输出以下结果：
- en: Standard error of estimated coefficients and intercept.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 估计系数和截距的标准误差。
- en: If `[GeneralizedLinearRegression.fitIntercept]` is set to true, then the last
    element returned corresponds to the intercept.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`[GeneralizedLinearRegression.fitIntercept]`设置为true，则返回的最后一个元素对应于截距。
- en: 'Coefficient Standard Errors in the previous code are as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码中的系数标准误差如下：
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'T-statistic of estimated coefficients and intercept is as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 估计系数和截距的T统计量如下：
- en: '[PRE17]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The two-sided p-value of estimated coefficients and intercept is as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 估计系数和截距的双侧p值如下：
- en: '[PRE18]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The dispersion is as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 离散度如下：
- en: '[PRE19]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The dispersion of the fitted model is taken as 1.0 for the "binomial" and "poisson"
    families, and otherwise estimated by the residual Pearson's Chi-Squared statistic
    (which is defined as the sum of the squares of the Pearson residuals) divided
    by the residual degrees of freedom.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合模型的离散度对于“二项式”和“泊松”族取1.0，否则由残差Pearson卡方统计量（定义为Pearson残差的平方和）除以残差自由度估计。
- en: 'The Null deviance output of the preceding code is as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的空偏差输出如下：
- en: '[PRE20]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Residual degree of freedom is as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 残差自由度如下：
- en: '[PRE21]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In logistic regression analysis, deviance is used in lieu of the sum of squares
    calculations. Deviance is analogous to the sum of squares calculations in linear
    regression, and is a measure of the lack of fit to the data in a logistic regression
    model. When a "saturated" model is available (a model with a theoretically perfect
    fit), deviance is calculated by comparing a given model with the saturated model.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在逻辑回归分析中，偏差用来代替平方和的计算。偏差类似于线性回归中的平方和计算，是对逻辑回归模型中数据拟合不足的度量。当“饱和”模型可用时（具有理论上完美的拟合模型），通过将给定模型与饱和模型进行比较来计算偏差。
- en: 'Deviance: `3.886235458383082E8`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差：`3.886235458383082E8`
- en: 'Reference: [https://en.wikipedia.org/wiki/Logistic_regression](https://en.wikipedia.org/wiki/Logistic_regression)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 参考：[https://en.wikipedia.org/wiki/Logistic_regression](https://en.wikipedia.org/wiki/Logistic_regression)
- en: '**Degrees of freedom**:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**自由度**：'
- en: The concept of degrees of freedom is central to the principle of estimating
    statistics of populations from samples of them. "Degrees of freedom" is commonly
    abbreviated to df.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 自由度的概念是从样本中估计总体统计量的原则的核心。 “自由度”通常缩写为df。
- en: 'Think of df as a mathematical restriction that needs to be put in place when
    estimating one statistic from an estimate of another. The preceding code will
    give the following output:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 将df视为在从另一个估计值中估计一个统计量时需要放置的数学限制。前面的代码将产生以下输出：
- en: '[PRE22]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The **Akaike information criterion** (**AIC**) is a measure of the relative
    quality of statistical models for a given set of data. Given a collection of models
    for the data, AIC estimates the quality of each model relative to each of the
    other models. Hence, AIC provides a means for model selection.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 阿凯克信息准则（AIC）是对给定数据集的统计模型相对质量的度量。给定数据的一组模型，AIC估计每个模型相对于其他模型的质量。因此，AIC提供了模型选择的一种方法。
- en: 'Reference : [https://en.wikipedia.org/wiki/Akaike_information_criterion](https://en.wikipedia.org/wiki/Akaike_information_criterion)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 参考：[https://en.wikipedia.org/wiki/Akaike_information_criterion](https://en.wikipedia.org/wiki/Akaike_information_criterion)
- en: 'AIC for the fitted model output will be as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合模型输出的AIC如下：
- en: '[PRE23]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The complete code listing is available at this link:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码清单可在此链接找到：
- en: '[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/GeneralizedLinearRegressionPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/GeneralizedLinearRegressionPipeline.scala)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/GeneralizedLinearRegressionPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/GeneralizedLinearRegressionPipeline.scala)'
- en: Decision tree regression
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树回归
- en: The decision tree model is a powerful, non-probabilistic technique, which can
    capture more complex nonlinear patterns and feature interactions. They have been
    shown to perform well on many tasks, are relatively easy to understand and interpret,
    can handle categorical and numerical features, and do not require input data to
    be scaled or standardized. They are well-suited to be included in ensemble methods
    (for example, ensembles of decision tree models, which are called decision forests).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树模型是一种强大的、非概率的技术，可以捕捉更复杂的非线性模式和特征交互。它们已被证明在许多任务上表现良好，相对容易理解和解释，可以处理分类和数值特征，并且不需要输入数据进行缩放或标准化。它们非常适合包含在集成方法中（例如，决策树模型的集成，称为决策森林）。
- en: The decision tree algorithm is a top-down approach, which begins at a root node
    (or feature), and then selects a feature at each step that gives the best split
    of the dataset, as measured by the information gain of this split. The information
    gain is computed from the node impurity (which is the extent to which the labels
    at the node are similar, or homogenous) minus the weighted sum of the impurities
    for the two child nodes that would be created by the split.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树算法是一种自顶向下的方法，从根节点（或特征）开始，然后在每一步选择一个特征，该特征通过信息增益来衡量数据集的最佳拆分。信息增益是从节点不纯度（标签在节点上相似或同质的程度）减去由拆分创建的两个子节点的不纯度的加权和来计算的。
- en: Let's train the bike sharing dataset by splitting it into 80 % training and
    20% testing, use `DecisionTreeRegression` with regression evaluator from Spark
    to build the model, and get evaluation metrics around the test data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将自行车共享数据集分成80%的训练和20%的测试，使用Spark中的`DecisionTreeRegression`和回归评估器来构建模型，并获得测试数据周围的评估指标。
- en: '[PRE24]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This should output the following result:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该输出以下结果：
- en: '[PRE25]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Please refer to the previous section (Generalized Linear Regression) to learn
    how to interpret the results.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考前一节（广义线性回归）以了解如何解释结果。
- en: The code listing is available at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/DecisionTreeRegressionPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/DecisionTreeRegressionPipeline.scala).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单可在[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/DecisionTreeRegressionPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/DecisionTreeRegressionPipeline.scala)找到。
- en: Ensembles of trees
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 树的集成
- en: 'The ensemble method is a machine learning algorithm, which creates a model
    composed of a set of other base models. Spark machine learning supports two major
    ensemble algorithms: `RandomForest` and `GradientBoostedTrees`.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 集成方法是一种机器学习算法，它创建由一组其他基本模型组成的模型。Spark机器学习支持两种主要的集成算法：`RandomForest`和`GradientBoostedTrees`。
- en: Random forest regression
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林回归
- en: Random forests are known as ensembles of decision trees formed by combining
    many decision trees. Like decision trees, random forests can handle categorical
    features, support multiclass, and don't require feature scaling.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林被称为决策树的集成，由许多决策树组成。与决策树一样，随机森林可以处理分类特征，支持多类别，并且不需要特征缩放。
- en: Let's train the bike sharing dataset by splitting it into 80 % training and
    20% testing, use `RandomForestRegressor` with Regression Evaluator from Spark
    to build the model, and get evaluation metrics around the test data.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将自行车共享数据集分为80%的训练和20%的测试，使用Spark中的`RandomForestRegressor`和回归评估器构建模型，并获得关于测试数据的评估指标。
- en: '[PRE26]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This should output the following result:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该输出以下结果：
- en: '[PRE27]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The preceding code uses various features and their values to create a decision
    tree.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码使用各种特征及其值创建决策树。
- en: The code listing can be found at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/RandomForestRegressionPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/RandomForestRegressionPipeline.scala).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单可在[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/RandomForestRegressionPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/RandomForestRegressionPipeline.scala)找到。
- en: Gradient boosted tree regression
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升树回归
- en: Gradient boosted trees are ensembles of decision trees. Gradient boosted trees
    iteratively train decision trees to minimize the loss function. Gradient boosted
    trees handle categorical features, support multiclass, and don't require feature
    scaling.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度提升树是决策树的集成。梯度提升树迭代训练决策树以最小化损失函数。梯度提升树处理分类特征，支持多类别，并且不需要特征缩放。
- en: Spark ML implements gradient boosted trees using the existing decision tree
    implementation. It supports both classification and regression.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML使用现有的决策树实现梯度提升树。它支持分类和回归。
- en: Let's train the bike sharing dataset by splitting it into 80% training and 20%
    testing, use GBTRegressor with regression evaluator from Spark to build the model,
    and get evaluation metrics around the test data.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将自行车共享数据集分为80%的训练和20%的测试，使用Spark中的GBTRegressor和回归评估器构建模型，并获得关于测试数据的评估指标。
- en: '[PRE28]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This should output the following result:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该输出以下结果：
- en: '[PRE29]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The code listing is available at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/GradientBoostedTreeRegressorPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/GradientBoostedTreeRegressorPipeline.scala).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单可在[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/GradientBoostedTreeRegressorPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/bikesharing/GradientBoostedTreeRegressorPipeline.scala)找到。
- en: Improving model performance and tuning parameters
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进模型性能和调整参数
- en: 'In [Chapter 6](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml), *Building a Classification
    Model with Spark*, we showed how feature transformation and selection can make
    a large difference to the performance of a model. In this chapter, we will focus
    on another type of transformation that can be applied to a dataset: transforming
    the target variable itself.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml)中，*使用Spark构建分类模型*，我们展示了特征转换和选择如何对模型的性能产生很大影响。在本章中，我们将专注于可以应用于数据集的另一种转换类型：转换目标变量本身。
- en: Transforming the target variable
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换目标变量
- en: Recall that many machine learning models, including linear models, make assumptions
    regarding the distribution of the input data as well as target variables. In particular,
    linear regression assumes a normal distribution.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，许多机器学习模型，包括线性模型，对输入数据和目标变量的分布做出假设。特别是，线性回归假设正态分布。
- en: In many real-world cases, the distributional assumptions of linear regression
    do not hold. In this case, for example, we know that the number of bike rentals
    can never be negative. This alone should indicate that the assumption of normality
    might be problematic. To get a better idea of the target distribution, it is often
    a good idea to plot a histogram of the target values.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多实际情况下，线性回归的分布假设并不成立。例如，在这种情况下，我们知道自行车租赁数量永远不会是负数。这一点就应该表明正态分布的假设可能存在问题。为了更好地了解目标分布，通常最好绘制目标值的直方图。
- en: 'We will now create a plot of the target variable distribution in the following
    piece of code:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将创建目标变量分布的图表如下所示：
- en: Scala
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: The code for plotting raw data can be found at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/1.6.2/scala-spark-app/src/main/scala/org/sparksamples/PlotRawData.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/1.6.2/scala-spark-app/src/main/scala/org/sparksamples/PlotRawData.scala).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制原始数据的代码可以在[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/1.6.2/scala-spark-app/src/main/scala/org/sparksamples/PlotRawData.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_07/scala/1.6.2/scala-spark-app/src/main/scala/org/sparksamples/PlotRawData.scala)找到。
- en: '[PRE30]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The plot for the preceding output is shown as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 前述输出的图如下所示：
- en: '![](img/image_07_005.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_005.png)'
- en: One way in which we might deal with this situation is by applying a transformation
    to the target variable such that we take the logarithm of the target value instead
    of the raw value. This is often referred to as log-transforming the target variable
    (this transformation can also be applied to feature values).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们处理这种情况的一种方法是对目标变量应用转换，即我们取目标值的对数而不是原始值。这通常被称为对目标变量进行对数转换（此转换也可以应用于特征值）。
- en: 'We will apply a log transformation to the following target variable, and plot
    a histogram of the log-transformed values using the following code:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对以下目标变量应用对数变换，并使用以下代码绘制对数变换后的值的直方图：
- en: Scala
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: '[PRE31]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The plot for the preceding output is shown as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 前面输出的图表如下所示：
- en: '![](img/image_07_006.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_006.png)'
- en: A second type of transformation that is useful in the case of target values
    that do not take on negative values, and, in addition, might take on a very wide
    range of values, is to take the square root of the variable.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种转换类型在目标值不取负值，并且可能取值范围非常广泛的情况下非常有用，那就是对变量取平方根。
- en: 'We will apply the square root transform in the following code, once more plotting
    the resulting target variable distribution:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在以下代码中应用平方根变换，再次绘制结果目标变量的分布：
- en: From the plots of the log and square root transformations, we can see that both
    result in a more even distribution relative to the raw values. While they are
    still not normally distributed, they are a lot closer to a normal distribution
    when compared to the original target variable.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 从对数和平方根变换的图表中，我们可以看到两者都相对于原始值产生了更均匀的分布。虽然它们仍然不是正态分布，但与原始目标变量相比，它们更接近正态分布。
- en: Impact of training on log-transformed targets
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对对数变换目标的训练影响
- en: So, does applying these transformations have any impact on model performance?
    Let's evaluate the various metrics we used previously on the log-transformed data
    as an example.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，应用这些转换对模型性能有影响吗？让我们以对数变换数据为例，评估我们之前使用的各种指标。
- en: We will do this first for the linear model by applying the log function to the
    `label` field of each `LabeledPoint` RDD. Here, we will only transform the target
    variable, and we will not apply any transformations to the features.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先对线性模型进行操作，通过对每个`LabeledPoint` RDD的`label`字段应用对数函数。在这里，我们只会对目标变量进行转换，不会对特征进行任何转换。
- en: We will then train a model on this transformed data, and form the RDD of predicted
    versus true values.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将在转换后的数据上训练模型，并形成预测值与真实值的RDD。
- en: Note that now that we have transformed the target variable, the predictions
    of the model will be on the log scale, as will the target values of the transformed
    dataset. Therefore, in order to use our model and evaluate its performance, we
    must first transform the log data back into the original scale by taking the exponent
    of both the predicted and true values using the `numpy exp` function.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在我们已经转换了目标变量，模型的预测将在对数尺度上，转换后数据集的目标值也将在对数尺度上。因此，为了使用我们的模型并评估其性能，我们必须首先通过使用`numpy
    exp`函数将对数数据转换回原始尺度，对预测值和真实值都进行指数化。
- en: 'Finally, we will compute the MSE, MAE, and RMSLE metrics for the model:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将计算模型的MSE、MAE和RMSLE指标：
- en: Scala
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: '[PRE32]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output of the preceding code will be similar to the following:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出将类似于以下内容：
- en: '[PRE33]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The code listing is available at this link:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单可在以下链接找到：
- en: '[https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/
    linearregression/LinearRegressionWithLog.scala](https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/%20linearregression/LinearRegressionWithLog.scala)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/
    linearregression/LinearRegressionWithLog.scala](https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/%20linearregression/LinearRegressionWithLog.scala)'
- en: '[https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/
    linearregression/LinearRegression.scala](https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/%20linearregression/LinearRegression.scala)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/
    linearregression/LinearRegression.scala](https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_07/scala/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/regression/%20linearregression/LinearRegression.scala)'
- en: If we compare these preceding results to the results on the raw target variable,
    we see that all three values became worse.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这些前面的结果与原始目标变量的结果进行比较，我们会发现所有三个值都变得更糟。
- en: '[PRE34]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Tuning model parameters
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整模型参数
- en: So far in this chapter, we have illustrated the concepts of model training and
    evaluation for MLlib's regression models by training and testing on the same dataset.
    We will now use a cross-validation approach similar to what we used previously
    to evaluate the effect of different parameter settings on the performance of our
    models.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章中，我们已经通过在相同数据集上进行训练和测试来说明了MLlib回归模型的模型训练和评估的概念。现在，我们将使用与之前类似的交叉验证方法来评估不同参数设置对模型性能的影响。
- en: Creating training and testing sets to evaluate parameters
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建训练和测试集以评估参数。
- en: The first step is to create a test and training set for cross-validation purposes.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是为交叉验证目的创建测试和训练集。
- en: 'In Scala, the split is easier to implement, and the `randomSplit` function
    is available:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在Scala中，拆分更容易实现，并且`randomSplit`函数可用：
- en: '[PRE35]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Splitting data for Decision tree
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树的数据拆分
- en: The final step is to apply the same approach to the features extracted for the
    decision tree model.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是对决策树模型提取的特征应用相同的方法。
- en: Scala
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: '[PRE36]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The impact of parameter settings for linear models
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性模型参数设置的影响
- en: Now that we have prepared our training and test sets, we are ready to investigate
    the impact of the different parameter settings on model performance. We will first
    carry out this evaluation for the linear model. We will create a convenience function
    to evaluate the relevant performance metric by training the model on the training
    set, and evaluating it on the test set for different parameter settings.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了我们的训练和测试集，我们准备研究不同参数设置对模型性能的影响。我们将首先对线性模型进行评估。我们将创建一个方便的函数，通过在训练集上训练模型，并在不同的参数设置下在测试集上评估相关性能指标。
- en: We will use the RMSLE evaluation metric, as it is the one used in the Kaggle
    competition with this dataset, and this allows us to compare our model results
    against the competition leaderboard to see how we perform.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用RMSLE评估指标，因为这是Kaggle竞赛中使用的指标，这样可以让我们将模型结果与竞赛排行榜进行比较，看看我们的表现如何。
- en: 'The evaluation function is defined here:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 评估函数在这里定义：
- en: Scala
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: '[PRE37]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Note that in the following sections, you might get slightly different results
    due to some random initialization for SGD. However, your results will be comparable.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在接下来的部分，由于SGD的一些随机初始化，您可能会得到略有不同的结果。但是，您的结果是可以比较的。
- en: Iterations
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迭代
- en: As we saw when evaluating our classification models, we generally expect that
    a model trained with SGD will achieve better performance as the number of iterations
    increases, although the increase in performance will slow down as the number of
    iterations goes above some minimum number. Note that here, we will set the step
    size to 0.01 to better illustrate the impact at higher iteration numbers.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在评估分类模型时看到的，通常情况下，我们期望使用SGD训练的模型随着迭代次数的增加而获得更好的性能，尽管随着迭代次数超过某个最小值，性能的提高将放缓。请注意，在这里，我们将步长设置为0.01，以更好地说明在较高的迭代次数下的影响。
- en: 'We implemented the same in Scala with different values of iterations, as follows:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用不同的迭代次数在Scala中实现了相同的功能，如下所示：
- en: '[PRE38]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'For the scala implementation, we use JfreeChart''s scala version. Implementation
    reaches minimum RMSLE at 20 iterations:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Scala实现，我们使用了JfreeChart的Scala版本。实现在20次迭代时达到最小的RMSLE：
- en: '[PRE39]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The plot for the preceding output is shown as follows:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 前面输出的图如下所示：
- en: '![](img/image_07_007.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_007.png)'
- en: Step size
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步长
- en: 'We will perform a similar analysis for step size in the following code:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下面的代码中对步长执行类似的分析：
- en: Scala
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: '[PRE40]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Output for the previous code is as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '[PRE41]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The plot for the preceding output is shown as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 前面输出的图如下所示：
- en: '![](img/image_07_008.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_008.png)'
- en: Now we can see why we avoided using the default step size when training the
    linear model originally. The default is set to *1.0*, which, in this case, results
    in a `nan` output for the RMSLE metric. This typically means that the SGD model
    has converged to a very poor local minimum in the error function that it is optimizing.
    This can happen when the step size is relatively large, as it is easier for the
    optimization algorithm to overshoot good solutions.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '现在我们可以看到为什么在最初训练线性模型时避免使用默认步长。默认值设置为*1.0*，在这种情况下，导致RMSLE指标输出为`nan`。这通常意味着SGD模型已经收敛到了一个非常糟糕的局部最小值，这是优化算法容易超过好的解决方案的情况。 '
- en: We can also see that for low step sizes and a relatively low number of iterations
    (we used 10 here), the model performance is slightly poorer. However, in the preceding
    *Iterations* section, we saw that for the lower step-size setting, a higher number
    of iterations will generally converge to a better solution.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到，对于较低的步长和相对较少的迭代次数（这里我们使用了10次），模型性能略差。然而，在前面的*迭代*部分，我们看到对于较低的步长设置，更多的迭代次数通常会收敛到更好的解决方案。
- en: Generally speaking, setting step size and number of iterations involves a trade-off.
    A lower step size means that convergence is slower, but slightly more assured.
    However, it requires a higher number of iterations, which is more costly in terms
    of computation and time, particularly, at a very large scale.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，设置步长和迭代次数涉及权衡。较低的步长意味着收敛速度较慢，但稍微更有保证。然而，它需要更多的迭代次数，在计算和时间方面更加昂贵，特别是在非常大规模的情况下。
- en: Selecting the best parameter settings can be an intensive process, which involves
    training a model on many combinations of parameter settings and selecting the
    best outcome. Each instance of model training involves a number of iterations,
    so this process can be very expensive and time consuming when performed on very
    large datasets. Model initialization also has an impact on the results, both on
    reaching global minima, or reaching a sub-optimal local minima in the gradient
    descent graph.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 选择最佳参数设置可能是一个密集的过程，涉及在许多参数设置的组合上训练模型并选择最佳结果。每个模型训练实例都涉及一定数量的迭代，因此当在非常大的数据集上执行时，这个过程可能非常昂贵和耗时。模型初始化也会对结果产生影响，无论是达到全局最小值，还是在梯度下降图中达到次优局部最小值。
- en: L2 regularization
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: L2正则化
- en: In [Chapter 6](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml), *Building a Classification
    Model with Spark*, we saw that regularization has the effect of penalizing model
    complexity in the form of an additional loss term that is a function of the model
    weight vector. L2 regularization penalizes the L2-norm of the weight vector, while
    L1 regularization penalizes the L1-norm.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](7bd5bfd3-6301-49dc-ba28-5d6553b57e01.xhtml)中，*使用Spark构建分类模型*，我们看到正则化会惩罚模型复杂性，形式上是一个额外的损失项，是模型权重向量的函数。L2正则化惩罚权重向量的L2范数，而L1正则化惩罚权重向量的L1范数。
- en: We expect training set performance to deteriorate with increasing regularization,
    as the model cannot fit the dataset well. However, we would also expect some amount
    of regularization that will result in optimal generalization performance as evidenced
    by the best performance on the test set.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预计随着正则化的增加，训练集性能会下降，因为模型无法很好地拟合数据集。然而，我们也期望一定程度的正则化将导致最佳的泛化性能，这可以通过测试集上的最佳性能来证明。
- en: L1 regularization
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: L1正则化
- en: 'We can apply the same approach for differing levels of L1 regularization, as
    follows:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对不同水平的L1正则化应用相同的方法，如下所示：
- en: '[PRE42]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Again, the results are more clearly seen when plotted in the following graph.
    We see that there is a much more subtle decline in RMSLE, and it takes a very
    high value to cause a jump back up. Here, the level of L1 regularization required
    is much higher than that for the L2 form; however, the overall performance is
    poorer:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，当以图表形式绘制时，结果更加清晰。我们看到RMSLE有一个更加微妙的下降，需要一个非常高的值才会导致反弹。在这里，所需的L1正则化水平比L2形式要高得多；然而，整体性能较差：
- en: '[PRE43]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Using L1 regularization can encourage sparse weight vectors. Does this hold
    true in this case? We can find out by examining the number of entries in the weight
    vector that are zero, with increasing levels of regularization.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 使用L1正则化可以鼓励稀疏的权重向量。在这种情况下是否成立？我们可以通过检查权重向量中零的条目数来找出答案，随着正则化水平的增加，零的条目数也在增加。
- en: '[PRE44]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We can see from the results that, as we might expect, the number of zero feature
    weights in the model weight vector increases as greater levels of L1 regularization
    are applied.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果中可以看出，正如我们所预期的，随着L1正则化水平的增加，模型权重向量中零特征权重的数量也在增加。
- en: '[PRE45]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Intercept
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 截距
- en: The final parameter option for the linear model is whether to use an intercept
    or not. An intercept is a constant term that is added to the weight vector, and
    effectively accounts for the mean value of the target variable. If the data is
    already centered or normalized, an intercept is not necessary; however, it often
    does not hurt to use one in any case.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型的最终参数选项是是否使用截距。截距是添加到权重向量的常数项，有效地解释了目标变量的平均值。如果数据已经居中或标准化，则不需要截距；然而，在任何情况下使用截距通常也不会有坏处。
- en: 'We will evaluate the effect of adding an intercept term to the model here:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将评估在模型中添加截距项的影响：
- en: Scala
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: '[PRE46]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The plot for the preceding output is shown as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出的图表如下所示：
- en: '![](img/image_07_009.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_009.png)'
- en: As can be seen in the preceding image, the RMSLE value for intercept=true is
    slightly higher as compared to intercept=false.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，当截距为true时，RMSLE值略高于截距为false时。
- en: The impact of parameter settings for the decision tree
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树参数设置的影响
- en: 'Decision trees provide two main parameters: maximum tree depth and maximum
    number of bins. We will now perform the same evaluation of the effect of parameter
    settings for the decision tree model. Our starting point is to create an evaluation
    function for the model, similar to the one used for the linear regression earlier.
    This function is provided here:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树提供两个主要参数：最大树深度和最大箱数。我们现在将对决策树模型的参数设置效果进行相同的评估。我们的起点是创建一个模型的评估函数，类似于之前用于线性回归的函数。该函数如下所示：
- en: Scala
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: '[PRE47]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Tree depth
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 树深度
- en: We would generally expect performance to increase with more complex trees (that
    is, trees of greater depth). Having a lower tree depth acts as a form of regularization,
    and it might be the case that as with L2 or L1 regularization in linear models,
    there is a tree depth that is optimal with respect to the test set performance.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 通常我们期望性能会随着更复杂的树（即更深的树）而提高。较低的树深度起到一种正则化的作用，可能会出现与线性模型中的L2或L1正则化类似的情况，即存在一个最优的树深度与测试集性能相关。
- en: 'Here, we will try to increase the depth of trees to see what impact they have
    on the test set RMSLE, keeping the number of bins at the default level of `32`:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将尝试增加树的深度，以查看它们对测试集RMSLE的影响，保持箱数的默认水平为`32`：
- en: Scala
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: '[PRE48]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The plot for the preceding output is shown as follows:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出的图表如下所示：
- en: '![](img/image_07_010.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_010.png)'
- en: Maximum bins
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大箱数
- en: Finally, we will perform our evaluation on the impact of setting the number
    of bins for the decision tree. As with the tree depth, a larger number of bins
    should allow the model to become more complex, and might help performance with
    larger feature dimensions. After a certain point, it is unlikely that it will
    help any more, and might, in fact, hinder performance on the test set due to over-fitting.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将评估决策树箱数设置的影响。与树深度一样，更多的箱数应该允许模型变得更复杂，并可能有助于处理更大的特征维度。在一定程度之后，它不太可能再有帮助，实际上可能会由于过拟合而影响测试集的性能。
- en: Scala
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: '[PRE49]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The plot for the preceding output is shown as follows:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出的图表如下所示：
- en: '![](img/image_07_011.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_011.png)'
- en: The impact of parameter settings for the Gradient Boosted Trees
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升树的参数设置影响
- en: Gradient boosted trees have two main parameter iterations and maximum depth.
    We are going to make variations in these and see the effects.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度提升树有两个主要参数：迭代次数和最大深度。我们将对这些进行变化并观察效果。
- en: Iterations
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迭代
- en: Scala
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: '[PRE50]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The plot for the preceding output is shown as follows:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出的图表如下所示：
- en: '![](img/image_07_012.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_012.png)'
- en: MaxBins
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MaxBins
- en: Next we look at how changing the maximum number of bins affects the RMSLE values.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们看一下改变最大箱数如何影响RMSLE值。
- en: Scala
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: Scala
- en: 'Let us look at the sample implementation in Scala. We will calculate the RMSLE
    value for maximum number of bins: `10`, `16`, `32`, and `64`.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下Scala中的示例实现。我们将计算最大箱数为`10`、`16`、`32`和`64`时的RMSLE值。
- en: '[PRE51]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The plot for the preceding output is shown as follows:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出的图表如下所示：
- en: '![](img/image_07_013.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_013.png)'
- en: Summary
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you saw how to use ML Library's linear model, decision tree,
    gradient boosted trees, Ridge Regression, and the isotonic regression functionality
    in Scala within the context of regression models. We explored categorical feature
    extraction, and the impact of applying transformations to the target variable
    in a regression problem. Finally, we implemented various performance-evaluation
    metrics, and used them to implement a cross-validation exercise that explores
    the impact of the various parameter settings available in both linear models and
    decision trees on test set model performance.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您看到了如何在回归模型的背景下使用ML库的线性模型、决策树、梯度提升树、岭回归和等温回归功能。我们探讨了分类特征提取，以及在回归问题中应用转换对目标变量的影响。最后，我们实现了各种性能评估指标，并使用它们来实施交叉验证练习，探讨线性模型和决策树中各种参数设置对测试集模型性能的影响。
- en: In the next chapter, we will cover a different approach to machine learning,
    that is, unsupervised learning, specifically in clustering models.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍一种不同的机器学习方法，即无监督学习，特别是聚类模型。
