- en: Building a Recommendation Engine with Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark构建推荐引擎
- en: Now that you have learned the basics of data processing and feature extraction,
    we will move on to explore individual machine learning models in detail, starting
    with recommendation engines.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经学会了数据处理和特征提取的基础知识，我们将继续详细探讨各个机器学习模型，首先是推荐引擎。
- en: Recommendation engines are probably among the best types of machine learning
    models known to the general public. Even if people do not know exactly what a
    recommendation engine is, they have most likely experienced one through the use
    of popular websites, such as Amazon, Netflix, YouTube, Twitter, LinkedIn, and
    Facebook. Recommendations are a core part of all these businesses, and in some
    cases, they drive significant percentages of their revenue.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎可能是公众所知的最好的机器学习模型之一。即使人们不确切知道推荐引擎是什么，他们很可能通过使用流行网站（如亚马逊、Netflix、YouTube、Twitter、LinkedIn和Facebook）来体验过。推荐是所有这些业务的核心部分，在某些情况下，推荐引擎推动了它们相当大比例的收入。
- en: The idea behind recommendation engines is to predict what people might like
    and to uncover relationships between items to aid in the discovery process; in
    this way, they are similar and, in fact, often complementary to search engines,
    which also play a role in discovery. However, unlike search engines, recommendation
    engines try to present people with relevant content that they did not necessarily
    search for or that they might have not even heard of.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎的理念是预测人们可能喜欢什么，并揭示项目之间的关系，以帮助发现过程；在这方面，它们与搜索引擎相似，实际上通常是互补的，后者也在发现中发挥作用。然而，与搜索引擎不同，推荐引擎试图向人们呈现他们并非必然搜索或甚至可能从未听说过的相关内容。
- en: Typically, a recommendation engine tries to model the connections between users
    and some type of item. In our movie stream scenario from [Chapter 3](fbb4c025-a861-4b26-8284-a8ae5f0f0d88.xhtml),
    *Designing a Machine Learning System*, for example, we can use a recommendation
    engine to show our users movies that they might enjoy. If we can do this well,
    we could keep our users engaged using our service, which is good for both our
    users and us. Similarly, if we can do a good job of showing our users movies related
    to a given movie, we could aid in discovery and navigation on our site, again
    improving our users' experience, engagement, and the relevance of our content
    to them.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，推荐引擎试图建模用户和某种类型项目之间的连接。例如，在我们的电影流场景中，我们可以使用推荐引擎向用户展示他们可能喜欢的电影。如果我们能做到这一点，我们可以通过我们的服务保持用户的参与，这对我们的用户和我们都是有利的。同样，如果我们能够很好地向用户展示与给定电影相关的电影，我们可以帮助他们在我们的网站上发现和导航，从而提高我们用户的体验、参与度和我们内容对他们的相关性。
- en: However, recommendation engines are not limited to movies, books, or products.
    The techniques we will explore in this chapter can be applied to just about any
    user-to-item relationship as well as user-to-user connections, such as those found
    on social networks, allowing us to make recommendations, such as people you may
    know or who to follow.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，推荐引擎不仅限于电影、书籍或产品。本章将探讨的技术可以应用于几乎任何用户对项目的关系，以及用户对用户的连接，比如社交网络上的连接，使我们能够做出推荐，比如你可能认识的人或者应该关注谁。
- en: 'Recommendation engines are most effective in two general scenarios, which are
    not mutually exclusive. They are explained here:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎在两种一般情况下最有效，它们并不是互斥的。这里进行了解释：
- en: '**Large number of available options for users**: When there are a very large
    number of available items, it becomes increasingly difficult for the user to find
    something they want. Searching can help when the user knows what they are looking
    for, but often, the right item might be something previously unknown to them.
    In this case, being recommended relevant items that the user may not already know
    about can help them discover new items.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户可用选项的大量**：当有大量可用项目时，用户要找到他们想要的东西变得越来越困难。当用户知道他们在寻找什么时，搜索可以帮助，但通常，合适的项目可能是他们以前不知道的东西。在这种情况下，被推荐相关的用户可能不知道的项目可以帮助他们发现新项目。'
- en: '**A significant degree of personal taste involved**: When personal taste plays
    a large role in selection, recommendation models, which often utilize a wisdom-of-the-crowd
    approach, can be helpful in discovering items based on the behavior of others
    that have similar taste profiles.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**涉及个人口味的显著程度**：当个人口味在选择中起到重要作用时，推荐模型（通常利用众人的智慧方法）可以帮助根据具有相似口味配置的其他人的行为发现项目。'
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introduce the various types of recommendation engines
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍各种类型的推荐引擎
- en: Build a recommendation model using data about user preferences
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用关于用户偏好的数据构建推荐模型
- en: Use the trained model to compute recommendations for a given user as well compute
    similar items for a given item, that is, related items
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用训练好的模型为特定用户计算推荐，同时为给定项目计算类似项目，即相关项目
- en: Apply standard evaluation metrics to the model that we created to measure how
    well it performs in terms of predictive capability
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用标准评估指标来衡量我们创建的模型在预测能力方面的表现如何
- en: Types of recommendation models
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐模型的类型
- en: 'Recommender systems are widely studied, and there are many approaches used,
    but there are two that are probably most prevalent: content-based filtering and
    collaborative filtering. Recently, other approaches, such as ranking models, have
    also gained in popularity. In practice, many approaches are hybrids, incorporating
    elements of many different methods into a model or combination of models.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统得到了广泛研究，有许多不同的方法，但其中两种可能最为普遍：基于内容的过滤和协同过滤。最近，其他方法，如排名模型，也变得越来越受欢迎。在实践中，许多方法是混合的，将许多不同方法的元素纳入模型或模型组合。
- en: Content-based filtering
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于内容的过滤
- en: Content-based methods try to use the content or attributes of an item, together
    with some notion of similarity between two pieces of content, to generate items
    similar to a given item. These attributes are often textual content, such as titles,
    names, tags, and other metadata attached to an item, or in the case of media,
    they could include other features of the item, such as attributes extracted from
    audio and video content.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内容的方法试图使用项目的内容或属性，以及两个内容之间的相似性概念，来生成与给定项目相似的项目。这些属性通常是文本内容，如标题、名称、标签和附加到项目的其他元数据，或者在媒体的情况下，它们可能包括从音频和视频内容中提取的项目的其他特征。
- en: In a similar manner, user recommendations can be generated based on attributes
    of users or user profiles, which are then matched to item attributes using the
    same measure of similarity. For example, a user can be represented by the combined
    attributes of the items they have interacted with. This becomes their user profile,
    which is then compared to item attributes to find items that match the user profile.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以类似的方式，用户推荐可以基于用户或用户资料的属性生成，然后使用相似度的度量来将其与项目属性进行匹配。例如，用户可以由他们互动过的项目的组合属性来表示。这就成为了他们的用户资料，然后将其与项目属性进行比较，以找到与用户资料匹配的项目。
- en: 'These are a few examples of creating a profile for each user or item to characterize
    its nature:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是为每个用户或项目创建描述其性质的资料的几个例子：
- en: Movie profile includes attributes regarding actors, genre, popularity, and so
    on.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影资料包括有关演员、流派、受欢迎程度等的属性。
- en: User profile includes demographic information or answers given to specific questions.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户资料包括人口统计信息或对特定问题的回答。
- en: Content filtering uses profiles to associate users or items.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内容过滤使用资料来关联用户或项目。
- en: Compute similarity of a new item with the user profile based on keyword overlap
    example using Dice coefficient. There are other approaches as well.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于关键词重叠的新项目与用户资料的相似度使用Dice系数进行计算。还有其他方法。
- en: Collaborative filtering
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协同过滤
- en: Collaborative filtering relies only on past behavior, such as previous ratings
    or transactions. The idea behind this is the notion of similarity.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤仅依赖于过去的行为，如先前的评分或交易。其背后的思想是相似性的概念。
- en: The basic idea is that the user gives ratings to items, implicitly or explicitly.
    Users who had a similar taste in the past will have a similar taste in the future.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 基本思想是用户对项目进行评分，隐式或显式地。过去口味相似的用户将来口味也会相似。
- en: In a user-based approach, if two users have exhibited similar preferences, that
    is, patterns of interacting with the same items in broadly the same way, then
    we would assume that they are similar to each other in terms of taste. To generate
    recommendations for unknown items for a given user, we can use the known preferences
    of other users that exhibit similar behavior. We can do this by selecting a set
    of similar users and computing some form of combined score based on the items
    they have shown a preference for. The overall logic is that if others have tastes
    similar to a set of items, these items would tend to be good candidates for recommendation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于用户的方法中，如果两个用户表现出类似的偏好，即以广泛相同方式与相同项目互动的模式，那么我们会假设他们在口味上相似。为了为给定用户生成未知项目的推荐，我们可以使用表现出类似行为的其他用户的已知偏好。我们可以通过选择一组相似的用户并计算基于他们对项目的偏好的某种形式的综合评分来实现这一点。总体逻辑是，如果其他人对一组项目有类似的口味，这些项目很可能是推荐的良好候选项。
- en: We can also take an item-based approach that computes some measure of similarity
    between items. This is usually based on the existing user-item preferences or
    ratings. Items that tend to be rated the same by similar users will be classed
    as similar under this approach. Once we have these similarities, we can represent
    a user in terms of the items they have interacted with and find items that are
    similar to these known items, which we can then recommend to the user. Again,
    a set of items similar to the known items is used to generate a combined score
    to estimate for an unknown item.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以采用基于项目的方法，计算项目之间的相似度。这通常基于现有的用户-项目偏好或评分。那些倾向于被类似用户评价的项目在这种方法下会被归类为相似的。一旦我们有了这些相似性，我们可以根据用户与其互动的项目来表示用户，并找到与这些已知项目相似的项目，然后推荐给用户。同样，一组与已知项目相似的项目被用来生成一个综合评分，以估计未知项目。
- en: The user- and item-based approaches are usually referred to as nearest-neighbor
    models, since the estimated scores are computed based on the set of most similar
    users or items, that is, their neighbors.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 基于用户和基于项目的方法通常被称为最近邻模型，因为估计的分数是基于最相似的用户或项目集合计算的，即它们的邻居。
- en: 'A traditional collaborative filtering algorithm represents a user as an N-dimensional
    vector of items, where N is the number of distinct items. The components of the
    vector are positive or negative items. To calculate for best items, the algorithm
    typically multiplies the vector components by the inverse frequency, that is,
    the inverse of the number of users who have rated the item, making less well-known
    items much more relevant. For most users, this vector is extremely sparse. The
    algorithm generates recommendations based on a few users who are most similar
    to the user. It can measure the similarity of two users, *X* and *Y*, using a
    common method called cosine of the angle between the two vectors:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的协同过滤算法将用户表示为项目的N维向量，其中N是不同项目的数量。向量的分量是正面或负面项目。为了计算最佳项目，该算法通常将向量分量乘以频率的倒数，即评价该项目的用户数量的倒数，使得不太知名的项目更加相关。对于大多数用户来说，这个向量非常稀疏。该算法基于与用户最相似的少数用户生成推荐。它可以使用一种称为余弦相似度的常见方法来衡量两个用户*X*和*Y*的相似度，即两个向量之间的夹角的余弦值。
- en: '![](img/image_05_001.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_001.png)'
- en: Finally, there are many model-based methods that attempt to model the user-item
    preferences themselves, so that new preferences can be estimated directly by applying
    the model to unknown user-item combinations.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，有许多基于模型的方法试图对用户-物品偏好本身进行建模，以便通过将模型应用于未知的用户-物品组合来直接估计新的偏好。
- en: 'Two primary modeling methods for collaborative filtering are as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤的两种主要建模方法如下：
- en: '**Neighborhood methods**:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**邻域方法**：'
- en: The user-oriented approach is centered on computing the relationships between
    users
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以用户为中心的方法集中在计算用户之间的关系
- en: The item-oriented approach evaluates a user's preference for an item based on
    ratings of a neighboring item by the same user
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以物品为中心的方法根据同一用户对相邻物品的评分来评估用户对物品的偏好
- en: Use centered cosine distance for similarity calculation, which is also known
    as **Pearson correlation coefficients**
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用居中余弦距离进行相似性计算，也称为**皮尔逊相关系数**
- en: '**Latent factor models**:'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在因子模型**：'
- en: The **Latent factor model** (**LFM**) approach explains ratings by characterizing
    both users and items to find the hidden latent features
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在因子模型**（LFM）方法通过表征用户和物品来解释评分，以找到隐藏的潜在特征'
- en: In movies, features such as action or drama, type of actors, and so on, are
    the latent factors
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在电影中，诸如动作或戏剧、演员类型等都是潜在因子
- en: In users, features such as liking the score for movie is an example of a latent
    factor
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在用户中，喜欢电影评分的特征是潜在因子的一个例子
- en: Types are neural networks, latent dirichlet allocation, matrix factorization
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类型包括神经网络、潜在狄利克雷分配、矩阵分解
- en: In the next section, we will discuss Matrix Factorization models.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论矩阵分解模型。
- en: Matrix factorization
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 矩阵分解
- en: Since Spark's recommendation models currently only include an implementation
    of Matrix factorization, we will focus our attention on this class of models.
    This focus is with good reason; however, these types of models have consistently
    been shown to perform extremely well in collaborative filtering and were among
    the best models in well-known competitions, such as the Netflix prize.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Spark的推荐模型目前只包括矩阵分解的实现，因此我们将把注意力集中在这类模型上。这种关注是有充分理由的；然而，这些类型的模型在协同过滤中一直表现出色，并且在著名的比赛中，如Netflix奖，它们一直是最佳模型之一。
- en: 'Matrix Factorization assumes that:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵分解假设：
- en: Each user can be described by n attributes or features. For example, feature
    one might be a number that says how much each user likes action movies.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个用户可以用n个属性或特征来描述。例如，特征一可能是一个数字，表示每个用户对动作电影的喜欢程度。
- en: Each item can be described by a set of n attributes or features. To connect
    with the preceding example, feature one for the movie might be a number that says
    how close the movie is to pure action.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个物品可以用一组n个属性或特征来描述。与前面的例子相连，电影的特征一可能是一个数字，表示电影与纯动作的接近程度。
- en: If we multiply each feature of the user by the corresponding feature of the
    item and add everything together, this will be a good approximation for the rating
    the user would give that item.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们将用户的每个特征乘以物品的相应特征并将所有内容相加，这将是用户给出该物品评分的良好近似。
- en: For more information on and a brief overview of the performance of the best
    algorithms for the Netflix prize, see [http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html](http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Netflix奖的最佳算法的更多信息和简要概述，请参阅[http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html](http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html)。
- en: Explicit matrix factorization
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 显式矩阵分解
- en: When we deal with data that consists of preferences of users, which are provided
    by the users themselves, we refer to explicit preference data. This includes,
    for example, ratings, thumbs up, likes, and so on that are given by users to items.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们处理由用户自己提供的用户偏好数据时，我们称之为显式偏好数据。这包括用户对物品的评分、点赞、喜欢等。
- en: We can take these ratings and form a two-dimensional matrix with users as rows
    and items as columns. Each entry represents a rating given by a user to a certain
    item. Since, in most cases, each user has only interacted with a relatively small
    set of items, this matrix has only a few non-zero entries, that is, it is very
    sparse.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些评分组成一个二维矩阵，以用户为行，物品为列。每个条目表示用户对某个物品的评分。由于在大多数情况下，每个用户只与相对较小的一组物品进行了交互，因此该矩阵只有少数非零条目，即非常稀疏。
- en: 'As a simple example, let''s assume that we have the following user ratings
    for a set of movies:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 举个简单的例子，假设我们有一组电影的以下用户评分：
- en: 'Tom: Star Wars, 5'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 'Tom: 星球大战，5'
- en: 'Jane: Titanic, 4'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 'Jane: 泰坦尼克号，4'
- en: 'Bill: Batman, 3'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 'Bill: 蝙蝠侠，3'
- en: 'Jane: Star Wars, 2'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 'Jane: 星球大战，2'
- en: 'Bill: Titanic, 3'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 'Bill: 泰坦尼克号，3'
- en: 'We will form the following ratings matrix:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将形成以下评分矩阵：
- en: '![](img/image_05_002.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_002.png)'
- en: A simple movie-rating matrix
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的电影评分矩阵
- en: 'Matrix Factorization (or matrix completion) attempts to directly model this
    user-item matrix by representing it as a product of two smaller matrices of lower
    dimension. Thus, it is a dimensionality-reduction technique. If we have **U**
    users and **I** items, then our user-item matrix is of dimension U x I and might
    look something like the one shown in the following diagram:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵分解（或矩阵完成）试图直接对用户-物品矩阵进行建模，将其表示为较低维度的两个较小矩阵的乘积。因此，这是一种降维技术。如果我们有**U**个用户和**I**个物品，那么我们的用户-物品矩阵的维度为U
    x I，可能看起来像下图所示的矩阵：
- en: '![](img/image_05_003.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_003.png)'
- en: A sparse ratings matrix
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个稀疏的评分矩阵
- en: 'If we want to find a lower dimension (low-rank) approximation to our user-item
    matrix with the dimension **k**, we would end up with two matrices: one for users
    of size U x k and one for items of size I x k; these are known as factor matrices.
    If we multiply these two factor matrices, we will reconstruct an approximate version
    of the original ratings matrix. Note that while the original ratings matrix is
    typically very sparse, each factor matrix is dense, as shown in the following
    diagram:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要找到一个低维（低秩）的用户-物品矩阵的近似值，维度为**k**，我们将得到两个矩阵：一个是用户大小为U x k的矩阵，另一个是物品大小为I
    x k的矩阵；这些被称为因子矩阵。如果我们将这两个因子矩阵相乘，我们将重构原始评分矩阵的近似版本。请注意，原始评分矩阵通常非常稀疏，而每个因子矩阵是密集的，如下图所示：
- en: '![](img/image_05_004.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_004.png)'
- en: The user- and item-factor matrices
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 用户和物品因子矩阵
- en: These models are often also called latent feature models, as we are trying to
    discover some form of hidden features (which are represented by the factor matrices)
    that account for the structure of behavior inherent in the user-item rating matrix.
    While the latent features or factors are not directly interpretable, they might,
    perhaps, represent things such as the tendency of a user to like movies from a
    certain director, genre, style, or group of actors.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型通常也被称为潜在特征模型，因为我们试图发现一些隐藏特征（由因子矩阵表示），这些特征解释了用户-物品评分矩阵中固有的行为结构。虽然潜在特征或因子通常不是直接可解释的，但它们可能代表一些东西，比如用户倾向于喜欢某个导演、类型、风格或一组演员的电影。
- en: 'As we are directly modeling the user-item matrix, the prediction in these models
    is relatively straightforward: to compute a predicted rating for a user and item,
    we will compute the vector dot product between the relevant row of the user-factor
    matrix, that is, the user''s factor vector, and the relevant row of the item-factor
    matrix, that is, the item''s factor vector.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们直接对用户-物品矩阵进行建模，因此这些模型中的预测相对简单：要计算用户和物品的预测评分，我们将计算用户因子矩阵的相关行（即用户的因子向量）与物品因子矩阵的相关行（即物品的因子向量）之间的向量点积。
- en: 'This is illustrated with the highlighted vectors in the following diagram:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这在下图中突出显示的向量中得到了说明：
- en: '![](img/image_05_005.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_005.png)'
- en: Computing recommendations from user- and item-factor vectors
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户和物品因子向量计算推荐
- en: 'To find out the similarity between two items, we can use the same measures
    of similarity as we would use in the nearest-neighbor models, except that we can
    use the factor vectors directly by computing the similarity between two item-factor
    vectors, as illustrated in the following diagram:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要找出两个物品之间的相似性，我们可以使用与最近邻模型中使用的相似性度量相同的度量，只是我们可以直接使用因子向量，通过计算两个物品因子向量之间的相似性，如下图所示：
- en: '![](img/image_05_006.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_006.png)'
- en: Computing similarity with item-factor vectors
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用物品因子向量计算相似性
- en: The benefit of factorization models is the relative ease of computing recommendations
    once the model is created. However, for very large user and item sets, this can
    become a challenge, as it requires storage and computation across potentially
    many millions of user- and item-factor vectors. Another advantage, as mentioned
    earlier, is that they tend to offer very good performance.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 因子化模型的好处在于一旦模型创建完成，推荐的计算相对容易。然而，对于非常庞大的用户和物品集，这可能会成为一个挑战，因为它需要跨可能有数百万用户和物品因子向量的存储和计算。另一个优势，正如前面提到的，是它们往往提供非常好的性能。
- en: Projects such as Oryx ([https://github.com/OryxProject/oryx](https://github.com/OryxProject/oryx))
    and Prediction.io ([https://github.com/PredictionIO/PredictionIO](https://github.com/PredictionIO/PredictionIO))
    focus on model serving for large-scale models, including recommenders based on
    matrix factorization.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Oryx（[https://github.com/OryxProject/oryx](https://github.com/OryxProject/oryx)）和Prediction.io（[https://github.com/PredictionIO/PredictionIO](https://github.com/PredictionIO/PredictionIO)）等项目专注于为大规模模型提供模型服务，包括基于矩阵因子分解的推荐系统。
- en: On the down side, factorization models are relatively more complex to understand
    and interpret compared to nearest-neighbor models and are often more computationally
    intensive during the model's training phase.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 不足之处在于，与最近邻模型相比，因子化模型相对更复杂，而且在模型的训练阶段通常需要更多的计算资源。
- en: Implicit Matrix Factorization
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 隐式矩阵因子分解
- en: So far, we have dealt with explicit preferences such as ratings. However, much
    of the preference data that we might be able to collect is implicit feedback,
    where the preferences between a user and item are not given to us, but are, instead,
    implied from the interactions they might have with an item. Examples include binary
    data, such as whether a user viewed a movie, whether they purchased a product,
    and so on, as well as count data, such as the number of times a user watched a
    movie.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经处理了诸如评分之类的显式偏好。然而，我们可能能够收集到的许多偏好数据是隐式反馈，即用户和物品之间的偏好并未直接给出，而是从他们可能与物品的互动中暗示出来。例如，二进制数据，比如用户是否观看了一部电影，是否购买了一个产品，以及计数数据，比如用户观看一部电影的次数。
- en: 'There are many different approaches to deal with implicit data. MLlib implements
    a particular approach that treats the input rating matrix as two matrices: a binary
    preference matrix, **P**, and a matrix of confidence weights, **C**.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 处理隐式数据有许多不同的方法。MLlib实现了一种特定的方法，将输入评分矩阵视为两个矩阵：一个是二进制偏好矩阵**P**，另一个是置信权重矩阵**C**。
- en: For example, let's assume that the user-movie ratings we saw previously were,
    in fact, the number of times each user had viewed that movie. The two matrices
    would look something like the ones shown in the following screenshot. Here, the
    matrix **P** informs us that a movie was viewed by a user, and the matrix **C**
    represents the confidence weighting, in the form of the view counts--generally,
    the more a user has watched a movie, the higher the confidence that they actually
    like it.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们之前看到的用户-电影评分实际上是每个用户观看该电影的次数。这两个矩阵看起来可能像以下截图中显示的矩阵。在这里，矩阵**P**告诉我们电影被用户观看了，矩阵**C**代表置信度加权，以观看次数的形式--通常情况下，用户观看电影的次数越多，他们实际上喜欢它的置信度就越高。
- en: '![](img/image_05_007.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_007.png)'
- en: Representation of an implicit preference and confidence matrix
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 隐式偏好和置信度矩阵的表示
- en: The implicit model still creates a user- and item-factor matrix. In this case,
    however, the matrix that the model is attempting to approximate is not the overall
    ratings matrix, but the preference matrix **P**. If we compute a recommendation
    by calculating the dot product of a user- and item-factor vector, the score will
    not be an estimate of a rating directly. It will rather be an estimate of the
    preference of a user for an item; although, not strictly between 0 and 1, these
    scores will generally be fairly close to a scale of 0 to 1.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 隐式模型仍然创建用户和物品因子矩阵。然而，在这种情况下，模型试图逼近的矩阵不是整体评分矩阵，而是偏好矩阵**P**。如果我们通过计算用户和物品因子向量的点积来计算推荐，得分将不是对评分的直接估计。它将更多地是对用户对物品的偏好的估计；尽管不严格在0到1之间，这些得分通常会相当接近0到1的范围。
- en: In a nutshell, Matrix Factorization methods characterize both users and items
    by vectors of factors inferred from a rating pattern. High confidence or correspondence
    between user and item factors leads to a recommendation. Two main data types are
    Explicit feedback, such as ratings (represented by sparse matrix), and Implicit
    feedback, such as purchase history, search patterns, browse history, and clickstream
    data (represented by dense matrix).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，矩阵分解方法通过从评分模式中推断出的因子向量来表征用户和物品。用户和物品因子之间的高置信度或对应关系会导致推荐。两种主要的数据类型是显式反馈，如评分（由稀疏矩阵表示），和隐式反馈，如购买历史、搜索模式、浏览历史和点击流数据（由密集矩阵表示）。
- en: Basic model for Matrix Factorization
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 矩阵分解的基本模型
- en: Both users and items are mapped to a joint latent factor space of dimensionality
    *f*, where user-item interaction is modeled as inner product in this space. Item
    *i* is associated with vector *q* where *q* measures the extent to which the item
    possesses the latent factors and User *u* is associated with vector *p*, where
    *p* measures the extent of interest the user has in the item.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 用户和物品都被映射到维度为*f*的联合潜在因子空间中，用户-物品交互在该空间中被建模为内积。物品*i*与向量*q*相关联，其中*q*衡量物品具有潜在因子的程度，用户*u*与向量*p*相关联，其中*p*衡量用户对物品的兴趣程度。
- en: The dot product ![](img/image_6.png) between *q* and *p* captures the interaction
    between user u and item I, that is, a user's interest in an item. Key to model
    is finding vectors *q* and *p*.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*q*和*p*之间的点积![](img/image_6.png)捕捉了用户*u*和物品*I*之间的交互，即用户对物品的兴趣。模型的关键是找到向量*q*和*p*。'
- en: To design the model, get latent relationship between users and items. Produce
    a low dimensional representation of rating matrix. Perform SVD on thye rating
    matrix to get *Q*, *S*, *P*. Reduce matrix *S* to dimension *k* to get *q* and
    *p*.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 设计模型，获取用户和物品之间的潜在关系。生成评分矩阵的低维表示。对评分矩阵执行SVD以获取*Q*、*S*、*P*。将矩阵*S*降维到*k*维以获取*q*和*p*。
- en: '**![](img/Screen-Shot-2017-04-27-at-3.55.57-PM.png)**'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/Screen-Shot-2017-04-27-at-3.55.57-PM.png)**'
- en: 'Now, calculate the recommendations:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，计算推荐：
- en: '![](img/Screen-Shot-2017-04-27-at-3.56.04-PM.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Screen-Shot-2017-04-27-at-3.56.04-PM.png)'
- en: Optimization function (on observed ratings) is shown in the following diagram;
    learn the latent factor vectors *q* and *p*, the system minimizes the regularized
    squared error on set of ratings.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 优化函数（对观察到的评分）如下图所示；学习潜在因子向量*q*和*p*，系统最小化一组评分的正则化平方误差。
- en: '![](img/Screen-Shot-2017-04-27-at-3.56.08-PM.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Screen-Shot-2017-04-27-at-3.56.08-PM.png)'
- en: Learning algorithms used are **stochastic gradient descent** (**SGD**) or **alternating
    least squares** (**ALS**).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的学习算法是**随机梯度下降**（**SGD**）或**交替最小二乘**（**ALS**）。
- en: Alternating least squares
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交替最小二乘
- en: ALS is an optimization technique to solve Matrix Factorization problems; this
    technique is powerful, achieves good performance, and has proven to be relatively
    easy to implement in a parallel fashion. Hence, it is well suited for platforms
    such as Spark. At the time of writing this book, it is the only recommendation
    model implemented in Spark ML.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ALS是解决矩阵分解问题的优化技术；这种技术功能强大，性能良好，并且已被证明相对容易在并行环境中实现。因此，它非常适合像Spark这样的平台。在撰写本书时，它是Spark
    ML中唯一实现的推荐模型。
- en: 'ALS works by iteratively solving a series of least squares regression problems.
    In each iteration, one of the user- or item-factor matrices is treated as fixed,
    while the other one is updated using the fixed factor and the rating data. Then,
    the factor matrix that was solved for is, in turn, treated as fixed, while the
    other one is updated. This process continues until the model has converged (or
    for a fixed number of iterations):'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ALS通过迭代地解决一系列最小二乘回归问题来工作。在每次迭代中，用户或物品因子矩阵中的一个被视为固定，而另一个则使用固定因子和评分数据进行更新。然后，解决的因子矩阵依次被视为固定，而另一个被更新。这个过程持续进行直到模型收敛（或者达到固定次数的迭代）：
- en: '![](img/Screen-Shot-2017-04-27-at-3.56.08-PM.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Screen-Shot-2017-04-27-at-3.56.08-PM.png)'
- en: Objective function is not convex since both *q* and *p* are not known, but if
    we fix one of the unknown optimization can be solved. ALS rotates between fixing
    *q*'s and *p*'s as explained earlier.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 目标函数不是凸的，因为*q*和*p*都是未知的，但是如果我们固定其中一个未知数，优化可以被解决。如前所述，ALS在固定*q*和*p*之间交替。
- en: Spark's documentation for collaborative filtering contains references to the
    papers that underlie the ALS algorithms implemented each component of explicit
    and implicit data. You can view the documentation at http://spark.apache.org/docs/latest/ml-collaborative-filtering.html.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的协同过滤文档包含了支持ALS算法实现显式和隐式数据的论文的引用。您可以在http://spark.apache.org/docs/latest/ml-collaborative-filtering.html上查看文档。
- en: The following code explains how to implement ALS algorithm from scratch.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码解释了如何从头开始实现ALS算法。
- en: 'Let''s take an example and show how it is implemented and look at a real matrix
    of 3 movies and 3 users:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举个例子，展示它是如何实现的，并看一个真实的3部电影和3个用户的矩阵：
- en: '[PRE0]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The first iteration of movie matrix is chosen randomly:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 电影矩阵的第一次迭代是随机选择的：
- en: '[PRE1]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The first iteration of user matrix is chosen randomly:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 用户矩阵的第一次迭代是随机选择的：
- en: '[PRE2]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Pickup the first row of user matrix `us`, Calculate `XtX` (matrix) and `Xty`
    (a vector) as shown in the following code:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 挑选用户矩阵`us`的第一行，计算`XtX`（矩阵）和`Xty`（向量），如下面的代码所示：
- en: '[PRE3]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: j:0
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: j:0
- en: '[PRE4]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Pickup the second row of user matrix `us`, and add values to `XtX` (matrix)
    and `Xty` (a vector) as shown in the folowing code:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 挑选用户矩阵`us`的第二行，并按照下面的代码向`XtX`（矩阵）和`Xty`（向量）添加值：
- en: j:1
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: j:1
- en: '[PRE5]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: j:2
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: j:2
- en: '[PRE6]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Calculate value of first row of `ms` (movie matrix using Cholesky decomposition
    of `XtX` and `XtY`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 计算`ms`（使用`XtX`和`XtY`的Cholesky分解的电影矩阵）的第一行的值：
- en: '[PRE7]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After going through each row of us and following the steps above we arrive
    at:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 经过我们每一行的步骤后，我们得到了：
- en: '[PRE8]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Listing the following source code for the mathematical implementation explained
    previously:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 列出了先前解释的数学实现的源代码：
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You can find the code listing at: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/AlternatingLeastSquares.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/AlternatingLeastSquares.scala)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下网址找到代码清单：[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/AlternatingLeastSquares.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/AlternatingLeastSquares.scala)
- en: Extracting the right features from your data
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据中提取正确的特征
- en: In this section, we will use explicit rating data, without additional user,
    item metadata, or other information related to the user-item interactions. Hence,
    the features that we need as inputs are simply the user IDs, movie IDs, and the
    ratings assigned to each user and movie pair.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将使用显式评分数据，没有额外的用户、物品元数据或其他与用户-物品交互相关的信息。因此，我们需要的输入特征只是用户ID、电影ID和分配给每个用户和电影对的评分。
- en: Extracting features from the MovieLens 100k dataset
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从MovieLens 100k数据集中提取特征
- en: In this example, we will use the same MovieLens dataset that we used in the
    previous chapter. Use the directory in which you placed the MovieLens 100k dataset
    as the input path in the following code.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用在上一章中使用的相同的MovieLens数据集。在下面的代码中，将使用放置MovieLens 100k数据集的目录作为输入路径。
- en: 'First, let''s inspect the raw ratings dataset:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们检查原始评分数据集：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can find the code listing at: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下网址找到代码清单：[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala)
- en: 'You will see an output similar to these lines of code:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到类似于以下代码行的输出：
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Recall that this dataset (mapped to the `Rating` class using case) consisted
    of the `userID`, `movieID`, `rating`, and `timestamp` fields separated by a tab
    (`"t"`) character. We don''t need the time when the rating was made to train our
    model, so in the following code snippet we simply extracted the first three fields:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这个数据集（使用案例映射到`Rating`类）由`userID`、`movieID`、`rating`和`timestamp`字段组成，由制表符（`"t"`）字符分隔。我们不需要训练模型时的评分时间，所以下面的代码片段中我们只是提取了前三个字段：
- en: '[PRE12]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can find the code listing at: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下网址找到代码清单：[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala)
- en: We will first split each record on the `"t"` character, which gives us a `String[]`
    array. We will then use case class to map and keep only the first `3` elements
    of the array, which correspond to `userID`, `movieID`, and `rating`, respectively.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先将每条记录分割为`"t"`字符，这样我们就得到了一个`String[]`数组。然后我们将使用案例类来映射并保留数组的前`3`个元素，分别对应`userID`、`movieID`和`rating`。
- en: Training the recommendation model
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练推荐模型
- en: Once we have extracted these simple features from our raw data, we are ready
    to proceed with model training; ML takes care of this for us. All we have to do
    is provide the correctly-parsed input dataset we just created as well as our chosen
    model parameters.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们从原始数据中提取了这些简单的特征，我们就可以继续进行模型训练；ML会为我们处理这些。我们所要做的就是提供正确解析的输入数据集以及我们选择的模型参数。
- en: 'Split the dataset in to training and testing sets with ratio 80:20, as shown
    in the following lines of code:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集分割为训练集和测试集，比例为80:20，如下面的代码所示：
- en: '[PRE13]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You can find the code listing at: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下网址找到代码清单：[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala)
- en: 'You will see the following output:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下输出：
- en: '[PRE14]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Training a model on the MovieLens 100k dataset
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在MovieLens 100k数据集上训练模型
- en: 'We''re now ready to train our model! The other inputs required for our model
    are as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备训练我们的模型！我们模型所需的其他输入如下：
- en: '`rank`: This refers to the number of factors in our ALS model, that is, the
    number of hidden features in our low-rank approximation matrices. Generally, the
    greater the number of factors, the better, but this has a direct impact on memory
    usage, both for computation and to store models for serving, particularly for
    large numbers of users or items. Hence, this is often a trade-off in real-world
    use cases. It also impacts the amount of training data required.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rank`：这指的是我们ALS模型中的因子数量，也就是我们低秩近似矩阵中的隐藏特征数量。通常来说，因子数量越多越好，但这直接影响内存使用，无论是计算还是存储模型用于服务，特别是对于大量用户或物品。因此，在实际应用中，这通常是一个权衡。它还影响所需的训练数据量。'
- en: A rank in the range of 10 to 200 is usually reasonable.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在10到200的范围内选择一个秩通常是合理的。
- en: '`iterations`: This refers to the number of iterations to run. While each iteration
    in ALS is guaranteed to decrease the reconstruction error of the ratings matrix,
    ALS models will converge to a reasonably good solution after relatively little
    iterations. So, we don''t need to run too many iterations in most cases--around
    10 is often a good default.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iterations`：这是指要运行的迭代次数。虽然ALS中的每次迭代都保证会减少评级矩阵的重构误差，但ALS模型在相对较少的迭代后就会收敛到一个相当不错的解决方案。因此，在大多数情况下，我们不需要运行太多次迭代--大约10次通常是一个很好的默认值。'
- en: '`numBlocks`: This is the number of blocks the users and items will be partitioned
    into, to parallelize computation (defaults to 10). The number depends on the number
    of cluster nodes as well as how data is partitioned.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numBlocks`：这是用户和物品将被分区成的块的数量，以并行化计算（默认为10）。该数字取决于集群节点的数量以及数据的分区方式。'
- en: '`regParam`: This specifies the regularization parameter in ALS (defaults to
    1.0). The constant *λ* is called the regularization parameter and essentially
    penalizes the components of the user and item matrices if they get too large (in
    magnitude). This is important for numerical stability, and some kind of regularization
    is almost always used.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regParam`：这指定ALS中的正则化参数（默认为1.0）。常数*λ*称为正则化参数，如果用户和物品矩阵的分量过大（绝对值），它会对其进行惩罚。这对于数值稳定性很重要，几乎总是会使用某种形式的正则化。'
- en: '`implicitPrefs`: This specifies whether to use the Explicit feedback ALS variant
    or one adapted for Implicit feedback data; it defaults to false, which means using
    Explicit feedback.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`implicitPrefs`：这指定是否使用显式反馈ALS变体或者适用于隐式反馈数据的变体；默认为false，表示使用显式反馈。'
- en: '`alpha`: This is a parameter applicable to the Implicit feedback variant of
    ALS that governs the *baseline* confidence in preference observations (defaults
    to 1.0).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha`：这是ALS隐式反馈变体适用的参数，它控制对偏好观察的*基线*置信度（默认为1.0）。'
- en: '`nonnegative`: This specifies whether or not to use nonnegative constraints
    for least squares (defaults to `false`).'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nonnegative`：这指定是否使用最小二乘法的非负约束（默认为`false`）。'
- en: 'We''ll use default `rank`, `5``maxIter`, and a `regParam` parameter of `0.01`
    to illustrate how to train our model which is shown in the following code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用默认的`rank`，`5`个`maxIter`，以及`regParam`参数为`0.01`来说明如何训练我们的模型，如下面的代码所示：
- en: '[PRE15]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: You can find the code listing at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala)找到代码清单。
- en: This returns a `ALSModel` object, which contains the user and item factors.
    These are called `userFactors` and `itemFactors`, respectively.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回一个`ALSModel`对象，其中包含用户和物品因子。它们分别称为`userFactors`和`itemFactors`。
- en: For example, `model.userFactors`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`model.userFactors`。
- en: 'You will see the output as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下输出：
- en: '[PRE16]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We can see that the factors are in the form of `Array[float]`.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这些因子的形式是`Array[float]`。
- en: 'Note that the operations used in MLlib''s ALS implementation are lazy transformations,
    so the actual computation will only be performed once we call some sort of action
    on the resulting DataFrame of the user and item factors. In the following code
    we can force the computation using a Spark action such as `count`:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib的ALS实现中使用的操作是惰性转换，因此实际计算只有在我们对用户和物品因子的DataFrame调用某种操作时才会执行。在下面的代码中，我们可以使用Spark操作（如`count`）来强制执行计算：
- en: '[PRE17]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This will trigger the computation, and we will see quite a bit of output texts
    similar to the following lines of code:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这将触发计算，并且我们将看到类似以下代码行的大量输出文本：
- en: '[PRE18]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If we call `count` for the movie factors, it will be done with the help of
    following code:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对电影因子调用`count`，将会使用以下代码完成：
- en: '[PRE19]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This will trigger the computation, and we will get the following output:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这将触发计算，并且我们将得到以下输出：
- en: '[PRE20]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As expected, we have a factor array for each user (`943` factors) and each movie
    (`1651` factors).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，我们为每个用户（`943`个因子）和每部电影（`1651`个因子）都有一个因子数组。
- en: Training a model using Implicit feedback data
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用隐式反馈数据训练模型
- en: The standard Matrix Factorization approach in MLlib deals with explicit ratings.
    To work with implicit data, you can use the `trainImplicit` method. It is called
    in a manner similar to the standard `train` method. There is an additional parameter,
    `alpha`, that can be set (and in the same way, the regularization parameter, `lambda`,
    should be selected via testing and cross-validation methods).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib中的标准矩阵分解方法处理显式评分。要处理隐式数据，可以使用`trainImplicit`方法。它的调用方式类似于标准的`train`方法。还有一个额外的参数`alpha`，可以设置（同样，正则化参数`lambda`应该通过测试和交叉验证方法进行选择）。
- en: The `alpha` parameter controls the baseline level of confidence, weighting applied.
    A higher level of `alpha` tends to make the model more confident about the fact
    that missing data equates to no preference for the relevant user-item pair.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`alpha`参数控制应用的基线置信度权重。较高水平的`alpha`倾向于使模型更加确信缺失数据意味着用户-物品对的偏好不存在。'
- en: 'From Spark version 2.0, if the rating matrix is derived from another source
    of information that is, it is inferred from other signals, you can `setImplicitPrefs`
    to `true` to get better results, as shown in the following example:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 从Spark版本2.0开始，如果评分矩阵是从其他信息推断出来的，即从其他信号中推断出来的，您可以将`setImplicitPrefs`设置为`true`以获得更好的结果，如下例所示：
- en: '[PRE21]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As an exercise, try to take the existing MovieLens dataset and convert it into
    an implicit dataset. One possible approach is to convert it to binary feedback
    (0s and 1s) by applying a threshold on the ratings at some level.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 作为练习，尝试将现有的MovieLens数据集转换为隐式数据集。一种可能的方法是通过在某个水平上对评分应用阈值，将其转换为二进制反馈（0和1）。
- en: Another approach could be to convert the ratings' values into confidence weights
    (for example, perhaps, low ratings could imply zero weights, or even negative
    weights, which are supported by MLlib's implementation).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法可能是将评分值转换为置信权重（例如，也许低评分可能意味着零权重，甚至是负权重，这是MLlib实现支持的）。
- en: Train a model on this dataset and compare the results of the following section
    with those generated by your implicit model.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在此数据集上训练模型，并将以下部分的结果与您的隐式模型生成的结果进行比较。
- en: Using the recommendation model
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用推荐模型
- en: Now that we have our trained model, we're ready to use it to make predictions.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练好模型，准备使用它进行预测。
- en: ALS Model recommendations
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ALS模型推荐
- en: Starting Spark v2.0, `org.apache.spark.ml.recommendation.ALS` modeling is a
    blocked implementation of the factorization algorithm that groups "users" and
    "products" factors into blocks and decreases communication by sending only one
    copy of each user vector to each product block at each iteration, and only for
    the product blocks that need that user's feature vector.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 从Spark v2.0开始，`org.apache.spark.ml.recommendation.ALS`建模是因子分解算法的阻塞实现，它将“用户”和“产品”因子分组到块中，并通过在每次迭代时仅向每个产品块发送每个用户向量的一份副本，并且仅对需要该用户特征向量的产品块进行通信，从而减少通信。
- en: 'Here, we will load the rating data from the movies dataset where each row consists
    of a user, movie, rating, and a timestamp. We will then train an ALS model by
    default works on explicit preferences (`implicitPrefs` is `false`). We will evaluate
    the recommendation model by measuring the root-mean-square error of rating prediction
    as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将从电影数据集中加载评分数据，其中每一行包括用户、电影、评分和时间戳。然后我们将训练一个ALS模型，默认情况下该模型适用于显式偏好（`implicitPrefs`为`false`）。我们将通过测量评分预测的均方根误差来评估推荐模型，具体如下：
- en: '[PRE22]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You can find the code listing at: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下链接找到代码列表：[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala)
- en: 'The following is the output for the preceding code:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前述代码的输出：
- en: '[PRE23]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Before we proceed further, please note that the following examples for User
    and Item recommendations use MLlib from Spark v1.6\. Kindly follow the code listing
    to get the details of creating recommendation models using `org.apache.spark.mllib.recommendation.ALS`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，请注意以下关于用户和物品推荐的示例使用了Spark v1.6的MLlib。请按照代码列表获取使用`org.apache.spark.mllib.recommendation.ALS`创建推荐模型的详细信息。
- en: User recommendations
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户推荐
- en: In this case, we would like to generate recommended items for a given user.
    This usually takes the form of a *top-K* list, that is, the *K* items that our
    model predicts will have the highest probability of the user liking them. This
    is done by computing the predicted score for each item and ranking the list based
    on this score.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们希望为给定的用户生成推荐的物品。这通常采用*top-K*列表的形式，即我们的模型预测用户最有可能喜欢的*K*个物品。这是通过计算每个物品的预测得分并根据这个得分对列表进行排名来实现的。
- en: The exact method to perform this computation depends on the model involved.
    For example, in user-based approaches, the ratings of similar users on items are
    used to compute the recommendations for a user; while in an item-based approach,
    the computation is based on the similarity of items the user has rated to the
    candidate items.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此计算的确切方法取决于所涉及的模型。例如，在基于用户的方法中，使用相似用户对物品的评分来计算对用户的推荐；而在基于物品的方法中，计算基于用户评分的物品与候选物品的相似性。
- en: In matrix factorization, because we are modeling the ratings matrix directly,
    the predicted score can be computed as the vector dot product between a user-factor
    vector and an item-factor vector.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在矩阵分解中，因为我们直接对评分矩阵进行建模，所以预测得分可以通过用户因子向量和物品因子向量之间的向量点积来计算。
- en: Generating movie recommendations from the MovieLens 100k dataset
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从MovieLens 100k数据集生成电影推荐
- en: As MLlib's recommendation model is based on matrix factorization, we can use
    the factor matrices computed by our model to compute predicted scores (or ratings)
    for a user. We will focus on the explicit rating case using MovieLens data; however,
    the approach is the same when using the implicit model.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 由于MLlib的推荐模型是基于矩阵分解的，我们可以使用模型计算出的因子矩阵来计算用户的预测分数（或评分）。我们将专注于使用MovieLens数据的显式评分情况；然而，使用隐式模型时，方法是相同的。
- en: 'The `MatrixFactorizationModel` class has a convenient `predict` method that
    will compute a predicted score for a given user and item combination as shown
    in the following code:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`MatrixFactorizationModel`类有一个方便的`predict`方法，可以计算给定用户和项目组合的预测分数，如下面的代码所示：'
- en: '[PRE24]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE25]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As we can see, this model predicts a rating of `3.12` for user `789` and movie
    `123`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，这个模型预测用户`789`对电影`123`的评分为`3.12`。
- en: Note that you might see different results than those shown in this section because
    the ALS model is initialized randomly. So, different runs of the model will lead
    to different solutions.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您可能会看到与本节中显示的结果不同的结果，因为ALS模型是随机初始化的。因此，模型的不同运行将导致不同的解决方案。
- en: The `predict` method can also take an RDD of `(user, item)` IDs as the input
    and will generate predictions for each of these. We can use this method to make
    predictions for many users and items at the same time.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict`方法也可以接受一个`(user, item)` ID的RDD作为输入，并为每个生成预测。我们可以使用这个方法同时为许多用户和项目进行预测。'
- en: 'To generate the *top-K* recommended items for a user, `MatrixFactorizationModel`
    provides a convenience method called `recommendProducts`. This takes two arguments:
    `user` and `num`, where `user` is the user ID and `num` is the number of items
    to recommend.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为用户生成*top-K*推荐项目，`MatrixFactorizationModel`提供了一个方便的方法叫做`recommendProducts`。这需要两个参数：`user`和`num`，其中`user`是用户ID，`num`是要推荐的项目数。
- en: It returns the top `num` items ranked in the order of the predicted score. Here,
    the scores are computed as the dot product between the user-factor vector and
    each item-factor vector.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回按预测分数排序的前`num`个项目。在这里，分数是通过用户因子向量和每个项目因子向量之间的点积计算的。
- en: 'Let''s generate the top `10` recommended items for user `789` as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照以下方式为用户`789`生成前`10`个推荐项目：
- en: '[PRE26]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We now have a set of predicted ratings for each movie for user `789`. If we
    print this out, by writing the following line of code, we could inspect the top
    10 recommendations for this user:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经为用户`789`的每部电影预测了一组评分。如果我们打印出来，通过编写以下代码行，我们可以检查这个用户的前`10`个推荐：
- en: '[PRE27]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You should see the following output on your console:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在控制台上看到以下输出：
- en: '[PRE28]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Inspecting the recommendations
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查推荐
- en: 'We can give these recommendations a sense check by taking a quick look at the
    titles of the movies a user has rated and the recommended movies. First, we will
    need to load the movie data, which is one of the datasets we explored in the previous
    chapter. In the following code we''ll collect this data as a `Map[Int, String]`
    method, mapping the movie ID to the title:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过快速查看用户评价过的电影和推荐的电影的标题来对这些推荐进行一次检查。首先，我们需要加载电影数据，这是我们在上一章中探讨的数据集之一。在下面的代码中，我们将收集这些数据作为`Map[Int,
    String]`方法，将电影ID映射到标题：
- en: '[PRE29]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The preceding code will produce the following output:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将产生以下输出：
- en: '[PRE30]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'For our user `789`, we can find out what movies they have rated, take the `10`
    movies with the highest rating, and then check the titles. We will do this now
    by first using the `keyBy` Spark function to create an RDD of key-value pairs
    from our `ratings` RDD, where the key will be the user ID. We will then use the
    `lookup` function to return just the ratings for this key (that is, that particular
    user ID) to the driver which is described as follows:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的用户`789`，我们可以找出他们评价过的电影，取得评分最高的`10`部电影，然后检查标题。我们将首先使用`keyBy` Spark函数从我们的`ratings`
    RDD中创建一个键值对的RDD，其中键将是用户ID。然后，我们将使用`lookup`函数将这个键（即特定的用户ID）的评分返回给驱动程序，如下所述：
- en: '[PRE31]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let''s see how many movies this user has rated. This will be the `size` of
    the `moviesForUser` collection:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个用户评价了多少部电影。这将是`moviesForUser`集合的`size`：
- en: '[PRE32]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We will see that this user has rated `33` movies.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到这个用户已经评价了`33`部电影。
- en: 'Next, we will take the 10 movies with the highest ratings by sorting the `moviesForUser`
    collection using the `rating` field of the `Rating` object. We will then extract
    the movie title for the relevant product ID attached to the `Rating` class from
    our mapping of movie titles and print out the top `10` titles with their ratings
    as shown next:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过对`moviesForUser`集合使用`Rating`对象的`rating`字段进行排序，取得评分最高的`10`部电影。然后，我们将从我们的电影标题映射中提取相关产品ID附加到`Rating`类的电影标题，并打印出带有其评分的前`10`个标题，如下所示：
- en: '[PRE33]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'You will see the following output displayed:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下输出显示：
- en: '[PRE34]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, let''s take a look at the top 10 recommendations for this user and see
    what the titles are, using the same approach as the one we used earlier (note
    that the recommendations are already sorted):'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看这个用户的前`10`个推荐，并查看标题，使用与我们之前使用的相同方法（请注意，推荐已经排序）：
- en: '[PRE35]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The output is as follows:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE36]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We leave it for you to decide whether these recommendations make sense.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们留给您决定这些推荐是否有意义。
- en: Item recommendations
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目推荐
- en: 'Item recommendations are about answering the following question: for a certain
    item, what are the items most similar to it? Here, the precise definition of similarity
    is dependent on the model involved. In most cases, similarity is computed by comparing
    the vector representation of two items using some similarity measure. Common similarity
    measures include Pearson correlation and cosine similarity for real-valued vectors,
    and Jaccard similarity for binary vectors.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 项目推荐是关于回答以下问题的：对于某个项目，与之最相似的项目是什么？在这里，相似性的精确定义取决于所涉及的模型。在大多数情况下，相似性是通过使用某些相似性度量来比较两个项目的向量表示来计算的。常见的相似性度量包括皮尔逊相关系数和余弦相似度用于实值向量，以及杰卡德相似度用于二进制向量。
- en: Generating similar movies for the MovieLens 100k dataset
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为MovieLens 100k数据集生成相似的电影
- en: The current `MatrixFactorizationModel` API does not directly support item-to-item
    similarity computations. Therefore, we will need to create our own code to do
    this.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的`MatrixFactorizationModel`API不直接支持项目之间的相似度计算。因此，我们需要创建自己的代码来完成这个任务。
- en: We will use the cosine similarity metric, and we will use the jblas linear algebra
    library (a dependency of MLlib) to compute the required vector dot products. This
    is similar to how the existing `predict` and `recommendProducts` methods work,
    except that we will use cosine similarity as opposed to just the dot product.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用余弦相似度度量，并使用jblas线性代数库（MLlib的依赖项）来计算所需的向量点积。这类似于现有的`predict`和`recommendProducts`方法的工作方式，只是我们将使用余弦相似度而不仅仅是点积。
- en: 'We would like to compare the factor vector of our chosen item with each of
    the other items using our similarity metric. In order to perform linear algebra
    computations, we will first need to create a vector object out of the factor vectors,
    which are in the form of `Array[Double]`. The `JBLAS` class, `DoubleMatrix`, takes
    `Array[Double]` as the constructor argument, as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要使用我们的相似度度量来比较我们选择的项目的因子向量与其他项目的因子向量。为了执行线性代数计算，我们首先需要从因子向量中创建一个向量对象，这些因子向量的形式是`Array[Double]`。`JBLAS`类`DoubleMatrix`以`Array[Double]`作为构造函数参数，如下所示：
- en: '[PRE37]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Use the following constructor to instantiate `DoubleMatrix` from an array.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下构造函数从数组实例化`DoubleMatrix`。
- en: The `jblas` class is a linear algebra library written in Java. It is based on
    BLAS and LAPACK, the de-facto industry standard for matrix computations, and uses
    implementations like `ATLAS` for its computational routines, making jBLAS very
    fast.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`jblas`类是一个用Java编写的线性代数库。它基于BLAS和LAPACK，是矩阵计算的事实行业标准，并使用像`ATLAS`这样的实现来进行计算例程，使得jBLAS非常快速。'
- en: It is a light-weight wrapper around the BLAS and LAPACK routines. BLAS and LAPACK
    packages have originated in the Fortran community.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 它是对BLAS和LAPACK例程的轻量级封装。BLAS和LAPACK包起源于Fortran社区。
- en: 'Let''s see an example of it:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个例子：
- en: '[PRE38]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Create a column vector using `newData` as the data array. Any change in the
    created `DoubleMatrix` will change in input array `newData`.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`newData`作为数据数组创建一个列向量。对创建的`DoubleMatrix`的任何更改都将在输入数组`newData`中进行更改。
- en: 'Let''s create a simple `DoubleMatrix`:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个简单的`DoubleMatrix`：
- en: '[PRE39]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Here is the output of the preceding code:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面代码的输出：
- en: '[PRE40]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Note that using jblas, vectors are represented as a one-dimensional `DoubleMatrix`
    class, while matrices are a two-dimensional `DoubleMatrix` class.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，使用jblas，向量表示为一维的`DoubleMatrix`类，而矩阵表示为二维的`DoubleMatrix`类。
- en: We will need a method to compute the cosine similarity between two vectors.
    Cosine similarity is a measure of the angle between two vectors in an *n*-dimensional
    space. It is computed by first calculating the dot product between the vectors
    and then dividing the result by a denominator, which is the norm (or length) of
    each vector multiplied together (specifically, the L2-norm is used in cosine similarity).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个方法来计算两个向量之间的余弦相似度。余弦相似度是*n*维空间中两个向量之间角度的度量。首先计算向量之间的点积，然后将结果除以分母，分母是每个向量的范数（或长度）相乘在一起（具体来说，余弦相似度中使用L2范数）。
- en: In linear algebra, the size of a vector ![](img/image_05_014.png) is called
    the norm of ![](img/image_05_015.png). We will discuss a few different kinds of
    norms. For this discussion, we will define a vector v as an ordered tuple of numbers.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性代数中，向量![](img/image_05_014.png)的大小称为![](img/image_05_015.png)的范数。我们将讨论几种不同类型的范数。在本讨论中，我们将向量v定义为一组有序的数字。
- en: '![](img/image_05_016.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_016.png)'
- en: 'One Norm: The one-norm (also known as the L1-norm, or mean norm) of vector
    ![](img/image_05_017.png) is denoted as shown in the following diagram and is
    defined as the sum of the absolute values of its components:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 一范数：向量![](img/image_05_017.png)的一范数（也称为L1范数或均值范数）如下图所示，并定义为其组件的绝对值的总和：
- en: '![](img/image_05_018.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_018.png)'
- en: Two-norm (also known as the L2-norm, mean-square norm, least-squares norm)
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 二范数（也称为L2范数、均方根范数、最小二乘范数）
- en: 'of a ![](img/image_05_019.png) vector is denoted as shown in this diagram::'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/image_05_019.png)向量的范数如下图所示：'
- en: '![](img/image_05_020.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_020.png)'
- en: 'Moreover, it is defined as the square root of the sum of the squares of the
    absolute values of its components:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，它被定义为其组件的绝对值的平方和的平方根：
- en: '![](img/image_05_021.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_021.png)'
- en: 'In this way, cosine similarity is a normalized dot product. The cosine similarity
    measure takes on values between `-1` and 1\. A value of `1` implies completely
    similarity, while a value of 0 implies independence (that is, no similarity).
    This measure is useful because it also captures negative similarity, that is,
    a value of `-1` implies that not only are the vectors not similar, but they are
    also completely dissimilar:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，余弦相似度是一个归一化的点积。余弦相似度测量值介于`-1`和`1`之间。值为`1`意味着完全相似，而值为0意味着独立（即没有相似性）。这个度量是有用的，因为它还捕捉到了负相似性，即值为`-1`意味着向量不仅不相似，而且完全不相似：
- en: '![](img/image_05_022.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_05_022.png)'
- en: 'Let''s create our `cosineSimilarity` function here:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里创建我们的`cosineSimilarity`函数：
- en: '[PRE41]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Note that we defined a return type for this function of `Double`. We are not
    required to do this since Scala features type inference. However, it can often
    be useful to document return types for Scala functions.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们为这个函数定义了一个`Double`的返回类型。虽然Scala具有类型推断功能，我们并不需要这样做。然而，为Scala函数记录返回类型通常是有用的。
- en: Let's try it out on one of our item factors for item `567`. We will need to
    collect an item factor from our model; we will do this using the `lookup` method
    in a similar way that we did earlier to collect the ratings for a specific user.
    In the following lines of code, we will also use the `head` function, since `lookup`
    returns an array of values, and we will only need the first value (in fact, there
    will only be one value, which is the factor vector for this item).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试对项目`567`的项目因子之一进行操作。我们需要从我们的模型中收集一个项目因子；我们将使用`lookup`方法来做到这一点，方式与我们之前收集特定用户的评分的方式类似。在下面的代码行中，我们还将使用`head`函数，因为`lookup`返回一个值数组，我们只需要第一个值（实际上，只会有一个值，即这个项目的因子向量）。
- en: 'Since this will be an constructor `Array[Double]`, we will then need to create
    a `DoubleMatrix` object from it and compute the cosine similarity with itself
    which is shown as follows:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这将是一个构造函数`Array[Double]`，因此我们需要从中创建一个`DoubleMatrix`对象，并计算与自身的余弦相似度，如下所示：
- en: '[PRE42]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'A similarity metric should measure how close, in some sense, two vectors are
    to each other. In the following example, we can see that our cosine similarity
    metric tells us that this item vector is identical to itself, which is what we
    would expect:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 相似度度量应该衡量两个向量在某种意义上的接近程度。在下面的示例中，我们可以看到我们的余弦相似度度量告诉我们，这个项目向量与自身相同，这是我们所期望的。
- en: '[PRE43]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now, we are ready to apply our similarity metric to each item which is shown
    as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备将我们的相似度度量应用于每个项目，如下所示：
- en: '[PRE44]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Next, we can compute the top 10 most similar items by sorting out the similarity
    score for each item:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以通过对每个项目的相似度分数进行排序来计算前10个最相似的项目：
- en: '[PRE45]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: In the preceding code snippet, we used Spark's `top` function, which is an efficient
    way to compute *top-K* results in a distributed fashion, instead of using `collect`
    to return all the data to the driver and sorting it locally (remember that we
    could be dealing with millions of users and items in the case of recommendation
    models).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码片段中，我们使用了Spark的`top`函数，这是一种在分布式方式中计算*top-K*结果的高效方法，而不是使用`collect`将所有数据返回到驱动程序并在本地进行排序（请记住，在推荐模型的情况下，我们可能会处理数百万用户和项目）。
- en: We will need to tell Spark how to sort the `(item id, similarity score)` pairs
    in the `sims` RDD. To do this, we will pass an extra argument to `top`, which
    is a Scala `Ordering` object that tells Spark that it should sort by the value
    in the key-value pair (that is, sort by `similarity`).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要告诉Spark如何对`sims` RDD中的`(项目ID，相似度分数)`对进行排序。为此，我们将传递一个额外的参数给`top`，这是一个Scala`Ordering`对象，告诉Spark应该按照键值对中的值进行排序（即按照`相似度`进行排序）。
- en: 'Finally, we can print the 10 items with the highest computed similarity metric
    to our given item:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以打印与给定项目计算出的最高相似度度量的10个项目：
- en: '[PRE46]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'You will see an output like the following one:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下类似的输出：
- en: '[PRE47]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Not surprisingly, we can see that the top-ranked similar item is our item. The
    rest are the other items in our set of items, ranked in order of our similarity
    metric.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，我们可以看到排名最高的相似项是我们的项目。其余的是我们项目集中的其他项目，按照我们的相似度度量进行排名。
- en: Inspecting the similar items
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查相似项目
- en: 'Let''s see what the title of our chosen movie is:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们选择的电影的标题是什么：
- en: '[PRE48]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The preceding code will print the following output:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将打印以下输出：
- en: '[PRE49]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'As we did for user recommendations, we can sense check our item-to-item similarity
    computations and take a look at the titles of the most similar movies. This time,
    we will take the top 11, so that we can exclude our given movie. So, we will take
    the numbers 1 to 11 in the list:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 与用户推荐一样，我们可以对项目之间的相似性计算进行感知检查，并查看最相似电影的标题。这次，我们将取前11个，以便排除给定的电影。因此，我们将在列表中取1到11的数字：
- en: '[PRE50]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'You will see the movie titles and scores displayed similar to this output:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到显示电影标题和分数的输出类似于此输出：
- en: '[PRE51]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Once again, note that you might see quite different results due to random model
    initialization.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 再次注意，由于随机模型初始化，您可能会看到完全不同的结果。
- en: Now that you have computed similar items using cosine similarity, see if you
    can do the same with the user-factor vectors to compute similar users for a given
    user.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经使用余弦相似度计算了相似的项目，请尝试对用户因子向量执行相同操作，以计算给定用户的相似用户。
- en: Evaluating the performance of recommendation models
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估推荐模型的性能
- en: How do we know whether the model we have trained is a good model? We will need
    to be able to evaluate its predictive performance in some way. Evaluation metrics
    are measures of a model's predictive capability or accuracy. Some are direct measures
    of how well a model predicts the model's target variable, such as Mean Squared
    Error, while others are concerned with how well the model performs at predicting
    things that might not be directly optimized in the model, but are often closer
    to what we care about in the real world, such as Mean Average Precision.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何知道我们训练的模型是否是一个好模型？我们需要能够以某种方式评估其预测性能。评估指标是模型预测能力或准确性的度量。有些是直接衡量模型预测模型目标变量的能力，例如均方误差，而其他指标则关注模型在预测可能不会直接优化的事物方面的表现，但通常更接近我们在现实世界中关心的内容，例如平均精度。
- en: Evaluation metrics provide a standardized way of comparing the performance of
    the same model with different parameter settings and of comparing performance
    across different models. Using these metrics, we can perform model selection to
    choose the best-performing model from the set of models we wish to evaluate.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标提供了一种标准化的方式，用于比较具有不同参数设置的相同模型的性能，并比较跨不同模型的性能。使用这些指标，我们可以执行模型选择，从我们希望评估的模型集中选择表现最佳的模型。
- en: 'Here, we will show you how to calculate two common evaluation metrics used
    in recommender systems and collaborative filtering models: **Mean Squared Error**
    (**MSE**) and **Mean Average Precision at K** (**MAPK**).'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将向您展示如何计算推荐系统和协同过滤模型中使用的两个常见评估指标：**均方误差**（**MSE**）和**K处的平均精度**（**MAPK**）。
- en: ALS Model Evaluation
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ALS模型评估
- en: 'From Spark v2.0, we will use `org.apache.spark.ml.evaluation.RegressionEvaluator`
    for regression problems. Regression evaluation is a metric to measure how well
    a fitted model does on held-out test data. Here, we will use **Root Mean Squared
    Error** (**RMSE**), which is just the square root of the MSE metric:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 从Spark v2.0开始，我们将使用`org.apache.spark.ml.evaluation.RegressionEvaluator`来解决回归问题。回归评估是衡量拟合模型在留出测试数据上表现如何的度量标准。在这里，我们将使用**均方根误差**（**RMSE**），它只是MSE度量的平方根：
- en: '[PRE52]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: You can find the code-listing at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala)找到代码清单。
- en: 'You will see an output like the following one:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到如下输出：
- en: '[PRE53]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Before we proceed further, please note that the following evaluation examples
    use MLLib from Spark v1.6\. Kindly follow the code listing to get the details
    of creating recommendation model using `org.apache.spark.mllib.recommendation.ALS`.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进一步进行之前，请注意以下评估示例使用Spark v1.6中的MLLib。请按照代码清单获取使用`org.apache.spark.mllib.recommendation.ALS`创建推荐模型的详细信息。
- en: Mean Squared Error
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 均方误差
- en: The MSE is a direct measure of the reconstruction error of the user-item rating
    matrix. It is also the objective function being minimized in certain models, specifically
    many matrix-factorization techniques, including ALS. As such, it is commonly used
    in explicit ratings settings.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: MSE是用户-物品评分矩阵重建误差的直接度量。它也是某些模型中被最小化的目标函数，特别是包括ALS在内的许多矩阵分解技术。因此，在显式评分设置中通常使用它。
- en: It is defined as the sum of the squared errors divided by the number of observations.
    The squared error, in turn, is the square of the difference between the predicted
    rating for a given user-item pair and the actual rating.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 它被定义为平方误差之和除以观察次数。而平方误差则是给定用户-物品对的预测评分与实际评分之间的差的平方。
- en: 'We will use our user `789` as an example. Let''s take the first rating for
    this user from the `moviesForUser` set of `Ratings` that we previously computed:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以用户`789`为例。让我们从之前计算的`moviesForUser`集合的`Ratings`中取出该用户的第一个评分：
- en: '[PRE54]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Here is the output:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '[PRE55]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We will see that the rating for this user-item combination is 4\. Next, we
    will compute the model''s predicted rating:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到该用户-物品组合的评分为4。接下来，我们将计算模型的预测评分：
- en: '[PRE56]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The output of the model''s predicted rating is as follows:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 模型预测评分的输出如下：
- en: '[PRE57]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We will see that the predicted rating is about 4, very close to the actual
    rating. Finally, we will compute the squared error between the actual rating and
    the predicted rating:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到预测评分约为4，非常接近实际评分。最后，我们将计算实际评分和预测评分之间的平方误差：
- en: '[PRE58]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The preceding code will output the squared error:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将输出平方误差：
- en: '[PRE59]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: So, in order to compute the overall MSE for the dataset, we will need to compute
    this squared error for each (`user`, `movie`, `actual rating`, `predicted rating`)
    entry, sum them up, and divide them by the number of ratings. We will do this
    in the following code snippet.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了计算数据集的整体MSE，我们需要为每个（`用户`，`电影`，`实际评分`，`预测评分`）条目计算这个平方误差，将它们相加，然后除以评分数量。我们将在以下代码片段中执行此操作。
- en: 'Note: the following code is adapted from the Apache Spark programming guide
    for ALS at [http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html](http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html).'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：以下代码改编自Apache Spark ALS的编程指南，网址为[http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html](http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html)。
- en: 'First, we will extract the user and product IDs from the `ratings` RDD and
    make predictions for each user-item pair using `model.predict`. We will use the
    user-item pair as the key and the predicted rating as the value:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将从`ratings` RDD中提取用户和产品ID，并使用`model.predict`对每个用户-物品对进行预测。我们将使用用户-物品对作为键，预测评分作为值：
- en: '[PRE60]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Next, we will extract the actual ratings and also map the `ratings` RDD so
    that the user-item pair is the key and the actual rating is the value. Now that
    we have two RDDs with the same form of key, we can join them together to create
    a new RDD with the actual and predicted ratings for each user-item combination:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将提取实际评分，并将`ratings` RDD映射，使用户-物品对成为键，实际评分成为值。现在我们有了两个具有相同键形式的RDD，我们可以将它们连接在一起，创建一个新的RDD，其中包含每个用户-物品组合的实际和预测评分：
- en: '[PRE61]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Finally, we will compute the MSE by summing up the squared errors using `reduce`
    and dividing by the `count` method of the number of records:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将通过使用`reduce`求和平方误差，并除以记录数量的`count`方法来计算MSE：
- en: '[PRE62]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The output is as follows:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE63]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'It is common to use the RMSE, which is just the square root of the MSE metric.
    This is somewhat more interpretable, as it is in the same units as the underlying
    data (that is, the ratings in this case). It is equivalent to the standard deviation
    of the differences between the predicted and actual ratings. We can compute it
    simply as follows:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 通常使用RMSE，它只是MSE度量的平方根。这更具可解释性，因为它与基础数据（即本例中的评分）具有相同的单位。它相当于预测和实际评分之间差异的标准差。我们可以简单地计算如下：
- en: '[PRE64]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The preceding code will print the RMSE:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将打印RMSE：
- en: '[PRE65]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: To interpret the preceding result, keep following the definition in mind. Lowering
    the value of RMSE closer is the fit of predicted value to the actual value. While
    interpreting RMSE, keep the minimum and maximum of the actual data in mind.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释前面的结果，请记住以下定义。降低RMSE值意味着预测值与实际值的拟合更好。在解释RMSE时，请记住实际数据的最小值和最大值。
- en: Mean Average Precision at K
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K处的平均精度
- en: Mean Average Precision at *K* is the mean of the **average precision at K**
    (**APK**) metric across all instances in the dataset. APK is a metric commonly
    used for information retrieval. APK is a measure of the average relevance scores
    of a set of the *top-K* documents presented in response to a query. For each query
    instance, we will compare the set of *top-K* results with the set of actual relevant
    documents, that is, a ground truth set of relevant documents for the query.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在*K*处的平均精度是数据集中所有实例的**K处的平均精度**(**APK**)指标的平均值。APK是信息检索常用的度量标准。APK是对响应查询呈现的*top-K*文档的平均相关性分数的度量。对于每个查询实例，我们将*top-K*结果集与实际相关文档集进行比较，也就是查询的真实相关文档集。
- en: In the APK metric, the order of the result set matters, in that the APK score
    would be higher if the result documents are both relevant and the relevant documents
    are presented higher in the results. It is, thus, a good metric for recommender
    systems; in that, typically, we would compute the *top-K* recommended items for
    each user and present these to the user. Of course, we prefer models where the
    items with the highest predicted scores, which are presented at the top of the
    list of recommendations, are, in fact, the most relevant items for the user. APK
    and other ranking-based metrics are also more appropriate evaluation measures
    for implicit datasets; here, MSE makes less sense.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在APK指标中，结果集的顺序很重要，如果结果文档既相关又相关文档在结果中排名较高，则APK得分会更高。因此，这是推荐系统的一个很好的指标；通常，我们会为每个用户计算*top-K*推荐的项目，并将这些项目呈现给用户。当然，我们更喜欢那些具有最高预测分数的项目的模型，这些项目在推荐列表的顶部呈现时，实际上是用户最相关的项目。APK和其他基于排名的指标也更适合隐式数据集的评估指标；在这里，MSE没有太多意义。
- en: In order to evaluate our model, we can use APK, where each user is the equivalent
    of a query, and the set of *top-K* recommended items is the document result set.
    The relevant documents, that is, the ground truth, in this case, is the set of
    items that a user interacted with. Hence, APK attempts to measure how good our
    model is at predicting items that a user will find relevant and choose to interact
    with.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们的模型，我们可以使用APK，其中每个用户相当于一个查询，而*top-K*推荐项目集是文档结果集。相关文档，也就是在这种情况下的真相，是用户交互的项目集。因此，APK试图衡量我们的模型在预测用户会发现相关并选择与之交互的项目方面有多好。
- en: The code for the following average precision computation is based on [https://github.com/benhamner/Metrics](https://github.com/benhamner/Metrics).
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 以下平均精度计算的代码基于[https://github.com/benhamner/Metrics](https://github.com/benhamner/Metrics)。
- en: More information on MAPK can be found at [https://www.kaggle.com/wiki/MeanAveragePrecision](https://www.kaggle.com/wiki/MeanAveragePrecision).
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于MAPK的信息可以在[https://www.kaggle.com/wiki/MeanAveragePrecision](https://www.kaggle.com/wiki/MeanAveragePrecision)找到。
- en: 'Our function to compute the APK is shown here:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的计算APK的函数如下所示：
- en: '[PRE66]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: As you can see, this takes as input a list of `actual` item IDs that are associated
    with the user and another list of `predicted` IDs so that our estimate will be
    relevant for the user.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这需要输入一个与用户相关联的“实际”项目ID列表和另一个“预测”ID列表，以便我们的估计对用户是相关的。
- en: 'We can compute the APK metric for our example user `789` as follows. First,
    we will extract the actual movie IDs for the user, as follows:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计算我们示例用户“789”的APK指标如下。首先，我们将提取用户的实际电影ID，如下所示：
- en: '[PRE67]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The output is as follows:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE68]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'We will then use the movie recommendations we made previously to compute the
    APK score using `K = 10`:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用先前制作的电影推荐来使用`K = 10`计算APK得分：
- en: '[PRE69]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Here is the output:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE70]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The following code will produce the average precision:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将产生平均精度：
- en: '[PRE71]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The preceding code will print the following command line:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码将打印以下命令行：
- en: '[PRE72]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: In this case, we can see that our model is not doing a very good job of predicting
    relevant movies for this user, as the APK score is `0`.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以看到我们的模型并没有很好地预测这个用户的相关电影，因为APK得分为`0`。
- en: In order to compute the APK for each user and average them to compute the overall
    MAPK, we will need to generate the list of recommendations for each user in our
    dataset. While this can be fairly intensive on a large scale, we can distribute
    the computation using our Spark functionality. However, one limitation is that
    each worker must have the full item-factor matrix available so that it can compute
    the dot product between the relevant user vector and all item vectors. This can
    be a problem when the number of items is extremely high, as the item matrix must
    fit in the memory of one machine.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算每个用户的APK并对其进行平均以计算整体MAPK，我们需要为数据集中的每个用户生成推荐列表。虽然这在大规模上可能相当密集，但我们可以使用我们的Spark功能来分发计算。然而，一个限制是每个工作节点必须有完整的项目因子矩阵可用，以便它可以计算相关用户向量和所有项目向量之间的点积。当项目数量非常高时，这可能是一个问题，因为项目矩阵必须适合一个机器的内存中。
- en: There is actually no easy way around this limitation. One possible approach
    is to only compute recommendations for a subset of items from the total item set,
    using approximate techniques such as Locality Sensitive Hashing ([http://en.wikipedia.org/wiki/Locality-sensitive_hashing](http://en.wikipedia.org/wiki/Locality-sensitive_hashing)).
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，没有简单的方法可以解决这个限制。一种可能的方法是仅使用近似技术，如局部敏感哈希([http://en.wikipedia.org/wiki/Locality-sensitive_hashing](http://en.wikipedia.org/wiki/Locality-sensitive_hashing))，为总项目集的子集计算推荐。
- en: 'We will now see how to go about this. First, we will collect the item factors
    and form a `DoubleMatrix` object from them:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将看看如何做。首先，我们将收集项目因子并从中形成一个“DoubleMatrix”对象：
- en: '[PRE73]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '[PRE74]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'This gives us a matrix with `1682` rows and `50` columns, as we would expect
    from `1682` movies with a factor dimension of `50`. Next, we will distribute the
    item matrix as a broadcast variable so that it is available on each worker node:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们一个具有`1682`行和`50`列的矩阵，这是我们从`1682`部电影中期望的因子维度为`50`的矩阵。接下来，我们将将项目矩阵作为广播变量分发，以便它在每个工作节点上都可用：
- en: '[PRE75]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'You will see the output as follows:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下输出：
- en: '[PRE76]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Now we are ready to compute the recommendations for each user. We will do this
    by applying a `map` function to each user factor within which we will perform
    a matrix multiplication between the user-factor vector and the movie-factor matrix.
    The result is a vector (of length `1682`, that is, the number of movies we have)
    with the predicted rating for each movie. We will then sort these predictions
    by the predicted rating:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备为每个用户计算推荐。我们将通过对每个用户因子应用`map`函数来执行用户因子向量和电影因子矩阵之间的矩阵乘法来实现这一点。结果是一个向量（长度为`1682`，即我们拥有的电影数量），其中包含每部电影的预测评分。然后，我们将按预测评分对这些预测进行排序：
- en: '[PRE77]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'You will see the following on the screen:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在屏幕上看到以下内容：
- en: '[PRE78]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: As we can see, we now have an RDD that contains a list of movie IDs for each
    user ID. These movie IDs are sorted in order of the estimated rating.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个RDD，其中包含每个用户ID的电影ID列表。这些电影ID按照估计的评分顺序排列。
- en: Note that we needed to add 1 to the returned movie IDs (as highlighted in the
    preceding code snippet), as the item-factor matrix is 0-indexed, while our movie
    IDs start at `1`.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们需要将返回的电影ID加1（如前面的代码片段中所示），因为项目因子矩阵是从0开始索引的，而我们的电影ID从`1`开始。
- en: We will also need the list of movie IDs for each user to pass into our APK function
    as the `actual` argument. We already have the `ratings` RDD ready, so we can extract
    just the user and movie IDs from it.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要每个用户的电影ID列表，作为`actual`参数传递给我们的APK函数。我们已经准备好了`ratings` RDD，所以我们可以从中提取用户和电影ID。
- en: 'If we use Spark''s `groupBy` operator, we will get an RDD that contains a list
    of `(userid, movieid)` pairs for each user ID (as the user ID is the key on which
    we perform the `groupBy` operation) shown as follows:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用Spark的`groupBy`操作符，我们将得到一个RDD，其中包含每个用户ID的`(userid, movieid)`对列表（因为用户ID是我们执行`groupBy`操作的键），如下所示：
- en: '[PRE79]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '[PRE80]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Finally, we can use Spark''s `join` operator to join these two RDDs together
    on the user ID key. Then, for each user, we have the list of actual and predicted
    movie IDs that we can pass to our APK function. In a manner similar to how we
    computed MSE, we will sum each of these APK scores using a `reduce` action and
    divide by the number of users, that is, the count of the `allRecs` RDD as shown
    in the following code:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用Spark的`join`操作符在用户ID键上将这两个RDD连接在一起。然后，对于每个用户，我们有实际和预测的电影ID列表，我们可以将其传递给我们的APK函数。类似于我们计算MSE的方式，我们将使用`reduce`操作来对这些APK分数进行求和，并除以用户数量，即`allRecs`
    RDD的计数，如下面的代码所示：
- en: '[PRE81]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'The preceding code will print the `Mean Average Precision at``K` as follows:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将打印`K`处的`平均精度`如下：
- en: '[PRE82]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Our model achieves a fairly low MAPK. However, note that typical values for
    recommendation tasks are usually relatively low, especially if the item set is
    extremely large.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型实现了一个相当低的MAPK。但是，请注意，推荐任务的典型值通常相对较低，特别是如果项目集非常大的话。
- en: Try out a few parameter settings for `lambda` and `rank` (and `alpha`, if you
    are using the implicit version of ALS) and see whether you can find a model that
    performs better based on the RMSE and MAPK evaluation metrics.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试一些`lambda`和`rank`（如果您使用ALS的隐式版本，则还有`alpha`）的参数设置，并查看是否可以找到基于RMSE和MAPK评估指标表现更好的模型。
- en: Using MLlib's built-in evaluation functions
  id: totrans-382
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MLlib的内置评估函数
- en: While we have computed MSE, RMSE, and MAPK from scratch, and it's a useful learning
    exercise to do so, MLlib provides convenience functions to do this for us in the
    `RegressionMetrics` and `RankingMetrics` classes.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们已经从头开始计算了MSE、RMSE和MAPK，这是一个有用的学习练习，但是MLlib提供了方便的函数来在`RegressionMetrics`和`RankingMetrics`类中为我们执行这些操作。
- en: RMSE and MSE
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RMSE和MSE
- en: 'First, we will compute the MSE and RMSE metrics using `RegressionMetrics`.
    We will instantiate a `RegressionMetrics` instance by passing in an RDD of key-value
    pairs that represent the predicted and true values for each data point, as shown
    in the following code snippet. Here, we will again use the `ratingsAndPredictions`
    RDD we computed in our earlier example:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用`RegressionMetrics`计算MSE和RMSE指标。我们将通过传入表示每个数据点的预测和真实值的键值对RDD来实例化`RegressionMetrics`实例，如下面的代码片段所示。在这里，我们将再次使用我们在之前示例中计算的`ratingsAndPredictions`
    RDD：
- en: '[PRE83]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'We can then access various metrics, including MSE and RMSE. We will print out
    these metrics here:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以访问各种指标，包括MSE和RMSE。我们将在这里打印出这些指标：
- en: '[PRE84]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'In the following command lines, you will see that the output for MSE and RMSE,
    is exactly the same as the metrics we computed earlier:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下命令行中，您将看到MSE和RMSE的输出与我们之前计算的指标完全相同：
- en: '[PRE85]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: MAP
  id: totrans-391
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MAP
- en: As we did for MSE and RMSE, we can compute ranking-based evaluation metrics
    using MLlib's `RankingMetrics` class. Similarly, to our own average precision
    function, we will need to pass in an RDD of key-value pairs, where the key is
    `Array` of predicted item IDs for a user, while the value is an array of actual
    item IDs.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们对MSE和RMSE所做的那样，我们可以使用MLlib的`RankingMetrics`类来计算基于排名的评估指标。类似地，与我们自己的平均精度函数一样，我们需要传入一个键值对的RDD，其中键是用户的预测项目ID数组，而值是实际项目ID的数组。
- en: The implementation of the average precision at the K function in `RankingMetrics`
    is slightly different from ours, so we will get different results. However, the
    computation of the overall Mean Average Precision (MAP, which does not use a threshold
    at K) is the same as our function if we select `K` to be very high (say, at least
    as high as the number of items in our item set).
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 在`RankingMetrics`中，平均精度在K函数的实现与我们的略有不同，因此我们将得到不同的结果。但是，如果我们选择`K`非常高（比如至少与我们的项目集中的项目数量一样高），则整体平均精度（MAP，不使用K阈值）的计算与我们的函数相同。
- en: 'First, we will calculate MAP using `RankingMetrics` as follows:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用`RankingMetrics`计算MAP如下：
- en: '[PRE86]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'You will see the following output:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在屏幕上看到以下输出：
- en: '[PRE87]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Next, we will use our function to compute the MAP in exactly the same way as
    we did previously, except that we set `K` to a very high value, say `2000`:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用我们的函数以与之前完全相同的方式计算MAP，只是将`K`设置为一个非常高的值，比如`2000`：
- en: '[PRE88]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'You will see that the MAP from our own function is the same as the one computed
    using `RankingMetrics`:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到我们自己函数计算的MAP与使用`RankingMetrics`计算的MAP相同：
- en: '[PRE89]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: We will not cover cross-validation in this chapter, as we will provide a detailed
    treatment in the next few chapters. However, note that the same techniques for
    cross-validation that are explored in the upcoming chapters can be used to evaluate
    recommendation models using the performance metrics such as MSE, RMSE, and MAP,
    which we covered in this section.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不在本章涵盖交叉验证，因为我们将在接下来的几章中提供详细的处理。但是，请注意，探讨在即将到来的章节中探索的交叉验证技术可以用于使用MSE、RMSE和MAP等性能指标来评估推荐模型的性能，这些指标我们在本节中已经涵盖。
- en: FP-Growth algorithm
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FP-Growth算法
- en: We will apply the FP-Growth algorithm to find frequently recommended movies.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将应用FP-Growth算法来找出经常推荐的电影。
- en: The FP-Growth algorithm has been described in the paper by Han et al., *Mining
    frequent patterns without candidate generation* available at: [http://dx.doi.org/10.1145/335191.335372](http://dx.doi.org/10.1145/335191.335372),
    where **FP** stands for the **frequent pattern**. For given a dataset of transactions,
    the first step of FP-Growth is to calculate item frequencies and identify frequent
    items. The second step of FP-Growth algorithm implementation uses a suffix tree
    (FP-tree) structure to encode transactions; this is done without generating candidate
    sets explicitly, which are usually expensive to generate for large datasets.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: FP-Growth算法已在Han等人的论文中描述，*Mining frequent patterns without candidate generation*，可在[http://dx.doi.org/10.1145/335191.335372](http://dx.doi.org/10.1145/335191.335372)上找到，其中**FP**代表**frequent
    pattern**。对于给定的交易数据集，FP-Growth的第一步是计算项目频率并识别频繁项目。FP-Growth算法实现的第二步使用后缀树（FP-tree）结构来编码交易；这是在不显式生成候选集的情况下完成的，通常对于大型数据集来说生成候选集是昂贵的。
- en: FP-Growth Basic Sample
  id: totrans-406
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FP-Growth基本示例
- en: 'Let''s start with a very simple dataset of random numbers:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个非常简单的随机数字数据集开始：
- en: '[PRE90]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'We will find out the most frequent items (character in this case). First, we
    will get the spark context as follows:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将找出最频繁的项目（在本例中是字符）。首先，我们将按如下方式获取Spark上下文：
- en: '[PRE91]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Convert our data in an RDD:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们的数据转换为RDD：
- en: '[PRE92]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Initialize the `FPGrowth` instance:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化`FPGrowth`实例：
- en: '[PRE93]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'FP-Growth can be configured with the following parameters:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: FP-Growth可以配置以下参数：
- en: '`minSupport`: the minimum support number for an itemset to be identified as
    frequent. For example, if an item appears in 3 out of 10 transactions, it has
    a support of 3/10=0.3.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minSupport`：被识别为频繁项集的最小支持数。例如，如果一个项目在10个交易中出现3次，则其支持率为3/10=0.3。'
- en: '`numPartitions`: the number of partitions to distribute the work.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numPartitions`：要分发工作的分区数。'
- en: 'Set `minsupport` and number of partitions for the FP-Growth instance and call
    run on the RDD object. Number of partitions should be set to the number of partitions
    in the dataset--number of worker nodes from where data will be loaded, as follows:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 设置`minsupport`和FP-Growth实例的分区数，并在RDD对象上调用run。分区数应设置为数据集中的分区数--数据将从中加载的工作节点数，如下所示：
- en: '[PRE94]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'Get the item sets of the output and print:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 获取输出的项目集并打印：
- en: '[PRE95]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The output for the preceding code is listed as follows, as you can see `[Z]`
    occurs the most:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下，您可以看到`[Z]`出现最多：
- en: '[PRE96]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: FP-Growth Applied to Movie Lens Data
  id: totrans-424
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用于Movie Lens数据的FP-Growth
- en: 'Let''s apply the algorithm to Movie Lens data to find our frequent movie titles:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将算法应用于Movie Lens数据，以找到我们频繁的电影标题：
- en: 'Instantiate the `SparkContext` by writing the following lines of code:'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过编写以下代码行来实例化`SparkContext`：
- en: '[PRE97]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Get raw ratings and print first by writing the following lines of code:'
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取原始评分并通过编写以下代码行打印第一个：
- en: '[PRE98]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Load the movie data and get the titles as follows:'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载电影数据并获取标题如下：
- en: '[PRE99]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: Next, we will find out the most frequent movies for 400 users from 501 to 900
    using the FP-Growth algorithm.
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用FP-Growth算法找出从501到900号用户中400个用户最频繁的电影。
- en: 'The FP-Growth model is created first by writing the following lines of code:'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先通过编写以下代码行创建FP-Growth模型：
- en: '[PRE100]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Where `0.1` is the minimum cutoff to be considered, `rddx` is the RDD with raw
    movie ratings loaded into RDD for 400 users. Once we have the model we can iterate
    `overitemsetr`, the `itemset` and print the results.
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其中`0.1`是要考虑的最小截止值，`rddx`是加载到400个用户的原始电影评分的RDD。一旦我们有了模型，我们可以迭代`overitemsetr`，`itemset`并打印结果。
- en: The complete code listing is given here and can also be found at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/scala-spark-app/src/main/scala/MovieLensFPGrowthApp.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/scala-spark-app/src/main/scala/MovieLensFPGrowthApp.scala).
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码清单在此处给出，并且也可以在[https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/scala-spark-app/src/main/scala/MovieLensFPGrowthApp.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/scala-spark-app/src/main/scala/MovieLensFPGrowthApp.scala)找到。
- en: 'This can be done by writing the following lines of code:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过编写以下代码行来完成：
- en: '[PRE101]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'The output of the preceding sample is as follows:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 前面示例的输出如下：
- en: '[PRE102]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: This provides movies with the maximum frequency for user IDs 501 to 900.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 这为用户ID 501到900提供了具有最大频率的电影。
- en: Summary
  id: totrans-442
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we used Spark's ML and MLlib library to train a collaborative
    filtering recommendation model, and you learned how to use this model to make
    predictions for the items that a given user may have a preference for. We also
    used our model to find items that are similar or related to a given item. Finally,
    we explored common metrics to evaluate the predictive capability of our recommendation
    model.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用Spark的ML和MLlib库来训练协同过滤推荐模型，并学习如何使用该模型来预测给定用户可能偏好的项目。我们还使用我们的模型来找到与给定项目相似或相关的项目。最后，我们探索了评估我们推荐模型的预测能力的常见指标。
- en: In the next chapter, you will learn how to use Spark to train a model to classify
    your data and to use standard evaluation mechanisms to gauge the performance of
    your model.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将学习如何使用Spark训练模型来对数据进行分类，并使用标准评估机制来衡量模型的性能。
