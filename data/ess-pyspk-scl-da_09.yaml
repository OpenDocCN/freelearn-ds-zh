- en: 'Chapter 7: Supervised Machine Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第七章：监督机器学习
- en: In the previous two chapters, you were introduced to the machine learning process,
    the various stages involved, and the first step of the process, namely **feature
    engineering**. Equipped with the fundamental knowledge of the machine learning
    process and with a usable set of machine learning features, you are ready to move
    on to the core part of the machine learning process, namely **model training**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两章中，你已经了解了机器学习过程、各个阶段以及该过程的第一步——**特征工程**。掌握了机器学习过程的基本知识，并拥有一组可用的机器学习特征后，你已准备好进入机器学习过程的核心部分——**模型训练**。
- en: In this chapter, you will be introduced to the **supervised learning** category
    of machine learning algorithms, where you will learn about **parametric** and
    **non-parametric** algorithms, as well as gain the knowledge required to solve
    **regression** and **classification** problems using machine learning. Finally,
    you will implement a few regression algorithms using the Spark machine learning
    library, such as **linear regression** and **decision trees**, and a few classification
    algorithms such as **logistic regression**, **naïve Bayes**, and **support vector
    machines**. **Tree ensemble** methods will also be presented, which can improve
    the performance and accuracy of decision trees. A few real-world applications
    of both regression and classification will also be presented to help you gain
    an appreciation of how machine learning can be leveraged in some day-to-day scenarios.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将接触到**监督学习**类别的机器学习算法，了解**参数化**和**非参数化**算法，掌握使用机器学习解决**回归**和**分类**问题所需的知识。最后，你将使用Spark机器学习库实现一些回归算法，如**线性回归**和**决策树**，以及一些分类算法，如**逻辑回归**、**朴素贝叶斯**和**支持向量机**。还将介绍**树集成**方法，这可以提高决策树的性能和准确性。本章还将展示回归和分类的几个现实世界应用，帮助你理解机器学习如何在日常场景中得到应用。
- en: 'The following main topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要主题：
- en: Introduction to supervised machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习简介
- en: Regression
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归
- en: Classification
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类
- en: Tree ensembles
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 树集成
- en: Real-world supervised learning applications
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现实世界中的监督学习应用
- en: Toward the end of this chapter, you should have gained sufficient knowledge
    and the skills required for building your own regression and classification models
    at scale using Spark MLlib.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应已掌握足够的知识和技能，能够使用Spark MLlib构建你自己的回归和分类模型并进行大规模训练。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we will be using Databricks Community Edition to run our code
    ([https://community.cloud.databricks.com](https://community.cloud.databricks.com)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Databricks Community Edition来运行我们的代码([https://community.cloud.databricks.com](https://community.cloud.databricks.com))。
- en: Sign-up instructions can be found at [https://databricks.com/try-databricks](https://databricks.com/try-databricks).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注册说明可以在[https://databricks.com/try-databricks](https://databricks.com/try-databricks)找到。
- en: The code for this chapter can be downloaded from [https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/Chapter07](https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/Chapter07).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的代码可以从[https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/Chapter07](https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/Chapter07)下载。
- en: The datasets for this chapter can be found at [https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/data](https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/data).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的数据集可以在[https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/data](https://github.com/PacktPublishing/Essential-PySpark-for-Data-Analytics/tree/main/data)找到。
- en: Introduction to supervised machine learning
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习简介
- en: A machine learning problem can be considered as a process where an unknown variable
    is derived from a set of known variables using a mathematical or statistical function.
    The difference here is that a machine learning algorithm learns the mapping function
    from a given dataset.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习问题可以看作是一个过程，通过数学或统计函数从一组已知变量中推导出一个未知变量。不同之处在于，机器学习算法从给定的数据集中学习映射函数。
- en: Supervised learning is a class of machine learning algorithms where a model
    is trained on a dataset and the outcome for each set of inputs is already known.
    This is known as supervised learning as the algorithm here behaves like a teacher,
    guiding the training process until the desired level of model performance is achieved.
    Supervised learning requires data that is already labeled. Supervised learning
    algorithms can be further classified as parametric and non-parametric algorithms.
    We will look at these in the following sections.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习是一类机器学习算法，其中模型在一个数据集上进行训练，每一组输入的结果已经是已知的。这被称为监督学习，因为在此过程中，算法像教师一样引导训练，直到达到期望的模型性能水平。监督学习需要已经标注的数据。监督学习算法可以进一步分为参数化算法和非参数化算法。我们将在接下来的章节中详细讨论这些内容。
- en: Parametric machine learning
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数化机器学习
- en: A machine learning algorithm that simplifies the learning process by summarizing
    the data with a fixed set of parameters is called a parametric learning algorithm.
    It achieves this by assuming a known form for the learning function and learning
    the coefficients of the linear function from the given dataset. The assumed form
    of the learning function is usually a linear function or an algebraic equation
    describing a straight line. Thus, parametric learning functions are also known
    as linear machine learning algorithms.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一种通过用一组固定参数总结数据来简化学习过程的机器学习算法称为参数化学习算法。它通过假设学习函数具有已知的形式，并从给定的数据集中学习线性函数的系数来实现这一点。学习函数的假定形式通常是线性函数或描述直线的代数方程。因此，参数化学习函数也被称为线性机器学习算法。
- en: One important property of parametric learning algorithms is that the number
    of parameters needed for the linear learning function is independent of the input
    training dataset. This greatly simplifies the learning process and makes it relatively
    faster. One disadvantage here is that the underlying learning function for the
    given dataset might not necessarily be a straight line, hence oversimplifying
    the learned model. However, most practical machine learning algorithms are parametric
    learning algorithms, such as linear regression, logistic regression, and naïve
    Bayes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 参数化学习算法的一个重要特性是，线性学习函数所需的参数数量与输入的训练数据集无关。这大大简化了学习过程，使得训练相对更快。这里的一个缺点是，给定数据集的潜在学习函数不一定是直线，因此可能会过度简化所学模型。然而，大多数实际的机器学习算法是参数化学习算法，例如线性回归、逻辑回归和朴素贝叶斯。
- en: Non-parametric machine learning
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非参数化机器学习
- en: Non-parametric learning algorithms do not make any assumptions regarding the
    form of the learning function. These algorithms make the best use of the training
    dataset by learning a mapping function, while still maintaining the ability to
    conform to unseen data. This means that non-parametric learning algorithms can
    learn from a wider variety of learning functions. The advantage of these algorithms
    is that that they are flexible and yield better performing models, while the disadvantages
    are that they usually require more data to learn, have relatively slow training
    times, and may sometimes lead to model overfitting. Some examples of non-parametric
    learning algorithms include K-nearest neighbors, decision trees, and support vector
    machines.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 非参数化学习算法不对学习函数的形式做任何假设。这些算法通过学习映射函数最大限度地利用训练数据集，同时保持对未见数据的适应能力。这意味着非参数化学习算法可以学习更广泛的学习函数。这些算法的优势在于它们灵活，并且能生成更优性能的模型，而劣势是通常需要更多的数据来学习，训练时间较慢，并且有时可能导致模型过拟合。一些非参数化学习算法的例子包括
    K 最近邻、决策树和支持向量机。
- en: Supervised learning algorithms have two major applications, namely regression
    and classification. We will explore these in the following sections.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习算法有两个主要应用，即回归和分类。我们将在接下来的章节中探讨这些内容。
- en: Regression
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归
- en: 'Regression is a supervised learning technique that helps us learn the correlation
    between a continuous output parameter called **Label** and a set of input parameters
    called **Features**. Regression produces machine learning models that predict
    a continuous label, given a feature vector. The concept of regression can be best
    explained using the following diagram:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是一种监督学习技术，它帮助我们学习一个称为**标签**的连续输出参数与一组输入参数（称为**特征**）之间的关系。回归生成的机器学习模型根据特征向量预测一个连续的标签。回归的概念可以通过以下图示来最好地解释：
- en: '![Figure 7.1 – Linear regression'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.1 – 线性回归'
- en: '](img/B16736_07_01.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16736_07_01.jpg)'
- en: Figure 7.1 – Linear regression
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – 线性回归
- en: In the preceding diagram, the scatterplot represents data points spread across
    a two-dimensional space. The linear regression algorithm, being a parametric learning
    algorithm, assumes that the learning function will have a linear form. Thus, it
    learns the coefficients that are required to represent a straight line that approximately
    fits the data points on the scatterplot.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，散点图表示分布在二维空间中的数据点。线性回归算法是一种参数化学习算法，它假设学习函数将呈线性形式。因此，它学习表示直线的系数，这条直线大致拟合散点图中的数据点。
- en: Spark MLlib has distributed and scalable implementations of a few prominent
    regression algorithms, such as linear regression, decision trees, random forests,
    and gradient boosted trees. In the following sections, we will implement a few
    of these regression algorithms using Spark MLlib.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib 提供了几种著名回归算法的分布式和可扩展实现，例如线性回归、决策树、随机森林和梯度提升树。在接下来的章节中，我们将使用 Spark
    MLlib 实现这些回归算法中的几个。
- en: Linear regression
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性回归
- en: 'In the previous chapters, we cleaned, integrated, and curated a dataset containing
    online retail sales transactions by customers and captured their demographic information
    in the same integrated dataset. In [*Chapter 6*](B16736_06_Final_JM_ePub.xhtml#_idTextAnchor107),
    *Feature Engineering – Extraction, Transformation, and Selection*, we also converted
    the pre-processed data into a feature vector that''s ready for machine learning
    training and stored it in **Delta Lake** as our offline **feature store**. Let''s
    make use of this feature-engineered dataset to train a regression algorithm that
    can find out the age of a customer by providing other features as parameters,
    as shown in the following code block:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们清理、整合并策划了一个包含客户在线零售销售交易的数据集，并在同一整合数据集中捕获了他们的 demographic 信息。在 [*第 6
    章*](B16736_06_Final_JM_ePub.xhtml#_idTextAnchor107)，*特征工程 – 提取、转换和选择* 中，我们还将预处理的数据转换成了一个适合机器学习训练的特征向量，并将其存储在
    **Delta Lake** 中，作为我们的离线 **特征存储**。让我们利用这个特征工程数据集来训练一个回归算法，利用其他特征作为参数预测客户的年龄，如下方代码块所示：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the preceding block of code, we have done the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们做了以下操作：
- en: First, we imported the `LinearRegression` algorithm from Spark MLlib.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们从 Spark MLlib 导入了 `LinearRegression` 算法。
- en: The retail features were loaded from a Delta table and loaded into a Spark DataFrame.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 零售特征是从 Delta 表中加载的，并被加载到 Spark DataFrame 中。
- en: We only needed the feature vector and the label column for training a `LinearRegression`
    model, so we only selected these two columns in the training DataFrame.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只需要特征向量和标签列来训练一个 `LinearRegression` 模型，因此我们仅在训练 DataFrame 中选择了这两列。
- en: Then, we initialized a `LinearRegression` transformer by specifying the hyperparameters
    required by this algorithm.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们通过指定该算法所需的超参数来初始化一个 `LinearRegression` 变换器。
- en: After, we called the `fit` method on the training dataset to start the training
    process, which starts a Spark job behind the scenes that carries out the training
    task in a distributed manner.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在训练数据集上调用了 `fit` 方法来启动训练过程，这会在后台启动一个 Spark 任务，分布式地执行训练任务。
- en: Once the model has been successfully trained, we printed the model training
    summary, including the learned coefficients of the linear learning function and
    the intercept.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型成功训练完成，我们打印了模型训练摘要，包括学习到的线性学习函数的系数和截距。
- en: We also displayed the model accuracy metrics, such as the RMSE and R-squared
    metrics. It is generally desirable to get a model with as lower an RMSE as possible.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还显示了模型的准确性指标，例如 RMSE 和 R 平方值。通常，理想的情况是得到一个尽可能低的 RMSE 的模型。
- en: Thus, utilizing Spark MLlib's distributed implementation of linear regression,
    you can train a regression model in a distributed manner on a large dataset, without
    having to deal with any of the underlying complexities of distributed computing.
    The model can then be applied to a new set of data to generate predictions. Spark
    MLlib models can also be persisted to disk or a data lake using built-in methods
    and then reused later.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，利用 Spark MLlib 的线性回归分布式实现，您可以在大型数据集上以分布式方式训练回归模型，而无需处理任何底层的分布式计算复杂性。然后，模型可以应用于新数据集，以生成预测。Spark
    MLlib 模型还可以使用内置方法持久化到磁盘或数据湖中，然后稍后重新使用。
- en: Now that we have trained a simple linear regression model using a parametric
    learning algorithm, let's look at using a non-parametric learning algorithm to
    solve the same regression problem.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经使用参数学习算法训练了一个简单的线性回归模型，让我们来看看如何使用非参数学习算法来解决同样的回归问题。
- en: Regression using decision trees
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用决策树进行回归
- en: Decision trees are a popular form of non-parametric learning algorithm for solving
    both regression and classification machine learning problems. Decision trees are
    popular because they are easy to use, they can handle a wide variety of categorical
    as well as continuous features, and are also easy to interpret and explain.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是解决回归和分类机器学习问题的流行非参数学习算法。决策树之所以流行，是因为它们易于使用，能够处理各种分类和连续特征，同时也易于解释和说明。
- en: Spark MLlib's implementation of decision trees allows for distributed training
    by partitioning data by rows. Since non-parametric learning algorithms typically
    require large amounts of data, Spark's implementation of decision trees can scale
    to a very large number of rows, even millions or billions.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib的决策树实现通过按行划分数据来实现分布式训练。由于非参数学习算法通常需要大量数据，Spark的决策树实现能够扩展到非常大规模的数据集，甚至是数百万或数十亿行。
- en: 'Let''s train a decision tree to predict the age of a customer while using other
    online retail transactional features as input, as shown in the following code
    block:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们训练一个决策树模型，通过使用其他在线零售交易特征作为输入，预测客户的年龄，如下方代码块所示：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the preceding code snippet, we have done the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们完成了以下操作：
- en: First, we imported the `DecisionTreeRegressor` Spark ML library, along with
    a utility method to help evaluate the accuracy of the trained model.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入了`DecisionTreeRegressor` Spark ML库，并引入了一个工具方法来帮助评估训练模型的准确性。
- en: We loaded our feature vector dataset from Delta Lake into a Spark DataFrame
    and only selected the feature and label columns.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将特征向量数据集从Delta Lake加载到Spark DataFrame，并只选择特征和标签列。
- en: To be able to evaluate our model accuracy after the training process, we needed
    a dataset that wouldn't be used for training. Thus, we split our dataset into
    two sets for training and testing, respectively. We used 80% of the data for model
    training while preserving 20% for model evaluation.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了能够在训练过程后评估我们模型的准确性，我们需要一个不会用于训练的数据集。因此，我们将数据集分为训练集和测试集两部分。我们使用80%的数据进行模型训练，同时保留20%用于模型评估。
- en: Then, we initialized the `DecisionTreeRegressor` class with the required hyperparameters,
    resulting in a `Transformer` object.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们用所需的超参数初始化了`DecisionTreeRegressor`类，从而得到了一个`Transformer`对象。
- en: We fit the `DecisionTreeRegressor` transformer to our training dataset, which
    resulted in a decision tree model estimator.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将`DecisionTreeRegressor`变换器拟合到我们的训练数据集，从而得到一个决策树模型估算器。
- en: We applied the model's `Estimator` object to the test dataset to produce actual
    predictions.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将模型的`Estimator`对象应用于测试数据集，以生成实际预测结果。
- en: This prediction DataFrame was then used along with the `RegressionEvaluator`
    utility method to derive the RMSE of the model, which can be used to evaluate
    the accuracy of the trained model.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随后，这个预测数据框（DataFrame）与`RegressionEvaluator`工具方法一起使用，用于推导模型的RMSE，该值可用于评估训练模型的准确性。
- en: By using Spark MLlib's built-in decision tree regression algorithms, we can
    train regressions models in a distributed fashion on very large amounts of data,
    in a very fast and efficient manner. One thing to note is that the RMSE value
    of both regression models is about the same. These models can be tuned further
    using model tuning techniques, which help improve their accuracy. You will learn
    more about model tuning in [*Chapter 9*](B16736_09_Final_JM_ePub.xhtml#_idTextAnchor164),
    *Machine Learning Life Cycle Management*.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用Spark MLlib内置的决策树回归算法，我们可以在非常大量的数据上，以分布式的方式快速高效地训练回归模型。需要注意的一点是，这两个回归模型的RMSE值大致相同。这些模型可以通过模型调优技术进一步调优，以提高其准确性。你将会在[*第9章*](B16736_09_Final_JM_ePub.xhtml#_idTextAnchor164)，*机器学习生命周期管理*中学到更多关于模型调优的内容。
- en: Classification
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类
- en: 'Classification is another type of supervised learning technique, where the
    task is to categorize a given dataset into different classes. Machine learning
    classifiers learn a mapping function from input parameters called **Features**
    that go to a discreet output parameter called **Label**. Here, the learning function
    tries to predict whether the label belongs to one of several known classes. The
    following diagram depicts the concept of classification:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是另一种监督学习技术，其任务是将给定的数据集分类到不同的类别中。机器学习分类器从输入参数（称为**特征**）中学习映射函数，输出一个离散的输出参数（称为**标签**）。在这里，学习函数尝试预测标签是否属于几个已知类别中的一个。下图展示了分类的概念：
- en: '![Figure 7.2 – Logistic regression'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.2 – 逻辑回归'
- en: '](img/B16736_07_02.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16736_07_02.jpg)'
- en: Figure 7.2 – Logistic regression
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – 逻辑回归
- en: In the preceding diagram, a logistic regression algorithm is learning a mapping
    function that divides the data points in a two-dimensional space into two distinct
    classes. The learning algorithm learns the coefficients of a **Sigmoid function**,
    which classifies a set of input parameters into one of two possible classes. This
    type of classification can be split into two distinct classes. This is known as
    **binary classification** or **binomial classification**.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，逻辑回归算法正在学习一个映射函数，将二维空间中的数据点分成两个不同的类别。学习算法学习**Sigmoid 函数**的系数，该函数将一组输入参数分类为两个可能类别之一。这种分类方法可以分为两个不同的类别，这就是**二分类**或**二项分类**。
- en: Logistic regression
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Logistic regression is a popular classification algorithm that can learn a model
    from labeled data to predict the class of an output variable. Spark MLlib's implementation
    of logistic regression supports both binomial and multinomial classification problems.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一种流行的分类算法，可以从标记数据中学习模型，以预测输出变量的类别。Spark MLlib 实现的逻辑回归支持二项分类和多项分类问题。
- en: Binomial classification
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 二项分类
- en: 'Binomial classification or binary classification is where the learning algorithm
    needs to classify whether the output variable belongs to one of two possible outcomes.
    Building on the example from previous sections, let''s train a model using logistic
    regression that tries to predict the gender of a customer, given other features
    from an online retail transaction. Let''s see how we can implement this using
    Spark MLlib, as shown in the following code example:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 二项分类或二分类是指学习算法需要判断输出变量是否属于两个可能结果之一。基于前面章节的示例，我们将使用逻辑回归训练一个模型，尝试根据在线零售交易中的其他特征预测顾客的性别。让我们看看如何使用
    Spark MLlib 来实现这一点，代码示例如下：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the preceding block of code, we have done the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们做了以下操作：
- en: The gender in our training dataset is a string data type, so it needs to be
    converted into numeric format first. For this, we made use of `StringIndexer`
    to convert it into a numeric label column.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的训练数据集中，性别是一个字符串数据类型，因此首先需要将其转换为数字格式。为此，我们使用了 `StringIndexer` 将其转换为一个数字标签列。
- en: Then, we initialized a `LogisticRegression` class by specifying the hyperparameters
    required by this algorithm.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们通过指定该算法所需的超参数，初始化了 `LogisticRegression` 类。
- en: Then, we stitched the `StringIndexer` and `LogisticRegression` stages together
    into a pipeline.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们将 `StringIndexer` 和 `LogisticRegression` 阶段串联在一起，形成一个管道。
- en: Then, we called the `fit` method on the training dataset to start the training
    process using the pipeline's `Transformer` object.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在训练数据集上调用 `fit` 方法，开始使用管道中的 `Transformer` 对象进行训练过程。
- en: Once the model had been successfully trained, we printed the model's coefficients
    and intercepts, along with the receiver-operating characteristic and the area
    under the ROC curve metric, to measure the accuracy of the trained model.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型成功训练，我们打印了模型的系数和截距，并且展示了接收器操作特征曲线（ROC）以及ROC曲线下的面积（AUC）指标，以衡量训练模型的准确性。
- en: With that, we have seen how, using the logistic regression algorithm from the
    Spark machine learning library, to implement binary classification in a scalable
    manner.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们已经展示了如何利用 Spark 机器学习库中的逻辑回归算法，以可扩展的方式实现二分类。
- en: Multinomial classification
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多项分类
- en: 'In **multinomial classification**, the learning algorithm needs to predict
    more than two possible outcomes. Let''s extend the example from the previous section
    to build a model that, using logistic regression, tries to predict the country
    of origin of a customer, given other features from an online retail transaction,
    as shown in the following code snippet:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在**多项分类**中，学习算法需要预测多个可能的结果。让我们从前一节的示例出发，扩展一个模型，使用逻辑回归来预测一个客户的来源国家，基于来自在线零售交易的其他特征，如下面的代码片段所示：
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The previous code snippet is almost the same as the binary classification example,
    except the label column has more than two possible values and we specified the
    family parameter for the `LogisticRegression` class as `multinomial`. Once the
    model has been trained, the receiver-operating characteristics of the model and
    the area under the ROC curve metric can be displayed to measure the model's accuracy.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段几乎与二分类示例相同，唯一的区别是标签列具有多个可能值，并且我们为 `LogisticRegression` 类指定了 `multinomial`
    的 family 参数。一旦模型训练完成，可以通过显示模型的接收者操作特征（ROC）和 ROC 曲线下的面积来衡量模型的准确性。
- en: Classification using decision trees
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用决策树进行分类
- en: 'Spark MLlib comes with a `DecsionTreeClassifier` class to solve classification
    problems as well. In the following code, we will implement binary classification
    using decision trees:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib 提供了一个 `DecisionTreeClassifier` 类来解决分类问题。在下面的代码中，我们将使用决策树实现二分类：
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the previous block of code, we did the following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们做了以下操作：
- en: First, we split our dataset into two sets for training and testing. This allows
    us to evaluate the model's accuracy once it has been trained.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将数据集分为两个集合，用于训练和测试。这使我们能够在训练完成后评估模型的准确性。
- en: Then, we made use of `StringIndexer` to convert the gender string column into
    a numeric label column.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用了 `StringIndexer` 将性别字符串列转换为数值标签列。
- en: After, we initialized a `DecsionTreeClassifier` class with the required hyperparameters.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们初始化了一个带有所需超参数的 `DecisionTreeClassifier` 类。
- en: Then, we combined the `StringIndexer` and `DecisionTreeClassifier` stages into
    a pipeline.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将 `StringIndexer` 和 `DecisionTreeClassifier` 阶段组合成一个管道。
- en: After, we called the `fit` method on the training dataset to start the model
    training process and applied the model's `Estimator` object on the test dataset
    to calculate predictions.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们在训练数据集上调用了 `fit` 方法开始模型训练过程，并将模型的 `Estimator` 对象应用于测试数据集以计算预测值。
- en: Finally, we used this DataFrame, along with the `MulticlassClassificationEvaluator`
    utility method, to derive the accuracy of the trained model.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用这个 DataFrame，并结合 `MulticlassClassificationEvaluator` 工具方法，推导出训练模型的准确性。
- en: This way, we have seen how the Spark machine learning library's decision trees
    can be used to solve classification problems at scale.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们展示了如何使用 Spark 机器学习库的决策树来解决大规模的分类问题。
- en: Naïve Bayes
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 朴素贝叶斯
- en: 'Naïve Bayes is a family of probabilistic classification algorithms based on
    the Bayes'' theorem, which assumes independence among features that are used as
    input to the learning algorithm. Bayes'' theorem can be used to predict the probability
    of an event happening, given that another event has already taken place. The naïve
    Bayes algorithm calculates the probability of the given set of input features
    for all possible values of the category of the output label, and then it picks
    the output with the maximum probability. Naïve Bayes can used for binomial as
    well as multinomial classification problems. Let''s see how naïve Bayes can be
    implemented using Spark MLlib, as shown in the following code example:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯是基于贝叶斯定理的概率分类算法家族，它假设输入学习算法的特征之间是独立的。贝叶斯定理可以用来预测一个事件发生的概率，前提是另一个事件已经发生。朴素贝叶斯算法计算给定输入特征集的所有可能输出标签类别的概率，然后选择具有最大概率的输出。朴素贝叶斯可以用于二项分类问题以及多项分类问题。让我们来看一下如何使用
    Spark MLlib 实现朴素贝叶斯，如下面的代码示例所示：
- en: '[PRE5]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the preceding block of code, we did the following:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们做了以下操作：
- en: First, we split our dataset into two sets for training and testing, respectively.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将数据集分别分为训练集和测试集。
- en: Then, we made use of `StringIndexer` to convert the gender string column into
    a numeric label column.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用了 `StringIndexer` 将性别字符串列转换为数值标签列。
- en: After, we initialized a `NaiveBayes` class with the required hyperparameters.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们初始化了一个带有所需超参数的 `NaiveBayes` 类。
- en: Then we combined the `StringIndexer` and `NaiveBayes` stages into a pipeline.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们将`StringIndexer`和`NaiveBayes`阶段合并到一个管道中。
- en: After, we called the `fit` method on the training dataset to start the model
    training process, which applied the model's `Estimator` object to the test dataset
    to calculate predictions.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在训练数据集上调用了`fit`方法，以启动模型训练过程，将模型的`Estimator`对象应用到测试数据集上进行预测计算。
- en: This DataFrame was then used with the `MulticlassClassificationEvaluator` utility
    method to derive the accuracy of the trained model.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，将这个DataFrame与`MulticlassClassificationEvaluator`工具方法一起使用，以推导训练模型的准确性。
- en: Note
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Multinomial and Bernoulli naïve Bayes models require non-negative features.
    Thus, it is recommended to select only features with positive values or to use
    another classification algorithm that can handle features with non-negative values.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多项式和伯努利朴素贝叶斯模型需要非负特征。因此，建议只选择具有正值的特征，或者使用其他能够处理非负值特征的分类算法。
- en: Support vector machines
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持向量机
- en: '**Support vector machines** (**SVM**) is a class of classification algorithms
    that takes data points as input and outputs the hyperplane that best separates
    the given data points into two separate classes, represented on a two-dimensional
    plane. Thus, SVM supports binomial classification problems only. Let''s implement
    binary classification using Spark MLlib''s implementation of SVM, as shown in
    the following code block:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机** (**SVM**) 是一类分类算法，它以数据点作为输入，输出最佳分隔给定数据点的超平面，将数据点分为两个不同的类别，并在二维平面上表示。因此，SVM仅支持二分类问题。让我们使用Spark
    MLlib的SVM实现来实现二分类，如以下代码块所示：'
- en: '[PRE6]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the preceding code block, we did the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们做了以下操作：
- en: First, we made use of `StringIndexer` to convert the gender column into a numeric
    label column.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们使用了`StringIndexer`将性别列转换为数值标签列。
- en: Then, we initialized a `LinearSVC` class by specifying the hyperparameters required
    by this algorithm.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们通过指定此算法所需的超参数来初始化`LinearSVC`类。
- en: Then, we combined the `StringIndexer` and `LinearSVC` stages into a pipeline.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将`StringIndexer`和`LinearSVC`阶段合并到一个管道中。
- en: After, we called the `fit` method on the training dataset to start the training
    process using the pipeline's `Transformer` object.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在训练数据集上调用了`fit`方法，以开始使用管道的`Transformer`对象进行训练过程。
- en: Once the model had been successfully trained, we printed the model coefficients
    and intercepts.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型成功训练，我们打印了模型的系数和截距。
- en: So far, you have learned about the most popular supervised learning algorithms
    for solving regression and classification problems and saw their implementation
    details in Spark MLlib using working code examples. In the following section,
    you will be introduced to the concept of tree ensembles and how they can be used
    to combine multiple decision tree models to arrive at the best possible model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经了解了最流行的有监督学习算法，用于解决回归和分类问题，并通过实际代码示例看到它们在Spark MLlib中的实现。在接下来的章节中，你将了解树集成的概念，以及如何使用树集成方法将多个决策树模型结合起来，以获得最佳模型。
- en: Tree ensembles
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 树集成
- en: Non-parametric learning algorithms such as decision trees do not make any assumptions
    on the form of the learning function being learned and try to fit a model to the
    data at hand. However, decision trees run the risk of overfitting training data.
    Tree ensemble methods are a great way to leverage the benefits of decision trees
    while minimizing the risk of overfitting. Tree ensemble methods combine several
    decision trees to produce better-performing predictive models. Some popular tree
    ensemble methods include random forests and gradient boosted trees. We will explore
    how these ensemble methods can be used to build regression and classification
    models using Spark MLlib.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 非参数化学习算法，如决策树，不对学习函数的形式做任何假设，而是尝试将模型拟合到手头的数据。然而，决策树可能会出现过拟合训练数据的风险。树集成方法是利用决策树优势同时最小化过拟合风险的好方法。树集成方法将多个决策树结合起来，从而生成表现更好的预测模型。一些常见的树集成方法包括随机森林和梯度提升树。我们将探讨如何使用这些集成方法通过Spark
    MLlib构建回归和分类模型。
- en: Regression using random forests
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用随机森林进行回归
- en: 'Random forests build multiple decision trees and merge them to produce a more
    accurate model and reduce the risk of overfitting. Random forests can be used
    to train regression models, as shown in the following code example:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林构建多个决策树并将它们合并，从而生成一个更准确的模型并减少过拟合的风险。随机森林可以用于训练回归模型，如以下代码示例所示：
- en: '[PRE7]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the preceding code snippet, we did the following:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们做了以下操作：
- en: First, we split our dataset into two sets for training and testing, respectively.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将数据集拆分为两个子集，分别用于训练和测试。
- en: Then, we initialized the `RandomForestRegressor` class with several trees to
    be trained. We set this to `5`.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们初始化`RandomForestRegressor`类，并设置多个树进行训练。我们将其设置为`5`。
- en: Next, we fit the `RandomForestRegressor` transformer to our training dataset
    to get a random forest model.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将`RandomForestRegressor`转换器应用于训练数据集，以获得一个随机森林模型。
- en: After, we applied the model's `Estimator` object to the test dataset to produce
    actual predictions.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将模型的`Estimator`对象应用于测试数据集，以生成实际的预测结果。
- en: This DataFrame was then used with the `RegressionEvaluator` utility method to
    derive the `RMSE` value.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，这个DataFrame被用在`RegressionEvaluator`工具方法中，以得出`RMSE`值。
- en: Finally, we printed the trained random forest using the `toDebugString` attribute
    of the model object.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用模型对象的`toDebugString`属性打印训练好的随机森林。
- en: Classification using random forests
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用随机森林进行分类
- en: 'Just like decision trees, random forests also support training multi-class
    classification models, as shown in the following code block:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 就像决策树一样，随机森林也支持训练多类分类模型，如下面的代码块所示：
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the previous code snippet, we did the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们做了以下操作：
- en: First, we split our dataset into two sets for training and testing, respectively.
    This will allow us to evaluate the model's accuracy once it has been trained.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将数据集拆分为两个子集，分别用于训练和测试。这将使我们能够在训练完成后评估模型的准确性。
- en: We made use of `StringIndexer` to convert the gender string column into a numeric
    label column.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们利用`StringIndexer`将性别字符串列转换为数值标签列。
- en: Then, we initialized a `RandomForestClassifier` class with the required hyperparameters
    and specified the number of decision trees to be trained as `5`.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们初始化一个`RandomForestClassifier`类，设置所需的超参数，并指定训练的决策树数量为`5`。
- en: Then, we joined the `StringIndexer` and `RandomForestClassifier` stages into
    a pipeline.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将`StringIndexer`和`RandomForestClassifier`阶段合并到一个管道中。
- en: After, we called the `fit` method on the training dataset to start the model
    training process and applied the model's `Estimator` object to the test dataset
    to calculate predictions.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在训练数据集上调用`fit`方法，开始模型训练过程，并将模型的`Estimator`对象应用于测试数据集，以计算预测结果。
- en: This DataFrame was then used with the `MulticlassClassificationEvaluator` utility
    method to derive the accuracy of the trained model.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，这个DataFrame被用在`MulticlassClassificationEvaluator`工具方法中，以得出训练模型的准确性。
- en: The random forest model can also be printed using the `toDebugString` attribute,
    which is available on the model object.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机森林模型也可以使用`toDebugString`属性进行打印，模型对象上可以访问该属性。
- en: This way, machine learning classification can be implemented at scale using
    the Spark machine learning library.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，机器学习分类就可以通过Spark机器学习库在大规模上实现。
- en: Regression using gradient boosted trees
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用梯度提升树进行回归
- en: '**Gradient boosted trees** (**GBTs**) is another type of ensemble method based
    on decision trees that also improve the stability and accuracy of the trained
    model while minimizing the risk of overfitting. GBTs iteratively train several
    decision trees while minimizing a loss function through a process called gradient
    boosting. Let''s explore an example of training regression models using GBTs in
    Spark, as shown in the following code example:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**梯度提升树**（**GBTs**）是另一种基于决策树的集成方法，它也能提高训练模型的稳定性和准确性，同时最小化过拟合的风险。GBTs通过梯度提升的过程，迭代训练多个决策树，同时最小化损失函数。让我们通过下面的代码示例，探讨如何在Spark中使用GBTs训练回归模型：'
- en: '[PRE9]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the preceding code snippet, we did the following:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们做了以下操作：
- en: First, we split our dataset into two sets for training and testing, respectively.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将数据集拆分为两个子集，分别用于训练和测试。
- en: Then, we initialized the `GBTRegressor` class with the max iterations set to
    `5`.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们初始化`GBTRegressor`类，并将最大迭代次数设置为`5`。
- en: Next, we fit the `RandomForestRegressor` transformer on our training dataset.
    This resulted in a random forest model estimator. After, we set the number of
    trees to be trained to `5`.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将`RandomForestRegressor`转换器应用于训练数据集。这导致了一个随机森林模型估算器。之后，我们将要训练的树的数量设置为`5`。
- en: After, we applied the model's `Estimator` object to the test dataset to produce
    actual predictions.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将模型的`Estimator`对象应用于测试数据集，以生成实际的预测结果。
- en: This DataFrame was then with the `RegressionEvaluator` utility method to derive
    the `RMSE` value.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用`RegressionEvaluator`工具方法对这个DataFrame进行处理，以得出`RMSE`值。
- en: The trained random forest can also be printed using the `toDebugString` attribute
    of the model object.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练后的随机森林也可以通过模型对象的`toDebugString`属性打印出来。
- en: This way, the GBTs algorithm from the Spark MLlib can be used to implement regression
    at scale.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，可以使用Spark MLlib中的GBT算法在大规模上实现回归。
- en: Classification using GBTs
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用GBT进行分类
- en: 'GBTs can also be used to train classification models, as shown in the following
    code example:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: GBT也可以用来训练分类模型，如以下代码示例所示：
- en: '[PRE10]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the previous code snippet, we did the following:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们做了以下操作：
- en: First, we made use of `StringIndexer` to convert the gender string column into
    a numeric label column.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们使用`StringIndexer`将性别字符串列转换为数字标签列。
- en: Then, we initialized the `GBTClassifier` class and set the number of decision
    trees to be trained to `5`.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们初始化了`GBTClassifier`类，并将要训练的决策树数量设置为`5`。
- en: Then, we joined the `StringIndexer` and `RandomForestClassifier` stages into
    a pipeline.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将`StringIndexer`和`RandomForestClassifier`阶段合并到一个管道中。
- en: After, we called the `fit` method on the training dataset to start the model
    training process and applied the model's `Estimator` object to the test dataset
    to calculate predictions.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们在训练数据集上调用`fit`方法，开始模型训练过程，并将模型的`Estimator`对象应用到测试数据集上以计算预测值。
- en: This DataFrame was then used with the `MulticlassClassificationEvaluator` utility
    method to derive the accuracy of the trained model.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用`MulticlassClassificationEvaluator`工具方法对这个DataFrame进行处理，以得出训练模型的准确度。
- en: So far, you have explored how to use tree ensemble methods to combine multiple
    decision trees to produce better and more accurate machine learning models for
    solving both regression and classification problems. In the following section,
    you will be introduced to some real-world applications of machine learning classification
    and regression models that can be applied to day-to-day scenarios.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经探索了如何使用树集成方法将多个决策树结合起来，生成更好、更准确的机器学习模型，以解决回归和分类问题。在接下来的部分中，您将了解一些可以应用于日常场景的机器学习分类和回归模型的真实世界应用。
- en: Real-world supervised learning applications
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 真实世界的监督学习应用
- en: In the past, data science and machine learning were used exclusively for academic
    research purposes. However, over the past decade, this field has found its use
    in actual business applications to help businesses find their competitive edge,
    improve overall business performance, and become profitable. In this section,
    we will look at some real-world applications of machine learning.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 过去，数据科学和机器学习仅用于学术研究。然而，在过去的十年里，这一领域已在实际商业应用中找到了用途，帮助企业寻找竞争优势、提升整体业务表现并实现盈利。在本节中，我们将探讨一些机器学习的真实世界应用。
- en: Regression applications
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归应用
- en: Some of the applications of machine learning regression models and how they
    help improve business performance will be presented in this section.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍机器学习回归模型的一些应用及其如何帮助改善业务表现。
- en: Customer lifetime value estimation
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 客户生命周期价值估算
- en: In any retail or CPG kind of business where customer churn is a huge factor,
    it is necessary to direct marketing spend at those customers who are profitable.
    In non-subscription kinds of businesses, typically 20% of the customer base generates
    up to 80% of revenue. Machine learning models can be leveraged to model and predict
    each customer's **lifetime value**. **Customer lifetime value** (**CLV**) models
    help predict an individual customer's **estimated lifetime**, which is an indicator
    of how much longer we can expect the customer to be profitable. CLV models can
    also be used to predict the amount of revenue that individual customers can be
    expected to generate over their expected lifetime. Thus, regression models can
    be used to estimate CLV and help direct marketing dollars toward promoting to
    and retaining profitable customers over their expected lifetimes.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何零售或消费品行业中，客户流失率是一个重要因素，因此必须将营销预算定向到那些具有盈利潜力的客户。在非订阅型业务中，通常20%的客户群体贡献了80%的收入。可以利用机器学习模型来模拟并预测每个客户的**生命周期价值**。**客户生命周期价值**（**CLV**）模型有助于预测一个客户的**预期生命周期**，这是衡量我们预计客户还能盈利多久的一个指标。CLV模型还可以预测单个客户在其预期生命周期内可能产生的收入。因此，回归模型可以用来估算CLV，并帮助将营销预算集中用于吸引和留住那些在预期生命周期内具有盈利潜力的客户。
- en: Shipment lead time estimation
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 货运提前期估算
- en: Retailers, logistics firms, food service aggregators, or any businesses that
    are in the business of delivering products to customers need to be able to predict
    the amount of time it will take them to ship a product to a customer. Regression
    models can be used to take factors such as origin and destination ZIP codes, the
    past performance of shipments between these locations, inventory availability,
    and also seasonality, weather conditions, and even local traffic into consideration
    to build models that can estimate the amount of time it would take for the product
    to reach the customer. This helps the business with inventory optimization, supply
    chain planning, and even improving overall customer satisfaction.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 零售商、物流公司、餐饮服务聚合商或任何需要将产品交付给客户的企业，都需要能够预测将产品送达客户所需的时间。回归模型可以用来考虑诸如起始和目的地邮政编码、这两个地点之间过往的运输表现、库存可用性，以及季节性、天气状况甚至当地交通等因素，从而建立模型，估算产品到达客户所需的时间。这有助于企业进行库存优化、供应链规划，甚至提升整体客户满意度。
- en: Dynamic price optimization
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 动态定价优化
- en: '**Dynamic price optimization**, also known as **dynamic pricing**, is where
    you set a price for a product or service based on current product demand or market
    conditions. It is a common practice in many industries, ranging from transportation
    to travel and hospitality, e-commerce, entertainment, and digital aggregators
    to perform dynamic price optimization. Businesses can take advantage of the massive
    amounts of data that is generated in the digital economy by adjusting prices in
    real time. Although dynamic pricing is an **optimization** problem, regression
    models can be used to predict the price at a given point in time, current demand,
    market conditions, and competitor pricing.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**动态定价优化**，也称为**动态定价**，是根据当前产品需求或市场状况为产品或服务设定价格的过程。这在多个行业中都是一种常见做法，包括交通、旅游和酒店业、电子商务、娱乐业以及数字聚合平台等。企业可以利用数字经济中产生的大量数据，通过实时调整价格来优化定价。虽然动态定价是一个**优化**问题，回归模型可以用来预测特定时刻的价格、当前需求、市场状况以及竞争对手的定价。'
- en: Classification applications
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类应用
- en: A few examples of how classification models can be used to solve business scenarios
    will be discussed in this section.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将讨论一些分类模型如何应用于解决业务场景的示例。
- en: Financial fraud detection
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 金融欺诈检测
- en: Financial fraud and identity theft are some of the biggest challenges facing
    the financial industry. Financial organizations have historically used statistical
    models and rules-based engines to detect financial fraud; however, fraudsters
    have managed to circumvent legacy fraud detection mechanisms using novel types
    of fraud. Classification models can be built using something rudimentary, such
    as naïve Bayes, or something much more robust, such as decision tree ensemble
    methods. These can be leveraged to keep up with emerging fraud patterns and flag
    financial transactions as fraudulent.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 金融欺诈和身份盗窃是金融行业面临的最大挑战之一。金融机构历来使用统计模型和基于规则的引擎来检测金融欺诈；然而，欺诈分子已通过使用新型欺诈手段绕过传统的欺诈检测机制。分类模型可以使用一些简单的算法，例如朴素贝叶斯，或者一些更为复杂的方法，例如决策树集成方法来构建。这些模型可以帮助企业应对新兴的欺诈模式，并将金融交易标记为欺诈交易。
- en: Email spam detection
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 邮件垃圾信息检测
- en: This is a common scenario that anyone using email must have witnessed; that
    is, getting unwanted and soliciting or sometimes outright offensive content via
    email. Classification models are being used by email providers to classify and
    flag emails as spam and exclude them from user inboxes.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这是任何使用电子邮件的人都曾经历过的常见场景：即收到不需要的、推销性质的或有时甚至是令人反感的电子邮件内容。电子邮件提供商正在使用分类模型来将电子邮件分类，并将垃圾邮件标记出来，从而将其排除在用户的收件箱之外。
- en: Industrial machinery and equipment and failure prediction
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工业机械设备故障预测
- en: Heavy industries such as oil and construction companies have already installed
    or started installing IoT devices on their heavy industrial equipment, which sends
    out a constant stream of telemetry and diagnostic data to backend servers. Classification
    models that have been trained on the swath of telemetry and diagnostic data can
    help predict machine failures, help industries prevent downtime, flag problematic
    ancillary part vendors, and even save huge costs by preventing massive machinery
    recalls.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 油气和建筑等重工业公司已经在其重型工业设备上安装或开始安装物联网设备，这些设备不断向后台服务器发送遥测和诊断数据。经过训练的分类模型可以帮助预测机器故障，帮助行业防止停机，标记出问题的辅助零部件供应商，甚至通过防止大规模的机械召回来节省巨额成本。
- en: Object detection
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 物体检测
- en: Classification models have always been part of high-end cameras that have built-in
    object tracking and autofocus functions. Modern-day mobile phone applications
    also leverage classification models to isolate the subject of the photograph from
    the background, as well as to identify and tag individuals in photographs.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型一直是高端相机的组成部分，这些相机内置了物体跟踪和自动对焦功能。现代手机应用程序也利用分类模型来将照片中的主体与背景分离，以及识别和标记照片中的人物。
- en: Summary
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you were introduced to a class of machine learning algorithms
    called supervised learning algorithms, which can learn from well-labeled existing
    data. You explored the concepts of parametric and non-parametric learning algorithms
    and their pros and cons. Two major use cases of supervised learning algorithms
    called regression and classification were presented. Model training examples,
    along with code from Spark MLlib, were explored so that we could look at a few
    prominent types of regression and classification models. Tree ensemble methods,
    which improve the stability, accuracy, and performance of decision tree models
    by combining several models and preventing overfitting, were also presented.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了一类叫做监督学习算法的机器学习算法，它可以从已标记的现有数据中学习。你探讨了参数化和非参数化学习算法的概念及其优缺点。还介绍了监督学习算法的两个主要应用场景——回归和分类。通过模型训练示例以及来自
    Spark MLlib 的代码，我们探索了几种常见的回归和分类模型。同时，介绍了树集成方法，这些方法通过结合多个模型并防止过拟合，提升了决策树模型的稳定性、准确性和性能。
- en: Finally, you explored some real-world business applications of the various machine
    learning models presented in this chapter. We explained how supervised learning
    can be leveraged for business use cases, and working code samples were presented
    to help you train your models at scale using Spark MLlib and solve business problems
    efficiently.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你探索了本章中介绍的各种机器学习模型在现实世界商业中的应用。我们解释了如何利用监督学习来解决商业用例，并提供了工作代码示例，帮助你使用 Spark
    MLlib 在大规模上训练模型并高效解决商业问题。
- en: In the next chapter, we will explore unsupervised machine learning algorithms,
    how they are different from supervised learning models, and their application
    in solving real-world business problems. We will also provide working code examples
    to showcase this.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探索无监督机器学习算法，了解它们与监督学习模型的区别，以及它们在解决现实世界商业问题中的应用。我们还将提供工作代码示例来展示这一点。
