- en: 8 Outlier Detection Using Statistical Methods
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 使用统计方法进行异常值检测
- en: Join our book community on Discord
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的书籍社区，参与 Discord 讨论
- en: '![](img/file0.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/file0.png)'
- en: '[https://packt.link/zmkOY](https://packt.link/zmkOY)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/zmkOY](https://packt.link/zmkOY)'
- en: In addition to missing data, as discussed in *Chapter 7*, *Handling Missing
    Data*, a common data issue you may face is the presence of **outliers**. Outliers
    can be point outliers, collective outliers, or contextual outliers. For example,
    a **point outlier** occurs when a data point deviates from the rest of the population—sometimes
    referred to as a **global outlier**. **Collective outliers**, which are groups
    of observations, differ from the population and don't follow the expected pattern.
    Lastly, **contextual outliers** occur when an observation is considered an outlier
    based on a particular condition or context, such as deviation from neighboring
    data points. Note that with contextual outliers, the same observation may not
    be considered an outlier if the context changes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 除了缺失数据，如*第七章*《*缺失数据处理*》所讨论的内容，您可能遇到的另一个常见数据问题是**异常值**。异常值可以是点异常值、集体异常值或上下文异常值。例如，**点异常值**发生在某个数据点偏离其余数据集时——有时被称为**全局异常值**。**集体异常值**是指一组观察值，它们与总体不同，并且不遵循预期的模式。最后，**上下文异常值**是指当某个观察值在特定条件或上下文下被认为是异常值时，例如偏离邻近数据点的情况。需要注意的是，对于上下文异常值，如果上下文发生变化，同一观察值可能不再被视为异常值。
- en: In this chapter, you will be introduced to a handful of practical statistical
    techniques that cover parametric and non-parametric methods. In *Chapter 14*,
    *Outlier Detection Using Unsupervised Machine Learning*, you will dive into more
    advanced machine learning and deep learning-based techniques.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将接触到一些实用的统计技术，包括参数方法和非参数方法。在*第14章*《*使用无监督机器学习进行异常值检测*》中，您将深入了解基于机器学习和深度学习的更高级技术。
- en: In the literature, you will find another popular term, **anomaly detection**,
    which can be synonymous with **outlier detection**. The methods and techniques
    to identify outlier or anomaly observations are similar; the difference lies in
    the context and the actions that follow once these points have been identified.
    For example, an outlier transaction in financial transactions may be referred
    to as an anomaly and trigger a fraud investigation to stop them from re-occurring.
    Under a different context, survey data with outlier data points may simply be
    removed by the researchers once they examine the overall impact of keeping versus
    removing such points. Sometimes you may decide to keep these outlier points if
    they are part of the natural process. In other words, they are legitimate and
    opt to use robust statistical methods that are not influenced by outliers.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在文献中，您会发现另一个常用的术语，**异常检测**，它与**异常值检测**是同义的。识别异常或异常值的方式和技术是相似的；它们的区别在于上下文和识别后采取的措施。例如，金融交易中的异常交易可能被视为异常，并触发反欺诈调查，以防止其再次发生。在不同的上下文中，研究人员在检查保留与移除这些点的总体影响后，可能会选择简单地删除调查数据中的异常数据点。有时，您可能会决定保留这些异常值，如果它们是自然过程的一部分。换句话说，它们是合法的，并选择使用不受异常值影响的稳健统计方法。
- en: Another concept, known as **change point detection** (**CPD**), relates to outlier
    detection. In CPD, the goal is to anticipate abrupt and impactful fluctuations
    (increasing or decreasing) in the time series data. CPD covers specific techniques,
    for example, **cumulative sum** (**CUSUM**) and **Bayesian online change point
    detection** (**BOCPD**). Detecting change is vital in many situations. For example,
    a machine may break if the internal temperature reaches a certain point or if
    you are trying to understand whether the discounted price did increase sales or
    not. This distinction between outlier detection and CPD is vital since sometimes
    you may want the latter. Where the two disciplines converge, depending on the
    context, sudden changes may indicate the potential presence of outliers (anomalies).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个与异常值检测相关的概念是**变点检测**（**CPD**）。在变点检测中，目标是预测时间序列数据中的剧烈且有影响的波动（增加或减少）。变点检测包含特定技术，例如**累积和**（**CUSUM**）和**贝叶斯在线变点检测**（**BOCPD**）。变点检测在许多情况下至关重要。例如，当机器的内部温度达到某个点时，可能会发生故障，或者如果您想了解打折价格是否促进了销售增长时，这也很重要。异常值检测和变点检测之间的区别至关重要，因为有时您可能需要后者。当这两种学科相交时，根据上下文，突发的变化可能表明异常值（异常）的潜在存在。
- en: 'The recipes that you will encounter in this chapter are as follows:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中您将遇到的食谱如下：
- en: Resampling time series data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新采样时间序列数据
- en: Detecting outliers using visualizations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用可视化方法检测异常值
- en: Detecting outliers using the Tukey method
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Tukey方法检测异常值
- en: Detecting outliers using a z-score
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用z-score检测异常值
- en: Detecting outliers using a modified z-score
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用修改后的z-score检测异常值
- en: Detecting outliers using other non-parametric methods
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用其他非参数方法检测异常值
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You can download the Jupyter Notebooks and needed datasets from the GitHub
    repository:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从GitHub仓库下载Jupyter Notebooks和所需的数据集：
- en: 'Jupyter Notebook: [https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook-Second-Edition/blob/main/code/Ch8/Chapter%208.ipynb](https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook-Second-Edition/blob/main/code/Ch8/Chapter%208.ipynb)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jupyter Notebook：[https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook-Second-Edition/blob/main/code/Ch8/Chapter%208.ipynb](https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook-Second-Edition/blob/main/code/Ch8/Chapter%208.ipynb)
- en: 'Datasets: [https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook-Second-Edition/tree/main/datasets/Ch8](https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook-Second-Edition/tree/main/datasets/Ch8)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集：[https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook-Second-Edition/tree/main/datasets/Ch8](https://github.com/PacktPublishing/Time-Series-Analysis-with-Python-Cookbook-Second-Edition/tree/main/datasets/Ch8)
- en: 'Throughout the chapter, you will be using a dataset from the **Numenta Anomaly
    Benchmark** (**NAB**), which provides outlier detection benchmark datasets. For
    more information about NAB, please visit their GitHub repository here: [https://github.com/numenta/NAB](https://github.com/numenta/NAB).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将使用**Numenta异常基准**（**NAB**）提供的数据集，它提供了用于异常值检测的基准数据集。有关NAB的更多信息，请访问他们的GitHub仓库：[https://github.com/numenta/NAB](https://github.com/numenta/NAB)。
- en: The *New York Taxi dataset* captures the number of NYC taxi passengers at a
    specific timestamp. The data contains known anomalies that are provided to evaluate
    the performance of our outlier detectors. The dataset contains *10,320* records
    between *July 1, 2014*, to *May 31, 2015*. The observations are captured in a
    30-minute interval, which translates to `freq = ‘30T’`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*纽约出租车数据集*记录了特定时间戳下纽约市出租车乘客的数量。该数据包含已知的异常值，用于评估我们异常值检测器的性能。数据集包含*10,320*条记录，时间范围是*2014年7月1日*到*2015年5月31日*。这些观测值是以30分钟的间隔记录的，对应于`freq
    = ''30T''`。'
- en: 'To prepare for the outlier detection recipes, start by loading the libraries
    that you will be using throughout the chapter:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备异常值检测步骤，首先加载你将在整个章节中使用的库：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Load the `nyc_taxi.csv` data into a pandas DataFrame as it will be used throughout
    the chapter:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 将`nyc_taxi.csv`数据加载到pandas DataFrame中，因为它将在本章中贯穿始终：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can store the known dates containing outliers, also known as **ground truth
    labels**:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以存储包含异常值的已知日期，这些异常值也被称为**真实标签**：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If you investigate these dates to gain more insight into their significance,
    you will find similar information to the following summary:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你研究这些日期以获得更多的见解，你会发现类似以下总结的信息：
- en: '*Saturday, November 1, 2014*, was before the New York Marathon, and the official
    marathon event was on Sunday, November 2, 2014.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*2014年11月1日，星期六*，是在纽约马拉松赛之前，官方的马拉松赛事是在2014年11月2日，星期日。'
- en: '*Thursday, November 27, 2014*, was Thanksgiving Day.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*2014年11月27日，星期四*，是感恩节。'
- en: '*Thursday, December 25, 2014*, was Christmas Day.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*2014年12月25日，星期四*，是圣诞节。'
- en: '*Thursday, January 1, 2015*, was New Year’s Day.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*2015年1月1日，星期四*，是元旦。'
- en: '*Tuesday, January 27, 2015*, was the North American Blizzard where all vehicles
    were ordered off the street from January 26 to January 27, 2015.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*2015年1月27日，星期二*，是北美暴风雪事件，在2015年1月26日至1月27日之间，所有车辆被命令停驶。'
- en: 'You can plot the time series data to gain an intuition on the data you will
    be working with for outlier detection:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以绘制时间序列数据，以便对你将在异常值检测中使用的数据有一个直观的了解：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This should produce a time series with a 30-minute frequency:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该生成一个频率为30分钟的时间序列：
- en: '![Figure 8.1: Plot of the New York City taxi time series data](img/file82.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1：纽约市出租车时间序列数据的图示](img/file82.jpg)'
- en: 'Figure 8.1: Plot of the New York City taxi time series data'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1：纽约市出租车时间序列数据的图示
- en: 'Finally, create the `plot_outliers` function that you will use throughout the
    recipes:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，创建一个`plot_outliers`函数，你将在整个过程中使用该函数：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As we proceed with the outlier detection recipes, the goal is to see how the
    different techniques capture outliers and compare them to the ground truth labels.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们推进异常值检测的步骤，目标是看看不同的技术如何捕捉异常值，并将其与真实标签进行比较。
- en: Understanding outliers
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解异常值
- en: The presence of outliers requires special handling and further investigation
    before hastily jumping to decisions on how to handle them. First, you will need
    to detect and spot their existence, which this chapter is all about. Domain knowledge
    can be instrumental in determining whether these identified points are outliers,
    their impact on your analysis, and how you should deal with them.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值的存在需要特别处理和进一步调查，不能草率决定如何处理它们。首先，你需要检测并识别它们的存在，这一章正是讲解这个内容。领域知识在确定这些被识别为异常值的点、它们对分析的影响以及如何处理它们方面可以发挥重要作用。
- en: Outliers can indicate bad data due to a random variation in the process, known
    as noise, or due to data entry error, faulty sensors, bad experiment, or natural
    variation. Outliers are usually undesirable if they seem synthetic, for example,
    bad data. On the other hand, if outliers are a natural part of the process, you
    may need to rethink removing them and opt to keep these data points. In such circumstances,
    you can rely on **non-parametric** statistical methods that do not make assumptions
    on the underlying distribution.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值可能表示由于过程中的随机变化（称为噪声）、数据输入错误、传感器故障、实验问题或自然变异等原因导致的错误数据。如果异常值看起来像是人工合成的，通常是不希望看到的，例如错误数据。另一方面，如果异常值是过程中的自然一部分，你可能需要重新考虑是否删除它们，而选择保留这些数据点。在这种情况下，你可以依赖于**非参数**统计方法，这些方法不对底层分布做假设。
- en: Generally, outliers can cause side effects when building a model based on strong
    assumptions on the data distribution; for example, the data is from a Gaussian
    (normal) distribution. Statistical methods and tests based on assumptions of the
    underlying distribution are referred to as **parametric methods**.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，异常值会在基于强假设的模型构建过程中引发副作用；例如，数据来自高斯（正态）分布。基于假设底层分布的统计方法和测试称为**参数方法**。
- en: There is no fixed protocol for dealing with outliers, and the magnitude of their
    impact will vary. For example, sometimes you may need to test your model with
    outliers and again without outliers to understand the overall impact on your analysis.
    In other words, not all outliers are created, nor should they be treated equally.
    However, as stated earlier, having domain knowledge is essential when dealing
    with these outliers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 处理异常值没有固定的协议，异常值的影响程度会有所不同。例如，有时你可能需要分别在有异常值和没有异常值的情况下测试你的模型，以了解它们对分析的整体影响。换句话说，并非所有异常值都是相同的，也不应当一视同仁。然而，正如前面所述，拥有领域知识在处理这些异常值时至关重要。
- en: Now, before using a dataset to build a model, you will need to test for the
    presence of such outliers so you can further investigate their significance. Spotting
    outliers is usually part of the data cleansing and preparation process before
    going deep into your analysis.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在使用数据集构建模型之前，你需要测试是否存在异常值，以便进一步调查它们的重要性。识别异常值通常是数据清洗和准备过程的一部分，之后才会深入进行分析。
- en: A common approach to handling outliers is to delete these data points and not
    have them be part of the analysis or model development. Alternatively, you may
    wish to replace the outliers using similar techniques highlighted in *Chapter
    7, Handling Missing Data*, such as imputation and interpolation. Other methods,
    such as smoothing the data, could minimize the impact of outliers. Smoothing,
    such as exponential smoothing, is discussed in *Chapter 10, Building Univariate
    Time Series Models Using Statistical Methods* . You may also opt to keep the outliers
    and use more resilient algorithms to their effect.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 处理异常值的常见方法是删除这些数据点，使它们不成为分析或模型开发的一部分。或者，你也可以希望使用*第7章，处理缺失数据*中提到的类似技术，如插补和插值，来替换异常值。其他方法，如平滑数据，可能有助于最小化异常值的影响。平滑方法，如指数平滑法，在*第10章，使用统计方法构建单变量时间序列模型*中有讨论。你也可以选择保留异常值，并使用对它们影响更为坚韧的算法。
- en: There are many well-known methods for outlier detection. The area of research
    is evolving, ranging from basic statistical techniques to more advanced approaches
    leveraging neural networks and deep learning. In statistical methods, you have
    different tools that you can leverage, such as the use of visualizations (boxplots,
    QQ-plots, histograms, and scatter plots), z-score, **interquartile range** (**IQR**)
    and Tukey fences, and statistical tests such as Grubbs test, the Tietjen-Moore
    test, or the generalized **Extreme Studentized Deviate** (**ESD**) test. These
    are basic, easy to interpret, and effective methods.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多知名的异常值检测方法。该研究领域正在发展，范围从基本的统计技术到更先进的方法，利用神经网络和深度学习。在统计方法中，你可以使用不同的工具，例如可视化工具（箱型图、QQ图、直方图和散点图）、z分数、**四分位距**（**IQR**）和图基围栏，以及诸如Grubbs检验、Tietjen-Moore检验或广义**极值学生化偏差**（**ESD**）检验等统计检验。这些方法是基本的、易于解释且有效的。
- en: In your first recipe, you will be introduced to a crucial time series transformation
    technique known as resampling before diving into outlier detection.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的第一个实例中，你将会在深入异常值检测之前，学习一个重要的时间序列转换技术——重采样。
- en: Resampling time series data
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重采样时间序列数据
- en: A typical transformation that is done on time series data is **resampling**.
    The process implies changing the frequency or level of granularity of the data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列数据中，一个典型的转换操作是**重采样**。该过程意味着改变数据的频率或粒度水平。
- en: Usually, you will have limited control over how the time series is generated
    in terms of frequency. For example, the data can be generated and stored in small
    intervals, such as milliseconds, minutes, or hours. In some cases, the data can
    be in larger intervals, such as daily, weekly, or monthly.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你对时间序列生成的频率控制有限。例如，数据可能在小的时间间隔内生成和存储，如毫秒、分钟或小时。在某些情况下，数据可能是按较大的时间间隔生成的，如按天、按周或按月。
- en: The need for resampling time series can be driven by the nature of your analysis
    and at what granular level you need your data to be. For instance, you can have
    daily data, but your analysis requires the data to be weekly, and thus you will
    need to resample. This process is known as **downsampling**. When you are downsampling,
    you will need to provide some level of aggregation, such as mean, sum, min, or
    max, to name a few. On the other hand, some situations require you to resample
    your data from daily to hourly. This process is known as **upsampling**. When
    upsampling, you may introduce null rows, which you can fill using imputation or
    interpolation techniques. See *Chapter 7*, *Handling Missing Data*, where both
    imputation and interpolation methods were discussed in more detail.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对时间序列进行重采样的需求可能来源于你的分析性质以及数据需要达到的粒度级别。例如，你可以拥有按天记录的数据，但分析要求数据以周为单位，因此你需要进行重采样。这个过程称为**下采样**。进行下采样时，你需要提供某种聚合方式，如均值、总和、最小值或最大值等。另一方面，一些情况下需要将数据从每日重采样为每小时。这一过程称为**上采样**。在上采样时，可能会引入空值行，你可以使用插补或插值技术来填充这些空值。详见*第7章*，*处理缺失数据*，其中详细讨论了插补和插值方法。
- en: In this recipe, you will explore how resampling is done using the `pandas` library.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实例中，你将会使用`pandas`库来探索如何进行重采样。
- en: How to do it…
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何操作……
- en: In this recipe, you will work with the `nyc_taxis` DataFrame created earlier
    in the *Technical requirements* section. The data captures the number of passengers
    in *30-minute* intervals.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实例中，你将使用*技术要求*部分中早些时候创建的`nyc_taxis` DataFrame。该数据捕获了*30分钟*间隔内的乘客数量。
- en: '**Downsample** the data to a daily frequency. Currently, you have `10,320`
    records, and when you resample the data to daily, you will need to aggregate the
    data. In this example, you will use the `.mean()` function. This will reduce the
    number of samples to 215 records. The term *downsampling* indicates that the number
    of samples went down, and more concretely, we are decreasing the frequency of
    the data.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下采样**数据至每日频率。当前，你有`10,320`条记录，当你将数据重采样至每日时，你需要对数据进行聚合。在这个例子中，你将使用`.mean()`函数。这将把样本数减少到215条记录。术语*下采样*表示样本数量减少，具体来说，我们正在减少数据的频率。'
- en: 'Inspect the first five rows of the original DataFrame:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 检查原始DataFrame的前五行：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Resampling is done using the `DataFrame.resample()` function. For daily, you
    will use `''D''` as the date offset rule, followed by `.mean()` as the method
    of aggregation:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 重采样通过`DataFrame.resample()`函数来完成。对于按天重采样，你将使用`'D'`作为日期偏移规则，然后使用`.mean()`作为聚合方法：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Notice how `DatetimeIndex` is now at a daily frequency, and the number of passengers
    now reflects the daily average. Inspect the first `DatetimeIndex` to check its
    frequency:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在`DatetimeIndex`的频率为每日频率，且乘客数量现在反映的是每日平均数。检查第一个`DatetimeIndex`以查看其频率：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You can also check frequency directly using the `.freq` property:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以直接使用`.freq`属性检查频率：
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Check the number of records now after downsampling:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 检查下采样后的记录数：
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Indeed, now you have `215` records.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，您现在有`215`条记录。
- en: 'Resample the `nyc_taxi` data again, but this time as a 3-day frequency. You
    can do this by using the offset string `''3D''`. This time, use the `.sum()` method
    instead:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次重采样`nyc_taxi`数据，这次使用3天频率。您可以使用偏移字符串`'3D'`来做到这一点。这次，请使用`.sum()`方法：
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Check the frequency of `DatetimeIndex`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 检查`DatetimeIndex`的频率：
- en: '[PRE11]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If you use `df_downsampled.shape` you will notice the number of records got
    reduced to 72 records.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用`df_downsampled.shape`，您会注意到记录的数量减少到了72条。
- en: 'Now, change the frequency to three (3) business days instead. The default in
    `pandas` is Monday to Friday. In the *Working with custom business days recipe*
    in *Chapter 6*, *Working with Date and Time in Python*, You learned how to create
    custom business days. For now, you will use the default definition of business
    days. If you observe the output from the previous step, `2014-07-13` falls on
    a Sunday. Using `''3B''` as the `DateOffset` will push it to the following Monday,
    `2014-07-14`:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，将频率改为三（3）个工作日。`pandas`的默认值是从星期一到星期五。在*第6章，处理日期和时间*的*使用自定义工作日的技巧*中，您已经学习了如何创建自定义工作日。目前，您将使用默认的工作日定义。如果您查看上一步骤的输出，`2014-07-13`是星期天。使用`'3B'`作为`DateOffset`会将其推到下一个星期一，即`2014-07-14`：
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Interesting output in how it skips 5 days from 2014-07-04 to 2014-07-09, and
    then again from 2014-07-09 to 2014-07-14\. The reason is the *Business Day rule*
    which specifies we have two (2) days of the week as weekends. Since the function
    is calendar-aware, it knows a weekend is coming after the first 3-day increment,
    so it adds a 2-day weekend to skip them, and thus, it makes a 5-day jump. Starting
    from 2014-07-04, thus moving to 2014-07-09, and from 2017-07-09 moving to 2017-07-14\.
    And similarly, from 2014-07-17 to 2014-07-22, and so on.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的输出显示，它跳过了从2014-07-04到2014-07-09的5天时间，然后又从2014-07-09跳到2014-07-14。原因是*工作日规则*，它规定了我们有两（2）天作为周末。由于该函数是日历感知的，它知道在第一次3天的增量之后会有周末，所以它会加上2天的周末来跳过它们，从而形成了一个5天的跳跃。从2014-07-04开始，跳到2014-07-09，然后从2017-07-09跳到2017-07-14。类似的，从2014-07-17跳到2014-07-22，依此类推。
- en: 'Lastly, let''s **upsample** the data from a 30-minute interval (frequency)
    to a 15-minutes frequency. This will create an empty entry (`NaN`) between every
    other entry. You will use offset string `''T''` for minutes, since `''M''` is
    used for monthly aggregation:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们**上采样**数据，从30分钟间隔（频率）变为15分钟频率。这将会在每两个数据之间创建一个空条目（`NaN`）。您将使用偏移字符串`'T'`表示分钟，因为`'M'`用于按月聚合：
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Notice that upsampling creates `NaN` rows. Unlike *downsampling*, when *upsampling*,
    you need to give instructions on how to fill the `NaN` rows. You might be wondering
    why we used `.mean()` here? The simple answer is because it would not matter whether
    you used `.sum()`, `.max()`, or `.min()`, for example. You will need to augment
    the missing rows using imputation or interpolation techniques when you *upsample*.
    For example, you can specify an imputation value using `.fillna()` or by using
    `.ffill()` or `.bfill() methods`:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，上采样会创建`NaN`行。与*下采样*不同，在*上采样*时，您需要提供如何填充`NaN`行的说明。您可能会想知道为什么我们这里使用了`.mean()`？简单的答案是，无论您是使用`.sum()`、`.max()`还是`.min()`，例如，结果都不会有所不同。在*上采样*时，您需要使用插补或插值技术来填充缺失的行。例如，您可以使用`.fillna()`指定插补值，或者使用`.ffill()`或`.bfill()`方法：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The first five records show the use of forward filling. For more information
    on using `.fillna()`, `.bfill()`, or `.ffill()` or imputation in general, refer
    to *Chapter 7, Handling Missing Data*.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 前五条记录显示了使用前向填充的方法。如需更多关于使用`.fillna()`、`.bfill()`或`.ffill()`，或一般插补的相关信息，请参考*第7章，处理缺失数据*。
- en: Overall, resampling in pandas is very convenient and straightforward. This can
    be a handy tool when you want to change the frequency of your time series.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，pandas中的重采样非常方便和直接。当您想要改变时间序列的频率时，这是一个很实用的工具。
- en: How it works…
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: The `DataFrame.resample()` method allows you to group rows in a specified time
    frame, for example, by day, week, month, year, or any DateTime attribute. The
    way `.resample()` works is by grouping the data using the `DatetimeIndex` and
    the frequency provided, hence, this method is specific to time series DataFrames.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataFrame.resample()` 方法允许你在指定的时间框架内对行进行分组，例如按天、周、月、年或任何 DateTime 属性。`.resample()`
    的工作原理是通过使用 `DatetimeIndex` 和提供的频率对数据进行分组，因此，此方法特定于时间序列 DataFrame。'
- en: The `.resample()` function works in a very similar manner to the `.groupby()`
    function; the difference is that `.resample()` is specific to time series data
    and groups at the `DatetimeIndex`.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`.resample()` 函数的工作方式与 `.groupby()` 函数非常相似；不同之处在于，`.resample()` 专门用于时间序列数据，并按
    `DatetimeIndex` 进行分组。'
- en: There's more...
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 还有更多...
- en: You can supply more than one aggregation at once when downsampling using the
    `.agg()` function.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行降采样时，你可以一次提供多个聚合操作，使用 `.agg()` 函数。
- en: 'For example, using `''M''` for monthly, you can supply the `.agg()` function
    with a list of aggregations you want to perform:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用`'M'`表示按月，你可以为 `.agg()` 函数提供一个你想要执行的聚合操作列表：
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This should produce a DataFrame with five columns, one for each aggregation
    method specified. The index column, a `timestamp` column, will be grouped at monthly
    intervals:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该生成一个包含五列的 DataFrame，每个聚合方法对应一列。索引列和`timestamp`列将按月进行分组：
- en: '![Figure 8.2: Multiple aggregations using the .agg() method](img/file83.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2：使用 `.agg()` 方法进行多重聚合](img/file83.jpg)'
- en: 'Figure 8.2: Multiple aggregations using the .agg() method'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2：使用 `.agg()` 方法进行多重聚合
- en: Notice that the default behavior for `'M'` or monthly frequency is at the month's
    end (example *2014-07-31*). You can change to month's start instead by using `'MS'`.
    For example, this will produce *2014-07-01* instead (the beginning of each month).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`'M'` 或月频率的默认行为是在月末（例如 *2014-07-31*）。你也可以改为使用 `'MS'` 来设置为月初。例如，这将生成 *2014-07-01*（每月的第一天）。
- en: See also
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'To learn more about pandas `DataFrame.resample()`, please visit the official
    documentation here: [https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 pandas `DataFrame.resample()` 的信息，请访问官方文档：[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html)。
- en: Detecting outliers using visualizations
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用可视化方法检测异常值
- en: 'There are two general approaches for using statistical techniques to detect
    outliers: **parametric** and **non-parametric** methods. **Parametric** methods
    assume you know the underlying distribution of the data. For example, if your
    data follows a normal distribution. On the other hand, in **non-parametric** methods,
    you make no such assumptions.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用统计技术检测异常值有两种常见方法：**参数性**方法和**非参数性**方法。**参数性**方法假设你知道数据的基础分布。例如，如果你的数据遵循正态分布。另一方面，**非参数性**方法则没有这样的假设。
- en: 'Using histograms and box plots are basic non-parametric techniques that can
    provide insight into the distribution of the data and the presence of outliers.
    More specifically, box plots, also known as **box and whisker** plots, provide
    a five-number summary: the *minimum*, *first quartile* (25th percentile), *median*
    (50th percentile), *third quartile* (75th percentile), and the *maximum*. There
    are different implementations for how far the whiskers extend, for example, the
    whiskers can extend to the *minimum* and *maximum* values. In most statistical
    software, including Python''s **matplotlib** and **seaborn** libraries, the whiskers
    extend to what is called **Tukey''s Lower and Upper Fences**. Any data point outside
    these boundaries is considered a potential outlier. You will dive into the actual
    calculation and implementation in the *Detecting outliers using the Tukey method*
    recipe. For now, let''s focus on the visualization aspect of the analysis.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 使用直方图和箱型图是基本的非参数技术，可以提供数据分布和异常值存在的洞察。更具体地说，箱型图，也叫做 **箱线图**，提供了五个数值概述：*最小值*、*第一四分位数*（25
    百分位数）、*中位数*（50 百分位数）、*第三四分位数*（75 百分位数）和 *最大值*。在箱线图中，须的扩展范围有不同的实现方式，例如，须可以延伸到 *最小值*
    和 *最大值*。在大多数统计软件中，包括 Python 的 **matplotlib** 和 **seaborn** 库，须会延伸到所谓的 **Tukey's
    Lower and Upper Fences**。任何超出这些边界的数据点都被认为是潜在的异常值。在 *使用 Tukey 方法检测异常值* 这一配方中，你将深入了解实际的计算和实现。现在，让我们关注分析中的可视化部分。
- en: In this recipe, you will use **seaborn** as another Python visualization library
    that is based on **matplotlib**`.`
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，你将使用**seaborn**，这是另一个基于**matplotlib**的 Python 可视化库。
- en: Getting ready
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备工作
- en: You can download the Jupyter Notebooks and required datasets from the GitHub
    repository. Please refer to the *Technical requirements* section of this chapter.
    You will be using the `nyc_taxi` DataFrame that you loaded earlier in the *Technical
    requirements* section.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从 GitHub 仓库下载 Jupyter Notebook 和所需的数据集。请参考本章的*技术要求*部分。你将使用在*技术要求*部分中加载的 `nyc_taxi`
    数据框。
- en: You will be using `seaborn` version *0.11.2*, which is the latest version as
    of this writing.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用 `seaborn` 版本 *0.11.2*，这是截至目前的最新版本。
- en: 'To install `seaborn` using `pip`, use the following:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 `pip` 安装 `seaborn`，请使用以下命令：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To install `seaborn` using `conda`, use the following:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 `conda` 安装 `seaborn`，请使用以下命令：
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: How to do it...
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何操作...
- en: In this recipe, you will explore different plots available from `seaborn` including
    `histplot()`, `displot()`, `boxplot()`, `boxenplot()`, and `violinplot()`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，你将探索来自 `seaborn` 的不同图表，包括 `histplot()`、`displot()`、`boxplot()`、`boxenplot()`
    和 `violinplot()`。
- en: 'You will notice that these plots tell a similar story but visually, each plot
    represents the information differently. Eventually, you will develop a preference
    toward some of these plots for your own use when investigating your data:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，这些图表传达了相似的故事，但在视觉上，每个图表的呈现方式不同。最终，在调查数据时，你将对这些图表中的某些图表产生偏好，用于自己的分析：
- en: 'Start by importing the `seaborn` library to begin exploring how these plots
    work to help you detect outliers:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导入 `seaborn` 库，开始探索这些图表如何帮助你检测异常值：
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Recall from *Figure 8.1*, the `nyc_taxi` DataFrame contains passenger counts
    recorded every 30 minutes. Keep in mind that every analysis or investigation is
    unique and so should be your approach to align with the problem you are solving.
    This also means that you will need to consider your data preparation approach,
    for example, determine what transformations you need to apply to your data.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回想一下*图 8.1*，`nyc_taxi` 数据框包含每 30 分钟记录的乘客数量。请记住，每个分析或调查都是独特的，因此你的方法应该与解决的问题相匹配。这也意味着你需要考虑数据准备方法，例如，确定需要对数据应用哪些转换。
- en: For this recipe, the goal is to find which days have outlier observations, not
    at which interval within the day, so you will *resample* the data to a daily frequency.
    You will start by **downsampling** the data using the `mean` aggregation. Even
    though such a transformation will smooth out the data, you will not lose too much
    of the detail as it pertains to finding outliers since the `mean` is sensitive
    to outliers. In other words, if there was an extreme outlier on a specific interval
    (there are 48 intervals in a day), the `mean` will still carry that information.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本例，目标是找出哪些天存在异常观察值，而不是哪一天的哪个时间段，因此你将*重采样*数据以按天进行分析。你将首先使用 `mean` 聚合来**下采样**数据。尽管这样的转换会平滑数据，但由于
    `mean` 对异常值敏感，因此你不会失去太多与查找异常值相关的细节。换句话说，如果某个特定时间段内存在极端异常值（一天有 48 个时间段），`mean`
    仍然会保留这一信息。
- en: 'In this step you will Downsample the data to a daily frequency using the `.resample()`
    method and using `‘D’` as the offset string. This will reduce the number of observations
    from `10,320` to `215` (which is `10320/48 = 215`):'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，你将使用 `.resample()` 方法将数据下采样到每日频率，并使用 `‘D’` 作为偏移字符串。这将把观察值的数量从 `10,320`
    减少到 `215`（即 `10320/48 = 215`）：
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Plot the new `tx` DataFrame with the ground truth labels to use as a reference.
    You will call the `plot_outliers` function that you created from the *Technical
    requirements* section:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制新的 `tx` 数据框，并使用真实标签作为参考。你将调用你在*技术要求*部分中创建的 `plot_outliers` 函数：
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This should produce a time series plot with `X` markers for known outliers.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成一个带有 `X` 标记的时间序列图，标记出已知的异常值。
- en: '![Figure 8.3: Plotting the NYC Taxi data after downsampling with ground truth
    labels (outliers)](img/file84.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3：使用真实标签（异常值）对纽约出租车数据进行下采样后的绘图](img/file84.jpg)'
- en: 'Figure 8.3: Plotting the NYC Taxi data after downsampling with ground truth
    labels (outliers)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3：使用真实标签（异常值）对纽约出租车数据进行下采样后的绘图
- en: 'Now, let''s start with your first plot for inspecting your time series data
    using the `histplot()` function:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们从第一个图开始，使用 `histplot()` 函数检查你的时间序列数据：
- en: '[PRE21]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This should produce the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成以下结果：
- en: '![Figure 8.4: Histogram showing extreme daily mean passenger rides](img/file85.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图8.4：显示极端每日平均乘客乘车次数的直方图](img/file85.jpg)'
- en: 'Figure 8.4: Histogram showing extreme daily mean passenger rides'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4：显示极端每日平均乘客乘车次数的直方图
- en: In *Figure 8.4*, the observations labeled as `1`, `2`, `3`, `4`, and `5` seem
    to represent extreme passenger values. Recall, these numbers represent the average
    daily passengers after resampling. The question you should ask is whether these
    observations are outliers. The center of the histogram is close to 15,000 daily
    average passengers. This should make you question whether the extreme value close
    to 20,000 (*label* `5`) is that extreme. Similarly, the observations labeled `3`
    and `4` (since they are close to the tail of the distribution), are they actually
    extreme values? How about labels `1` and `2` with average passenger rides at 3,000
    and 8,000 daily average passengers respectively? These do seem more extreme compared
    to the rest and may potentially be actual outliers. Again, determining what is
    an outlier and what is not requires domain knowledge and further analysis. There
    is no specific rule, and you will see throughout this chapter that some of the
    generally accepted rules are arbitrary and subjective. You should not jump to
    conclusions immediately.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图8.4*中，标记为`1`、`2`、`3`、`4`和`5`的观测值似乎代表了极端的乘客数值。回想一下，这些数字表示的是重采样后的平均每日乘客数量。你需要问自己的是，这些观测值是否是离群值。直方图的中心接近15,000每日平均乘客数量。这应该让你质疑接近20,000的极端值（*标签*
    `5`）是否真的那么极端。类似地，标记为`3`和`4`的观测值（因为它们接近分布的尾部），它们是否真的是极端值？那么标记为`1`和`2`的观测值呢？它们的平均乘客数量分别为3,000和8,000每日乘客，似乎比其他值更极端，可能是实际的离群值。再一次，确定什么是离群值、什么不是离群值需要领域知识和进一步分析。没有具体的规则，你会发现在本章中，一些被普遍接受的规则实际上是任意的、主观的。你不应急于得出结论。
- en: 'You can achieve a similar plot using `displot()`, which has a `kind` parameter.
    The `kind` parameter can take one of three values: `hist` for the histogram plot,
    `kde` for the kernel density estimate plot, and `ecdf` for the empirical cumulative
    distribution function plot.'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用`displot()`绘制类似的图表，它具有一个`kind`参数。`kind`参数可以取三个值之一：`hist`表示直方图，`kde`表示核密度估计图，`ecdf`表示经验累积分布函数图。
- en: 'You will use `displot(kind=''hist'')` to plot a similar histogram as the one
    in *Figure 8.4*:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用`displot(kind='hist')`来绘制一个类似于*图8.4*中的直方图：
- en: '[PRE22]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: A box plot provides more information than a histogram and can be a better choice
    for spotting outliers. In a box plot, observations that are outside the whiskers
    or boundaries are considered potential outliers. The whiskers represent the visual
    boundary for the upper and lower fences as proposed by mathematician **John Tukey**
    in 1977.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 箱型图提供的信息比直方图更多，可以更好地帮助识别离群值。在箱型图中，超出须状线或边界的观测值被认为是潜在的离群值。须状线表示上界和下界的视觉边界，这是数学家**约翰·图基**于1977年提出的。
- en: 'The following code shows how to create a box plot using `seaborn`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何使用`seaborn`创建箱型图：
- en: '[PRE23]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following figure shows the potential outliers:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了潜在的离群值：
- en: '![Figure 8.5: A box plot showing potential outliers that are outside the boundaries
    (whiskers)](img/file86.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图8.5：显示可能的离群值超出边界（须状线）的箱型图](img/file86.jpg)'
- en: 'Figure 8.5: A box plot showing potential outliers that are outside the boundaries
    (whiskers)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5：显示可能的离群值超出边界（须状线）的箱型图
- en: The width of the box (**Q1** to **Q3**) is called the **interquartile range**
    (**IQR**) calculated as the difference between the 75th and 25th percentiles (**Q3**
    – **Q1**). The lower fence is calculated as `Q1 - (1.5 x IQR)`, and the upper
    fence as `Q3 + (1.5 x IQR)`. Any observation less than the lower boundary or greater
    than the upper boundary is considered a potential outlier. More on that in the
    *Detecting outliers using the Tukey method* recipe. The `whis` parameter in the
    `boxplot()` function is set to `1.5` by default (1.5 times IQR), which controls
    the width or distance between the upper and lower fences. Larger values mean fewer
    observations will be deemed as outliers, and smaller values will make non-outlier
    points seem outside of boundaries (more outliers).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 箱体的宽度（**Q1**到**Q3**）称为**四分位数范围**（**IQR**），其计算方式为75th和25th百分位数的差值（**Q3** – **Q1**）。下边界的计算公式为`Q1
    - (1.5 x IQR)`，上边界为`Q3 + (1.5 x IQR)`。任何小于下边界或大于上边界的观测值都被视为潜在的异常值。有关更多信息，请参阅*使用Tukey方法检测异常值*一文。`boxplot()`函数中的`whis`参数默认为`1.5`（1.5倍IQR），控制上下边界之间的宽度或距离。较大的值意味着较少的观测值会被视为异常值，而较小的值则会让非异常值看起来超出边界（更多的异常值）。
- en: '[PRE24]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'There are two more variations for box plots in **seaborn** (`boxenplot()` and
    `violinplot()`). They provide similar insight as to the boxplot but are presented
    differently. The *boxen plot*, which in literature is referred to as a *letter-value*
    plot, can be considered as an enhancement to regular box plots to address some
    of their shortcomings, as described in the paper *Heike Hofmann, Hadley Wickham
    & Karen Kafadar (2017) Letter-Value Plots: Boxplots for Large Data, Journal of
    Computational and Graphical Statistics, 26:3, 469-477*. More specifically, boxen
    (letter-value) plots are better suited when working with larger datasets (higher
    number of observations for displaying data distribution and more suitable for
    differentiating outlier points for larger datasets). The `seaborn` implementation
    of `boxenplot` is based on that paper.'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**seaborn**中有两种额外的箱型图变种（`boxenplot()` 和 `violinplot()`）。它们提供与箱型图相似的见解，但呈现方式不同。*boxen图*（在文献中称为*字母值*图）可以视为对常规箱型图的增强，旨在解决它们的一些不足之处，具体描述见论文*Heike
    Hofmann, Hadley Wickham & Karen Kafadar (2017) Letter-Value Plots: Boxplots for
    Large Data, Journal of Computational and Graphical Statistics, 26:3, 469-477*。更具体地说，boxen（字母值）图更适合用于处理较大数据集（用于显示数据分布的观测值较多，更适合区分较大数据集中的异常值）。`seaborn`实现的`boxenplot`基于该论文。'
- en: 'The following code shows how to create a boxen (letter-value) plot using `seaborn`:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何使用`seaborn`创建boxen（字母值）图：
- en: '[PRE25]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This should produce a plot that looks like the box plot in *Figure 8.5*, but
    with boxes extending beyond the quartiles (**Q1**, **Q2**, and **Q3**). The 25th
    percentile is at the 14,205 daily average passengers mark, and the 75th percentile
    is at the 16,209 daily average passengers mark.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成类似于*图8.5*中箱型图的图形，但箱体会延伸超出四分位数（**Q1**、**Q2**和**Q3**）。25th百分位数位于14,205每日平均乘客数的位置，75th百分位数位于16,209每日平均乘客数的位置。
- en: '![Figure 8.6: A boxen (letter-value) plot for the average daily taxi passengers
    in NYC](img/file87.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图8.6：纽约市每日出租车乘客的boxen（字母值）图](img/file87.jpg)'
- en: 'Figure 8.6: A boxen (letter-value) plot for the average daily taxi passengers
    in NYC'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6：纽约市每日出租车乘客的boxen（字母值）图
- en: PERCENTILE VALUES
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 百分位值
- en: ''
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Are you wondering how I was able to determine the exact value for the 25th,
    50th, and 75th percentiles?
  id: totrans-146
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你是否好奇我如何确定25th、50th和75th百分位的精确值？
- en: ''
  id: totrans-147
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can obtain these values for a DataFrame or series with the `describe` method.
    For example, if you run `tx.describe()`, you should see a table of descriptive
    statistics that includes count, mean, standard deviation, minimum, maximum, 25th,
    50th, and 75th percentile values for the dataset.
  id: totrans-148
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以通过`describe`方法为DataFrame或序列获取这些值。例如，如果你运行`tx.describe()`，你应该能看到一张描述性统计表，其中包括数据集的计数、均值、标准差、最小值、最大值、25th、50th和75th百分位数值。
- en: In *Figure 8.6*, you are getting additional insight into the distribution of
    passengers beyond the quantiles. In other words, it extends the box plot to show
    additional distributions to give more insight into the tail of the data. The boxes
    in theory could keep going to accommodate all the data points, but in order to
    show outliers, there needs to be a stopping point, referred to as **depth**. In
    `seaborn`, this parameter is called `k_depth`, which can take a numeric value,
    or you can specify different methods such as `tukey`, `proportion`, `trustworthy`,
    or `full`. For example, a `k_depth=1` numeric value will show a similar box to
    the boxplot in *Figure 8.5* (one box). As a reference, *Figure 8.6* shows four
    boxes determined using the `Tukey` method, which is the default value (`k_depth="tukey"`).
    Using `k_depth=4` would produce the same plot.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 8.6*中，你可以获得超越分位数的乘客分布的额外洞察。换句话说，它扩展了箱形图以显示额外的分布，从而为数据的尾部提供更多的洞察。理论上，这些框可以一直延伸，以容纳所有数据点，但为了显示异常值，需要有一个停止点，这个点称为**深度**。在`seaborn`中，这个参数被称为`k_depth`，它可以接受一个数值，或者你可以指定不同的方法，如`tukey`、`proportion`、`trustworthy`或`full`。例如，`k_depth=1`的数值将显示与*图
    8.5*中的箱形图相似的框（一个框）。作为参考，*图 8.6*显示了使用`Tukey`方法确定的四个框，这是默认值（`k_depth="tukey"`）。使用`k_depth=4`将产生相同的图形。
- en: 'These methods are explained in the referenced paper by *Heike Hofmann, Hadley
    Wickham & Karen Kafadar (2017)*. To explore the different methods, you can try
    the following code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法在*Heike Hofmann、Hadley Wickham & Karen Kafadar（2017）*的参考论文中有所解释。要探索不同的方法，你可以尝试以下代码：
- en: '[PRE26]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This should produce four plots; notice the different numbers of boxes that
    were determined by each method. Recall, you can also specify `k_depth` numerically
    as well:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生四个图形；请注意，每种方法确定的框数不同。回顾一下，你也可以按数值指定`k_depth`：
- en: '![Figure 8.7: The different k_depth methods available in seaborn for the boxenplot
    function](img/file88.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.7：seaborn中boxenplot函数可用的不同k_depth方法](img/file88.jpg)'
- en: 'Figure 8.7: The different k_depth methods available in seaborn for the boxenplot
    function'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7：seaborn中boxenplot函数可用的不同k_depth方法
- en: 'Now, the final variation is the violin plot, which you can display using the
    `violinplot` function:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，最后的变体是提琴图，你可以使用`violinplot`函数来显示：
- en: '[PRE27]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This should produce a plot that is a hybrid between a box plot and a **kernel
    density estimation** (**KDE**). A kernel is a function that estimates the probability
    density function, the larger peaks (wider area), for example, show where the majority
    of the points are concentrated. This means that there is a higher probability
    that a data point will be in that region as opposed to the much thinner regions
    showing much lower probability.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生一个介于箱形图和**核密度估计**（**KDE**）之间的混合图。核是一个估算概率密度函数的函数，较大的峰值（较宽的区域），例如，表示大多数点集中所在的区域。这意味着一个数据点出现在该区域的概率较高，而在较薄的区域，概率则较低。
- en: '![Figure 8.8: A violin plot for the average daily taxi passengers in NYC](img/file89.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.8：纽约市每日出租车乘客的提琴图](img/file89.jpg)'
- en: 'Figure 8.8: A violin plot for the average daily taxi passengers in NYC'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8：纽约市每日出租车乘客的提琴图
- en: Notice that *Figure 8.8* shows the distribution for the entire dataset. Another
    observation is the number of peaks; in this case, we have one peak, which makes
    it a unimodal distribution. If there is more than one peak, we call it a multimodal
    distribution, which should trigger a further investigation into the data. A KDE
    plot will provide similar insight as a histogram but with a more smoothed curve.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，*图 8.8*显示了整个数据集的分布。另一个观察点是峰值的数量；在这种情况下，我们有一个峰值，这使得它成为一个单峰分布。如果有多个峰值，我们称之为多峰分布，这应该引发对数据的进一步调查。KDE图将提供与直方图类似的洞察，但其曲线更加平滑。
- en: How it works...
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the recipe, we were introduced to several plots that help visualize the distribution
    of the data and show outliers. Generally, histograms are great for showing distribution,
    but a box plot (and its variants) are much better for outlier detection. We also
    explored the boxen (letter-value) plot, which is more suited for larger datasets
    and is more appropriate than regular box plots.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们介绍了几种图表，它们有助于可视化数据的分布并显示异常值。通常，直方图很适合显示分布，但箱形图（及其变体）在异常值检测方面要好得多。我们还探讨了箱线（字母值）图，它更适用于较大的数据集，比普通的箱形图更为合适。
- en: There's more...
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'In **seaboarn** both `histlpot()` and `displot()` support adding the kernel
    density estimate (KDE) plot with the parameter `kde`. The following code snippets
    should produce a similar plot:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **seaborn** 中，`histplot()` 和 `displot()` 都支持通过参数 `kde` 添加核密度估计（KDE）图。以下代码片段应该会生成一个相似的图形：
- en: '[PRE28]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This should produce a plot that combines a histogram and a KDE plot as shown:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成一个结合直方图和 KDE 图的图形，如下所示：
- en: '![Figure 8.9: A histogram with a KDE plot](img/file90.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.9：带有 KDE 图的直方图](img/file90.png)'
- en: 'Figure 8.9: A histogram with a KDE plot'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9：带有 KDE 图的直方图
- en: Additionally, another useful visualization for spotting outliers is the **lag
    plot**. A lag plot is essentially a scatter plot, but instead of plotting two
    variables to observe correlation, as an example, we plot the same variable against
    its lagged version. This means, it is a scatter plot using the same variable,
    but the *y* axis represents passenger count at the current time (*t*) and the
    *x* axis will show passenger count at a prior period (*t-1*), which we call **lag**.
    The lag parameter determines how many periods to go back; for example, a lag of
    `1` means one period back, while a lag of `2` means two periods back. In our resampled
    data (downsampled to daily), a lag of `1` represents the prior day.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，另一个有用的可视化方法用于发现异常值是 **滞后图**。滞后图本质上是一个散点图，但与绘制两个变量以观察相关性不同，举个例子，我们将同一变量与其滞后版本进行比较。这意味着，它是一个使用相同变量的散点图，但
    *y* 轴表示当前时刻 (*t*) 的乘客数量，*x* 轴显示的是前一个时刻 (*t-1*) 的乘客数量，这被称为 **滞后**。滞后参数决定了回溯的周期数；例如，滞后
    `1` 表示回溯一个周期，滞后 `2` 表示回溯两个周期。在我们的重采样数据（降采样至每日）中，滞后 `1` 代表前一天。
- en: 'The pandas library provides the `lag_plot` function, which you can use as shown
    in the following example:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库提供了 `lag_plot` 函数，你可以像下面的示例所示使用它：
- en: '[PRE29]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This should produce the following scatter plot:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成以下散点图：
- en: '![Figure 8.10: A lag plot of average daily taxi passengers in NYC](img/file91.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.10：纽约市日均出租车乘客的滞后图](img/file91.jpg)'
- en: 'Figure 8.10: A lag plot of average daily taxi passengers in NYC'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10：纽约市日均出租车乘客的滞后图
- en: The circled data points highlight interesting points that can be potential outliers.
    Some seem more extreme than others. Further, you can see some linear relationship
    between the passenger counts and its lagged version (prior day) indicating the
    existence of an autocorrelation. Recall from basic statistics that correlation
    shows the relationship between two independent variables, so you can think of
    autocorrelation as a correlation of a variable at a time (*t*) and its prior version
    at a time (*t-1*). More on this in *Chapter 9, Exploratory Data Analysis and Diagnosis*,
    and *Chapter 10, Building Univariate Time Series Models Using Statistical Methods*.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 被圈出的数据点突出显示了可能的异常值。有些点看起来比其他点更加极端。此外，你还可以看到乘客数量与其滞后版本（前一天）的线性关系，表明存在自相关性。回顾基础统计学中的相关性，相关性显示了两个独立变量之间的关系，因此你可以把自相关看作是一个变量在某一时刻
    (*t*) 和它在前一时刻 (*t-1*) 的版本之间的相关性。更多内容请参见 *第 9 章，探索性数据分析与诊断* 和 *第 10 章，使用统计方法构建单变量时间序列模型*。
- en: 'The labels for the *x*-axis and the *y*-axis in *Figure 8.10* can be a bit
    confusing, with the *y-axis* being labeled as *y(t+1)*. Essentially it is saying
    the same thing we described earlier: the *x*-axis represents prior values (the
    predictor) to its future self at *t+1*, which is what the *y*-axis represents.
    To make it clearer, you can recreate the exact visualization produced by `lag_plot`
    using `seaborn` manually, as shown in the following code:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 8.10* 中，*x* 轴和 *y* 轴的标签可能会有些混淆，*y 轴* 被标记为 *y(t+1)*。实际上，这表示了我们之前描述的同一个意思：*x*
    轴表示的是先前的值（预测变量），而 *y* 轴表示的是它的未来值 *t+1*。为了更清晰地理解，你可以像下面的代码所示，手动使用 `seaborn` 重现
    `lag_plot` 所生成的可视化效果：
- en: '[PRE30]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This should produce a similar plot to that in *Figure 8.10*.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成一个与 *图 8.10* 相似的图形。
- en: Notice in the code that the `y` values start from *t+1* (we skipped the value
    at index `0`) up to the last observation, and the `x` values start from index
    `0` up to index `-1` (we skip the last observation). This makes the values in
    the *y* axis ahead by one period.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 注意代码中，`y` 值从 *t+1* 开始（我们跳过了索引 `0` 处的值），直到最后一个观测值，而 `x` 值从索引 `0` 开始，到索引 `-1`（我们跳过了最后一个观测值）。这使得
    *y* 轴上的值领先一个周期。
- en: In the next recipe, we will dive further into **IQR** and **Tukey fences** that
    we briefly discussed when talking about box plots.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个食谱中，我们将进一步探讨 **IQR** 和 **Tukey fences**，这两个概念我们在讨论箱形图时简要提到过。
- en: See also
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 另见
- en: 'You can learn more about the plots we used and the different options available
    from the `seaborn` documentation. To learn more about the following, visit the
    associated URLs:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过`seaborn`文档了解我们使用的图表以及不同的选项。要了解更多信息，请访问相关网址：
- en: For box plots (`boxplot`), you can visit [https://seaborn.pydata.org/generated/seaborn.boxplot.html](https://seaborn.pydata.org/generated/seaborn.boxplot.html).
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于箱型图（`boxplot`），你可以访问 [https://seaborn.pydata.org/generated/seaborn.boxplot.html](https://seaborn.pydata.org/generated/seaborn.boxplot.html)。
- en: For boxen plots (`boxenplot`), you can visit [https://seaborn.pydata.org/generated/seaborn.boxenplot.html](https://seaborn.pydata.org/generated/seaborn.boxenplot.html).
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于箱型图（`boxenplot`），你可以访问 [https://seaborn.pydata.org/generated/seaborn.boxenplot.html](https://seaborn.pydata.org/generated/seaborn.boxenplot.html)。
- en: For violin plots (`violinplot`), you can visit [https://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot](https://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot).
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于小提琴图（`violinplot`），你可以访问 [https://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot](https://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot)。
- en: For histograms (`histpolot`), you can visit [https://seaborn.pydata.org/generated/seaborn.histplot.html](https://seaborn.pydata.org/generated/seaborn.histplot.html).
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于直方图（`histplot`），你可以访问 [https://seaborn.pydata.org/generated/seaborn.histplot.html](https://seaborn.pydata.org/generated/seaborn.histplot.html)。
- en: For distribution plots (`displot`), you can visit [https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn.displot](https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn.displot).
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于分布图（`displot`），你可以访问 [https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn.displot](https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn.displot)。
- en: Detecting outliers using the Tukey method
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Tukey方法检测异常值
- en: This recipe will extend on the previous recipe, *Detecting outliers using visualizations*.
    In *Figure 8.5*, the box plot showed the quartiles with whiskers extending to
    the upper and lower fences. These boundaries or fences were calculated using the
    Tukey method.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例将扩展前一个示例，*使用可视化检测异常值*。在*图 8.5*中，箱型图显示了四分位数，须状线延伸至上下边界。这些边界或围栏是使用Tukey方法计算得出的。
- en: 'Let''s expand on *Figure 8.5* with additional information of other components:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在*图 8.5*的基础上，扩展一些其他组件的信息：
- en: '![Figure 8.11: Box plot for the daily average taxi passengers data](img/file92.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.11：每日平均出租车乘客数据的箱型图](img/file92.jpg)'
- en: 'Figure 8.11: Box plot for the daily average taxi passengers data'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11：每日平均出租车乘客数据的箱型图
- en: Visualizations are great to give you a high-level perspective on the data you
    are dealing with, such as the overall distribution and potential outliers. Ultimately
    you want to identify these outliers programmatically so you can isolate these
    data points for further investigation and analysis. This recipe will teach you
    how to calculate IQR and define points that fall outside the lower and upper Tukey
    fences.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化图表非常有助于你对所处理数据的整体分布和潜在异常值有一个高层次的了解。最终，你需要通过编程识别这些异常值，以便隔离这些数据点，进行进一步的调查和分析。这个示例将教你如何计算IQR，并定义落在Tukey围栏外的点。
- en: How to do it...
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Most statistical methods allow you to spot extreme values beyond a certain threshold.
    For example, this could be the mean, standard deviation, the 10th or 90th percentile,
    or some other value that you want to compare against. You will start the recipe
    by learning how to obtain basic descriptive statistics and more specifically,
    the quantiles.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数统计方法允许你发现超出某个阈值的极端值。例如，这个阈值可能是均值、标准差、第10或第90百分位数，或者其他你想要比较的值。你将通过学习如何获取基本的描述性统计量，特别是分位数，来开始这个示例。
- en: 'Both DataFrame and Series have the `describe` method that outputs summary descriptive
    statistics. By default, it shows the quartiles: the first quartile, which is the
    25th percentile, the second quartile (median), which is the 50th percentile, and
    the third quartile, which is the 75th percentile. You can customize the percentiles
    by providing a list of values to the `percentiles` parameter. The following code
    shows how you can get values for additional percentiles:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DataFrame和Series都有`describe`方法，用于输出总结性描述性统计量。默认情况下，它显示四分位数：第一四分位数，即第25百分位数，第二四分位数（中位数），即第50百分位数，第三四分位数，即第75百分位数。你可以通过向`percentiles`参数提供一个值列表来定制百分位数。以下代码演示了如何获取额外百分位数的值：
- en: '[PRE31]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This should produce the following DataFrame:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该生成以下DataFrame：
- en: '![Figure 8.12: Descriptive statistics with custom percentiles for the daily
    taxi passenger data](img/file93.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![图8.12：包含自定义百分位数的每日出租车乘客数据描述性统计](img/file93.jpg)'
- en: 'Figure 8.12: Descriptive statistics with custom percentiles for the daily taxi
    passenger data'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12：包含自定义百分位数的每日出租车乘客数据描述性统计
- en: QUANTILES VERSUS QUARTILES VERSUS PERCENTILES
  id: totrans-201
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 分位数与四分位数与百分位数
- en: ''
  id: totrans-202
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The terms can be confusing, but essentially both percentiles and quartiles are
    quantiles. Sometimes you will see people use percentiles more loosely and interchangeably
    with quantiles.
  id: totrans-203
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这些术语可能会让人混淆，但本质上，百分位数和四分位数都是分位数。有时你会看到人们更宽松地使用百分位数，并将其与分位数交替使用。
- en: ''
  id: totrans-204
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Quartiles divide your distribution into four segments (hence the name) marked
    as *Q1* (25th percentile), *Q2* (50th percentile or Median), and *Q3* (75th percentile).
    Percentiles, on the other hand, can take any range from 0 to 100 (in pandas from
    0 to 1, while in NumPy from 0 to 100), but most commonly refer to when the distribution
    is partitioned into 100 segments. These segments are called quantiles.
  id: totrans-205
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 四分位数将数据分为四个部分（因此得名），分别标记为*Q1*（第25百分位）、*Q2*（第50百分位或中位数）和*Q3*（第75百分位）。百分位数则可以取0到100之间的任何范围（在pandas中为0到1，在NumPy中为0到100），但最常见的是将数据分为100个部分。这些部分称为分位数。
- en: ''
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The names pretty much indicate the type of partitioning (number of quantiles)
    applied on the distribution; for example, with four quantiles we call it quartiles,
    with two quantiles we call it median, with 10 quantiles we call it deciles, and
    with 100 quantiles we call it percentiles.
  id: totrans-207
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这些名称基本上表示应用于数据分布的分割类型（分位数的数量）；例如，四个分位数称为四分位数，两个分位数称为中位数，十个分位数称为十分位数，100个分位数称为百分位数。
- en: 'The NumPy library also offers the `percentile` function, which would return
    the value(s) for the specified percentiles. The following code explains how this
    can be used:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NumPy库还提供了`percentile`函数，该函数返回指定百分位数的值。以下代码解释了如何使用该函数：
- en: '[PRE32]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In *Figure 8.11*, notice that most extreme values, potential outliers, fall
    below the lower fence calculated as `Q1 – (1.5 x IQR)` or above the upper fence
    calculated as `Q3 + (1.5 x IQR)`. IQR is calculated as the difference between
    *Q3* and *Q1* (`IQR = Q3 – Q1`), which determines the width of the box in the
    box plot. These upper and lower fences are known as **Tukey's fences**, and more
    specifically, they are referred to as **inner boundaries**. The **outer boundaries**
    also have lower `Q1 - (3.0 x IQR)` and upper `Q3 + (3.0 x IQR)` fences. We will
    focus on the inner boundaries and describe anything outside of those as potential
    outliers.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*图8.11*中，注意到大多数极端值和潜在异常值位于低界限以下（低界限计算公式为`Q1 – (1.5 x IQR)`）或位于高界限以上（高界限计算公式为`Q3
    + (1.5 x IQR)`）。IQR是*Q3*与*Q1*的差值（`IQR = Q3 – Q1`），它决定了箱形图中箱体的宽度。这些上下界限被称为**Tukey界限**，更具体地说，它们被称为**内界限**。**外界限**也有更低的`Q1
    - (3.0 x IQR)`和更高的`Q3 + (3.0 x IQR)`界限。我们将重点关注内界限，并将任何超出这些界限的数据点视为潜在异常值。
- en: 'You will create a function, `iqr_outliers`, which calculates the IQR, upper
    (inner) fence, lower (inner) fence, and then filters the data to return the outliers.
    These outliers are any data points that are below the lower fence or above the
    upper fence:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 你将创建一个名为`iqr_outliers`的函数，该函数计算IQR、上界（内界限）、下界（内界限），然后过滤数据以返回异常值。这些异常值是任何低于下界或高于上界的数据点：
- en: '[PRE33]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Test the function by passing the `tx` DataFrame:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过传递`tx`数据框来测试该函数：
- en: '[PRE34]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: These dates (points) are the same ones identified in *Figure 8.5* and *Figure
    8.11* as outliers based on Tukey's fences.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这些日期（点）与*图8.5*和*图8.11*中根据Tukey界限识别的异常值相同。
- en: 'Use the `plot_outliers` function defined earlier in the *Technical requirements*
    section:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*技术要求*部分中定义的`plot_outliers`函数：
- en: '[PRE35]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This should produce a plot similar to that in *Figure 8.3*, except the `x`
    markers are based on the outliers identified using the Tukey method:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这应生成类似于*图8.3*中的图表，只不过`x`标记是基于Tukey方法识别的异常值：
- en: '![Figure 8.13: Daily average taxi passengers and outliers identified using
    the Tukey method](img/file94.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图8.13：使用Tukey方法识别的每日平均出租车乘客数和异常值](img/file94.jpg)'
- en: 'Figure 8.13: Daily average taxi passengers and outliers identified using the
    Tukey method'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13：使用Tukey方法识别的每日平均出租车乘客数和异常值
- en: Compare *Figures 8.13* and *Figure 8.3* and you will see that this simple method
    did a great job at identifying four of the five known outliers. In addition, Tukey's
    method identified two additional outliers on *2014-12-26* and *2015-01-26*.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 比较*图 8.13*和*图 8.3*，你会看到这个简单的方法在识别已知的五个异常值中的四个方面做得非常好。此外，Tukey 方法还识别出了在*2014-12-26*和*2015-01-26*的两个额外的异常值。
- en: How it works...
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Using IQR and Tukey's fences is a simple non-parametric statistical method.
    Most box plot implementations use `1.5x(IQR)` to define the upper and lower fences.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 IQR 和 Tukey’s fences 是一种简单的非参数统计方法。大多数箱线图实现使用 `1.5x(IQR)` 来定义上下界限。
- en: There's more...
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 还有更多……
- en: The use of `1.5x(IQR)` is common when it comes to defining outliers; the choice
    is still arbitrary, even though there is a lot of discussion about its reasoning.
    You can change the value for more experimentation. For example, in `seaborn,`
    you can change the default `1.5` value by updating the `whis` parameter in the
    `boxplot` function. The choice of `1.5` makes the most sense when the data follows
    a Gaussian distribution (normal), but this is not always the case. Generally,
    the larger the value, the fewer outliers you will capture as you expand your boundaries
    (fences). Similarly, the smaller the value, the more non-outliers will be defined
    as outliers, as you are shrinking the boundaries (fences).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `1.5x(IQR)` 来定义异常值是很常见的；尽管有很多关于其理由的讨论，但这个选择仍然是任意的。你可以更改这个值进行更多实验。例如，在 `seaborn`
    中，你可以通过更新 `boxplot` 函数中的 `whis` 参数来改变默认的 `1.5` 值。当数据符合高斯分布（正态分布）时，选择 `1.5` 是最有意义的，但这并不总是如此。一般来说，值越大，你捕获的异常值就越少，因为你扩展了边界（界限）。同样，值越小，更多的非异常值会被定义为异常值，因为你缩小了边界（界限）。
- en: 'Let''s update the `iqr_outliers` function to accept a `p` parameter so you
    can experiment with different values:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更新 `iqr_outliers` 函数，接受一个 `p` 参数，这样你就可以尝试不同的值：
- en: '[PRE36]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Run the function on different values:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同值上运行函数：
- en: '[PRE37]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The best value will depend on your data and how sensitive you need the outlier
    detection to be.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳值将取决于你的数据以及你需要多敏感的异常值检测。
- en: See also
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'To learn more about Tukey''s fences for outlier detection, you can refer to
    this Wikipedia page: [https://en.wikipedia.org/wiki/Outlier#Tukey''s_fences](https://en.wikipedia.org/wiki/Outlier#Tukey''s_fences).'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 Tukey’s fences 用于异常值检测的内容，可以参考这个维基百科页面：[https://en.wikipedia.org/wiki/Outlier#Tukey's_fences](https://en.wikipedia.org/wiki/Outlier#Tukey's_fences)。
- en: We will explore another statistical method based on a z-score in the following
    recipe.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的配方中探索另一种基于 z-score 的统计方法。
- en: Detecting outliers using a z-score
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 z-score 检测异常值
- en: 'The **z-score** is a common transformation for standardizing data. This is
    common when you want to compare different datasets. For example, it is easier
    to compare two data points from two different datasets relative to their distributions.
    This can be done because the z-score standardizes the data to be centered around
    a zero mean and the units represent standard deviations away from the mean. For
    example, in our dataset, the unit is measured in daily taxi passengers (in thousands).
    Once you apply the z-score transformation, you are no longer dealing with the
    number of passengers, but rather, the units represent standard deviation, which
    tells us how far an observation is from the mean. Here is the formula for the
    z-score:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '**z-score** 是一种常见的数据标准化变换。当你需要比较不同的数据集时，这种方法非常常见。例如，比较来自两个不同数据集的两个数据点相对于它们的分布会更容易。之所以能做到这一点，是因为
    z-score 将数据标准化，使其围绕零均值居中，并且单位表示的是偏离均值的标准差。例如，在我们的数据集中，单位是按日计的出租车乘客数量（以千人计）。一旦应用了
    z-score 变换，你将不再处理乘客数量，而是单位表示的是标准差，这告诉我们一个观测值距离均值有多远。以下是 z-score 的公式：'
- en: '![](img/file95.jpg)Where![](img/file96.png)is a data point (an observation),
    mu (![](img/file97.png)) is the mean of the dataset, and sigma (![](img/file98.png))
    is the standard deviation for the dataset.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/file95.jpg)其中 ![](img/file96.png) 是一个数据点（观测值），mu (![](img/file97.png))
    是数据集的均值，sigma (![](img/file98.png)) 是数据集的标准差。'
- en: Keep in mind that the z-score is a lossless transformation, which means you
    will not lose information such as its distribution (shape of the data) or the
    relationship between the observations. All that is changing is the units of measurement
    as they are being scaled (standardized).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，z-score 是一种无损变换，这意味着你不会丢失诸如数据分布（数据形状）或观测之间关系的信息。唯一改变的是度量单位，它们正在被缩放（标准化）。
- en: Once the data is transformed using the z-score, you can pick a threshold. So,
    any data point above or below that threshold (in standard deviation) is considered
    an outlier. For example, your threshold can be `+3` and `-3` standard deviations
    away from the mean. Any point lower than `-3` or higher than `+3` standard deviation
    can be considered an outlier. In other words, the further a point is from the
    mean, the higher the probability of it being an outlier.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦使用 z-score 转换数据，您就可以选择一个阈值。所以，任何高于或低于该阈值的数据点（以标准差为单位）都被视为异常值。例如，您的阈值可以设置为离均值`+3`和`-3`标准差。任何低于`-3`或高于`+3`标准差的点可以视为异常值。换句话说，点离均值越远，它作为异常值的可能性就越大。
- en: The z-score has one major shortcoming due to it being a parametric statistical
    method based on assumptions. It assumes a Gaussian (normal) distribution. So,
    suppose the data is not normal. In that case, you will need to use a modified
    version of the z-score, which is discussed in the following recipe, *Detecting
    outliers using a modified z-score*.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: z-score 有一个主要的缺点，因为它是基于假设的参数统计方法。它假设数据服从高斯（正态）分布。那么，假设数据不是正态分布，您将需要使用修改版的 z-score，这将在下一个部分中讨论，*使用修改版
    z-score 检测异常值*。
- en: How to do it...
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 操作方法...
- en: You will start by creating the `zscore` function that takes in a dataset and
    a threshold value that we will call `degree`. The function will return the standardized
    data and the identified outliers. These outliers are any points above the positive
    threshold or below the negative threshold.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 您将首先创建 `zscore` 函数，该函数接受一个数据集和一个阈值，我们称其为 `degree`。该函数将返回标准化后的数据和识别出的异常值。这些异常值是指任何高于正阈值或低于负阈值的点。
- en: 'Create the `zscore()` function to standardize the data and filter out the extreme
    values based on a threshold. Recall, the threshold is based on the standard deviation:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 `zscore()` 函数来标准化数据，并根据阈值过滤掉极端值。请记住，阈值是基于标准差的：
- en: '[PRE38]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, use the `zscore` function and store the returned objects:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `zscore` 函数并存储返回的对象：
- en: '[PRE39]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'To see the effect of the z-score transformation, you can plot a histogram.
    The transformed DataFrame contains two columns, the original data labeled `value`
    and the standardized data labeled `zscore`:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看 z-score 转换的效果，您可以绘制一个直方图。转换后的 DataFrame 包含两列数据，原始数据标记为 `value`，标准化数据标记为
    `zscore`：
- en: '[PRE40]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This should produce two histograms for the two columns:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成两个直方图，分别对应两列数据：
- en: '![Figure 8.14: Histogram to compare the distribution of the original and standardized
    data](img/file99.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.14：原始数据和标准化数据分布对比的直方图](img/file99.jpg)'
- en: 'Figure 8.14: Histogram to compare the distribution of the original and standardized
    data'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.14：原始数据和标准化数据分布对比的直方图
- en: Notice how the shape of the data did not change, hence why the z-score is called
    a *lossless transformation*. The only difference between the two is the scale
    (units).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 注意数据的形状没有变化，这也是为什么 z-score 被称为 *无损转换* 的原因。两者唯一的区别是尺度（单位）。
- en: 'You ran the `zscore` function using a threshold of `2.5`, meaning any data
    point that is 2.5 standard deviations away from the mean in either direction.
    For example, any data point that is above the `+2.5` standard deviations or below
    the `-2.5` standard deviations will be considered an outlier. Print out the results
    captured in the `outliers` object:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您使用阈值 `2.5` 运行了 `zscore` 函数，意味着任何与均值相距 2.5 标准差的数据点（无论正负方向）都将被视为异常值。例如，任何高于 `+2.5`
    标准差或低于 `-2.5` 标准差的数据点都将被视为异常值。打印出捕获在 `outliers` 对象中的结果：
- en: '[PRE41]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This simple method managed to capture three out of the five known outliers.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这种简单的方法成功地捕捉到了五个已知异常值中的三个。
- en: 'Use the `plot_outliers` function defined earlier in the *Technical requirements*
    section:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用在 *技术要求* 部分中定义的 `plot_outliers` 函数：
- en: '[PRE42]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'This should produce a plot similar to that in *Figure 8.3*, except the `x`
    markers are based on the outliers identified using the z-score method:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成类似于 *图 8.3* 中的图形，只不过 `x` 标记是基于使用 z-score 方法识别的异常值：
- en: '![Figure 8.15: Daily average taxi passengers and outliers identified using
    the z-score method](img/file100.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.15：每日平均出租车乘客数和使用 z-score 方法识别的异常值](img/file100.jpg)'
- en: 'Figure 8.15: Daily average taxi passengers and outliers identified using the
    z-score method'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.15：每日平均出租车乘客数和使用 z-score 方法识别的异常值
- en: You will need to play around to determine the best threshold value. The larger
    the threshold, the fewer outliers you will capture, and the smaller the threshold,
    the more non-outliers will be labeled as outliers.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要多尝试几次，确定最佳阈值。阈值越大，你捕捉到的异常值就越少；阈值越小，更多的非异常值会被标记为异常值。
- en: 'Finally, let''s create a `plot_zscore` function that takes the standardized
    data to plot the data with the threshold lines. This way you can visually see
    how the threshold is isolating extreme values:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们创建一个`plot_zscore`函数，该函数接受标准化数据，并使用阈值线绘制数据。这样，你可以直观地看到阈值如何隔离极端值：
- en: '[PRE43]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Run the function using a threshold of `2.5`:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 使用阈值`2.5`运行该函数：
- en: '[PRE44]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This should produce a scatter plot with two horizontal lines:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该生成一个包含两条水平线的散点图：
- en: '![Figure 8.16: Plot of the standardized data and outliers based on the threshold
    lines](img/file101.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图8.16：基于阈值线的标准化数据和异常值的图示](img/file101.jpg)'
- en: 'Figure 8.16: Plot of the standardized data and outliers based on the threshold
    lines'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.16：基于阈值线的标准化数据和异常值的图示
- en: The four circled data points represent the outliers that were returned by the
    `zscore` function. Run the function using different threshold values to gain a
    deeper understanding of this simple technique.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 四个被圈出的数据点代表了`zscore`函数返回的异常值。使用不同的阈值运行该函数，以更深入理解这个简单的技术。
- en: How it works...
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The z-score method is a very simple and interpretable method. The z-scores are
    interpreted as standard deviation units away from the mean, which is the center
    of the distribution. Since we are subtracting the mean from all observations,
    we are essentially mean-centering the data. We also divide by the standard deviation
    to standardize the data.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: z分数方法是一种非常简单且易于解释的方法。z分数被解释为与均值的标准差单位距离，均值是分布的中心。由于我们从所有观测值中减去均值，本质上是在进行数据的均值中心化。我们还通过标准差进行除法，以标准化数据。
- en: '*Figure 8.15* pretty much explains the understanding of this method. Once the
    data is standardized, it became easy to just use the standard deviation threshold.
    If the data was not standardized, it may have been challenging to determine the
    threshold based on daily passengers.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8.15*几乎解释了这种方法的理解。一旦数据被标准化，使用标准差阈值就变得非常容易。如果数据没有标准化，可能很难基于日常乘客量来确定阈值。'
- en: There's more...
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The z-score is a parametric method and assumes the data comes from a Gaussian
    (normal) distribution. There are several tests available in the `statsmodels`
    library to test if the data is normally distributed. One of these tests is the
    *Kolmogorov-Smirnov* test. The null hypothesis is that the data comes from a normal
    distribution. The test returns the test statistics and a `p`-value; if the `p`-value
    is less than `0.05`, you can reject the null hypothesis (data is not normally
    distributed). Otherwise, you would fail to reject the null hypothesis (data is
    normally distributed).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: z分数是一种参数化方法，假设数据来自高斯（正态）分布。`statsmodels`库中有几种测试可以检测数据是否符合正态分布。这些测试中的一个是*Kolmogorov-Smirnov*检验。零假设是数据来自正态分布。该检验返回检验统计量和`p`值；如果`p`值小于`0.05`，你可以拒绝零假设（数据不服从正态分布）。否则，你将无法拒绝零假设（数据服从正态分布）。
- en: 'You will use the `kstest_normal` function from the `statsmodels` library. To
    make the results easier to interpret, create the `test_normal` function as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用来自`statsmodels`库的`kstest_normal`函数。为了让结果更易于解释，创建`test_normal`函数如下：
- en: '[PRE45]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Run the test using the `test_normal` function:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`test_normal`函数运行检验：
- en: '[PRE46]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: As expected, the dataset is not normally distributed. In Chapter 9, Exploratory
    Data Analysis and Diagnosis, you will learn about additional normality tests under
    the Applying power transformations recipe. But do be cautious; these tests will
    usually fail in the presence of outliers. If your data fails a normality test,
    then use some of the plotting methods discussed in the Detecting outliers using
    visualizations recipe to examine any outliers that may be causing the test to
    fail.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，该数据集不符合正态分布。在第9章《探索性数据分析与诊断》中，你将学习更多的正态性检验方法，具体内容在应用幂次变换配方中。但是要小心，这些检验通常在存在异常值时会失败。如果你的数据未通过正态性检验，那么可以使用《使用可视化检测异常值》一节中讨论的一些绘图方法，检查任何可能导致检验失败的异常值。
- en: See also
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'To read more about z-scores and standardization, you can refer to this Wikipedia
    page: [https://en.wikipedia.org/wiki/Standard_score](https://en.wikipedia.org/wiki/Standard_score).'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于z-score和标准化的内容，可以参考这篇维基百科页面：[https://en.wikipedia.org/wiki/Standard_score](https://en.wikipedia.org/wiki/Standard_score)。
- en: In the following recipe, you will explore a very similar method to the z-score
    that is more robust to outliers and is more suitable with non-normal data.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的方法中，你将探索一种与z-score非常相似的方法，这种方法对异常值更为鲁棒，并且更适合非正态数据。
- en: Detecting outliers using a modified z-score
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用修改版z-score检测异常值
- en: 'In the *Detecting outliers using a z-score* recipe, you experienced how simple
    and intuitive the method is. But it has one major drawback: it assumes your data
    is normally distributed.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在*使用z-score检测异常值*这一方法中，你体验了该方法的简单性和直观性。但是它有一个主要缺点：假设你的数据是正态分布的。
- en: 'But, what if your data is not normally distributed? Luckily, there is a modified
    version of the z-score to work with non-normal data. The main difference between
    the regular z-score and the modified z-score is that we replace the mean with
    the median:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果你的数据不是正态分布的怎么办？幸运的是，存在一种修改版的z-score，适用于非正态数据。常规z-score和修改版z-score之间的主要区别在于，我们用中位数代替均值：
- en: '![](img/file102.jpg)Where![](img/file103.png)(*tilde x*) is the median of the
    dataset, and MAD is the median absolute deviation of the dataset:![](img/file104.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![](img/file102.jpg)其中![](img/file103.png)(*tilde x*)是数据集的中位数，MAD是数据集的中位绝对偏差：![](img/file104.jpg)'
- en: The `0.6745` value is the standard deviation unit that corresponds to the 75th
    percentile (*Q3*) in a Gaussian distribution and is used as a normalization factor.
    In other words, it is used to approximate the standard deviation. This way, the
    units you obtain from this method are measured in standard deviation, similar
    to how you would interpret the regular z-score.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '`0.6745`值是标准差单位，表示高斯分布中第75百分位数（*Q3*），用于作为归一化因子。换句话说，它用于近似标准差。这样，你从该方法中获得的单位是以标准差为度量的，类似于你如何解释常规z-score。'
- en: You can obtain this value using SciPy's **percent point function** (**PPF**),
    also known as the inverse of the **cumulative distribution function** (**CDF**).
    Simply give the PPF function a percentile, for example, 75%, and it will return
    the quantile corresponding to the lower tail probability.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用SciPy的**百分位点函数**（**PPF**），也称为**累积分布函数**（**CDF**）的反函数，来获得此值。只需为PPF函数提供一个百分位数，例如75%，它将返回对应的下尾概率的分位数。
- en: '[PRE47]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This is the normalization factor used in the formula.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这是公式中使用的归一化因子。
- en: Lastly, the modified z-score is sometimes referred to as the **robust z-score**.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，修改版z-score有时也被称为**鲁棒z-score**。
- en: How to do it...
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何实现...
- en: Overall, the approach will work exactly as the steps used when using the standard
    z-score method. You will start by creating the `modified_zscore` function that
    takes in a dataset, and a threshold value we will call `degree`, and the function
    will return the standardized data as well as the identified outliers. These outliers
    are any points above the positive threshold or below the negative threshold.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，该方法的工作原理与使用常规z-score方法时的步骤完全相同。你将首先创建`modified_zscore`函数，该函数接收一个数据集和一个我们称之为`degree`的阈值，然后该函数将返回标准化后的数据以及识别出的异常值。这些异常值是指超出正阈值或低于负阈值的点。
- en: 'Create the `modified_zscore` `()` function to standardize the data and filter
    out the extreme values based on a threshold. Recall, the threshold is based on
    the standard deviation:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`modified_zscore` `()`函数来标准化数据，并根据阈值过滤掉极端值。回想一下，阈值是基于标准差的：
- en: '[PRE48]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now, use the `modified_zscore` function and store the returned objects:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`modified_zscore`函数并存储返回的对象：
- en: '[PRE49]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: To see the effect of the modified z-score transformation, let's plot a histogram.
    The transformed DataFrame contains two columns, the original data labeled `value`
    and the standardized data labeled `zscore`.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了查看修改版z-score转换的效果，让我们绘制一个直方图。转换后的DataFrame包含两列数据，原始数据列标为`value`，标准化数据列标为`zscore`。
- en: '[PRE50]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'This should produce two histograms for the two columns:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成两个直方图，分别对应两列数据：
- en: '![Figure 8.17: Histogram to compare the distribution of the original and modified
    z-score standardized data](img/file105.jpg)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![图8.17：比较原始和修改版z-score标准化数据分布的直方图](img/file105.jpg)'
- en: 'Figure 8.17: Histogram to compare the distribution of the original and modified
    z-score standardized data'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.17：比较原始和修改版z-score标准化数据分布的直方图
- en: Compare the results from *Figure 8.16* with *Figure 8.13*. Both approaches,
    the z-score and modified z-score approaches, do not change the shape of the data.
    The difference is in the scaling factor.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 比较*图 8.16*与*图 8.13*中的结果。两种方法，z-score和修改后的z-score方法，都没有改变数据的形状。不同之处在于缩放因子。
- en: 'Run the `modified_zscore` function using a threshold of `3`, meaning any data
    point three standard deviations away from the median in either direction. For
    example, any data point above `+3` standard deviations or below `-3` standard
    deviations will be considered an outlier. Print out the results captured in the
    `outliers` object:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`modified_zscore`函数，设置阈值为`3`，这意味着任何数据点距离中位数三倍标准差的距离（无论方向如何）都会被视为异常值。例如，任何高于`+3`标准差或低于`-3`标准差的数据点都将被视为异常值。打印出`outliers`对象中捕获的结果：
- en: '[PRE51]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Interestingly, the modified z-score did a much better job capturing four out
    of the five known outliers.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，修改后的z-score在捕捉五个已知异常值中的四个时表现得更好。
- en: 'Use the `plot_outliers` function defined earlier in the *Technical requirements*
    section:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前面在*技术要求*部分定义的`plot_outliers`函数：
- en: '[PRE52]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'This should produce a plot similar to that in *Figure 8.3,* except the **x**
    markers are based on the outliers identified using the modified z-score method:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成类似于*图 8.3*中的图表，只不过**x**标记是基于使用修改后的z-score方法识别的异常值：
- en: '![Figure 8.18: Daily average taxi passengers and outliers identified using
    the modified z-score method](img/file106.jpg)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.18：使用修改后的z-score方法识别的每日平均出租车乘客及异常值](img/file106.jpg)'
- en: 'Figure 8.18: Daily average taxi passengers and outliers identified using the
    modified z-score method'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.18：使用修改后的z-score方法识别的每日平均出租车乘客及异常值
- en: You will need to play around to determine the best threshold value. The larger
    the threshold, the fewer outliers you will capture, and the smaller the threshold,
    the more non-outliers will be labeled as outliers.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要调整阈值来确定最佳值。阈值越大，你捕获的异常值就越少；阈值越小，更多的非异常值会被标记为异常值。
- en: 'Finally, let''s create a `plot_m_zscore` function that takes the standardized
    data to plot the data with the threshold lines. This way you can visually see
    how the threshold is isolating extreme values:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们创建一个`plot_m_zscore`函数，接受标准化数据并绘制带有阈值线的数据。通过这种方式，你可以直观地看到阈值如何隔离极端值：
- en: '[PRE53]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Run the function using a threshold of `3`:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 使用阈值为`3`来运行该函数：
- en: '[PRE54]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'This should produce a scatter plot with two horizontal lines:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成一个带有两条水平线的散点图：
- en: '![Figure 8.19: Plot of the standardized data and outliers based on the threshold
    lines](img/file107.jpg)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.19：基于阈值线的标准化数据和异常值的图](img/file107.jpg)'
- en: 'Figure 8.19: Plot of the standardized data and outliers based on the threshold
    lines'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.19：基于阈值线的标准化数据和异常值的图
- en: The six circled data points represent the outliers that were returned by the
    `modified_score` function. Run the function using different threshold values to
    gain more profound intuition into this simple technique.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 六个圈中的数据点代表了由`modified_score`函数返回的异常值。使用不同的阈值运行此函数，以便对这种简单的技术有更深的直觉理解。
- en: Notice in *Figure 8.19* how we have a data point that is right at the threshold
    line. Would you consider this an outlier? Generally, when it comes to outlier
    detection you will still need to apply due diligence to inspect the results.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在*图 8.19*中，我们有一个数据点正好位于阈值线处。你认为这是异常值吗？通常，异常值检测时，你仍然需要进行尽职调查来检查结果。
- en: How it works...
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The modified z-score (robust z-score) method is very similar to the z-score
    approach, as it depends on defining a standard deviation threshold. What makes
    this method more robust to outliers is the use of the median instead of the mean.
    We also use the **median absolute deviation** (**MAD**) instead of the standard
    deviation.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 修改后的z-score（稳健z-score）方法与z-score方法非常相似，因为它依赖于定义标准差阈值。使得这种方法对异常值更加稳健的是它使用了中位数而不是均值。我们还使用了**中位数绝对偏差**（**MAD**）来代替标准差。
- en: There's more...
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In the previous recipe, *Detecting outliers using a z-score*, we used `kstest_normal`
    from `statsmodels` to test normality.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个配方中，*使用z-score检测异常值*，我们使用了`statsmodels`中的`kstest_normal`来测试正态性。
- en: Another helpful plot that is specifically designed to test for normality and
    sometimes can help detect outliers is the **Quantile-Quantile plot** (**QQ-plot**).
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有用的图形是专门用来测试正态性并且有时可以帮助检测异常值的**分位数-分位数图**（**QQ图**）。
- en: You can plot a QQ-plot using SciPy or `statsmodels`. Both will produce the same
    plot. The following code will show you can plot using either.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 SciPy 或 `statsmodels` 绘制 QQ 图。两者都会生成相同的图。以下代码展示了你如何使用其中任何一个绘图。
- en: 'This shows how you can plot using SciPy:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了如何使用 SciPy 绘图：
- en: '[PRE55]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'This shows how you can plot using `statsmodels`:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了如何使用`statsmodels`绘图：
- en: '[PRE56]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Both SciPy and `statsmodels` will produce the following plot:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是 SciPy 还是`statsmodels`，都会生成以下图形：
- en: '![Figure 8.20: QQ-plot comparing the taxi passenger data against a hypothetical
    normal distribution](img/file108.jpg)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.20：QQ图，比较出租车乘客数据与假设的正态分布](img/file108.jpg)'
- en: 'Figure 8.20: QQ-plot comparing the taxi passenger data against a hypothetical
    normal distribution'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.20：QQ图，比较出租车乘客数据与假设的正态分布
- en: The solid line represents a reference line for what normally distributed data
    would look like. If the data you are comparing is normally distributed, all the
    points will lie on that straight line. In *Figure 8.19*, we can see that the distribution
    is almost normal (not perfect), and we see issues toward the distribution's tails.
    This also aligns with what we have seen in *Figure 8.16* and *Figure 8.13,* showing
    the majority of the outliers are at the bottom tail end (less than `-2` standard
    deviation).
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 实线代表正态分布数据的参考线。如果你比较的数据是正态分布的，所有数据点将会落在这条直线上。在*图 8.19*中，我们可以看到分布几乎是正态的（虽然不完美），并且在分布的尾部存在一些问题。这与我们在*图
    8.16*和*图 8.13*中看到的情况一致，显示大多数异常值位于底部尾部（低于`-2`标准差）。
- en: See also
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 另见
- en: 'To learn more about MAD, you can refer to the Wikipedia page here: [https://en.wikipedia.org/wiki/Median_absolute_deviation](https://en.wikipedia.org/wiki/Median_absolute_deviation).'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 若想了解更多关于 MAD 的信息，你可以参考维基百科页面：[https://en.wikipedia.org/wiki/Median_absolute_deviation](https://en.wikipedia.org/wiki/Median_absolute_deviation)。
