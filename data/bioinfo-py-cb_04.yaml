- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Next-Generation Sequencing
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下一代测序
- en: '**Next-generation sequencing** (**NGS**) is one of the fundamental technological
    developments of the century in life sciences. **Whole-genome sequencing** (**WGS**),
    **restriction site-associated DNA sequencing** (**RAD-Seq**), **ribonucleic acid
    sequencing** (**RNA-Seq**), **chromatin immunoprecipitation sequencing** (**ChIP-Seq**),
    and several other technologies are routinely used to investigate important biological
    problems. These are also called high-throughput sequencing technologies, and with
    good reason: they generate vast amounts of data that needs to be processed. NGS
    is the main reason that computational biology has become a big-data discipline.
    More than anything else, this is a field that requires strong bioinformatics techniques.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**下一代测序**（**NGS**）是本世纪生命科学领域的基础性技术发展之一。**全基因组测序**（**WGS**）、**限制酶切位点关联DNA测序**（**RAD-Seq**）、**核糖核酸测序**（**RNA-Seq**）、**染色质免疫沉淀测序**（**ChIP-Seq**）以及其他几种技术已被广泛应用于研究重要的生物学问题。这些技术也被称为高通量测序技术，且理由充分：它们产生大量需要处理的数据。NGS是计算生物学成为大数据学科的主要原因。最重要的是，这是一个需要强大生物信息学技术的领域。'
- en: Here, we will not discuss each individual NGS technique *per se* (this would
    require a whole book of its own). We will use an existing WGS dataset—the 1,000
    Genomes Project—to illustrate the most common steps necessary to analyze genomic
    data. The recipes presented here will be easily applicable to other genomic sequencing
    approaches. Some of them can also be used for transcriptomic analysis (for example,
    RNA-Seq). The recipes are also species-independent, so you will be able to apply
    them to any other species for which you have sequenced data. The biggest difference
    in processing data from different species is related to genome size, diversity,
    and the quality of the reference genome (if it exists for your species). These
    will not affect the automated Python part of NGS processing much. In any case,
    we will discuss different genomes in [*Chapter 5*](B17942_05.xhtml#_idTextAnchor122),
    *Working with Genomes*.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们不会讨论每一种单独的NGS技术*本身*（这将需要一本完整的书）。我们将使用现有的WGS数据集——千人基因组计划，来说明分析基因组数据所需的最常见步骤。这里提供的步骤可以轻松应用于其他基因组测序方法。其中一些也可以用于转录组分析（例如，RNA-Seq）。这些步骤也与物种无关，因此你可以将它们应用于任何其他已测序物种的数据。来自不同物种的数据处理之间最大的差异与基因组大小、多样性以及参考基因组的质量（如果存在的话）有关。这些因素不会对NGS处理的自动化Python部分产生太大影响。无论如何，我们将在[*第五章*](B17942_05.xhtml#_idTextAnchor122)中讨论不同的基因组，*基因组分析*。
- en: As this is not an introductory book, you are expected to know at least what
    **FASTA** (**FASTA**), FASTQ, **Binary Alignment Map** (**BAM**), and **Variant
    Call Format** (**VCF**) files are. I will also make use of basic genomic terminology
    without introducing it (such as exomes, nonsynonymous mutations, and so on). You
    are required to be familiar with basic Python. We will leverage this knowledge
    to introduce the fundamental libraries in Python to perform NGS analysis. Here,
    we will follow the flow of a standard bioinformatics pipeline.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这不是一本入门书籍，你需要至少了解**FASTA**（**FASTA**）、FASTQ、**二进制比对映射**（**BAM**）和**变异调用格式**（**VCF**）文件是什么。我还将使用一些基本的基因组术语而不做介绍（例如外显子、非同义突变等）。你需要具备基本的Python知识。我们将利用这些知识来介绍Python中进行NGS分析的基本库。在这里，我们将遵循标准的生物信息学流程。
- en: However, before we delve into real data from a real project, let’s get comfortable
    with accessing existing genomic databases and basic sequence processing—a simple
    start before the storm.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们深入研究来自真实项目的真实数据之前，让我们先熟悉访问现有的基因组数据库和基本的序列处理——在风暴来临之前的简单开始。
- en: If you are running the content via Docker, you can use the `tiagoantao/bioinformatics_ngs`
    image. If you are using Anaconda Python, the required software for the chapter
    will be introduced in each recipe.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你通过Docker运行内容，可以使用`tiagoantao/bioinformatics_ngs`镜像。如果你使用的是Anaconda Python，本章所需的软件将在每个步骤中介绍。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下步骤：
- en: Accessing GenBank and moving around **National Center for Biotechnology Information**
    (**NCBI**) databases
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问GenBank并浏览**国家生物技术信息中心**（**NCBI**）数据库
- en: Performing basic sequence analysis
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行基本的序列分析
- en: Working with modern sequence formats
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理现代序列格式
- en: Working with alignment data
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理比对数据
- en: Extracting data from VCF files
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从VCF文件中提取数据
- en: Studying genome accessibility and filtering **single-nucleotide polymorphism**
    (**SNP**) data
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究基因组可访问性并筛选**单核苷酸多态性**（**SNP**）数据
- en: Processing NGS data with HTSeq
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用HTSeq处理NGS数据
- en: Accessing GenBank and moving around NCBI databases
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问GenBank并在NCBI数据库中浏览
- en: Although you may have your own data to analyze, you will probably need existing
    genomic datasets. Here, we will look at how to access such databases from NCBI.
    We will not only discuss GenBank but also other databases from NCBI. Many people
    refer (wrongly) to the whole set of NCBI databases as GenBank, but NCBI includes
    the nucleotide database and many others—for example, PubMed.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可能有自己的数据需要分析，但你很可能需要现有的基因组数据集。在这里，我们将探讨如何访问NCBI的这些数据库。我们不仅会讨论GenBank，还会讨论NCBI的其他数据库。许多人错误地将整个NCBI数据库集称为GenBank，但NCBI还包括核苷酸数据库和其他许多数据库——例如，PubMed。
- en: As sequencing analysis is a long subject and this book targets intermediate
    to advanced users, we will not be very exhaustive with a topic that is, at its
    core, not very complicated.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于测序分析是一个庞大的主题，而本书面向的是中高级用户，我们不会对这个本质上并不复杂的主题进行非常详尽的讲解。
- en: Nonetheless, it’s a good warm-up for the more complex recipes that we will see
    at the end of this chapter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，这也是一个很好的热身练习，为我们在本章末尾看到的更复杂的教程做准备。
- en: Getting ready
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will use Biopython, which you installed in [*Chapter 1*](B17942_01.xhtml#_idTextAnchor020),
    *Python and the Surrounding Software Ecology*. Biopython provides an interface
    to `Entrez`, the data retrieval system made available by NCBI.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用你在[*第1章*](B17942_01.xhtml#_idTextAnchor020)中安装的Biopython，*Python与周围的软件生态*。Biopython为`Entrez`提供了接口，`Entrez`是NCBI提供的数据检索系统。
- en: This recipe is made available in the `Chapter03/Accessing_Databases.py` file.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个教程可以在`Chapter03/Accessing_Databases.py`文件中找到。
- en: Tip
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: You will be accessing a live **application programming interface** (**API**)
    from NCBI. Note that the performance of the system may vary during the day. Furthermore,
    you are expected to be a “good citizen” while using it. You will find some recommendations
    at [https://www.ncbi.nlm.nih.gov/books/NBK25497/#chapter2.Usage_Guidelines_and_Requiremen](https://www.ncbi.nlm.nih.gov/books/NBK25497/#chapter2.Usage_Guidelines_and_Requiremen).
    Notably, you are required to specify an email address with your query. You should
    try to avoid a large number of requests (100 or more) during peak times (between
    9.00 a.m. and 5.00 p.m. American Eastern Time on weekdays), and do not post more
    than three queries per second (Biopython will take care of this for you). It’s
    not only good citizenship, but you risk getting blocked if you overuse NCBI’s
    servers (a good reason to give a real email address, because NCBI may try to contact
    you).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你将访问NCBI的实时**应用程序编程接口**（**API**）。请注意，系统的性能可能会在一天中有所波动。此外，使用时需要保持“良好的公民行为”。你可以在[https://www.ncbi.nlm.nih.gov/books/NBK25497/#chapter2.Usage_Guidelines_and_Requiremen](https://www.ncbi.nlm.nih.gov/books/NBK25497/#chapter2.Usage_Guidelines_and_Requiremen)找到一些使用建议。特别需要注意的是，查询时你需要指定一个电子邮件地址。你应尽量避免在高峰时段（工作日美国东部时间上午9:00到下午5:00之间）发出大量请求（100个或更多），并且每秒不超过三次查询（Biopython会为你处理这个问题）。这不仅是为了遵守规定，而且如果你过度使用NCBI的服务器，你可能会被封锁（这也是一个好理由提供真实的电子邮件地址，因为NCBI可能会联系你）。
- en: How to do it...
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Now, let’s look at how we can search and fetch data from NCBI databases:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看如何从NCBI数据库中搜索和获取数据：
- en: 'We will start by importing the relevant module and configuring the email address:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从导入相关模块并配置电子邮件地址开始：
- en: '[PRE0]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We will also import the module to process sequences. Do not forget to put in
    the correct email address.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将导入用于处理序列的模块。请不要忘记填写正确的电子邮件地址。
- en: 'We will now try to find the `Plasmodium falciparum` (the parasite that causes
    the deadliest form of malaria) on the `nucleotide` database:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将尝试在`nucleotide`数据库中查找`Plasmodium falciparum`（导致最致命疟疾的寄生虫）：
- en: '[PRE1]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We will search the `nucleotide` database for our gene and organism (for the
    syntax of the search string, check the NCBI website). Then, we will read the result
    that is returned. Note that the standard search will limit the number of record
    references to 20, so if you have more, you may want to repeat the query with an
    increased maximum limit. In our case, we will actually override the default limit
    with `retmax`. The `Entrez` system provides quite a few sophisticated ways to
    retrieve a large number of results (for more information, check the Biopython
    or NCBI Entrez documentation). Although you now have the **identifiers** (**IDs**)
    of all of the records, you still need to retrieve the records properly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将搜索 `nucleotide` 数据库中的基因和生物体（关于搜索字符串的语法，参考 NCBI 网站）。然后，我们将读取返回的结果。请注意，标准搜索会将记录引用的数量限制为
    20，因此如果有更多记录，可能需要重复查询并增加最大限制。在我们的例子中，我们将使用 `retmax` 来覆盖默认限制。`Entrez` 系统提供了多种复杂的方法来检索大量结果（更多信息请参考
    Biopython 或 NCBI Entrez 文档）。尽管现在你已经拥有了所有记录的**标识符**（**ID**），但你仍然需要正确地检索记录。
- en: 'Now, let’s try to retrieve all of these records. The following query will download
    all matching nucleotide sequences from GenBank, which is 1,374 at the time of
    writing this book. You probably won’t want to do this all the time:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们尝试检索所有这些记录。以下查询将从 GenBank 下载所有匹配的核苷酸序列，截至本书编写时，共有 1,374 条。你可能不想每次都这样做：
- en: '[PRE2]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Well, in this case, go ahead and do it. However, be careful with this technique,
    because you will retrieve a large number of complete records, and some of them
    will have fairly large sequences inside. You risk downloading a lot of data (which
    would be a strain both on your side and on the NCBI servers).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，在这种情况下，继续进行吧。然而，使用这种技术时要小心，因为你将检索大量完整的记录，其中一些记录包含相当大的序列。你有可能下载大量数据（这会对你的机器和
    NCBI 服务器都造成压力）。
- en: There are several ways around this. One way is to make a more restrictive query
    and/or download just a few at a time and stop when you have found the one that
    you need. The precise strategy will depend on what you are trying to achieve.
    In any case, we will retrieve a list of records in the GenBank format (which includes
    sequences, plus a lot of interesting metadata).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以解决这个问题。一个方法是进行更严格的查询和/或每次只下载少量记录，当你找到需要的记录时就停止。具体策略取决于你的目标。无论如何，我们将检索
    GenBank 格式的记录列表（该格式包含序列以及大量有趣的元数据）。
- en: 'Let’s read and parse the result:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们读取并解析结果：
- en: '[PRE3]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that we have converted an iterator (the result of `SeqIO.parse`) to a list.
    The advantage of doing this is that we can use the result as many times as we
    want (for example, iterate many times over), without repeating the query on the
    server.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们已经将一个迭代器（`SeqIO.parse` 的结果）转换为列表。这样做的好处是我们可以多次使用结果（例如，多次迭代），而无需在服务器上重复查询。
- en: This saves time, bandwidth, and server usage if you plan to iterate many times
    over. The disadvantage is that it will allocate memory for all records. This will
    not work for very large datasets; you might not want to do this conversion genome-wide
    as in [*Chapter 5*](B17942_05.xhtml#_idTextAnchor122), *Working with Genomes*.
    We will return to this topic in the last part of this book. If you are doing interactive
    computing, you will probably prefer to have a list (so that you can analyze and
    experiment with it multiple times), but if you are developing a library, an iterator
    will probably be the best approach.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算进行多次迭代，这可以节省时间、带宽和服务器使用。缺点是它会为所有记录分配内存。对于非常大的数据集，这种方法不可行；你可能不想像在 [*第 5
    章*](B17942_05.xhtml#_idTextAnchor122) 《处理基因组》那样进行全基因组的转换。如果你正在进行交互式计算，你可能更倾向于获取一个列表（以便你可以多次分析和实验），但如果你在开发一个库，迭代器可能是最佳的选择。
- en: 'We will now just concentrate on a single record. This will only work if you
    used the exact same preceding query:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将集中精力处理单条记录。只有当你使用完全相同的前一个查询时，这种方法才有效：
- en: '[PRE4]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `rec` variable now has our record of interest. The `rec.description` file
    will contain its human-readable description.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`rec` 变量现在包含我们感兴趣的记录。`rec.description` 文件将包含它的人类可读描述。'
- en: 'Now, let’s extract some sequence features that contain information such as
    `gene` products and `exon` positions on the sequence:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们提取一些包含 `gene` 产品和序列中 `exon` 位置等信息的序列特征：
- en: '[PRE5]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If the `feature.type` value is `gene`, we will print its name, which will be
    in the `qualifiers` dictionary. We will also print all the locations of exons.
    Exons, as with all features, have locations in this sequence: a start, an end,
    and the strand from where they are read. While all the start and end positions
    for our exons are `ExactPosition`, note that Biopython supports many other types
    of positions. One type of position is `BeforePosition`, which specifies that a
    location point is before a certain sequence position. Another type of position
    is `BetweenPosition`, which gives the interval for a certain location start/end.
    There are quite a few more position types; these are just some examples.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`feature.type`值是`gene`，我们将打印其名称，它会在`qualifiers`字典中。我们还将打印所有外显子的位置。外显子和所有特征一样，具有该序列的位置：起始位置、结束位置，以及它们读取的链。虽然所有外显子的起始和结束位置都是`ExactPosition`，但请注意，Biopython支持许多其他类型的位置。位置的一种类型是`BeforePosition`，它指定某个位置点位于某个特定序列位置之前。另一种类型是`BetweenPosition`，它给出了某个位置的起始/结束区间。还有许多其他位置类型，这些只是一些例子。
- en: Coordinates will be specified in such a way that you will be able to easily
    retrieve the sequence from a Python array with ranges, so generally, the start
    will be one before the value on the record, and the end will be equal. The issue
    of coordinate systems will be revisited in future recipes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 坐标将以这样一种方式指定，使得你能够轻松地从带有范围的Python数组中检索序列，因此通常开始位置会比记录上的值小1，结束位置将相等。坐标系统的问题将在未来的教程中再次讨论。
- en: For other feature types, we simply print them. Note that Biopython will provide
    a human-readable version of the feature when you print it.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他特征类型，我们只需打印它们。请注意，当你打印特征时，Biopython会提供一个可读的人类版本。
- en: 'We will now look at the annotations on the record, which are mostly metadata
    that is not related to the sequence position:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来看一下记录上的注释，这些注释主要是与序列位置无关的元数据：
- en: '[PRE6]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note that some values are not strings; they can be numbers or even lists (for
    example, the taxonomy annotation is a list).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，有些值不是字符串；它们可以是数字，甚至是列表（例如，分类注释就是一个列表）。
- en: 'Last but not least, you can access a fundamental piece of information—the sequence:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，你可以访问一个基础信息——序列：
- en: '[PRE7]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The sequence object will be the main topic of our next recipe.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 序列对象将是我们下一个教程的主要主题。
- en: There’s more...
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: There are many more databases at NCBI. You will probably want to check the **Sequence
    Read Archive** (**SRA**) database (previously known as **Short Read Archive**)
    if you are working with NGS data. The SNP database contains information on SNPs,
    whereas the protein database has protein sequences, and so on. A full list of
    databases in Entrez is linked in the *See also* section of this recipe.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: NCBI还有许多其他数据库。如果你正在处理NGS数据，可能会想查看**序列读取档案**（**SRA**）数据库（以前称为**短序列档案**）。SNP数据库包含SNP信息，而蛋白质数据库包含蛋白质序列，等等。Entrez数据库的完整列表可在本教程的*另见*部分找到。
- en: 'Another database that you probably already know about with regard to NCBI is
    PubMed, which includes a list of scientific and medical citations, abstracts,
    and even full texts. You can also access it via Biopython. Furthermore, GenBank
    records often contain links to PubMed. For example, we can perform this on our
    previous record, as shown here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个你可能已经知道的与NCBI相关的数据库是PubMed，它包含了科学和医学的引用、摘要，甚至是全文。你也可以通过Biopython访问它。此外，GenBank记录通常包含指向PubMed的链接。例如，我们可以在之前的记录上执行此操作，如下所示：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This will take all reference annotations, check whether they have a PubMed ID,
    and then access the PubMed database to retrieve the records, parse them, and then
    print them.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这将获取所有参考注释，检查它们是否具有PubMed ID，然后访问PubMed数据库以检索记录，解析它们，并打印出来。
- en: The output per record is a Python dictionary. Note that there are many references
    to external databases on a typical GenBank record.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 每条记录的输出是一个Python字典。请注意，典型的GenBank记录中有许多指向外部数据库的引用。
- en: Of course, there are many other biological databases outside NCBI, such as Ensembl
    ([http://www.ensembl.org](http://www.ensembl.org)) and **University of California,
    Santa Cruz** (**UCSC**) Genome Bioinformatics ([http://genome.ucsc.edu/](http://genome.ucsc.edu/)).
    The support for many of these databases in Python will vary a lot.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，NCBI之外还有许多其他生物数据库，如Ensembl（[http://www.ensembl.org](http://www.ensembl.org)）和**加利福尼亚大学圣克鲁兹分校**（**UCSC**）基因组生物信息学（[http://genome.ucsc.edu/](http://genome.ucsc.edu/)）。这些数据库在Python中的支持程度差异很大。
- en: An introductory recipe on biological databases would not be complete without
    at least a passing reference to **Basic Local Alignment Search Tool** (**BLAST**).
    BLAST is an algorithm that assesses the similarity of sequences. NCBI provides
    a service that allows you to compare your sequence of interest against its own
    database. Of course, you can use your local BLAST database instead of using NCBI’s
    service. Biopython provides extensive support for this, but as this is too introductory,
    I will just refer you to the Biopython tutorial.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍生物数据库的食谱如果没有至少提到**基础本地比对搜索工具**（**BLAST**），那就不完整了。BLAST是一种评估序列相似性的算法。NCBI提供了一项服务，允许你将目标序列与其数据库进行比对。当然，你也可以使用本地BLAST数据库，而不是NCBI的服务。Biopython为此提供了广泛的支持，但由于这是一个入门教程，我仅将你指引至Biopython的教程。
- en: See also
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'This additional information will also be useful:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这些附加信息也会很有用：
- en: You can find more examples on the Biopython tutorial at [http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml](http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml).
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在Biopython教程中找到更多示例，链接为[http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml](http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml)。
- en: A list of accessible NCBI databases can be found at [http://www.ncbi.nlm.nih.gov/gquery/](http://www.ncbi.nlm.nih.gov/gquery/).
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可访问的NCBI数据库列表可以在[http://www.ncbi.nlm.nih.gov/gquery/](http://www.ncbi.nlm.nih.gov/gquery/)找到。
- en: A great **question and answer** (**Q&A**) site where you can find help for your
    problems with databases and sequence analysis is Biostars ([http://www.biostars.org](http://www.biostars.org));
    you can use it for all of the content in this book, not just for this recipe.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个很棒的**问答**（**Q&A**）网站，你可以在上面找到关于数据库和序列分析问题的帮助，就是Biostars ([http://www.biostars.org](http://www.biostars.org))；你可以使用它来查找本书中的所有内容，而不仅仅是本章的这道示例。
- en: Performing basic sequence analysis
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行基本的序列分析
- en: We will now do some basic analysis of DNA sequences. We will work with FASTA
    files and do some manipulation, such as reverse complementing or transcription.
    As with the previous recipe, we will use Biopython, which you installed in [*Chapter
    1*](B17942_01.xhtml#_idTextAnchor020), *Python and the Surrounding Software Ecology*.
    These two recipes provide you with the necessary introductory building blocks
    with which we will perform all the modern NGS analysis and then genome processing
    in this chapter and [*Chapter 5*](B17942_05.xhtml#_idTextAnchor122), *Working
    with Genomes*.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将对DNA序列进行一些基本分析。我们将处理FASTA文件，并进行一些操作，例如反向互补或转录。与前面介绍的食谱一样，我们将使用你在[*第1章*](B17942_01.xhtml#_idTextAnchor020)中安装的Biopython，*Python与周边软件生态*。这两道食谱为你提供了执行本章和[*第5章*](B17942_05.xhtml#_idTextAnchor122)中所有现代NGS分析和基因组处理所需的入门基础。
- en: Getting ready
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The code for this recipe is available in `Chapter03/Basic_Sequence_Processing.py`.
    We will use the human `Entrez` research interface:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱的代码可以在`Chapter03/Basic_Sequence_Processing.py`中找到。我们将使用人类`Entrez`研究接口：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now that we have the GenBank record, let’s extract the gene sequence. The record
    has a bit more than that, but let’s get the precise location of the gene first:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了GenBank记录，让我们提取基因序列。该记录中包含的内容比这更多，但首先让我们获取基因的精确位置：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Our example sequence is available on the Biopython sequence record.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例序列已经包含在Biopython序列记录中。
- en: How to do it...
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let’s take a look at the following steps:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下接下来的步骤：
- en: 'As our sequence of interest is available in a Biopython sequence object, let’s
    start by saving it to a FASTA file on our local disk:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们的目标序列已经存储在一个Biopython序列对象中，首先让我们把它保存为本地磁盘上的FASTA文件：
- en: '[PRE11]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `SeqIO.write` function takes a list of sequences to write (in our case,
    it’s just a single one). Be careful with this idiom. If you want to write many
    sequences (and you could easily write millions with NGS), do not use a list (as
    shown in the preceding code snippet) because this will allocate massive amounts
    of memory. Use either an iterator or the `SeqIO.write` function several times
    with a subset of the sequence on each write.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`SeqIO.write`函数接受一个序列列表进行写入（在我们这里只是一个序列）。使用这个惯用法时要小心。如果你想写入多个序列（并且你可能会用NGS写入数百万个序列），不要使用列表（如前面的代码片段所示），因为这会分配大量内存。应使用迭代器，或者每次写入时只处理序列的子集，并多次调用`SeqIO.write`函数。'
- en: 'In most situations, you will actually have the sequence on the disk, so you
    will be interested in reading it:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在大多数情况下，你实际上会把序列保存在磁盘上，因此你会对读取它感兴趣：
- en: '[PRE12]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here, we are concerned with processing a single sequence, but FASTA files can
    contain multiple records. The Python idiom to perform this is quite easy. To read
    a FASTA file, you just use standard iteration techniques, as shown in the following
    code snippet. For our example, the preceding code will print the following output:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们关注的是处理单一序列，但FASTA文件可以包含多个记录。实现这一点的Python惯用法非常简单。要读取FASTA文件，你只需使用标准的迭代技巧，如以下代码片段所示。对于我们的示例，前面的代码将打印以下输出：
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that we printed `seq[:10]`. The sequence object can use typical array slices
    to get part of a sequence.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们打印了`seq[:10]`。序列对象可以使用典型的数组切片来获取序列的一部分。
- en: 'As we now have an unambiguous DNA, we can transcribe it as follows:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 既然我们现在有了明确无误的DNA，我们可以按如下方式转录它：
- en: '[PRE14]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, we can translate our gene into a protein:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终，我们可以将我们的基因转化为蛋白质：
- en: '[PRE15]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now, we have the amino acid sequence for our gene.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经有了我们基因的氨基酸序列。
- en: There’s more...
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Much more can be said about the management of sequences in Biopython, but this
    is mostly introductory material that you can find in the Biopython tutorial. I
    think it’s important to give you a taste of sequence management, mostly for completion
    purposes. To support those of you who might have some experience in other fields
    of bioinformatics but are just starting with sequence analysis, there are, nonetheless,
    a few points that you should be aware of:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 关于在Biopython中管理序列，还可以说很多，但这些主要是介绍性的内容，你可以在Biopython教程中找到。我认为给你们一个序列管理的概述是很重要的，主要是为了完整性。为了支持那些可能在生物信息学其他领域有一些经验，但刚刚开始做序列分析的人，尽管如此，仍然有几个点是你们应该注意的：
- en: When you perform an RNA translation to get your protein, be sure to use the
    correct genetic code. Even if you are working with “common” organisms (such as
    humans), remember that the mitochondrial genetic code is different.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你执行RNA翻译以获得你的蛋白质时，请确保使用正确的遗传密码。即使你正在处理“常见”的生物体（如人类），也要记住线粒体的遗传密码是不同的。
- en: Biopython’s `Seq` object is much more flexible than what’s shown here. For some
    good examples, refer to the Biopython tutorial. However, this recipe will be enough
    for the work we need to do with FASTQ files (see the next recipe).
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Biopython的`Seq`对象比这里展示的要灵活得多。有一些很好的例子可以参考Biopython教程。然而，这个教程足以应付我们需要处理的FASTQ文件（请参见下一个教程）。
- en: To deal with strand-related issues, there are—as expected—sequence functions
    such as `reverse_complement`.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了处理与链相关的问题，正如预期的那样，有一些序列函数，比如`reverse_complement`。
- en: The GenBank record from which we started includes a lot of metadata information
    about the sequence, so be sure to explore it.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们开始的GenBank记录包含了关于序列的大量元数据，所以一定要深入探索。
- en: See also
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: Genetic codes known to Biopython are the ones specified by NCBI, available at
    [http://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi](http://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi).
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Biopython已知的遗传密码是由NCBI指定的，可以在[http://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi](http://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi)找到。
- en: As in the previous recipe, the Biopython tutorial is your main port of call
    and is available at [http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml](http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml).
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如同前面的教程一样，Biopython教程是你的主要参考资料，可以在[http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml](http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml)找到。
- en: Be sure to also check the Biopython SeqIO page at [http://biopython.org/wiki/SeqIO](http://biopython.org/wiki/SeqIO).
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保也查看Biopython的SeqIO页面，[http://biopython.org/wiki/SeqIO](http://biopython.org/wiki/SeqIO)。
- en: Working with modern sequence formats
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用现代序列格式
- en: Here, we will work with FASTQ files, the standard format output used by modern
    sequencers. You will learn how to work with quality scores per base and also consider
    variations in output coming from different sequencing machines and databases.
    This is the first recipe that will use real data (big data) from the human 1,000
    Genomes Project. We will start with a brief description of the project.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将处理FASTQ文件，这是现代测序仪使用的标准格式输出。你将学习如何处理每个碱基的质量分数，并考虑不同测序仪和数据库的输出变化。这是第一个将使用来自人类1000基因组计划的真实数据（大数据）的教程。我们将首先简要介绍这个项目。
- en: Getting ready
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The human 1,000 Genomes Project aims to catalog worldwide human genetic variation
    and takes advantage of modern sequencing technology to do WGS. This project makes
    all data publicly available, which includes output from sequencers, sequence alignments,
    and SNP calls, among many other artifacts. The name “1,000 Genomes” is actually
    a misnomer, because it currently includes more than 2,500 samples. These samples
    are divided into hundreds of populations, spanning the whole planet. We will mostly
    use data from four populations: **African Yorubans** (**YRI**), **Utah Residents
    with Northern and Western European Ancestry** (**CEU**), **Japanese in Tokyo**
    (**JPT**), and **Han Chinese in Beijing** (**CHB**). The reason we chose these
    specific populations is that they were the first ones that came from HapMap, an
    old project with similar goals. They used genotyping arrays to find out more about
    the quality of this subset. We will revisit the 1,000 Genomes and HapMap projects
    in [*Chapter 6*](B17942_06.xhtml#_idTextAnchor154), *Population Genetics*.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 人类1,000基因组计划旨在 catalog 世界范围的人类遗传变异，并利用现代测序技术进行全基因组测序（WGS）。这个项目使所有数据公开可用，包括来自测序仪的输出、序列比对、SNP调用以及许多其他数据。这一名称“1,000基因组”实际上是一个误称，因为它目前包含了超过2,500个样本。这些样本分布在数百个人群中，遍布全球。我们将主要使用四个人群的数据：**非洲约鲁巴人**（**YRI**），**拥有北欧和西欧血统的犹他州居民**（**CEU**），**东京的日本人**（**JPT**），以及**北京的汉族人**（**CHB**）。之所以选择这些特定的人群，是因为它们是最早来自HapMap的样本，HapMap是一个具有类似目标的旧项目。它们使用基因分型阵列来进一步了解该子集的质量。我们将在[*第6章*](B17942_06.xhtml#_idTextAnchor154)“*种群遗传学*”中重新回顾1,000基因组和HapMap项目。
- en: Tip
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Next-generation datasets are generally very large. As we will be using real
    data, some of the files that you will download will be big. While I have tried
    to choose the smallest real examples possible, you will still need a good network
    connection and a considerably large amount of disk space. Waiting for the download
    will probably be your biggest hurdle in this recipe, but data management is a
    serious problem with NGS. In real life, you will need to budget time for data
    transfer, allocate disk space (which can be financially costly), and consider
    backup policies. The most common initial mistake with NGS is to think that these
    problems are trivial, but they are not. An operation such as copying a set of
    BAM files to a network, or even to your computer, will become a headache. Be prepared.
    After downloading large files, at the very least, you should check that the size
    is correct. Some databases offer **Message Digest 5** (**MD5**) checksums. You
    can compare these checksums with the ones on the files you downloaded by using
    tools such as md5sum.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 下一代数据集通常非常大。由于我们将使用真实数据，你下载的某些文件可能会非常大。尽管我已经尽量选择最小的真实示例，但你仍然需要一个良好的网络连接以及相当大的磁盘空间。等待下载可能是你在这个配方中遇到的最大障碍，但数据管理是NGS中一个严重的问题。在现实生活中，你需要为数据传输预留时间，分配磁盘空间（这可能会涉及财务成本），并考虑备份策略。NGS的最常见初始错误是认为这些问题微不足道，但事实并非如此。像将一组BAM文件复制到网络，甚至复制到你的计算机上，都会变成一件头疼的事。要做好准备。下载大文件后，至少应检查文件大小是否正确。一些数据库提供**消息摘要5**（**MD5**）校验和。你可以通过使用像md5sum这样的工具，将这些校验和与下载文件中的校验和进行对比。
- en: The instructions to download the data are at the top of the notebook, as specified
    in the first cell of `Chapter03/Working_with_FASTQ.py`. This is a fairly small
    file (27 `NA18489`). If you refer to the 1,000 Genomes Project, you will see that
    the vast majority of FASTQ files are much bigger (up to two orders of magnitude
    bigger).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 下载数据的指令位于笔记本的顶部，正如`Chapter03/Working_with_FASTQ.py`文件的第一单元格中所指定的。这是一个相当小的文件（27
    `NA18489`）。如果你参考1,000基因组计划，你会发现绝大多数的FASTQ文件要大得多（大约大两个数量级）。
- en: The processing of FASTQ sequence files will mostly be performed using Biopython.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: FASTQ序列文件的处理将主要使用Biopython来完成。
- en: How to do it...
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Before we start coding, let’s take a look at the FASTQ file, in which you will
    have many records, as shown in the following code snippet:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始编写代码之前，让我们先看一下FASTQ文件，你将会看到许多记录，正如以下代码片段所示：
- en: '[PRE16]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*Line 1* starts with `@`, followed by a sequence ID and a description string.
    The description string will vary from a sequencer or a database source, but will
    normally be amenable to automated parsing.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*第1行*以`@`开始，后面跟着一个序列ID和描述字符串。描述字符串会根据测序仪或数据库源有所不同，但通常是可以自动解析的。'
- en: The second line has the sequenced DNA, which is just like a FASTA file. The
    third line is a `+` sign, sometimes followed by the description line on the first
    line.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 第二行包含测序的 DNA，类似于 FASTA 文件。第三行是一个`+`符号，有时后面会跟上第一行的描述行。
- en: The fourth line contains quality values for each base that’s read on *line 2*.
    Each letter encodes a Phred quality score ([http://en.wikipedia.org/wiki/Phred_quality_score](http://en.wikipedia.org/wiki/Phred_quality_score)),
    which assigns a probability of error to each read. This encoding can vary a bit
    among platforms. Be sure to check for this on your specific platform.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 第四行包含每个在*第二行*读取的碱基的质量值。每个字母编码一个 Phred 质量分数（[http://en.wikipedia.org/wiki/Phred_quality_score](http://en.wikipedia.org/wiki/Phred_quality_score)），该分数为每个读取分配一个错误概率。这个编码在不同平台间可能略有不同。请确保在您的特定平台上检查此内容。
- en: 'Let’s take a look at the following steps:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看接下来的步骤：
- en: 'Let’s open the file:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们打开文件：
- en: '[PRE17]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We will open a `gzip` module. We will also specify the `fastq` format. Note
    that some variations in this format will impact the interpretation of the Phred
    quality scores. You may want to specify a slightly different format. Refer to
    [http://biopython.org/wiki/SeqIO](http://biopython.org/wiki/SeqIO) for all formats.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将打开一个`gzip`模块，并指定`fastq`格式。请注意，这种格式的某些变体会影响 Phred 质量分数的解释。您可能需要指定一个稍有不同的格式。有关所有格式的详细信息，请参考[http://biopython.org/wiki/SeqIO](http://biopython.org/wiki/SeqIO)。
- en: Tip
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: You should usually store your FASTQ files in a compressed format. Not only do
    you gain a lot of disk space, as these are text files, but you probably also gain
    some processing time. Although decompressing is a slow process, it can still be
    faster than reading a much bigger (uncompressed) file from a disk.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您应该将 FASTQ 文件存储为压缩格式。这样不仅可以节省大量磁盘空间（因为这些是文本文件），而且可能还可以节省一些处理时间。尽管解压缩是一个较慢的过程，但它仍然可能比从磁盘读取一个更大的（未压缩的）文件更快。
- en: We print the standard fields and quality scores from the previous recipe into
    `rec.letter_annotations`. As long as we choose the correct parser, Biopython will
    convert all the Phred encoding letters to logarithmic scores, which we will use
    soon.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从之前的例子中打印标准字段和质量分数到`rec.letter_annotations`。只要我们选择正确的解析器，Biopython 会将所有 Phred
    编码字母转换为对数分数，我们很快就会使用这些分数。
- en: 'For now, *don’t* do this:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，*不要*这样做：
- en: '[PRE18]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Although this might work with some FASTA files (and with this very small FASTQ
    file), if you do something such as this, you will allocate memory so that you
    can load the complete file in memory. With an average FASTQ file, this is the
    best way to crash your computer. As a rule, always iterate over your file. If
    you have to perform several operations over it, you have two main options. The
    first option is to perform a single iteration or all operations at once. The second
    option to is open a file several times and repeat the iteration.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法可能适用于某些 FASTA 文件（以及这个非常小的 FASTQ 文件），但如果您这样做，您将分配内存以便将完整文件加载到内存中。对于一个普通的
    FASTQ 文件，这是让您的计算机崩溃的最佳方式。一般来说，始终遍历您的文件。如果您需要对文件执行多次操作，您有两个主要选择。第一种选择是一次性执行所有操作。第二种选择是多次打开文件并重复迭代。
- en: 'Now, let’s take a look at the distribution of nucleotide reads:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们看看核苷酸读取的分布：
- en: '[PRE19]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We will reopen the file and use `defaultdict` to maintain a count of nucleotide
    references in the FASTQ file. If you have never used this Python standard dictionary
    type, you may want to consider it because it removes the need to initialize dictionary
    entries, assuming default values for each type.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重新打开文件并使用`defaultdict`来维护 FASTQ 文件中核苷酸引用的计数。如果您从未使用过这种 Python 标准字典类型，您可能会考虑使用它，因为它消除了初始化字典条目的需要，并为每种类型假设默认值。
- en: Note
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: There is a residual number for `N` calls. These are calls in which a sequencer
    reports an unknown base. In our FASTQ file example, we have cheated a bit because
    we used a filtered file (the fraction of `N` calls will be quite low). Expect
    a much bigger number of `N` calls in a file that comes out of the sequencer unfiltered.
    In fact, you can even expect something more with regard to the spatial distribution
    of `N` calls.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个`N`调用的剩余数目。这些是测序仪报告的未知碱基。在我们的 FASTQ 文件示例中，我们稍微作弊了一下，因为我们使用了一个过滤后的文件（`N`调用的比例会非常低）。在从测序仪未过滤的文件中，您会看到更多的`N`调用。事实上，您可能还会看到关于`N`调用的空间分布方面更多的信息。
- en: 'Let’s plot the distribution of `N`s according to their read position:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们根据读取位置绘制`N`的分布：
- en: '[PRE20]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We import the `seaborn` library. Although we do not use it explicitly at this
    point, this library has the advantage of making `matplotlib` plots look better,
    because it tweaks the default `matplotlib` style.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入`seaborn`库。尽管目前我们并没有显式使用它，但这个库的优点在于它能使`matplotlib`绘图看起来更好，因为它调整了默认的`matplotlib`样式。
- en: 'We then open the file to parse again (remember that you do not use a list but
    iterate again). We iterate through the file and get the position of any references
    to `N`. Then, we plot the distribution of `N`s as a function of the distance from
    the start of the sequence:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们再次打开文件进行解析（记住，这时你不使用列表，而是再次进行迭代）。我们遍历文件，找出所有指向`N`的引用位置。接着，我们将`N`的分布作为序列开始位置的距离函数绘制出来：
- en: '![Figure 3.1 – The number of N calls as a function of the distance from the
    start of the sequencer read ](img/B17942_03_001.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.1 – `N`调用的数量与序列读取起始位置的距离函数](img/B17942_03_001.jpg)'
- en: Figure 3.1 – The number of N calls as a function of the distance from the start
    of the sequencer read
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – `N`调用的数量与序列读取起始位置的距离函数
- en: You will see that until position `25`, there are no errors. This is not what
    you will get from a typical sequencer output. Our example file is already filtered,
    and the 1,000 Genomes filtering rules enforce that no `N` calls can occur before
    position `25`.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到，直到位置`25`，没有错误。这并不是你从典型的测序仪输出中得到的结果。我们的示例文件已经经过过滤，1,000基因组过滤规则要求在位置`25`之前不能有`N`调用。
- en: While we cannot study the behavior of `N`s in this dataset before position `25`
    (feel free to use one of your own unfiltered FASTQ files with this code in order
    to see how `N`s distribute across the read position), we can see that after position
    `25`, the distribution is far from uniform. There is an important lesson here,
    which is that the quantity of uncalled bases is position-dependent. So, what about
    the quality of the reads?
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们不能在位置`25`之前研究`N`在这个数据集中的行为（如果你有一个未过滤的FASTQ文件，可以使用这段代码查看`N`在读取位置的分布），但我们可以看到，在位置`25`之后，分布远非均匀。在这里有一个重要的教训，那就是未调用的碱基数量是与位置相关的。那么，读取的质量如何呢？
- en: 'Let’s study the distribution of Phred scores (that is, the quality of our reads):'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们研究Phred分数的分布（即我们读取的质量）：
- en: '[PRE21]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We will start by reopening the file (again) and initializing a default dictionary.
    We then get the `phred_quality` letter annotation, but we ignore sequencing positions
    that are up to 24 **base pairs** (**bp**) from the start (because of the filtering
    of our FASTQ file, if you have an unfiltered file, you may want to drop this rule).
    We add the quality score to our default dictionary and, finally, print it.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重新打开文件（再次）并初始化一个默认字典。然后，我们获取`phred_quality`字母注释，但我们忽略从起始位置到`24`的测序位置**碱基对**（**bp**）（由于我们的FASTQ文件已过滤，如果你有未过滤的文件，可能需要删除此规则）。我们将质量分数添加到默认字典中，最后打印出来。
- en: Note
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: As a short reminder, the Phred quality score is a logarithmic representation
    of the probability of an accurate call. This probability is given as ![](img/B17942_03_009.png).
    So, a *Q* of 10 represents 90 percent call accuracy, 20 represents 99 percent
    call accuracy, and 30 will be 99.9 percent. For our file, the maximum accuracy
    will be 99.99 percent (40). In some cases, values of 60 are possible (99.9999
    percent accuracy).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 简单提醒一下，Phred质量分数是准确调用概率的对数表示。这个概率可以表示为！[](img/B17942_03_009.png)。因此，*Q* 为 10
    表示 90% 的调用准确率，20 表示 99% 的调用准确率，30 表示 99.9%。对于我们的文件，最大准确率将是 99.99%（40）。在某些情况下，60
    的值是可能的（99.9999%的准确率）。
- en: 'More interestingly, we can plot the distribution of qualities according to
    their read position:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更有趣的是，我们可以根据读取位置绘制质量分布：
- en: '[PRE22]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this case, we will ignore both positions sequenced as `25` bp from the start
    (again, remove this rule if you have unfiltered sequencer data) and the maximum
    quality score for this file (`40`). However, in your case, you can consider starting
    your plotting analysis with the maximum. You may want to check the maximum possible
    value for your sequencer hardware. Generally, as most calls can be performed with
    maximum quality, you may want to remove them if you are trying to understand where
    quality problems lie.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将忽略序列位置为从起始位置`25` bp的两个位置（如果你有未过滤的测序数据，请删除此规则），以及该文件的最大质量分数（`40`）。不过，在你的情况下，你可以考虑从最大值开始绘制分析。你可能想要检查你测序仪硬件的最大可能值。通常，由于大多数调用可以在最大质量下执行，如果你想了解质量问题的所在，可能会希望删除这些数据。
- en: Note that we are using the `boxplot` function of `seaborn`; we are only using
    this because the output looks slightly better than the standard `boxplot` function
    of `matplotlib`. If you prefer not to depend on `seaborn`, just use the stock
    `matplotlib` function. In this case, you will call `ax.boxplot(vps)` instead of
    `sns.boxplot(data=vps, ax=ax)`.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们使用的是`seaborn`的`boxplot`函数；我们之所以使用它，是因为它的输出效果比`matplotlib`的标准`boxplot`函数稍好。如果你不想依赖`seaborn`，可以直接使用`matplotlib`的内建函数。在这种情况下，你可以调用`ax.boxplot(vps)`，而不是`sns.boxplot(data=vps,
    ax=ax)`。
- en: 'As expected, the distribution is not uniform, as shown in the following screenshot:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，分布并不均匀，如下图所示：
- en: '![Figure 3.2 – The distribution of Phred scores as a function of the distance
    from the start of the sequencer read ](img/B17942_03_002.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2 – Phred得分与测序读取起始位置距离的关系分布](img/B17942_03_002.jpg)'
- en: Figure 3.2 – The distribution of Phred scores as a function of the distance
    from the start of the sequencer read
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – Phred得分与测序读取起始位置距离的关系分布
- en: There’s more...
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'Although it’s impossible to discuss all the variations of output coming from
    sequencer files, paired-end reads are worth mentioning because they are common
    and require a different processing approach. With paired-end sequencing, both
    ends of a DNA fragment are sequenced with a gap in the middle (called the insert).
    In this case, two files will be produced: `X_1.FASTQ` and `X_2.FASTQ`. Both files
    will have the same order and the exact same number of sequences. The first sequence
    will be in `X_1` pairs with the first sequence of `X_2`, and so on. With regard
    to the programming technique, if you want to keep the pairing information, you
    might perform something such as this:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管无法讨论来自测序仪文件的所有输出变化，但双端读取值得一提，因为它们很常见并且需要不同的处理方式。在双端测序中，DNA片段的两端会被测序，并且中间有一个间隙（称为插入）。在这种情况下，将生成两个文件：`X_1.FASTQ`和`X_2.FASTQ`。这两个文件的顺序相同，且包含相同数量的序列。`X_1`中的第一个序列与`X_2`中的第一个序列配对，以此类推。关于编程技巧，如果你想保持配对信息，你可以执行如下操作：
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The preceding code reads all pairs in order and just counts the number of pairs.
    You will probably want to do something more, but this exposes a dialect that is
    based on the Python `zip` function that allows you to iterate through both files
    simultaneously. Remember to replace `X` with your `FASTQ` prefix.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码按顺序读取所有配对并简单地计算配对的数量。你可能需要做更多的操作，但这展示了一种基于Python `zip`函数的语法，它允许你同时迭代两个文件。记得用你的`FASTQ`前缀替换`X`。
- en: Finally, if you are sequencing human genomes, you may want to use sequencing
    data from Complete Genomics. In this case, read the *There’s more…* section in
    the next recipe, where we briefly discuss Complete Genomics data.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果你正在测序人类基因组，可能想要使用Complete Genomics的测序数据。在这种情况下，请阅读下一个食谱中的*更多内容…*部分，我们会简要讨论Complete
    Genomics数据。
- en: See also
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'Here are some links with more information:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些提供更多信息的链接：
- en: The Wikipedia page on the FASTQ format is quite informative ([http://en.wikipedia.org/wiki/FASTQ_format](http://en.wikipedia.org/wiki/FASTQ_format)).
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于FASTQ格式的维基百科页面信息非常丰富（[http://en.wikipedia.org/wiki/FASTQ_format](http://en.wikipedia.org/wiki/FASTQ_format)）。
- en: You can find more information on the 1,000 Genomes Project at [http://www.1000genomes.org/](http://www.1000genomes.org/).
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在[http://www.1000genomes.org/](http://www.1000genomes.org/)找到更多关于1000基因组计划的信息。
- en: Information about the Phred quality score can be found at [http://en.wikipedia.org/wiki/Phred_quality_score](http://en.wikipedia.org/wiki/Phred_quality_score).
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于Phred质量分数的信息可以在[http://en.wikipedia.org/wiki/Phred_quality_score](http://en.wikipedia.org/wiki/Phred_quality_score)找到。
- en: Illumina provides a good introduction page to paired-end reads at [https://www.illumina.com/science/technology/next-generation-sequencing/paired-end-vs-single-read-sequencing.xhtml](https://www.illumina.com/science/technology/next-generation-sequencing/paired-end-vs-single-read-sequencing.xhtml).
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Illumina在[https://www.illumina.com/science/technology/next-generation-sequencing/paired-end-vs-single-read-sequencing.xhtml](https://www.illumina.com/science/technology/next-generation-sequencing/paired-end-vs-single-read-sequencing.xhtml)提供了一篇关于双端读取的良好介绍页面。
- en: The *Computational methods for discovering structural variation with next-generation
    sequencing* paper from Medvedev et al. on nature methods ([http://www.nature.com/nmeth/journal/v6/n11s/abs/nmeth.1374.xhtml](http://www.nature.com/nmeth/journal/v6/n11s/abs/nmeth.1374.xhtml));
    note that this is not open access.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Medvedev等人在《自然方法》期刊上发表的论文《*使用下一代测序发现结构变异的计算方法*》([http://www.nature.com/nmeth/journal/v6/n11s/abs/nmeth.1374.xhtml](http://www.nature.com/nmeth/journal/v6/n11s/abs/nmeth.1374.xhtml))；请注意，这篇文章并非开放获取。
- en: Working with alignment data
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理对齐数据
- en: After you receive your data from the sequencer, you will normally use a tool
    such as `bwa`) to align your sequences to a reference genome. Most users will
    have a reference genome for their species. You can read more on reference genomes
    in [*Chapter 5*](B17942_05.xhtml#_idTextAnchor122), *Working with Genomes*.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在您从测序仪获得数据后，通常会使用像`bwa`这样的工具将您的序列与参考基因组进行比对。大多数用户会有自己物种的参考基因组。您可以在[*第5章*](B17942_05.xhtml#_idTextAnchor122)，*与基因组工作*中了解更多关于参考基因组的信息。
- en: The most common representation for aligned data is the `tabix` utility of SAMtools.
    SAMtools is probably the most widely used tool for manipulating SAM/BAM files.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 对齐数据最常见的表示方法是SAMtools的`tabix`工具。SAMtools可能是最广泛使用的SAM/BAM文件操作工具。
- en: Getting ready
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: As discussed in the previous recipe, we will use data from the 1,000 Genomes
    Project. We will use the exome alignment for chromosome 20 of female `NA18489`.
    This is just 312 MB. The whole-exome alignment for this individual is 14.2 **gigabytes**
    (**GB**), and the whole genome alignment (at low coverage of 4x) is 40.1 GB. This
    data is a paired end with reads of 76 bp. This is common nowadays, but slightly
    more complex to process. We will take this into account. If your data is not paired,
    just simplify the following recipe appropriately.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一篇食谱中所讨论的，我们将使用来自1,000基因组计划的数据。我们将使用女性`NA18489`的染色体20外显子对齐数据。数据大小为312 MB。该个体的全外显子对齐数据为14.2
    **吉字节**（**GB**），全基因组对齐数据（低覆盖度为4x）为40.1 GB。该数据为双端读取，读取长度为76 bp。如今这很常见，但处理起来稍微复杂一些。我们会考虑这一点。如果您的数据不是双端数据，可以适当简化以下食谱。
- en: The cell at the top of `Chapter03/Working_with_BAM.py` will download the data
    for you. The files you will want are `NA18490_20_exome.bam` and `NA18490_20_exome.bam.bai`.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`Chapter03/Working_with_BAM.py`文件顶部的单元格将为您下载数据。您需要的文件是`NA18490_20_exome.bam`和`NA18490_20_exome.bam.bai`。'
- en: 'We will use `pysam`, a Python wrapper to the SAMtools C API. You can install
    it with the following command:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`pysam`，它是SAMtools C API的Python包装器。您可以通过以下命令安装它：
- en: '[PRE24]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: OK—let’s get started.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 好的—让我们开始吧。
- en: How to do it...
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Before you start coding, note that you can inspect the BAM file using `samtools
    view -h` (this is if you have SAMtools installed, which we recommend, even if
    you use the **Genome Analysis Toolkit** (**GATK**) or something else for variant
    calling). We suggest that you take a look at the header file and the first few
    records. The SAM format is too complex to be described here. There is plenty of
    information on the internet about it; nonetheless, sometimes, there’s some really
    interesting information buried in these header files.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始编码之前，请注意，您可以使用`samtools view -h`检查BAM文件（前提是您已经安装了SAMtools，我们推荐您安装，即使您使用的是**基因组分析工具包**（**GATK**）或其他变异调用工具）。我们建议您查看头文件和前几个记录。SAM格式过于复杂，无法在这里描述。网上有很多关于它的信息；不过，有时，某些非常有趣的信息就隐藏在这些头文件中。
- en: Tip
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: One of the most complex operations in NGS is to generate good alignment files
    from raw sequence data. This not only calls the aligner but also cleans up data.
    Now, in the `@PG` headers of high-quality BAM files, you will find the actual
    command lines used for most—if not all—of the procedures used to generate this
    BAM file. In our example BAM file, you will find all the information needed to
    run bwa, SAMtools, GATK IndelRealigner, and the Picard application suite to clean
    up data. Remember that while you can generate BAM files easily, the programs after
    it will be quite picky in terms of the correctness of the BAM input. For instance,
    if you use GATK’s variant caller to generate genotype calls, the files will have
    to be extensively cleaned. The header of other BAM files can thus provide you
    with the best way to generate yours. A final recommendation is that if you do
    not work with human data, try to find good BAMs for your species, because the
    parameters of a given program may be slightly different. Also, if you use something
    other than the WGS data, check for similar types of sequencing data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: NGS 中最复杂的操作之一是从原始序列数据生成良好的比对文件。这不仅涉及调用比对工具，还包括清理数据。在高质量的 BAM 文件的 `@PG` 头部，你将找到用于生成该
    BAM 文件的绝大多数（如果不是全部）过程的实际命令行。在我们的示例 BAM 文件中，你会找到所有运行 bwa、SAMtools、GATK IndelRealigner
    和 Picard 应用程序套件来清理数据所需的信息。记住，虽然你可以轻松生成 BAM 文件，但之后的程序对于 BAM 输入的正确性会非常挑剔。例如，如果你使用
    GATK 的变异调用器来生成基因型调用，文件必须经过广泛的清理。因此，其他 BAM 文件的头部可以为你提供生成自己文件的最佳方式。最后的建议是，如果你不处理人类数据，尝试为你的物种找到合适的
    BAM 文件，因为某些程序的参数可能略有不同。此外，如果你使用的是非 WGS 数据，检查类似类型的测序数据。
- en: 'Let’s take a look at the following steps:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下步骤：
- en: 'Let’s inspect the header files:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查一下头文件：
- en: '[PRE25]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The header is represented as a dictionary (where the key is `record_type`).
    As there can be several instances of the same `record_type`, the value of the
    dictionary is a list (where each element is—again—a dictionary, or sometimes a
    string containing tag/value pairs).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 头部被表示为字典（其中键是 `record_type`）。由于同一 `record_type` 可能有多个实例，字典的值是一个列表（其中每个元素再次是一个字典，或者有时是包含标签/值对的字符串）。
- en: 'We will now inspect a single record. The amount of data per record is quite
    complex. Here, we will focus on some of the fundamental fields for paired-end
    reads. Check the SAM file specification and the `pysam` API documentation for
    more details:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将检查一个单一的记录。每个记录的数据量相当复杂。在这里，我们将重点关注配对末端读取的一些基本字段。有关更多详细信息，请查看 SAM 文件规范和
    `pysam` API 文档：
- en: '[PRE26]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note that the BAM file object can be iterated over its records. We will transverse
    it until we find a record whose **Concise Idiosyncratic Gapped Alignment Report**
    (**CIGAR**) string contains a match and a soft clip.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，BAM 文件对象可以通过其记录进行迭代。我们将遍历它，直到找到一个 **Concise Idiosyncratic Gapped Alignment
    Report**（**CIGAR**）字符串包含匹配和软剪切的记录。
- en: The CIGAR string gives an indication of the alignment of individual bases. The
    clipped part of the sequence is the part that the aligner failed to align (but
    is not removed from the sequence). We will also want the read, its mate ID, and
    position (of the pair, as we have paired-end reads) that was mapped to the reference
    genome.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: CIGAR 字符串给出了单个碱基的比对信息。序列中被剪切的部分是比对工具未能对齐的部分（但未从序列中删除）。我们还需要读取序列、其配对 ID 以及映射到参考基因组上的位置（由于我们有配对末端读取，因此是配对的位置信息）。
- en: First, we print the query template name, followed by the reference ID. The reference
    ID is a pointer to the name of the sequence on the given references on the lookup
    table of references. An example will make this clear. For all records on this
    BAM file, the reference ID is `19` (a non-informative number), but if you apply
    `bam.getrname(19)`, you will get `20`, which is the name of the chromosome. So,
    do not confuse the reference ID (in this case, `19`) with the name of the chromosome
    (`20`). This is then followed by the reference start and reference end. `pysam`
    is 0-based, not 1-based, so be careful when you convert coordinates to other libraries.
    You will notice that the start and end for this case are 59,996 and 60,048, which
    means an alignment of 52 bases. Why are there only 52 bases when the read size
    is 76 (remember—the read size used in this BAM file)? The answer can be found
    on the CIGAR string, which in our case will be `52M24S`, which is a 52-bases match,
    followed by 24 bases that were soft-clipped.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们打印查询模板名称，接着是参考 ID。参考 ID 是指向给定参考序列查找表中序列名称的指针。一个示例可以使这点更加清晰。对于该 BAM 文件中的所有记录，参考
    ID 是`19`（一个没有实际意义的数字），但如果你应用`bam.getrname(19)`，你会得到`20`，这就是染色体的名称。所以，不要将参考 ID（此处是`19`）与染色体名称（`20`）混淆。接下来是参考开始和参考结束。`pysam`是基于
    0 的，而非基于 1 的，所以在将坐标转换为其他库时要小心。你会注意到，在这个例子中，开始和结束的位置分别是 59,996 和 60,048，这意味着一个
    52 碱基的比对。为什么当读取大小是 76（记住，这是该 BAM 文件中使用的读取大小）时，只有 52 个碱基？答案可以通过 CIGAR 字符串找到，在我们的例子中是`52M24S`，即
    52 个匹配碱基，后面是 24 个软剪接的碱基。
- en: Then, we print where the alignment starts and ends and calculate its length.
    By the way, you can compute this by looking at the CIGAR string. It starts at
    0 (as the first part of the read is mapped) and ends at 52\. The length is 76
    again.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们打印比对的开始和结束位置，并计算其长度。顺便说一句，你可以通过查看 CIGAR 字符串来计算这一点。它从 0 开始（因为读取的第一部分已被比对），并在
    52 处结束。长度再次是 76。
- en: Now, we query the mate (something that you will only do if you have paired-end
    reads). We get its reference ID (as shown in the previous code snippet), its start
    position, and a measure of the distance between both pairs. This measure of distance
    only makes sense if both mates are mapped to the same chromosome.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们查询配对端（如果你有双端读取，才会做这个操作）。我们获取它的参考 ID（如前面的代码片段所示），它的开始位置，以及两个配对之间的距离度量。这个距离度量只有在两个配对都映射到同一染色体时才有意义。
- en: We then plot the Phred score (refer to the previous recipe, *Working with modern
    sequence formats*, on Phred scores) for the sequence, and then only for the aligned
    part. Finally, we print the sequence (don’t forget to do this!). This is the complete
    sequence, not the clipped one (of course, you can use the preceding coordinates
    to clip).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们绘制序列的 Phred 分数（参见之前的配方，*处理现代序列格式*，关于 Phred 分数的部分），然后仅绘制已比对部分的 Phred 分数。最后，我们打印出该序列（别忘了这么做！）。这是完整的序列，而不是剪接过的序列（当然，你可以使用之前的坐标来进行剪接）。
- en: 'Now, let’s plot the distribution of the successfully mapped positions in a
    subset of sequences in the BAM file:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们在 BAM 文件中的一个子集序列中绘制成功映射位置的分布：
- en: '[PRE27]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We will start by initializing an array to keep the count for the entire `76`
    positions. Note that we then fetch only the records for chromosome 20 between
    positions 0 and 10 `tabix`) for these kinds of fetch operations; the speed of
    execution will be completely different.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先初始化一个数组，用来保存整个`76`个位置的计数。请注意，我们接下来只获取染色体 20 上从位置 0 到 10 的记录（`tabix`）进行此类抓取操作；执行速度将会完全不同。
- en: 'We traverse all records in the 10 Mbp boundary. For each boundary, we get the
    alignment start and end and increase the counter of mappability among the positions
    that were aligned. Finally, we convert this into frequencies, and then plot it,
    as shown in the following screenshot:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历所有位于 10 Mbp 边界内的记录。对于每个边界，我们获取比对的开始和结束，并增加在这些已比对位置中的映射性计数器。最后，我们将其转换为频率，然后进行绘制，如下图所示：
- en: '![Figure 3.3 – The percentage of mapped calls as a function of the position
    from the start of the sequencer read ](img/B17942_03_003.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.3 – 映射调用的百分比与测序器读取开始位置的函数关系](img/B17942_03_003.jpg)'
- en: Figure 3.3 – The percentage of mapped calls as a function of the position from
    the start of the sequencer read
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 – 映射调用的百分比与测序器读取开始位置的函数关系
- en: It’s quite clear that the distribution of mappability is far from being uniform;
    it’s worse at the extremes, with a drop in the middle.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，映射性分布远非均匀；在极端位置更差，中间位置则出现下降。
- en: 'Finally, let’s get the distribution of Phred scores across the mapped part
    of the reads. As you may suspect, this is probably not going to be uniform:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们获取映射部分的 Phred 分数分布。正如你可能猜到的，这可能不会是均匀分布的：
- en: '[PRE28]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here, we again use default dictionaries that allow you to use a bit of initialization
    code. We now fetch from start to end and create a list of Phred scores in a dictionary
    whose index is the relative position in the sequence read.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们再次使用默认字典，它允许你使用一些初始化代码。我们现在从开始到结束提取数据，并在字典中创建一个 Phred 分数的列表，其中索引是序列读取中的相对位置。
- en: We then use NumPy to calculate the 95th, 50th (median), and 5th percentiles,
    along with the maximum of quality scores per position. For most computational
    biology analyses, having a statistical summarized view of the data is quite common.
    So, you’re probably already familiar with not only percentile calculations, but
    also with other Pythonic ways to calculate means, standard deviations, maximums,
    and minimums.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 NumPy 计算每个位置的 95 百分位、50 百分位（中位数）和 5 百分位，以及质量分数的最大值。对于大多数计算生物学分析，拥有数据的统计汇总视图是非常常见的。因此，你可能不仅熟悉百分位数的计算，还熟悉其他
    Pythonic 方式来计算均值、标准差、最大值和最小值。
- en: 'Finally, we will perform a stacked plot of the distribution of Phred scores
    per position. Due to the way `matplotlib` expects stacks, we have to subtract
    the value of the lower percentile from the one before with the `stackplot` call.
    We can use the list for the bottom percentiles, but we have to correct the median
    and the top, as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将绘制每个位置的 Phred 分数的堆叠图。由于`matplotlib`期望堆叠的方式，我们必须通过 `stackplot` 调用从前一个百分位值中减去较低百分位的值。我们可以使用底部百分位数的列表，但我们需要修正中位数和顶部百分位，如下所示：
- en: '![Figure 3.4 – The distribution of Phred scores as a function of the position
    in the read; the bottom blue color spans from 0 to the 5th percentile; the green
    color up to the median, red to the 95th percentile, and purple to the maximum
    ](img/B17942_03_004.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.4 – Phred 分数在读取位置上的分布；底部蓝色表示从 0 到 5 百分位；绿色表示中位数，红色表示 95 百分位，紫色表示最大值](img/B17942_03_004.jpg)'
- en: Figure 3.4 – The distribution of Phred scores as a function of the position
    in the read; the bottom blue color spans from 0 to the 5th percentile; the green
    color up to the median, red to the 95th percentile, and purple to the maximum
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 – Phred 分数在读取位置上的分布；底部蓝色表示从 0 到 5 百分位；绿色表示中位数，红色表示 95 百分位，紫色表示最大值
- en: There’s more...
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Although we will discuss data filtering in the *Studying genome accessibility
    and filtering SNP data* recipe of this chapter, it’s not our objective to explain
    the SAM format in detail or give a detailed course in data filtering. This task
    would require a book of its own, but with the basics of `pysam`, you can navigate
    through SAM/BAM files. However, in the last recipe of this chapter, we will take
    a look at extracting genome-wide metrics from BAM files (via annotations on VCF
    files that represent metrics of BAM files) for the purpose of understanding the
    overall quality of our dataset.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们将在本章的*学习基因组可达性与过滤 SNP 数据*配方中讨论数据过滤，但我们的目标并不是详细解释 SAM 格式或给出数据过滤的详细课程。这项任务需要一本专门的书籍，但凭借`pysam`的基础，你可以浏览
    SAM/BAM 文件。不过，在本章的最后一个配方中，我们将探讨如何从 BAM 文件中提取全基因组度量（通过表示 BAM 文件度量的 VCF 文件注释），目的是了解我们数据集的整体质量。
- en: You will probably have very large data files to work with. It’s possible that
    some BAM processing will take too much time. One of the first approaches to reducing
    the computation time is subsampling. For example, if you subsample at 10 percent,
    you ignore 9 records out of 10\. For many tasks, such as some of the analysis
    done for the quality assessment of BAM files, subsampling at 10 percent (or even
    1 percent) will be enough to get the gist of the quality of the file.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会有非常大的数据文件需要处理。有可能某些 BAM 处理会花费太多时间。减少计算时间的第一个方法是抽样。例如，如果你以 10% 进行抽样，你将忽略
    10 条记录中的 9 条。对于许多任务，比如一些 BAM 文件质量评估的分析，以 10%（甚至 1%）进行抽样就足够获得文件质量的大致情况。
- en: If you use human data, you may have your data sequenced at Complete Genomics.
    In this case, the alignment files will be different. Although Complete Genomics
    provides tools to convert to standard formats, you might be served better if you
    use its own data.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是人类数据，你可能会在 Complete Genomics 上进行测序。在这种情况下，比对文件将会有所不同。尽管 Complete Genomics
    提供了将数据转换为标准格式的工具，但如果使用其自己的数据，可能会更适合你。
- en: See also
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'Additional information can be found at the following links:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的信息可以通过以下链接获得：
- en: The SAM/BAM format is described at [http://samtools.github.io/hts-specs/SAMv1.pdf](http://samtools.github.io/hts-specs/SAMv1.pdf).
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SAM/BAM格式的描述可以在[http://samtools.github.io/hts-specs/SAMv1.pdf](http://samtools.github.io/hts-specs/SAMv1.pdf)找到。
- en: You can find an introductory explanation of the SAM format on the Abecasis group
    wiki page at [http://genome.sph.umich.edu/wiki/SAM](http://genome.sph.umich.edu/wiki/SAM).
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在Abecasis小组的维基页面上找到关于SAM格式的介绍：[http://genome.sph.umich.edu/wiki/SAM](http://genome.sph.umich.edu/wiki/SAM)。
- en: If you really need to get complex statistics from BAM files, Alistair Miles’
    `pysamstats` library is your port of call, at [https://github.com/alimanfoo/pysamstats](https://github.com/alimanfoo/pysamstats).
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你真的需要从BAM文件中提取复杂的统计数据，Alistair Miles的`pysamstats`库是你的首选，网址：[https://github.com/alimanfoo/pysamstats](https://github.com/alimanfoo/pysamstats)。
- en: To convert your raw sequence data to alignment data, you will need an aligner;
    the most widely used is bwa ([http://bio-bwa.sourceforge.net/](http://bio-bwa.sourceforge.net/)).
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要将原始序列数据转换为比对数据，你需要一个比对工具；最常用的是bwa，网址：[http://bio-bwa.sourceforge.net/](http://bio-bwa.sourceforge.net/)。
- en: 'Picard (surely a reference to *Star Trek: The Next Generation*) is the most
    commonly used tool to clean up BAM files; refer to [http://broadinstitute.github.io/picard/](http://broadinstitute.github.io/picard/).'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Picard（显然是指*星际迷航：下一代*中的人物）是最常用的工具来清理BAM文件；参考：[http://broadinstitute.github.io/picard/](http://broadinstitute.github.io/picard/)。
- en: The technical forum for sequence analysis is called *SEQanswers* ([http://seqanswers.com/](http://seqanswers.com/)).
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列分析的技术论坛叫做*SEQanswers*，网址：[http://seqanswers.com/](http://seqanswers.com/)。
- en: I would like to repeat the recommendation on Biostars here (which is referred
    to in the previous recipe, *Working with modern sequence formats*); it’s a treasure
    trove of information and has a very friendly community, at [http://www.biostars.org/](http://www.biostars.org/).
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我想在这里重复一下Biostars上的推荐（在前面的“*处理现代序列格式*”一节中提到过）；这是一个信息宝库，且拥有一个非常友好的社区，网址：[http://www.biostars.org/](http://www.biostars.org/)。
- en: If you have the Complete Genomics data, take a look at the **frequently asked
    questions** (**FAQs**) at [http://www.completegenomics.com/customer-support/faqs/](http://www.completegenomics.com/customer-support/faqs/).
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有Complete Genomics数据，可以查看**常见问题解答**（**FAQs**），网址：[http://www.completegenomics.com/customer-support/faqs/](http://www.completegenomics.com/customer-support/faqs/)。
- en: Extracting data from VCF files
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从VCF文件中提取数据
- en: After running a genotype caller (for example, GATK or SAMtools), you will have
    a VCF file reporting on genomic variations, such as SNPs, `cyvcf2` module.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行基因型调用工具（例如，GATK或SAMtools）后，你将得到一个VCF文件，报告基因组变异信息，如SNPs，`cyvcf2`模块。
- en: Getting ready
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'While NGS is all about big data, there is a limit to how much I can ask you
    to download as a dataset for this book. I believe that 2 to 20 GB of data for
    a tutorial is asking too much. While the 1,000 Genomes VCF files with realistic
    annotations are in this OOM, we will want to work with much less data here. Fortunately,
    the bioinformatics community has developed tools to allow for the partial download
    of data. As part of the SAMtools/`htslib` package ([http://www.htslib.org/](http://www.htslib.org/)),
    you can download `tabix` and `bgzip`, which will take care of data management.
    On the command line, perform the following operation:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管NGS主要涉及大数据，但我不能要求你为本书下载过多的数据集。我认为2到20 GB的数据对于教程来说太多了。虽然1,000基因组计划的VCF文件和实际注释数据在这个数量级，但我们这里将处理更少的数据。幸运的是，生物信息学社区已经开发了工具，允许部分下载数据。作为SAMtools/`htslib`包的一部分（[http://www.htslib.org/](http://www.htslib.org/)），你可以下载`tabix`和`bgzip`，它们将负责数据管理。在命令行中，执行以下操作：
- en: '[PRE29]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The first line will partially download the VCF file for chromosome 22 (up to
    17 Mbp) of the 1,000 Genomes Project. Then, `bgzip` will compress it.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行将部分下载来自1,000基因组计划的22号染色体VCF文件（最多17 Mbp），然后，`bgzip`会进行压缩。
- en: The second line will create an index, which we will need for direct access to
    a section of the genome. As usual, you have the code to do this in a notebook
    (the `Chapter03/Working_with_VCF.py` file).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 第二行将创建一个索引，这是我们直接访问基因组某一部分所需要的。像往常一样，你可以在笔记本中找到执行此操作的代码（`Chapter03/Working_with_VCF.py`文件）。
- en: 'You will need to install `cyvcf2`:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要安装`cyvcf2`：
- en: '[PRE30]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Tip
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: If you have conflict resolution problems, you can try using `pip` instead. This
    is a last-resort solution that you will find yourself doing with `conda`, as it
    is incapable of resolving package dependencies, something that happens more often
    than not. You can execute `pip install cyvcf2`.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遇到冲突解决问题，可以尝试改用 `pip`。这是一个最后的解决方案，当你使用 `conda` 时，往往会因为其无法解决软件包依赖问题而不得不这样做，你可以执行
    `pip install cyvcf2`。
- en: How to do it...
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'Take a look at the following steps:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下步骤：
- en: 'Let’s start by inspecting the information that we can get per record:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从检查每条记录可以获取的信息开始：
- en: '[PRE31]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We start by inspecting the annotations that are available for each record (remember
    that each record encodes a variant, such as SNP, CNV, INDELs, and so on, and the
    state of that variant per sample). At the variant (record) level, we find `AC`—the
    total number of `ALT` alleles in called genotypes, `AF`—the estimated allele frequency,
    `NS`—the number of samples with data, `AN`—the total number of alleles in called
    genotypes, and `DP`—the total read depth. There are others, but they are mostly
    specific to the 1,000 Genomes Project (here, we will try to be as general as possible).
    Your own dataset may have more annotations (or none of these).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从检查每条记录可用的注释开始（记住，每条记录编码一个变异，例如 SNP、CNV、INDEL 等，以及该变异在每个样本中的状态）。在变异（记录）级别，我们会找到
    `AC` —— 在调用基因型中 `ALT` 等位基因的总数，`AF` —— 估算的等位基因频率，`NS` —— 有数据的样本数，`AN` —— 在调用基因型中的等位基因总数，以及
    `DP` —— 总读取深度。还有其他信息，但它们大多数是 1000 基因组计划特有的（在这里，我们将尽量保持通用）。你自己的数据集可能有更多的注释（或没有这些注释）。
- en: 'At the sample level, there are only two annotations in this file: `GT`—genotype,
    and `DP`—the per-sample read depth. You have the per-variant (total) read depth
    and the per-sample read depth; be sure not to confuse both.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在样本级别，这个文件中只有两个注释：`GT` —— 基因型，和 `DP` —— 每个样本的读取深度。你有每个变异的总读取深度和每个样本的读取深度，请确保不要混淆两者。
- en: 'Now that we know what information is available, let’s inspect a single VCF
    record:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们知道了有哪些信息可用，让我们查看单个 VCF 记录：
- en: '[PRE32]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We will start by retrieving the standard information: the chromosome, position,
    ID, reference base (typically just one) and alternative bases (you can have more
    than one, but it’s not uncommon as a first filtering approach to only accept a
    single `ALT`, for example, only accept biallelic SNPs), quality (as you might
    expect, Phred-scaled), and filter status. Regarding the filter status, remember
    that whatever the VCF file says, you may still want to apply extra filters (as
    in the next recipe, *Studying genome accessibility and filtering SNP data*).'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从获取标准信息开始：染色体、位置、ID、参考碱基（通常只有一个）和替代碱基（可以有多个，但作为一种常见的初步筛选方法，通常只接受单个 `ALT`，例如只接受双等位基因
    SNP），质量（如你所预期，采用 Phred 扩展评分），以及过滤状态。关于过滤状态，请记住，不论 VCF 文件中如何表示，你可能仍然需要应用额外的过滤器（如下一个教程所述，*研究基因组可访问性和筛选
    SNP 数据*）。
- en: We then print the additional variant-level information (`AC`, `AS`, `AF`, `AN`,
    `DP`, and so on), followed by the sample format (in this case, `DP` and `GT`).
    Finally, we count the number of samples and inspect a single sample to check whether
    it was called for this variant. Also, the reported alleles, heterozygosity, and
    phasing status (this dataset happens to be phased, which is not that common) are
    included.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们打印附加的变异级别信息（`AC`、`AS`、`AF`、`AN`、`DP` 等），接着是样本格式（在此案例中为 `DP` 和 `GT`）。最后，我们统计样本数并检查单个样本，以确认它是否针对该变异进行了调用。同时，还包括报告的等位基因、杂合性和相位状态（该数据集恰好是相位的，虽然这并不常见）。
- en: 'Let’s check the type of variant and the number of nonbiallelic SNPs in a single
    pass:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们一次性检查变异的类型和非双等位基因 SNP 的数量：
- en: '[PRE33]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We will now use the now-common Python default dictionary. We find that this
    dataset has INDELs, CNVs, and—of course—SNPs (roughly two-thirds being transitions
    with one-third transversions). There is a residual number (79) of triallelic SNPs.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用现在常见的 Python 默认字典。我们发现该数据集中包含 INDEL、CNV 和——当然——SNP（大约三分之二是转换突变，一三分之一是倒位突变）。还有一个剩余的数量（79）为三等位基因
    SNP。
- en: There’s more...
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: 'The purpose of this recipe is to get you up to speed with the `cyvcf2` module.
    At this stage, you should be comfortable with the API. We will not spend too much
    time on usage details because this will be the main purpose of the next recipe:
    using the VCF module to study the quality of your variant calls.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的目的是让你快速熟悉 `cyvcf2` 模块。此时，你应该已经能熟练使用该 API。我们不会花太多时间讲解使用细节，因为下一个教程的主要内容是：使用
    VCF 模块研究变异调用的质量。
- en: While `cyvcf2` is quite fast, it can still take a lot of time to process text-based
    VCF files. There are two main strategies for dealing with this problem. One strategy
    is parallel processing, which we will discuss in the last chapter, [*Chapter 9*](B17942_09.xhtml#_idTextAnchor237),
    *Bioinformatics Pipelines*. The second strategy is to convert to a more efficient
    format; we will provide an example of this in [*Chapter 6*](B17942_06.xhtml#_idTextAnchor154),
    *Population Genetics*. Note that VCF developers are working on a **Binary Variant
    Call Format** (**BCF**) version to deal with parts of these problems ([http://www.1000genomes.org/wiki/analysis/variant-call-format/bcf-binary-vcf-version-2](http://www.1000genomes.org/wiki/analysis/variant-call-format/bcf-binary-vcf-version-2)).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`cyvcf2`非常快速，但处理基于文本的VCF文件仍然可能需要很长时间。有两种主要策略来处理这个问题。一种策略是并行处理，我们将在最后一章[*第9章*](B17942_09.xhtml#_idTextAnchor237)，*生物信息学管道*中讨论。第二种策略是转换为更高效的格式；我们将在[*第6章*](B17942_06.xhtml#_idTextAnchor154)，*群体遗传学*中提供示例。请注意，VCF开发人员正在开发**二进制变异调用格式**（**BCF**）版本，以解决这些问题的部分内容（[http://www.1000genomes.org/wiki/analysis/variant-call-format/bcf-binary-vcf-version-2](http://www.1000genomes.org/wiki/analysis/variant-call-format/bcf-binary-vcf-version-2)）。
- en: See also
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'Some useful links are as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 一些有用的链接如下：
- en: The specification for VCF is available at [http://samtools.github.io/hts-specs/VCFv4.2.pdf](http://samtools.github.io/hts-specs/VCFv4.2.pdf).
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VCF的规格可以在[http://samtools.github.io/hts-specs/VCFv4.2.pdf](http://samtools.github.io/hts-specs/VCFv4.2.pdf)找到。
- en: GATK is one of the most widely used variant callers; check out [https://www.broadinstitute.org/gatk/](https://www.broadinstitute.org/gatk/)
    for details.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GATK是最广泛使用的变异调用工具之一；详情请查阅[https://www.broadinstitute.org/gatk/](https://www.broadinstitute.org/gatk/)。
- en: SAMtools and `htslib` are used for variant calling and SAM/BAM management; check
    out [http://htslib.org](http://htslib.org) for details.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SAMtools和`htslib`用于变异调用和SAM/BAM管理；详情请查阅[http://htslib.org](http://htslib.org)。
- en: Studying genome accessibility and filtering SNP data
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 研究基因组可及性和过滤SNP数据
- en: While the previous recipes were focused on giving an overview of Python libraries
    to deal with alignment and variant call data, in this recipe, we will concentrate
    on actually using them with a clear purpose in mind.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然之前的配方集中于提供Python库的概述，用于处理比对和变异调用数据，但在这篇配方中，我们将专注于实际使用这些库，并明确目标。
- en: If you are using NGS data, chances are that your most important file to analyze
    is a VCF file, which is produced by a genotype caller such as SAMtools, `mpileup`,
    or GATK. The quality of your VCF calls may need to be assessed and filtered. Here,
    we will put in place a framework to filter SNP data. Rather than giving you filtering
    rules (an impossible task to be performed in a general way), we will give you
    procedures to assess the quality of your data. With this, you can devise your
    own filters.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用NGS数据，很可能你要分析的最重要文件是VCF文件，它由基因型调用器（如SAMtools、`mpileup`或GATK）生成。你可能需要评估和过滤你的VCF调用的质量。在这里，我们将建立一个框架来过滤SNP数据。我们不会提供具体的过滤规则（因为在一般情况下无法执行这一任务），而是给出评估数据质量的程序。通过这些程序，你可以设计自己的过滤规则。
- en: Getting ready
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In the best-case scenario, you have a VCF file with proper filters applied.
    If this is the case, you can just go ahead and use your file. Note that all VCF
    files will have a `FILTER` column, but this might not mean that all of the proper
    filters were applied. You have to be sure that your data is properly filtered.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在最佳情况下，你会有一个应用了适当过滤的VCF文件。如果是这种情况，你可以直接使用你的文件。请注意，所有VCF文件都会有一个`FILTER`列，但这可能并不意味着所有正确的过滤都已应用。你必须确保数据已正确过滤。
- en: In the second case, which is one of the most common, your file will have unfiltered
    data, but you’ll have enough annotations and can apply hard filters (there is
    no need for programmatic filtering). If you have a GATK annotated file, refer
    to [http://gatkforums.broadinstitute.org/discussion/2806/howto-apply-hard-filters-to-a-call-set](http://gatkforums.broadinstitute.org/discussion/2806/howto-apply-hard-filters-to-a-call-set).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种情况中，这是最常见的一种情况，你的文件将包含未过滤的数据，但你会有足够的注释，并且可以应用硬过滤（无需程序化过滤）。如果你有GATK注释的文件，可以参考[http://gatkforums.broadinstitute.org/discussion/2806/howto-apply-hard-filters-to-a-call-set](http://gatkforums.broadinstitute.org/discussion/2806/howto-apply-hard-filters-to-a-call-set)。
- en: In the third case, you have a VCF file that has all the annotations that you
    need, but you may want to apply more flexible filters (for example, “if read depth
    > 20, accept if mapping quality > 30; otherwise, accept if mapping quality > 40”).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三种情况下，你有一个包含所有必要注释的VCF文件，但你可能希望应用更灵活的过滤器（例如，“如果读取深度 > 20，则映射质量 > 30 时接受；否则，映射质量
    > 40 时接受”）。
- en: In the fourth case, your VCF file does not have all the necessary annotations
    and you have to revisit your BAM files (or even other sources of information).
    In this case, the best solution is to find whatever extra information you can
    and create a new VCF file with the required annotations. Some genotype callers
    (such as GATK) allow you to specify which annotations you want; you may also want
    to use extra programs to provide more annotations. For example, **SnpEff** ([http://snpeff.sourceforge.net/](http://snpeff.sourceforge.net/))
    will annotate your SNPs with predictions of their effect (for example, if they
    are in exons, are they coding or non-coding?).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在第四种情况下，你的VCF文件缺少所有必要的注释，你必须重新检查BAM文件（甚至其他信息来源）。在这种情况下，最好的解决方案是找到任何额外的信息，并创建一个带有所需注释的新VCF文件。一些基因型调用器（如GATK）允许你指定需要哪些注释；你可能还需要使用额外的程序来提供更多的注释。例如，**SnpEff**
    ([http://snpeff.sourceforge.net/](http://snpeff.sourceforge.net/)) 会为你的SNPs注释其效应预测（例如，如果它们位于外显子中，它们是编码区还是非编码区？）。
- en: It’s impossible to provide a clear-cut recipe, as it will vary with your type
    of sequencing data, your species of study, and your tolerance to errors, among
    other variables. What we can do is provide a set of typical analyses that is done
    for high-quality filtering.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 提供一个明确的配方是不可能的，因为它会根据你的测序数据类型、研究物种以及你对错误的容忍度等变量有所不同。我们能做的是提供一套典型的高质量过滤分析方法。
- en: In this recipe, we will not use data from the human 1,000 Genomes Project. We
    want *dirty*, unfiltered data that has a lot of common annotations that can be
    used to filter it. We will use data from the Anopheles gambiae 1,000 Genomes Project
    (Anopheles is a mosquito vector involved in the transmission of a parasite that
    causes malaria), which makes filtered and unfiltered data available. You can find
    more information on this project at [http://www.malariagen.net/projects/vector/ag1000g](http://www.malariagen.net/projects/vector/ag1000g).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们不会使用来自人类1000基因组计划的数据。我们想要的是*脏*的、未过滤的数据，其中有许多常见的注释可以用来进行过滤。我们将使用来自按蚊1000基因组计划的数据（按蚊是传播疟疾寄生虫的蚊子载体），该计划提供了过滤和未过滤的数据。你可以在[http://www.malariagen.net/projects/vector/ag1000g](http://www.malariagen.net/projects/vector/ag1000g)上找到有关此项目的更多信息。
- en: 'We will get a part of the centromere of chromosome `3L` for around 100 mosquitoes,
    which is followed by a part somewhere in the middle of this chromosome (and index
    both):'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将获取大约100只蚊子的染色体`3L`的部分着丝粒区域，接着获取该染色体中间某部分（并索引两者）：
- en: '[PRE34]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: If the links do not work, be sure to check [https://github.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition/blob/main/Datasets.py](https://github.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition/blob/main/Datasets.py)
    for updates. As usual, the code for downloading this data is available in the
    `Chapter02/Filtering_SNPs.ipynb` notebook.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如果链接无法使用，请确保查看[https://github.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition/blob/main/Datasets.py](https://github.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition/blob/main/Datasets.py)以获取更新。像往常一样，用于下载该数据的代码在`Chapter02/Filtering_SNPs.ipynb`笔记本中。
- en: 'Finally, a word of warning on this recipe: the level of Python here will be
    slightly more complicated than usual. The more general code we write, the easier
    it will be for you to reuse it for your specific case. We will use functional
    programming techniques (`lambda` functions) and the `partial` function application
    extensively.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，关于这个配方的一个警告：这里的Python难度会比平时稍微复杂一些。我们编写的越通用的代码，你就越容易将其重用于你的特定情况。我们将广泛使用函数式编程技术（`lambda`函数）和`partial`函数应用。
- en: How to do it...
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Take a look at the following steps:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下步骤：
- en: 'Let’s start by plotting the distribution of variants across the genome in both
    files:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从绘制两个文件中基因组变异分布的图表开始：
- en: '[PRE35]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We will start by performing the required imports (as usual, remember to remove
    the first line if you are not using the IPython Notebook). Before I explain the
    function, note what we are doing.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从执行所需的导入开始（和往常一样，如果你不使用IPython Notebook，请记得删除第一行）。在我解释功能之前，请注意我们正在做什么。
- en: For both files, we will compute windowed statistics. We will divide our file,
    which includes 200,000 bp of data, into windows of size 2,000 (100 windows). Every
    time we find a biallelic SNP, we will add a 1 to the list related to this window
    in the `window` function.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这两个文件，我们将计算窗口统计数据。我们将我们的数据文件（包含200,000 bp的数据）分成大小为2,000的窗口（100个窗口）。每次找到一个双等位基因SNP，我们将在`window`函数相关的列表中添加一个1。
- en: The `window` function will take a VCF record (a `rec.is_snp` SNP that is not
    biallelic len `(rec.ALT) == 1`), determine the window where that record belongs
    (by performing an integer division of `rec.POS` by size), and extend the list
    of results of that window by the function passed to it as the `fun` parameter
    (which, in our case, is just a 1).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '`window`函数将获取一个VCF记录（`rec.is_snp`表示不是双等位基因的SNP，长度为`(rec.ALT) == 1`），确定该记录所属的窗口（通过将`rec.POS`整除大小来执行），并通过作为`fun`参数传递给它的函数（在我们的情况下，只是1）扩展该窗口结果列表。'
- en: So, now we have a list of 100 elements (each representing 2,000 bp). Each element
    will be another list that will have a 1 for each biallelic SNP found.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在我们有了一个包含100个元素的列表（每个代表2,000 bp）。每个元素将是另一个列表，其中每个双等位基因SNP找到时将有一个1。
- en: So, if you have 200 SNPs in the first 2,000 bp, the first element of the list
    will have 200 ones.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果在前2,000 bp中有200个SNP，列表的第一个元素将有200个1。
- en: 'Let’s continue, as follows:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们继续，如下所示：
- en: '[PRE36]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Here, we perform a plot that contains statistical information for each of our
    100 windows. `apply_win_funs` will calculate a set of statistics for every window.
    In this case, it will sum all the numbers in the window. Remember that every time
    we find an SNP, we add 1 to the window list. This means that if we have 200 SNPs,
    we will have 200 ones; hence, summing them will return 200.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们执行一个包含每个100个窗口的统计信息的图表。`apply_win_funs`将为每个窗口计算一组统计数据。在这种情况下，它将对窗口中的所有数字求和。请记住，每次找到一个SNP，我们都会在窗口列表中添加一个1。这意味着如果我们有200个SNP，我们将有200个1；因此，将它们求和将返回200。
- en: 'So, we are able to compute the number of SNPs per window in an apparently convoluted
    way. Why we perform things with this strategy will become apparent soon. However,
    for now, let’s check the result of this computation for both files, as shown in
    the following screenshot:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们能够以一种显然复杂的方式计算每个窗口中的SNP数量。为什么我们用这种策略执行事情很快就会显而易见。但是，现在，让我们检查这两个文件的计算结果，如下屏幕截图所示：
- en: '![Figure 3.5 – The number of biallelic SNP distributed windows of 2,000 bp
    in size for an area of 200 kilobase pairs (kbp) near the centromere (orange),
    and in the middle of the chromosome (blue); both areas come from chromosome 3L
    for circa 100 Ugandan mosquitoes from the Anopheles 1,000 Genomes Project ](img/B17942_03_005.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5 – 位于染色体3L附近200千碱基对（kbp）区域的2000 bp大小的双等位基因SNP分布窗口（橙色），以及染色体中部（蓝色）的情况；这两个区域来自约100只乌干达按蚊的Anopheles
    1,000基因组计划 ](img/B17942_03_005.jpg)'
- en: Figure 3.5 – The number of biallelic SNP distributed windows of 2,000 bp in
    size for an area of 200 kilobase pairs (kbp) near the centromere (orange), and
    in the middle of the chromosome (blue); both areas come from chromosome 3L for
    circa 100 Ugandan mosquitoes from the Anopheles 1,000 Genomes Project
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – 位于染色体3L附近200千碱基对（kbp）区域的2000 bp大小的双等位基因SNP分布窗口（橙色），以及染色体中部（蓝色）的情况；这两个区域来自约100只乌干达按蚊的Anopheles
    1,000基因组计划。
- en: Tip
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: Note that the amount of SNPs in the centromere is smaller than in the middle
    of the chromosome. This is expected because calling variants in chromosomes is
    more difficult than calling in the middle. Also, there is probably less genomic
    diversity in centromeres. If you are used to humans or other mammals, you will
    find the density of variants obnoxiously high—that’s mosquitoes for you!
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在中心粒的SNP数量比染色体中部少。这是因为在染色体中调用变异体比在中部更困难。此外，中心粒的基因组多样性可能较少。如果您习惯于人类或其他哺乳动物，您会发现变异体的密度非常高——这就是蚊子的特点！
- en: 'Let’s take a look at the sample-level annotation. We will inspect mapping quality
    zero (refer to [https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_annotator_MappingQualityZeroBySample.php](https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_annotator_MappingQualityZeroBySample.php)
    for details), which is a measure of how well sequences involved in calling this
    variant map clearly to this position. Note that there is also an `MQ0` annotation
    at the variant level:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来看看样本级别的注释。我们将检查映射质量零（请参阅 [https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_annotator_MappingQualityZeroBySample.php](https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_annotator_MappingQualityZeroBySample.php)
    了解详情），这是衡量参与调用该变异的序列是否能够清晰地映射到此位置的一个指标。请注意，变异级别也有一个 `MQ0` 注释：
- en: '[PRE37]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Start inspecting this by looking at the last `for`; we will perform a windowed
    analysis by reading the `MQ0` annotation from each record. We perform this by
    calling the `get_sample` function, which will return our preferred annotation
    (in this case, `MQ0`) that has been cast with a certain type (`my_type=np.int32`).
    We use the `partial` application function here. Python allows you to specify some
    parameters of a function and wait for other parameters to be specified later.
    Note that the most complicated thing here is the functional programming style.
    Also, note that it makes it very easy to compute other sample-level annotations.
    Just replace `MQ0` with `AB`, `AD`, `GQ`, and so on. You immediately have a computation
    for that annotation. If the annotation is not of the integer type, no problem;
    just adapt `my_type`. It’s a difficult programming style if you are not used to
    it, but you will reap its benefits very soon.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 从检查最后一个 `for` 开始；我们将通过读取每个记录中的 `MQ0` 注释进行窗口分析。我们通过调用 `get_sample` 函数来执行此操作，该函数将返回我们首选的注释（在本例中为
    `MQ0`），该注释已被转换为特定类型（`my_type=np.int32`）。我们在这里使用了 `partial` 应用函数。Python 允许您指定函数的某些参数，等待稍后再指定其他参数。请注意，这里最复杂的部分是函数式编程风格。此外，请注意，这使得计算其他样本级别的注释变得非常容易。只需将
    `MQ0` 替换为 `AB`、`AD`、`GQ` 等，您就能立即得到该注释的计算结果。如果该注释不是整数类型，也没问题；只需调整 `my_type` 即可。如果您不习惯这种编程风格，它可能比较困难，但您很快就会发现它的好处。
- en: 'Now, let’s print the median and the top 75 percentile for each window (in this
    case, with a size of 5,000):'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们打印每个窗口的中位数和第 75 百分位数（在本例中，窗口大小为 5,000）：
- en: '[PRE38]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Note that we now have two different statistics on `apply_win_funs` (percentile
    and median). Again, we pass functions as parameters (`np.median` and `np.percentile`),
    with `partial` function application done on `np.percentile`. The result looks
    like this:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在我们在 `apply_win_funs` 上有两种不同的统计数据（百分位数和中位数）。我们再次将函数作为参数传递（`np.median` 和
    `np.percentile`），并在 `np.percentile` 上进行了 `partial` 函数应用。结果如下所示：
- en: '![Figure 3.6 – Median (continuous line) and 75th percentile (dashed) of MQ0
    of sample SNPs distributed on windows of 5,000 bp in size for an area of 200 kbp
    near the centromere (blue) and in the middle of chromosome (green); both areas
    come from chromosome 3L for circa 100 Ugandan mosquitoes from the Anopheles 1,000
    Genomes Project ](img/B17942_03_006.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.6 – 样本 SNP 的 MQ0 中位数（实线）和第 75 百分位数（虚线），这些 SNP 分布在每个窗口大小为 5,000 bp 的区域内，覆盖了位于着丝粒附近（蓝色）和染色体中部（绿色）的
    200 kbp 区域；这两个区域来自 100 只左右乌干达蚊子的 3L 染色体，数据来自蚊子基因组 1,000 项目](img/B17942_03_006.jpg)'
- en: Figure 3.6 – Median (continuous line) and 75th percentile (dashed) of MQ0 of
    sample SNPs distributed on windows of 5,000 bp in size for an area of 200 kbp
    near the centromere (blue) and in the middle of chromosome (green); both areas
    come from chromosome 3L for circa 100 Ugandan mosquitoes from the Anopheles 1,000
    Genomes Project
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6 – 样本 SNP 的 MQ0 中位数（实线）和第 75 百分位数（虚线），这些 SNP 分布在每个窗口大小为 5,000 bp 的区域内，覆盖了位于着丝粒附近（蓝色）和染色体中部（绿色）的
    200 kbp 区域；这两个区域来自 100 只左右乌干达蚊子的 3L 染色体，数据来自蚊子基因组 1,000 项目。
- en: For the `standard.vcf.gz` file, the median `MQ0` is `0` (it’s plotted at the
    very bottom and is almost unseen). This is good as it suggests that most sequences
    involved in the calling of variants map clearly to this area of the genome. For
    the `centro.vcf.gz` file, `MQ0` is of poor quality. Furthermore, there are areas
    where the genotype caller cannot find any variants at all (hence the incomplete
    chart).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `standard.vcf.gz` 文件，中位数 `MQ0` 为 `0`（它绘制在图表底部，几乎不可见）。这是好的，表明大部分涉及变异调用的序列都能清晰地映射到基因组的这个区域。对于
    `centro.vcf.gz` 文件，`MQ0` 的质量较差。此外，还有一些区域，基因型调用器无法找到任何变异（因此图表不完整）。
- en: Let’s compare heterozygosity with **DP**, the sample-level annotation. Here,
    we will plot the fraction of heterozygosity calls as a function of the **sample
    read depth** (**DP**) for every SNP. First, we will explain the result and then
    the code that generates it.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将杂合性与**DP**（样本级注释）进行比较。在这里，我们将绘制每个SNP的杂合性调用比例与**样本读取深度**（**DP**）的关系图。首先，我们将解释结果，然后是生成它的代码。
- en: 'The following screenshot shows the fraction of calls that are heterozygous
    at a certain depth:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 下一张截图显示了在某一深度下杂合体调用的比例：
- en: '![Figure 3.7 – The continuous line represents the fraction of heterozygosite
    calls computed at a certain depth; in orange is the centromeric area; in blue
    is the “standard” area; the dashed lines represent the number of sample calls
    per depth; both areas come from chromosome 3L for circa 100 Ugandan mosquitoes
    from the Anopheles 1,000 Genomes Project ](img/B17942_03_007.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.7 – 连续线表示在某一深度计算的杂合体调用比例；橙色区域为着丝粒区域；蓝色区域为“标准”区域；虚线表示每个深度的样本调用数；这两个区域来自于安哥拉疟蚊1000基因组计划中大约100只乌干达蚊子的3L号染色体](img/B17942_03_007.jpg)'
- en: Figure 3.7 – The continuous line represents the fraction of heterozygosite calls
    computed at a certain depth; in orange is the centromeric area; in blue is the
    “standard” area; the dashed lines represent the number of sample calls per depth;
    both areas come from chromosome 3L for circa 100 Ugandan mosquitoes from the Anopheles
    1,000 Genomes Project
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7 – 连续线表示在某一深度计算的杂合体调用比例；橙色区域为着丝粒区域；蓝色区域为“标准”区域；虚线表示每个深度的样本调用数；这两个区域来自于安哥拉疟蚊1000基因组计划中大约100只乌干达蚊子的3L号染色体。
- en: In the preceding screenshot, there are two considerations to take into account.
    At a very low depth, the fraction of heterozygote calls is biased—in this case,
    lower. This makes sense, as the number of reads per position does not allow you
    to make a correct estimate of the presence of both alleles in a sample. Therefore,
    you should not trust calls at very low depth.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，有两个因素需要考虑。在非常低的深度下，杂合体调用的比例是偏倚的——在这种情况下，它较低。这是有道理的，因为每个位置的读取次数不足以准确估计样本中两种等位基因的存在。因此，您不应该相信在非常低深度下的调用。
- en: As expected, the number of calls in the centromere is way lower than outside
    it. The distribution of SNPs outside the centromere follows a common pattern that
    you can expect in many datasets.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，着丝粒区域的调用次数明显低于其外部区域。着丝粒外的SNP分布遵循许多数据集中常见的模式。
- en: 'The code for this is presented here:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是这部分代码的展示：
- en: '[PRE39]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Start by looking for the `for` loop. Again, we use functional programming; the
    `get_sample_relation` function will traverse all SNP records and apply two functional
    parameters. The first parameter determines heterozygosity, whereas the second
    parameter acquires the sample `DP` (remember that there is also a variant of `DP`).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，寻找`for`循环。我们再次使用函数式编程；`get_sample_relation`函数将遍历所有SNP记录并应用两个函数参数。第一个参数确定杂合性，第二个参数获取样本的`DP`（记住，`DP`也有变种）。
- en: 'Now, since the code is as complex as it is, I opted for a naive data structure
    to be returned by `get_sample_relation`: a dictionary where the key is a pair
    of results (in this case, heterozygosity and `DP`) and the sum of SNPs that share
    both values. There are more elegant data structures with different trade-offs.
    For this, there are SciPy sparse matrices, pandas DataFrames, or you may want
    to consider PyTables. The fundamental point here is to have a framework that is
    general enough to compute relationships between a couple of sample annotations.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，由于代码本身相当复杂，我选择使用一个朴素的数据结构来返回`get_sample_relation`：一个字典，键是结果对（在此案例中为杂合性和`DP`），值是共享这两个值的SNP总数。还有更优雅的数据结构，具有不同的权衡。比如，您可以使用SciPy稀疏矩阵、pandas
    DataFrame，或者考虑使用PyTables。这里的关键是要有一个足够通用的框架来计算样本注释之间的关系。
- en: Also, be careful with the dimension space of several annotations. For example,
    if your annotation is of the float type, you might have to round it (if not, the
    size of your data structure might become too big).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，注意多个注释的维度空间。例如，如果您的注释是浮动类型，您可能需要对其进行四舍五入（如果不进行处理，数据结构的大小可能会变得过大）。
- en: 'Now, let’s take a look at the plotting code. Let’s perform this in two parts.
    Here is part one:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下绘图代码。我们分两部分来进行。以下是第一部分：
- en: '[PRE40]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This function will take a data structure, as generated by `get_sample_relation`,
    expecting that the first parameter of the key tuple is the heterozygosity state
    (`0`=homozygote, `1`=heterozygote) and the second parameter is `DP`. With this,
    it will generate two lines: one with the fraction of samples (which are heterozygotes
    at a certain depth) and the other with the SNP count.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数将接受由`get_sample_relation`生成的数据结构，假定关键元组的第一个参数是杂合状态（`0`=纯合子，`1`=杂合子），第二个参数是`DP`。这样，它将生成两条数据：一条表示在某一深度下为杂合子的样本比例，另一条表示
    SNP 数量。
- en: 'Now, let’s call this function:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们调用这个函数：
- en: '[PRE41]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Here, we will use two axes. On the left-hand side, we will have the fraction
    of heterozygous SNPs. On the right-hand side, we will have the number of SNPs.
    We then call `plot_hz_rel` for both data files. The rest is standard `matplotlib`
    code.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用两个坐标轴。左边是杂合 SNP 的比例，右边是 SNP 的数量。然后，我们为两个数据文件调用`plot_hz_rel`。其余部分是标准的`matplotlib`代码。
- en: 'Finally, let’s compare the `DP` variant with a categorical variant-level annotation
    (`EFF`). `EFF` is provided by SnpEff and tells us (among many other things) the
    type of SNP (for example, intergenic, intronic, coding synonymous, and coding
    nonsynonymous). The Anopheles dataset provides this useful annotation. Let’s start
    by extracting variant-level annotations and the functional programming style:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们将`DP`变异与类别变异级注释（`EFF`）进行比较。`EFF`由 SnpEff 提供，告诉我们（以及其他许多信息）SNP 类型（例如，基因间、内含子、同义编码和非同义编码）。疟蚊数据集提供了这个有用的注释。让我们从提取变异级注释和功能编程样式开始：
- en: '[PRE42]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The programming style here is similar to `get_sample_relation`, but we will
    not delve into any samples. Now, we define the type of effect that we’ll work
    with and convert its effect into an integer (as this will allow us to use it as
    an index—for example, matrices). Now, think about coding a categorical variable:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的编程风格类似于`get_sample_relation`，但我们不会深入讨论任何样本。现在，我们定义我们将处理的效应类型，并将其效应转换为整数（因为这将允许我们将其作为索引使用——例如，矩阵）。现在，考虑为类别变量编写代码：
- en: '[PRE43]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We will now traverse the file; the style should be clear to you now:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将遍历文件；样式现在应该对你清晰可见：
- en: '[PRE44]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Finally, we plot the distribution of `DP` using the SNP effect:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用 SNP 效应绘制`DP`的分布：
- en: '[PRE45]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Here, we just print a `boxplot` for the non-centromeric file, as shown in the
    following diagram. The results are as expected: SNPs in coding areas will probably
    have more depth because they are in more complex regions that are easier to call
    than intergenic SNPs:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们仅为非着丝粒文件打印一个`箱线图`，如下面的图所示。结果符合预期：编码区域中的 SNP 可能会有更高的深度，因为它们位于更复杂的区域，这些区域比基因间的
    SNP 更容易被调用：
- en: '![Figure 3.8 – Boxplot for the distribution of variant read depth across different
    SNP effects ](img/B17942_03_008.jpg)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.8 – 不同 SNP 效应下变异读取深度的箱线图](img/B17942_03_008.jpg)'
- en: Figure 3.8 – Boxplot for the distribution of variant read depth across different
    SNP effects
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8 – 不同 SNP 效应下变异读取深度的箱线图
- en: There’s more...
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: The whole issue of filtering SNPs and other genome features will need a book
    of its own. This approach will depend on the type of sequencing data that you
    have, the number of samples, and potential extra information (for example, a pedigree
    among samples).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 关于过滤 SNP 和其他基因组特征的问题，需要一本书来详细讲解。这个方法将取决于你所拥有的测序数据类型、样本数量以及潜在的附加信息（例如，样本之间的家系关系）。
- en: This recipe is very complex as it is, but parts of it are profoundly naive (there
    is a limit regarding the complexity that I can force on you in a simple recipe).
    For example, the window code does not support overlapping windows. Also, data
    structures are simplistic. However, I hope that they give you an idea of the general
    strategy to process genomic, high-throughput sequencing data. You can read more
    in [*Chapter 4*](B17942_04.xhtml#_idTextAnchor104), *Advanced NGS Processing*.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法本身非常复杂，但其中一些部分非常简单（在一个简单的配方中，我无法强行加上过于复杂的内容）。例如，窗口代码不支持重叠窗口。并且，数据结构相对简单。然而，我希望它们能给你提供一种处理基因组高通量测序数据的整体策略。你可以在[*第
    4 章*](B17942_04.xhtml#_idTextAnchor104)，*高级 NGS 处理*中阅读更多内容。
- en: See also
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'More information can be found via these links:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息可以通过以下链接找到：
- en: There are many filtering rules, but I would like to draw your attention to the
    need for reasonably good coverage (clearly above 10x). Refer to *Meynert et al.*,
    *Variant detection sensitivity and biases in whole genome and exome sequencing*,
    at [http://www.biomedcentral.com/1471-2105/15/247/](http://www.biomedcentral.com/1471-2105/15/247/).
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有许多过滤规则，但我想特别提醒你注意需要有足够好的覆盖度（显然需要超过10x）。请参考*Meynert et al.*的论文《全基因组和外显子组测序中的变异检测灵敏度与偏差》，网址：[http://www.biomedcentral.com/1471-2105/15/247/](http://www.biomedcentral.com/1471-2105/15/247/)。
- en: '`bcbio-nextgen` is a Python-based pipeline for high-throughput sequencing analysis
    and is worth checking out ([https://bcbio-nextgen.readthedocs.org](https://bcbio-nextgen.readthedocs.org)).'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bcbio-nextgen`是一个基于Python的高通量测序分析管道，值得一试 ([https://bcbio-nextgen.readthedocs.org](https://bcbio-nextgen.readthedocs.org))。'
- en: Processing NGS data with HTSeq
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用HTSeq处理NGS数据
- en: HTSeq ([https://htseq.readthedocs.io](https://htseq.readthedocs.io)) is an alternative
    library that’s used for processing NGS data. Most of the functionality made available
    by HTSeq is actually available in other libraries covered in this book, but you
    should be aware of it as an alternative way of processing NGS data. HTSeq supports,
    among others, FASTA, FASTQ, SAM (via `pysam`), VCF, **General Feature Format**
    (**GFF**), and **Browser Extensible Data** (**BED**) file formats. It also includes
    a set of abstractions for processing (mapped) genomic data, encompassing concepts
    such as genomic positions and intervals or alignments. A complete examination
    of the features of this library is beyond our scope, so we will concentrate on
    a small subset of features. We will take this opportunity to also introduce the
    BED file format.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: HTSeq（[https://htseq.readthedocs.io](https://htseq.readthedocs.io)）是一个用于处理NGS数据的替代库。HTSeq提供的大部分功能实际上在本书中覆盖的其他库中也有，但是你应该知道它作为一种替代方式来处理NGS数据。HTSeq支持包括FASTA、FASTQ、SAM（通过`pysam`）、VCF、**通用特征格式**（**GFF**）和**浏览器可扩展数据**（**BED**）文件格式等。它还包括一组用于处理（映射）基因组数据的抽象概念，涵盖了如基因组位置、区间或比对等概念。由于本书无法详细探讨该库的所有功能，我们将专注于其中的一小部分功能，并借此机会介绍BED文件格式。
- en: The BED format allows for the specification of features for annotations’ tracks.
    It has many uses, but it’s common to load BED files into genome browsers to visualize
    features. Each line includes information about at least the position (chromosome,
    start, and end) and also optional fields such as name or strand. Full details
    about the format can be found at [https://genome.ucsc.edu/FAQ/FAQformat.xhtml#format1](https://genome.ucsc.edu/FAQ/FAQformat.xhtml#format1).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: BED格式允许为注释轨道指定特征。它有许多用途，但常见的用途是将BED文件加载到基因组浏览器中以可视化特征。每行包含关于至少位置（染色体、起始和结束）的信息，也包括可选字段，如名称或链。关于该格式的详细信息可以在[https://genome.ucsc.edu/FAQ/FAQformat.xhtml#format1](https://genome.ucsc.edu/FAQ/FAQformat.xhtml#format1)找到。
- en: Getting ready
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Our simple example will use data from the region where the LCT gene is located
    in the human genome. The LCT gene codifies lactase, an enzyme involved in the
    digestion of lactose.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的简单示例将使用来自人类基因组中LCT基因所在区域的数据。LCT基因编码乳糖酶，这是一种参与乳糖消化的酶。
- en: We will take this information from Ensembl. Go to [http://uswest.ensembl.org/Homo_sapiens/Gene/Summary?db=core;g=ENSG00000115850](http://uswest.ensembl.org/Homo_sapiens/Gene/Summary?db=core;g=ENSG00000115850)
    and choose `LCT.bed` is available in the `Chapter03` directory.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从Ensembl获取这些信息。请访问[http://uswest.ensembl.org/Homo_sapiens/Gene/Summary?db=core;g=ENSG00000115850](http://uswest.ensembl.org/Homo_sapiens/Gene/Summary?db=core;g=ENSG00000115850)，并选择`LCT.bed`文件，该文件位于`Chapter03`目录中。
- en: The notebook for this code is called `Chapter03/Processing_BED_with_HTSeq.py`.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的笔记本文件名为`Chapter03/Processing_BED_with_HTSeq.py`。
- en: 'Take a look at the file before we start. An example of a few lines of this
    file is provided here:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，先查看一下文件。这里提供了该文件几行内容的示例：
- en: '[PRE46]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The fourth column is the feature name. This will vary widely from file to file,
    and you will have to check it each and every time. However, in our case, it seems
    apparent that we have Ensembl exons (`ENSE`...), GenBank records (`NM`_...), and
    coding region information (`CCDS`) from the **Consensus Coding Sequence** (**CCDS**)
    database ([https://www.ncbi.nlm.nih.gov/CCDS/CcdsBrowse.cgi](https://www.ncbi.nlm.nih.gov/CCDS/CcdsBrowse.cgi)).
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 第四列是特征名称。这个名称在不同的文件中会有很大的不同，你需要每次都检查它。然而，在我们的案例中，似乎显而易见的是我们有Ensembl外显子（`ENSE`...）、GenBank记录（`NM`_...）以及来自**共识编码序列**（**CCDS**）数据库的编码区信息（[https://www.ncbi.nlm.nih.gov/CCDS/CcdsBrowse.cgi](https://www.ncbi.nlm.nih.gov/CCDS/CcdsBrowse.cgi)）。
- en: 'You will need to install HTSeq:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要安装HTSeq：
- en: '[PRE47]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Now, we can begin.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以开始了。
- en: How to do it...
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'Take a look at the following steps:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下步骤：
- en: 'We will start by setting up a reader for our file. Remember that this file
    has already been supplied to you, and should be in your current work directory:'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先为文件设置一个读取器。记住，这个文件已经提供给你，并且应该在你的当前工作目录中：
- en: '[PRE48]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We are now going to extract all the types of features via their name:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将通过它们的名称提取所有类型的特征：
- en: '[PRE49]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Remember that this code is specific to our example. You will have to adapt it
    to your case.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，这段代码是特定于我们的例子。你需要根据你的情况调整它。
- en: Tip
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: You will find that the preceding code uses a **regular expression** (**regex**).
    Be careful with regexes, as they tend to generate read-only code that is difficult
    to maintain. You might have better alternatives. In any case, regexes exist, and
    you will find them from time to time.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现前面的代码使用了 **正则表达式** (**regex**) 。使用正则表达式时要小心，因为它们往往生成只读代码，难以维护。你可能会找到更好的替代方案。不管怎样，正则表达式是存在的，你会时不时遇到它们。
- en: 'The output for our case looks like this:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，输出结果如下所示：
- en: '[PRE50]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We stored the last record so that we can inspect it:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们保存了最后一条记录，以便检查它：
- en: '[PRE51]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'There are many fields available, most notably `name` and `interval`. For the
    preceding code, the output looks like this:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多可用的字段，最显著的是 `name` 和 `interval`。对于前面的代码，输出如下所示：
- en: '[PRE52]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Let’s dig deeper into the interval:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们深入研究这个区间：
- en: '[PRE53]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output looks like this:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE54]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Note the genomic position (chromosome, start, and end). The most complex issue
    is how to deal with the strand. If the feature is coded in the negative strand,
    you have to be careful with processing. HTSeq offers the `start_d` and `end_d`
    fields to help you with this (that is, they will be reversed with regard to the
    start and end if the strand is negative).
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 注意基因组位置（染色体、起始位置和结束位置）。最复杂的问题是如何处理链。如果特征是编码在负链上，你需要小心处理。HTSeq 提供了 `start_d`
    和 `end_d` 字段来帮助你处理这个问题（也就是说，如果链是负链，起始和结束位置会被反转）。
- en: 'Finally, let’s extract some statistics from our coding regions (CCDS records).
    We will use CCDS since it’s probably better than the curated database here:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们从编码区域（CCDS 记录）中提取一些统计信息。我们将使用 CCDS，因为它可能比这里的策划数据库更好：
- en: '[PRE55]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output should be self-explanatory:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该是自我解释的：
- en: '[PRE56]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: There’s more...
  id: totrans-358
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The BED format can be a bit more complex than this. Furthermore, the preceding
    code is based on quite specific premises with regard to the contents of our file.
    However, this example should be enough to get you started. Even at its worst,
    the BED format is not very complicated.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: BED 格式可能比这更复杂。此外，前面的代码是基于我们的文件内容的特定前提。不过，这个例子应该足够让你入门。即使在最糟糕的情况下，BED 格式也不是特别复杂。
- en: HTSeq has much more functionality than this, but this recipe is mostly provided
    as a starting point for the whole package. HTSeq has functionality that can be
    used as an alternative to most of the recipes that we’ve covered thus far.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: HTSeq 的功能远不止这些，但这个例子主要作为整个包的起点。HTSeq 具有可以替代我们到目前为止介绍的大部分配方的功能。
