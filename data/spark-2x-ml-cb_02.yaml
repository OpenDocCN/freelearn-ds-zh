- en: Just Enough Linear Algebra for Machine Learning with Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习与Spark的线性代数基础
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Package imports and initial setup for vectors and matrices
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量和矩阵的包导入和初始设置
- en: Creating DenseVector and setup with Spark 2.0
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建DenseVector并在Spark 2.0中设置
- en: Creating SparseVector and setup with Spark 2.0
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建SparseVector并在Spark 2.0中设置
- en: Creating DenseMatrix and setup with Spark 2.0
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建DenseMatrix并在Spark 2.0中设置
- en: Using sparse local matrices with Spark 2.0
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark 2.0的稀疏本地矩阵
- en: Performing vector arithmetic using Spark 2.0
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark 2.0进行向量运算
- en: Performing matrix arithmetic with Spark 2.0
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark 2.0进行矩阵运算
- en: Distributed matrices in Spark 2.0 ML library
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark 2.0 ML库中的分布式矩阵
- en: Exploring RowMatrix in Spark 2.0
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索RowMatrix
- en: Exploring distributed IndexedRowMatrix in Spark 2.0
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索分布式IndexedRowMatrix
- en: Exploring distributed CoordinateMatrix in Spark 2.0
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索分布式CoordinateMatrix
- en: Exploring distributed BlockMatrix in Spark 2.0
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索分布式BlockMatrix
- en: Introduction
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Linear algebra is the cornerstone of **machine learning** (**ML**) and **mathematical**
    **programming** (**MP**). When dealing with Spark's machine library, one must
    understand that the Vector/Matrix structures provided by Scala (imported by default)
    are different from the Spark ML, MLlib Vector, Matrix facilities provided by Spark.
    The latter, powered by RDDs, is the desired data structure if you are going to
    use Spark (that is, parallelism) out of the box for large-scale matrix/vector
    computation (for example, SVD implementation alternatives with more numerical
    accuracy, desired in some cases for derivatives pricing and risk analytics). The
    Scala Vector/Matrix libraries provide a rich set of linear algebra operations
    such as dot product, additions, and so on, that still have their own place in
    an ML pipeline. In summary, the key difference between using Scala Breeze and
    Spark or Spark ML is that the Spark facility is backed by RDDs which allows for
    simultaneous distributed, concurrent computing, and resiliency without requiring
    any additional concurrency module or extra effort (for example, Akka + Breeze).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数是**机器学习**（**ML**）和**数学** **编程**（**MP**）的基石。在处理Spark的机器库时，必须了解Scala提供的Vector/Matrix结构（默认导入）与Spark提供的ML、MLlib
    Vector、Matrix设施有所不同。后者由RDD支持，是所需的数据结构，如果要使用Spark（即并行性）进行大规模矩阵/向量计算（例如，某些情况下用于衍生定价和风险分析的SVD实现替代方案，具有更高的数值精度）。Scala
    Vector/Matrix库提供了丰富的线性代数操作，如点积、加法等，在ML管道中仍然有其自己的位置。总之，使用Scala Breeze和Spark或Spark
    ML之间的关键区别在于，Spark设施由RDD支持，允许同时分布式、并发计算和容错，而无需任何额外的并发模块或额外的工作（例如，Akka + Breeze）。
- en: Almost all machine learning algorithms use some form of classification or regression
    mechanism (not necessarily linear) to train a model and then proceed to minimize
    errors by comparing the training output to the actual output. For example, any
    implementation of a recommendation system in Spark will heavily rely on matrix
    decomposition, factorization, approximation, or **Single Value Decomposition**
    (**SVD**). Another machine learning area of interest dealing with dimensionality
    reduction for big datasets is **Principal Component Analysis** (**PCA**), which
    relies heavily on linear algebra, factorization, and matrix manipulation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有的机器学习算法都使用某种形式的分类或回归机制（不一定是线性的）来训练模型，然后通过比较训练输出和实际输出来最小化错误。例如，在Spark中任何推荐系统的实现都会严重依赖于矩阵分解、因子分解、近似或**单值分解**（**SVD**）。另一个与处理大型数据集的维度约简有关的机器学习领域是**主成分分析**（**PCA**），它严重依赖于线性代数、因子分解和矩阵操作。
- en: When we examined the Spark ML and MLlib algorithms' source code for the first
    time in Spark 1.x.x, we quickly noticed that Vectors and Matrices use RDDs as
    the base for many prominent algorithms.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们第一次在Spark 1.x.x中检查Spark ML和MLlib算法的源代码时，我们很快注意到向量和矩阵使用RDD作为许多重要算法的基础。
- en: 'When we revisited the source code for Spark 2.0 and machine learning libraries,
    we noticed some interesting changes that need to be considered going forward.
    Here is an example of such changes from Spark 1.6.2 to Spark 2.0.0 that impacted
    some of our linear algebra code with Spark:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们重新审视Spark 2.0和机器学习库的源代码时，我们注意到一些有趣的变化需要在以后考虑。以下是从Spark 1.6.2到Spark 2.0.0的一些变化的示例，这些变化影响了我们在Spark中的一些线性代数代码：
- en: 'In the previous version (Spark 1.6.x), you can convert the `DenseVector` or
    `SparseVector` (refer to [https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/Vectors.html](https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/Vectors.html))
    directly by using the `toBreeze()` function, as shown in the following code base:'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在之前的版本（Spark 1.6.x）中，您可以通过使用`toBreeze()`函数直接将`DenseVector`或`SparseVector`（参见[https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/Vectors.html](https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/Vectors.html)）转换为`BreezeVector`实例，如下面的代码所示：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In Spark 2.0, the `toBreeze()` function has not only been changed to `asBreeze()`,
    but it has also been demoted to a private function
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中，`toBreeze()`函数不仅已更改为`asBreeze()`，而且还已降级为私有函数
- en: 'To remedy this, use one of the following code snippets to convert the preceding
    vector to the commonly used `BreezeVector` instance:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了解决这个问题，可以使用以下代码片段之一将前面的向量转换为常用的`BreezeVector`实例：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Scala is a concise language in which both object-oriented and functional programming
    paradigms can coexist without conflict. While in the machine learning paradigm,
    functional programming is preferred, there is nothing wrong with using the object-oriented
    approach for initial data collection and presentation at a later stage.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Scala是一种简洁的语言，对象导向和函数式编程范式可以在其中共存而不冲突。虽然在机器学习范式中，函数式编程更受青睐，但在初始数据收集和稍后的展示阶段使用面向对象的方法也没有问题。
- en: In terms of large-scale distributed matrices, our experience shows that when
    approaching large matrix sets 10⁹ to 10^(13) to 10^(27), and so on, you have to
    take a deeper look at the resulting network operation and shuffling that are inherent
    in a distributed operation. Based on our experience, the combination of local
    and distributed matrix/vector operations (for example, dot product, multiplication,
    and so on) work best when you operate at scale.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在大规模分布式矩阵方面，我们的经验表明，当处理大矩阵集10⁹至10^(13)至10^(27)等时，您必须更深入地研究分布式操作中固有的网络操作和洗牌。根据我们的经验，当您以规模运行时，本地和分布式矩阵/向量操作的组合（例如，点积，乘法等）在操作时效果最佳。
- en: 'The following figure depicts the categorization of available Spark vectors
    and matrices:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片描述了可用Spark向量和矩阵的分类：
- en: '![](img/00044.jpeg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00044.jpeg)'
- en: Package imports and initial setup for vectors and matrices
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 包导入和向量矩阵的初始设置
- en: Before we can program in Spark or use vector and matrix artifacts, we need to
    first import the right packages and then set up `SparkSession` so we can gain
    access to the cluster handle.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以在Spark中编程或使用向量和矩阵工件之前，我们首先需要导入正确的包，然后设置`SparkSession`，以便我们可以访问集群句柄。
- en: In this short recipe, we highlight a comprehensive number of packages that can
    cover most of the linear algebra operations in Spark. The individual recipes that
    follow will include the exact subset required for the specific program.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简短的配方中，我们突出了一系列可以涵盖大多数Spark线性代数操作的包。接下来的各个配方将包括特定程序所需的确切子集。
- en: How to do it...
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Set up the package location where the program will reside:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置程序将驻留的包位置：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入用于向量和矩阵操作的必要包：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Import the packages for setting up the logging level for `log4j`. This step
    is optional, but we highly recommend it (change the level appropriately as you
    move through the development cycle):'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入设置`log4j`的包。这一步是可选的，但我们强烈建议这样做（随着开发周期的推移，适当更改级别）：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Set up the logging level to warning and error to cut down on output. See the
    previous step for the package requirement:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将日志级别设置为警告和错误，以减少输出。有关包要求，请参阅上一步：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Set up the Spark context and application parameters so Spark can run:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark上下文和应用程序参数，以便Spark可以运行：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There's more...
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Prior to Spark 2.0, the SparkContext and SQLContext had to be initialized separately.
    Refer to the following code snippet if you plan to run the code in previous versions
    of Spark.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark 2.0之前，SparkContext和SQLContext必须分别初始化。如果您计划在Spark的早期版本中运行代码，请参考以下代码片段。
- en: 'Set up the application parameters so Spark can run (using Spark 1.5.2 or Spark
    1.6.1):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 设置应用程序参数，以便Spark可以运行（使用Spark 1.5.2或Spark 1.6.1）：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: See also
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: SparkSession is the new entry point into the cluster in Spark 2.x.x and above.
    SparkSession unifies access entry to the cluster and all things data. It unifies
    access to SparkContext, SQLContext, or HiveContext, while making it easier to
    work with the DataFrame and Dataset APIs. We will revisit the SparkSession with
    a dedicated recipe in [Chapter 4](part0200.html#5UNGG0-4d291c9fed174a6992fd24938c2f9c77),
    *Common Recipes for Implementing a Robust Machine Learning System*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: SparkSession是Spark 2.x.x及以上版本中集群的新入口点。SparkSession统一了对集群和所有数据的访问。它统一了对SparkContext、SQLContext或HiveContext的访问，同时使得使用DataFrame和Dataset
    API更加容易。我们将在[第4章](part0200.html#5UNGG0-4d291c9fed174a6992fd24938c2f9c77)中专门的配方中重新讨论SparkSession，*实现强大的机器学习系统的常见配方*。
- en: 'See the following figure for reference:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 参考以下图片：
- en: '![](img/00045.jpeg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00045.jpeg)'
- en: The documentation for method calls can be seen at [https://spark.apache.org/docs/2.0.0/api/scala/#org.apache.spark.sql.SparkSession](https://spark.apache.org/docs/2.0.0/api/scala/#org.apache.spark.sql.SparkSession).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 方法调用的文档可以在[https://spark.apache.org/docs/2.0.0/api/scala/#org.apache.spark.sql.SparkSession](https://spark.apache.org/docs/2.0.0/api/scala/#org.apache.spark.sql.SparkSession)中查看。
- en: Creating DenseVector and setup with Spark 2.0
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建DenseVector并在Spark 2.0中设置
- en: In this recipe, we explore `DenseVectors` using the Spark 2.0 machine library.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用Spark 2.0机器库来探索`DenseVectors`。
- en: Spark provides two distinct types of vector facilities (dense and sparse) for
    storing and manipulating feature vectors that are going to be used in machine
    learning or optimization algorithms.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供了两种不同类型的向量设施（密集和稀疏），用于存储和操作将用于机器学习或优化算法中的特征向量。
- en: How to do it...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: In this section, we examine `DenseVector` examples that you would most likely
    use for implementing/augmenting existing machine learning programs. These examples
    also help to better understand Spark ML or MLlib source code and the underlying
    implementation (for example, Single Value Decomposition).
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本节中，我们将研究使用Spark 2.0机器库的`DenseVectors`示例，这些示例最有可能用于实现/增强现有的机器学习程序。这些示例还有助于更好地理解Spark
    ML或MLlib源代码和底层实现（例如，单值分解）。
- en: 'Here we look at creating an ML vector feature (with independent variables)
    from arrays, which is a common use case. In this case, we have three almost fully
    populated Scala arrays corresponding to customer and product feature sets. We
    convert these arrays to the corresponding `DenseVectors` in Scala:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们将从数组创建ML向量特征（具有独立变量），这是一个常见用例。在这种情况下，我们有三个几乎完全填充的Scala数组，对应于客户和产品特征集。我们将这些数组转换为Scala中相应的`DenseVectors`：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Set the variables to create the vectors from the array. Convert from the array
    to the `DenseVector`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 设置变量以从数组创建向量。从数组转换为`DenseVector`：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The next step is to create a `DenseVector` and to assign values via initialization.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是创建`DenseVector`并通过初始化赋值。
- en: 'This is the most cited case and is often used in class constructors that deal
    with batch input:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最常引用的情况，通常用于处理批量输入的类构造函数：
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following is another example to show on-the-fly conversion from a string
    to a double during the initialization. Here we start with a string and invoke
    `toDouble` inline:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下是另一个示例，展示了在初始化期间从字符串转换为双精度的即时转换。在这里，我们从一个字符串开始，并在内联中调用`toDouble`：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: How it works...
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The signature for this method constructor is:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该方法构造函数的签名为：
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The method inherits from the following which makes its concrete methods available
    to all routines:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该方法继承自以下内容，使其具体方法对所有例程可用：
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There are several method calls that are of interest:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有几个感兴趣的方法调用：
- en: 'Make a deep copy of the vector:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制作向量的深拷贝：
- en: '[PRE15]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Convert to the `SparseVector`. You will do this if your vector is long and
    the density decreases after a number of operations (for example, zero out non-contributing
    members):'
  id: totrans-76
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换为`SparseVector`。如果您的向量很长，并且在进行了一定数量的操作后密度减小（例如，将不贡献的成员归零），则会执行此操作：
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Find the number of non-zero elements. This is useful so you can convert on-the-fly
    to the SparseVector if the density ID is low:'
  id: totrans-78
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找非零元素的数量。如果密度ID较低，则这很有用，因此您可以即时转换为SparseVector：
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Convert the vector to the array. This is often necessary when dealing with
    distributed operations that require close interactions with RDDs or proprietary
    algorithms that use Spark ML as a subsystem:'
  id: totrans-80
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将向量转换为数组。在处理需要与RDD或使用Spark ML作为子系统的专有算法进行紧密交互的分布式操作时，这通常是必要的：
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: There's more...
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: One must be careful not to mix vector facilities provided by the `Breeze` library
    with Spark ML vectors. To work with ML library algorithms, you are required to
    use its native data structures, but you can always convert from ML vectors to
    `Breeze`, do all your math operations, and then convert to Spark's desired data
    structure when using the ML library algorithms (for example, ALS or SVD).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 必须小心，不要将`Breeze`库提供的向量功能与Spark ML向量混合使用。要使用ML库算法，您需要使用其本机数据结构，但您始终可以从ML向量转换为`Breeze`，进行所有数学运算，然后在使用ML库算法（例如ALS或SVD）时转换为Spark所需的数据结构。
- en: We need the vector and matrix import statements so we can work with the ML library
    itself, otherwise the Scala vector and matrix will be used by default. This is
    the source of much confusion when the programs fail to scale on cluster.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要向量和矩阵导入语句，这样我们才能使用ML库本身，否则Scala向量和矩阵将默认使用。当程序无法在集群上扩展时，这是导致许多混乱的根源。
- en: 'The following figure depicts a pictorial view which should help clarify the
    subject:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示了一个图解视图，这应该有助于澄清主题：
- en: '![](img/00046.jpeg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00046.jpeg)'
- en: See also
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#constructor_summary)
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#constructor_summary)找到
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#method_summary)
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#method_summary)找到
- en: Creating SparseVector and setup with Spark
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建SparseVector并使用Spark进行设置
- en: In this recipe, we examine several types of `SparseVector` creation. As the
    length of the vector increases (millions) and the density remains low (few non-zero
    members), then sparse representation becomes more and more advantageous over the
    `DenseVector`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们检查了几种`SparseVector`的创建类型。当向量的长度增加（百万级）且密度保持较低（非零成员较少）时，稀疏表示变得越来越有利于`DenseVector`。
- en: How to do it...
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入向量和矩阵操作所需的必要包：
- en: '[PRE19]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Set up the Spark context and application parameters so Spark can run. See the
    first recipe in this chapter for more details and variations:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark上下文和应用程序参数，以便Spark可以运行。有关更多详细信息和变体，请参见本章的第一个示例：
- en: '[PRE20]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here we look at creating a ML SparseVector that corresponds to its equivalent
    DenseVector. The call consists of three parameters: Size of the vector, indexes
    to non-zero data, and finally, the data itself.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们看一下创建与其等效的DenseVector相对应的ML SparseVector。调用包括三个参数：向量的大小，非零数据的索引，最后是数据本身。
- en: 'In the following example, we can compare the dense versus SparseVector creation.
    As you can see, the four elements that are non-zero (5, 3, 8, 9) correspond to
    locations (0, 2, 18, 19) while the number 20 indicates the total size:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们可以比较密集与SparseVector的创建。如您所见，四个非零元素（5、3、8、9）对应于位置（0、2、18、19），而数字20表示总大小：
- en: '[PRE21]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: To understand the data structure better, we compare the output and some of the
    important attributes that help us, especially with dynamic programming using vectors.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了更好地理解数据结构，我们比较输出和一些重要属性，这些属性对我们有所帮助，特别是在使用向量进行动态编程时。
- en: 'First we take a look at the printout for the DenseVector to see its representation:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们看一下DenseVector的打印输出，以查看其表示：
- en: '[PRE22]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE23]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, we take a look at the printout for the SparseVector to see its internal
    representation:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们看一下SparseVector的打印输出，以查看其内部表示：
- en: '[PRE24]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: If we compare and contrast the internal representation and the number of elements
    versus active and non-zero, you will see that the SparseVector only stores non-zero
    elements and indexes to reduce storage requirement.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们比较内部表示和元素数量与活跃和非零元素的对比，您会发现SparseVector只存储非零元素和索引以减少存储需求。
- en: 'The output is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE25]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can convert back and forth between sparse and DenseVectors as needed. The
    reason that you might want to do this is that external math and linear algebra
    do not conform to Spark''s internal representation. We made the variable type
    explicit to make the point, but you can eliminate that extra declaration in actual
    practice:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以根据需要在稀疏向量和密集向量之间进行转换。您可能想这样做的原因是，外部数学和线性代数不符合Spark的内部表示。我们明确指定了变量类型以阐明观点，但在实际操作中可以消除该额外声明：
- en: '[PRE26]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output is as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE27]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: How it works...
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'The signature for this method constructor is:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此方法构造函数的签名为：
- en: '[PRE28]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The method inherits from the following which makes its concrete methods available
    to all routines:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法继承自以下内容，使其具体方法对所有例程可用：
- en: '[PRE29]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'There are several method calls related to vectors that are of interest:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个与向量相关的方法调用是有趣的：
- en: 'Make a deep copy of the vector:'
  id: totrans-121
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对向量进行深拷贝：
- en: '[PRE30]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Convert to the `SparseVector`. You will do this if your vector is long and
    the density decreases after a number of operations (for example, zero out non-contributing
    members):'
  id: totrans-123
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换为`SparseVector`。如果您的向量很长，并且密度在多次操作后减少（例如，将不贡献的成员归零），则会执行此操作：
- en: '[PRE31]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Find the number of non-zero elements. This is useful so you can convert on-the-fly
    to the SparseVector if the density ID is low.
  id: totrans-125
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找非零元素的数量。这很有用，因此您可以在需要时将其转换为稀疏向量，如果密度ID较低。
- en: '[PRE32]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Convert the vector to an array. This is often necessary when dealing with distributed
    operations that require 1:1 interactions with RDDs or proprietary algorithms that
    use Spark ML as a subsystem:'
  id: totrans-127
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将向量转换为数组。在处理需要与RDD或使用Spark ML作为子系统的专有算法进行1:1交互的分布式操作时，通常需要这样做：
- en: '[PRE33]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: There's more...
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: One must remember that the dense and SparseVectors are local vectors and they
    must not be confused with the distributed facilities (for example, distributed
    matrices such as the RowMatrix class).
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 必须记住，密集向量和稀疏向量是本地向量，不得与分布式设施混淆（例如，分布式矩阵，如RowMatrix类）。
- en: 'The underlying math operations for the vectors on a local machine will be provided
    by two libraries:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本地机器上向量的基本数学运算将由两个库提供：
- en: '**Breeze**: [http://www.scalanlp.org/](http://www.scalanlp.org/)'
  id: totrans-132
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Breeze**：[http://www.scalanlp.org/](http://www.scalanlp.org/)'
- en: '**JBLAS**: [http://jblas.org/](http://jblas.org/)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**JBLAS**：[http://jblas.org/](http://jblas.org/)'
- en: 'There is another data structure related directly to Vectors called LabeledPoint,
    which we covered in [Chapter 4](part0200.html#5UNGG0-4d291c9fed174a6992fd24938c2f9c77), *Common
    Recipes for Implementing a Robust Machine Learning System*. In short, it is a
    data structure corresponding to `LIBSVM` and `LIBLINEAR` formats for storing ML
    data consisting of a feature vector plus a label (for example, independent and
    dependent variables in a regression):'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个与向量直接相关的数据结构，称为LabeledPoint，我们在[第4章](part0200.html#5UNGG0-4d291c9fed174a6992fd24938c2f9c77)中介绍过，*实现强大的机器学习系统的常见配方*。简而言之，它是一种数据结构，用于存储ML数据，包括特征向量和标签（例如，回归中的自变量和因变量）。
- en: '**LIBSVM**: [http://www.csie.ntu.edu.tw/~cjlin/libsvm/](http://www.csie.ntu.edu.tw/~cjlin/libsvm/)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LIBSVM**：[http://www.csie.ntu.edu.tw/~cjlin/libsvm/](http://www.csie.ntu.edu.tw/~cjlin/libsvm/)'
- en: '**LIBLINEAR**: [http://www.csie.ntu.edu.tw/~cjlin/liblinear/](http://www.csie.ntu.edu.tw/~cjlin/liblinear/)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LIBLINEAR**：[http://www.csie.ntu.edu.tw/~cjlin/liblinear/](http://www.csie.ntu.edu.tw/~cjlin/liblinear/)'
- en: See also
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#constructor_summary)
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#constructor_summary)找到
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#method_summary)
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#method_summary)找到
- en: Creating dense matrix and setup with Spark 2.0
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建密集矩阵并使用Spark 2.0进行设置
- en: In this recipe, we explore matrix creation examples that you most likely would
    need in your Scala programming and while reading the source code for many of the
    open source libraries for machine learning.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们探讨了您在Scala编程中可能需要的矩阵创建示例，以及在阅读许多用于机器学习的开源库的源代码时可能需要的示例。
- en: Spark provides two distinct types of local matrix facilities (dense and sparse)
    for storage and manipulation of data at a local level. For simplicity, one way
    to think of a matrix is to visualize it as columns of Vectors.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供了两种不同类型的本地矩阵设施（密集和稀疏），用于在本地级别存储和操作数据。简单来说，将矩阵视为向量的列是一种思考方式。
- en: Getting ready
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The key to remember here is that the recipe covers local matrices stored on
    one machine. We will use another recipe, *D**istributed matrices in the Spark2.0
    ML library*, covered in this chapter, for storing and manipulating distributed
    matrices.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里要记住的关键是，该配方涵盖了存储在一台机器上的本地矩阵。我们将在本章中介绍的另一个配方*Spark2.0 ML库中的分布式矩阵*，用于存储和操作分布式矩阵。
- en: How to do it...
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入向量和矩阵操作所需的包：
- en: '[PRE34]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Set up the Spark session and application parameters so Spark can run:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark会话和应用程序参数，以便Spark可以运行：
- en: '[PRE35]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Here we look at creating an ML vector feature from Scala arrays. Let us define
    a 2x2 dense matrix and instantiate it with an array:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们将从Scala数组创建ML向量特征。让我们定义一个2x2的密集矩阵，并用数组实例化它：
- en: '[PRE36]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output is as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE37]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Constructing a dense matrix and assigning values via initialization in a single
    step:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 通过初始化一步构建密集矩阵并分配值：
- en: 'Construct a dense local matrix directly by defining the array inline. This
    is an array of 3x3 and has nine members. You can think of it as three columns
    of three vectors (3x3):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通过内联定义数组直接构造密集本地矩阵。这是一个3x3的数组，有九个成员。您可以将其视为三列三个向量（3x3）：
- en: '[PRE38]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output is as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE39]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This is another example to show inline instantiation of a dense local matrix
    with vectors. This is a common case in which you collect vectors into a matrix
    (column order) and then perform an operation on the entire set. The most common
    case is to collect the vectors and then use a distributed matrix to do distributed
    parallel operation.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个示例，展示了使用向量内联实例化密集本地矩阵。这是一个常见情况，您将向量收集到矩阵（列顺序）中，然后对整个集合执行操作。最常见的情况是收集向量，然后使用分布式矩阵执行分布式并行操作。
- en: 'In Scala, we use the `++` operator with arrays to achieve concatenation:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在Scala中，我们使用`++`运算符与数组实现连接：
- en: '[PRE40]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output is as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE41]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: How it works...
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The signatures for this method constructor are (Column-major dense matrix):'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此方法构造函数的签名为（按列主要密集矩阵）：
- en: '[PRE42]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The method inherits from the following which makes their concrete methods available
    to all routines:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该方法继承自以下内容，使其具体方法对所有例程可用：
- en: interface class java.lang.Object
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接口类java.lang.Object
- en: java.io.Serializable
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: java.io.Serializable
- en: Matrix
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵
- en: 'There are several method calls that are of interest:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有几个感兴趣的方法调用：
- en: 'Generate the diagonal matrix from the supplied values in the vector:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从向量中提供的值生成对角矩阵：
- en: '[PRE43]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Create an identity matrix. An identity matrix is a matrix that has diagonals
    as 1 and any other element as 0:'
  id: totrans-175
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个单位矩阵。单位矩阵是对角线为1，其他元素为0的矩阵：
- en: '[PRE44]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Keep track of whether the matrix is transposed:'
  id: totrans-177
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟踪矩阵是否被转置：
- en: '[PRE45]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Create a matrix with a set of random numbers - drawn from uniform distribution:'
  id: totrans-179
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含一组随机数的矩阵-从均匀分布中抽取：
- en: '[PRE46]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Create a matrix with a set of random numbers - drawn from gaussian distribution:'
  id: totrans-181
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含一组随机数的矩阵-从高斯分布中抽取：
- en: '[PRE47]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Transpose the matrix:'
  id: totrans-183
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转置矩阵：
- en: '[PRE48]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Make a deep copy of the vector:'
  id: totrans-185
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对向量进行深拷贝：
- en: '[PRE49]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Convert to a SparseVector. You will do this if your vector is long and the
    density decreases after a number of operations (for example, zero out non-contributing
    members):'
  id: totrans-187
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换为稀疏向量。如果您的向量很长，并且密度在一系列操作后减少（例如，将不贡献的成员归零），则会执行此操作：
- en: '[PRE50]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Find the number of non-zero elements. This is useful so you can convert on-the-fly
    to a SparseVector if the density ID is low:'
  id: totrans-189
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找非零元素的数量。这很有用，因此您可以根据需要将其转换为稀疏向量，如果密度ID较低：
- en: '[PRE51]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Get all the values stored in Matrix:'
  id: totrans-191
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取矩阵中存储的所有值：
- en: '[PRE52]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: There's more...
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The most difficult part of working with matrices in Spark is to getting used
    to column order versus row order. It is key to remember that Spark ML uses underlying
    libraries that work better with column stored mechanisms. Here is an example to
    demonstrate:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark中处理矩阵最困难的部分是习惯于列顺序与行顺序。要记住的关键是，Spark ML使用的底层库更适合使用列存储机制。以下是一个示例：
- en: 'Given a matrix definition which defines a 2x2 matrix:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定定义2x2矩阵的矩阵：
- en: '[PRE53]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The matrix is actually stored as :'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 矩阵实际上存储为：
- en: '[PRE54]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: You move from left to right in the value set and then from column to column
    for the placement in the Matrix.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 您从值集合的左侧移动到右侧，然后从列到列进行矩阵的放置。
- en: 'As you can see, the assumption that the matrix is stored row wise is not in
    alignment with the Spark approach. The following order is not correct from Spark''s
    perspective:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如您所见，矩阵按行存储的假设与Spark方法不一致。从Spark的角度来看，以下顺序是不正确的：
- en: '[PRE55]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: See also
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#constructor_summary)
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#constructor_summary)找到
- en: Documentation For method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#method_summary)
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#method_summary)找到
- en: Using sparse local matrices with Spark 2.0
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark 2.0的稀疏本地矩阵
- en: In this recipe, we concentrate on SparseMatrix creation. In the previous recipe,
    we saw how a local dense matrix is declared and stored. A good number of machine
    learning problem domains can be represented as a set of features and labels within
    the matrix. In large-scale machine learning problems (for example, progression
    of a disease through large population centers, security fraud, political movement
    modeling, and so on), a good portion of the cells will be 0 or null (for example,
    the current number of people with a given disease versus the healthy population).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们专注于稀疏矩阵的创建。在上一个示例中，我们看到了如何声明和存储本地密集矩阵。许多机器学习问题领域可以表示为矩阵中的一组特征和标签。在大规模机器学习问题中（例如，疾病在大型人口中的传播，安全欺诈，政治运动建模等），许多单元格将为0或null（例如，患有某种疾病的人数与健康人口的当前数量）。
- en: To help with storage and efficient operation in real time, sparse local matrices
    specialize in storing the cells efficiently as a list plus an index, which leads
    to faster loading and real time operations.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助存储和实时操作的高效性，稀疏本地矩阵专门用于以列表加索引的方式高效存储单元格，从而实现更快的加载和实时操作。
- en: How to do it...
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入向量和矩阵操作所需的包：
- en: '[PRE56]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Set up the Spark context and application parameters so Spark can run - See
    the first recipe in this chapter for more details and variations:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark上下文和应用程序参数，以便Spark可以运行-有关更多详细信息和变体，请参见本章的第一个配方：
- en: '[PRE57]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The creation of a SparseMatrix is a little bit more complicated due to the way
    we store the sparse presentation as Compressed Column Storage (CCS), also referred
    to as the Harwell-Boeing SparseMatrix format. Please see, *How it works...* for
    a detailed explanation.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们将稀疏表示存储为压缩列存储（CCS），因此稀疏矩阵的创建要复杂一些，也称为Harwell-Boeing稀疏矩阵格式。 请参见*它是如何工作...*以获取详细说明。
- en: 'We declare and create a local 3x2 SparseMatrix with only three non-zero members:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声明并创建一个本地的3x2稀疏矩阵，只有三个非零成员：
- en: '[PRE58]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Let''s examine the output so we fully understand what is happening at a lower
    level. The three values will be placed at (0,0),(1,1),(2,1):'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查输出，以便我们充分理解在较低级别发生的情况。 这三个值将被放置在（0,0），（1,1），（2,1）：
- en: '[PRE59]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The output is as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE60]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'To clarify further, here is the code for the SparseMatrix that is illustrated
    on Spark''s documentation pages of the SparseMatrix (see following section titled
    *See also*). This is a 3x3 Matrix with six non-zero values. Note that the order
    of the declaration is: Matrix Size, Column Pointers, Row Indexes, and the Value
    as the last member:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步澄清，这是稀疏矩阵的代码，该矩阵在Spark的文档页面上有所说明（请参阅以下标题为*另请参阅*的部分）。 这是一个3x3矩阵，有六个非零值。 请注意，声明的顺序是：矩阵大小，列指针，行索引，值作为最后一个成员：
- en: '[PRE61]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The output is as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE62]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Column Pointers = [0,2,3,6]
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列指针= [0,2,3,6]
- en: Row Indexes = [0,2,1,0,1,2]
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行索引= [0,2,1,0,1,2]
- en: Non-Zero Values = [1.0,2.0,3.0,4.0,5.0,6.0]
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非零值= [1.0,2.0,3.0,4.0,5.0,6.0]
- en: How it works...
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In our experience, most of the difficulties with SparseMatrices come from a
    lack of understanding of the difference between **Compressed Row Storage** (**CRS**)
    and **Compressed Column Storage** (**CCS**). We highly recommend that the reader
    researches this topic in depth to clearly understand the differences.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的经验，大多数稀疏矩阵的困难来自于对**压缩行存储**（**CRS**）和**压缩列存储**（**CCS**）之间差异的理解不足。 我们强烈建议读者深入研究这个主题，以清楚地理解这些差异。
- en: 'In short, the CCS format is used by Spark for the transposed target matrix:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，Spark使用CCS格式来处理转置目标矩阵：
- en: 'There are two distinct signatures for this method call constructor:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此方法调用构造函数有两个不同的签名：
- en: '`SparseMatrix (int numRows, int numCols, int[] colPtrs, int[] rowIndices, double[]
    values)`'
  id: totrans-232
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SparseMatrix（int numRows，int numCols，int[] colPtrs，int[] rowIndices，double[]
    values）`'
- en: '`SparseMatrix(int numRows, int numCols, int[] colPtrs, int[] rowIndices, double[]
    values, boolean isTransposed)`'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稀疏矩阵（int numRows，int numCols，int[] colPtrs，int[] rowIndices，double[] values，boolean
    isTransposed）
- en: In option number two, we are indicating that the matrix is declared as transposed
    already, so the matrix will be treated differently.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个选项中，我们指示矩阵已经声明为转置，因此将以不同方式处理矩阵。
- en: 'The method inherits from the following which makes their concrete methods available
    to all routines:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该方法继承自以下内容，使它们的具体方法对所有例程可用：
- en: interface class java.lang.Object
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接口类java.lang.Object
- en: java.io.Serializable
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: java.io.Serializable
- en: Matrix
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵
- en: 'There are several method calls that are of interest:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有几个感兴趣的方法调用：
- en: 'Generate the diagonal matrix from the supplied values in the vector:'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从向量中提供的值生成对角矩阵：
- en: '[PRE63]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Create an identity matrix. An identity matrix is a matrix that has diagonals
    as 1 and any other element as 0:'
  id: totrans-242
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个单位矩阵。 单位矩阵是一个对角线为1，其他任何元素为0的矩阵：
- en: '[PRE64]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Keep track of whether the matrix is transposed:'
  id: totrans-244
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪矩阵是否转置：
- en: '[PRE65]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Create a matrix with a set of random numbers - drawn from uniform distribution:'
  id: totrans-246
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个具有一组随机数的矩阵-从均匀分布中抽取：
- en: '[PRE66]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Create a matrix with a set of random numbers - drawn from gaussian distribution:'
  id: totrans-248
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个具有一组随机数的矩阵-从高斯分布中抽取：
- en: '[PRE67]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Transpose the matrix:'
  id: totrans-250
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转置矩阵：
- en: '[PRE68]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Make a deep copy of the vector
  id: totrans-252
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对向量进行深层复制
- en: '[PRE69]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Convert to a SparseVector. You will do this if your vector is long and the
    density decreases after a number of operations (for example, zero out non-contributing
    members):'
  id: totrans-254
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换为稀疏向量。 如果您的向量很长，并且在一些操作后密度减小（例如，将不贡献的成员归零），则会执行此操作：
- en: '[PRE70]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Find the number of non-zero elements. This is useful so you can convert on-the-fly
    to the SparseVector if the density ID is low:'
  id: totrans-256
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找非零元素的数量。 这很有用，因此您可以根据需要将其转换为稀疏向量（例如，如果密度ID较低）：
- en: '[PRE71]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Get all the values stored in the Matrix:'
  id: totrans-258
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取矩阵中存储的所有值：
- en: '[PRE72]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'There are other calls corresponding to the specific operation for the SparseMatrix.
    The following is a sample, but we strongly recommend that you familiarize yourself
    with the manual pages (see the *There''s more...* section):'
  id: totrans-260
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还有其他对应于稀疏矩阵特定操作的调用。 以下是一个示例，但我们强烈建议您熟悉手册页面（请参阅*还有更多...*部分）：
- en: 'Get Row Indexes: `int rowIndices()`'
  id: totrans-261
  prefs:
  - PREF_OL
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取行索引：`int rowIndices()`
- en: 'Check for transposition: `booleanisTransposed()`'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查是否转置：`booleanisTransposed()`
- en: Get Column pointers: `int[]colPtrs()`
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取列指针：`int[]colPtrs()`
- en: There's more...
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'To reiterate, in a lot of machine learning applications, you end up dealing
    with sparsity due to the large dimensional nature of the feature space that is
    not linearly distributed. To illustrate, we take the simplest case in which we
    have 10 customers indicating their affinity for four themes in the product line:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，在许多机器学习应用中，由于特征空间的大尺寸特性不是线性分布的，最终会处理稀疏性。 举例来说，我们以最简单的情况为例，有10个客户指示他们对产品线中四个主题的亲和力：
- en: '|  | **Theme 1** | **Theme 2** | **Theme 3** | **Theme 4** |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '|  | **主题1** | **主题2** | **主题3** | **主题4** |'
- en: '| **Cust 1** | 1 | 0 | 0 | 0 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| **Cust 1** | 1 | 0 | 0 | 0 |'
- en: '| **Cust 2** | 0 | 0 | 0 | 1 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| **Cust 2** | 0 | 0 | 0 | 1 |'
- en: '| **Cust 3** | 0 | 0 | 0 | 0 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| **Cust 3** | 0 | 0 | 0 | 0 |'
- en: '| **Cust 4** | 0 | 1 | 0 | 0 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| **Cust 4** | 0 | 1 | 0 | 0 |'
- en: '| **Cust 5** | 1 | 1 | 1 | 0 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| **Cust 5** | 1 | 1 | 1 | 0 |'
- en: '| **Cust 6** | 0 | 0 | 0 | 0 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| **Cust 6** | 0 | 0 | 0 | 0 |'
- en: '| **Cust 7** | 0 | 0 | 1 | 0 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| **Cust 7** | 0 | 0 | 1 | 0 |'
- en: '| **Cust 8** | 0 | 0 | 0 | 0 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| **Cust 8** | 0 | 0 | 0 | 0 |'
- en: '| **Cust 9** | 1 | 0 | 1 | 1 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| **客户9** | 1 | 0 | 1 | 1 |'
- en: '| **Cust 10** | 0 | 0 | 0 | 0 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| **客户10** | 0 | 0 | 0 | 0 |'
- en: As you can see, most of the elements are 0 and storing them as a dense matrix
    is not desirable while we increase the number of customers and themes to tens
    of millions (M x N). The SparseVector and matrix help with the storage and operation
    of these sparse structures in an efficient way.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，大部分元素都是0，当我们增加客户和主题的数量到数千万（M x N）时，将它们存储为密集矩阵是不可取的。SparseVector和矩阵有助于以高效的方式存储和操作这些稀疏结构。
- en: See also
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#constructor_summary)
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#constructor_summary)找到
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#method_summary)
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#method_summary)找到
- en: Performing vector arithmetic using Spark 2.0
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark 2.0进行向量运算
- en: In this recipe, we explore vector addition in the Spark environment using the
    `Breeze` library for underlying operations. Vectors allow us to collect features
    and then manipulate them via linear algebra operations such as add, subtract,
    transpose, dot product, and so on.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们使用`Breeze`库进行底层操作，探索了在Spark环境中进行向量加法的方法。向量允许我们收集特征，然后通过线性代数运算（如加法、减法、转置、点积等）对其进行操作。
- en: How to do it...
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入向量和矩阵操作所需的包：
- en: '[PRE73]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Set up the Spark session and application parameters so Spark can run:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark会话和应用程序参数，以便Spark可以运行：
- en: '[PRE74]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'We create the Vectors:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建向量：
- en: '[PRE75]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'We convert the vectors from the Spark public interface to a `Breeze` (library)
    artifact so we can use a rich set of operators provided for Vector manipulation:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将向量从Spark公共接口转换为`Breeze`（库）工件，以便使用丰富的向量操作符：
- en: '[PRE76]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Let's look at the output and understand the results. For an operational understanding
    of vector addition, subtraction, and multiplication, see the *How it works...*
    section in this recipe.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看一下输出并理解结果。要了解向量加法、减法和乘法的操作原理，请参阅本教程中的*How it works...*部分。
- en: 'The output is as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE77]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Vector operations using both sparse and dense vectors with the Breeze library
    conversion are:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Breeze库转换的稀疏和密集向量的向量操作包括：
- en: '[PRE78]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'This is an alternate way, but it has the drawback of using a private function
    (see the actual source code for Spark 2.x.x itself). We recommend the method presented
    previously:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种替代方法，但它的缺点是使用了一个私有函数（请参阅Spark 2.x.x的实际源代码）。我们建议使用之前介绍的方法：
- en: '[PRE79]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'We take a look at the output:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下输出：
- en: '[PRE80]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: How it works...
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作原理...
- en: Vectors are mathematical artifacts that allow us to express magnitude and direction.
    In machine learning, we collect object/user preferences into vectors and matrices
    in order to take advantage of distributed operations at scale.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 向量是数学工件，允许我们表达大小和方向。在机器学习中，我们将对象/用户的偏好收集到向量和矩阵中，以便利用分布式操作规模化。
- en: Vectors are tuples of numbers usually corresponding to some attributes collected
    for machine learning algorithms. The vectors are usually real numbers (measured
    values), but many times we use binary values to show the presence or absence of
    a preference or bias for a particular topic.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 向量通常是一些属性的元组，通常用于机器学习算法。这些向量通常是实数（测量值），但很多时候我们使用二进制值来表示对特定主题的偏好或偏见的存在或不存在。
- en: 'A vector can be thought of as either a row vector or a column vector. The column
    vector presentation is more suitable for ML thinking. The column vector is represented
    as follows:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 向量可以被看作是行向量或列向量。列向量的表示更适合于机器学习思维。列向量表示如下：
- en: '![](img/00047.jpeg)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00047.jpeg)'
- en: 'The row vector is represented as follows:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 行向量表示如下：
- en: '![](img/00048.jpeg)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00048.jpeg)'
- en: 'Vector addition is represented as follows:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 向量加法表示如下：
- en: '![](img/00049.gif)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00049.gif)'
- en: 'Vector subtraction is represented as follows:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 向量减法表示如下：
- en: '![](img/00050.gif)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00050.gif)'
- en: 'Vector multiplication or "dot" product is represented as follows:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 向量乘法或“点”积表示如下：
- en: '![](img/00051.jpeg)![](img/00052.gif)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00051.jpeg)![](img/00052.gif)'
- en: There's more...
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The public interfaces offered by the Spark ML and MLlib library, whether used
    for sparse or dense vectors, currently lacks the necessary operators to do full
    vector arithmetic. We must convert our local vectors to the `Breeze` library vector
    to have the operators available for linear algebra.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML和MLlib库提供的公共接口，无论是用于稀疏向量还是密集向量，目前都缺少进行完整向量运算所需的运算符。我们必须将我们的本地向量转换为`Breeze`库向量，以便使用线性代数运算符。
- en: Prior to Spark 2.0, the method for conversion to `Breeze` (`toBreeze`) was available
    to use, but now the method has changed to `asBreeze()` and made private! A quick
    read of the source code is necessary to understand the new paradigm. Perhaps the
    change reflects Spark's core developers' desire to have less dependency on an
    underlying `Breeze` library.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark 2.0之前，转换为`Breeze`（`toBreeze`）的方法是可用的，但现在该方法已更改为`asBreeze()`并且变为私有！需要快速阅读源代码以了解新的范式。也许这种变化反映了Spark核心开发人员希望减少对底层`Breeze`库的依赖。
- en: If you are using any version of Spark prior to Spark 2.0 (Spark 1.5.1 or 1.6.1),
    use the following code snippets for conversion.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是Spark 2.0之前的任何版本（Spark 1.5.1或1.6.1），请使用以下代码片段进行转换。
- en: 'Pre-Spark 2.0 example 1:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 2.0之前的示例1：
- en: '[PRE81]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Pre-spark 2.0 example 2:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 2.0之前的示例2：
- en: '[PRE82]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: See also
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '`Breeze` library documentation is available at [http://www.scalanlp.org/api/breeze/#breeze.package](http://www.scalanlp.org/api/breeze/#breeze.package)'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Breeze`库文档可在[http://www.scalanlp.org/api/breeze/#breeze.package](http://www.scalanlp.org/api/breeze/#breeze.package)找到'
- en: '`Linalg` library documentation is available at [https://spark.apache.org/docs/latest/api/java/allclasses-noframe.html](https://spark.apache.org/docs/latest/api/java/allclasses-noframe.html)'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Linalg`库文档可在[https://spark.apache.org/docs/latest/api/java/allclasses-noframe.html](https://spark.apache.org/docs/latest/api/java/allclasses-noframe.html)找到'
- en: Performing matrix arithmetic using Spark 2.0
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark 2.0执行矩阵运算
- en: In this recipe, we explore matrix operations such as addition, transpose, and
    multiplication in Spark. The more complex operations such as inverse, SVD, and
    so on, will be covered in future sections. The native sparse and dense matrices
    for the Spark ML library provide multiplication operators so there is no need
    to convert to `Breeze` explicitly.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们探讨了Spark中的矩阵操作，如加法、转置和乘法。更复杂的操作，如逆、SVD等，将在未来的章节中介绍。Spark ML库的本机稀疏和密集矩阵提供了乘法运算符，因此不需要显式转换为`Breeze`。
- en: Matrices are the workhorses of distributed computing. ML features that are collected
    can be arranged in a matrix configuration and operated at scale. Many of the ML
    methods such as **ALS** (**Alternating Least Square**) and **SVD** (**Singular
    Value Decomposition**) rely on efficient matrix and vector operations to achieve
    large-scale machine learning and training.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵是分布式计算的工作马。收集的ML特征可以以矩阵配置的形式进行排列，并在规模上进行操作。许多ML方法，如**ALS**（**交替最小二乘法**）和**SVD**（**奇异值分解**），依赖于高效的矩阵和向量操作来实现大规模机器学习和训练。
- en: How to do it...
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包进行向量和矩阵操作：
- en: '[PRE83]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Set up the Spark session and application parameters so Spark can run:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark会话和应用程序参数，以便Spark可以运行：
- en: '[PRE84]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'We create the matrices:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了矩阵：
- en: '[PRE85]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Multiply the matrix and vector and print the results. This is an extremely
    useful operation which becomes a common theme in most Spark ML cases. We use a
    `SparseMatrix` to demonstrate the fact that the Dense, Sparse, and Matrix are
    interchangeable and only the density (for example, the percent of non-zero elements)
    and performance should be the criteria for selection:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将矩阵和向量相乘并打印结果。这是一个非常有用的操作，在大多数Spark ML案例中都是一个常见主题。我们使用`SparseMatrix`来演示密集、稀疏和矩阵是可互换的，只有密度（例如非零元素的百分比）和性能应该是选择的标准：
- en: '[PRE86]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The output is as follows:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE87]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Multiplying a `DenseMatrix` with `DenseVector`.
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`DenseMatrix`与`DenseVector`相乘。
- en: 'This is provided for completeness and will help the user to follow the matrix
    and vector multiplication more easily without worrying about sparsity:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为了完整性考虑，将帮助用户更轻松地跟随矩阵和向量乘法，而不用担心稀疏性：
- en: '[PRE88]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'The output is as follows:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE89]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: We demonstrate the transposing of a Matrix, which is an operation to swap rows
    with columns. It is an important operation and used almost on a daily basis if
    you are involved in Spark ML or data engineering.
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们演示了矩阵的转置，这是一种交换行和列的操作。如果你参与Spark ML或数据工程，这是一个重要的操作，几乎每天都会用到。
- en: 'Here we demonstrate two steps:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们演示了两个步骤：
- en: 'Transposing a `SparseMatrix` and examining the new resulting matrix via the
    output:'
  id: totrans-348
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将稀疏矩阵转置并通过输出检查新的结果矩阵：
- en: '[PRE90]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The output is as follows:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE91]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Demonstrating that the transpose of a transpose yields the original matrix:'
  id: totrans-352
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 演示转置的转置产生原始矩阵：
- en: '[PRE92]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'The output is as follows:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE93]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Transposing a dense matrix and examining the new resulting matrix via the output:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 转置密集矩阵并通过输出检查新的结果矩阵：
- en: 'This makes it easier to see how row and column indexes are swapped:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 这样更容易看到行和列索引是如何交换的：
- en: '[PRE94]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: We now look at matrix multiplication and how it would look in code.
  id: totrans-359
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来看矩阵乘法以及在代码中的表现。
- en: 'We declare two 2x2 Dense Matrices:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声明了两个2x2的密集矩阵：
- en: '[PRE95]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The output is as follows:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE96]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: How it works...
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: A matrix can be thought of as columns of vectors. Matrices are the power tools
    for distributed computation involving linear algebra transformation. A variety
    of attributes or feature representation can be collected and operated upon via
    matrices.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵可以被看作是向量的列。矩阵是涉及线性代数变换的分布式计算的强大工具。可以通过矩阵收集和操作各种属性或特征表示。
- en: 'In short, matrices are two-dimensional *m x n* arrays of numbers (usually real
    numbers) whose elements can be referenced using a two-element subscript, *i* and
    *j*:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，矩阵是二维*m x n*数组，其中元素可以使用两个元素的下标*i*和*j*来引用（通常是实数）：
- en: 'A matrix is represented as follows:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵表示如下：
- en: '![](img/00053.gif)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00053.gif)'
- en: 'A matrix transpose is represented as follows:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵转置表示如下：
- en: '![](img/00054.jpeg)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00054.jpeg)'
- en: 'Matrix multiplication is represented as follows:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法表示如下：
- en: '![](img/00055.gif)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00055.gif)'
- en: 'Vector matrix multiplication or "dot" product is represented as follows:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 向量矩阵乘法或“点”积表示如下：
- en: '![](img/00056.gif)![](img/00057.gif)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00056.gif)![](img/00057.gif)'
- en: '*Distributed matrices in the Spark 2.0 ML library*: In the next four recipes,
    we will cover the four types of distributed matrices in Spark. Spark provides
    full support for distributed matrices baked by RDDs right out of the box. The
    fact that Spark supports distributed computing does not relieve the developer
    from planning their algorithms with parallelism in mind.'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '*Spark 2.0 ML库中的分布式矩阵*：在接下来的四个配方中，我们将介绍Spark中的四种分布式矩阵类型。Spark提供了对由RDD支持的分布式矩阵的全面支持。Spark支持分布式计算的事实并不意味着开发人员可以不考虑并行性来规划他们的算法。'
- en: The underlying RDDs provide full parallelism and fault tolerance over the underlying
    data that is stored in the matrix. Spark is bundled with MLLIB and LINALG, which
    jointly provide a public interface and support for matrices that are not local
    and need full cluster support due to their size or complexity of chained operations.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 底层的RDD提供了存储在矩阵中的数据的全面并行性和容错性。Spark捆绑了MLLIB和LINALG，它们共同提供了一个公共接口，并支持那些由于其大小或链式操作的复杂性而需要完整集群支持的矩阵。
- en: 'Spark ML provides four types of distributed matrices to support parallelism:
    `RowMatrix`, `IndexedRowMatrix`, `CoordinateMatrix`, and `BlockMatrix`:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML提供了四种类型的分布式矩阵来支持并行性：`RowMatrix`、`IndexedRowMatrix`、`CoordinateMatrix`和`BlockMatrix`：
- en: '`RowMatrix`: Represents a row-oriented distributed matrix compatible with ML
    library'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RowMatrix`：表示与ML库兼容的面向行的分布式矩阵'
- en: '`IndexedRowMatrix`: Similar to `RowMatrix` with one additional benefit of indexing
    the rows. This is a specialized version of `RowMatrix` in which the matrix itself
    is created from the RDD of `IndexedRow` (Index, Vector) data structure. To visualize
    it, imagine a matrix where each row is a pair (long, RDD) and the work of pairing
    them (`zip` function) is done for you. This will allow you to carry the Index
    together with the RDD along its computational path in a given algorithm (matrix
    operations at scale)'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IndexedRowMatrix`：与`RowMatrix`类似，但具有一个额外的好处，即对行进行索引。这是`RowMatrix`的一个专门版本，其中矩阵本身是从`IndexedRow`（索引，向量）数据结构的RDD创建的。要可视化它，想象一个矩阵，其中每一行都是一对（长，RDD），并且已经为您完成了它们的配对（`zip`函数）。这将允许您在给定算法的计算路径中将索引与RDD一起携带（规模上的矩阵运算）。'
- en: '`CoordinateMatrix`: A very useful format which is used for coordinates (for
    example, *x*, *y*, *z* coordinates in a projection space)'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CoordinateMatrix`：用于坐标的非常有用的格式（例如，在投影空间中的*x*、*y*、*z*坐标）'
- en: '`BlockMatrix`: A distributed matrix made of blocks of locally maintained matrices'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BlockMatrix`：由本地维护的矩阵块组成的分布式矩阵'
- en: We cover the creation of the four types in a brief recipe and then quickly move
    to a more complicated (code and concept) use case involving `RowMatrix` which
    is a typical ML use case involving a massively parallel distributed matrix operation
    (for example, multiplication) with a local matrix.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将简要介绍这四种类型的创建，然后迅速转向一个更复杂（代码和概念）的用例，涉及`RowMatrix`，这是一个典型的ML用例，涉及大规模并行分布式矩阵操作（例如乘法）与本地矩阵。
- en: If you plan to code or design large matrix operations, you must dig into the
    Spark internals such as core Spark and how staging, pipelining, and shuffling
    works in each version of Spark (continuous improvement and optimization in each
    version).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您计划编写或设计大型矩阵操作，您必须深入了解Spark内部，例如核心Spark以及在每个版本的Spark中分期、流水线和洗牌的工作方式（每个版本中的持续改进和优化）。
- en: 'We also recommend the following before embarking on a large-scale matrix and
    optimization journey:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在着手进行大规模矩阵和优化之旅之前，我们还建议以下几点：
- en: The source for matrix computations and optimization in Apache Spark is available
    at [http://www.kdd.org/kdd2016/papers/files/adf0163-bosagh-zadehAdoi.pdf](http://www.kdd.org/kdd2016/papers/files/adf0163-bosagh-zadehAdoi.pdf)
    and [https://pdfs.semanticscholar.org/a684/fc37c79a3276af12a21c1af1ebd8d47f2d6a.pdf](https://pdfs.semanticscholar.org/a684/fc37c79a3276af12a21c1af1ebd8d47f2d6a.pdf).
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark中矩阵计算和优化的来源可在[http://www.kdd.org/kdd2016/papers/files/adf0163-bosagh-zadehAdoi.pdf](http://www.kdd.org/kdd2016/papers/files/adf0163-bosagh-zadehAdoi.pdf)和[https://pdfs.semanticscholar.org/a684/fc37c79a3276af12a21c1af1ebd8d47f2d6a.pdf](https://pdfs.semanticscholar.org/a684/fc37c79a3276af12a21c1af1ebd8d47f2d6a.pdf)找到。
- en: The source for efficient large scale distributed matrix computation with Spark
    is available at [https://www.computer.org/csdl/proceedings/big-data/2015/9926/00/07364023.pdf](https://www.computer.org/csdl/proceedings/big-data/2015/9926/00/07364023.pdf)
    and [http://dl.acm.org/citation.cfm?id=2878336&preflayout=flat](http://dl.acm.org/citation.cfm?id=2878336&preflayout=flat)
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Spark进行高效大规模分布式矩阵计算的来源可在[https://www.computer.org/csdl/proceedings/big-data/2015/9926/00/07364023.pdf](https://www.computer.org/csdl/proceedings/big-data/2015/9926/00/07364023.pdf)和[http://dl.acm.org/citation.cfm?id=2878336&preflayout=flat](http://dl.acm.org/citation.cfm?id=2878336&preflayout=flat)找到。
- en: The source for exploring matrix dependency for efficient distributed matrix
    computation is available at [http://net.pku.edu.cn/~cuibin/Papers/2015-SIGMOD-DMac.pdf](http://net.pku.edu.cn/~cuibin/Papers/2015-SIGMOD-DMac.pdf)
    and [http://dl.acm.org/citation.cfm?id=2723712](http://dl.acm.org/citation.cfm?id=2723712)
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 探索矩阵依赖关系以实现高效的分布式矩阵计算的来源可在[http://net.pku.edu.cn/~cuibin/Papers/2015-SIGMOD-DMac.pdf](http://net.pku.edu.cn/~cuibin/Papers/2015-SIGMOD-DMac.pdf)和[http://dl.acm.org/citation.cfm?id=2723712](http://dl.acm.org/citation.cfm?id=2723712)找到。
- en: Exploring RowMatrix in Spark 2.0
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索Spark 2.0中的RowMatrix
- en: In this recipe, we explore the `RowMatrix` facility that is provided by Spark.
    `RowMatrix`, as the name implies, is a row-oriented matrix with the catch being
    the lack of an index that can be defined and carried through the computational
    life cycle of a `RowMatrix`. The rows are RDDs which provide distributed computing
    and resiliency with fault tolerance.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们探索了Spark提供的`RowMatrix`功能。`RowMatrix`顾名思义，是一个面向行的矩阵，但缺少可以在`RowMatrix`的计算生命周期中定义和传递的索引。这些行是RDD，它们提供了分布式计算和容错性。
- en: The matrix is made of rows of local vectors that are parallelized and distributed
    via RDDs. In short, each row will be an RDD, but the total number of columns will
    be limited by the maximum size of a local vector. This is not an issue in most
    cases, but we felt we should mention it for completion.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵由本地向量的行组成，通过RDDs并行化和分布。简而言之，每行将是一个RDD，但列的总数将受到本地向量最大大小的限制。在大多数情况下，这不是问题，但出于完整性考虑，我们觉得应该提一下。
- en: How to do it...
  id: totrans-391
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入向量和矩阵操作所需的包：
- en: '[PRE97]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Set up the Spark context and application parameters so Spark can run. See the
    first recipe in the chapter for more details and variations:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark上下文和应用程序参数，以便Spark可以运行。有关更多详细信息和变体，请参阅本章的第一个配方：
- en: '[PRE98]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The amount and timing of warning statements returned as output varies due to
    the nature of distributed computing (non-sequential) with distributed matrices.
    The interlacing of messages with actual output varies depending on the execution
    path and that results in hard to read output. In the following statements, we
    elevate the `log4j` messages from warning (WARN - out of the box) to errors (ERROR)
    for clarity. We suggest that the developer follows the warning messages in detail
    to grasp the parallel nature of these operations and to fully understand the concept
    of an RDD:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于分布式计算（非顺序）的性质，警告语句的数量和时间返回的输出会有所不同。消息与实际输出的交错程度取决于执行路径，这导致输出难以阅读。在以下语句中，我们将`log4j`消息从警告（WARN
    - 默认）提升到错误（ERROR）以便更清晰。我们建议开发人员详细跟踪警告消息，以了解这些操作的并行性质并充分理解RDD的概念：
- en: '[PRE99]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Set the level to error:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 将级别设置为错误：
- en: '[PRE100]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Originally comes out the box like this
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 最初的输出如下
- en: '[PRE101]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: We define two sequence data structures of dense vectors.
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了两个密集向量的序列数据结构。
- en: 'A Scala sequence of dense local vectors which will be the data for the distributed
    `RowMatrix`:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: Scala密集本地向量的序列，这将是分布式`RowMatrix`的数据：
- en: '[PRE102]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'A Scala sequence of dense local vectors which will be the data for the local
    identity matrix. A quick check of linear algebra shows that any matrix multiplied
    by an identity matrix will yield the same original matrix (that is, *A x I = A*).
    We like to use the identity matrix to prove that the multiplication worked and
    the original statistic computed over the original matrix is the same as the original
    *x* identity:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: Scala密集本地向量的序列，这将是本地身份矩阵的数据。线性代数的快速检查表明，任何矩阵乘以一个单位矩阵将产生相同的原始矩阵（即，*A x I = A*）。我们喜欢使用单位矩阵来证明乘法有效，并且原始矩阵上计算的原始统计量与原始*
    x *单位矩阵相同：
- en: '[PRE103]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: Create our first distributed matrix by parallelizing the underlying dense vectors
    to RDDs.
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过并行化基础密集向量到RDDs，创建我们的第一个分布式矩阵。
- en: Going forward, our dense vectors are now rows in the new distributed vectors
    backed by RDD (that is, all RDD operations are fully supported!).
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我们的密集向量现在是由RDD支持的新分布式向量中的行（即，所有RDD操作都得到充分支持！）。
- en: 'Take the original Sequences (made of vectors) and turn them into RDDs. We will
    cover RDDs in detail in the next chapter. In this single statement, we have turned
    a local data structure to a distributed artifact:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 将原始序列（由向量组成）转换为RDDs。我们将在下一章详细介绍RDDs。在这个单一语句中，我们已经将一个本地数据结构转换为了一个分布式工件：
- en: '[PRE104]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'We calculate some basic statistics to verify that the `RowMatrix` is constructed
    properly. The point to remember is that the dense vectors are now rows and not
    columns (which is the source of much confusion):'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算一些基本统计量，以验证`RowMatrix`是否正确构建。要记住的是，密集向量现在是行而不是列（这是导致许多混淆的根源）：
- en: '[PRE105]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'The output is as follows:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: The statistics calculated (mean, variance, min, max, and so on) are for each
    column and not the entire matrix. This is the reason you see three numbers for
    mean and variance which corresponds to each column.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 计算的统计量（均值、方差、最小值、最大值等）是针对每列而不是整个矩阵的。这就是为什么您看到均值和方差对应于每列的三个数字的原因。
- en: '[PRE106]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'In this step, we create our local matrix from the identity vector''s data structure.
    The point to remember is that the multiplication requires a local matrix and not
    a distributed one. Please see the call signature for verification. We use the
    `map`, `toArray`, and `flatten` operators to create a Scala flattened array data
    structure that can be used as one of the parameters to create a local matrix as
    shown in the next step:'
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，我们从身份向量的数据结构中创建我们的本地矩阵。要记住的一点是，乘法需要一个本地矩阵而不是分布式矩阵。请查看调用签名以进行验证。我们使用`map`、`toArray`和`flatten`操作符来创建一个Scala扁平化数组数据结构，该数据结构可以作为创建本地矩阵的参数之一，如下一步所示：
- en: '[PRE107]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'We create the local matrix as an identity matrix so we can verify the multiplication
    *A * I = A*:'
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将本地矩阵创建为单位矩阵，以便验证乘法*A * I = A*：
- en: '[PRE108]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'We multiply the distributed matrix by the local one and create a new distributed
    matrix. This is a typical use case in which you end up multiplying a tall and
    skinny local matrix with a large-scale distributed matrix to achieve scale and
    the inherited dimensionality reduction of the resulting matrix:'
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将分布式矩阵乘以本地矩阵，并创建一个新的分布式矩阵。这是一个典型的用例，您最终会将一个高瘦的本地矩阵与大规模分布式矩阵相乘，以实现规模和结果矩阵的继承降维：
- en: '[PRE109]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: Comparing step 7 and 8, we see that in fact the operation proceeded correctly
    and we can verify via descriptive statistics and the co-variance matrix that *A
    x I = A* using a distributed and local matrix.
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较第7步和第8步，我们实际上看到操作进行正确，并且我们可以通过描述性统计和协方差矩阵验证*A x I = A*，使用分布式和本地矩阵。
- en: 'The output is as follows:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE110]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: How it works...
  id: totrans-426
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'The signatures for this method constructor are:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此方法构造函数的签名为：
- en: '`RowMatrix(RDD<Vector> rows)`'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RowMatrix(RDD<Vector> rows)`'
- en: '`RowMatrix(RDD<Vector>, long nRows, Int nCols)`'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RowMatrix(RDD<Vector>, long nRows, Int nCols)`'
- en: 'The method inherits from the following which makes their concrete methods available
    to all routines:'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该方法继承自以下内容，使它们的具体方法对所有例程可用：
- en: interface class java.lang.Object
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接口类java.lang.Object
- en: 'Implements the following interfaces:'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现以下接口：
- en: Logging
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录
- en: Distributed matrix
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式矩阵
- en: 'There are several method calls that are of interest:'
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有一些有趣的方法调用：
- en: 'Calculate descriptive statistics such as mean, min, max, variance, and so on:'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算描述性统计，如均值、最小值、最大值、方差等：
- en: '`MultivariateStatisticalSummary`'
  id: totrans-437
  prefs:
  - PREF_OL
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultivariateStatisticalSummary`'
- en: '`computeColumnSummaryStatistics()`'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`computeColumnSummaryStatistics()`'
- en: 'Compute the co-variance matrix from the original:'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从原始计算协方差矩阵：
- en: '`Matrix computeCovariance()`'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Matrix computeCovariance()`'
- en: Compute the Gramian matrix, also referred to as the Gram Matrix
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算Gramian矩阵，也称为Gram矩阵
- en: '(*A^TA* ):'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '(*A^TA* ):'
- en: '``Matrix computeGramianMatrix()``'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '``Matrix computeGramianMatrix()``'
- en: 'Calculate the PCA components:'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算PCA组件：
- en: '`Matrix computePrincipalComponents(int k)`'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Matrix computePrincipalComponents(int k)`'
- en: '*k* is the number of principal components'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*是主成分的数量'
- en: 'Calculate the SVD decomposition of the original matrix:'
  id: totrans-447
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算原始矩阵的SVD分解：
- en: '`SingularValueDecomposition<RowMatrix, Matrix> computeSVD(int k, boolean compute,
    double rCond)`'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SingularValueDecomposition<RowMatrix, Matrix> computeSVD(int k, boolean compute,
    double rCond)`'
- en: '*k* is the number of leading singular values to keep (*0<k<=n*).'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*是要保留的前导奇异值的数量（*0<k<=n*）。'
- en: 'Multiply:'
  id: totrans-450
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相乘：
- en: '`RowMatrix Multiply(Matrix B)`'
  id: totrans-451
  prefs:
  - PREF_OL
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RowMatrix Multiply(Matrix B)`'
- en: 'Rows:'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行：
- en: '`RDD<Vector> rows()`'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RDD<Vector> rows()`'
- en: 'Calculate the QR decomposition:'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算QR分解：
- en: '`QRDecomposition<RowMatrix, Matrix> tallSkinnyQR(boolean computeQ))`'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`QRDecomposition<RowMatrix, Matrix> tallSkinnyQR(boolean computeQ))`'
- en: 'Find the number of non-zero elements. This is useful so you can convert on-the-fly
    to the SparseVector if the density ID is low:'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到非零元素的数量。如果密度较低，这很有用，因此您可以在需要时转换为SparseVector：
- en: '`Int numNonzeros()`'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Int numNonzeros()`'
- en: 'Get all the values stored in the matrix:'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取矩阵中存储的所有值：
- en: '`Double[] Values()`'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Double[] Values()`'
- en: 'Others:'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他：
- en: Calculate the column similarities (very useful in document analysis). There
    are two methods available which are covered in the [Chapter 12](part0512.html#F89000-4d291c9fed174a6992fd24938c2f9c77), *Implementing
    Text Analytics with Spark 2.0 ML Library*
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算列之间的相似性（在文档分析中非常有用）。有两种可用的方法，这些方法在[第12章](part0512.html#F89000-4d291c9fed174a6992fd24938c2f9c77)中有介绍，*使用Spark
    2.0 ML库实现文本分析*
- en: Number of columns and number of rows which we find useful for dynamic programming
  id: totrans-462
  prefs:
  - PREF_OL
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们发现对于动态规划很有用的列数和行数
- en: There's more...
  id: totrans-463
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: There are some additional factors to consider when you use sparse or dense elements
    (vectors or block matrices). Multiplying by a local matrix is usually preferable
    since it doesn't require expensive shuffling.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用稀疏或密集元素（向量或块矩阵）时，还有一些额外的因素需要考虑。通常情况下，通过本地矩阵进行乘法是更可取的，因为它不需要昂贵的洗牌。
- en: 'While simplicity and control is preferred when dealing with large matrices,
    the four types of distributed matrices simplify the setup and operation. Each
    of the four types has advantages and disadvantages that have to be considered
    and weighed against these three criteria:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理大矩阵时，更喜欢简单和控制，这四种分布式矩阵类型简化了设置和操作。这四种类型各有优缺点，必须根据以下三个标准进行考虑和权衡：
- en: Sparsity or Density of underlying data
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础数据的稀疏度或密度
- en: Shuffling that will take place when using these facilities.
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用这些功能时将进行的洗牌。
- en: Network capacity utilization when dealing with edge cases
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理边缘情况时的网络容量利用率
- en: For the reasons mentioned, and especially to reduce the shuffling (that is,
    a network bottleneck) required during a distributed matrix operation (for example,
    multiplication of two RowMatrixes), we prefer multiplication with a local matrix
    to reduce shuffle noticeably. While this seems a bit counter-intuitive at first,
    in practice it is fine for the cases we have encountered. The reason for this
    is because when we multiply a large matrix with a vector or tall and skinny matrix,
    the resulting matrix is small enough that fits into the memory.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 出于上述原因，尤其是为了减少分布式矩阵操作（例如两个RowMatrix相乘）期间所需的洗牌（即网络瓶颈），我们更喜欢使用本地矩阵进行乘法，以显着减少洗牌。虽然这乍看起来有点违反直觉，但在实践中，对于我们遇到的情况来说是可以的。原因是当我们将一个大矩阵与一个向量或高瘦矩阵相乘时，结果矩阵足够小，可以放入内存中。
- en: The other point of caution will be that the returning information (a row or
    local matrix) has to be small enough so it can be returned to the driver.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要注意的地方是返回的信息（行或本地矩阵）必须足够小，以便可以将其返回给驱动程序。
- en: For imports, we need both local and distributed vector and matrix imports so
    we can work with the ML library. Otherwise, the Scala vector and matrix will be
    used by default.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 对于导入，我们需要本地和分布式向量和矩阵导入，以便我们可以使用ML库进行工作。否则，默认情况下将使用Scala向量和矩阵。
- en: See also
  id: totrans-472
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#constructor_summary)
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#constructor_summary)找到
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#method_summary](https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#method_summary)
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#method_summary](https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#method_summary)找到
- en: Exploring Distributed IndexedRowMatrix in Spark 2.0
  id: totrans-475
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索分布式IndexedRowMatrix
- en: In this recipe, we cover the `IndexRowMatrix`, which is the first specialized
    distributed matrix that we cover in this chapter. The primary advantage of `IndexedRowMatrix`
    is that the index can be carried along with the row (RDD), which is the data itself.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们介绍了`IndexRowMatrix`，这是本章中我们介绍的第一个专门的分布式矩阵。`IndexedRowMatrix`的主要优势是索引可以与行（RDD）一起传递，这就是数据本身。
- en: In the case of `IndexRowMatrix`, we have an index defined by the developer which
    is permanently paired with a given row that is very useful for random access cases.
    The index not only helps with random access, but is also used for identifying
    the row itself when performing `join()` operations.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 在`IndexRowMatrix`的情况下，我们有一个由开发人员定义的索引，它与给定的行永久配对，对于随机访问非常有用。索引不仅有助于随机访问，而且在执行`join()`操作时也用于标识行本身。
- en: How to do it...
  id: totrans-478
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入向量和矩阵操作所需的包：
- en: '[PRE111]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'Set up the Spark context and application parameters so Spark can run. See the
    first recipe in the chapter for more details and variations:'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark上下文和应用程序参数，以便Spark可以运行。有关更多详细信息和变体，请参见本章的第一个教程：
- en: '[PRE112]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: We start with our original data vectors and then proceed to construct an appropriate
    data structure (that is, RowIndex) to house the index and vector.
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从原始数据向量开始，然后继续构造一个适当的数据结构（即RowIndex）来容纳索引和向量。
- en: We then proceed to construct the `IndexedRowMatrix` and show the access. For
    those of you who have worked with LIBSVM, this format is close to label and vector
    artifacts with a twist that labels are now indexes (that is, long).
  id: totrans-485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们继续构造`IndexedRowMatrix`并显示访问。对于那些使用过LIBSVM的人来说，这种格式接近标签和向量的工件，但标签现在是索引（即长）。
- en: 'Start with a sequence of vectors as the base data structure for `IndexedRowMatrix`:'
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从一系列向量作为`IndexedRowMatrix`的基本数据结构开始：
- en: '[PRE113]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Start with a sequence of vectors as the base data structure for `IndexedRowMatrix`:'
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从一系列向量作为`IndexedRowMatrix`的基本数据结构开始：
- en: '[PRE114]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'The output is as follows:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE115]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: How it works...
  id: totrans-492
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The index is a long data structure which provides a meaningful row index corresponding
    to each row of the `IndexedRowMatrix`. The horsepower underneath the implementation
    are the RDDs which offer all the advantages of a distributed resilient data structure
    in a parallel environment from the get go.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 索引是一个长数据结构，为`IndexedRowMatrix`的每一行提供了一个有意义的行索引。实现底层的动力是RDDs，它们从一开始就在并行环境中提供了分布式弹性数据结构的所有优势。
- en: The primary advantage of `IndexedRowMatrix` is that the index can be carried
    along with the row (RDD) which is the data itself. The fact that we can define
    and carry along the index with the data (the actual row of matrix) is very useful
    when we have the `join()` operation that needs a key to select a specific row
    of data.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: '`IndexedRowMatrix`的主要优势是索引可以与数据本身（RDD）一起传递。我们可以定义并携带数据（矩阵的实际行）的索引，这在`join()`操作需要键来选择特定数据行时非常有用。'
- en: 'The following figure shows a pictorial view of the `IndexedRowMatrix` which
    should help clarify the subject:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了`IndexedRowMatrix`的图解视图，应有助于澄清主题：
- en: '![](img/00058.jpeg)'
  id: totrans-496
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00058.jpeg)'
- en: 'The definition may be unclear as you are required to repeatedly define the
    index and the data to compose the original matrix. The following code snippet
    shows the inner list with (index, Data) repetition for reference:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 定义可能不清晰，因为您需要重复定义索引和数据来组成原始矩阵。以下代码片段显示了内部列表中（索引，数据）的重复以供参考：
- en: '[PRE116]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: The other operations are similar to the `IndexRow` matrix that was covered in
    the previous recipe.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 其他操作与前一篇中介绍的`IndexRow`矩阵类似。
- en: See also
  id: totrans-500
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#constructor_summary)
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#constructor_summary)找到。
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#method_summary)
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#method_summary)找到。
- en: Exploring distributed CoordinateMatrix in Spark 2.0
  id: totrans-503
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索分布式CoordinateMatrix
- en: In this recipe, we cover the second form of specialized distributed matrix.
    This is very handy when dealing with ML implementations that need to deal with
    often large 3D coordinate systems (x, y, z). It is a convenient way to package
    the coordinate data structure into a distributed matrix.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们介绍了专门的分布式矩阵的第二种形式。在处理需要处理通常较大的3D坐标系（x，y，z）的ML实现时，这是非常方便的。这是一种将坐标数据结构打包成分布式矩阵的便捷方式。
- en: How to do it...
  id: totrans-505
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-507
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入向量和矩阵操作所需的包：
- en: '[PRE117]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'Set up the Spark context and application parameters so Spark can run. See the
    first recipe in the chapter for more details and variations:'
  id: totrans-509
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark上下文和应用程序参数，以便Spark可以运行。有关更多详细信息和变体，请参见本章的第一个教程：
- en: '[PRE118]'
  id: totrans-510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'We start with a SEQ of `MatrixEntry`, which corresponds to each coordinate
    and will be placed in the `CoordinateMatrix`. Note that the entries cannot be
    real numbers any more (they are x, y, z coordinates after all):'
  id: totrans-511
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从“MatrixEntry”的SEQ开始，它对应于每个坐标，并将放置在“CoordinateMatrix”中。请注意，这些条目不再可以是实数（毕竟它们是x、y、z坐标）：
- en: '[PRE119]'
  id: totrans-512
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'We instantiate the call and construct the `CoordinateMatrix`. We need an additional
    step to create RDDs which we have shown in the constructor by using the Spark
    context for parallelization (that is, `sc.parallelize`):'
  id: totrans-513
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实例化调用并构造“CoordinateMatrix”。我们需要额外的步骤来创建RDD，我们已经在构造函数中使用Spark上下文进行了展示（即`sc.parallelize`）：
- en: '[PRE120]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'We print the first `MatrixEntry` to verify the matrix elements. We will address
    RDDs in the next chapter, but note that `count()` is an action by itself and using
    `collect()` will be redundant:'
  id: totrans-515
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们打印第一个“MatrixEntry”以验证矩阵元素。我们将在下一章中讨论RDD，但请注意，“count（）”本身就是一个动作，使用“collect（）”将是多余的：
- en: '[PRE121]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'The output is as follows:'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE122]'
  id: totrans-518
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: How it works...
  id: totrans-519
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: '`CoordinateMatrix` is a specialized matrix in which each entry is a coordinate
    system or a tuple of three numbers (long, long, long corresponding to *x*, *y*,
    *z* coordinates). A related data structure is `MatrixEntry`, in which coordinates
    will be stored and then placed at a location in the `CoordinateMatrix`. The following
    code snippet demonstrates the use of `MaxEntry`, which seems to be a source of
    confusion in itself.'
  id: totrans-520
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “CoordinateMatrix”是一种专门的矩阵，其中每个条目都是一个坐标系或三个数字的元组（长，长，长对应于*x*，*y*，*z*坐标）。相关的数据结构是“MatrixEntry”，其中将存储坐标，然后放置在“CoordinateMatrix”的位置。以下代码片段演示了“MaxEntry”的使用，这似乎本身就是一个混乱的来源。
- en: 'The following figure shows a pictorial view of the `CoordinateMatrix`, which
    should help clarify the subject:'
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下图显示了“CoordinateMatrix”的图示视图，这应该有助于澄清主题：
- en: '![](img/00059.jpeg)'
  id: totrans-522
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00059.jpeg)'
- en: 'The code snippet which holds three coordinates is:'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 包含三个坐标的代码片段是：
- en: '[PRE123]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '`MaxEntry` is nothing but a required structure to hold the coordinate. Unless
    you need to modify the source code supplied by Spark (see GitHub `CoordinateMatrix.scala`)
    to define a more specialized container (compressed), there is no need to understand
    it any further:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: “MaxEntry”只是一个必需的结构，用于保存坐标。除非您需要修改Spark提供的源代码（请参阅GitHub“CoordinateMatrix.scala”）以定义一个更专业的容器（压缩），否则没有必要进一步了解它：
- en: The `CoordinateMatrix` is also backed by RDDs which lets you leverage parallelism
    from the get go.
  id: totrans-526
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: “CoordinateMatrix”也由RDD支持，这让您可以从一开始就利用并行性。
- en: You need to import `IndexedRow` as well so you can define the row with its index
    prior to instantiating the `IndexedRowMatrix`.
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您还需要导入“IndexedRow”，这样您就可以在实例化“IndexedRowMatrix”之前定义带有索引的行。
- en: This matrix can be converted to `RowMatrix`, `IndexedRowMatrix`, and `BlockMatrix`.
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个矩阵可以转换为“RowMatrix”、“IndexedRowMatrix”和“BlockMatrix”。
- en: There is also an added benefit of efficient storage, retrieval, and operation
    that comes with a sparse coordinate system (for example, security threat matrix
    of all devices versus location).
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏坐标系统还带来了高效的存储、检索和操作的附加好处（例如，所有设备与位置的安全威胁矩阵）。
- en: See also
  id: totrans-530
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#constructor_summary)
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档位于[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#constructor_summary)
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#method_summary)
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档位于[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#method_summary)
- en: Documentation for MaxEntry is available at [http://spark.apache.org/docs/latest/api/java/index.html](http://spark.apache.org/docs/latest/api/java/index.html)
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MaxEntry的文档位于[http://spark.apache.org/docs/latest/api/java/index.html](http://spark.apache.org/docs/latest/api/java/index.html)
- en: Exploring distributed BlockMatrix in Spark 2.0
  id: totrans-534
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索分布式BlockMatrix
- en: In this recipe, we explore `BlockMatrix`, which is a nice abstraction and a
    placeholder for the block of other matrices. In short, it is a matrix of other
    matrices (matrix blocks) which can be accessed as a cell.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们探索了“BlockMatrix”，这是一个很好的抽象和其他矩阵块的占位符。简而言之，它是其他矩阵（矩阵块）的矩阵，可以作为单元访问。
- en: '[PRE124]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: How to do it...
  id: totrans-537
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an editor of your choice and make sure
    all the necessary JAR files (Scala and Spark) are available to your application.
  id: totrans-538
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的编辑器中启动一个新项目，并确保所有必要的JAR文件（Scala和Spark）对您的应用程序可用。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-539
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入用于向量和矩阵操作的必要包：
- en: '[PRE125]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: 'Set up the Spark context and application parameters so Spark can run. See the
    first recipe in this chapter for more details and variations:'
  id: totrans-541
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark上下文和应用程序参数，以便Spark可以运行。有关更多详细信息和变化，请参见本章的第一个示例：
- en: '[PRE126]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: 'Create a `CoordinateMatrix` quickly to use as a base for conversion:'
  id: totrans-543
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 快速创建一个“CoordinateMatrix”以用作转换的基础：
- en: '[PRE127]'
  id: totrans-544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'We take the `CoordinateMatrix` and convert it into a `BlockMatrix`:'
  id: totrans-545
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将“CoordinateMatrix”转换为“BlockMatrix”：
- en: '[PRE128]'
  id: totrans-546
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: 'This is a very useful call with this type of matrix. In real life, it is often
    necessary to check the setup before proceeding to compute:'
  id: totrans-547
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个非常有用的矩阵类型的调用。在现实生活中，通常需要在进行计算之前检查设置：
- en: '[PRE129]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'The output is as follows:'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE130]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: How it works...
  id: totrans-551
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: A matrix block will be defined as a tuple of (int, int, Matrix). What is unique
    about this matrix is that it has `Add()` and `Multiply()` functions that can take
    another `BlockMatrix` as a second parameter to the distributed matrix. While setting
    it up is a bit confusing at first (especially on-the-fly as data arrives), there
    are helper functions that can help you verify your work and make sure the `BlockMatrix`
    is set up properly. This type of matrix can be converted to a local, `IndexRowMatrix`,
    and `CoordinateMatrix`. One of the most common use cases for the `BlockMatrix`
    is to have a `BlockMatrix` of `CoordinateMatrices`.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵块将被定义为（int，int，Matrix）的元组。这种矩阵的独特之处在于它具有`Add()`和`Multiply()`函数，这些函数可以将另一个`BlockMatrix`作为分布式矩阵的第二个参数。虽然一开始设置它有点令人困惑（特别是在数据到达时），但有一些辅助函数可以帮助您验证您的工作，并确保`BlockMatrix`被正确设置。这种类型的矩阵可以转换为本地的`IndexRowMatrix`和`CoordinateMatrix`。`BlockMatrix`最常见的用例之一是拥有`CoordinateMatrices`的`BlockMatrix`。
- en: See also
  id: totrans-553
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#constructor_summary)
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#constructor_summary)找到。
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#method_summary)
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#method_summary)找到。
