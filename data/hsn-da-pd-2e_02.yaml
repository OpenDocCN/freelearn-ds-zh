- en: '*Chapter 1*: Introduction to Data Analysis'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第1章*：数据分析简介'
- en: Before we can begin our hands-on introduction to data analysis with `pandas`,
    we need to learn about the fundamentals of data analysis. Those who have ever
    looked at the documentation for a software library know how overwhelming it can
    be if you have no clue what you are looking for. Therefore, it is essential that
    we master not only the coding aspect but also the thought process and workflow
    required to analyze data, which will prove the most useful in augmenting our skill
    set in the future.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用 `pandas` 进行数据分析的实践介绍之前，我们需要学习数据分析的基础知识。那些曾经查看过软件库文档的人都知道，如果你不知道自己在找什么，它可能会让人感到压倒性的复杂。因此，掌握不仅是编码方面的技能，还需要掌握分析数据所需的思维方式和工作流程，这将对未来提升我们的技能集非常有帮助。
- en: Much like the scientific method, data science has some common workflows that
    we can follow when we want to conduct an analysis and present the results. The
    backbone of this process is **statistics**, which gives us ways to describe our
    data, make predictions, and also draw conclusions about it. Since prior knowledge
    of statistics is not a prerequisite, this chapter will give us exposure to the
    statistical concepts we will use throughout this book, as well as areas for further
    exploration.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与科学方法类似，数据科学也有一些常见的工作流程，当我们想进行分析并展示结果时，可以遵循这些流程。这个过程的核心是**统计学**，它为我们提供了描述数据、做出预测以及得出结论的方法。由于不要求具备统计学的先验知识，本章将让我们接触到在本书中将要使用的统计概念，以及可以进一步探索的领域。
- en: 'After covering the fundamentals, we will get our Python environment set up
    for the remainder of this book. Python is a powerful language, and its uses go
    way beyond data science: building web applications, software, and web scraping,
    to name a few. In order to work effectively across projects, we need to learn
    how to make **virtual environments**, which will isolate each project''s dependencies.
    Finally, we will learn how to work with Jupyter Notebooks in order to follow along
    with the text.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在掌握基础知识之后，我们将为本书的剩余部分设置我们的 Python 环境。Python 是一门强大的语言，其用途远远超出了数据科学：例如构建 web 应用程序、软件开发和网页抓取等。为了在项目之间有效地工作，我们需要学习如何创建**虚拟环境**，这样可以将每个项目的依赖关系隔离开来。最后，我们将学习如何使用
    Jupyter Notebooks，以便跟随书中的内容进行实践。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The fundamentals of data analysis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分析的基础
- en: Statistical foundations
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计基础
- en: Setting up a virtual environment
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置虚拟环境
- en: Chapter materials
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本章材料
- en: All the files for this book are on GitHub at [https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition).
    While having a GitHub account isn't necessary to work through this book, it is
    a good idea to create one, as it will serve as a portfolio for any data/coding
    projects. In addition, working with Git will provide a version control system
    and make collaboration easy.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的所有文件都可以在 GitHub 上找到：[https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition)。虽然不一定需要
    GitHub 账户来完成本书中的内容，但创建一个账户是个好主意，因为它可以作为任何数据/编程项目的作品集。此外，使用 Git 将提供一个版本控制系统，并使协作变得更容易。
- en: Tip
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: 'Check out this article to learn some Git basics: [https://www.freecodecamp.org/news/learn-the-basics-of-git-in-under-10-minutes-da548267cc91/](https://www.freecodecamp.org/news/learn-the-basics-of-git-in-under-10-minutes-da548267cc91/).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读这篇文章，了解一些 Git 基础：[https://www.freecodecamp.org/news/learn-the-basics-of-git-in-under-10-minutes-da548267cc91/](https://www.freecodecamp.org/news/learn-the-basics-of-git-in-under-10-minutes-da548267cc91/)。
- en: 'In order to get a local copy of the files, we have a few options (ordered from
    least useful to most useful):'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取文件的本地副本，我们有几个选项（按从最不实用到最实用的顺序排列）：
- en: Download the ZIP file and extract the files locally.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载 ZIP 文件并在本地解压文件。
- en: Clone the repository without forking it.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接克隆仓库，而不是先 fork。
- en: Fork the repository and then clone it.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先 fork 仓库然后克隆它。
- en: This book includes exercises for every chapter; therefore, for those who want
    to keep a copy of their solutions along with the original content on GitHub, it
    is highly recommended to **fork** the repository and **clone** the forked version.
    When we fork a repository, GitHub will make a repository under our own profile
    with the latest version of the original. Then, whenever we make changes to our
    version, we can push the changes back up. Note that if we simply clone, we don't
    get this benefit.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本书为每一章都提供了练习；因此，建议那些希望将自己的解答与原始内容一起保存在GitHub上的读者**fork**仓库并**克隆**fork后的版本。当我们fork一个仓库时，GitHub会在我们自己的个人资料下创建一个包含原始仓库最新版本的仓库。然后，任何时候我们对自己的版本做出更改，都可以将更改推送回去。请注意，如果我们只是克隆仓库，将无法享受到这一点。
- en: 'The relevant buttons for initiating this process are circled in the following
    screenshot:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 启动此过程的相关按钮在以下截图中已被圈出：
- en: '![Figure 1.1 – Getting a local copy of the code for following along'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.1 – 获取本地代码副本以便跟随](img/Figure_1.1_B16834.jpg)'
- en: '](img/Figure_1.1_B16834.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.1_B16834.jpg)'
- en: Figure 1.1 – Getting a local copy of the code for following along
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1 – 获取本地代码副本以便跟随
- en: Important note
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The cloning process will copy the files to the current working directory in
    a folder called `Hands-On-Data-Analysis-with-Pandas-2nd-edition`. To make a folder
    to put this repository in, we can use `mkdir my_folder && cd my_folder`. This
    will create a new folder (directory) called `my_folder` and then change the current
    directory to that folder, after which we can clone the repository. We can chain
    these two commands (and any number of commands) together by adding `&&` in between
    them. This can be thought of as *and then* (provided the first command succeeds).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 克隆过程将把文件复制到当前工作目录中的一个名为`Hands-On-Data-Analysis-with-Pandas-2nd-edition`的文件夹中。为了创建一个文件夹来放置这个仓库，我们可以使用`mkdir
    my_folder && cd my_folder`。这将创建一个名为`my_folder`的新文件夹（目录），然后将当前目录更改为该文件夹，之后我们就可以克隆仓库。我们可以通过在命令之间添加`&&`来将这两个命令（以及任何数量的命令）连接起来。这可以理解为*然后*（前提是第一个命令成功执行）。
- en: This repository has folders for each chapter. This chapter's materials can be
    found at [https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_01](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_01).
    While the bulk of this chapter doesn't involve any coding, feel free to follow
    along in the `introduction_to_data_analysis.ipynb` notebook on the GitHub website
    until we set up our environment toward the end of the chapter. After we do so,
    we will use the `check_your_environment.ipynb` notebook to get familiar with Jupyter
    Notebooks and to run some checks to make sure that everything is set up properly
    for the rest of this book.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这个仓库为每一章提供了文件夹。本章的材料可以在[https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_01](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_01)找到。虽然本章大部分内容不涉及编程，但你可以在GitHub网站上跟随`introduction_to_data_analysis.ipynb`笔记本，直到我们在本章末尾设置环境为止。设置完成后，我们将使用`check_your_environment.ipynb`笔记本来熟悉Jupyter笔记本并运行一些检查，确保一切都为本书的其余部分做好准备。
- en: Since the code that's used to generate the content in these notebooks is not
    the main focus of this chapter, the majority of it has been separated into the
    `visual_aids` package, which is used to create visuals for explaining concepts
    throughout the book, and the `check_environment.py` file. If you choose to inspect
    these files, don't be overwhelmed; everything that's relevant to data science
    will be covered in this book.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 由于用于生成这些笔记本内容的代码并不是本章的主要内容，因此大部分代码已被分离到`visual_aids`包中，该包用于创建视觉效果以便在本书中解释概念，还有`check_environment.py`文件。如果你选择查看这些文件，不必感到不知所措；本书将涵盖所有与数据科学相关的内容。
- en: 'Every chapter includes exercises; however, for this chapter only, there is
    an `exercises.ipynb` notebook, with code to generate some initial data. Knowledge
    of basic Python will be necessary to complete these exercises. For those who would
    like to review the basics, make sure to run through the `python_101.ipynb` notebook,
    included in the materials for this chapter, for a crash course. The official Python
    tutorial is a good place to start for a more formal introduction: [https://docs.python.org/3/tutorial/index.html](https://docs.python.org/3/tutorial/index.html).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 每一章都有练习；然而，仅此一章中有一个`exercises.ipynb`笔记本，其中包含生成一些初始数据的代码。完成这些练习需要具备基本的Python知识。对于想复习基础的读者，请确保运行本章材料中附带的`python_101.ipynb`笔记本，进行快速入门。对于更正式的介绍，官方的Python教程是一个很好的起点：[https://docs.python.org/3/tutorial/index.html](https://docs.python.org/3/tutorial/index.html)。
- en: The fundamentals of data analysis
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析基础
- en: 'Data analysis is a highly iterative process involving collection, preparation
    (wrangling), **exploratory data analysis** (**EDA**), and drawing conclusions.
    During an analysis, we will frequently revisit each of these steps. The following
    diagram depicts a generalized workflow:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析是一个高度迭代的过程，包括收集、准备（清洗）、**探索性数据分析**（**EDA**）和得出结论。在分析过程中，我们将频繁回顾这些步骤。下图展示了一个通用的工作流程：
- en: '![Figure 1.2 – The data analysis workflow'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.2 – 数据分析工作流程'
- en: '](img/Figure_1.2_B16834.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.2_B16834.jpg)'
- en: Figure 1.2 – The data analysis workflow
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 – 数据分析工作流程
- en: Over the next few sections, we will get an overview of each of these steps,
    starting with data collection. In practice, this process is heavily skewed toward
    the data preparation side. Surveys have found that although data scientists enjoy
    the data preparation side of their job the least, it makes up 80% of their work
    ([https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/)).
    This data preparation step is where `pandas` really shines.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将概述每个步骤，首先是数据收集。实际上，这个过程通常偏向于数据准备阶段。调查发现，尽管数据科学家最不喜欢数据准备工作，但它占据了他们80%的工作时间（[https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/)）。这一数据准备步骤正是`pandas`大放异彩的地方。
- en: Data collection
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据收集
- en: 'Data collection is the natural first step for any data analysis—we can''t analyze
    data we don''t have. In reality, our analysis can begin even before we have the
    data. When we decide what we want to investigate or analyze, we have to think
    about what kind of data we can collect that will be useful for our analysis. While
    data can come from anywhere, we will explore the following sources throughout
    this book:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集是任何数据分析的自然第一步——我们无法分析没有的数据。实际上，我们的分析可以在我们拥有数据之前就开始。当我们决定想要调查或分析什么时，我们必须考虑可以收集哪些对分析有用的数据。虽然数据可以来自任何地方，但在本书中我们将探讨以下几种数据来源：
- en: Web scraping to extract data from a website's HTML (often with Python packages
    such as `selenium`, `requests`, `scrapy`, and `beautifulsoup`)
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用网页抓取从网站的HTML中提取数据（通常使用Python包，如`selenium`、`requests`、`scrapy`和`beautifulsoup`）
- en: '`cURL` or the `requests` Python package)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cURL`或`requests` Python包'
- en: Databases (data can be extracted with SQL or another database-querying language)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库（可以通过SQL或其他数据库查询语言提取数据）
- en: Internet resources that provide data for download, such as government websites
    or Yahoo! Finance
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供数据下载的互联网资源，如政府网站或雅虎财经
- en: Log files
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志文件
- en: Important note
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要说明
- en: '[*Chapter 2*](B16834_02_Final_SK_ePub.xhtml#_idTextAnchor035), *Working with
    Pandas DataFrames*, will give us the skills we need to work with the aforementioned
    data sources. [*Chapter 12*](B16834_12_Final_SK_ePub.xhtml#_idTextAnchor254),
    *The Road Ahead*, provides numerous resources for finding data sources.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[*第二章*](B16834_02_Final_SK_ePub.xhtml#_idTextAnchor035)，*使用Pandas DataFrame*，将教会我们如何处理上述数据来源。[*第十二章*](B16834_12_Final_SK_ePub.xhtml#_idTextAnchor254)，*前方的道路*，提供了许多寻找数据源的资源。'
- en: We are surrounded by data, so the possibilities are limitless. It is important,
    however, to make sure that we are collecting data that will help us draw conclusions.
    For example, if we are trying to determine whether hot chocolate sales are higher
    when the temperature is lower, we should collect data on the amount of hot chocolate
    sold and the temperatures each day. While it might be interesting to see how far
    people traveled to get the hot chocolate, it's not relevant to our analysis.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们周围充满了数据，因此可能性是无限的。然而，重要的是要确保我们收集的数据有助于我们得出结论。例如，如果我们试图确定温度较低时热巧克力的销售量是否更高，我们应该收集每天售出的热巧克力数量和当天的温度数据。虽然了解人们为获取热巧克力旅行的距离可能很有趣，但这与我们的分析无关。
- en: Don't worry too much about finding the perfect data before beginning an analysis.
    Odds are, there will always be something we want to add/remove from the initial
    dataset, reformat, merge with other data, or change in some way. This is where
    data wrangling comes into play.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始分析之前，不要过于担心找到完美的数据。很可能，总会有一些我们想要从初始数据集中添加/删除、重新格式化、与其他数据合并或以某种方式更改的内容。这就是数据清理发挥作用的地方。
- en: Data wrangling
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据清理
- en: '**Data wrangling** is the process of preparing the data and getting it into
    a format that can be used for analysis. The unfortunate reality of data is that
    it is often dirty, meaning that it requires cleaning (preparation) before it can
    be used. The following are some issues we may encounter with our data:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据清理**是准备数据并将其转换为可以用于分析的格式的过程。数据的一个不幸现实是，它通常是“脏”的，这意味着在使用之前需要进行清理（准备）。以下是我们可能遇到的一些数据问题：'
- en: '`100` instead of `1000`, or typos. In addition, there may be multiple versions
    of the same entry recorded, such as `New York City`, `NYC`, and `nyc`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`100`而不是`1000`，或是打字错误。此外，可能会记录多个相同条目的版本，比如`New York City`、`NYC`和`nyc`。'
- en: '**Computer error**: Perhaps we weren''t recording entries for a while (missing
    data).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算机错误**：也许我们有一段时间没有记录条目（缺失数据）。'
- en: '**Unexpected values**: Maybe whoever was recording the data decided to use
    a question mark for a missing value in a numeric column, so now all the entries
    in the column will be treated as text instead of numeric values.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**意外值**：也许记录数据的人决定用问号表示数字列中的缺失值，这样该列中的所有条目就会被当作文本处理，而不是数字值。'
- en: '**Incomplete information**: Think of a survey with optional questions; not
    everyone will answer them, so we will have missing data, but not due to computer
    or human error.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息不完整**：想象一下一个带有可选问题的调查；并不是每个人都会回答这些问题，因此我们会有缺失数据，但这并非由于计算机或人为错误。'
- en: '**Resolution**: The data may have been collected per second, while we need
    hourly data for our analysis.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分辨率**：数据可能是按秒收集的，而我们需要按小时的数据来进行分析。'
- en: '**Relevance of the fields**: Often, data is collected or generated as a product
    of some process rather than explicitly for our analysis. In order to get it to
    a usable state, we will have to clean it up.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域的相关性**：通常，数据是作为某个过程的产物被收集或生成的，而不是专门为我们的分析而收集。为了将其转化为可用状态，我们需要对其进行清理。'
- en: '**Format of the data**: Data may be recorded in a format that isn''t conducive
    to analysis, which will require us to reshape it.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据的格式**：数据可能以不利于分析的格式记录，这需要我们对其进行重塑。'
- en: '**Misconfigurations in the data-recording process**: Data coming from sources
    such as misconfigured trackers and/or webhooks may be missing fields or passed
    in the wrong order.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据记录过程中的配置错误**：来自配置错误的跟踪器和/或Web钩子的数据可能会缺失字段或以错误的顺序传递。'
- en: Most of these data quality issues can be remedied, but some cannot, such as
    when the data is collected daily and we need it on an hourly resolution. It is
    our responsibility to carefully examine our data and handle any issues so that
    our analysis doesn't get distorted. We will cover this process in depth in [*Chapter
    3*](B16834_03_Final_SK_ePub.xhtml#_idTextAnchor061), *Data Wrangling with Pandas*,
    and [*Chapter 4*](B16834_04_Final_SK_ePub.xhtml#_idTextAnchor082), *Aggregating
    Pandas DataFrames*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据质量问题是可以解决的，但有些问题是无法解决的，比如当数据是按天收集的，而我们需要按小时的数据。这时，我们有责任仔细检查我们的数据，处理任何问题，以确保我们的分析不被扭曲。我们将在[*第3章*](B16834_03_Final_SK_ePub.xhtml#_idTextAnchor061)《使用Pandas的数据清理》和[*第4章*](B16834_04_Final_SK_ePub.xhtml#_idTextAnchor082)《Pandas数据框架的聚合》中详细讨论这个过程。
- en: 'Once we have performed an initial cleaning of the data, we are ready for EDA.
    Note that during EDA, we may need some additional data wrangling: these two steps
    are highly intertwined.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们对数据进行了初始清理，我们就准备好进行 EDA 了。请注意，在 EDA 过程中，我们可能需要一些额外的数据整理：这两个步骤是高度交织在一起的。
- en: Exploratory data analysis
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: During EDA, we use visualizations and summary statistics to get a better understanding
    of the data. Since the human brain excels at picking out visual patterns, data
    visualization is essential to any analysis. In fact, some characteristics of the
    data can only be observed in a plot. Depending on our data, we may create plots
    to see how a variable of interest has evolved over time, compare how many observations
    belong to each category, find outliers, look at distributions of continuous and
    discrete variables, and much more. In [*Chapter 5*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106),
    *Visualizing Data with Pandas and Matplotlib*, and [*Chapter 6*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125),
    *Plotting with Seaborn and Customization Techniques*, we will learn how to create
    these plots for both EDA and presentation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在 EDA 过程中，我们使用可视化和总结统计来更好地理解数据。由于人脑擅长发现视觉模式，数据可视化对于任何分析都是至关重要的。事实上，某些数据的特征只能在图表中观察到。根据我们的数据，我们可能创建图表来查看感兴趣的变量随时间的变化情况，比较每个类别包含多少观察结果，查找异常值，查看连续和离散变量的分布等等。在[*第5章*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106)，*使用
    Pandas 和 Matplotlib 可视化数据*，以及[*第6章*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125)，*使用
    Seaborn 和自定义技术绘图*，我们将学习如何为 EDA 和演示创建这些图表。
- en: Important note
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Data visualizations are very powerful; unfortunately, they can often be misleading.
    One common issue stems from the scale of the *y*-axis because most plotting tools
    will zoom in by default to show the pattern up close. It would be difficult for
    software to know what the appropriate axis limits are for every possible plot;
    therefore, it is our job to properly adjust the axes before presenting our results.
    You can read about some more ways that plots can be misleading at [https://venngage.com/blog/misleading-graphs/](https://venngage.com/blog/misleading-graphs/).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可视化非常强大；不幸的是，它们经常会误导。一个常见问题源于*y*轴的刻度，因为大多数绘图工具默认会放大以展示近距离的模式。软件很难知道每种可能图形的合适轴限制；因此，在展示结果之前，我们的工作是适当调整坐标轴。您可以阅读更多有关图表可能误导的方法，详见[https://venngage.com/blog/misleading-graphs/](https://venngage.com/blog/misleading-graphs/)。
- en: 'In the workflow diagram we saw earlier (*Figure 1.2*), EDA and data wrangling
    shared a box. This is because they are closely tied:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前看到的工作流程图（*图1.2*）中，EDA 和数据整理共享一个框。这是因为它们密切相关：
- en: Data needs to be prepped before EDA.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在进行 EDA 之前，数据需要准备好。
- en: Visualizations that are created during EDA may indicate the need for additional
    data cleaning.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 EDA 过程中创建的可视化可能表明需要进行额外的数据清理。
- en: Data wrangling uses summary statistics to look for potential data issues, while
    EDA uses them to understand the data. Improper cleaning will distort the findings
    when we're conducting EDA. In addition, data wrangling skills will be required
    to get summary statistics across subsets of the data.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据整理使用总结统计来查找潜在的数据问题，而 EDA 则用于理解数据。当我们进行 EDA 时，不正确的清理将扭曲研究结果。此外，需要数据整理技能来跨数据子集获取总结统计。
- en: When calculating summary statistics, we must keep the type of data we collected
    in mind. Data can be **quantitative** (measurable quantities) or **categorical**
    (descriptions, groupings, or categories). Within these classes of data, we have
    further subdivisions that let us know what types of operations we can perform
    on them.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算总结统计时，我们必须牢记我们收集到的数据类型。数据可以是**定量**的（可测量的数量）或**分类**的（描述、分组或类别）。在这些数据类别中，我们有进一步的细分，可以让我们知道可以在其上执行哪些操作。
- en: For example, categorical data can be `on = 1`/`off = 0`. Note that the fact
    that `on` is greater than `off` is meaningless because we arbitrarily chose those
    numbers to represent the states `on` and `off`. When there is a ranking among
    the categories, they are `low < medium < high`).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，分类数据可以是 `on = 1` / `off = 0`。请注意，`on` 大于 `off` 的事实是没有意义的，因为我们任意选择这些数字来表示
    `on` 和 `off` 的状态。当类别之间有排名时，它们是 `low < medium < high`。
- en: Quantitative data can use an **interval scale** or a **ratio scale**. The interval
    scale includes things such as temperature. We can measure temperatures in Celsius
    and compare the temperatures of two cities, but it doesn't mean anything to say
    one city is twice as hot as the other. Therefore, interval scale values can be
    meaningfully compared using addition/subtraction, but not multiplication/division.
    The ratio scale, then, are those values that can be meaningfully compared with
    ratios (using multiplication and division). Examples of the ratio scale include
    prices, sizes, and counts.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 定量数据可以使用**区间尺度**或**比例尺度**。区间尺度包括像温度这样的量。我们可以用摄氏度来测量温度，并比较两个城市的温度，但说一个城市的温度是另一个城市的两倍并没有意义。因此，区间尺度的值可以通过加法/减法进行有意义的比较，但不能通过乘法/除法进行比较。比例尺度则是那些可以通过比率（乘法和除法）进行有意义比较的值。例如，价格、大小和数量都属于比例尺度。
- en: When we complete our EDA, we can decide on the next steps by drawing conclusions.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 完成EDA后，我们可以通过得出结论来决定接下来的步骤。
- en: Drawing conclusions
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 得出结论
- en: 'After we have collected the data for our analysis, cleaned it up, and performed
    some thorough EDA, it is time to draw conclusions. This is where we summarize
    our findings from EDA and decide the next steps:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们收集了分析所需的数据、清理了数据并进行了深入的EDA（探索性数据分析）之后，就到了得出结论的阶段。这时，我们总结EDA中的发现，并决定接下来的步骤：
- en: Did we notice any patterns or relationships when visualizing the data?
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可视化数据时，我们是否注意到了任何模式或关系？
- en: Does it look like we can make accurate predictions from our data? Does it make
    sense to move to modeling the data?
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否可以从数据中做出准确的预测？继续对数据进行建模是否有意义？
- en: Should we handle missing data points? How?
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否需要处理缺失的数据点？如何处理？
- en: How is the data distributed?
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的分布情况如何？
- en: Does the data help us answer the questions we have or give insight into the
    problem we are investigating?
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是否能帮助我们回答问题或为我们正在调查的问题提供洞察？
- en: Do we need to collect new or additional data?
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否需要收集新的或额外的数据？
- en: If we decide to model the data, this falls under machine learning and statistics.
    While not technically data analysis, it is usually the next step, and we will
    cover it in [*Chapter 9*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188), *Getting
    Started with Machine Learning in Python*, and [*Chapter 10*](B16834_10_Final_SK_ePub.xhtml#_idTextAnchor217),
    *Making Better Predictions – Optimizing Models*. In addition, we will see how
    this entire process will work in practice in [*Chapter 11*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237),
    *Machine Learning Anomaly Detection*. As a reference, in the *Machine learning
    workflow* section in the *Appendix*, there is a workflow diagram depicting the
    full process from data analysis to machine learning. [*Chapter 7*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146),
    *Financial Analysis – Bitcoin and the Stock Market*, and [*Chapter 8*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172),
    *Rule-Based Anomaly Detection*, will focus on drawing conclusions from data analysis,
    rather than building models.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们决定对数据进行建模，这将涉及到机器学习和统计学。虽然严格来说，这不属于数据分析范畴，但通常是下一步，我们将在[*第9章*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188)，*Python中的机器学习入门*，和[*第10章*](B16834_10_Final_SK_ePub.xhtml#_idTextAnchor217)，*做出更好的预测——优化模型*中讨论。此外，我们将在[*第11章*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237)，*机器学习异常检测*中看到这个过程在实践中的应用。作为参考，*附录*中的*机器学习工作流*部分提供了一张完整的工作流图，展示了从数据分析到机器学习的全过程。[*第7章*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146)，*金融分析——比特币与股市*，和[*第8章*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172)，*基于规则的异常检测*，将集中讨论从数据分析中得出结论，而不是构建模型。
- en: The next section will be a review of statistics; those with knowledge of statistics
    can skip ahead to the *Setting up a virtual environment* section.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将回顾统计学内容；有统计学基础的读者可以跳过并直接阅读*设置虚拟环境*部分。
- en: Statistical foundations
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计学基础
- en: When we want to make observations about the data we are analyzing, we often,
    if not always, turn to statistics in some fashion. The data we have is referred
    to as the **sample**, which was observed from (and is a subset of) the **population**.
    Two broad categories of statistics are descriptive and inferential statistics.
    With **descriptive statistics**, as the name implies, we are looking to *describe*
    the sample. **Inferential statistics** involves using the sample statistics to
    *infer*, or deduce, something about the population, such as the underlying distribution.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要对所分析的数据做出观察时，我们常常（如果不是总是的话）以某种方式借助统计学。我们所拥有的数据被称为**样本**，它是从（并且是）**总体**中观察到的一个子集。统计学有两大类：描述性统计和推断性统计。通过**描述性统计**，顾名思义，我们的目的是*描述*样本。**推断性统计**则是利用样本统计量来*推断*或推测有关总体的某些信息，比如潜在的分布情况。
- en: Important note
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Sample statistics are used as **estimators** of the population parameters, meaning
    that we have to quantify their bias and variance. There is a multitude of methods
    for this; some will make assumptions on the shape of the distribution (parametric)
    and others won't (non-parametric). This is all well beyond the scope of this book,
    but it is good to be aware of.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 样本统计量被用作总体参数的**估计量**，这意味着我们必须量化它们的偏差和方差。对此有多种方法；一些方法会对分布的形状做出假设（参数法），而另一些则不会（非参数法）。这些内容远远超出了本书的范围，但了解它们是有益的。
- en: 'Often, the goal of an analysis is to create a story for the data; unfortunately,
    it is very easy to misuse statistics. It''s the subject of a famous quote:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，分析的目标是为数据创造一个故事；不幸的是，统计数据非常容易被误用。这正是某句名言的主题：
- en: '"There are three kinds of lies: lies, damned lies, and statistics."'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '"有三种谎言：谎言、可恶的谎言和统计数据。"'
- en: — Benjamin Disraeli
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: — 本杰明·迪斯雷利
- en: This is especially true of inferential statistics, which is used in many scientific
    studies and papers to show the significance of the researchers' findings. This
    is a more advanced topic and, since this isn't a statistics book, we will only
    briefly touch upon some of the tools and principles behind inferential statistics,
    which can be pursued further. We will focus on descriptive statistics to help
    explain the data we are analyzing.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这在推断性统计中尤为突出，推断性统计在许多科学研究和论文中用于展示研究者发现的显著性。这是一个更为高级的话题，因为本书并非统计学书籍，我们将仅简要介绍推断性统计背后的一些工具和原理，读者可以进一步深入学习。我们将专注于描述性统计，帮助解释我们正在分析的数据。
- en: Sampling
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 抽样
- en: 'There''s an important thing to remember before we attempt any analysis: our
    sample must be a **random sample** that is representative of the population. This
    means that the data must be sampled without bias (for example, if we are asking
    people whether they like a certain sports team, we can''t only ask fans of the
    team) and that we should have (ideally) members of all distinct groups from the
    population in our sample (in the sports team example, we can''t just ask men).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们尝试进行任何分析之前，有一个重要的事情需要记住：我们的样本必须是**随机样本**，且能够代表总体。这意味着数据必须是无偏采样的（例如，如果我们在询问人们是否喜欢某个体育队，我们不能只问该队的球迷），同时我们应该确保样本中包含（理想情况下）总体中所有不同群体的成员（在体育队的例子中，我们不能只问男性）。
- en: 'When we discuss machine learning in [*Chapter 9*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188),
    *Getting Started with Machine Learning in Python*, we will need to sample our
    data, which will be a sample to begin with. This is called **resampling**. Depending
    on the data, we will have to pick a different method of sampling. Often, our best
    bet is a **simple random sample**: we use a random number generator to pick rows
    at random. When we have distinct groups in the data, we want our sample to be
    a **stratified random sample**, which will preserve the proportion of the groups
    in the data. In some cases, we don''t have enough data for the aforementioned
    sampling strategies, so we may turn to random sampling with replacement (**bootstrapping**);
    this is called a **bootstrap sample**. Note that our underlying sample needs to
    have been a random sample or we risk increasing the bias of the estimator (we
    could pick certain rows more often because they are in the data more often if
    it was a convenience sample, while in the true population these rows aren''t as
    prevalent). We will see an example of bootstrapping in [*Chapter 8*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172),
    *Rule-Based Anomaly Detection*.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论在[*第9章*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188)中关于机器学习的内容时，*在Python中入门机器学习*，我们需要对数据进行抽样，而数据本身就是一个初步的样本。这称为**重采样**。根据数据的不同，我们需要选择不同的抽样方法。通常，我们最好的选择是**简单随机抽样**：我们使用随机数生成器随机挑选行。当数据中有不同的组时，我们希望我们的样本是**分层随机抽样**，这种方法会保持数据中各组的比例。在某些情况下，我们没有足够的数据来使用上述的抽样策略，因此我们可能会采用有放回的随机抽样（**自助法**）；这称为**自助样本**。请注意，我们的基础样本需要是随机样本，否则我们可能会增加估计量的偏差（如果是便利样本，由于某些行在数据中出现的频率较高，我们可能会更频繁地选择这些行，但在真实的总体中，这些行的出现频率可能没有那么高）。我们将在[*第8章*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172)中看到自助法的一个例子，*基于规则的异常检测*。
- en: Important note
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'A thorough discussion of the theory behind bootstrapping and its consequences
    is well beyond the scope of this book, but watch this video for a primer: [https://www.youtube.com/watch?v=gcPIyeqymOU](https://www.youtube.com/watch?v=gcPIyeqymOU).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论自助法背后的理论及其后果远远超出了本书的范围，但可以通过观看这个视频来了解基本概念：[https://www.youtube.com/watch?v=gcPIyeqymOU](https://www.youtube.com/watch?v=gcPIyeqymOU)。
- en: You can read more about sampling methods, along with their strengths and weaknesses,
    at [https://www.khanacademy.org/math/statistics-probability/designing-studies/sampling-methods-stats/a/sampling-methods-review](https://www.khanacademy.org/math/statistics-probability/designing-studies/sampling-methods-stats/a/sampling-methods-review).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://www.khanacademy.org/math/statistics-probability/designing-studies/sampling-methods-stats/a/sampling-methods-review](https://www.khanacademy.org/math/statistics-probability/designing-studies/sampling-methods-stats/a/sampling-methods-review)阅读更多关于抽样方法的信息，以及它们的优缺点。
- en: Descriptive statistics
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述性统计
- en: We will begin our discussion of descriptive statistics with **univariate statistics**;
    univariate simply means that these statistics are calculated from one (**uni**)
    variable. Everything in this section can be extended to the whole dataset, but
    the statistics will be calculated per variable we are recording (meaning that
    if we had 100 observations of speed and distance pairs, we could calculate the
    averages across the dataset, which would give us the average speed and average
    distance statistics).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从描述性统计的**单变量统计**开始讨论；单变量意味着这些统计量是从一个（**单**）变量计算出来的。本节中的所有内容都可以扩展到整个数据集，但统计量将是按我们记录的每个变量来计算的（意味着如果我们有100个速度和距离的配对观测值，我们可以计算整个数据集的平均值，这将给出平均速度和平均距离的统计数据）。
- en: Descriptive statistics are used to describe and/or summarize the data we are
    working with. We can start our summarization of the data with a measure of **central
    tendency**, which describes where most of the data is centered around, and a measure
    of **spread** or **dispersion**, which indicates how far apart values are.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 描述性统计用于描述和/或总结我们正在处理的数据。我们可以通过**集中趋势**的度量开始数据的总结，它描述了大多数数据集中在哪个区域，并且通过**离散度**或**分散度**的度量来表示数据值的分布范围。
- en: Measures of central tendency
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集中趋势的度量
- en: 'Measures of central tendency describe the center of our distribution of data.
    There are three common statistics that are used as measures of center: mean, median,
    and mode. Each has its own strengths, depending on the data we are working with.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 集中趋势的度量描述了我们数据分布的中心位置。有三种常用的统计量作为中心的度量：均值、中位数和众数。每种方法都有其独特的优点，取决于我们处理的数据类型。
- en: Mean
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 均值
- en: 'Perhaps the most common statistic for summarizing data is the average, or `(0
    + 1 + 1 + 2 + 9)/5`):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 也许最常见的用于总结数据的统计量是平均值，或`(0 + 1 + 1 + 2 + 9)/5`：
- en: '![](img/B16834_01_002.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16834_01_002.jpg)'
- en: We use *x*i to represent the *i*thobservation of the variable *X*. Note how
    the variable as a whole is represented with a capital letter, while the specific
    observation is lowercase. *Σ* (the Greek capital letter *sigma*) is used to represent
    a summation, which, in the equation for the mean, goes from *1* to *n*, which
    is the number of observations.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用*x*i来表示变量*X*的第*i*个观察值。注意，变量本身用大写字母表示，而具体的观察值则用小写字母表示。*Σ*（希腊大写字母*Sigma*）用于表示求和，在均值的公式中，它的求和范围从*1*到*n*，其中*n*是观察值的数量。
- en: One important thing to note about the mean is that it is very sensitive to **outliers**
    (values created by a different generative process than our distribution). In the
    previous example, we were dealing with only five values; nevertheless, the 9 is
    much larger than the other numbers and pulled the mean higher than all but the
    9\. In cases where we suspect outliers to be present in our data, we may want
    to instead use the median as our measure of central tendency.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 关于均值，有一点需要注意，那就是它对**异常值**（由与我们分布不同的生成过程产生的值）非常敏感。在前面的例子中，我们只处理了五个数据值；然而，9远大于其他数字，并把均值拉高了，几乎比除了9以外的所有值都要高。在我们怀疑数据中存在异常值时，可能更倾向于使用中位数作为我们的集中趋势度量。
- en: Median
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 中位数
- en: Unlike the mean, the **median** is robust to outliers. Consider income in the
    US; the top 1% is much higher than the rest of the population, so this will skew
    the mean to be higher and distort the perception of the average person's income.
    However, the median will be more representative of the average income because
    it is the 50th percentile of our data; this means that 50% of the values are greater
    than the median and 50% are less than the median.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 与均值不同，**中位数**对异常值具有较强的鲁棒性。以美国的收入为例；最高的1%收入远高于其他人群，这会使均值偏高，从而扭曲对平均收入的认知。然而，中位数能更好地代表平均收入，因为它是我们数据的第50百分位数；这意味着50%的数据值大于中位数，50%的数据值小于中位数。
- en: Tip
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: The *i*th percentile is the value at which *i*% of the observations are less
    than that value, so the 99th percentile is the value in *X* where 99% of the *x*'s
    are less than it.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*i*百分位数是指数据中有*i*%的观察值小于该值，因此99百分位数是*X*中的值，表示99%的*x*小于它。'
- en: The median is calculated by taking the middle value from an ordered list of
    values; in cases where we have an even number of values, we take the mean of the
    middle two values. If we take the numbers 0, 1, 1, 2, and 9 again, our median
    is 1\. Notice that the mean and median for this dataset are different; however,
    depending on the distribution of the data, they may be the same.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 中位数是通过从一个有序数列中取中间值来计算的；如果数据的个数是偶数，则取中间两个值的平均值。如果我们再次使用数字0、1、1、2和9，那么我们的中位数是1。请注意，这个数据集的均值和中位数是不同的；然而，取决于数据的分布，它们可能是相同的。
- en: Mode
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 众数
- en: 'The **mode** is the most common value in the data (if we, once again, have
    the numbers 0, 1, 1, 2, and 9, then 1 is the mode). In practice, we will often
    hear things such as *the distribution is bimodal or multimodal* (as opposed to
    unimodal) in cases where the distribution has two or more most popular values.
    This doesn''t necessarily mean that each of them occurred the same amount of times,
    but rather, they are more common than the other values by a significant amount.
    As shown in the following plots, a unimodal distribution has only one mode (at
    **0**), a bimodal distribution has two (at **-2** and **3**), and a multimodal
    distribution has many (at **-2**, **0.4**, and **3**):'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**众数**是数据中最常见的值（如果我们再次使用数字0、1、1、2和9，那么1就是众数）。在实践中，我们常常会听到类似“分布是双峰的或多峰的”（与单峰分布相对）的说法，这表示数据的分布有两个或更多的最常见值。这并不一定意味着它们每个出现的次数相同，而是它们比其他值的出现次数显著多。如下面的图所示，单峰分布只有一个众数（位于**0**），双峰分布有两个众数（分别位于**-2**和**3**），而多峰分布有多个众数（分别位于**-2**、**0.4**和**3**）：'
- en: '![Figure 1.3 – Visualizing the mode with continuous data'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.3 – 可视化连续数据的众数'
- en: '](img/Figure_1.3_B16834.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.3_B16834.jpg)'
- en: Figure 1.3 – Visualizing the mode with continuous data
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – 可视化连续数据的众数
- en: Understanding the concept of the mode comes in handy when describing continuous
    distributions; however, most of the time when we're describing our continuous
    data, we will use either the mean or the median as our measure of central tendency.
    When working with categorical data, on the other hand, we will typically use the
    mode.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 理解众数的概念在描述连续分布时非常有用；然而，在大多数情况下，当我们描述连续数据时，我们会使用均值或中位数作为中心趋势的度量。而在处理分类数据时，我们通常会使用众数。
- en: Measures of spread
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分散度的度量
- en: Knowing where the center of the distribution is only gets us partially to being
    able to summarize the distribution of our data—we need to know how values fall
    around the center and how far apart they are. Measures of spread tell us how the
    data is dispersed; this will indicate how thin (low dispersion) or wide (very
    spread out) our distribution is. As with measures of central tendency, we have
    several ways to describe the spread of a distribution, and which one we choose
    will depend on the situation and the data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 知道分布的中心在哪里，只是帮助我们部分总结数据分布——我们还需要知道数据如何围绕中心分布，以及它们之间的距离有多远。分散度的度量告诉我们数据的分布情况；这将指示我们的分布是狭窄（低分散）还是宽广（分布很广）。与中心趋势的度量一样，我们有多种方式来描述分布的分散度，选择哪种方式取决于情况和数据。
- en: Range
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 范围
- en: 'The **range** is the distance between the smallest value (**minimum**) and
    the largest value (**maximum**). The units of the range will be the same units
    as our data. Therefore, unless two distributions of data are in the same units
    and measuring the same thing, we can''t compare their ranges and say one is more
    dispersed than the other:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**范围**是最小值（**最小值**）和最大值（**最大值**）之间的距离。范围的单位与数据的单位相同。因此，除非两个数据分布的单位相同且测量的是相同的事物，否则我们不能比较它们的范围并说一个比另一个更分散：'
- en: '![](img/B16834_01_003.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16834_01_003.jpg)'
- en: Just from the definition of the range, we can see why it wouldn't always be
    the best way to measure the spread of our data. It gives us upper and lower bounds
    on what we have in the data; however, if we have any outliers in our data, the
    range will be rendered useless.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 从范围的定义中，我们可以看出，为什么它并不总是衡量数据分散度的最佳方式。它给出了数据的上下界限；然而，如果数据中存在异常值，范围就会变得没有意义。
- en: Another problem with the range is that it doesn't tell us how the data is dispersed
    around its center; it really only tells us how dispersed the entire dataset is.
    This brings us to the variance.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关于范围的问题是，它没有告诉我们数据如何在其中心周围分散；它实际上只是告诉我们整个数据集的分散程度。这就引出了方差的问题。
- en: Variance
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 方差
- en: The **variance** describes how far apart observations are spread out from their
    average value (the mean). The population variance is denoted as *σ*2 (pronounced
    *sigma-squared*), and the sample variance is written as *s*2\. It is calculated
    as the average squared distance from the mean. Note that the distances must be
    squared so that distances below the mean don't cancel out those above the mean.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**方差**描述了观察值与其平均值（均值）之间的分散程度。总体方差表示为*σ*²（读作*西格玛平方*），样本方差表示为*s*²。它是通过计算离均值的平均平方距离来得出的。注意，必须对这些距离进行平方，这样均值以下的距离就不会与均值以上的距离相互抵消。'
- en: 'If we want the sample variance to be an unbiased estimator of the population
    variance, we divide by *n - 1* instead of *n* to account for using the sample
    mean instead of the population mean; this is called Bessel''s correction ([https://en.wikipedia.org/wiki/Bessel%27s_correction](https://en.wikipedia.org/wiki/Bessel%27s_correction)).
    Most statistical tools will give us the sample variance by default, since it is
    *very* rare that we would have data for the entire population:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望样本方差成为总体方差的无偏估计量，我们需要除以*n - 1*而不是*n*，以弥补使用样本均值而非总体均值的偏差；这就是贝塞尔修正（[https://en.wikipedia.org/wiki/Bessel%27s_correction](https://en.wikipedia.org/wiki/Bessel%27s_correction)）。大多数统计工具默认会给出样本方差，因为获取整个总体的数据是*非常*罕见的：
- en: '![](img/B16834_01_004.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16834_01_004.jpg)'
- en: The variance gives us a statistic with *squared* units. This means that if we
    started with data on income in dollars ($), then our variance would be in dollars
    squared ($2). This isn't really useful when we're trying to see how this describes
    the data; we can use the **magnitude** (size) itself to see how spread out something
    is (large values = large spread), but beyond that, we need a measure of spread
    with units that are the same as our data. For this purpose, we use the standard
    deviation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 方差给我们提供了一个带有*平方*单位的统计量。这意味着，如果我们从以美元（$）表示的收入数据开始，那么我们的方差将是以美元平方（$²）为单位的。当我们试图了解数据的分布时，这并不十分有用；我们可以使用**幅度**（大小）本身来查看某个事物的分布情况（大值
    = 大范围），但除此之外，我们需要一个单位与数据相同的分布度量。为此，我们使用标准差。
- en: Standard deviation
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 标准差
- en: 'We can use the **standard deviation** to see how far from the mean data points
    are *on average*. A small standard deviation means that values are close to the
    mean, while a large standard deviation means that values are dispersed more widely.
    This is tied to how we would imagine the distribution curve: the smaller the standard
    deviation, the thinner the peak of the curve (**0.5**); the larger the standard
    deviation, the wider the peak of the curve (**2**):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用**标准差**来查看数据点离均值有多远，*平均而言*。小的标准差意味着值接近均值，而大的标准差意味着值分散得更广。这与我们想象的分布曲线有关：标准差越小，曲线的峰值越窄（**0.5**）；标准差越大，曲线的峰值越宽（**2**）：
- en: '![Figure 1.4 – Using standard deviation to quantify the spread of a distribution'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.4 – 使用标准差来量化分布的扩散'
- en: '](img/Figure_1.4_B16834.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.4_B16834.jpg)'
- en: Figure 1.4 – Using standard deviation to quantify the spread of a distribution
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 – 使用标准差来量化分布的扩散
- en: 'The standard deviation is simply the square root of the variance. By performing
    this operation, we get a statistic in units that we can make sense of again ($
    for our income example):'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 标准差仅仅是方差的平方根。通过执行这个操作，我们得到的统计量使用的单位可以让我们再次理解（以收入为例，使用$作为单位）：
- en: '![](img/B16834_01_005.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16834_01_005.jpg)'
- en: Note that the population standard deviation is represented as *σ*, and the sample
    standard deviation is denoted as *s*.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，人口标准差用*σ*表示，样本标准差用*s*表示。
- en: Coefficient of variation
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 变异系数
- en: 'When we moved from variance to standard deviation, we were looking to get to
    units that made sense; however, if we then want to compare the level of dispersion
    of one dataset to another, we would need to have the same units once again. One
    way around this is to calculate the **coefficient of variation** (**CV**), which
    is unitless. The CV is the ratio of the standard deviation to the mean:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们从方差转到标准差时，我们的目的是得到一个更具意义的单位；然而，如果我们想将一个数据集的分散度与另一个数据集进行比较，我们需要再次使用相同的单位。解决这一问题的一种方法是计算**变异系数**（**CV**），它是无单位的。变异系数是标准差与均值的比值：
- en: '![](img/B16834_01_006.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16834_01_006.jpg)'
- en: We will use this metric in [*Chapter 7*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146),
    *Financial Analysis – Bitcoin and the Stock Market*; since the CV is unitless,
    we can use it to compare the volatility of different assets.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第7章*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146)《金融分析——比特币与股市》中使用这个指标；由于变异系数是无单位的，我们可以用它来比较不同资产的波动性。
- en: Interquartile range
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 四分位距
- en: So far, other than the range, we have discussed mean-based measures of dispersion;
    now, we will look at how we can describe the spread with the median as our measure
    of central tendency. As mentioned earlier, the median is the 50th percentile or
    the 2nd **quartile** (Q2). Percentiles and quartiles are both **quantiles**—values
    that divide data into equal groups each containing the same percentage of the
    total data. Percentiles divide the data into 100 parts, while quartiles do so
    into four (25%, 50%, 75%, and 100%).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，除了范围，我们讨论了基于均值的分散度量；现在，我们将探讨如何使用中位数作为集中趋势的度量来描述数据的扩散。如前所述，中位数是第50百分位数或第2**四分位数**（Q2）。百分位数和四分位数都是**分位数**——将数据划分为包含相同比例数据的相等组的值。百分位数将数据分成100个部分，而四分位数将其分成四个部分（25%、50%、75%和100%）。
- en: 'Since quantiles neatly divide up our data, and we know how much of the data
    goes in each section, they are a perfect candidate for helping us quantify the
    spread of our data. One common measure for this is the **interquartile range**
    (**IQR**), which is the distance between the 3rd and 1st quartiles:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 由于分位数整齐地划分了数据，并且我们知道每个部分中有多少数据，它们是帮助我们量化数据分布的理想选择。一个常见的度量是**四分位距**（**IQR**），即第三四分位数和第一四分位数之间的距离：
- en: '![](img/B16834_01_007.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16834_01_007.jpg)'
- en: The IQR gives us the spread of data around the median *and* quantifies how much
    dispersion we have in the middle 50% of our distribution. It can also be useful
    when checking the data for outliers, which we will cover in [*Chapter 8*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172),
    *Rule-Based Anomaly Detection*. In addition, the IQR can be used to calculate
    a unitless measure of dispersion, which we will discuss next.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: IQR给出了围绕中位数的数据显示的分布*并且*量化了分布中50%数据的离散度。当检查数据是否存在异常值时，它也很有用，我们将在[*第8章*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172)中讨论，“基于规则的异常检测”。此外，IQR可以用来计算一个无单位的离散度度量，我们接下来会讨论。
- en: Quartile coefficient of dispersion
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 四分位数离散系数
- en: 'Just like we had the coefficient of variation when using the mean as our measure
    of central tendency, we have the **quartile coefficient of dispersion** when using
    the median as our measure of center. This statistic is also unitless, so it can
    be used to compare datasets. It is calculated by dividing the **semi-quartile
    range** (half the IQR) by the **midhinge** (midpoint between the first and third
    quartiles):'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 就像当我们使用均值作为中心趋向度时会有变异系数一样，当我们使用中位数作为中心度量时，也有**四分位离散系数**。这个统计量也是无单位的，因此可以用来比较不同的数据集。它通过将**半四分位距**（IQR的一半）除以**中位数**（第一四分位数和第三四分位数之间的中点）来计算：
- en: '![](img/B16834_01_008.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16834_01_008.jpg)'
- en: We will see this metric again in [*Chapter 7*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146),
    *Financial Analysis – Bitcoin and the Stock Market*, when we assess stock volatility.
    For now, let's take a look at how we can use measures of central tendency and
    dispersion to summarize our data.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第7章*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146)，“金融分析——比特币与股市”中再次看到这个度量，当时我们会评估股票的波动性。现在，让我们看看如何使用中心趋向度和离散度度量来总结数据。
- en: Summarizing data
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结数据
- en: 'We have seen many examples of descriptive statistics that we can use to summarize
    our data by its center and dispersion; in practice, looking at the **5-number
    summary** and visualizing the distribution prove to be helpful first steps before
    diving into some of the other aforementioned metrics. The 5-number summary, as
    its name indicates, provides five descriptive statistics that summarize our data:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了许多可以用来通过数据的中心和离散度来总结数据的描述性统计量；实际上，在深入一些其他前述的度量指标之前，查看**5数概括**并可视化分布被证明是有帮助的第一步。正如其名称所示，5数概括提供了五个描述性统计量来总结我们的数据：
- en: '![Figure 1.5 – The 5-number summary'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.5 – 5数概括'
- en: '](img/Figure_1.5_B16834.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.5_B16834.jpg)'
- en: Figure 1.5 – The 5-number summary
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5 – 5数概括
- en: 'A **box plot** (or box and whisker plot) is a visual representation of the
    5-number summary. The median is denoted by a thick line in the box. The top of
    the box is Q3 and the bottom of the box is Q1\. Lines (whiskers) extend from both
    sides of the box boundaries toward the minimum and maximum. Based on the convention
    our plotting tool uses, though, they may only extend to a certain statistic; any
    values beyond these statistics are marked as outliers (using points). For this
    book in general, the lower bound of the whiskers will be **Q**1 **– 1.5 * IQR**
    and the upper bound will be **Q**3 **+ 1.5 * IQR**, which is called the **Tukey
    box plot**:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**箱型图**（或称箱线图）是5数概括的可视化表示。中位数用盒子中的粗线表示。盒子的顶部是Q3，底部是Q1。盒子两侧的线（胡须）延伸到最小值和最大值。根据我们绘图工具使用的约定，尽管如此，它们可能只延伸到某个统计量；任何超出这些统计量的值都被标记为异常值（使用点表示）。对于本书而言，胡须的下界为**Q**1
    **– 1.5 * IQR**，上界为**Q**3 **+ 1.5 * IQR**，这被称为**Tukey箱型图**：'
- en: '![Figure 1.6 – The Tukey box plot'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.6 – Tukey箱型图'
- en: '](img/Figure_1.6_B16834.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.6_B16834.jpg)'
- en: Figure 1.6 – The Tukey box plot
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – Tukey箱型图
- en: While the box plot is a great tool for getting an initial understanding of the
    distribution, we don't get to see how things are distributed inside each of the
    quartiles. For this purpose, we turn to **histograms** for **discrete** variables
    (for instance, the number of people or books) and **kernel density estimates**
    (**KDEs**) for **continuous** variables (for instance, heights or time). There
    is nothing stopping us from using KDEs on discrete variables, but it is easy to
    confuse people that way. Histograms work for both discrete and continuous variables;
    however, in both cases, we must keep in mind that the number of bins we choose
    to divide the data into can easily change the shape of the distribution we see.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然箱型图是了解数据分布的一个很好的工具，但它不能显示每个四分位数内部的分布情况。为了这个目的，我们使用**直方图**来处理**离散**变量（例如：人数或书籍数量），使用**核密度估计**（**KDEs**）来处理**连续**变量（例如：身高或时间）。虽然我们可以在离散变量上使用KDE，但这容易让人产生混淆。直方图适用于离散和连续变量；然而，在这两种情况下，我们必须记住，选择的分箱数量会轻易改变我们看到的分布形状。
- en: 'To make a histogram, a certain number of equal-width bins are created, and
    then bars with heights for the number of values we have in each bin are added.
    The following plot is a histogram with 10 bins, showing the three measures of
    central tendency for the same data that was used to generate the box plot in *Figure
    1.6*:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 制作直方图时，会创建若干个等宽的分箱，并为每个分箱的值添加相应高度的条形。以下图为一个具有10个分箱的直方图，展示了与*图1.6*中生成箱型图的数据相同的三个中心趋势度量：
- en: '![Figure 1.7 – Example histogram'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.7 – 直方图示例'
- en: '](img/Figure_1.7_B16834.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.7_B16834.jpg)'
- en: Figure 1.7 – Example histogram
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7 – 直方图示例
- en: Important note
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In practice, we need to play around with the number of bins to find the best
    value. However, we have to be careful as this can misrepresent the shape of the
    distribution.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 实际操作中，我们需要调整分箱数量以找到最佳值。然而，我们必须小心，因为这可能会误导分布的形状。
- en: 'KDEs are similar to histograms, except rather than creating bins for the data,
    they draw a smoothed curve, which is an estimate of the distribution''s **probability
    density function** (**PDF**). The PDF is for continuous variables and tells us
    how probability is distributed over the values. Higher values for the PDF indicate
    higher likelihoods:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: KDE类似于直方图，不同之处在于，KDE不是为数据创建分箱，而是绘制一个平滑的曲线，它是分布**概率密度函数**（**PDF**）的估计。PDF适用于连续变量，并告诉我们概率在各个值之间的分布。PDF的值越高，表示对应值的概率越大：
- en: '![Figure 1.8 – KDE with marked measures of center'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.8 – 带有标记中心位置的KDE'
- en: '](img/Figure_1.8_B16834.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.8_B16834.jpg)'
- en: Figure 1.8 – KDE with marked measures of center
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8 – 带有标记中心位置的KDE
- en: 'When the distribution starts to get a little lopsided with long tails on one
    side, the mean measure of center can easily get pulled to that side. Distributions
    that aren''t symmetric have some **skew** to them. A **left (negative) skewed
    distribution** has a long tail on the left-hand side; a **right (positive) skewed
    distribution** has a long tail on the right-hand side. In the presence of negative
    skew, the mean will be less than the median, while the reverse happens with a
    positive skew. When there is no skew, both will be equal:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当分布开始偏斜，且一侧尾部较长时，均值中心度量容易被拉向那一侧。非对称的分布会表现出一定的**偏度**。**左偏（负偏）分布**具有左侧长尾；**右偏（正偏）分布**具有右侧长尾。在负偏的情况下，均值会小于中位数，而在正偏的情况下则相反。当没有偏度时，均值和中位数相等：
- en: '![Figure 1.9 – Visualizing skew'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.9 – 可视化偏度'
- en: '](img/Figure_1.9_B16834.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.9_B16834.jpg)'
- en: Figure 1.9 – Visualizing skew
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9 – 可视化偏度
- en: Important note
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: There is also another statistic called **kurtosis**, which compares the density
    of the center of the distribution with the density at the tails. Both skewness
    and kurtosis can be calculated with the SciPy package.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个统计量是**峰度**，它比较分布中心的密度与尾部的密度。偏度和峰度都可以通过SciPy包进行计算。
- en: 'Each column in our data is a **random variable**, because every time we observe
    it, we get a value according to the underlying distribution—it''s not static.
    When we are interested in the probability of getting a value of *x* or less, we
    use the **cumulative distribution function** (**CDF**), which is the integral
    (area under the curve) of the PDF:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据中的每一列都是一个**随机变量**，因为每次观察时，我们会根据潜在的分布获得一个值——它不是静态的。当我们对获得*X*或更小值的概率感兴趣时，我们使用**累积分布函数**（**CDF**），它是概率密度函数（PDF）的积分（曲线下的面积）：
- en: '![](img/Formula_01_009.jpg)![](img/Formula_01_010.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_01_009.jpg)![](img/Formula_01_010.jpg)'
- en: 'The probability of the random variable *X* being less than or equal to the
    specific value of *x* is denoted as *P(X ≤ x)*. With a continuous variable, the
    probability of getting exactly *x* is 0\. This is because the probability will
    be the integral of the PDF from *x* to *x* (area under a curve with zero width),
    which is 0:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量*X*小于或等于特定值*x*的概率记作*P(X ≤ x)*。对于连续变量，获得精确值*x*的概率是0。这是因为该概率将是从*x*到*x*的PDF积分（曲线下宽度为零的面积），即为0：
- en: '![](img/Formula_01_011.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_01_011.jpg)'
- en: 'In order to visualize this, we can find an estimate of the CDF from the sample,
    called the **empirical cumulative distribution function** (**ECDF**). Since this
    is cumulative, at the point where the value on the *x*-axis is equal to *x*, the
    *y* value is the cumulative probability of *P(X ≤ x)*. Let''s visualize **P(X
    ≤ 50)**, **P(X = 50)**, and **P(X > 50)** as an example:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现可视化，我们可以从样本中估计累积分布函数（CDF），称为**经验累积分布函数**（**ECDF**）。由于这是累积的，在*X*轴上的值等于*x*时，*Y*值表示的是累积概率*P(X
    ≤ x)*。让我们以**P(X ≤ 50)**，**P(X = 50)**和**P(X > 50)**为例进行可视化：
- en: '![Figure 1.10 – Visualizing the CDF'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.10 – 可视化累积分布函数'
- en: '](img/Figure_1.10_B16834.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.10_B16834.jpg)'
- en: Figure 1.10 – Visualizing the CDF
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.10 – 可视化累积分布函数
- en: In addition to examining the distribution of our data, we may find the need
    to utilize probability distributions for uses such as simulation (discussed in
    [*Chapter 8*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172), *Rule-Based Anomaly
    Detection*) or hypothesis testing (see the *Inferential statistics* section);
    let's take a look at a few distributions that we are likely to come across.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 除了检查数据的分布外，我们可能还需要使用概率分布进行模拟等用途（如在[*第8章*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172)中讨论的*基于规则的异常检测）或假设检验（见*推断统计*部分）；让我们来看一些我们可能会遇到的分布。
- en: Common distributions
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 常见分布
- en: While there are many probability distributions, each with specific use cases,
    there are some that we will come across often. The **Gaussian**, or **normal**,
    looks like a bell curve and is parameterized by its mean (*μ*) and standard deviation
    (*σ*). The **standard normal** (*Z*) has a mean of 0 and a standard deviation
    of 1\. Many things in nature happen to follow the normal distribution, such as
    heights. Note that testing whether a distribution is normal is not trivial—check
    the *Further reading* section for more information.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有许多概率分布，每个分布都有特定的应用场景，但有一些我们会经常遇到。**高斯分布**或**正态分布**呈钟形曲线，参数化由其均值（*μ*）和标准差（*σ*）。**标准正态分布**（*Z*）的均值为0，标准差为1。许多自然现象遵循正态分布，如身高。请注意，测试一个分布是否符合正态分布并非易事——有关更多信息，请参见*进一步阅读*部分。
- en: The **Poisson distribution** is a discrete distribution that is often used to
    model arrivals. The time between arrivals can be modeled with the **exponential
    distribution**. Both are defined by their mean, lambda (*λ*). The **uniform distribution**
    places equal likelihood on each value within its bounds. We often use this for
    random number generation. When we generate a random number to simulate a single
    success/failure outcome, it is called a **Bernoulli trial**. This is parameterized
    by the probability of success (*p*). When we run the same experiment multiple
    times (*n*), the total number of successes is then a **binomial** random variable.
    Both the Bernoulli and binomial distributions are discrete.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**泊松分布**是一种离散分布，通常用来模拟到达事件。到达之间的时间可以通过**指数分布**来建模。两者都由它们的均值λ（*λ*）定义。**均匀分布**在其区间内对每个值赋予相同的概率。我们经常使用它来生成随机数。当我们生成一个随机数以模拟一次成功/失败的结果时，这叫做**伯努利试验**。它通过成功概率（*p*）进行参数化。当我们多次进行同样的实验（*n*）时，总成功次数便是一个**二项式**随机变量。伯努利分布和二项式分布都是离散的。'
- en: 'We can visualize both discrete and continuous distributions; however, discrete
    distributions give us a **probability mass function** (**PMF**) instead of a PDF:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以可视化离散和连续分布；然而，离散分布给我们提供了一个**概率质量函数**（**PMF**）而不是概率密度函数（PDF）：
- en: '![Figure 1.11 – Visualizing some commonly used distributions'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 1.11 – 可视化一些常用的分布'
- en: '](img/Figure_1.11_B16834.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.11_B16834.jpg)'
- en: Figure 1.11 – Visualizing some commonly used distributions
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.11 – 可视化一些常用的分布
- en: We will use some of these distributions in [*Chapter 8*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172),
    *Rule-Based Anomaly Detection*, when we simulate some login attempt data for anomaly
    detection.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第8章*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172)，*基于规则的异常检测*中使用这些分布，当我们模拟一些登录尝试数据以进行异常检测时。
- en: Scaling data
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缩放数据
- en: 'In order to compare variables from different distributions, we would have to
    **scale** the data, which we could do with the range by using **min-max scaling**.
    We take *each* data point, subtract the minimum of the dataset, then divide by
    the range. This **normalizes** our data (scales it to the range [0, 1]):'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较来自不同分布的变量，我们必须对数据进行**缩放**，我们可以通过使用**最小-最大缩放**来实现。我们取*每个*数据点，减去数据集的最小值，然后除以范围。这将**标准化**我们的数据（将其缩放到[0,
    1]的范围内）：
- en: '![](img/Formula_01_012.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_01_012.jpg)'
- en: 'This isn''t the only way to scale data; we can also use the mean and standard
    deviation. In this case, we would subtract the mean from each observation and
    then divide by the standard deviation to **standardize** the data. This gives
    us what is known as a **Z-score**:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是缩放数据的唯一方式；我们还可以使用均值和标准差。在这种情况下，我们将从每个观察值中减去均值，然后除以标准差来**标准化**数据。这给出了我们所知道的**Z-分数**：
- en: '![](img/Formula_01_013.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_01_013.jpg)'
- en: We are left with a normalized distribution with a mean of 0 and a standard deviation
    (and variance) of 1\. The Z-score tells us how many standard deviations from the
    mean each observation is; the mean has a Z-score of 0, while an observation of
    0.5 standard deviations below the mean will have a Z-score of -0.5.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一个均值为0且标准差（和方差）为1的标准化分布。Z-分数告诉我们每个观察结果与均值相差了多少个标准差；均值的Z-分数为0，而一个比均值低0.5个标准差的观察结果的Z-分数为-0.5。
- en: There are, of course, additional ways to scale our data, and the one we end
    up choosing will be dependent on our data and what we are trying to do with it.
    By keeping the measures of central tendency and measures of dispersion in mind,
    you will be able to identify how the scaling of data is being done in any other
    methods you come across.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，还有其他方式来缩放我们的数据，我们最终选择的方式将取决于我们的数据及其用途。通过牢记中心趋势和离散度的测量，您将能够确定如何在遇到的任何其他方法中进行数据缩放。
- en: Quantifying relationships between variables
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 量化变量之间的关系
- en: In the previous sections, we were dealing with univariate statistics and were
    only able to say something about the variable we were looking at. With multivariate
    statistics, we seek to quantify relationships between variables and attempt to
    make predictions for future behavior.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们处理的是单变量统计，并且只能对我们关注的变量做出某些描述。通过多变量统计，我们试图量化变量之间的关系，并尝试预测未来的行为。
- en: 'The **covariance** is a statistic for quantifying the relationship between
    variables by showing how one variable changes with respect to another (also referred
    to as their joint variance):'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**协方差**是一种用于量化变量之间关系的统计量，它显示一个变量随着另一个变量的变化（也称为它们的联合方差）：'
- en: '![](img/Formula_01_014.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_01_014.jpg)'
- en: Important note
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: '*E[X]* is a new notation for us. It is read as *the expected value of X* or
    *the expectation of X*, and it is calculated by summing all the possible values
    of *X* multiplied by their probability—it''s the long-run average of *X*.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '*E[X]* 对于我们来说是一个新的符号。它被读作*X的期望值*或*X的期望*，通过将*X*的所有可能值乘以它们的概率相加来计算——它是*X*的长期平均值。'
- en: 'The magnitude of the covariance isn''t easy to interpret, but its sign tells
    us whether the variables are positively or negatively correlated. However, we
    would also like to quantify how *strong* the relationship is between the variables,
    which brings us to correlation. **Correlation** tells us how variables change
    together both in direction (same or opposite) and magnitude (strength of the relationship).
    To find the correlation, we calculate the **Pearson correlation coefficient**,
    symbolized by *ρ* (the Greek letter *rho*), by dividing the covariance by the
    product of the standard deviations of the variables:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 协方差的大小不容易解释，但它的符号告诉我们变量是正相关还是负相关。然而，我们也希望量化变量之间关系的*强度*，这就引出了相关性。**相关性**告诉我们变量如何在方向（相同或相反）和大小（关系的强度）上共同变化。为了找到相关性，我们通过将协方差除以变量标准差的乘积来计算**皮尔逊相关系数**，其符号为*ρ*（希腊字母*rho*）：
- en: '![](img/Formula_01_015.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_01_015.jpg)'
- en: This normalizes the covariance and results in a statistic bounded between -1
    and 1, making it easy to describe both the direction of the correlation (sign)
    and the strength of it (magnitude). Correlations of 1 are said to be perfect positive
    (linear) correlations, while those of -1 are perfect negative correlations. Values
    near 0 aren't correlated. If correlation coefficients are near 1 in absolute value,
    then the variables are said to be strongly correlated; those closer to 0.5 are
    said to be weakly correlated.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得协方差标准化，并产生一个介于-1和1之间的统计量，便于描述相关性的方向（符号）和强度（大小）。相关系数为1被称为完美正相关（线性相关），-1则为完美负相关。接近0的值表示没有相关性。如果相关系数接近1的绝对值，那么变量被认为是强相关的；而接近0.5的相关系数则表示变量间的相关性较弱。
- en: 'Let''s look at some examples using scatter plots. In the leftmost subplot of
    *Figure 1.12* (**ρ = 0.11**), we see that there is no correlation between the
    variables: they appear to be random noise with no pattern. The next plot with
    **ρ = -0.52** has a weak negative correlation: we can see that the variables appear
    to move together with the *x* variable increasing, while the *y* variable decreases,
    but there is still a bit of randomness. In the third plot from the left (**ρ =
    0.87**), there is a strong positive correlation: *x* and *y* are increasing together.
    The rightmost plot with **ρ = -0.99** has a near-perfect negative correlation:
    as *x* increases, *y* decreases. We can also see how the points form a line:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过散点图来看一些例子。在*图 1.12*的最左边的子图（**ρ = 0.11**）中，我们看到变量之间没有相关性：它们看起来像是没有模式的随机噪声。下一个图（**ρ
    = -0.52**）有弱的负相关性：我们可以看到，随着*x*变量的增加，*y*变量下降，尽管仍有一些随机性。第三个图（**ρ = 0.87**）有强的正相关性：*x*和*y*一起增加。最右边的图（**ρ
    = -0.99**）有接近完美的负相关性：随着*x*的增加，*y*减少。我们还可以看到点如何形成一条直线：
- en: '![Figure 1.12 – Comparing correlation coefficients'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.12 – 比较相关系数'
- en: '](img/Figure_1.12_B16834.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.12_B16834.jpg)'
- en: Figure 1.12 – Comparing correlation coefficients
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.12 – 比较相关系数
- en: 'To quickly eyeball the strength and direction of the relationship between two
    variables (and see whether there even seems to be one), we will often use scatter
    plots rather than calculating the exact correlation coefficient. This is for a
    couple of reasons:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速估计两个变量之间关系的强度和方向（并判断是否存在关系），我们通常会使用散点图，而不是计算精确的相关系数。这是因为以下几个原因：
- en: It's easier to find patterns in visualizations, but it's more work to arrive
    at the same conclusion by looking at numbers and tables.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可视化中寻找模式更容易，但通过查看数字和表格得出相同的结论则需要更多的工作。
- en: We might see that the variables seem related, but they may not be *linearly*
    related. Looking at a visual representation will make it easy to see if our data
    is actually quadratic, exponential, logarithmic, or some other non-linear function.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可能会看到变量之间似乎有关联，但它们可能不是*线性*相关的。查看视觉表现可以很容易地判断我们的数据是否实际上是二次的、指数的、对数的或其他非线性函数。
- en: 'Both of the following plots depict data with strong positive correlations,
    but it''s pretty obvious when looking at the scatter plots that these are not
    linear. The one on the left is logarithmic, while the one on the right is exponential:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以下两个图都显示了强正相关的数据，但通过观察散点图，显然这些数据并不是线性的。左边的是对数型的，而右边的是指数型的：
- en: '![Figure 1.13 – The correlation coefficient can be misleading'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.13 – 相关系数可能会误导'
- en: '](img/Figure_1.13_B16834.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.13_B16834.jpg)'
- en: Figure 1.13 – The correlation coefficient can be misleading
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13 – 相关系数可能会误导人
- en: It's very important to remember that while we may find a correlation between
    *X* and *Y*, it doesn't mean that *X causes Y* or that *Y causes X*. There could
    be some *Z* that actually causes both; perhaps *X* causes some intermediary event
    that causes *Y*, or it is actually just a coincidence. Keep in mind that we often
    don't have enough information to report causation—*correlation does not imply
    causation*.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 很重要的一点是，尽管我们可能发现*X*和*Y*之间存在相关性，但这并不意味着*X导致Y*，或者*Y导致X*。可能存在某个*Z*实际上同时引起了这两者；也许*X*导致某个中介事件，从而导致*Y*，或者这其实只是巧合。请记住，我们往往没有足够的信息来报告因果关系——*相关性并不意味着因果关系*。
- en: Tip
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Be sure to check out Tyler Vigen's *Spurious Correlations* blog ([https://www.tylervigen.com/spurious-correlations](https://www.tylervigen.com/spurious-correlations))
    for some interesting correlations.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 一定要查看Tyler Vigen的*虚假相关性*博客([https://www.tylervigen.com/spurious-correlations](https://www.tylervigen.com/spurious-correlations))，里面有一些有趣的相关性。
- en: Pitfalls of summary statistics
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结统计量的陷阱
- en: 'There is a very interesting dataset illustrating how careful we must be when
    only using summary statistics and correlation coefficients to describe our data.
    It also shows us that plotting is not optional. **Anscombe''s quartet** is a collection
    of four different datasets that have identical summary statistics and correlation
    coefficients, but when plotted, it is obvious they are not similar:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个非常有趣的数据集，展示了当我们仅使用总结统计量和相关系数来描述数据时，我们必须多么小心。它还向我们展示了绘图并非可选项。**安斯科姆四重奏**是一个包含四个不同数据集的集合，它们具有相同的总结统计量和相关系数，但当被绘制出来时，很明显它们并不相似：
- en: '![Figure 1.14 – Summary statistics can be misleading'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.14 – 总结统计量可能会误导人'
- en: '](img/Figure_1.14_B16834.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.14_B16834.jpg)'
- en: Figure 1.14 – Summary statistics can be misleading
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.14 – 总结统计量可能会误导人
- en: Notice that each of the plots in *Figure 1.14* has an identical best-fit line
    defined by the equation **y = 0.50x + 3.00**. In the next section, we will discuss,
    at a high level, how this line is created and what it means.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，*图 1.14* 中的每个图都具有相同的最佳拟合线，其方程为**y = 0.50x + 3.00**。在下一节中，我们将高层次地讨论这个直线是如何创建的，以及它代表了什么意义。
- en: Important note
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Summary statistics are very helpful when we're getting to know the data, but
    be wary of relying exclusively on them. Remember, statistics can be misleading;
    be sure to also plot the data before drawing any conclusions or proceeding with
    the analysis. You can read more about Anscombe's quartet at [https://en.wikipedia.org/wiki/Anscombe%27s_quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet).
    Also, be sure to check out the **Datasaurus Dozen**, which are 13 datasets that
    also have the same summary statistics, at [https://www.autodeskresearch.com/publications/samestats](https://www.autodeskresearch.com/publications/samestats).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 总结统计量在我们了解数据时非常有帮助，但要小心仅仅依赖它们。记住，统计数据可能会误导人；在得出任何结论或继续分析之前，务必先绘制数据图表。你可以在[https://en.wikipedia.org/wiki/Anscombe%27s_quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)了解更多关于安斯科姆四重奏的内容。此外，也要查看**Datasaurus
    Dozen**，这是13个数据集，它们具有相同的总结统计量，访问地址为[https://www.autodeskresearch.com/publications/samestats](https://www.autodeskresearch.com/publications/samestats)。
- en: Prediction and forecasting
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测与预报
- en: 'Say our favorite ice cream shop has asked us to help predict how many ice creams
    they can expect to sell on a given day. They are convinced that the temperature
    outside has a strong influence on their sales, so they have collected data on
    the number of ice creams sold at a given temperature. We agree to help them, and
    the first thing we do is make a scatter plot of the data they collected:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们最喜欢的冰淇淋店请求我们帮助预测他们在某一天能卖出多少冰淇淋。他们相信外面的温度对他们的销售有很大的影响，因此他们收集了在不同温度下售出冰淇淋的数量。我们同意帮助他们，第一步就是绘制他们收集的数据的散点图：
- en: '![Figure 1.15 – Observations of ice cream sales at various temperatures'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.15 – 不同温度下冰淇淋销售的观察结果'
- en: '](img/Figure_1.15_B16834.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.15_B16834.jpg)'
- en: Figure 1.15 – Observations of ice cream sales at various temperatures
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.15 – 不同温度下冰淇淋销售的观察结果
- en: 'We can observe an upward trend in the scatter plot: more ice creams are sold
    at higher temperatures. In order to help out the ice cream shop, though, we need
    to find a way to make predictions from this data. We can use a technique called
    **regression** to model the relationship between temperature and ice cream sales
    with an equation. Using this equation, we will be able to **predict** ice cream
    sales at a given temperature.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在散点图中观察到一个上升趋势：在较高温度下，卖出的冰激凌更多。然而，为了帮助冰激凌店，我们需要找到一种方法来从这些数据中做出预测。我们可以使用一种叫做**回归分析**的技术，通过一个方程来描述温度和冰激凌销售量之间的关系。通过这个方程，我们将能够**预测**在某一温度下的冰激凌销售量。
- en: Important note
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Remember that correlation does not imply causation. People may buy ice cream
    when it is warmer, but warmer temperatures don't necessarily cause people to buy
    ice cream.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，相关性并不意味着因果关系。人们可能会在气温升高时购买冰激凌，但气温升高并不一定导致人们购买冰激凌。
- en: 'In [*Chapter 9*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188), *Getting
    Started with Machine Learning in Python*, we will go over regression in depth,
    so this discussion will be a high-level overview. There are many types of regression
    that will yield a different type of equation, such as linear (which we will use
    for this example) and logistic. Our first step will be to identify the **dependent
    variable**, which is the quantity we want to predict (ice cream sales), and the
    variables we will use to predict it, which are called **independent variables**.
    While we can have many independent variables, our ice cream sales example only
    has one: temperature. Therefore, we will use simple linear regression to model
    the relationship as a line:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第9章*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188)《Python中的机器学习入门》中，我们将深入讨论回归分析，因此本讨论将仅为概述。回归有许多种类型，会产生不同的方程，例如线性回归（我们将在这个例子中使用）和逻辑回归。我们的第一步是确定**因变量**，即我们想要预测的量（冰激凌销售量），以及我们将用来预测它的变量，这些被称为**自变量**。虽然我们可以有许多自变量，但我们的冰激凌销售例子只有一个自变量：温度。因此，我们将使用简单线性回归将温度和销售量之间的关系建模为一条直线：
- en: '![Figure 1.16 – Fitting a line to the ice cream sales data'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.16 – 拟合冰激凌销售数据的直线'
- en: '](img/Figure_1.16_B16834.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.16_B16834.jpg)'
- en: Figure 1.16 – Fitting a line to the ice cream sales data
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.16 – 拟合冰激凌销售数据的直线
- en: 'The regression line in the previous scatter plot yields the following equation
    for the relationship:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个散点图中的回归线得出了以下关系方程：
- en: '![](img/Formula_01_016.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_01_016.jpg)'
- en: Suppose that today the temperature is 35°C—we would plug that in for *temperature*
    in the equation. The result predicts that the ice cream shop will sell 24.54 ice
    creams. This prediction is along the red line in the previous plot. Note that
    the ice cream shop can't actually sell fractions of ice cream.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 假设今天温度是35°C——我们将把这个值代入方程中的*温度*。结果预测冰激凌店将销售24.54个冰激凌。这个预测值位于前图中的红线旁边。注意，冰激凌店实际上不能卖部分冰激凌。
- en: Before leaving the model in the hands of the ice cream shop, it's important
    to discuss the difference between the dotted and solid portions of the regression
    line that we obtained. When we make predictions using the solid portion of the
    line, we are using **interpolation**, meaning that we will be predicting ice cream
    sales for temperatures the regression was created on. On the other hand, if we
    try to predict how many ice creams will be sold at 45°C, it is called **extrapolation**
    (the dotted portion of the line), since we didn't have any temperatures this high
    when we ran the regression. Extrapolation can be very dangerous as many trends
    don't continue indefinitely. People may decide not to leave their houses because
    it is so hot. This means that instead of selling the predicted 39.54 ice creams,
    they would sell zero.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型交给冰激凌店之前，重要的是要讨论我们得到的回归线中的虚线和实线部分之间的区别。当我们使用回归线的实线部分进行预测时，我们正在使用**插值**，这意味着我们将预测回归所建立时的温度下的冰激凌销售量。另一方面，如果我们试图预测在45°C时会卖出多少个冰激凌，这就是**外推**（虚线部分），因为在我们进行回归时并没有包括这么高的温度。外推可能非常危险，因为许多趋势并不会无限延续。人们可能会决定由于温度过高而不外出，这意味着他们将不会销售预测的39.54个冰激凌，而是会销售零个。
- en: 'When working with time series, our terminology is a little different: we often
    look to **forecast** future values based on past values. Forecasting is a type
    of prediction for time series. Before we try to model the time series, however,
    we will often use a process called **time series decomposition** to split the
    time series into components, which can be combined in an additive or multiplicative
    fashion and may be used as parts of a model.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理时间序列时，我们的术语略有不同：我们通常会根据过去的值来**预测**未来的值。预测是时间序列的一种预测类型。然而，在尝试对时间序列建模之前，我们通常会使用一个叫做**时间序列分解**的过程，将时间序列分解成多个组成部分，这些组成部分可以以加法或乘法的方式组合，并可作为模型的组成部分。
- en: The **trend** component describes the behavior of the time series in the **long
    term** without accounting for seasonal or cyclical effects. Using the trend, we
    can make broad statements about the time series in the long run, such as *the
    population of Earth is increasing* or *the value of a stock is stagnating*. The
    **seasonality** component explains the systematic and calendar-related movements
    of a time series. For example, the number of ice cream trucks on the streets of
    New York City is high in the summer and drops to nothing in the winter; this pattern
    repeats every year, regardless of whether the actual amount each summer is the
    same. Lastly, the **cyclical** component accounts for anything else unexplained
    or irregular with the time series; this could be something such as a hurricane
    driving the number of ice cream trucks down in the **short term** because it isn't
    safe to be outside. This component is difficult to anticipate with a forecast
    due to its unexpected nature.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '**趋势**组件描述了时间序列在**长期**内的行为，而不考虑季节性或周期性效应。通过趋势，我们可以对时间序列的长期变化做出广泛的判断，比如*地球人口在增加*或*某只股票的价值停滞不前*。**季节性**组件解释了时间序列中与季节相关的系统性变化。例如，纽约市街头的冰淇淋车在夏季数量较多，冬季则几乎消失；这种模式每年都会重复，不管每年夏天的实际数量是否相同。最后，**周期性**组件解释了时间序列中其他无法用季节性或趋势解释的异常或不规则波动；例如，飓风可能会导致冰淇淋车数量在**短期内**减少，因为在户外不安全。由于周期性成分的不可预测性，这一部分很难通过预测来预见。'
- en: 'We can use Python to **decompose** the time series into trend, seasonality,
    and **noise** or **residuals**. The cyclical component is captured in the noise
    (random, unpredictable data); after we remove the trend and seasonality from the
    time series, what we are left with is the residual:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Python 来**分解**时间序列为趋势、季节性和**噪声**或**残差**。周期性成分被包含在噪声中（随机且不可预测的数据）；在我们去除时间序列中的趋势和季节性后，剩下的就是残差：
- en: '![Figure 1.17 – An example of time series decomposition'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.17 – 时间序列分解的示例'
- en: '](img/Figure_1.17_B16834.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.17_B16834.jpg)'
- en: Figure 1.17 – An example of time series decomposition
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.17 – 时间序列分解的示例
- en: When building models to forecast time series, some common methods include exponential
    smoothing and ARIMA-family models. **ARIMA** stands for **autoregressive** (**AR**),
    **integrated** (**I**), **moving average** (**MA**). **Autoregressive** models
    take advantage of the fact that an observation at time *t* is *correlated* to
    a previous observation, for example, at time *t - 1*. In [*Chapter 5*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106),
    *Visualizing Data with Pandas and Matplotlib*, we will look at some techniques
    for determining whether a time series is autoregressive; note that not all time
    series are. The **integrated** component concerns the **differenced** data, or
    the *change* in the data from one time to another. For example, if we were concerned
    with a **lag** (distance between times) of 1, the differenced data would be the
    value at time *t* subtracted by the value at time *t - 1*. Lastly, the **moving
    average** component uses a sliding window to average the last *x* observations,
    where *x* is the length of the sliding window. If, for example, we have a 3-period
    moving average, by the time we have all of the data up to time 5, our moving average
    calculation only uses time periods 3, 4, and 5 to forecast time 6\. We will build
    an ARIMA model in [*Chapter 7*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146),
    *Financial Analysis – Bitcoin and the Stock Market*.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建时间序列预测模型时，一些常见的方法包括指数平滑法和ARIMA模型。**ARIMA**代表**自回归**（**AR**）、**差分**（**I**）、**移动平均**（**MA**）。**自回归**模型利用了一个观察值在时间*t*时与先前某个观察值之间的*相关性*，例如时间*t
    - 1*时的观察值。在[*第5章*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106)，《使用Pandas和Matplotlib可视化数据》中，我们将探讨一些技术来判断一个时间序列是否具有自回归性；需要注意的是，并不是所有的时间序列都有自回归性。**差分**部分涉及**差分数据**，即数据从一个时间点到另一个时间点的*变化*。例如，如果我们关心的是**滞后**（时间间隔）为1的情况，那么差分数据就是时间*t*的值减去时间*t
    - 1*的值。最后，**移动平均**部分使用滑动窗口计算最后*x*个观察值的平均值，其中*x*是滑动窗口的长度。例如，如果我们有一个3期的移动平均，那么当我们获得所有的数据直到时间5时，我们的移动平均计算只会使用时间3、4和5来预测时间6的值。在[*第7章*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146)，《金融分析——比特币与股市》中，我们将构建一个ARIMA模型。
- en: The moving average puts equal weight on each time period in the past involved
    in the calculation. In practice, this isn't always a realistic expectation of
    our data. Sometimes, *all* past values are important, but they *vary* in their
    influence on future data points. For these cases, we can use **exponential smoothing**,
    which allows us to put more weight on more recent values and less weight on values
    further away from what we are predicting.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 移动平均给过去的每一个时间段赋予相等的权重。在实际操作中，这并不总是对我们的数据一个现实的期望。有时候，*所有*过去的数值都很重要，但它们对未来数据点的影响*不同*。对于这些情况，我们可以使用**指数平滑法**，它使我们能够对最近的数值赋予更多权重，对更远的数值赋予较少的权重，从而预测未来的数据。
- en: Note that we aren't limited to predicting numbers; in fact, depending on the
    data, our predictions could be categorical in nature—things such as determining
    which flavor of ice cream will sell the most on a given day or whether an email
    is spam or not. This type of prediction will be introduced in [*Chapter 9*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188),
    *Getting Started with Machine Learning in Python*.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们不仅限于预测数字；事实上，根据数据的不同，我们的预测也可以是类别性的——例如预测某种口味的冰淇淋在某一天销售量最多，或者判断一封邮件是否为垃圾邮件。这类预测将在[*第9章*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188)，《Python机器学习入门》中介绍。
- en: Inferential statistics
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推断统计学
- en: As mentioned earlier, inferential statistics deals with inferring or deducing
    things from the sample data we have in order to make statements about the population
    as a whole. When we're looking to state our conclusions, we have to be mindful
    of whether we conducted an observational study or an experiment. With an **observational
    study**, the independent variable is not under the control of the researchers,
    and so we are *observing* those taking part in our study (think about studies
    on smoking—we can't force people to smoke). The fact that we can't control the
    independent variable means that we *cannot* conclude causation.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，推断统计学处理的是从我们拥有的样本数据中推断或推导出关于总体的结论。在我们得出结论时，必须注意我们是进行的观察性研究还是实验。对于**观察性研究**，独立变量不受研究者控制，因此我们是*观察*参与研究的人（比如吸烟研究——我们不能强迫人们吸烟）。我们不能控制独立变量意味着我们*不能*得出因果关系的结论。
- en: With an **experiment**, we are able to directly influence the independent variable
    and randomly assign subjects to the control and test groups, such as A/B tests
    (for anything from website redesigns to ad copy). Note that the control group
    doesn't receive treatment; they can be given a placebo (depending on what the
    study is). The ideal setup for this is **double-blind**, where the researchers
    administering the treatment don't know which treatment is the placebo and also
    don't know which subject belongs to which group.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 通过**实验**，我们能够直接影响自变量，并将受试者随机分配到对照组和实验组，例如A/B测试（适用于网站重设计到广告文案等各种场景）。请注意，对照组不接受治疗；他们可能会接受安慰剂（具体取决于研究的内容）。这种设置的理想方式是**双盲**，即负责施治的研究人员不知道哪个治疗是安慰剂，也不知道哪个受试者属于哪个组别。
- en: Important note
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We can often find reference to Bayesian inference and frequentist inference.
    These are based on two different ways of approaching probability. Frequentist
    statistics focuses on the frequency of the event, while Bayesian statistics uses
    a degree of belief when determining the probability of an event. We will see an
    example of Bayesian statistics in [*Chapter 11*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237),
    *Machine Learning Anomaly Detection*. You can read more about how these methods
    differ at [https://www.probabilisticworld.com/frequentist-bayesian-approaches-inferential-statistics/](https://www.probabilisticworld.com/frequentist-bayesian-approaches-inferential-statistics/).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常会看到贝叶斯推断和频率推断的相关内容。这两者基于两种不同的概率处理方式。频率学派统计学侧重于事件发生的频率，而贝叶斯统计学则在确定事件概率时使用信念的程度。在[*第11章*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237)，*机器学习中的异常检测*中，我们会看到贝叶斯统计学的一个例子。你可以在[https://www.probabilisticworld.com/frequentist-bayesian-approaches-inferential-statistics/](https://www.probabilisticworld.com/frequentist-bayesian-approaches-inferential-statistics/)了解更多关于这两种方法的差异。
- en: Inferential statistics gives us tools to translate our understanding of the
    sample data to a statement about the population. Remember that the sample statistics
    we discussed earlier are estimators for the population parameters. Our estimators
    need **confidence intervals**, which provide a point estimate and a margin of
    error around it. This is the range that the true population parameter will be
    in at a certain **confidence level**. At the 95% confidence level, 95% of the
    confidence intervals that are calculated from random samples of the population
    contain the true population parameter. Frequently, 95% is chosen for the confidence
    level and other purposes in statistics, although 90% and 99% are also common;
    the higher the confidence level, the wider the interval.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 推论统计学为我们提供了将样本数据的理解转化为对总体的推断的工具。记住，我们之前讨论的样本统计量是总体参数的估计量。我们的估计量需要**置信区间**，它提供一个点估计以及围绕点估计的误差范围。这是一个范围，表示真实的总体参数在某个**置信水平**下的可能取值范围。在95%的置信水平下，95%从总体中随机抽取的样本计算出的置信区间包含真实的总体参数。通常，统计学中会选择95%作为置信水平，虽然90%和99%也很常见；置信水平越高，区间越宽。
- en: 'Hypothesis tests allow us to test whether the true population parameter is
    less than, greater than, or not equal to some value at a certain **significance
    level** (called **alpha**). The process of performing a hypothesis test starts
    with stating our initial assumption or **null hypothesis**: for example, *the
    true population mean is 0*. We pick a level of statistical significance, usually
    5%, which is the probability of rejecting the null hypothesis when it is true.
    Then, we calculate the critical value for the test statistic, which will depend
    on the amount of data we have and the type of statistic (such as the mean of one
    population or the proportion of votes for a candidate) we are testing. The critical
    value is compared to the test statistic from our data and, based on the result,
    we either reject or fail to reject the null hypothesis. Hypothesis tests are closely
    related to confidence intervals. The significance level is equivalent to 1 minus
    the confidence level. This means that a result is statistically significant if
    the null hypothesis value is not in the confidence interval.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 假设检验允许我们测试真实总体参数是否小于、大于或不等于某个值在某个**显著性水平**（称为**α**）下。执行假设检验的过程始于陈述我们的初始假设或**零假设**：例如，*真实总体均值为0*。我们选择一个统计显著性水平，通常为5%，这是在零假设为真时拒绝零假设的概率。然后，我们计算测试统计量的临界值，这将取决于我们拥有的数据量以及我们正在测试的统计量类型（例如一个总体的平均值或候选人得票比例）。将临界值与来自我们数据的测试统计量进行比较，并根据结果，我们要么拒绝要么不拒绝零假设。假设检验与置信区间密切相关。显著性水平相当于1减去置信水平。这意味着如果零假设值不在置信区间内，则结果在统计上是显著的。
- en: Important note
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: There are many things we have to be aware of when picking the method to calculate
    a confidence interval or the proper test statistic for a hypothesis test. This
    is beyond the scope of this book, but check out the link in the *Further reading*
    section at the end of this chapter for more information. Also, be sure to look
    at some of the mishaps with the p-values used in hypothesis testing, such as p-hacking,
    at [https://en.wikipedia.org/wiki/Misuse_of_p-values](https://en.wikipedia.org/wiki/Misuse_of_p-values).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择计算置信区间的方法或假设检验的适当检验统计量时，我们必须注意许多事项。这超出了本书的范围，请参阅本章末尾的*Further reading*部分的链接获取更多信息。此外，请务必查看一些假设检验中使用的p值的失误，例如p-hacking，详见[https://en.wikipedia.org/wiki/Misuse_of_p-values](https://en.wikipedia.org/wiki/Misuse_of_p-values)。
- en: Now that we have an overview of statistics and data analysis, we are ready to
    get started with the Python portion of this book. Let's start by setting up a
    virtual environment.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经概述了统计学和数据分析，准备开始本书的Python部分。让我们从设置虚拟环境开始。
- en: Setting up a virtual environment
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置虚拟环境
- en: This book was written using Python 3.7.3, but the code should work for Python
    3.7.1+, which is available on all major operating systems. In this section, we
    will go over how to set up the virtual environment in order to follow along with
    this book. If Python isn't already installed on your computer, read through the
    following sections on virtual environments first, and then decide whether to install
    Anaconda, since it will also install Python. To install Python without Anaconda,
    download it from [https://www.python.org/downloads/](https://www.python.org/downloads/),
    and then follow the *venv* section instead of the *conda* section.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用Python 3.7.3编写，但代码应适用于所有主要操作系统上的Python 3.7.1+。在本节中，我们将讲解如何设置虚拟环境，以便跟随本书的内容。如果您的计算机尚未安装Python，请首先阅读有关虚拟环境的以下部分，然后决定是否安装Anaconda，因为它也会安装Python。要安装不带Anaconda的Python，请从[https://www.python.org/downloads/](https://www.python.org/downloads/)下载，并按照*venv*部分而不是*conda*部分操作。
- en: Important note
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: To check whether Python is already installed, run `where python3` from the command
    line on Windows or `which python3` from the command line on Linux/macOS. If this
    returns nothing, try running it with just `python` (instead of `python3`). If
    Python is installed, check the version by running `python3 --version`. Note that
    if `python3` works, then you should use that throughout the book (and conversely,
    use `python` if `python3` doesn't work).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查Python是否已安装，请在Windows命令行上运行`where python3`或在Linux/macOS上运行`which python3`。如果返回结果为空，请尝试仅使用`python`（而不是`python3`）运行。如果已安装Python，请通过运行`python3
    --version`来检查版本。请注意，如果`python3`可用，则应在整本书中使用它（反之亦然，如果`python3`不可用，则使用`python`）。
- en: Virtual environments
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 虚拟环境
- en: 'Most of the time, when we want to install software on our computer, we simply
    download it, but the nature of programming languages where packages are constantly
    being updated and rely on specific versions of others means this can cause issues.
    We could be working on a project one day where we need a certain version of a
    Python package (say 0.9.1), but the next day be working on an analysis where we
    need the most recent version of that same package to access some newer functionality
    (1.1.0). Sounds like there wouldn''t be an issue, right? Well, what happens if
    this update causes a breaking change to the first project or another package in
    our project that relies on this one? This is a common enough problem that a solution
    already exists to prevent this from being an issue: virtual environments.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，当我们想在电脑上安装软件时，我们只需下载它，但编程语言的特性要求包不断更新并依赖于其他特定版本，这可能会导致一些问题。比如，我们有一天在做一个项目时需要一个特定版本的Python包（比如0.9.1），但第二天我们在做另一个分析时需要同一个包的最新版本（比如1.1.0），以便访问一些更新的功能。听起来好像不会有什么问题，对吧？但是，如果这个更新导致了第一个项目或我们项目中依赖该包的其他包出现了兼容性问题怎么办呢？这是一个足够常见的问题，已经有了解决方案来防止这种情况：虚拟环境。
- en: A **virtual environment** allows us to create separate environments for each
    of our projects. Each of our environments will only have the packages that it
    needs installed. This makes it easy to share our environment with others, have
    multiple versions of the same package installed on our machine for different projects
    without interfering with each other, and avoid unexpected side effects from installing
    packages that update or have dependencies on others. It's good practice to make
    a dedicated virtual environment for any projects we work on.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '**虚拟环境**允许我们为每个项目创建独立的环境。每个环境只会安装它所需的包。这样可以方便地与他人共享我们的环境，安装多个版本的相同包用于不同的项目而不相互干扰，并避免安装更新包或有其他依赖关系的包时带来的意外副作用。为我们工作的任何项目创建一个专用的虚拟环境是一个好习惯。'
- en: We will discuss two common ways to achieve this setup, and you can decide which
    fits best. Note that all the code in this section will be executed on the command
    line.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论两种常见的设置方式，你可以决定哪种最适合。注意，本节中的所有代码将在命令行中执行。
- en: venv
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: venv
- en: 'Python 3 comes with the `venv` module, which will create a virtual environment
    in the location of our choice. The process of setting up and using a development
    environment is as follows (after Python is installed):'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3自带`venv`模块，它将根据我们选择的路径创建一个虚拟环境。设置和使用开发环境的过程如下（安装了Python之后）：
- en: Create a folder for the project.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为项目创建一个文件夹。
- en: Use `venv` to create an environment in this folder.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`venv`在此文件夹中创建环境。
- en: Activate the environment.
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 激活环境。
- en: Install Python packages in the environment with `pip`.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pip`在环境中安装Python包。
- en: Deactivate the environment when finished.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后停用环境。
- en: 'In practice, we will create environments for each project we work on, so our
    first step will be to create a directory for all of our project files. For this,
    we can use the `mkdir` command. Once this has been created, we will change our
    current directory to the newly created one using the `cd` command. Since we already
    obtained the project files (from the instructions in the *Chapter materials* section),
    the following is for reference only. To make a new directory and move to that
    directory, we can use the following command:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们将为每个项目创建独立的环境，因此我们的第一步是为所有项目文件创建一个目录。我们可以使用`mkdir`命令来完成这项工作。创建完成后，我们将使用`cd`命令切换到新创建的目录。由于我们已经获得了项目文件（从*章节材料*部分获得的指示），以下内容仅供参考。要创建一个新目录并进入该目录，我们可以使用以下命令：
- en: '[PRE0]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Tip
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: '`cd <path>` changes the current directory to the path specified in `<path>`,
    which can be an **absolute** (full) path or **relative** (how to get there from
    the current directory) path.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '`cd <path>`将当前目录更改为`<path>`指定的路径，路径可以是**绝对路径**（完整路径）或**相对路径**（从当前目录到目标目录的路径）。'
- en: 'Before moving on, use `cd` to navigate to the directory containing this book''s
    repository. Note that the path will depend on where it was cloned/downloaded:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，使用`cd`命令导航到包含本书仓库的目录。注意，路径将取决于它被克隆/下载的位置：
- en: '[PRE1]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Since there are slight differences in operating systems for the remaining steps,
    we will go over Windows and Linux/macOS separately. Note that if you have both
    Python 2 and Python 3, make sure you use `python3` and not `python` in the following
    commands.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 由于操作系统之间在剩余步骤上有所不同，我们将分别讲解 Windows 和 Linux/macOS。请注意，如果你的系统同时安装了 Python 2 和
    Python 3，确保在以下命令中使用`python3`，而不是`python`。
- en: Windows
  id: totrans-283
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Windows
- en: 'To create our environment for this book, we will use the `venv` module from
    the standard library. Note that we must provide a name for our environment (`book_env`).
    Remember, if your Windows setup has `python` associated with Python 3, then use
    `python` instead of `python3` in the following command:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建本书的虚拟环境，我们将使用标准库中的`venv`模块。请注意，我们必须为环境提供一个名称（`book_env`）。记住，如果你的 Windows
    设置将`python`与 Python 3 相关联，那么在以下命令中使用`python`而不是`python3`：
- en: '[PRE2]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we have a folder for our virtual environment named `book_env` inside the
    repository folder that we cloned/downloaded earlier. In order to use the environment,
    we need to activate it:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们在之前克隆/下载的仓库文件夹中，有一个名为`book_env`的虚拟环境文件夹。为了使用该环境，我们需要激活它：
- en: '[PRE3]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Tip
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Windows replaces `%cd%` with the path to the current directory. This saves us
    from having to type the full path up to the `book_env` part.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: Windows 用当前目录的路径替换`%cd%`，这使我们不必输入完整的路径直到`book_env`部分。
- en: 'Note that after we activate the virtual environment, we can see `(book_env)`
    in front of our prompt on the command line; this lets us know we are in the environment:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在我们激活虚拟环境后，可以在命令行提示符前看到`(book_env)`，这表明我们已经进入该环境：
- en: '[PRE4]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When we are finished using the environment, we simply deactivate it:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用完环境后，只需将其停用：
- en: '[PRE5]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Any packages that are installed in the environment don't exist outside the environment.
    Note that we no longer have `(book_env)` in front of our prompt on the command
    line. You can read more about `venv` in the Python documentation at [https://docs.python.org/3/library/venv.html](https://docs.python.org/3/library/venv.html).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在环境中安装的任何软件包在环境外部是不存在的。请注意，我们在命令行提示符前不再看到`(book_env)`。你可以在 Python 文档中阅读更多关于`venv`的信息：[https://docs.python.org/3/library/venv.html](https://docs.python.org/3/library/venv.html)。
- en: Now that the virtual environment is created, activate it and then head to the
    *Installing the required Python packages* section for the next step.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟环境创建完成后，激活它，然后转到*安装所需的 Python 包*部分进行下一步操作。
- en: Linux/macOS
  id: totrans-296
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Linux/macOS
- en: 'To create our environment for this book, we will use the `venv` module from
    the standard library. Note that we must provide a name for our environment (`book_env`):'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建本书的虚拟环境，我们将使用标准库中的`venv`模块。请注意，我们必须为环境提供一个名称（`book_env`）：
- en: '[PRE6]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we have a folder for our virtual environment named `book_env` inside of
    the repository folder we cloned/downloaded earlier. In order to use the environment,
    we need to activate it:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们在之前克隆/下载的仓库文件夹中，有一个名为`book_env`的虚拟环境文件夹。为了使用该环境，我们需要激活它：
- en: '[PRE7]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Note that after we activate the virtual environment, we can see `(book_env)`
    in front of our prompt on the command line; this lets us know we are in the environment:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在我们激活虚拟环境后，可以在命令行提示符前看到`(book_env)`，这表明我们已经进入该环境：
- en: '[PRE8]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'When we are finished using the environment, we simply deactivate it:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用完环境后，只需将其停用：
- en: '[PRE9]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Any packages that are installed in the environment don't exist outside the environment.
    Note that we no longer have `(book_env)` in front of our prompt on the command
    line. You can read more about `venv` in the Python documentation at [https://docs.python.org/3/library/venv.html](https://docs.python.org/3/library/venv.html).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在环境中安装的任何软件包在环境外部是不存在的。请注意，我们在命令行提示符前不再看到`(book_env)`。你可以在 Python 文档中阅读更多关于`venv`的信息：[https://docs.python.org/3/library/venv.html](https://docs.python.org/3/library/venv.html)。
- en: Now that the virtual environment is created, activate it and then head to the
    *Installing the required Python packages* section for the next step.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟环境创建完成后，激活它，然后转到*安装所需的 Python 包*部分进行下一步操作。
- en: conda
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: conda
- en: 'Anaconda provides a way to set up a Python environment specifically for data
    science. It includes some of the packages we will use in this book, along with
    several others that may be necessary for tasks that aren''t covered in this book
    (and also deals with dependencies outside of Python that might be tricky to install
    otherwise). Anaconda uses `conda` as the environment and package manager instead
    of `pip`, although packages can still be installed with `pip` (as long as the
    `pip` installed by Anaconda is called). Note that some packages may not be available
    with `conda`, in which case we will have to use `pip`. Consult this page in the
    `conda` documentation for a comparison of commands used with `conda`, `pip`, and
    `venv`: [https://conda.io/projects/conda/en/latest/commands.html#conda-vs-pip-vs-virtualenv-commands](https://conda.io/projects/conda/en/latest/commands.html#conda-vs-pip-vs-virtualenv-commands).'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: Anaconda提供了一种专门为数据科学设置Python环境的方法。它包含了本书中将使用的一些包，以及一些可能对本书未涉及的任务有用的其他包（同时也解决了可能难以安装的Python外部依赖问题）。Anaconda使用`conda`作为环境和包管理器，而不是`pip`，尽管仍然可以使用`pip`安装包（前提是使用Anaconda自带的`pip`）。需要注意的是，有些包可能无法通过`conda`获得，在这种情况下，我们需要使用`pip`。可以查阅`conda`文档中的这个页面，比较`conda`、`pip`和`venv`的命令：[https://conda.io/projects/conda/en/latest/commands.html#conda-vs-pip-vs-virtualenv-commands](https://conda.io/projects/conda/en/latest/commands.html#conda-vs-pip-vs-virtualenv-commands)。
- en: Important note
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Be warned that Anaconda is a very large install (although the Miniconda version
    is much lighter). Those who use Python for purposes aside from data science may
    prefer the `venv` method we discussed earlier in order to have more control over
    what gets installed.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Anaconda的安装非常大（尽管Miniconda版本要轻得多）。那些用于数据科学以外目的的Python用户，可能更倾向于使用我们之前讨论的`venv`方法，以便更好地控制安装内容。
- en: Anaconda can also be packaged with the Spyder `venv` option as well.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: Anaconda还可以与Spyder的`venv`选项一起打包使用。
- en: 'You can read more about Anaconda and how to install it at the following pages
    in their official documentation:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在Anaconda的官方文档中阅读更多关于Anaconda及其安装的内容：
- en: '**Windows**: [https://docs.anaconda.com/anaconda/install/windows/](https://docs.anaconda.com/anaconda/install/windows/)'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Windows**：[https://docs.anaconda.com/anaconda/install/windows/](https://docs.anaconda.com/anaconda/install/windows/)'
- en: '**macOS**: [https://docs.anaconda.com/anaconda/install/mac-os/](https://docs.anaconda.com/anaconda/install/mac-os/)'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**macOS**：[https://docs.anaconda.com/anaconda/install/mac-os/](https://docs.anaconda.com/anaconda/install/mac-os/)'
- en: '**Linux**: [https://docs.anaconda.com/anaconda/install/linux/](https://docs.anaconda.com/anaconda/install/linux/)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Linux**：[https://docs.anaconda.com/anaconda/install/linux/](https://docs.anaconda.com/anaconda/install/linux/)'
- en: '**User guide**: [https://docs.anaconda.com/anaconda/user-guide/](https://docs.anaconda.com/anaconda/user-guide/)'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户指南**：[https://docs.anaconda.com/anaconda/user-guide/](https://docs.anaconda.com/anaconda/user-guide/)'
- en: Once you have installed either Anaconda or Miniconda, confirm that it is properly
    installed by running `conda -V` on the command line to display the version. Note
    that on Windows, all `conda` commands need to be run in **Anaconda Prompt** (as
    opposed to **Command Prompt**).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了Anaconda或Miniconda，确认是否正确安装，可以通过在命令行运行`conda -V`来显示版本。请注意，在Windows上，所有`conda`命令必须在**Anaconda
    Prompt**中运行（而不是**Command Prompt**）。
- en: 'To create a new `conda` environment for this book, called `book_env`, run the
    following:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 为本书创建一个新的`conda`环境，命名为`book_env`，可以运行以下命令：
- en: '[PRE10]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Running `conda env list` will show all the `conda` environments on the system,
    which will now include `book_env`. The current active environment will have an
    asterisk (`*`) next to it—by default, `base` will be active until we activate
    another environment:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`conda env list`将显示系统上的所有`conda`环境，其中现在包括`book_env`。当前活动的环境将有一个星号（`*`）标记—默认情况下，`base`环境将处于活动状态，直到我们激活另一个环境：
- en: '[PRE11]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To activate the `book_env` environment, we run the following command:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 要激活`book_env`环境，我们运行以下命令：
- en: '[PRE12]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Note that after we activate the virtual environment, we can see `(book_env)`
    in front of our prompt on the command line; this lets us know we are in the environment:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在我们激活虚拟环境后，可以在命令行提示符前看到`(book_env)`；这表明我们已经进入该环境：
- en: '[PRE13]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'When we are finished using the environment, we deactivate it:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 使用完环境后，我们可以停用它：
- en: '[PRE14]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Any packages that are installed in the environment don't exist outside the environment.
    Note that we no longer have `(book_env)` in front of our prompt on the command
    line. You can read more about how to use `conda` to manage virtual environments
    at [https://www.freecodecamp.org/news/why-you-need-python-environments-and-how-to-manage-them-with-conda-85f155f4353c/](https://www.freecodecamp.org/news/why-you-need-python-environments-and-how-to-manage-them-with-conda-85f155f4353c/).
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在环境中安装的任何包都只存在于该环境中。请注意，我们的命令行提示符前不再有`(book_env)`。你可以在[https://www.freecodecamp.org/news/why-you-need-python-environments-and-how-to-manage-them-with-conda-85f155f4353c/](https://www.freecodecamp.org/news/why-you-need-python-environments-and-how-to-manage-them-with-conda-85f155f4353c/)阅读更多关于如何使用`conda`管理虚拟环境的内容。
- en: In the next section, we will install the Python packages required for following
    along with this book, so be sure to activate the virtual environment now.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将安装跟随本书所需的 Python 包，因此请现在确保激活虚拟环境。
- en: Installing the required Python packages
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装所需的 Python 包
- en: We can do a lot with the Python standard library; however, we will often find
    the need to install and use an outside package to extend functionality. The `requirements.txt`
    file in the repository contains all the packages we need to install to work through
    this book. It will be in our current directory, but it can also be found at [https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/blob/master/requirements.txt](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/blob/master/requirements.txt).
    This file can be used to install a bunch of packages at once with the `-r` flag
    in the call to `pip3 install` and has the advantage of being easy to share.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用 Python 标准库做很多事情；然而，我们经常会发现需要安装并使用外部包来扩展功能。仓库中的`requirements.txt`文件包含了我们需要安装的所有包，以便跟随本书进行学习。该文件会位于当前目录中，也可以通过[https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/blob/master/requirements.txt](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/blob/master/requirements.txt)找到。我们可以通过在调用`pip3
    install`时使用`-r`标志，一次性安装多个包，这种方式的优势是方便共享。
- en: 'Before installing anything, be sure to activate the virtual environment that
    you created with either `venv` or `conda`. Be advised that if the environment
    is not activated before running the following command, the packages will be installed
    outside the environment:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装任何东西之前，请确保激活你用`venv`或`conda`创建的虚拟环境。请注意，如果在运行以下命令之前没有激活虚拟环境，包将会安装到虚拟环境外部：
- en: '[PRE15]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Tip
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: If you encounter any issues, report them at [https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/issues](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/issues).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遇到任何问题，可以在[https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/issues](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/issues)上报告。
- en: Why pandas?
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么选择 pandas？
- en: When it comes to data science in Python, the `pandas` library is pretty much
    ubiquitous. It is built on top of the NumPy library, which allows us to perform
    mathematical operations on arrays of single-type data efficiently. Pandas expands
    this to **dataframes**, which can be thought of as tables of data. We will get
    a more formal introduction to dataframes in [*Chapter 2*](B16834_02_Final_SK_ePub.xhtml#_idTextAnchor035),
    *Working with Pandas DataFrames*.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 数据科学领域，`pandas`库几乎是无处不在的。它建立在 NumPy 库之上，允许我们对单一类型数据的数组进行高效的数学运算。Pandas
    将这一点扩展到了**数据框（dataframes）**，可以将其视为数据表。我们将在[*第二章*](B16834_02_Final_SK_ePub.xhtml#_idTextAnchor035)，《使用
    Pandas 数据框》一章中正式介绍数据框。
- en: Aside from efficient operations, `pandas` also provides `matplotlib` plotting
    library, making it very easy to create a variety of plots without needing to write
    many lines of `matplotlib` code. We can always tweak our plots using `matplotlib`,
    but for quickly visualizing our data, we only need one line of code in `pandas`.
    We will explore this functionality in [*Chapter 5*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106),
    *Visualizing Data with Pandas and Matplotlib*, and [*Chapter 6*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125),
    *Plotting with Seaborn and Customization Techniques*.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 除了高效的运算外，`pandas`还提供了`matplotlib`绘图库，使得我们无需编写大量`matplotlib`代码就能轻松创建各种图表。我们始终可以通过`matplotlib`调整图表，但对于快速可视化数据，我们只需要在`pandas`中写一行代码即可。我们将在[*第五章*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106)，《使用
    Pandas 和 Matplotlib 可视化数据》一章，以及[*第六章*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125)，《使用
    Seaborn 绘图和定制技巧》一章中进一步探索这一功能。
- en: Important note
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Wrapper functions wrap around code from another library, obscuring some of its
    complexity and leaving us with a simpler interface for repeating that functionality.
    This is a core principle of **object-oriented programming** (**OOP**) called **abstraction**,
    which reduces complexity and the duplication of code. We will create our own wrapper
    functions throughout this book.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 封装函数是围绕另一个库的代码而编写的，它们隐藏了一些复杂性，并为重复该功能留下了更简单的接口。这是面向对象编程（**OOP**）的核心原则之一，称为**抽象**，它减少了代码的复杂性和重复。本书中我们将创建自己的封装函数。
- en: In addition to `pandas`, this book makes use of Jupyter Notebooks. While you
    are free to choose not to use them, it's important to be familiar with Jupyter
    Notebooks as they are very common in the data world. As an introduction, we will
    use a Jupyter Notebook to validate our setup in the next section.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`pandas`，这本书还使用了Jupyter Notebooks。虽然你可以选择不使用它们，但熟悉Jupyter Notebooks非常重要，因为它们在数据领域非常常见。作为介绍，我们将在下一节使用Jupyter
    Notebook验证我们的设置。
- en: Jupyter Notebooks
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Jupyter Notebooks
- en: Each chapter of this book includes Jupyter Notebooks for following along. Jupyter
    Notebooks are omnipresent in Python data science because they make it very easy
    to write and test code in more of a discovery environment compared to writing
    a program. We can execute one block of code at a time and have the results printed
    to the notebook, directly beneath the code that generated it. In addition, we
    can use **Markdown** to add text explanations to our work. Jupyter Notebooks can
    be easily packaged up and shared; they can be pushed to GitHub (where they will
    be rendered), converted into HTML or PDF, sent to someone else, or presented.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的每一章都包含用于跟随的Jupyter Notebooks。Jupyter Notebooks在Python数据科学中无处不在，因为它们使得在探索环境中编写和测试代码变得非常简单。我们可以逐块执行代码，并将生成的结果直接打印到笔记本中相应的代码下方。此外，我们可以使用**Markdown**为我们的工作添加文本说明。Jupyter
    Notebooks可以轻松打包和共享；它们可以推送到GitHub（在那里将被渲染），转换为HTML或PDF，发送给其他人，或进行演示。
- en: Launching JupyterLab
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启动 JupyterLab
- en: 'JupyterLab is an IDE that allows us to create Jupyter Notebooks and Python
    scripts, interact with the terminal, create text documents, reference documentation,
    and much more from a clean web interface on our local machine. There are lots
    of keyboard shortcuts to master before really becoming a power user, but the interface
    is pretty intuitive. When we created our environment, we installed everything
    we needed to run JupyterLab, so let''s take a quick tour of the IDE and make sure
    that our environment is set up properly. First, we activate our environment, and
    then we launch JupyterLab:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: JupyterLab是一个IDE，允许我们创建Jupyter Notebooks和Python脚本，与终端交互，创建文本文档，引用文档等等，所有这些功能都可以在我们本地机器的清晰Web界面上完成。在真正成为高级用户之前，有很多键盘快捷键需要掌握，但界面非常直观。在创建环境时，我们已经安装了运行JupyterLab所需的一切，因此让我们快速浏览IDE，确保我们的环境设置正确。首先，激活我们的环境，然后启动JupyterLab：
- en: '[PRE16]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This will then launch a window in the default browser with JupyterLab. We will
    be greeted with the **Launcher** tab and the **File Browser** pane to the left:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 然后会在默认浏览器中启动一个窗口，显示JupyterLab。我们将看到**启动器**选项卡和左侧的**文件浏览器**面板：
- en: '![Figure 1.18 – Launching JupyterLab'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.18 – 启动 JupyterLab'
- en: '](img/Figure_1.18_B16834.jpg)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.18_B16834.jpg)'
- en: Figure 1.18 – Launching JupyterLab
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.18 – 启动 JupyterLab
- en: Using the **File Browser** pane, double-click on the **ch_01** folder, which
    contains the Jupyter Notebook that we will use to validate our setup.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**文件浏览器**面板，在**ch_01**文件夹中双击，其中包含我们用来验证设置的Jupyter Notebook。
- en: Validating the virtual environment
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 验证虚拟环境设置
- en: 'Open the `checking_your_setup.ipynb` notebook in the **ch_01** folder, as shown
    in the following screenshot:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 打开`checking_your_setup.ipynb`笔记本，位于**ch_01**文件夹中，如下截图所示：
- en: '![Figure 1.19 – Validating the virtual environment setup'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.19 – 验证虚拟环境设置'
- en: '](img/Figure_1.19_B16834.jpg)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.19_B16834.jpg)'
- en: Figure 1.19 – Validating the virtual environment setup
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.19 – 验证虚拟环境设置
- en: Important note
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: The **kernel** is the process that runs and introspects our code in a Jupyter
    Notebook. Note that we aren't limited to running Python—we can run kernels for
    R, Julia, Scala, and other languages as well. By default, we will be running Python
    using the IPython kernel. We will learn a little more about IPython throughout
    the book.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核**是在Jupyter Notebook中运行和检查我们代码的进程。请注意，我们不限于运行Python代码 —— 我们也可以运行R、Julia、Scala和其他语言的内核。默认情况下，我们将使用IPython内核来运行Python。在本书中，我们将更深入地学习IPython。'
- en: 'Click on the code cell indicated in the previous screenshot and run it by clicking
    the play (▶) button. If everything shows up in green, the environment is all set
    up. However, if this isn''t the case, run the following command from the virtual
    environment to create a special kernel with the `book_env` virtual environment
    for use with Jupyter:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 点击前面截图中指示的代码单元格，然后通过点击播放（▶）按钮来运行它。如果所有内容都显示为绿色，则环境已经设置好了。但是，如果情况不是这样，请从虚拟环境中运行以下命令，为
    Jupyter 创建一个带有 `book_env` 虚拟环境的特殊核心：
- en: '[PRE17]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This adds an additional option in the `book_env` kernel from a Jupyter Notebook
    as well:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 这在 Jupyter Notebook 中的 `book_env` 核心中添加了一个额外的选项：
- en: '![Figure 1.20 – Selecting a different kernel'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.20 – 选择不同的核心'
- en: '](img/Figure_1.20_B16834.jpg)'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_1.20_B16834.jpg)'
- en: Figure 1.20 – Selecting a different kernel
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.20 – 选择不同的核心
- en: It's important to note that Jupyter Notebooks will retain the values we assign
    to variables while the kernel is running, and the results in the **Out[#]** cells
    will be saved when we save the file. Closing the file doesn't stop the kernel
    and neither does closing the JupyterLab tab in the browser.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，当内核运行时，Jupyter Notebooks 将保留我们为变量分配的值，并且在我们保存文件时，**Out[#]** 单元格中的结果也将被保存。关闭文件并不会停止内核，关闭浏览器中的
    JupyterLab 标签页也不会停止它。
- en: Closing JupyterLab
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关闭 JupyterLab
- en: 'Closing the browser with JupyterLab in it doesn''t stop JupyterLab or the kernels
    it is running (we also won''t get the command-line interface back). To shut down
    JupyterLab entirely, we need to hit *Ctrl* + *C* (which is a keyboard interrupt
    signal that lets JupyterLab know we want to shut it down) a couple of times in
    the terminal until we get the prompt back:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭浏览器中的 JupyterLab 不会停止 JupyterLab 或正在运行的内核（我们也不会重新获得命令行界面）。要完全关闭 JupyterLab，我们需要在终端中按下
    *Ctrl* + *C* 几次（这是一个键盘中断信号，让 JupyterLab 知道我们要关闭它），直到我们重新获得提示符：
- en: '[PRE18]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: For more information about Jupyter, including a tutorial, check out [http://jupyter.org/](http://jupyter.org/).
    Learn more about JupyterLab at [https://jupyterlab.readthedocs.io/en/stable/](https://jupyterlab.readthedocs.io/en/stable/).
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多关于 Jupyter 的信息，包括教程，请访问 [http://jupyter.org/](http://jupyter.org/)。在 [https://jupyterlab.readthedocs.io/en/stable/](https://jupyterlab.readthedocs.io/en/stable/)
    上了解更多关于 JupyterLab 的信息。
- en: Summary
  id: totrans-370
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we learned about the main processes in conducting data analysis:
    data collection, data wrangling, EDA, and drawing conclusions. We followed that
    up with an overview of descriptive statistics and learned how to describe the
    central tendency and spread of our data; how to summarize it both numerically
    and visually using the 5-number summary, box plots, histograms, and kernel density
    estimates; how to scale our data; and how to quantify relationships between variables
    in our dataset.'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了数据分析的主要过程：数据收集、数据整理、探索性数据分析（EDA）和得出结论。接着我们概述了描述性统计，并学习了如何描述数据的中心趋势和分布；如何用五数总结、箱线图、直方图和核密度估计来数值和视觉上总结数据；如何缩放我们的数据；以及如何量化数据集中变量之间的关系。
- en: We got an introduction to prediction and time series analysis. Then, we had
    a very brief overview of some core topics in inferential statistics that can be
    explored after mastering the contents of this book. Note that while all the examples
    in this chapter were of one or two variables, real-life data is often high-dimensional.
    [*Chapter 10*](B16834_10_Final_SK_ePub.xhtml#_idTextAnchor217), *Making Better
    Predictions – Optimizing Models*, will touch on some ways to address this. Lastly,
    we set up our virtual environment for this book and learned how to work with Jupyter
    Notebooks.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初步介绍了预测和时间序列分析。然后，我们简要概述了推断统计学的一些核心主题，这些主题可以在掌握本书内容后进一步探索。请注意，本章中的所有示例都是关于一个或两个变量的，而现实生活中的数据往往是高维的。[*第10章*](B16834_10_Final_SK_ePub.xhtml#_idTextAnchor217)，*做出更好的预测
    – 优化模型*，将涉及一些解决这个问题的方法。最后，我们为本书建立了虚拟环境，并学习了如何使用 Jupyter Notebooks。
- en: Now that we have built a strong foundation, we will start working with data
    in Python in the next chapter.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经打下了坚实的基础，下一章我们将开始在 Python 中处理数据。
- en: Exercises
  id: totrans-374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'Run through the `introduction_to_data_analysis.ipynb` notebook for a review
    of this chapter''s content, review the `python_101.ipynb` notebook (if needed),
    and then complete the following exercises to practice working with JupyterLab
    and calculating summary statistics in Python:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `introduction_to_data_analysis.ipynb` 笔记本来复习本章内容，再复习 `python_101.ipynb` 笔记本（如果需要），然后完成以下练习，练习在
    JupyterLab 中处理数据和计算汇总统计信息：
- en: Explore the JupyterLab interface and look at some of the shortcuts that are
    available. Don't worry about memorizing them for now (eventually, they will become
    second nature and save you a lot of time)—just get comfortable using Jupyter Notebooks.
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 探索JupyterLab界面，了解一些可用的快捷键。现在不用担心记住它们（最终，它们会变成第二天性，节省你很多时间）——只要熟悉使用Jupyter Notebooks。
- en: Is all data normally distributed? Explain why or why not.
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有数据都是正态分布的吗？请解释为什么或为什么不。
- en: When would it make more sense to use the median instead of the mean for the
    measure of center?
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在什么情况下使用中位数而不是均值作为中心度量更有意义？
- en: Run the code in the first cell of the `exercises.ipynb` notebook. It will give
    you a list of 100 values to work with for the rest of the exercises in this chapter.
    Be sure to treat these values as a sample of the population.
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`exercises.ipynb`笔记本中第一个单元格的代码。它将给你一个包含100个值的列表，你将在本章的其他练习中使用这些值。确保将这些值视为总体的样本。
- en: 'Using the data from *exercise 4*, calculate the following statistics without
    importing anything from the `statistics` module in the standard library ([https://docs.python.org/3/library/statistics.html](https://docs.python.org/3/library/statistics.html)),
    and then confirm your results match up to those that are obtained when using the
    `statistics` module (where possible):'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*练习4*中的数据，在不导入任何`statistics`模块（标准库中的[https://docs.python.org/3/library/statistics.html](https://docs.python.org/3/library/statistics.html)）的情况下计算以下统计数据，然后确认你的结果与使用`statistics`模块时得到的结果是否一致（在可能的情况下）：
- en: a) Mean
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 平均值
- en: b) Median
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 中位数
- en: 'c) Mode (hint: check out the `Counter` class in the `collections` module of
    the standard library at [https://docs.python.org/3/library/collections.html#collections.Counter](https://docs.python.org/3/library/collections.html#collections.Counter))'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 众数（提示：查看标准库中`collections`模块的`Counter`类，[https://docs.python.org/3/library/collections.html#collections.Counter](https://docs.python.org/3/library/collections.html#collections.Counter)）
- en: d) Sample variance
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 样本方差
- en: e) Sample standard deviation
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e) 样本标准差
- en: 'Using the data from *exercise 4*, calculate the following statistics using
    the functions in the `statistics` module where appropriate:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*练习4*中的数据，适当使用`statistics`模块中的函数计算以下统计数据：
- en: a) Range
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 范围
- en: b) Coefficient of variation
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 变异系数
- en: c) Interquartile range
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 四分位数间距
- en: d) Quartile coefficient of dispersion
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 四分位差系数
- en: 'Scale the data created in *exercise 4* using the following strategies:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下策略对*练习4*中创建的数据进行缩放：
- en: a) Min-max scaling (normalizing)
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 最小-最大缩放（归一化）
- en: b) Standardizing
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 标准化
- en: 'Using the scaled data from *exercise 7*, calculate the following:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*练习7*中的缩放数据，计算以下内容：
- en: a) The covariance between the standardized and normalized data
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 标准化和归一化数据之间的协方差
- en: b) The Pearson correlation coefficient between the standardized and normalized
    data (this is actually 1, but due to rounding along the way, the result will be
    slightly less)
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 标准化和归一化数据之间的皮尔逊相关系数（这实际上是1，但由于过程中四舍五入，结果会稍微小一点）
- en: Further reading
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The following are some resources that you can use to become more familiar with
    Jupyter:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些资源，可以帮助你更熟悉Jupyter：
- en: '*Jupyter Notebook Basics*: [https://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb](https://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb)'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Jupyter Notebook基础*: [https://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb](https://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb)'
- en: '*JupyterLab introduction*: [https://blog.jupyter.org/jupyterlab-is-ready-for-users-5a6f039b8906](https://blog.jupyter.org/jupyterlab-is-ready-for-users-5a6f039b8906)'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*JupyterLab简介*: [https://blog.jupyter.org/jupyterlab-is-ready-for-users-5a6f039b8906](https://blog.jupyter.org/jupyterlab-is-ready-for-users-5a6f039b8906)'
- en: '*Learning Markdown to make your Jupyter Notebooks presentation-ready*: [https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed](https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed)'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习Markdown，使你的Jupyter Notebooks准备好演示*: [https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed](https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed)'
- en: '*28 Jupyter Notebook Tips, Tricks, and Shortcuts*: [https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/](https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/)'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*28个Jupyter Notebook技巧、窍门和快捷键*: [https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/](https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/)'
- en: 'Some resources for learning more advanced concepts of statistics (that we won''t
    cover here) and carefully applying them are as follows:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 一些资源用于学习更多高级统计概念（我们这里不会涉及），并且仔细应用这些概念，如下所示：
- en: '*A Gentle Introduction to Normality Tests in Python*: [https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/](https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/)'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Python中的正态性检验温和入门*：[https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/](https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/)'
- en: '*How Hypothesis Tests Work: Confidence Intervals and Confidence Levels*: [https://statisticsbyjim.com/hypothesis-testing/hypothesis-tests-confidence-intervals-levels/](https://statisticsbyjim.com/hypothesis-testing/hypothesis-tests-confidence-intervals-levels/)'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*假设检验的工作原理：置信区间和置信水平*：[https://statisticsbyjim.com/hypothesis-testing/hypothesis-tests-confidence-intervals-levels/](https://statisticsbyjim.com/hypothesis-testing/hypothesis-tests-confidence-intervals-levels/)'
- en: '*Intro to Inferential Statistics (Making Predictions with Data) on Udacity*:
    [https://www.udacity.com/course/intro-to-inferential-statistics--ud201](https://www.udacity.com/course/intro-to-inferential-statistics--ud201)'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Udacity的推断统计学入门（用数据进行预测）*：[https://www.udacity.com/course/intro-to-inferential-statistics--ud201](https://www.udacity.com/course/intro-to-inferential-statistics--ud201)'
- en: '*Lesson 4: Confidence Intervals (Penn State Elementary Statistics)*: [https://online.stat.psu.edu/stat200/lesson/4](https://online.stat.psu.edu/stat200/lesson/4)'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第4课：置信区间（宾州州立大学初级统计学）*：[https://online.stat.psu.edu/stat200/lesson/4](https://online.stat.psu.edu/stat200/lesson/4)'
- en: '*Seeing Theory: A visual introduction to probability and statistics*: [https://seeing-theory.brown.edu/index.html](https://seeing-theory.brown.edu/index.html)'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*理论透视：概率与统计的视觉化介绍*：[https://seeing-theory.brown.edu/index.html](https://seeing-theory.brown.edu/index.html)'
- en: '*Statistics Done Wrong: The Woefully Complete Guide by Alex Reinhart*: [https://www.statisticsdonewrong.com/](https://www.statisticsdonewrong.com/)'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*统计学误区：亚历克斯·赖因哈特的完整指南*：[https://www.statisticsdonewrong.com/](https://www.statisticsdonewrong.com/)'
- en: '*Survey Sampling Methods*: [https://stattrek.com/survey-research/sampling-methods.aspx](https://stattrek.com/survey-research/sampling-methods.aspx)'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*调查抽样方法*：[https://stattrek.com/survey-research/sampling-methods.aspx](https://stattrek.com/survey-research/sampling-methods.aspx)'
