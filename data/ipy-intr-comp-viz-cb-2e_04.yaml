- en: Chapter 4. Profiling and Optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：性能分析与优化
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Evaluating the time taken by a statement in IPython
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 IPython 中评估语句所花费的时间
- en: Profiling your code easily with cProfile and IPython
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 cProfile 和 IPython 轻松分析代码
- en: Profiling your code line-by-line with line_profiler
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `line_profiler` 逐行分析代码的性能
- en: Profiling the memory usage of your code with memory_profiler
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `memory_profiler` 分析代码的内存使用情况
- en: Understanding the internals of NumPy to avoid unnecessary array copying
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 NumPy 的内部机制，以避免不必要的数组复制
- en: Using stride tricks with NumPy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 NumPy 的跨步技巧
- en: Implementing an efficient rolling average algorithm with stride tricks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用跨步技巧实现高效的滚动平均算法
- en: Making efficient array selections in NumPy
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 NumPy 中进行高效的数组选择
- en: Processing huge NumPy arrays with memory mapping
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内存映射处理超大的 NumPy 数组
- en: Manipulating large arrays with HDF5 and PyTables
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 HDF5 和 PyTables 操作大数组
- en: Manipulating large heterogeneous tables with HDF5 and PyTables
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 HDF5 和 PyTables 操作大规模异构数据表
- en: Introduction
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: Although Python is generally known (a bit unfairly) as a *slow* language, it
    is possible to achieve very good performance with the right methods. This is the
    objective of this chapter and the next. This chapter describes how to evaluate
    (**profile**) what makes a program slow, and how this information can be used
    to **optimize** the code and make it more efficient. The next chapter will deal
    with more advanced high-performance computing methods that should only be tackled
    when the methods described here are not sufficient.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Python 通常被认为是（有点不公平地）*较慢*的语言，但通过使用正确的方法，实际上可以实现非常好的性能。这就是本章和下一章的目标。本章将介绍如何评估（**分析**）程序变慢的原因，以及如何利用这些信息来**优化**代码，使其更加高效。下一章将讨论一些更高级的高性能计算方法，只有在本章中描述的方法不足以解决问题时才应采用。
- en: 'The recipes of this chapter are organized into three parts:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的内容分为三个部分：
- en: '**Time and memory profiling**: Evaluating the performance of code'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间和内存性能分析**：评估代码的性能'
- en: '**NumPy optimization**: Using NumPy more efficiently, particularly with large
    arrays'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy 优化**：更高效地使用 NumPy，特别是在处理大数组时'
- en: '**Memory mapping with arrays**: Implementing memory mapping techniques for
    out-of-core computations on huge arrays, notably with the HDF5 file format'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存映射与数组**：为超大数组的外存计算实现内存映射技术，特别是使用 HDF5 文件格式'
- en: Evaluating the time taken by a statement in IPython
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 IPython 中评估语句所花费的时间
- en: The `%timeit` magic and the `%%timeit` cell magic (that applies to an entire
    code cell) allow you to quickly evaluate the time taken by one or several Python
    statements. For more extensive profiling, you may need to use more advanced methods
    presented in the next recipes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`%timeit` 魔法命令和 `%%timeit` 单元格魔法命令（适用于整个代码单元）允许你快速评估一个或多个 Python 语句所花费的时间。对于更全面的性能分析，你可能需要使用本章后续介绍的更高级方法。'
- en: How to do it...
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'We are going to estimate the time taken to calculate the sum of the inverse
    squares of all positive integer numbers up to a given `n`:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将估算计算所有正整数的倒数平方和，直到给定的 `n` 所需的时间：
- en: 'Let''s define `n`:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义 `n`：
- en: '[PRE0]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s time this computation in pure Python:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在纯 Python 中计时这段计算：
- en: '[PRE1]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let''s use the `%%timeit` cell magic to time the same computation written
    on two lines:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们使用 `%%timeit` 单元格魔法命令来计时将相同的计算分成两行代码：
- en: '[PRE2]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, let''s time the NumPy version of this computation:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们计时使用 NumPy 版本的计算：
- en: '[PRE3]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How it works...
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `%timeit` command accepts several optional parameters. One such parameter
    is the number of statement evaluations. By default, this number is chosen automatically
    so that the `%timeit` command returns within a few seconds. However, this number
    can be specified directly with the `-r` and `-n` parameters. Type `%timeit?` in
    IPython to get more information.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`%timeit` 命令接受多个可选参数。其中一个参数是语句评估的次数。默认情况下，这个次数会自动选择，以确保 `%timeit` 命令在几秒钟内返回。然而，你也可以通过
    `-r` 和 `-n` 参数直接指定这个次数。在 IPython 中输入 `%timeit?` 以获取更多信息。'
- en: The `%%timeit` cell magic also accepts an optional setup statement in the first
    line (on the same line as `%%timeit`), which is executed but not timed. All variables
    created in this statement are available inside the cell.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`%%timeit` 单元格魔法命令还接受一个可选的设置语句（位于 `%%timeit` 的同一行），该语句会被执行，但不计时。所有在此语句中创建的变量都可以在单元格内部使用。'
- en: There's more...
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: If you are not in an IPython interactive session, you can use `timeit.timeit()`.
    This function, defined in Python's `timeit` module, benchmarks a Python statement
    stored in a string. IPython's `%timeit` magic command is a convenient wrapper
    around `timeit()`, useful in an interactive session. For more information on the
    `timeit` module, refer to [https://docs.python.org/3/library/timeit.html](https://docs.python.org/3/library/timeit.html).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不在 IPython 交互式会话中，可以使用 `timeit.timeit()`。这个函数定义在 Python 的 `timeit` 模块中，用于基准测试存储在字符串中的
    Python 语句。IPython 的 `%timeit` 魔法命令是 `timeit()` 的一个方便封装，适用于交互式会话。有关 `timeit` 模块的更多信息，请参阅
    [https://docs.python.org/3/library/timeit.html](https://docs.python.org/3/library/timeit.html)。
- en: See also
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: The *Profiling your code easily with cProfile and IPython* recipe
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 cProfile 和 IPython 轻松分析代码* 配方'
- en: The *Profiling your code line-by-line with line_profiler* recipe
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*逐行分析代码性能的 line_profiler 配方*'
- en: Profiling your code easily with cProfile and IPython
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 cProfile 和 IPython 轻松分析你的代码
- en: The `%timeit` magic command is often helpful, yet a bit limited when you need
    detailed information about what takes most of the execution time in your code.
    This magic command is meant for **benchmarking** (comparing the execution times
    of different versions of a function) rather than **profiling** (getting a detailed
    report of the execution time, function by function).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`%timeit` 魔法命令通常很有用，但当你需要详细了解代码中哪些部分占用了最多执行时间时，它的功能略显有限。这个魔法命令更适用于**基准测试**（比较不同版本函数的执行时间），而不是**性能分析**（获取按函数细分的执行时间报告）。'
- en: Python includes a profiler named `cProfile` that breaks down the execution time
    into the contributions of all called functions. IPython provides convenient ways
    to leverage this tool in an interactive session.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Python 包含一个名为 `cProfile` 的性能分析器，可以将执行时间分解为所有调用函数的贡献。IPython 提供了在交互式会话中方便使用此工具的方法。
- en: How to do it...
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: IPython offers the `%prun` line magic and the `%%prun` cell magic to easily
    profile one or multiple lines of code. The `%run` magic command also accepts a
    `-p` flag to run a Python script under the control of the profiler. These commands
    accept a lot of options, and you may want to take a look at their documentation
    with `%prun?` and `%run?`.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: IPython 提供了 `%prun` 行魔法命令和 `%%prun` 单元格魔法命令，可以轻松地分析一行或多行代码的性能。`%run` 魔法命令也接受
    `-p` 标志，用于在性能分析器的控制下运行 Python 脚本。这些命令有许多选项，你可能希望查看它们的文档，可以通过 `%prun?` 和 `%run?`
    进行查询。
- en: In this example, we will profile a numerical simulation of random walks starting
    at the origin. We will cover these kinds of simulations in more detail in [Chapter
    13](ch13.html "Chapter 13. Stochastic Dynamical Systems"), *Stochastic Dynamical
    Systems*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将分析一个从原点开始的随机漫步数值模拟。我们将在 [第13章](ch13.html "第13章：随机动力学系统") 中更详细地介绍这些类型的模拟，*随机动力学系统*。
- en: 'Let''s import NumPy and matplotlib:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入 NumPy 和 matplotlib：
- en: '[PRE4]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let''s create a function generating random +1 and -1 values in an array:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个生成随机 +1 和 -1 值的函数，并将其存储在数组中：
- en: '[PRE5]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now, let's write the simulation code in a cell starting with `%%prun` in order
    to profile the entire simulation. The various options allow us to save the report
    in a file and to sort the first 10 results by cumulative time. We will explain
    these options in more detail in the *How it works…* section.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们在一个以 `%%prun` 开头的单元格中编写模拟代码，以便分析整个模拟过程的性能。各种选项允许我们将报告保存到文件中，并按累计时间对前 10
    个结果进行排序。我们将在 *原理介绍* 部分更详细地解释这些选项。
- en: '[PRE6]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The profiling report has been saved in a text file named `prun0`. Let''s display
    it (the following output is a stripped down version that fits on this page):'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 性能分析报告已保存为名为 `prun0` 的文本文件。让我们展示一下它（以下输出是经过简化的版本，以适应本页面）：
- en: '[PRE7]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, we observe the time taken by the different functions involved, directly
    or indirectly, in our code.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们观察了在代码中直接或间接涉及的不同函数的执行时间。
- en: 'If we run the exact same simulation with 500 iterations instead of 50, we obtain
    the following results:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们将模拟的迭代次数从 50 增加到 500，那么运行相同的模拟，我们将得到以下结果：
- en: '[PRE8]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can observe that the number of iterations has a big influence on the relative
    performance cost of the involved functions (notably `cumsum` here).
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以观察到，迭代次数对涉及的函数（特别是 `cumsum` 函数）的相对性能开销有很大影响。
- en: How it works...
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原理介绍...
- en: Python's profiler creates a detailed report of the execution time of our code,
    function by function. Here, we can observe the number of calls of the functions
    `histogram`, `cumsum`, `step`, `sort`, and `rand`, and the total time spent in
    those functions during the code's execution. Internal functions are also profiled.
    For each function, we get the total number of calls, the total and cumulative
    times, and their per-call counterparts (division by `ncalls`). The **total time**
    represents how long the interpreter stays in a given function, *excluding* the
    time spent in calls to subfunctions. The **cumulative time** is similar but *includes*
    the time spent in calls to subfunctions. The filename, function name, and line
    number are displayed in the last column.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的性能分析器会生成关于我们代码执行时间的详细报告，按函数进行分类。在这里，我们可以观察到 `histogram`、`cumsum`、`step`、`sort`
    和 `rand` 函数的调用次数，以及在代码执行过程中这些函数的总时间。内部函数也会被分析。对于每个函数，我们会得到总调用次数、总时间和累积时间，以及每次调用的对应值（通过
    `ncalls` 除以总值）。**总时间**表示解释器在某个函数中停留的时间，*不包括*在调用子函数时所花费的时间。**累积时间**类似，但*包括*在调用子函数时所花费的时间。文件名、函数名和行号会显示在最后一列。
- en: The `%prun` and `%%prun` magic commands accept multiple optional options (type
    `%prun?` for more details). In the example, `-s` allows us to **sort** the report
    by a particular column, `-q` to suppress (**quell**) the pager output (which is
    useful when we want to integrate the output in a notebook), `-l` to **limit**
    the number of lines displayed or to filter the results by function name (which
    is useful when we are interested in a particular function), and `-T` to save the
    report in a **text** file. In addition, we can choose to save (**dump**) the binary
    report in a file with `-D`, or to **return** it in IPython with `-r`. This database-like
    object contains all information about the profiling and can be analyzed through
    Python's `pstats` module.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`%prun` 和 `%%prun` 魔法命令接受多个可选参数（输入 `%prun?` 查看详细信息）。在示例中，`-s` 允许我们按特定列**排序**报告，`-q`
    用于抑制（**抑制**）分页器输出（当我们想将输出整合到笔记本中时很有用），`-l` 用于**限制**显示的行数或按函数名筛选结果（当我们关注某个特定函数时非常有用），`-T`
    用于将报告保存为**文本**文件。此外，我们还可以选择使用 `-D` 保存（**转储**）二进制报告到文件中，或者使用 `-r` 在 IPython 中**返回**报告。这个类似数据库的对象包含所有分析信息，可以通过
    Python 的 `pstats` 模块进行分析。'
- en: Note
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Every profiler brings its own overhead that can bias the profiling results (**probe
    effect**). In other words, a profiled program may run significantly slower than
    a non-profiled program. That's a point to keep in mind.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 每个性能分析器都有其自身的开销，可能会影响分析结果（**探测效应**）。换句话说，一个被分析过的程序可能比未分析的程序运行得慢得多。这一点需要记住。
- en: '"Premature optimization is the root of all evil"'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: “过早的优化是万恶之源”
- en: As Donald Knuth's well-known quote suggests, optimizing code prematurely is
    generally considered a bad practice. Code optimization should only be conducted
    when it's really needed, that is, when the code is really too slow in normal situations.
    Additionally, we should know exactly where we need to optimize your code; typically,
    the vast majority of the execution time comprises a relatively small part of the
    code. The only way to find out is by profiling your code; optimization should
    never be done without preliminary profiling.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 正如 Donald Knuth 的名言所示，过早地优化代码通常被认为是一种不良实践。代码优化应仅在真正需要时进行，也就是说，当代码在正常情况下真的运行得很慢时。此外，我们应当准确知道需要优化代码的地方；通常，执行时间的大部分来自于代码的相对小部分。了解这一点的唯一方法是对代码进行性能分析；优化永远不应在没有初步分析的情况下进行。
- en: Tip
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: I was once dealing with some fairly complicated code that was slower than expected.
    I thought I had a pretty good idea of what was causing the problem and how I could
    resolve it. The solution would involve significant changes in the code. Fortunately,
    I first profiled my code, just to be sure. My diagnostic appeared to be utterly
    wrong; I had written somewhere `max(x)` instead of `np.max(x)` by mistake, where
    `x` was a very large vector. It was Python's built-in function that was called,
    instead of NumPy's heavily optimized routine for arrays. If I hadn't profiled
    my code, I would probably have missed this mistake forever. The program was working
    perfectly fine, only 150 times slower!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾经处理一些相当复杂的代码，速度比预期慢。我以为我对问题的原因和如何解决有相当好的想法。解决方案将涉及对代码的重大更改。幸运的是，我首先对我的代码进行了性能分析，只是为了确保。我的诊断似乎完全错误；我在某处错误地写成了
    `max(x)` 而不是 `np.max(x)`，其中 `x` 是一个非常大的向量。调用的是 Python 的内置函数，而不是 NumPy 为数组高度优化的例程。如果我没有对代码进行性能分析，我可能会永远错过这个错误。程序运行得非常好，只是慢了
    150 倍！
- en: For more general advice on programming optimization, see [http://en.wikipedia.org/wiki/Program_optimization](http://en.wikipedia.org/wiki/Program_optimization).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 有关编程优化的更一般建议，请参阅 [http://en.wikipedia.org/wiki/Program_optimization](http://en.wikipedia.org/wiki/Program_optimization)。
- en: There's more...
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Profiling code in IPython is particularly simple (especially in the notebook),
    as we have seen in this recipe. However, it may be undesirable or difficult to
    execute the code that we need to profile from IPython (GUIs, for example). In
    this case, we can use `cProfile` directly. It is slightly less straightforward
    than with IPython.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在 IPython 中对代码进行性能分析特别简单（尤其在笔记本中），正如我们在本方法中所见。但是，从 IPython 执行我们需要分析的代码可能是不可取或困难的（例如
    GUI）。在这种情况下，我们可以直接使用 `cProfile`。这比在 IPython 中稍微复杂一些。
- en: 'First, we call the following command:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们调用以下命令：
- en: '[PRE9]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The file `profresults` will contain the dump of the profiling results of `myscript.py`.
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文件 `profresults` 将包含 `myscript.py` 的性能分析结果的转储。
- en: 'Then, we execute the following code from Python or IPython to display the profiling
    results in a human-readable form:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们从 Python 或 IPython 执行以下代码，以以人类可读的形式显示性能分析结果：
- en: '[PRE10]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Explore the documentation of the `cProfile` and `pstats` modules to discover
    all of the analyses that you can perform on the profiling reports.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 探索 `cProfile` 和 `pstats` 模块的文档，以了解您可以对性能分析报告执行的所有分析。
- en: Tip
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: The repository at [https://github.com/rossant/easy_profiler](https://github.com/rossant/easy_profiler)
    contains a simple command-line tool that facilitates the profiling of Python scripts.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 位于 [https://github.com/rossant/easy_profiler](https://github.com/rossant/easy_profiler)
    的存储库包含一个简单的命令行工具，可帮助分析 Python 脚本的性能。
- en: There are a few GUI tools for exploring and visualizing the output of a profiling
    session. For example, **RunSnakeRun** allows you to view profile dumps in a GUI
    program.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些 GUI 工具可用于探索和可视化性能分析会话的输出。例如，**RunSnakeRun** 允许您在 GUI 程序中查看性能分析结果。
- en: 'Here are a few references:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些参考资料：
- en: Documentation of `cProfile` and `pstats`, available at [https://docs.python.org/3/library/profile.html](https://docs.python.org/3/library/profile.html)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cProfile` 和 `pstats` 的文档，可在 [https://docs.python.org/3/library/profile.html](https://docs.python.org/3/library/profile.html)
    获取'
- en: RunSnakeRun, at [www.vrplumber.com/programming/runsnakerun/](http://www.vrplumber.com/programming/runsnakerun/)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RunSnakeRun，在 [www.vrplumber.com/programming/runsnakerun/](http://www.vrplumber.com/programming/runsnakerun/)
    上
- en: Python profiling tools, available at [http://blog.ionelmc.ro/2013/06/08/python-profiling-tools/](http://blog.ionelmc.ro/2013/06/08/python-profiling-tools/)
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 的性能分析工具，可在 [http://blog.ionelmc.ro/2013/06/08/python-profiling-tools/](http://blog.ionelmc.ro/2013/06/08/python-profiling-tools/)
    获取
- en: See also
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Profiling your code line-by-line with line_profiler* recipe
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 `line_profiler` 逐行分析您的代码性能* 方法'
- en: Profiling your code line-by-line with line_profiler
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 `line_profiler` 逐行分析您的代码性能
- en: Python's native `cProfile` module and the corresponding `%prun` magic break
    down the execution time of code *function by function*. Sometimes, we may need
    an even more fine-grained analysis of code performance with a *line-by-line* report.
    Such reports can be easier to read than the reports of `cProfile`.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的原生 `cProfile` 模块和相应的 `%prun` 魔术将代码的执行时间*逐个函数*地分解。有时，我们可能需要更细粒度的代码性能分析，以*逐行*报告。这样的报告可能比
    `cProfile` 的报告更易读。
- en: To profile code line-by-line, we need an external Python module named `line_profiler`
    created by Robert Kern, available at [http://pythonhosted.org/line_profiler/](http://pythonhosted.org/line_profiler/).
    In this recipe, we will demonstrate how to use this module within IPython.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要按行分析代码，我们需要一个名为`line_profiler`的外部Python模块，由Robert Kern创建，模块可从[http://pythonhosted.org/line_profiler/](http://pythonhosted.org/line_profiler/)获得。在本教程中，我们将演示如何在IPython中使用该模块。
- en: Getting ready
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备好
- en: To install `line_profiler`, type `pip install line_profiler` in a terminal,
    or type `!pip install line_profiler` in IPython (you need a C compiler).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装`line_profiler`，在终端中输入`pip install line_profiler`，或在IPython中输入`!pip install
    line_profiler`（你需要一个C编译器）。
- en: On Windows, you can use Chris Gohlke's unofficial package available at [www.lfd.uci.edu/~gohlke/pythonlibs/#line_profiler](http://www.lfd.uci.edu/~gohlke/pythonlibs/#line_profiler).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上，你可以使用Chris Gohlke提供的非官方包，下载地址为[www.lfd.uci.edu/~gohlke/pythonlibs/#line_profiler](http://www.lfd.uci.edu/~gohlke/pythonlibs/#line_profiler)。
- en: How do to it...
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 怎么做...
- en: 'We will profile the same simulation code as in the previous recipe, line-by-line:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐行分析与上一教程相同的模拟代码：
- en: 'First, let''s import NumPy and the `line_profiler` IPython extension module
    that comes with the package:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们导入NumPy和随包一起提供的`line_profiler` IPython扩展模块：
- en: '[PRE11]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This IPython extension module provides a `%lprun` magic command to profile
    a Python function line-by-line. It works best when the function is defined in
    a file and not in the interactive namespace or in the notebook. Therefore, here
    we write our code in a Python script using the `%%writefile` cell magic:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个IPython扩展模块提供了一个`%lprun`魔法命令，用于逐行分析Python函数。它在函数定义在文件中而不是在交互式命名空间或笔记本中时效果最好。因此，在这里，我们将代码写入Python脚本，并使用`%%writefile`单元魔法：
- en: '[PRE12]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, let''s import this script into the interactive namespace so that we can
    execute and profile our code:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将这个脚本导入到交互式命名空间中，以便执行和分析我们的代码：
- en: '[PRE13]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We execute the function under the control of the line profiler. The functions
    to be profiled need to be explicitly specified in the `%lprun` magic command.
    We also save the report in a file, `lprof0`:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在行级分析器的控制下执行函数。需要分析的函数必须在`%lprun`魔法命令中明确指定。我们还将报告保存在一个文件中，命名为`lprof0`：
- en: '[PRE14]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s display the report (the following output is a stripped-down version
    that fits in the page):'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们展示报告（以下输出是经过精简的版本，以适应页面）：
- en: '[PRE15]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If we perform the same analysis with 10 times the previous number of iterations
    (`simulation.simulate(500)`), we get the following report:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们用比之前多10倍的迭代次数（`simulation.simulate(500)`）执行相同的分析，我们会得到如下报告：
- en: '[PRE16]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: How it works...
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `%lprun` command accepts a Python statement as its main argument. The functions
    to profile need to be explicitly specified with `-f`. Other optional arguments
    include `-D`, `-T`, and `-r`, and they work in a similar way to their `%prun`
    magic command counterparts.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`%lprun`命令接受一个Python语句作为其主要参数。需要分析的函数必须通过`-f`明确指定。其他可选参数包括`-D`、`-T`和`-r`，它们的工作方式类似于`%prun`魔法命令的对应参数。'
- en: The `line_profiler` module displays the time spent on each line of the profiled
    functions, either in timer units or as a fraction of the total execution time.
    These details are essential when we are looking for hotspots in our code.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`line_profiler`模块显示每一行分析函数所花费的时间，可以以计时单位或总执行时间的分数形式显示。当我们在查找代码热点时，这些详细信息至关重要。'
- en: There's more...
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: As in the previous recipe, there may be a need to run the line-by-line profiler
    on a standalone Python program that cannot be launched easily from IPython. The
    procedure is a bit convoluted.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一教程一样，可能需要对一个独立的Python程序运行逐行分析器，该程序无法从IPython轻松启动。这个过程稍显复杂。
- en: We download the `kernprof` file from [https://github.com/rkern/line_profiler/blob/master/kernprof.py](https://github.com/rkern/line_profiler/blob/master/kernprof.py),
    and save it in your code's directory.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从[https://github.com/rkern/line_profiler/blob/master/kernprof.py](https://github.com/rkern/line_profiler/blob/master/kernprof.py)下载`kernprof`文件，并将其保存在代码的目录中。
- en: 'In the code, we decorate the functions we wish to profile with `@profile`.
    We need to remove these decorators at the end of the profiling session, as they
    will raise `NameError` exceptions if the code is executed normally (that is, not
    under the control of the line profiler):'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在代码中，我们用`@profile`装饰器来装饰我们希望分析的函数。我们需要在分析会话结束后删除这些装饰器，因为如果代码正常执行（即不在行级分析器的控制下），它们会引发`NameError`异常：
- en: '[PRE17]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Tip
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: See also the [http://stackoverflow.com/questions/18229628/python-profiling-using-line-profiler-clever-way-to-remove-profile-statements](http://stackoverflow.com/questions/18229628/python-profiling-using-line-profiler-clever-way-to-remove-profile-statements)
    link for a clever way to remove profile statements.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参见[http://stackoverflow.com/questions/18229628/python-profiling-using-line-profiler-clever-way-to-remove-profile-statements](http://stackoverflow.com/questions/18229628/python-profiling-using-line-profiler-clever-way-to-remove-profile-statements)链接，了解一种巧妙的方法来移除配置文件语句。
- en: 'We execute the following command in a terminal:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在终端中执行以下命令：
- en: '[PRE18]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `myscript.py` script will be executed, and the report will be saved in `lprof.txt`.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将执行`myscript.py`脚本，并将报告保存到`lprof.txt`中。
- en: Tip
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: The repository at [https://github.com/rossant/easy_profiler](https://github.com/rossant/easy_profiler)
    offers a slightly simpler way of using the line-by-line profiler.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://github.com/rossant/easy_profiler](https://github.com/rossant/easy_profiler)上的代码库提供了一个稍微简化的逐行分析工具使用方法。'
- en: Tracing the step-by-step execution of a Python program
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪Python程序逐步执行过程
- en: Let's also talk about **tracing** tools for Python, which can be useful for
    profiling or debugging a program, or for educational purposes.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将讨论**跟踪**工具，它们对于性能分析、调试程序或用于教育目的非常有用。
- en: Python's `trace` module allows us to trace program execution of Python code.
    That's extremely useful during in-depth debugging and profiling sessions. We can
    follow the entire sequence of instructions executed by the Python interpreter.
    More information on the trace module is available at [https://docs.python.org/3/library/trace.html](https://docs.python.org/3/library/trace.html).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Python的`trace`模块允许我们跟踪Python代码的程序执行。这在深入调试和性能分析过程中非常有用。我们可以跟踪Python解释器执行的所有指令序列。有关trace模块的更多信息，请访问[https://docs.python.org/3/library/trace.html](https://docs.python.org/3/library/trace.html)。
- en: In addition, the **Online Python Tutor** is an online interactive educational
    tool that can help us understand what the Python interpreter is doing step-by-step
    as it executes a program's source code. The Online Python Tutor is available at
    [http://pythontutor.com/](http://pythontutor.com/).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，**在线 Python Tutor** 是一个在线交互式教育工具，帮助我们逐步理解 Python 解释器在执行程序源代码时的操作。在线 Python
    Tutor 可通过[http://pythontutor.com/](http://pythontutor.com/)访问。
- en: See also
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Profiling your code easily with cProfile and IPython* recipe
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用cProfile和IPython轻松进行代码性能分析*的技巧'
- en: The *Profiling the memory usage of your code with memory_profiler* recipe
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用memory_profiler分析代码的内存使用情况*的技巧'
- en: Profiling the memory usage of your code with memory_profiler
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用memory_profiler分析代码的内存使用情况
- en: The methods described in the previous recipe were about CPU time profiling.
    That may be the most obvious factor when it comes to code profiling. However,
    memory is also a critical factor. For instance, running `np.zeros(500000000)`
    is likely to instantaneously crash your computer! This command may allocate more
    memory than is available on your system; your computer will then reach a nonresponsive
    state within seconds.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 前一篇配方中描述的方法是关于CPU时间的性能分析。这可能是代码性能分析中最显著的因素。然而，内存也是一个关键因素。例如，运行`np.zeros(500000000)`很可能会立即崩溃你的计算机！这个命令可能会分配超过系统可用内存的内存；你的计算机会在几秒钟内进入无响应状态。
- en: Writing memory-optimized code is not trivial and can really make your program
    faster. This is particularly important when dealing with large NumPy arrays, as
    we will see later in this chapter.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 编写内存优化代码并不简单，但能显著提升程序的运行速度。尤其在处理大型NumPy数组时，这一点尤为重要，正如我们将在本章后面看到的那样。
- en: In this recipe, we will look at a simple memory profiler. This library, unsurprisingly
    called `memory_profiler`, was created by Fabian Pedregosa. Its usage is very similar
    to `line_profiler`, and it can be conveniently used from IPython. You can download
    it from [https://pypi.python.org/pypi/memory_profiler](https://pypi.python.org/pypi/memory_profiler).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将介绍一个简单的内存分析工具。这个库，毫不奇怪地叫做`memory_profiler`，由Fabian Pedregosa创建。它的使用方式与`line_profiler`非常相似，且可以方便地从IPython中使用。你可以从[https://pypi.python.org/pypi/memory_profiler](https://pypi.python.org/pypi/memory_profiler)下载它。
- en: Getting ready
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You can install `memory_profiler` with `pip install memory_profiler`.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过`pip install memory_profiler`来安装`memory_profiler`。
- en: On Windows, you also need `psutil`, which is available at [https://pypi.python.org/pypi/psutil](https://pypi.python.org/pypi/psutil).
    You can install it with `pip install psutil`, or by downloading the package from
    [https://code.google.com/p/psutil/](https://code.google.com/p/psutil/). You can
    also download an installer from Chris Gohlke's webpage at [www.lfd.uci.edu/~gohlke/pythonlibs/](http://www.lfd.uci.edu/~gohlke/pythonlibs/).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，您还需要 `psutil`，它可以在 [https://pypi.python.org/pypi/psutil](https://pypi.python.org/pypi/psutil)
    上找到。您可以使用 `pip install psutil` 安装，或者从 [https://code.google.com/p/psutil/](https://code.google.com/p/psutil/)
    下载该包。您也可以从 Chris Gohlke 的网页 [www.lfd.uci.edu/~gohlke/pythonlibs/](http://www.lfd.uci.edu/~gohlke/pythonlibs/)
    下载安装程序。
- en: The example in this recipe is the continuation of the previous recipe.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本方法中的示例是前一个方法的延续。
- en: How to do it...
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Assuming that the simulation code has been loaded as shown in the previous
    recipe, we load the memory profiler IPython extension:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设仿真代码已经如前一个方法中所示加载，我们加载内存分析器的 IPython 扩展：
- en: '[PRE19]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, let''s run the code under the control of the memory profiler:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们在内存分析器的控制下运行代码：
- en: '[PRE20]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s show the results:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们展示结果：
- en: '[PRE21]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Finally, here is the report with 500 iterations:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，这是进行 500 次迭代的报告：
- en: '[PRE22]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How it works...
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `memory_profiler` package checks the memory usage of the interpreter at
    every line. The **increment** column allows us to spot those places in the code
    where large amounts of memory are allocated. This is especially important when
    working with arrays. Unnecessary array creations and copies can considerably slow
    down a program. We will tackle this issue in the next few recipes.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`memory_profiler` 包检查每行代码的内存使用情况。**增量** 列帮助我们发现代码中分配大量内存的地方。当处理数组时，这一点尤其重要。不必要的数组创建和复制会显著减慢程序速度。我们将在接下来的几个方法中解决这个问题。'
- en: There's more...
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We can use `memory_profiler` without IPython, and we can also use a quick memory
    benchmark in IPython for single commands.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在没有 IPython 的情况下使用 `memory_profiler`，也可以在 IPython 中对单个命令进行快速内存基准测试。
- en: Using memory_profiler for standalone Python programs
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在独立的 Python 程序中使用 memory_profiler
- en: Using the memory profiler with standalone Python programs is similar but slightly
    simpler than with `line_profiler`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在独立的 Python 程序中使用内存分析器与使用 `line_profiler` 类似，但稍微简单一些。
- en: First, in our Python scripts, we decorate the functions we wish to profile with
    `@profile`.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，在我们的 Python 脚本中，我们通过 `@profile` 装饰器标记我们希望分析的函数。
- en: 'Then, we run:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们运行：
- en: '[PRE23]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The profiling report will be saved in `myprof.txt`.
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分析报告将保存在 `myprof.txt` 中。
- en: Using the %memit magic command in IPython
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 IPython 中使用 %memit 魔法命令
- en: 'The `memory_profiler` IPython extension also comes with a `%memit` magic command
    that lets us benchmark the memory used by a single Python statement. Here is a
    simple example:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`memory_profiler` 的 IPython 扩展还附带了一个 `%memit` 魔法命令，让我们可以基准测试单个 Python 语句所使用的内存。这里是一个简单的例子：'
- en: '[PRE24]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Other tools
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他工具
- en: There are other tools to monitor the memory usage of a Python program, notably
    Guppy-PE ([http://guppy-pe.sourceforge.net/](http://guppy-pe.sourceforge.net/)),
    PySizer ([http://pysizer.8325.org/](http://pysizer.8325.org/)), and Pympler ([https://code.google.com/p/pympler/](https://code.google.com/p/pympler/)).
    Used in conjunction with IPython and Python's introspection capabilities, these
    tools allow you to analyze the memory usage of a namespace or a particular object.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他工具可以监控 Python 程序的内存使用情况，特别是 Guppy-PE ([http://guppy-pe.sourceforge.net/](http://guppy-pe.sourceforge.net/))、PySizer
    ([http://pysizer.8325.org/](http://pysizer.8325.org/)) 和 Pympler ([https://code.google.com/p/pympler/](https://code.google.com/p/pympler/))。与
    IPython 及 Python 的自省功能结合使用时，这些工具允许您分析命名空间或特定对象的内存使用情况。
- en: See also
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Profiling your code line-by-line with line_profiler* recipe
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*逐行分析代码并使用 line_profiler* 方法'
- en: The *Understanding the internals of NumPy to avoid unnecessary array copying*
    recipe
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*理解 NumPy 的内部机制以避免不必要的数组复制* 方法'
- en: Understanding the internals of NumPy to avoid unnecessary array copying
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 NumPy 的内部机制以避免不必要的数组复制
- en: We can achieve significant performance speedups with NumPy over native Python
    code, particularly when our computations follow the **Single Instruction, Multiple
    Data** (**SIMD**) paradigm. However, it is also possible to unintentionally write
    non-optimized code with NumPy.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 NumPy，我们可以显著提高性能，特别是当我们的计算遵循 **单指令多数据** (**SIMD**) 模式时。然而，也有可能无意中写出非优化的 NumPy
    代码。
- en: In the next few recipes, we will see some tricks that can help us write optimized
    NumPy code. In this recipe, we will see how to avoid unnecessary array copies
    in order to save memory. In that respect, we will need to dig into the internals
    of NumPy.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几个案例中，我们将看到一些可以帮助我们编写优化NumPy代码的技巧。在这个案例中，我们将看到如何避免不必要的数组复制，从而节省内存。在这方面，我们需要深入了解NumPy的内部实现。
- en: Getting ready
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'First, we need a way to check whether two arrays share the same underlying
    data buffer in memory. Let''s define a function `id()` that returns the memory
    location of the underlying data buffer:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一种方法来检查两个数组是否共享相同的底层数据缓冲区。我们可以定义一个返回底层数据缓冲区内存位置的函数`id()`：
- en: '[PRE25]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Two arrays with the same data location (as returned by `id`) share the same
    underlying data buffer. However, the opposite is true only if the arrays have
    the same **offset** (meaning that they have the same first element). Two shared
    arrays with different offsets will have slightly different memory locations, as
    shown in the following example:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 两个具有相同数据位置（由`id`返回的）数组共享相同的底层数据缓冲区。然而，只有在数组具有相同**偏移量**（意味着它们的第一个元素相同）时，才会发生这种情况。具有不同偏移量的共享数组会有稍微不同的内存位置，下面的示例说明了这一点：
- en: '[PRE26]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In the next few recipes, we''ll make sure to use this method with arrays that
    have the same offset. Here is a more general and reliable solution for finding
    out whether two arrays share the same data:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几个案例中，我们将确保使用相同偏移量的数组。以下是一个更通用且可靠的解决方案，用于判断两个数组是否共享相同的数据：
- en: '[PRE27]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Thanks to Michael Droettboom for pointing this out and proposing this alternative
    solution.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢Michael Droettboom指出这一点并提出这种替代解决方案。
- en: How to do it...
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'Computations with NumPy arrays may involve internal copies between blocks of
    memory. These copies are not always necessary, in which case they should be avoided,
    as we will see in the following tips:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NumPy数组进行计算可能涉及内存块之间的内部复制。这些复制并非总是必要的，如果没有必要，应避免它们，正如我们将在以下提示中看到的：
- en: 'We may sometimes need to make a copy of an array; for instance, if we need
    to manipulate an array while keeping an original copy in memory:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们有时需要对数组进行复制；例如，如果我们需要在保留原始副本的情况下操作数组：
- en: '[PRE28]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Array computations can involve in-place operations (the first example in the
    following code: the array is modified) or implicit-copy operations (the second
    example: a new array is created):'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数组计算可以涉及就地操作（以下代码中的第一个示例：数组被修改）或隐式复制操作（第二个示例：创建了一个新数组）：
- en: '[PRE29]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Be sure to choose the type of operation you actually need. Implicit-copy operations
    are significantly slower, as shown here:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保选择你实际需要的操作类型。隐式复制操作显著较慢，如下所示：
- en: '[PRE30]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Reshaping an array may or may not involve a copy. The reasons will be explained
    in the *How it works...* section. For instance, reshaping a 2D matrix does not
    involve a copy, unless it is transposed (or more generally, **non-contiguous**):'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重塑数组可能会或可能不会涉及复制。原因将在*它是如何工作的...*部分解释。例如，重塑一个二维矩阵不会涉及复制，除非它被转置（或者更一般地说，**非连续**）：
- en: '[PRE31]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Therefore, the latter instruction will be significantly slower than the former.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，后者的操作将显著慢于前者。
- en: Both the `flatten` and the `ravel` methods of an array reshape it into a 1D
    vector (a flattened array). However, the `flatten` method always returns a copy,
    and the `ravel` method returns a copy only if necessary (thus it's faster, especially
    with large arrays).
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数组的`flatten`和`ravel`方法都会将其重塑为一维向量（一个扁平化的数组）。然而，`flatten`方法总是返回一个副本，而`ravel`方法仅在必要时返回副本（因此它更快，尤其是在处理大数组时）。
- en: '[PRE32]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '**Broadcasting rules** allow us to make computations on arrays with different
    but compatible shapes. In other words, we don''t always need to reshape or tile
    our arrays to make their shapes match. The following example illustrates two ways
    of doing an **outer product** between two vectors: the first method involves array
    tiling, the second one (faster) involves broadcasting:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**广播规则**允许我们对形状不同但兼容的数组进行计算。换句话说，我们不总是需要重塑或拼接数组来使它们的形状匹配。以下示例演示了在两个向量之间进行**外积**的两种方法：第一种方法涉及数组拼接，第二种方法（更快）涉及广播：'
- en: '[PRE33]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: How it works...
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this section, we will see what happens under the hood when using NumPy, and
    how this knowledge allows us to understand the tricks given in this recipe.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到在使用NumPy时，内部发生了什么，以及这些知识如何帮助我们理解本食谱中的技巧。
- en: Why are NumPy arrays efficient?
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么NumPy数组高效？
- en: A NumPy array is basically described by metadata (notably the number of dimensions,
    the shape, and the data type) and the actual data. The data is stored in a homogeneous
    and contiguous block of memory, at a particular address in system memory (**Random
    Access Memory**, or **RAM**). This block of memory is called the **data buffer**.
    This is the main difference when compared to a pure Python structure, such as
    a list, where the items are scattered across the system memory. This aspect is
    the critical feature that makes NumPy arrays so efficient.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 数组基本上由元数据描述（特别是维数、形状和数据类型）和实际数据组成。数据存储在一个同质且连续的内存块中，位于系统内存中的特定地址（**随机存取存储器**，或者**RAM**）。这个内存块称为**数据缓冲区**。与纯
    Python 结构（如列表）相比，其中项目分散在系统内存中，这是主要区别。这个方面是使 NumPy 数组如此高效的关键特性。
- en: 'Why is this so important? Here are the main reasons:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这么重要呢？以下是主要原因：
- en: Computations on arrays can be written very efficiently in a low-level language
    such as C (and a large part of NumPy is actually written in C). Knowing the address
    of the memory block and the data type, it is just simple arithmetic to loop over
    all items, for example. There would be a significant overhead to do that in Python
    with a list.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在低级语言（如 C）中，可以非常高效地编写数组上的计算（NumPy 的大部分实际上是用 C 编写的）。只要知道内存块的地址和数据类型，就可以简单地进行循环遍历所有项目，例如。在
    Python 中使用列表进行这样的操作会有很大的开销。
- en: '**Spatial locality** in memory access patterns results in performance gains
    notably due to the CPU cache. Indeed, the cache loads bytes in chunks from RAM
    to the CPU registers. Adjacent items are then loaded very efficiently (**sequential
    locality**, or **locality of reference**).'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空间局部性**在内存访问模式中导致性能提升，这主要是由于 CPU 缓存。事实上，缓存会将字节以块的形式从 RAM 加载到 CPU 寄存器中。然后，相邻的项目会被非常高效地加载（**顺序局部性**，或者**引用局部性**）。'
- en: Finally, the fact that items are stored contiguously in memory allows NumPy
    to take advantage of **vectorized instructions** of modern CPUs, such as Intel's
    **SSE** and **AVX**, AMD's XOP, and so on. For example, multiple consecutive floating
    point numbers can be loaded in 128, 256, or 512 bits registers for vectorized
    arithmetical computations implemented as CPU instructions.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，项目在内存中连续存储的事实使得 NumPy 能够利用现代 CPU 的**矢量化指令**，例如英特尔的**SSE**和**AVX**，AMD 的 XOP
    等。例如，多个连续的浮点数可以加载到 128、256 或 512 位寄存器中，用作实现为 CPU 指令的矢量化算术计算。
- en: Note
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Additionally, NumPy can be linked to highly optimized linear algebra libraries
    such as **BLAS** and **LAPACK** through **ATLAS** or the **Intel Math Kernel Library**
    (**MKL**). A few specific matrix computations may also be multithreaded, taking
    advantage of the power of modern multicore processors.
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另外，NumPy 可以通过**ATLAS**或**英特尔数学核心库**（**MKL**）与高度优化的线性代数库（如**BLAS**和**LAPACK**）链接。一些特定的矩阵计算也可以是多线程的，利用现代多核处理器的强大性能。
- en: In conclusion, storing data in a contiguous block of memory ensures that the
    architecture of modern CPUs is used optimally, in terms of memory access patterns,
    CPU cache, and vectorized instructions.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，将数据存储在连续的内存块中确保了现代 CPU 架构在内存访问模式、CPU 缓存和矢量化指令方面的最佳利用。
- en: What is the difference between in-place and implicit-copy operations?
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原地操作和隐式复制操作之间有什么区别？
- en: Let's explain the example in step 2\. An expression such as `a *= 2` corresponds
    to an in-place operation, where all values of the array are multiplied by two.
    By contrast, `a = a*2` means that a new array containing the values of `a*2` is
    created, and the variable `a` now points to this new array. The old array becomes
    unreferenced and will be deleted by the garbage collector. No memory allocation
    happens in the first case, contrary to the second case.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释第 2 步中的示例。诸如 `a *= 2` 这样的表达式对应于原地操作，其中数组的所有值都乘以了二。相比之下，`a = a*2` 意味着创建了一个包含
    `a*2` 值的新数组，并且变量 `a` 现在指向这个新数组。旧数组变得没有引用，并将被垃圾回收器删除。与第二种情况相反，第一种情况中不会发生内存分配。
- en: More generally, expressions such as `a[i:j]` are **views** to parts of an array;
    they point to the memory buffer containing the data. Modifying them with in-place
    operations changes the original array. Hence, `a[:] = a*2` results in an in-place
    operation, unlike `a = a*2`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地，诸如 `a[i:j]` 这样的表达式是数组的**视图**；它们指向包含数据的内存缓冲区。使用原地操作修改它们会改变原始数组。因此，`a[:]
    = a*2` 是一个原地操作，不同于 `a = a*2`。
- en: Knowing this subtlety of NumPy can help you fix some bugs (where an array is
    implicitly and unintentionally modified because of an operation on a view), and
    optimize the speed and memory consumption of your code by reducing the number
    of unnecessary copies.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 了解NumPy的这种微妙之处可以帮助你修复一些错误（因为一个数组由于对视图的操作而被隐式和无意中修改），并通过减少不必要的复制次数来优化代码的速度和内存消耗。
- en: Why can't some arrays be reshaped without a copy?
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么有些数组不能在没有复制的情况下重塑？
- en: 'We explain the example in step 3 here, where a transposed 2D matrix cannot
    be flattened without a copy. A 2D matrix contains items indexed by two numbers
    (row and column), but it is stored internally as a 1D contiguous block of memory,
    accessible with a single number. There is more than one way of storing matrix
    items in a 1D block of memory: we can put the elements of the first row first,
    then the second row, and so on, or the elements of the first column first, then
    the second column, and so on. The first method is called **row-major order**,
    whereas the latter is called **column-major order**. Choosing between the two
    methods is only a matter of internal convention: NumPy uses the row-major order,
    like C, but unlike FORTRAN.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里解释第3步的示例，其中一个转置的2D矩阵不能在没有复制的情况下被展平。一个2D矩阵包含由两个数字（行和列）索引的项目，但它在内部存储为一个1D连续的内存块，可以用一个数字访问。有多种将矩阵项目存储在1D内存块中的方法：我们可以先放第一行的元素，然后是第二行，依此类推，或者先放第一列的元素，然后是第二列，依此类推。第一种方法称为**行主序**，而后者称为**列主序**。在这两种方法之间的选择只是内部约定的问题：NumPy使用行主序，类似于C，但不同于FORTRAN。
- en: '![Why can''t some arrays be reshaped without a copy?](img/4818OS_04_01.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![为什么有些数组不能在没有复制的情况下重塑？](img/4818OS_04_01.jpg)'
- en: 'Internal array layouts: row-major and column-major orders'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 内部数组布局：行主序和列主序
- en: 'More generally, NumPy uses the notion of `strides` to convert between a multidimensional
    index and the memory location of the underlying (1D) sequence of elements. The
    specific mapping between `array[i1, i2]` and the relevant byte address of the
    internal data is given by:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地说，NumPy使用`strides`的概念来在多维索引和底层（1D）元素序列的内存位置之间进行转换。`array[i1, i2]`与内部数据的相关字节地址之间的具体映射如下：
- en: '[PRE34]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: When reshaping an array, NumPy avoids copies when possible by modifying the
    `strides` attribute. For example, when transposing a matrix, the order of strides
    is reversed, but the underlying data remains identical. However, flattening a
    transposed array cannot be accomplished simply by modifying strides (try it!),
    so a copy is needed (thanks to Chris Beaumont for clarifying an earlier version
    of this paragraph).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在重塑数组时，NumPy通过修改`strides`属性来尽可能避免复制。例如，当转置矩阵时，步幅的顺序被颠倒，但底层数据保持不变。然而，简单通过修改步幅来展平一个转置数组是不可能的（试试看！），因此需要进行复制（感谢Chris
    Beaumont澄清了本段早期版本）。
- en: Internal array layout can also explain some unexpected performance discrepancies
    between very similar NumPy operations. As a small exercise, can you explain the
    following benchmarks?
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 内部数组布局还可以解释一些非常相似的NumPy操作之间的意外性能差异。作为一个小练习，你能解释以下基准测试吗？
- en: '[PRE35]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: What are NumPy broadcasting rules?
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NumPy广播规则是什么？
- en: Broadcasting rules describe how arrays with different dimensions and/or shapes
    can be used for computations. The general rule is that *two dimensions are compatible
    when they are equal, or when one of them is 1*. NumPy uses this rule to compare
    the shapes of the two arrays element-wise, starting with the trailing dimensions
    and working its way forward. The smallest dimension is internally stretched to
    match the other dimension, but this operation does not involve any memory copy.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 广播规则描述了具有不同维度和/或形状的数组如何用于计算。一般规则是*当两个维度相等或其中一个为1时，它们是兼容的*。NumPy使用此规则逐个元素地比较两个数组的形状，从尾部维度开始，逐步向前工作。最小的维度在内部被拉伸以匹配另一个维度，但此操作不涉及任何内存复制。
- en: There's more...
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Here are a few references:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些参考资料：
- en: Broadcasting rules and examples, available at [http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广播规则和示例，可在[http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)找到。
- en: Array interface in NumPy, at [http://docs.scipy.org/doc/numpy/reference/arrays.interface.html](http://docs.scipy.org/doc/numpy/reference/arrays.interface.html)
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy中的数组接口，位于[http://docs.scipy.org/doc/numpy/reference/arrays.interface.html](http://docs.scipy.org/doc/numpy/reference/arrays.interface.html)
- en: Locality of reference, at [http://en.wikipedia.org/wiki/Locality_of_reference](http://en.wikipedia.org/wiki/Locality_of_reference)
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引用自[http://en.wikipedia.org/wiki/Locality_of_reference](http://en.wikipedia.org/wiki/Locality_of_reference)的参考资料
- en: Internals of NumPy in the SciPy lectures notes, available at [http://scipy-lectures.github.io/advanced/advanced_numpy/](http://scipy-lectures.github.io/advanced/advanced_numpy/)
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SciPy讲座笔记中的NumPy内部，可在[http://scipy-lectures.github.io/advanced/advanced_numpy/](http://scipy-lectures.github.io/advanced/advanced_numpy/)找到
- en: 100 NumPy exercises by Nicolas Rougier, available at [www.loria.fr/~rougier/teaching/numpy.100/index.html](http://www.loria.fr/~rougier/teaching/numpy.100/index.html)
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nicolas Rougier编写的100个NumPy练习，可在[www.loria.fr/~rougier/teaching/numpy.100/index.html](http://www.loria.fr/~rougier/teaching/numpy.100/index.html)找到
- en: See also
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Using stride tricks with NumPy* recipe
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用NumPy的步幅技巧*示例'
- en: Using stride tricks with NumPy
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用NumPy的步幅技巧
- en: In this recipe, we will dig deeper into the internals of NumPy arrays, by generalizing
    the notion of row-major and column-major orders to multidimensional arrays. The
    general notion is that of **strides**, which describe how the items of a multidimensional
    array are organized within a one-dimensional data buffer. Strides are mostly an
    implementation detail, but they can also be used in specific situations to optimize
    some algorithms.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将深入研究NumPy数组的内部，通过将行优先和列优先顺序的概念推广到多维数组。一般概念是**步幅**，描述多维数组的项在一维数据缓冲区内的组织方式。步幅大多是一个实现细节，但在特定情况下也可以用于优化一些算法。
- en: Getting ready
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We suppose that NumPy has been imported and that the `id` function has been
    defined (see the previous recipe, *Understanding the internals of NumPy to avoid
    unnecessary array copying*).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设已经导入了NumPy，并且`id`函数已经定义（参见前一个示例，*了解NumPy的内部以避免不必要的数组复制*）。
- en: How to do it...
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: Strides are integer numbers describing the byte step in the contiguous block
    of memory for each dimension.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 步幅是描述每个维度在连续内存块中的字节步长的整数。
- en: '[PRE36]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This vector `x` contains double-precision floating point numbers (float64, 8
    bytes); one needs to go *8 bytes forward* to go from one item to the next.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个向量`x`包含双精度浮点数（float64，8字节）；从一个项目到下一个项目需要*向前移动8字节*。
- en: 'Now, let''s look at the strides of a 2D array:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们看一下一个二维数组的步幅：
- en: '[PRE37]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In the first dimension (vertical), one needs to go *80 bytes* (10 float64 items)
    *forward* to go from one item to the next, because the items are internally stored
    in row-major order. In the second dimension (horizontal), one needs to go *8 bytes*
    *forward* to go from one item to the next.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第一维（垂直）中，从一个项目到下一个项目需要*向前移动80字节*（10个float64项目），因为项目在内部以行优先顺序存储。在第二维（水平）中，从一个项目到下一个项目需要*向前移动8字节*。
- en: 'Let''s show how we can revisit the broadcasting rules from the previous recipe
    using strides:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们展示如何使用步幅重新审视前一个示例中的广播规则：
- en: '[PRE38]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We will create a new array, `b`, pointing to the same memory block as `a`,
    but with a different shape and different strides. This new array will look like
    a vertically-tiled version of `a`. We use a special function in NumPy to change
    the strides of an array:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将创建一个新数组`b`，指向与`a`相同的内存块，但形状和步幅不同。这个新数组看起来像是`a`的垂直平铺版本。我们使用NumPy中的一个特殊函数来改变数组的步幅：
- en: '[PRE39]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: NumPy believes that this array contains one million different elements, whereas
    the data buffer actually contains the same 1000 elements as `a`.
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: NumPy认为这个数组包含一百万个不同的元素，而实际上数据缓冲区只包含与`a`相同的1000个元素。
- en: 'We can now perform an efficient outer product using the same principle as with
    broadcasting rules:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用与广播规则相同的原则执行高效的外积：
- en: '[PRE40]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: How it works...
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Every array has a number of dimensions, a shape, a data type, and strides. Strides
    describe how the items of a multidimensional array are organized in the data buffer.
    There are many different schemes for arranging the items of a multidimensional
    array in a one-dimensional block. NumPy implements a **strided indexing scheme**,
    where the position of any element is a **linear combination** of the dimensions,
    the coefficients being the strides. In other words, strides describe, in any dimension,
    how many bytes we need to jump over in the data buffer to go from one item to
    the next.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数组都有一定数量的维度、形状、数据类型和步幅。步幅描述了多维数组中的项是如何在数据缓冲区中组织的。有许多不同的方案来安排多维数组的项在一维块中。NumPy实现了一个**跨步索引方案**，其中任何元素的位置是维度的**线性组合**，系数是步幅。换句话说，步幅描述了在任何维度中，我们需要跳过多少字节在数据缓冲区中从一个项到下一个项。
- en: 'The position of any element in a multidimensional array is given by a linear
    combination of its indices, as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 多维数组中任何元素的位置由其索引的线性组合给出，如下所示：
- en: '![How it works...](img/4818OS_04_02.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理...](img/4818OS_04_02.jpg)'
- en: Artificially changing the strides allows us to make some array operations more
    efficient than with standard methods, which may involve array copies. Internally,
    that's how broadcasting works in NumPy.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 人为改变步幅允许我们使一些数组操作比标准方法更有效，后者可能涉及数组复制。在内部，这就是NumPy中广播的工作原理。
- en: The `as_strided` method takes an array, a shape, and strides as arguments. It
    creates a new array, but uses the same data buffer as the original array. The
    only thing that changes is the metadata. This trick lets us manipulate NumPy arrays
    as usual, except that they may take much less memory than what NumPy thinks. Here,
    using 0 in the strides implies that any array item can be addressed by many multidimensional
    indices, resulting in memory savings.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '`as_strided`方法接受一个数组、一个形状和步幅作为参数。它创建一个新数组，但使用与原始数组相同的数据缓冲区。唯一改变的是元数据。这个技巧让我们像平常一样操作NumPy数组，只是它们可能比NumPy认为的占用更少的内存。在这里，使用步幅中的0意味着任何数组项都可以由许多多维索引来寻址，从而节省内存。'
- en: Tip
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Be careful with strided arrays! The `as_strided` function does not check whether
    you stay inside the memory block bounds. This means that you need to handle edge
    effects manually; otherwise, you may end up with garbage values in your arrays.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 对于跨步数组要小心！`as_strided`函数不会检查你是否保持在内存块边界内。这意味着你需要手动处理边缘效应；否则，你的数组中可能会出现垃圾值。
- en: We will see a more useful application of stride tricks in the next recipe.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一个食谱中看到跨步技巧的更有用的应用。
- en: See also
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Implementing an efficient rolling average algorithm with stride tricks*
    recipe
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用跨步技巧实现高效的滚动平均算法*食谱'
- en: Implementing an efficient rolling average algorithm with stride tricks
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用跨步技巧实现高效的滚动平均算法
- en: Stride tricks can be useful for local computations on arrays, when the computed
    value at a given position depends on the neighboring values. Examples include
    dynamical systems, digital filters, and cellular automata.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 当在数组上进行局部计算时，跨步技巧可以很有用，当给定位置的计算值取决于相邻值时。示例包括动力系统、数字滤波器和细胞自动机。
- en: In this recipe, we will implement an efficient **rolling average** algorithm
    (a particular type of convolution-based linear filter) with NumPy stride tricks.
    A rolling average of a 1D vector contains, at each position, the average of the
    elements around this position in the original vector. Roughly speaking, this process
    filters out the noisy components of a signal so as to keep only the slower components.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用NumPy跨步技巧实现一个高效的**滚动平均**算法（一种特殊类型的基于卷积的线性滤波器）。1D向量的滚动平均在每个位置包含原始向量中该位置周围元素的平均值。粗略地说，这个过程滤除信号的嘈杂成分，以保留只有较慢的成分。
- en: Getting ready
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Make sure to reuse the `id()` function from the *Understanding the internals
    of NumPy to avoid unnecessary array copying* recipe. This function returns the
    memory address of the internal data buffer of a NumPy array.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 确保重用*了解NumPy内部以避免不必要的数组复制*食谱中的`id()`函数。这个函数返回NumPy数组的内部数据缓冲区的内存地址。
- en: How to do it...
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: The idea is to start from a 1D vector, and make a *virtual* 2D array where each
    line is a shifted version of the previous line. When using stride tricks, this
    process is very efficient as it does not involve any copy.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 思路是从一个1D向量开始，并创建一个*虚拟*的2D数组，其中每一行都是前一行的移位版本。使用跨步技巧时，这个过程非常高效，因为它不涉及任何复制。
- en: 'Let''s generate a 1D vector:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们生成一个一维向量：
- en: '[PRE41]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Let''s change the strides of `a` to add shifted rows:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们改变`a`的步幅以添加移位行：
- en: '[PRE42]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The last value indicates an out-of-bounds problem: stride tricks can be dangerous
    as memory access is not checked. Here, we should take edge effects into account
    by limiting the shape of the array.'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后一个值表示越界问题：步幅技巧可能存在危险，因为内存访问没有经过检查。在这里，我们应该通过限制数组的形状来考虑边缘效应。
- en: '[PRE43]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now, let''s implement the computation of the rolling average. The first version
    (standard method) involves explicit array copies, whereas the second version uses
    stride tricks:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们实现滚动平均值的计算。第一个版本（标准方法）涉及显式数组复制，而第二个版本使用步幅技巧：
- en: '[PRE44]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'These two functions return the same result, except that the array returned
    by the second function refers to the original data buffer:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这两个函数返回相同的结果，只是第二个函数返回的数组指向原始数据缓冲区：
- en: '[PRE45]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Let''s generate a signal:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们生成一个信号：
- en: '[PRE46]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We compute the signal rolling average by creating the shifted version of the
    signal, and averaging along the vertical dimension. The result is shown in the
    next figure:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过创建信号的移位版本，并沿着垂直维度进行平均，来计算信号的滚动平均值。结果显示在下一个图中：
- en: '[PRE47]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '![How to do it...](img/4818OS_04_03.jpg)'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何实现...](img/4818OS_04_03.jpg)'
- en: A signal and its rolling average
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个信号及其滚动平均值
- en: 'Let''s evaluate the time taken by the first method:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们评估第一种方法所花费的时间：
- en: '[PRE48]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'And by the second method:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以及第二种方法：
- en: '[PRE49]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: In the first version, most of the time is spent in the array copy, whereas in
    the stride trick version, most of the time is instead spent in the computation
    of the average.
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第一个版本中，大部分时间都花在数组复制上，而在步幅技巧版本中，大部分时间都花在平均值的计算上。
- en: See also
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Using stride tricks with NumPy* recipe
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用NumPy的步幅技巧*方法'
- en: Making efficient array selections in NumPy
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在NumPy中进行高效的数组选择
- en: NumPy offers several ways of selecting slices of arrays. **Array views** refer
    to the original data buffer of an array, but with different offsets, shapes, and
    strides. They only permit strided selections (that is, with linearly spaced indices).
    NumPy also offers specific functions to make arbitrary selections along one axis.
    Finally, fancy indexing is the most general selection method, but it is also the
    slowest as we will see in this recipe. Faster alternatives should be chosen when
    possible.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy提供了几种选择数组切片的方法。**数组视图**指的是数组的原始数据缓冲区，但具有不同的偏移、形状和步幅。它们只允许步进选择（即，具有线性间隔的索引）。NumPy还提供了特定函数来沿一个轴进行任意选择。最后，花式索引是最通用的选择方法，但也是最慢的，正如我们在这个方法中所看到的。在可能的情况下，应选择更快的替代方法。
- en: Getting ready
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We suppose that NumPy has been imported and that the `id` function has been
    defined (see the *Understanding the internals of NumPy to avoid unnecessary array
    copying* recipe).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设NumPy已经被导入，并且`id`函数已经被定义（参见*了解NumPy的内部以避免不必要的数组复制*方法）。
- en: How to do it...
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Let''s create an array with a large number of rows. We will select slices of
    this array along the first dimension:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个具有大量行的数组。我们将沿着第一个维度选择这个数组的切片：
- en: '[PRE50]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Let''s select one row from every 10 rows, using two different methods (array
    view and fancy indexing):'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们选择每10行中的一行，使用两种不同的方法（数组视图和花式索引）：
- en: '[PRE51]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The view refers to the original data buffer, whereas fancy indexing yields
    a copy:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视图指向原始数据缓冲区，而花式索引产生一个副本：
- en: '[PRE52]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Let''s compare the performance of both methods:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们比较两种方法的性能：
- en: '[PRE53]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Fancy indexing is several orders of magnitude slower as it involves copying
    a large array.
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 花式索引比涉及复制大数组的速度慢几个数量级。
- en: 'When nonstrided selections need to be done along one dimension, array views
    are not an option. However, alternatives to fancy indexing still exist in this
    case. Given a list of indices, NumPy''s `take()` function performs a selection
    along one axis:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当需要沿着一个维度进行非步进选择时，数组视图不是一个选择。然而，在这种情况下，仍然存在替代花式索引的方法。给定一个索引列表，NumPy的`take()`函数可以沿着一个轴进行选择：
- en: '[PRE54]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The second method is faster:'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二种方法更快：
- en: '[PRE55]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Tip
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Performance of fancy indexing has been improved in recent versions of NumPy;
    this trick is especially useful on older versions of NumPy.
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最近的NumPy版本中改进了花式索引的性能；这个技巧在旧版本的NumPy中特别有用。
- en: 'When the indices to select along one axis are specified by a vector of Boolean
    masks, the `compress()` function is an alternative to fancy indexing:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当沿着一个轴选择的索引由布尔掩码向量指定时，`compress()`函数是花式索引的一种替代方法：
- en: '[PRE56]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The second method is also faster than fancy indexing.
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二种方法也比花式索引更快。
- en: How it works...
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理是怎样的...
- en: Fancy indexing is the most general way of making completely arbitrary selections
    of an array. However, more specific and faster methods often exist and should
    be preferred when possible.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 花式索引是进行完全任意选择数组的最通用方式。然而，通常存在更具体且更快的方法，在可能的情况下应该优先选择这些方法。
- en: Array views should be used whenever strided selections have to be done, but
    we need to be careful about the fact that views refer to the original data buffer.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要进行步进选择时，应使用数组视图，但我们需要小心，因为视图是引用原始数据缓冲区的。
- en: There's more...
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: 'Here are a few references:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些参考资料：
- en: The complete list of NumPy routines is available in the NumPy Reference Guide,
    at [http://docs.scipy.org/doc/numpy/reference/](http://docs.scipy.org/doc/numpy/reference/)
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整的 NumPy 例程列表可以在 NumPy 参考指南中找到，网址是[http://docs.scipy.org/doc/numpy/reference/](http://docs.scipy.org/doc/numpy/reference/)
- en: The list of indexing routines is available at [http://docs.scipy.org/doc/numpy/reference/routines.indexing.html](http://docs.scipy.org/doc/numpy/reference/routines.indexing.html)
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引例程的列表可以在[http://docs.scipy.org/doc/numpy/reference/routines.indexing.html](http://docs.scipy.org/doc/numpy/reference/routines.indexing.html)查看
- en: Processing huge NumPy arrays with memory mapping
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用内存映射处理超大 NumPy 数组
- en: Sometimes, we need to deal with NumPy arrays that are too big to fit in the
    system memory. A common solution is to use **memory mapping** and implement **out-of-core
    computations**. The array is stored in a file on the hard drive, and we create
    a memory-mapped object to this file that can be used as a regular NumPy array.
    Accessing a portion of the array results in the corresponding data being automatically
    fetched from the hard drive. Therefore, we only consume what we use.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们需要处理无法完全放入系统内存的超大 NumPy 数组。一种常见的解决方案是使用**内存映射**并实现**核心外计算**。数组被存储在硬盘上的文件中，我们创建一个内存映射对象来访问该文件，该对象可以像普通的
    NumPy 数组一样使用。访问数组的一部分会自动从硬盘中获取相应的数据。因此，我们只消耗我们使用的部分。
- en: How to do it...
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Let''s create a memory-mapped array:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个内存映射数组：
- en: '[PRE57]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Let's feed the array with random values, one column at a time because our system's
    memory is limited!
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们一次性喂入随机值，一次处理一列，因为我们的系统内存有限！
- en: '[PRE58]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'We save the last column of the array:'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们保存数组的最后一列：
- en: '[PRE59]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Now, we flush memory changes to disk by deleting the object:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们通过删除对象将内存中的更改刷新到磁盘：
- en: '[PRE60]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Reading a memory-mapped array from disk involves the same `memmap` function.
    The data type and the shape need to be specified again, as this information is
    not stored in the file:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从磁盘读取内存映射数组使用相同的`memmap`函数。数据类型和形状需要重新指定，因为这些信息不会保存在文件中：
- en: '[PRE61]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Tip
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: This method is not the most adapted for long-term storage of data and data sharing.
    The following recipes in this chapter will show a better way based on the HDF5
    file format.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法并不是最适合长期存储数据和数据共享的。接下来的章节将展示一种基于 HDF5 文件格式的更好的方法。
- en: How it works...
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: Memory mapping lets you work with huge arrays almost as if they were regular
    arrays. Python code that accepts a NumPy array as input will also accept a `memmap`
    array. However, we need to ensure that the array is used efficiently. That is,
    the array is never loaded as a whole (otherwise, it would waste system memory
    and would dismiss any advantage of the technique).
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 内存映射使你几乎可以像使用常规数组一样处理超大数组。接受 NumPy 数组作为输入的 Python 代码也可以接受`memmap`数组。然而，我们需要确保高效使用该数组。也就是说，数组绝不能一次性全部加载（否则会浪费系统内存，并失去该技术的优势）。
- en: Memory mapping is also useful when you have a huge file containing raw data
    in a homogeneous binary format with a known data type and shape. In this case,
    an alternative solution is to use NumPy's `fromfile()` function with a file handle
    created with Python's native `open()` function. Using `f.seek()` lets you position
    the cursor at any location and load a given number of bytes into a NumPy array.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有一个包含已知数据类型和形状的原始二进制格式的大文件时，内存映射也很有用。在这种情况下，另一种解决方案是使用 NumPy 的`fromfile()`函数，并通过
    Python 的原生`open()`函数创建文件句柄。使用`f.seek()`可以将光标定位到任何位置，并将指定数量的字节加载到 NumPy 数组中。
- en: There's more...
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: Another way of dealing with huge NumPy matrices is to use **sparse matrices**
    through SciPy's **sparse** subpackage. It is adapted when our matrices contain
    mostly zeros, as is often the case with simulations of partial differential equations,
    graph algorithms, or specific machine learning applications. Representing matrices
    as dense structures can be a waste of memory, and sparse matrices offer a more
    efficient compressed representation.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 处理巨大的NumPy矩阵的另一种方法是通过SciPy的**稀疏**子包使用**稀疏矩阵**。当矩阵大部分包含零时，这种方法非常适用，这在偏微分方程的模拟、图算法或特定的机器学习应用中常常出现。将矩阵表示为稠密结构可能浪费内存，而稀疏矩阵提供了更高效的压缩表示。
- en: 'Using sparse matrices in SciPy is not straightforward as multiple implementations
    exist. Each implementation is best for a particular kind of application. Here
    are a few references:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在SciPy中使用稀疏矩阵并不简单，因为存在多种实现方法。每种实现最适合特定类型的应用。以下是一些参考资料：
- en: SciPy lecture notes about sparse matrices, available at [http://scipy-lectures.github.io/advanced/scipy_sparse/index.html](http://scipy-lectures.github.io/advanced/scipy_sparse/index.html)
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于稀疏矩阵的SciPy讲义，见[http://scipy-lectures.github.io/advanced/scipy_sparse/index.html](http://scipy-lectures.github.io/advanced/scipy_sparse/index.html)
- en: Reference documentation on sparse matrices, at [http://docs.scipy.org/doc/scipy/reference/sparse.html](http://docs.scipy.org/doc/scipy/reference/sparse.html)
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稀疏矩阵的参考文档，请见[http://docs.scipy.org/doc/scipy/reference/sparse.html](http://docs.scipy.org/doc/scipy/reference/sparse.html)
- en: Documentation of memmap, at [http://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html](http://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html)
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: memmap文档，请见[http://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html](http://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html)
- en: See also
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: The *Manipulating large arrays with HDF5 and PyTables* recipe
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用HDF5和PyTables操作大型数组*食谱'
- en: The *Manipulating large heterogeneous tables with HDF5 and PyTables* recipe
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用HDF5和PyTables操作大型异构表格*食谱'
- en: Manipulating large arrays with HDF5 and PyTables
  id: totrans-338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用HDF5和PyTables操作大型数组
- en: 'NumPy arrays can be persistently saved on disk using built-in functions in
    NumPy such as `np.savetxt`, `np.save`, or `np.savez`, and loaded in memory using
    analogous functions. These methods are best when the arrays contain less than
    a few million points. For larger arrays, these methods suffer from two major problems:
    they become too slow, and they require the arrays to be fully loaded in memory.
    Arrays containing billions of points can be too big to fit in system memory, and
    alternative methods are required.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy数组可以通过NumPy内建函数如`np.savetxt`、`np.save`或`np.savez`持久化保存到磁盘，并使用类似的函数加载到内存中。当数组包含的点数少于几百万时，这些方法表现最好。对于更大的数组，这些方法面临两个主要问题：它们变得过于缓慢，并且需要将数组完全加载到内存中。包含数十亿个点的数组可能太大，无法适应系统内存，因此需要替代方法。
- en: 'These alternative methods rely on **memory mapping**: the array resides on
    the hard drive, and chunks of the array are selectively loaded in memory as soon
    as the CPU needs them. This technique is memory-efficient, at the expense of a
    slight overhead due to hard drive access. Cache mechanisms and optimizations can
    mitigate this issue.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 这些替代方法依赖于**内存映射**：数组存储在硬盘上，只有当CPU需要时，数组的部分数据才会被有选择性地加载到内存中。这种技术在节省内存方面非常高效，但由于硬盘访问会带来轻微的开销。缓存机制和优化可以缓解这个问题。
- en: The previous recipe showed a basic memory mapping technique using NumPy. In
    this recipe, we will use a package named **PyTables**, which is specifically designed
    to deal with very large datasets. It implements fast memory-mapping techniques
    via a widely-used and open file format specification called **Hierarchical Data
    Format**, or **HDF5**. An HDF5 file contains one or several datasets (arrays or
    heterogeneous tables) organized into a POSIX-like hierarchy. Any part of the datasets
    can be accessed efficiently and easily without unnecessarily wasting the system
    memory.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个食谱展示了一种使用NumPy的基本内存映射技术。在这个食谱中，我们将使用一个名为**PyTables**的包，它专门用于处理非常大的数据集。它通过一个广泛使用的开放文件格式规范**层次数据格式**（**HDF5**）实现了快速的内存映射技术。一个HDF5文件包含一个或多个数据集（数组或异构表格），这些数据集按类Unix的POSIX层次结构组织。数据集的任何部分都可以高效且轻松地访问，而无需不必要地浪费系统内存。
- en: As we will see later in this recipe, an alternative for PyTables is **h5py**.
    It is more lightweight and more adapted than PyTables in some situations.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在下面的食谱中将看到的，PyTables的一个替代方案是**h5py**。在某些情况下，它比PyTables更加轻量且更适应需求。
- en: In this recipe, we will see how to manipulate large arrays using HDF5 and PyTables.
    The next recipe will be about pandas-like heterogeneous tables.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将学习如何使用 HDF5 和 PyTables 操作大数组。下一个食谱将讲解类似 pandas 的异构表格。
- en: Getting ready
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You need PyTables 3.0+ for this recipe and the next one. With Anaconda, you
    can install PyTables using `conda install tables`. You will also find binary installers
    at [http://pytables.github.io/usersguide/installation.html](http://pytables.github.io/usersguide/installation.html).
    Windows users can find installers on [www.lfd.uci.edu/~gohlke/pythonlibs/#pytables](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pytables).
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱和下一个食谱需要 PyTables 3.0+ 版本。使用 Anaconda，可以通过 `conda install tables` 安装 PyTables。你还可以在
    [http://pytables.github.io/usersguide/installation.html](http://pytables.github.io/usersguide/installation.html)
    找到二进制安装程序。Windows 用户可以在 [www.lfd.uci.edu/~gohlke/pythonlibs/#pytables](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pytables)
    上找到安装程序。
- en: Tip
  id: totrans-346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Prior to version 3.0, PyTables used a camel case convention for the names of
    attributes and methods. The latest versions use the more standard Python convention
    using underscores. So, for example, `tb.open_file` is `tb.openFile` in versions
    prior to 3.0.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在 3.0 版本之前，PyTables 使用驼峰命名法约定来命名属性和方法。最新版本使用更标准的 Python 约定，使用下划线。所以，例如，`tb.open_file`
    在 3.0 版本之前是 `tb.openFile`。
- en: How to do it...
  id: totrans-348
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'First, we need to import NumPy and PyTables (the package''s name is `tables`):'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要导入 NumPy 和 PyTables（该包的名称是 `tables`）：
- en: '[PRE62]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Let''s create a new empty HDF5 file:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个新的空 HDF5 文件：
- en: '[PRE63]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'We create a new top-level group named `experiment1`:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个名为 `experiment1` 的新顶级组：
- en: '[PRE64]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Let''s also add some metadata to this group:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们还向这个组添加一些元数据：
- en: '[PRE65]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'In this group, we create a 1000*1000 array named `array1`:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个组中，我们创建了一个 1000*1000 的数组，命名为 `array1`：
- en: '[PRE66]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Finally, we need to close the file to commit the changes on disk:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们需要关闭文件以提交磁盘上的更改：
- en: '[PRE67]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Now, let's open this file. We could have done this in another Python session
    since the array has been saved in the HDF5 file.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们打开这个文件。我们也可以在另一个 Python 会话中完成这项操作，因为数组已经保存在 HDF5 文件中。
- en: '[PRE68]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'We can retrieve an attribute by giving the group path and the attribute name:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过提供组路径和属性名称来检索属性：
- en: '[PRE69]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: We can access any item in the file using attributes, replacing slashes with
    dots in the paths, and starting with `root` (corresponding to the path `/`). IPython's
    tab completion is particularly useful in this respect when exploring a file interactively.
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用属性访问文件中的任何项目，通过用点替代路径中的斜杠，并以 `root` 开头（对应路径 `/`）。IPython 的自动补全功能在互动式探索文件时特别有用。
- en: '[PRE70]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The array can be used as a NumPy array, but an important distinction is that
    it is stored on disk instead of system memory. Performing a computation on this
    array automatically loads the requested section of the array into memory, thus
    it is more efficient to access only the array's views.
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个数组可以像 NumPy 数组一样使用，但一个重要的区别是它存储在磁盘上，而不是系统内存中。在这个数组上执行计算时，会自动将请求的数组部分加载到内存中，因此只访问数组的视图会更高效。
- en: '[PRE71]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'It is also possible to get a node from its absolute path, which is useful when
    the path is only known at runtime:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 也可以通过绝对路径获取节点，这在路径只在运行时已知时非常有用：
- en: '[PRE72]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'We''re done for this recipe, so let''s do some clean-up:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本食谱完成了，接下来让我们做一些清理工作：
- en: '[PRE73]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: How it works...
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this recipe, we stored a single array in the file, but HDF5 is especially
    useful when many arrays need to be saved in a single file. HDF5 is generally used
    in big projects, when large arrays have to be organized within a hierarchical
    structure. For example, it is largely used at NASA, NOAA, and many other scientific
    institutions (see [www.hdfgroup.org/users.html](http://www.hdfgroup.org/users.html)).
    Researchers can store recorded data across multiple devices, multiple trials,
    and multiple experiments.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将一个单独的数组存储到文件中，但当需要在一个文件中保存多个数组时，HDF5 特别有用。HDF5 通常用于大型项目，特别是当大数组必须在层次结构中组织时。例如，它在
    NASA、NOAA 和许多其他科学机构中被广泛使用（请参见 [www.hdfgroup.org/users.html](http://www.hdfgroup.org/users.html)）。研究人员可以在多个设备、多个试验和多个实验中存储记录的数据。
- en: In HDF5, the data is organized within a tree. Nodes are either **groups** (analogous
    to folders in a file system) or **datasets** (analogous to files). A group can
    contain subgroups and datasets, whereas datasets only contain data. Both groups
    and datasets can contain attributes (metadata) that have a basic data type (integer
    or floating point number, string, and so on). HDF5 also supports internal and
    external links; a given path can refer to another group or dataset within the
    same file, or within another file. This feature may be useful if you need different
    files for the same experiment or project.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在 HDF5 中，数据是以树的形式组织的。树的节点可以是**组**（类似于文件系统中的文件夹）或**数据集**（类似于文件）。一个组可以包含子组和数据集，而数据集只包含数据。组和数据集都可以包含具有基本数据类型（整数或浮点数、字符串等）的属性（元数据）。HDF5
    还支持内部和外部链接；某个路径可以引用同一文件中的另一个组或数据集，或者引用另一个文件中的组或数据集。如果需要为同一实验或项目使用不同的文件，这一特性可能会很有用。
- en: Being able to access a chunk of a single array without loading the rest of the
    array and the file in memory is quite convenient. Moreover, a loaded array can
    be polymorphically accessed using standard NumPy's slicing syntax. Code that accepts
    a NumPy array as an argument can, in principle, accept a PyTables array object
    as an argument as well.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 能够在不将整个数组及文件加载到内存中的情况下访问单个数组的一个块是非常方便的。此外，加载后的数组可以使用标准的 NumPy 切片语法进行多态访问。接受
    NumPy 数组作为参数的代码原则上也可以接受 PyTables 数组对象作为参数。
- en: There's more...
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In this recipe, we created a PyTables `Array` object to store our NumPy array.
    Other similar types of objects include `CArrays` that store large arrays in chunks
    and support lossless compression. Also, an `EArray` object is extendable in at
    most one dimension, which is useful when the dimensions of the array are not known
    when creating the array in the file. A common use case is recording data during
    an online experiment.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们创建了一个 PyTables `Array` 对象来存储我们的 NumPy 数组。其他类似的对象类型包括 `CArrays`，它们将大数组分块存储并支持无损压缩。此外，`EArray`
    对象在最多一个维度上是可扩展的，这在创建文件中的数组时，如果数组的维度未知时，非常有用。一个常见的使用场景是在在线实验中记录数据。
- en: The other main type of HDF5 object is `Table`, which stores tabular data in
    a two-dimensional table with heterogeneous data types. In PyTables, a `Table`
    is to an `Array` what a pandas `DataFrame` is to a NumPy `ndarray`. We will see
    those in the next recipe.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个主要的 HDF5 对象类型是 `Table`，它在一个二维表中存储异构数据类型的表格数据。在 PyTables 中，`Table` 与 `Array`
    的关系就像 pandas 的 `DataFrame` 与 NumPy 的 `ndarray` 之间的关系。我们将在下一个食谱中看到它们。
- en: An interesting feature of HDF5 files is that they are not tied to PyTables.
    As HDF5 is an open format specification, libraries exist in most languages (C,
    FORTRAN, MATLAB, and many others), so it's easy to open an HDF5 file in these
    languages.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: HDF5 文件的一个有趣特点是它们不依赖于 PyTables。由于 HDF5 是一个开放的格式规范，因此几乎所有语言（C、FORTRAN、MATLAB
    等）都有相关的库，因此可以轻松地在这些语言中打开 HDF5 文件。
- en: In HDF5, a dataset may be stored in a **contiguous** block of memory, or in
    chunks. **Chunks** are atomic objects and HDF5/PyTables can only read and write
    entire chunks. Chunks are internally organized within a tree data structure called
    a **B-tree**. When we create a new array or table, we can specify the **chunk
    shape**. It is an internal detail, but it can greatly affect performance when
    writing and reading parts of the dataset.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 在 HDF5 中，数据集可以存储在**连续**的内存块中，或者分块存储。**块（Chunks）**是原子对象，HDF5/PyTables 只能读取和写入整个块。块在内部通过一种树形数据结构组织，称为**B
    树**。当我们创建一个新的数组或表时，可以指定**块形状**。这是一个内部细节，但它在写入和读取数据集的部分时可能会极大影响性能。
- en: The optimal chunk shape depends on how we plan to access the data. There is
    a trade-off between many small chunks (large overhead due to managing lots of
    chunks) and a few large chunks (inefficient disk I/O). In general, the chunk size
    is recommended to be smaller than 1 MB. The chunk cache is also an important parameter
    that may affect performance.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 最优的块形状取决于我们计划如何访问数据。小块的数量较多（由于管理大量块导致较大的开销）与大块较少（磁盘 I/O 效率低）之间存在权衡。一般来说，建议块的大小小于
    1 MB。块缓存也是一个重要参数，可能会影响性能。
- en: Relatedly, we should specify as an optional argument the expected number of
    rows when we create an `EArray` or a `Table` object so as to optimize the internal
    structure of the file. You can find more information in the PyTables users guide
    section on optimization (see the link mentioned in the following references),
    which is a must-read if you plan to do anything slightly complex on large HDF5
    files (more than 100 MB).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 相关地，在我们创建 `EArray` 或 `Table` 对象时，应该指定一个可选参数，预期的行数，以便优化文件的内部结构。如果你打算在大型 HDF5
    文件（超过 100 MB）上进行任何稍复杂的操作，PyTables 用户指南中的优化部分（参见以下参考链接）是必须阅读的。
- en: Finally, we should mention another HDF5 library in Python named **h5py**. This
    lightweight library offers an easy interface to HDF5 files, with emphasis on arrays
    rather than tables. It provides very natural access to HDF5 arrays from NumPy,
    and may be sufficient if you do not need the database-like features of PyTables.
    For more information on h5py, refer to [www.h5py.org](http://www.h5py.org).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们应该提到另一个名为 **h5py** 的 Python HDF5 库。这个轻量级库提供了一个简单的接口来操作 HDF5 文件，侧重于数组而非表格。它为从
    NumPy 访问 HDF5 数组提供了非常自然的方式，如果你不需要 PyTables 中类似数据库的功能，它可能已经足够。有关 h5py 的更多信息，请参见
    [www.h5py.org](http://www.h5py.org)。
- en: 'Here are a few references:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些参考资料：
- en: HDF5 chunking, at [www.hdfgroup.org/HDF5/doc/Advanced/Chunking/](http://www.hdfgroup.org/HDF5/doc/Advanced/Chunking/)
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HDF5 分块，详见 [www.hdfgroup.org/HDF5/doc/Advanced/Chunking/](http://www.hdfgroup.org/HDF5/doc/Advanced/Chunking/)
- en: PyTables optimization guide, available at [http://pytables.github.io/usersguide/optimization.html](http://pytables.github.io/usersguide/optimization.html)
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTables 优化指南，详见 [http://pytables.github.io/usersguide/optimization.html](http://pytables.github.io/usersguide/optimization.html)
- en: Difference between PyTables and h5py, from the perspective of h5py, at [https://github.com/h5py/h5py/wiki/FAQ#whats-the-difference-between-h5py-and-pytables](https://github.com/h5py/h5py/wiki/FAQ#whats-the-difference-between-h5py-and-pytables)
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTables 和 h5py 的区别，从 h5py 的角度来看，详见 [https://github.com/h5py/h5py/wiki/FAQ#whats-the-difference-between-h5py-and-pytables](https://github.com/h5py/h5py/wiki/FAQ#whats-the-difference-between-h5py-and-pytables)
- en: Difference between PyTables and h5py, from the perspective of PyTables, at [www.pytables.org/moin/FAQ#HowdoesPyTablescomparewiththeh5pyproject.3F](http://www.pytables.org/moin/FAQ#HowdoesPyTablescomparewiththeh5pyproject.3F)
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTables 和 h5py 的区别，从 PyTables 的角度来看，详见 [www.pytables.org/moin/FAQ#HowdoesPyTablescomparewiththeh5pyproject.3F](http://www.pytables.org/moin/FAQ#HowdoesPyTablescomparewiththeh5pyproject.3F)
- en: See also
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: The *Processing huge NumPy arrays with memory mapping* recipe
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*处理巨大 NumPy 数组的内存映射* 配方'
- en: The *Manipulating large heterogeneous tables with HDF5 and PyTables* recipe
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 HDF5 和 PyTables 操作大型异构表格* 配方'
- en: The *Ten tips for conducting reproducible interactive computing experiments*
    recipe in [Chapter 2](ch02.html "Chapter 2. Best Practices in Interactive Computing"),
    *Best Practices in Interactive Computing*
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [第 2 章](ch02.html "第 2 章. 交互计算中的最佳实践")，*交互计算的最佳实践* 中的 *进行可重复交互计算实验的十个提示* 配方
- en: Manipulating large heterogeneous tables with HDF5 and PyTables
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 HDF5 和 PyTables 操作大型异构表格
- en: PyTables can store homogeneous blocks of data as NumPy-like arrays in HDF5 files.
    It can also store heterogeneous tables, as we will see in this recipe.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: PyTables 可以将同质数据块存储为类似 NumPy 数组的形式在 HDF5 文件中。它也可以存储异构表格，如我们将在这个配方中看到的那样。
- en: Getting ready
  id: totrans-396
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You need PyTables for this recipe (see the previous recipe for installation
    instructions).
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要 PyTables 来实现这个配方（有关安装说明，请参见前面的配方）。
- en: How to do it...
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Let''s import NumPy and PyTables:'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入 NumPy 和 PyTables：
- en: '[PRE74]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Let''s create a new HDF5 file:'
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个新的 HDF5 文件：
- en: '[PRE75]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'We will create an HDF5 table with two columns: the name of a city (a string
    with 64 characters at most), and its population (a 32-bit integer). We can specify
    the columns by creating a complex data type with NumPy:'
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将创建一个 HDF5 表格，包含两列：城市名称（最多 64 个字符的字符串）和其人口（32 位整数）。我们可以通过创建一个复杂的数据类型，并使用 NumPy
    来指定这些列：
- en: '[PRE76]'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Now, we create the table in `/table1`:'
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们在 `/table1` 中创建表格：
- en: '[PRE77]'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Let''s add a few rows:'
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们添加几行数据：
- en: '[PRE78]'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'After adding rows, we need to flush the table to commit the changes on disk:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加行数据后，我们需要刷新表格以提交更改到磁盘：
- en: '[PRE79]'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'There are many ways to access the data from a table. The easiest but not particularly
    efficient way is to load the entire table in memory, which returns a NumPy array:'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有多种方式可以访问表格中的数据。最简单但效率不高的方式是将整个表格加载到内存中，这将返回一个 NumPy 数组：
- en: '[PRE80]'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'It is also possible to load a particular column (with all rows):'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 也可以加载特定的列（所有行）：
- en: '[PRE81]'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'When dealing with a large number of rows, we can make a SQL-like query in the
    table to load all rows that satisfy particular conditions:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在处理大量行时，我们可以在表格中执行类似SQL的查询，加载所有满足特定条件的行：
- en: '[PRE82]'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Finally, if their indices are known, we can access specific rows:'
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，如果已知索引，我们可以访问特定的行：
- en: '[PRE83]'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: How it works...
  id: totrans-419
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: A table can be created from scratch like in this recipe, or from either an existing
    NumPy array or a pandas `DataFrame`. In the first case, the description of the
    columns can be given with a NumPy data type as shown here, with a dictionary,
    or with a class deriving from `IsDescription`. In the second case, the table description
    will be automatically inferred from the given array or table.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 表格可以像本教程中那样从头开始创建，也可以从现有的NumPy数组或pandas `DataFrame`创建。在第一种情况下，可以使用NumPy数据类型（如这里所示）、字典或继承自`IsDescription`的类来描述列。在第二种情况下，表格描述将根据给定的数组或表格自动推断。
- en: Rows can be added efficiently at the end of the table using `table.append()`.
    To add a single row, first get a new row instance with `row = table.row`, set
    the fields of the row as if it were a dictionary, and then call `row.append()`
    to add the new row at the end of the table. Calling `flush()` after a set of writing
    operations ensures that these changes are synchronized on disk. PyTables uses
    complex cache mechanisms to ensure maximum performance when writing and reading
    data in a table; thus, new rows are not immediately written to the disk.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过`table.append()`高效地在表格末尾添加行。要添加一行，首先使用`row = table.row`获取一个新行实例，像操作字典一样设置行的字段，然后调用`row.append()`将新行添加到表格的末尾。在一组写操作后调用`flush()`可以确保这些更改同步到磁盘。PyTables使用复杂的缓存机制来确保在表格中读写数据时获得最大性能，因此新行不会立即写入磁盘。
- en: PyTables supports highly efficient SQL-like queries called **in-kernel queries**.
    The string containing the query expression is compiled and evaluated on all rows.
    A less-efficient method consists of iterating over all rows with `table.iterrows()`
    and using an `if` statement on the rows' fields.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: PyTables支持高效的SQL-like查询，称为**内核查询**。包含查询表达式的字符串会在所有行上编译并评估。较低效的方法是使用`table.iterrows()`遍历所有行，并对行的字段使用`if`语句。
- en: There's more...
  id: totrans-423
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'Here are a few references:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些参考资料：
- en: In-kernel queries, at [http://pytables.github.io/usersguide/condition_syntax.html](http://pytables.github.io/usersguide/condition_syntax.html).
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核查询，详见[http://pytables.github.io/usersguide/condition_syntax.html](http://pytables.github.io/usersguide/condition_syntax.html)。
- en: An alternative to PyTables and HDF5 might come from the Blaze project, still
    in early development at the time of writing. For more information on Blaze, refer
    to [http://blaze.pydata.org](http://blaze.pydata.org).
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTables和HDF5的替代方案可能来自Blaze项目，该项目在撰写时仍处于早期开发阶段。有关Blaze的更多信息，请参考[http://blaze.pydata.org](http://blaze.pydata.org)。
- en: See also
  id: totrans-427
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Manipulating large arrays with HDF5 and PyTables* recipe
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用HDF5和PyTables操作大数组*的教程'
