- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Common Modeling Patterns for Time Series
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列的常见建模模式
- en: We reviewed a few major and common building blocks of a **deep learning** (**DL**)
    system, specifically suited for time series, in the last chapter. Now that we
    know what those blocks are, it’s time for a more practical lesson. Let’s see how
    we can put these common blocks together in the various ways in which time series
    forecasting is modeled using the dataset we have been working with all through
    this book.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们回顾了几个主要的、适合时间序列的**深度学习**（**DL**）系统的常见构建模块。现在我们知道这些模块是什么，是时候进行更实用的课程了。让我们看看如何将这些常见模块组合在一起，以不同的方式对本书中一直使用的数据集进行时间序列预测建模。
- en: 'In this chapter, we will be covering these main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Tabular regression
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表格回归
- en: Single-step-ahead recurrent neural networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单步前向递归神经网络
- en: Sequence-to-sequence models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列到序列模型
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need to set up the `Anaconda` environment following the instructions
    in the *Preface* of the book to get a working environment with all the libraries
    and datasets required for the code in this book. Any additional libraries will
    be installed while running the notebooks.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要按照本书*前言*中的说明设置`Anaconda`环境，以便获得一个包含本书代码所需所有库和数据集的工作环境。在运行笔记本时，任何额外的库都会被安装。
- en: 'You need to run the following notebooks for this chapter:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要运行以下笔记本以完成本章内容：
- en: '`02-Preprocessing_London_Smart_Meter_Dataset.ipynb` in `Chapter02`'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Chapter02`中的`02-Preprocessing_London_Smart_Meter_Dataset.ipynb`'
- en: '`01-Setting_up_Experiment_Harness.ipynb` in `Chapter04`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Chapter04`中的`01-Setting_up_Experiment_Harness.ipynb`'
- en: '`01-Feature_Engineering.ipynb` in `Chapter06`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Chapter06`中的`01-Feature_Engineering.ipynb`'
- en: '`00-Single_Step_Backtesting_Baselines.ipynb`, `01-Forecasting_with_ML.ipynb`,
    and `02-Forecasting_with_Target_Transformation.ipynb` in `Chapter08`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Chapter08`中的`00-Single_Step_Backtesting_Baselines.ipynb`，`01-Forecasting_with_ML.ipynb`和`02-Forecasting_with_Target_Transformation.ipynb`'
- en: '`01-Global_Forecasting_Models-ML.ipynb` in `Chapter10`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Chapter10`中的`01-Global_Forecasting_Models-ML.ipynb`'
- en: The associated code for the chapter can be found at [https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-/tree/main/notebooks/Chapter13](https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-/tree/main/notebooks/Chapter13).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的相关代码可以在[https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-/tree/main/notebooks/Chapter13](https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-/tree/main/notebooks/Chapter13)找到。
- en: Tabular regression
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 表格回归
- en: In *Chapter 5*, *Time Series Forecasting as Regression*, we saw how we can convert
    a time series problem into a standard regression problem with temporal embedding
    and time delay embedding. In *Chapter 6*, *Feature Engineering for Time Series
    Forecasting*, we have already created the necessary features for the household
    energy consumption dataset we have been working on, and in *Chapter 8*, *Forecasting
    Time Series with Machine Learning Models*, *Chapter 9*, *Ensembling and Stacking*,
    and *Chapter 10*, *Global Forecasting Models*, we used traditional **machine learning**
    (**ML**) models to create a forecast.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第5章*，*作为回归的时间序列预测*中，我们看到如何将时间序列问题转换为一个标准的回归问题，使用时序嵌入和时间延迟嵌入。在*第6章*，*时间序列预测的特征工程*中，我们已经为我们一直在使用的家庭能源消耗数据集创建了必要的特征，在*第8章*，*使用机器学习模型进行时间序列预测*，*第9章*，*集成和堆叠*，以及*第10章*，*全球预测模型*中，我们使用传统的**机器学习**（**ML**）模型进行预测。
- en: Just as we used standard ML models for forecasting, we can also use DL models
    built for tabular data using the feature-engineered dataset we have created. We
    already talked about data-driven methods and how they are better when given larger
    amounts of data. DL models take that paradigm even further and enable us to learn
    highly data-driven models. One of the advantages of using a DL model in this setting,
    over the ML models, is the flexibility DL offers us. All through *Chapters 8*,
    *9*, and *10*, we only saw how we can create single-step-ahead forecasting using
    ML models. We have a separate section on multi-step forecasting in *Chapter 18,*where
    we go into detail on different strategies with which we can generate multi-step
    forecasts, and we address one of the limitations of standard ML models in multi-step
    forecasting. But right now, let’s just understand that standard ML models are
    designed to have a single output and, because of that fact, getting multi-step
    forecasts is not straightforward. But with tabular DL models, we have the flexibility
    to train the model to predict multiple targets, and this enables us to generate
    multi-step forecasts easily.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们使用标准的机器学习模型进行预测一样，我们也可以使用为表格数据构建的深度学习模型，使用我们已创建的特征工程数据集。我们已经讨论过数据驱动的方法，以及它们在处理大规模数据时的优势。深度学习模型将这一范式推向了更远的层次，使我们能够学习高度数据驱动的模型。在这种情况下，相比于机器学习模型，使用深度学习模型的一个优点是其灵活性。在
    *第8章*，*第9章* 和 *第10章* 中，我们仅展示了如何使用机器学习模型进行单步预测。我们在 *第18章* 中有一个单独的部分，讨论了多步预测的不同策略，并详细介绍了标准机器学习模型在多步预测中的局限性。但现在，我们要理解的是，标准的机器学习模型设计上只输出一个预测值，因此多步预测并不简单。而使用表格数据深度学习模型，我们可以灵活地训练模型来预测多个目标，从而轻松生成多步预测。
- en: PyTorch Tabular is an open-source library ([https://github.com/manujosephv/pytorch_tabular](https://github.com/manujosephv/pytorch_tabular))
    that makes it easy to work with DL models in the tabular data domain, and it also
    has ready-to-use implementations of many state-of-the-art DL models. We are going
    to use PyTorch Tabular to generate forecasts using the feature-engineered datasets
    we created in *Chapter 6*, *Feature Engineering for Time Series Forecasting*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Tabular 是一个开源库（[https://github.com/manujosephv/pytorch_tabular](https://github.com/manujosephv/pytorch_tabular)），它使得在表格数据领域中使用深度学习模型变得更加容易，并且提供了许多最先进的深度学习模型的现成实现。我们将使用
    PyTorch Tabular，通过在 *第6章*，*时间序列预测的特征工程* 中创建的特征工程数据集来生成预测。
- en: 'PyTorch Tabular has very detailed documentation and tutorials to get you started
    here: [https://pytorch-tabular.readthedocs.io/en/latest/](https://pytorch-tabular.readthedocs.io/en/latest/).
    Although we won’t be going into detail on all the intricacies of the library,
    we will look at how we can use a bare-bones version to generate a forecast on
    the dataset we are working on using a `FTTransformer` model. `FTTransformer` is
    one of the state-of-the-art DL models for tabular data. DL for tabular data is
    a whole different kind of model, and I’ve linked a blog post in the *Further reading*
    section as a primer to the field of study. For our purposes, we can treat them
    as any standard ML model in scikit-learn.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Tabular 提供了非常详细的文档和教程，帮助你快速入门：[https://pytorch-tabular.readthedocs.io/en/latest/](https://pytorch-tabular.readthedocs.io/en/latest/)。虽然我们不会深入探讨这个库的所有细节，但我们会展示如何使用一个简化版的模型，利用
    `FTTransformer` 模型对我们正在处理的数据集进行预测。`FTTransformer` 是一种用于表格数据的最先进的深度学习（DL）模型。表格数据的深度学习模型是一个与其他类型模型完全不同的领域，我在
    *进一步阅读* 部分链接了一篇博客文章，作为该领域研究的入门。就我们而言，我们可以将这些模型视为任何标准的机器学习（ML）模型，类似于 scikit-learn
    中的模型。
- en: '**Notebook alert:**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**笔记本提示：**'
- en: To follow along with the complete code, use the notebook named `01-Tabular_Regression.ipynb`
    in the `Chapter13` folder and the code in the `src` folder.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要完整运行代码，请使用 `Chapter13` 文件夹中的 `01-Tabular_Regression.ipynb` 笔记本和 `src` 文件夹中的代码。
- en: We start off, pretty much like before, by loading the libraries and necessary
    datasets. Just one additional thing we are doing here is that instead of taking
    the same selection of blocks we worked with in *Part 2*, *Machine Learning for
    Time Series*, we take smaller data by selecting half the number of blocks as before.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的步骤与之前相似，首先加载所需的库和数据集。这里唯一不同的是，我们选择的块数比在 *第2部分*，*时间序列的机器学习* 中使用的要少，只有一半。
- en: This is done to make the **neural network** (**NN**) training smoother and faster
    and for it to fit into GPU memory (if any). I’d like to stress here that this
    is done purely for hardware reasons, and provided we have sufficiently powerful
    hardware, we need not have smaller datasets for DL. On the contrary—DL loves larger
    datasets. But since we want to keep the focus on the modeling side, the engineering
    constraints and techniques in working with larger datasets have been kept outside
    the scope of this book.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做是为了使**神经网络**（**NN**）的训练更顺畅、更快速，并且能够适应GPU内存（如果有的话）。在这里我要强调的是，这样做纯粹是出于硬件的原因，前提是我们拥有足够强大的硬件，我们不必使用较小的数据集进行深度学习。相反，深度学习更喜欢使用较大的数据集。但由于我们希望将重点放在建模方面，处理较大数据集的工程约束和技术已被排除在本书讨论范围之外。
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After handling the missing values, we are ready to start using PyTorch Tabular.
    We first import the necessary classes from the library, like so:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 处理完缺失值后，我们就可以开始使用PyTorch Tabular了。我们首先从库中导入必要的类，代码如下：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'PyTorch Tabular uses a set of config files to define the parameters required
    for running the model, and these configs include everything from how the `DataFrame`
    is configured to what kind of preprocessing needs to be applied, what kind of
    training we need to do, what model we need to use, what the hyperparameters of
    the model are, and so on. Let’s see how we can define a bare-bones configuration
    (because PyTorch Tabular makes use of intelligent defaults wherever possible to
    make the usage easier for the practitioner):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Tabular使用一组配置文件来定义运行模型所需的参数，这些配置涵盖了从`DataFrame`如何配置到需要应用什么样的预处理、我们需要进行什么样的训练、需要使用什么模型、模型的超参数等内容。让我们看看如何定义一个基础的配置（因为PyTorch
    Tabular尽可能利用智能默认值，使得使用者更便捷）：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We use a very high `max_epochs` parameter in `TrainerConfig` because, by default,
    PyTorch Tabular employs a technique called **early stopping**, where we continuously
    keep track of the performance on a validation set and stop the training when the
    validation loss starts to increase.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在`TrainerConfig`中，我们使用了一个非常高的`max_epochs`参数，因为默认情况下，PyTorch Tabular采用一种叫做**早停法**的技术，在这种技术下，我们持续跟踪验证集上的表现，并在验证损失开始增加时停止训练。
- en: 'Selecting which model to use from the implemented models in PyTorch Tabular
    is as simple as choosing the right configuration. Each model is associated with
    a configuration that defines the hyperparameters of the model. So, just by using
    that configuration, PyTorch Tabular understands which model the user wants to
    use. Let’s choose the `FTTransformerConfig` model and define a few hyperparameters:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从PyTorch Tabular中选择使用哪个模型就像选择正确的配置一样简单。每个模型都有一个与之关联的配置文件，定义了模型的超参数。所以，仅通过使用该配置，PyTorch
    Tabular就能理解用户想要使用哪个模型。让我们选择`FTTransformerConfig`模型并定义一些超参数：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The main and only mandatory parameter here is `task`, which tells PyTorch Tabular
    whether it is a *regression* or *classification* task.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的主要且唯一的强制性参数是`task`，它告诉PyTorch Tabular这是一个*回归*任务还是*分类*任务。
- en: Although PyTorch Tabular provides the best defaults, we only set these parameters
    to make the training faster and fit into the memory of the GPU we are running
    on. If you are not running the notebook on a machine with a GPU, choosing a smaller
    and faster model such as `CategoryEmbeddingConfig` would be better.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管PyTorch Tabular提供了最佳的默认设置，但我们设置这些参数的目的是加快训练速度，并使其能够适应我们正在使用的GPU的内存。如果你没有在带有GPU的机器上运行笔记本，选择一个更小更快的模型，如`CategoryEmbeddingConfig`会更好。
- en: 'Now, all that is left to do is put all these configs together in a class called
    `TabularModel`, which is the workhorse of the library, and as with any scikit-learn
    model, call `fit` on the object. But, unlike a scikit-learn model, you don’t need
    to split `x` and `y`; we just need to provide the `DataFrame`, as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，剩下的工作就是将所有这些配置放入一个名为`TabularModel`的类中，它是该库的核心部分，和任何scikit-learn模型一样，调用对象的`fit`方法。但与scikit-learn模型不同的是，你不需要拆分`x`和`y`；我们只需要提供`DataFrame`，如下所示：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the training is complete, you can save the model by running the following
    code:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，你可以通过运行以下代码保存模型：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If for any reason you have to close your notebook instance after training,
    you can always load the model back by using the following code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果由于某种原因你在训练后必须关闭笔记本实例，你可以通过以下代码重新加载模型：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This way, you don’t need to spend a lot of time training the model again, but
    instead, use it for prediction.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，你就无需再次花费大量时间训练模型，而是可以直接用于预测。
- en: 'Now, all that is left is to make predictions using the unseen data and evaluate
    the performance. Here’s how we can do this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，剩下的就是使用未见过的数据进行预测并评估性能。下面是我们如何做到这一点：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We have used the untuned global forecasting model with metadata that we trained
    in *Chapter 10*, *Global Forecasting Models*, as the baseline against which we
    can do a cursory check on how well the DL model is doing, as illustrated in the
    following screenshot:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用了在*第10章*中训练的未调优的全局预测模型与元数据，作为基准，来粗略检查深度学习模型的表现，如下图所示：
- en: '![Figure 13.1 – Evaluation of the DL-based tabular regression ](img/B22389_13_01.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.1 – 基于深度学习的表格回归评估](img/B22389_13_01.png)'
- en: 'Figure 13.1: Evaluation of the DL-based tabular regression'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.1：基于深度学习的表格回归评估
- en: We can see that the `FTTransformer` model is competitive with the `LightGBM`
    model we trained in *Chapter 10*. Maybe, with the right amount of tuning and partitioning,
    the `FTTransformer` model can do as well as or better than the `LightGBM` model.
    Training a competitive DL model in the same way as `LightGBM` is useful in many
    ways. First, it provides flexibility and trains the model to predict multiple
    timesteps at once. Second, this can also be combined with the `LightGBM` model
    in an ensemble, and because of the variety the DL model brings to the mix, this
    can make the ensemble performance better.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，`FTTransformer` 模型与我们在*第10章*中训练的 `LightGBM` 模型具有竞争力。也许，在适当的调优和分区下，`FTTransformer`
    模型的表现可以和 `LightGBM` 模型一样，甚至更好。以与 `LightGBM` 相同的方式训练一个有竞争力的深度学习模型，在许多方面都是有用的。首先，它提供了灵活性，并训练模型一次性预测多个时间步。其次，这也可以与
    `LightGBM` 模型结合在一起，作为集成模型使用，因为深度学习模型带来了多样性，这可以提升集成模型的表现。
- en: '**Things to try:**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**尝试的事项：**'
- en: Use PyTorch Tabular’s documentation and play around with other models or change
    the parameters to see how the performance changes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PyTorch Tabular 的文档，尝试其他模型或调整参数，观察性能如何变化。
- en: Select a few households and plot them to see how well the forecast matches up
    to the targets.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 选择几个家庭进行绘图，看看预测结果与目标值的匹配情况。
- en: Now, let’s look at how we can use **recurrent neural networks** (**RNNs**) for
    single-step-ahead forecasting.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下如何使用**循环神经网络**（**RNNs**）进行单步前瞻预测。
- en: Single-step-ahead recurrent neural networks
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单步前瞻的循环神经网络
- en: Although we took a little detour to check out how DL regression models can be
    used to train the same global models we learned about in *Chapter 10*, *Global
    Forecasting Models*, now we are back to looking at DL models and architectures
    specifically built for time series. As always, we will look at simple one-step-ahead
    and local models first before moving on to more complex modeling paradigms. In
    fact, we have another chapter (*Chapter 15*, *Strategies for Global Deep Learning
    Forecasting Models*) entirely devoted to techniques we can use to train global
    DL models.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们稍微绕了一点，检查了如何将深度学习回归模型用于训练我们在*第10章*中学到的相同全局模型，但现在我们回到专门为时间序列构建的深度学习模型和架构上。和往常一样，我们首先会看简单的一步前瞻和局部模型，然后再转向更复杂的建模范式。事实上，我们还有另一章（*第15章*，*全局深度学习预测模型的策略*），专门介绍了训练全局深度学习模型时可以使用的技术。
- en: Now, let’s bring our attention back to one-step-ahead local models. We saw RNNs
    (vanilla RNN, **long short-term memory** (**LSTM**), and **gated recurrent unit**
    (**GRU**)) as a few blocks we can use for sequences such as time series. Now,
    let’s see how we can use them in an **end-to-end** (**E2E**) model on the dataset
    we have been working on (the *London smart meters* dataset).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将注意力重新集中到一步步前瞻的局部模型上。我们看到 RNN（普通 RNN，**长短期记忆网络**（**LSTM**）和**门控循环单元**（**GRU**））是我们可以用于诸如时间序列等序列数据的一些模块。现在，让我们看看如何在我们一直使用的数据集上（*伦敦智能电表*数据集）将它们应用于**端到端**（**E2E**）模型。
- en: Although we will be looking at a few libraries (such as `darts`) that make the
    process of training DL models for time series forecasting easier, in this chapter,
    we will be looking at how to develop such models from scratch. Understanding how
    a DL model for time series forecasting is put together from the ground up will
    give you a good grasp of the concepts that are needed to use and tweak the libraries
    that we will be looking at later.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们将查看一些库（例如 `darts`），这些库使得训练用于时间序列预测的深度学习模型变得更容易，但在本章中，我们将着重讲解如何从零开始开发这些模型。了解时间序列预测的深度学习模型是如何从基础搭建起来的，将帮助你更好地理解在后续章节中我们将要使用和调整的库所需的概念。
- en: We will be using PyTorch, and if you are not comfortable, I suggest you head
    to *Chapter 12*, *Building Blocks of Deep Learning for Time Series*, and the associated
    notebooks for a quick refresher. On top of that, we are also going to use PyTorch
    Lightning, which is another library built on top of PyTorch to make training models
    using PyTorch easy, among other benefits.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用PyTorch，如果你不熟悉，我建议你去*第12章*，*时间序列深度学习的构建模块*，以及相关的笔记本做一个快速复习。此外，我们还将使用PyTorch
    Lightning，这是另一个建立在PyTorch之上的库，可以使使用PyTorch训练模型变得更加简单，除此之外还有其他一些优点。
- en: We talked about *time delay embedding* in *Chapter 5*, *Time Series Forecasting
    as Regression*, where we discussed using a window in time to embed the time series
    into a format more suitable for regression. When training NNs for time series
    forecasting also, we need such windows. Suppose we are training on a single time
    series. We can give this super-long time series to an RNN as is, but then it only
    becomes one sample in the dataset. And with just one sample in the dataset, it’s
    close to impossible to train any ML or DL models. So, it’s advisable to sample
    multiple windows from the time series to convert the time series into a number
    of data samples in a process that is very similar to time delay embedding. This
    window also sets the memory of the DL model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第5章*中讨论了*时间延迟嵌入*，在*时间序列预测作为回归*部分，我们讨论了如何使用一个时间窗口将时间序列嵌入到更适合回归的格式中。在训练神经网络进行时间序列预测时，我们也需要这样的时间窗口。假设我们正在训练一个单一的时间序列。我们可以将这个超长的时间序列直接输入到RNN中，但这样它只会成为数据集中的一个样本。而且，数据集中只有一个样本时，几乎不可能训练任何机器学习或深度学习模型。因此，建议从时间序列中采样多个窗口，将时间序列转换成多个数据样本，这一过程与时间延迟嵌入非常相似。这个窗口也设置了深度学习模型的记忆。
- en: 'The first step we need to take is to create a PyTorch dataset that takes the
    raw time series and prepares these samples’ windows. A dataset is like an iterator
    over the data that gives us samples corresponding to a provided index. Defining
    a custom dataset for PyTorch is as simple as defining a class that takes in a
    few arguments (data being one of them) and defining two mandatory methods in the
    class, as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要采取的第一步是创建一个PyTorch数据集，该数据集接受原始时间序列并准备这些样本的窗口。数据集类似于数据的迭代器，它根据提供的索引给出相应的样本。为PyTorch定义自定义数据集非常简单，只需定义一个类，接受几个参数（其中之一是数据），并在类中定义两个必需的方法，如下所示：
- en: '`__len__(self)`: This sets the maximum number of samples in the dataset.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__len__(self)`：此方法设置数据集中样本的最大数量。'
- en: '`__get_item__(self, idx)`: This picks the `idx`^(th) sample from the dataset.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__get_item__(self, idx)`：此方法从数据集中获取第`idx`个样本。'
- en: 'We have defined a dataset in `src/dl/dataloaders.py` with the name `TimeSeriesDataset`,
    which takes in the following parameters:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`src/dl/dataloaders.py`中定义了一个名为`TimeSeriesDataset`的数据集，该数据集接受以下参数：
- en: '`Data`: This argument can either be a pandas DataFrame or a NumPy array with
    the time series. This is the entire time series, including train, validation,
    and test, and the splits occur inside the class.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Data`：该参数可以是pandas DataFrame或包含时间序列的NumPy数组。这是整个时间序列，包括训练、验证和测试数据，数据划分在类内部进行。'
- en: '`window`: This sets the length of each sample.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`window`：此参数设置每个样本的长度。'
- en: '`horizon`: This sets the number of future timesteps we want to get as the target.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`horizon`：此参数设置我们希望获取的未来时间步数作为目标。'
- en: '`n_val`: This parameter can either be a `float` or an `int` data type. If `int`,
    it represents the number of timesteps to be reserved as validation data. If `float`,
    this represents the percent of total data to be reserved as validation data.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_val`：此参数可以是`float`或`int`数据类型。如果是`int`，则表示要保留作为验证数据的时间步数。如果是`float`，则表示要保留的验证数据占总数据的百分比。'
- en: '`n_test`: This parameter is similar to `n_val`, but does the same for test
    data.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_test`：此参数与`n_val`类似，但用于测试数据。'
- en: '`normalize`: This parameter defines how we want to normalize the data. This
    takes in three options: `none` means no normalizing and `global` means we calculate
    the mean and standard deviation of the train data and use it to standardize the
    entire series using this equation:'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalize`：该参数定义了我们希望如何对数据进行标准化。它有三个选项：`none`表示不进行标准化，`global`表示我们计算训练数据的均值和标准差，并用此标准化整个序列，使用的公式如下：'
- en: '![](img/B22389_13_001.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_13_001.png)'
- en: '`local` means we use the window mean and standard deviation to standardize
    the series.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`local`表示我们使用窗口的均值和标准差来标准化该序列。'
- en: '`normalize_params`: This parameter takes in a tuple of mean and standard deviations.
    If provided, this can be used to standardize in *global* standardization. This
    is typically used to use the train mean and standard deviation on validation and
    test data as well.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalize_params`：这个参数接收一个包含均值和标准差的元组。如果提供了这个参数，它可以用于进行*全局*标准化。这通常用于在验证集和测试集上使用训练集的均值和标准差。'
- en: '`mode`: This parameter sets which dataset we want to make. It takes in one
    of three values: `train`, `val`, or `test`.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mode`：这个参数设置我们希望创建的数据集类型。它接受以下三种值之一：`train`、`val` 或 `test`。'
- en: 'Each sample from this dataset returns to you two tensors—the window (*X*) and
    the corresponding target (*Y*) (see *Figure 13.2*):'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个数据集中的每个样本返回两个张量——窗口（*X*）和相应的目标（*Y*）（见*图 13.2*）：
- en: '![Figure 13.2 – Sampling the time series using a dataset and dataloader ](img/B22389_13_02.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.2 – 使用数据集和数据加载器抽样时间序列](img/B22389_13_02.png)'
- en: 'Figure 13.2: Sampling the time series using a dataset and dataloader'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2：使用数据集和数据加载器抽样时间序列
- en: Now that we have the dataset defined, we need another PyTorch artifact called
    a dataloader. A dataloader uses the dataset to pick samples into a batch of samples,
    among other things. In the PyTorch Lightning ecosystem, we have another concept
    called a datamodule, which is a standard way of generating dataloaders. We need
    train dataloaders, validation dataloaders, and test dataloaders. Datamodules provide
    a good abstraction to encapsulate the whole data part of the pipeline. We have
    defined a datamodule in `src/dl/dataloaders.py` called `TimeSeriesDataModule`
    that takes in the data along with the batch size and prepares the datasets and
    dataloaders necessary for training. The parameters are exactly the same as `TimeSeriesDataset`,
    with `batch_size` as the only additional parameter.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了数据集，我们需要另一个 PyTorch 组件，叫做数据加载器（dataloader）。数据加载器使用数据集将样本按批次提取出来。 在
    PyTorch Lightning 生态系统中，我们还有一个叫做数据模块（datamodule）的概念，它是生成数据加载器的标准方式。我们需要训练数据加载器、验证数据加载器和测试数据加载器。数据模块为数据管道部分提供了很好的抽象封装。我们在`src/dl/dataloaders.py`中定义了一个名为`TimeSeriesDataModule`的数据模块，它接收数据以及批次大小，并准备训练所需的数据集和数据加载器。参数与`TimeSeriesDataset`完全相同，唯一不同的是增加了`batch_size`参数。
- en: '**Notebook alert:**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**笔记本提醒：**'
- en: To follow along with the complete code, use the notebook named `02-One-Step_RNN.ipynb`
    in the `Chapter13` folder and the code in the `src` folder.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随完整代码，可以使用`Chapter13`文件夹中的`02-One-Step_RNN.ipynb`笔记本以及`src`文件夹中的代码。
- en: We will not be going into each and every step in the notebook but will be just
    stressing the key points. The code in the notebook is well commented, and we urge
    you to follow the code along with the book.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会逐步讲解笔记本中的每一步，只会强调关键点。笔记本中的代码有详细注释，强烈建议你边看书边跟着代码一起实践。
- en: 'We have already sampled a household from the data, and now, let’s see how we
    can define a datamodule:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经从数据中抽取了一个家庭样本，现在，让我们看看如何定义一个数据模块：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`datamodule.setup()` is the method that calculates and sets up the dataloaders.
    Now, we can access the train dataloader by simply calling `datamodule.train_dataloader()`,
    and similarly, validation and test by `val_dataloader` and `test_dataloader` methods,
    respectively. We can access the samples as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`datamodule.setup()`是用于计算并设置数据加载器的方法。现在，我们可以通过简单调用`datamodule.train_dataloader()`来访问训练数据加载器，类似地，验证集和测试集则通过`val_dataloader`和`test_dataloader`方法访问。我们可以如下访问样本：'
- en: '[PRE9]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We can see that each sample has two tensors—`x` and `y`. There are three dimensions
    for the tensors, and they correspond to *batch size*, *sequence length*, and *features*.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到每个样本包含两个张量——`x`和`y`。这些张量有三个维度，它们分别对应于*批次大小*、*序列长度*和*特征*。
- en: Now that we have the data pipeline ready, we need to build out the modeling
    and training pipelines. PyTorch Lightning has a standard way of defining these
    so that they can be plugged into the training engine they provide (which makes
    our life so much easier). The PyTorch Lightning documentation ([https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html](https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html))
    has good resources to get started with and to go into depth on as well. We have
    also linked to a video in the *Further reading* section that makes the transition
    from pure PyTorch to PyTorch Lightning easy. I strongly urge you to take some
    time to familiarize yourself with it.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据管道已经准备好，我们需要构建模型和训练管道。PyTorch Lightning有一种标准的方式来定义这些管道，以便它们可以插入到提供的训练引擎中（这使得我们的工作变得更容易）。PyTorch
    Lightning的文档（[https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html](https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html)）提供了很好的资源，帮助我们开始使用并深入了解。此外，在*进一步阅读*部分，我们还链接了一个视频，帮助从纯PyTorch过渡到PyTorch
    Lightning。我强烈建议你花一些时间熟悉它。
- en: 'When defining a model in PyTorch, a standard method called `forward` is the
    only mandatory method you have to define, apart from `__init__`. This is because
    the training loop is something that we will have to write on our own. In the `01-PyTorch_Basics.ipynb`
    notebook for *Chapter 12*, *Building Blocks of Deep Learning for Time Series*,
    we saw how we can write a PyTorch model and a training loop to train a simple
    classifier. But now that we are delegating the training loop to PyTorch Lightning,
    we have to include a few additional methods as well:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch中定义模型时，除了`__init__`外，必须定义一个标准方法`forward`。这是因为训练循环需要我们自己编写。在*第12章*《时间序列深度学习的构建块》的`01-PyTorch_Basics.ipynb`笔记本中，我们看到如何编写一个PyTorch模型和训练循环来训练一个简单的分类器。但现在，我们将训练循环委托给PyTorch
    Lightning，所以还需要包括一些额外的方法：
- en: '`training_step`: This method takes in a batch and uses the model to get the
    outputs, calculate the loss/metrics, and return the loss.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`training_step`：该方法接收批次数据，并使用模型获取输出，计算损失/指标，并返回损失值。'
- en: '`validation_step` and `test_step`: These methods take in the batch and use
    the model to get the outputs and calculate the loss/metrics.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`validation_step`和`test_step`：这些方法接收批次数据，并使用模型获取输出，计算损失/指标。'
- en: '`predict_step`: This method is used to define the step to be taken while inferencing.
    If there is anything special we have to do for inferencing, we can define this
    method. If this is not defined, it uses `test_step` for the prediction use case
    as well.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predict_step`：该方法用于定义推理时要执行的步骤。如果在推理过程中需要做一些特别的处理，我们可以定义这个方法。如果没有定义，它将使用`test_step`作为预测时的步骤。'
- en: '`configure_optimizers`: This method defines the optimizer to be used, for instance,
    `Adam` or `RMSProp`.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`configure_optimizers`：该方法定义了使用的优化器，例如`Adam`或`RMSProp`。'
- en: We have defined a `BaseModel` class in `src/dl/models.py` that implements all
    the common functions, such as loss and metric calculation and result logging,
    as a framework to implement new models. Using this `BaseModel` class, we have
    defined a `SingleStepRNNModel` class that takes in a standard config (`SingleStepRNNConfig`)
    and initializes an RNN, LSTM, or GRU model.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`src/dl/models.py`中定义了一个`BaseModel`类，实现了所有常见的功能，如损失和指标计算、结果日志记录等，作为实现新模型的框架。使用这个`BaseModel`类，我们定义了一个`SingleStepRNNModel`类，它接收标准配置（`SingleStepRNNConfig`）并初始化一个RNN、LSTM或GRU模型。
- en: 'Before we look at how the model is defined, let’s see what the different config
    (`SingleStepRNNConfig`) parameters are:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看模型是如何定义之前，先来看一下不同的配置（`SingleStepRNNConfig`）参数：
- en: '`rnn_type`: This parameter takes in one of three strings as input: `RNN`, `GRU`,
    or `LSTM`. This defines what kind of model we will initialize.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rnn_type`：该参数接收三个字符串中的一个作为输入：`RNN`、`GRU`或`LSTM`。它定义了我们将要初始化的模型类型。'
- en: '`input_size`: This parameter defines the number of features the RNN is expecting.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_size`：该参数定义了RNN所期望的特征数量。'
- en: '`hidden_size`, `num_layers`, and `bidirectional`: These parameters are the
    same as the ones we saw in the RNN cell in *Chapter 12*, *Building Blocks of Deep
    Learning for Time Series*.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size`、`num_layers`和`bidirectional`：这些参数与我们在*第12章*《时间序列深度学习的构建块》中看到的RNN单元相同。'
- en: '`learning_rate`: This defines the learning rate of the optimization procedure.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate`：该参数定义了优化过程中的学习率。'
- en: '`optimizer_params`, `lr_scheduler`, and `lr_scheduler_params`: These are parameters
    that let us tweak the optimization procedure. Let’s not worry about them for now
    because all of them have been set to intelligent defaults.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizer_params`，`lr_scheduler`，和 `lr_scheduler_params`：这些是可以让我们调整优化过程的参数。现在先不需要担心它们，因为它们都已经被设置为智能的默认值。'
- en: 'With this setup, defining a new model is as simple as this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种设置，定义一个新模型就像这样简单：
- en: '[PRE10]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, let’s take a peek at the `forward` method, which is the heart of the model.
    We want our model to do one-step-ahead prediction, and from *Chapter 12*, *Building
    Blocks of Deep Learning for Time Series*, we know what a typical RNN output is
    and how PyTorch RNNs just output the hidden state at each timestep. Let’s see
    what we want to do visually and then see how we can code it up:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一眼 `forward` 方法，它是模型的核心。我们希望我们的模型能进行一步预测，并且从*第12章*中，*时间序列深度学习的构建块*，我们知道典型的
    RNN 输出是什么，以及 PyTorch RNN 如何仅在每个时间步输出隐藏状态。让我们先从视觉上了解我们想要做什么，然后看看如何将其编码实现：
- en: '![Figure 13.3 – A single-step RNN ](img/B22389_13_03.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.3 – 单步 RNN](img/B22389_13_03.png)'
- en: 'Figure 13.3: A single-step RNN'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.3：单步 RNN
- en: Suppose we are using the same example we saw in the dataloader—a time series
    with the following entries, *x*[1], *x*[2], *x*[3], …, *x*[7], and a window of
    three. So, one of the samples the dataloader gives will have *x*[1], *x*[2], and
    *x*[3] as the input (*x*) and *x*[4] as the target. One way we can use this is
    by passing the sequence through the RNN, ignoring all the outputs except the last
    one, and using it to predict the target, *x*[4]. But that is not an efficient
    use of the samples we have, right? We also know that the output from the first
    timestep (using *x*[1]) should output *x*[2], the second timestep should output
    *x*[3], and so on. Therefore, we can formulate the RNN in such a way that we maximize
    the usage of the data and, while training, use these additional points in time
    to also give a better signal to our model. Now, let’s break down the `forward`
    method.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们使用的是在数据加载器中看到的相同示例——一个包含以下条目的时间序列，*x*[1]，*x*[2]，*x*[3]，……，*x*[7]，并且窗口大小为三。所以，数据加载器给出的一个样本将会包含
    *x*[1]，*x*[2] 和 *x*[3] 作为输入 (*x*)，并且 *x*[4] 作为目标。我们可以使用这种方法，将序列通过 RNN 处理，忽略所有输出，只保留最后一个输出，并利用它来预测目标
    *x*[4]。但这不是一种高效利用我们样本的方法，对吧？我们也知道，第一时间步的输出（使用 *x*[1]）应该是 *x*[2]，第二时间步的输出应该是 *x*[3]，依此类推。因此，我们可以将
    RNN 设计成一种方式，最大化数据的使用，同时在训练过程中使用这些额外的时间点来给模型提供更好的信号。现在，让我们详细分析 `forward` 方法。
- en: '`forward` takes in a single argument called `batch`, which is a tuple of input
    and output. So, we unpack `batch` into two variables, `x` and `y`, like so:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`forward` 方法接受一个名为 `batch` 的单一参数，它是输入和输出的元组。因此，我们将 `batch` 解包成两个变量 `x` 和 `y`，像这样：'
- en: '[PRE11]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '`x` will have the shape ![](img/B22389_13_002.png) *(batch size, window length,
    features)* and `y` will have the shape ![](img/B22389_13_003.png) *(batch size,
    target length, features)*.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`x` 的形状将是 ![](img/B22389_13_002.png) *(批量大小，窗口长度，特征数)*，而 `y` 的形状将是 ![](img/B22389_13_003.png)
    *(批量大小，目标长度，特征数)*。'
- en: 'Now we need to pass the input sequence (`x`) through the RNN (RNN, LSTM, or
    GRU), like so:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要将输入序列 (`x`) 通过 RNN（RNN、LSTM 或 GRU）处理，像这样：
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As we saw in *Chapter 12*, *Building Blocks of Deep Learning for Time Series*,
    the PyTorch RNNs process the input and return two outputs—hidden states for each
    timestep and output (which is the hidden state of the last timestep). Here, we
    need the hidden states from all the timesteps, and therefore we capture that in
    the `x` variable. `x` will now have the dimension (*batch size, window length,
    hidden size of RNN*).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*第12章*中看到的，*时间序列深度学习的构建块*，PyTorch RNN 会处理输入并返回两个输出——每个时间步的隐藏状态和输出（即最后一个时间步的隐藏状态）。在这里，我们需要来自所有时间步的隐藏状态，因此我们将其存储在
    `x` 变量中。`x` 现在的维度将是 (*批量大小，窗口长度，RNN 隐藏层大小*)。
- en: 'We have the hidden states, but to get the output, we need to apply a fully
    connected layer over the hidden states, and this fully connected layer should
    be shared across timesteps. An easy way to do this is to just define a fully connected
    layer with an input size equal to the hidden size of the RNN and then do the following:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有了隐藏状态，但要得到输出，我们需要对隐藏状态应用一个全连接层，这个全连接层应该在所有时间步中共享。实现这一点的简单方法是定义一个输入大小等于 RNN
    隐藏层大小的全连接层，然后执行以下操作：
- en: '[PRE13]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`x` is a three-dimensional tensor, and when we use a fully connected layer
    on a three-dimensional tensor, PyTorch automatically applies the fully connected
    layer to each of the timesteps. Now, this final output is captured in `x`, and
    its dimensions would be *(batch size, window length*, *1)*.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`x` 是一个三维张量，当我们在三维张量上使用全连接层时，PyTorch 会自动将全连接层应用到每个时间步上。现在，最终输出被保存在 `x` 中，其维度为
    *(batch size, window length*, *1)*。'
- en: 'Now, we have got the output of the network, but we also must do a bit of rearrangement
    to prepare the targets. Currently, `y` has just the one timestep beyond the window,
    but if we skip the first timestep from `x` and concatenate it with `y`, we would
    get the target, as we have in *Figure 13.3*:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经得到了网络的输出，但我们还需要做一些调整来准备目标。当前，`y` 只有窗口之外的一个时间步，但如果我们跳过 `x` 中的第一个时间步并将其与
    `y` 连接，我们就可以得到目标，正如我们在 *图 13.3* 中所看到的那样：
- en: '[PRE14]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: By using array indexing, we select everything except the first timestep from
    `x` and concatenate it with `y` on the first dimension (which is the *window length*).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用数组索引，我们选择 `x` 中除了第一个时间步之外的所有内容，并将其与 `y` 在第一维（即 *窗口长度*）上连接。
- en: And with that, we have the `x` and `y` variables, which we can return, and the
    `BaseModel` class will calculate loss and handle the rest of the training. For
    the entire class, along with the `forward` method, you can refer to `src/dl/models.py`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就有了 `x` 和 `y` 变量，我们可以返回它们，而 `BaseModel` 类将计算损失并处理其余的训练。有关整个类以及 `forward`
    方法的内容，您可以参考 `src/dl/models.py`。
- en: 'Let’s test the model we have initialized by passing the batch from the dataloader:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过传递数据加载器中的批次来测试我们初始化的模型：
- en: '[PRE15]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now that the model is working as expected, without errors, let’s start training
    the model. For that, we can use `Trainer` from PyTorch Lightning. There are so
    many options in the `Trainer` class, and a full list of all parameters to tweak
    the training can be found here: [https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html#pytorch_lightning.trainer.trainer.Trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html#pytorch_lightning.trainer.trainer.Trainer).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型按预期工作，没有错误，让我们开始训练模型。为此，我们可以使用 PyTorch Lightning 的 `Trainer`。`Trainer` 类中有许多选项，完整的参数列表可以在这里找到：[https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html#pytorch_lightning.trainer.trainer.Trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html#pytorch_lightning.trainer.trainer.Trainer)。
- en: 'But here, we are just going to use the bare minimum. Let’s go over the parameters
    we will be using here one by one:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 但在这里，我们只会使用最基本的参数。让我们逐一介绍我们将在这里使用的参数：
- en: '`auto_select_gpus` and `gpus`: Together, these parameters let us select GPUs
    for training if present. If we set `auto_select_gpus` to `True` and `gpus` to
    `-1`, the `Trainer` class will choose all GPUs present in the machine, and if
    there are no GPUs, it falls back to CPU-based training.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auto_select_gpus` 和 `gpus`：这两个参数让我们可以选择用于训练的 GPU（如果存在）。如果我们将 `auto_select_gpus`
    设置为 `True`，并将 `gpus` 设置为 `-1`，则 `Trainer` 类会选择机器中所有的 GPU，如果没有 GPU，它会回退到基于 CPU
    的训练。'
- en: '`callbacks`: PyTorch Lightning has a lot of useful callbacks that can be used
    during training such as `EarlyStopping`, `ModelCheckpoint`, and so on. Most useful
    callbacks are automatically added even if we don’t explicitly set them, but `EarlyStopping`
    is one useful callback that needs to be set explicitly. `EarlyStopping` is a callback
    that lets us monitor the validation loss or metrics while training and stop the
    training when this starts to become worse. This is a form of regularization and
    helps us keep our model from overfitting to the train data. `EarlyStopping` has
    the following major parameters (a full list of parameters can be found here: [https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.EarlyStopping.html](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.EarlyStopping.html)):'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callbacks`：PyTorch Lightning 提供了许多在训练过程中可以使用的有用回调，如 `EarlyStopping`、`ModelCheckpoint`
    等。即使我们没有显式设置，大多数有用的回调会自动添加，但 `EarlyStopping` 是一个需要显式设置的有用回调。`EarlyStopping` 是一个回调函数，可以在训练过程中监控验证损失或指标，并在验证损失开始变差时停止训练。这是一种正则化形式，帮助我们防止模型在训练数据上过拟合。`EarlyStopping`
    具有以下主要参数（完整的参数列表可以在这里找到：[https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.EarlyStopping.html](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.EarlyStopping.html)）：'
- en: '`monitor`: This parameter takes a string input that specifies the exact name
    of the metric that we want to monitor for early stopping.'
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`monitor`：这个参数接受一个字符串输入，指定我们希望监控的早停指标的确切名称。'
- en: '`patience`: This specifies the number of epochs with no improvement in the
    monitored metric before the callback stops the training. For instance, if we set
    `patience` to `10`, the callback will wait for 10 epochs of the degrading metric
    before stopping the training. There are finer points of detail on these, which
    are explained in the documentation.'
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patience`：这个参数指定了在监控的指标没有改善的情况下，回调停止训练的轮次。例如，如果我们将`patience`设置为`10`，回调将在监控指标恶化的10个轮次后停止训练。关于这些细节，还有更详细的说明，您可以在文档中找到。'
- en: '`mode`: This is a string input and takes one of `min` or `max`. This sets the
    direction of improvement. In `min` mode, training will stop when the quantity
    monitored has stopped decreasing, and in `max` mode, it will stop when the quantity
    monitored has stopped increasing.'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mode`：这是一个字符串输入，接受`min`或`max`中的一个。它设置了改善的方向。在`min`模式下，当监控的量停止下降时，训练会停止；在`max`模式下，当监控的量停止上升时，训练会停止。'
- en: '`min_epochs` and `max_epochs`: These parameters help us set `min` and `max`
    limits to the number of epochs the training should run. If we are using `EarlyStopping`,
    `min_epochs` decides the minimum number of epochs that will be run regardless
    of the validation loss/metrics, and `max_epochs` sets the upper limit on the number
    of epochs. So, even if the validation loss is still decreasing when we reach `max_epochs`,
    training will stop.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_epochs` 和 `max_epochs`：这些参数帮助我们设定训练应运行的`min`和`max`轮次的限制。如果我们使用了`EarlyStopping`，`min_epochs`决定了无论验证损失/度量如何，都会运行的最小轮次，而`max_epochs`则设置了最大轮次限制。所以，即使在达到`max_epochs`时验证损失仍在下降，训练也会停止。'
- en: '**Glossary:**'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**Glossary：**'
- en: 'Here are a few terms you should know to fully digest NN training:'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里有一些你应该了解的术语，以便全面理解神经网络训练：
- en: '**Training step**: This denotes a single gradient update to the parameter.
    In batched **stochastic gradient descent** (**SGD**), the gradient update after
    each batch is considered a step.'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Training step**：表示对参数的单次梯度更新。在批量**随机梯度下降**（**SGD**）中，每次批次后的梯度更新被视为一步。'
- en: '**Batch**: A batch is the number of data samples we run through the model and
    average the gradients over for the update in a training step.'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Batch**：一个batch是我们通过模型运行的数据样本数量，并在训练步骤中对这些样本的梯度进行平均更新。'
- en: '**Epoch**: An epoch is when the model has seen all the samples in a dataset,
    or all the batches in the dataset have been used for a gradient update.'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Epoch**：一个epoch指的是模型已经看过数据集中所有样本，或者数据集中的所有批次已经用于梯度更新。'
- en: 'So, let’s initialize a bare-bones `Trainer` class:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们初始化一个简单的`Trainer`类：
- en: '[PRE16]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, all that is left is to trigger the training by passing in the `model`
    and `datamodule` to a method called `fit`:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，只剩下通过将`model`和`datamodule`传递给一个名为`fit`的方法来触发训练：
- en: '[PRE17]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'It will run for a while and, depending on when the validation loss starts to
    increase, it will stop the training. Once the model is trained, we can still use
    the `Trainer` class to make predictions on new data. The prediction uses the `predict_step`
    method that we defined in the `BaseModel` class, which in turn uses the `predict`
    method that we defined in the `SingleStepRNN` model. It’s a very simple method
    that calls the `forward` method, takes in the model outputs, and just picks the
    last timestep from the output (which is the true output that we are projecting
    into the future). You can see an illustration of this here:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 它将运行一段时间，并根据验证损失何时开始增加来停止训练。模型训练完成后，我们仍然可以使用`Trainer`类对新数据进行预测。预测使用的是我们在`BaseModel`类中定义的`predict_step`方法，该方法又调用了我们在`SingleStepRNN`模型中定义的`predict`方法。这个方法非常简单，它调用`forward`方法，获取模型输出，并仅从输出中选择最后一个时间步（即我们正在预测的未来输出）。你可以在这里看到一个说明：
- en: '[PRE18]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'So, let’s see how we can use the `Trainer` class to make predictions on new
    data (or new dataloaders, to be exact):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们看看如何使用`Trainer`类对新数据（或者更准确地说，是新数据加载器）进行预测：
- en: '[PRE19]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We just need to provide the trained model and the dataloader (here, we use the
    test dataloader that we have already set up and defined).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要提供训练好的模型和数据加载器（在这里，我们使用已经设置并定义的测试数据加载器）。
- en: 'Now the output, `pred`, is a list of tensors, one for each batch in the dataloader.
    We just need to concatenate them, squeeze out any redundant dimensions, detach
    them from the computational graph, and convert them to a NumPy array. Here’s how
    we can do this:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，输出 `pred` 是一个张量列表，每个批次一个。我们只需要将它们拼接在一起，去除任何多余的维度，将其从计算图中分离出来，并转换为 NumPy 数组。我们可以这样做：
- en: '[PRE20]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, `pred` is a NumPy array of predictions for all the items in the test DataFrame
    (which was used to define `test_dataloader`), but remember we had applied a transformation
    to the raw time series to standardize it. Now, we need to reverse the transformation.
    The mean and standard deviation we used for the initial transformation are still
    stored in the train dataset. We merely retrieve them and invert the transformation
    we did earlier, like so:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`pred` 是一个包含所有测试数据框（用于定义 `test_dataloader`）项目预测的 NumPy 数组，但记得我们之前对原始时间序列进行了标准化处理。现在，我们需要将这个转换反向处理。我们最初用于标准化的均值和标准差仍然存储在训练数据集中。我们只需要将它们取出并反转之前的转换，如下所示：
- en: '[PRE21]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we can do all kinds of actions on them, such as evaluate against actuals,
    visualize the predictions, and so on. Let’s see how well the model has done. To
    get context, we have included the single-step ML models we did back in *Chapter
    8*, *Forecasting Time Series with Machine Learning Models*, as well:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以对它们进行各种操作，例如与实际数据进行对比、可视化预测结果等等。让我们看看模型的表现如何。为了提供背景信息，我们还包含了*第 8 章*中使用的单步机器学习模型，*《使用机器学习模型预测时间序列》*：
- en: '![Figure 13.4 – Metrics of the vanilla single-step-ahead RNN on MAC000193 household
    ](img/B22389_13_04.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.4 – MAC000193 家庭的基础单步前馈 RNN 指标](img/B22389_13_04.png)'
- en: 'Figure 13.4: Metrics of the vanilla single-step-ahead RNN on MAC000193 household'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.4：MAC000193 家庭的基础单步前馈 RNN 指标
- en: 'It looks like the RNN model did pretty badly. Let’s also look at the predictions
    visually:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来 RNN 模型的表现相当糟糕。让我们也来直观地看看预测结果：
- en: '![Figure 13.5 – Single-step-ahead RNN predictions for MAC000193 household ](img/B22389_13_05.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.5 – MAC000193 家庭的单步前馈 RNN 预测](img/B22389_13_05.png)'
- en: 'Figure 13.5: Single-step-ahead RNN predictions for MAC000193 household'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5：MAC000193 家庭的单步前馈 RNN 预测
- en: We can see that the model has failed to learn the scale of the peaks and the
    nuances of the patterns. Maybe this is because of the problem that we discussed
    in terms of RNNs because the seasonality pattern here is spread over 48 timesteps;
    remember that the pattern requires the RNN to have long-term memory. Let’s quickly
    swap out the model with LSTM and GRU and see how they are doing. The only thing
    we need to change is the `rnn_type` parameter in `SingleStepRNNConfig`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到模型未能学习到峰值的规模和模式的细微变化。也许这是我们在讨论 RNN 时提到的问题，因为季节性模式在 48 个时间步内展开；记住，这个模式需要
    RNN 具有长期记忆能力。让我们快速将模型替换为 LSTM 和 GRU，看看它们的表现如何。我们需要更改的唯一参数是 `rnn_type` 参数，位于 `SingleStepRNNConfig`
    中。
- en: 'The notebook has the code to train LSTM and GRU as well. But let’s look at
    the metrics with LSTM and GRU:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本中也包含了训练 LSTM 和 GRU 的代码。但是让我们来看一下 LSTM 和 GRU 的指标：
- en: '![Figure 13.6 – Metrics for single-step-ahead LSTM and GRU on MAC000193 household
    ](img/B22389_13_06.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.6 – MAC000193 家庭的单步前馈 LSTM 和 GRU 指标](img/B22389_13_06.png)'
- en: 'Figure 13.6: Metrics for single-step-ahead LSTM and GRU on MAC000193 household'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6：MAC000193 家庭的单步前馈 LSTM 和 GRU 指标
- en: 'Now, it looks competitive. LightGBM is still the best model, but now the LSTM
    and GRU models are competitive and not entirely lacking, like the vanilla RNN
    model. If we look at the predictions, we can see that the LSTM and GRU models
    have managed to capture the pattern much better as well:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，表现看起来具有竞争力。LightGBM 仍然是最好的模型，但现在 LSTM 和 GRU 模型表现得也很有竞争力，不像基础 RNN 模型那样完全缺乏。如果我们看一下预测结果，我们可以看到
    LSTM 和 GRU 模型已经能更好地捕捉到模式：
- en: '![Figure 13.7 – Single-step-ahead LSTM and GRU predictions for MAC000193 household
    ](img/B22389_13_07.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.7 – MAC000193 家庭的单步前馈 LSTM 和 GRU 预测](img/B22389_13_07.png)'
- en: 'Figure 13.7: Single-step-ahead LSTM and GRU predictions for MAC000193 household'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7：MAC000193 家庭的单步前馈 LSTM 和 GRU 预测
- en: '**Things to try:**'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**待尝试的事项：**'
- en: Try changing the parameters of the models and see how it works. How does a bidirectional
    LSTM perform? Can increasing the window increase performance?
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试更改模型的参数，看看效果如何。双向 LSTM 的表现如何？增加窗口大小能提高性能吗？
- en: Now that we have seen how a standard RNN can be used for single-step-ahead predictions,
    let’s look at another modeling pattern that is more flexible than the one we just
    saw.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了如何使用标准RNN进行单步预测，让我们来看看一种比我们刚才看到的模式更灵活的建模方式。
- en: Sequence-to-sequence (Seq2Seq) models
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列到序列（Seq2Seq）模型
- en: We talked in detail about the Seq2Seq architecture and the encoder-decoder paradigm
    in *Chapter 12*, *Building Blocks of Deep Learning for Time Series*. Just to refresh
    your memory, the Seq2Seq model is kind of an encoder-decoder model by which an
    encoder encodes the sequence into a latent representation, and then the decoder
    steps in to carry out the task at hand using this latent representation. This
    setup is inherently more flexible because of the separation between the encoder
    (which does the representation learning) and the decoder, which uses the representation
    for predictions. One of the biggest advantages of this approach, from a time series
    forecasting perspective, is that the restriction of single step ahead is taken
    out. In this modeling pattern, we can extend the forecast to any forecast horizon
    we want.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第12章*《时间序列深度学习基础》中详细讨论了Seq2Seq架构和编码器-解码器范式。为了帮助你回忆，Seq2Seq模型是一种编码器-解码器模型，其中编码器将序列编码成潜在表示，然后解码器使用该潜在表示执行任务。这种设置本质上更加灵活，因为编码器（负责表示学习）和解码器（使用表示进行预测）是分开的。从时间序列预测的角度来看，这种方法的最大优势之一是取消了单步预测的限制。在这种建模模式中，我们可以将预测扩展到任何我们想要的预测时间范围。
- en: In this section, let’s put together a few encoder-decoder models and test out
    our single-step-ahead forecasts, just like we have been doing with the single-step-ahead
    RNNs.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将组合几个编码器-解码器模型，并像以前使用单步前馈RNN一样测试我们的单步预测。
- en: '**Notebook alert:**'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**笔记本提示：**'
- en: To follow along with the complete code, use the notebook named `03-Seq2Seq_RNN.ipynb`
    in the `Chapter13` folder and the code in the `src` folder.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随完整的代码，请使用`Chapter13`文件夹中的`03-Seq2Seq_RNN.ipynb`笔记本以及`src`文件夹中的代码。
- en: We can use the same mechanism we developed in the last section, such as `TimeSeriesDataModule`,
    the `BaseModel` class, and the corresponding code, for our Seq2Seq modeling pattern
    as well. Let’s define a new PyTorch model called `Seq2SeqModel`, inheriting the
    `BaseModel` class. While we are at it, let’s also define a new config file, called
    `Seq2SeqConfig`, to set the hyperparameters of the model. The final version of
    both can be found in `src/dl/models.py`.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用上一节中开发的相同机制，如`TimeSeriesDataModule`、`BaseModel`类和相应的代码，来实现我们的Seq2Seq建模模式。让我们定义一个新的PyTorch模型，叫做`Seq2SeqModel`，继承`BaseModel`类。同时，我们还可以定义一个新的配置文件，叫做`Seq2SeqConfig`，用于设置模型的超参数。最终版本的代码可以在`src/dl/models.py`中找到。
- en: Before we explain the different parameters in the model and the config, let’s
    talk about the different ways we can set this Seq2Seq model.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们解释模型和配置中的不同参数之前，让我们先讨论一下如何设置这个Seq2Seq模型的不同方式。
- en: RNN-to-fully connected network
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RNN到全连接网络
- en: 'For our convenience, let’s restrict the encoder to be from the RNN family—it
    can be a vanilla RNN, LSTM, or GRU. Now, we saw in *Chapter 12*, *Building Blocks
    of Deep Learning for Time Series,* that in PyTorch, all the models in the RNN
    family have two outputs—*output* and *hidden states*, and we also saw that output
    is nothing but all the hidden states (final hidden states in stacked RNNs) at
    all timesteps. The hidden state that we get has the latest hidden states (and
    cell states, in the case of LSTM) of all layers in the stacked RNN setup. The
    encoder can be initialized just like we initialized the RNN family of models in
    the previous section, like so:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，我们将编码器限制为RNN系列模型——可以是普通的RNN、LSTM或GRU。如同我们在*第12章*《时间序列深度学习基础》一书中所看到的，在PyTorch中，所有RNN系列模型都有两个输出——*output*和*hidden
    states*，我们还看到，output实际上就是在所有时间步的隐藏状态（在堆叠RNN中为最终隐藏状态）。我们得到的隐藏状态包含所有层的最新隐藏状态（对于LSTM来说，也包括单元状态）。编码器可以像上一节中初始化RNN系列模型那样进行初始化，代码如下：
- en: '[PRE22]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'And in the `forward` method, we can just do the following to encode the time
    series:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在`forward`方法中，我们可以做如下操作来编码时间序列：
- en: '[PRE23]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, there are a few different ways we can decode the information. The first
    one we will discuss is using a fully connected layer. Either the fully connected
    layer can take the latest hidden state from the encoder and predict the desired
    output or we can flatten all the hidden states into a long vector and use that
    to predict the output. The latter provides more information to the decoder, but
    there can be more noise as well. Both are shown in *Figure 13.8*, using the same
    example we used in the last section as well:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有几种不同的方法可以解码信息。我们将讨论的第一种方法是使用完全连接层。完全连接层可以接受来自编码器的最新隐藏状态并预测所需的输出，或者我们可以将所有隐藏状态展平为一个长向量并用它来预测输出。后者为解码器提供了更多信息，但也可能会带来更多噪音。这两种方法在*图13.8*中展示，且使用的是我们在上一节中使用的相同示例：
- en: '![Figure 13.8 – RNN as the encoder and a fully connected layer as the decoder
    ](img/B22389_13_08.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图13.8 – RNN作为编码器，完全连接层作为解码器](img/B22389_13_08.png)'
- en: 'Figure 13.8: RNN as the encoder and a fully connected layer as the decoder'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.8：RNN作为编码器，完全连接层作为解码器
- en: 'Let’s also see how we can put this together in code. The decoder in the first
    case, where we are using just the last hidden state of the encoder, will look
    like this:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也看看如何将这些内容在代码中实现。在第一种情况下，我们只使用编码器的最后一个隐藏状态，解码器的代码将如下所示：
- en: '[PRE24]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here, `bi_directional_multiplier` is `2` if the encoder is bidirectional and
    `1` otherwise. This is done because if the encoder is bidirectional, there will
    be two hidden states concatenated together for each timestep. `horizon` is the
    number of timesteps ahead we want to forecast.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，如果编码器是双向的，那么`bi_directional_multiplier`为`2`，否则为`1`。这是因为如果编码器是双向的，每个时间步的隐藏状态将会连接成两个。`horizon`是我们希望预测的时间步数。
- en: 'In the second case, where we are using the hidden states from all the timesteps,
    we need to make the decoder, as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种情况下，我们使用所有时间步的隐藏状态时，需要按照如下方式构建解码器：
- en: '[PRE25]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Here, the input vector will be the flattened vector of all the hidden states
    from all the timesteps, and hence the input dimension would be `hidden_size *
    window_size`.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，输入向量将是来自所有时间步的所有隐藏状态的展平向量，因此输入维度将是`hidden_size * window_size`。
- en: 'And in the `forward` method, we can do the following for case 1:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在`forward`方法中，对于第一种情况，我们可以进行如下操作：
- en: '[PRE26]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Here, we are just taking the hidden state from the latest timestep and unsqueezing
    to maintain three dimensions as the target, `y`.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只取最新时间步的隐藏状态，并通过`unsqueeze`操作保持三维结构，以符合目标`y`的维度。
- en: 'For case 2, we can do the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二种情况，我们可以做如下操作：
- en: '[PRE27]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Here, we first reshape the entire hidden state to flatten it and then pass it
    through the decoder to get the predictions. We unsqueeze to insert the dimension
    we collapsed so that the output and target, `y`, have the same dimensions.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们首先重新调整整个隐藏状态，将其展平，然后将其传递给解码器以获得预测结果。我们使用`unsqueeze`操作来插入我们刚刚压缩的维度，使得输出和目标`y`具有相同的维度。
- en: Even though, in theory, we can use the fully connected decoder to predict as
    much into the future as possible, practically, there are limitations. When we
    have a large number of steps to forecast, the model will have to learn that big
    of a matrix to generate those outputs, and that becomes harder as the matrix becomes
    bigger. Another point worth noting is that each of these predictions happens independently
    with the information encoded in the latent representation. For instance, the prediction
    of 5 timesteps ahead is only dependent on the latent representation from the encoder
    and not predictions of *timesteps 1* to *4*. Let’s look at another type of Seq2Seq,
    which makes the decoding more flexible and aware of the temporal aspect of the
    problem.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管理论上我们可以使用全连接解码器来预测尽可能多的未来步数，但在实际操作中是有限制的。当我们需要预测大量的时间步时，模型必须学习一个如此大的矩阵来生成这些输出，而随着矩阵变大，学习变得更加困难。另一个值得注意的点是，这些预测每一个都是独立发生的，且仅依赖于编码器中潜在表示的信息。例如，预测5个时间步后的结果只依赖于编码器中的潜在表示，而与*时间步1*到*4*的预测无关。让我们看看另一种类型的Seq2Seq，它使得解码更加灵活，并且能更好地考虑问题的时间性。
- en: RNN-to-RNN
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RNN到RNN
- en: 'Instead of using a fully connected layer as the decoder, we can use another
    RNN for decoding as well—so, one model from the RNN family takes care of the encoding
    and another model from the RNN family takes care of the decoding. Initializing
    the decoder in the model is also similar to initializing the encoder. If we want
    an LSTM model as the decoder, we can do the following:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用另一个 RNN 来作为解码器，而不是使用全连接层作为解码器——所以，RNN 家族中的一个模型负责编码，另一个模型负责解码。初始化解码器的过程与初始化编码器相似。如果我们想使用
    LSTM 模型作为解码器，可以按照以下方式进行操作：
- en: '[PRE28]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let’s develop our understanding of how this is done through a visual representation:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个可视化表示来加深对这个过程的理解：
- en: '![Figure 13.9 – RNN as the encoder and decoder ](img/B22389_13_09.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.9 – RNN 作为编码器和解码器](img/B22389_13_09.png)'
- en: 'Figure 13.9: RNN as the encoder and decoder'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.9：RNN 作为编码器和解码器
- en: 'The encoder part remains the same: it takes in the input window, *x*[1] to
    *x*[3], and produces outputs, *o*[1] to *o*[3], and the last hidden state, *h*[3].
    Now, we have another decoder (a model from the RNN family) that takes in *h*[3]
    as the initial hidden state, and the latest input from the window to produce the
    next output. And now, this output is fed back into the RNN as the input and we
    produce the next output, and this cycle continues until we have got the required
    number of timesteps in our prediction.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器部分保持不变：它接收输入窗口，*x*[1] 到 *x*[3]，并产生输出，*o*[1] 到 *o*[3]，以及最后的隐藏状态，*h*[3]。现在，我们有另一个解码器（来自
    RNN 家族的模型），它将 *h*[3] 作为初始隐藏状态，并使用窗口中的最新输入来生成下一个输出。现在，这个输出被反馈到 RNN 作为输入，我们继续生成下一个输出，这个循环会一直持续，直到我们得到预测所需的时间步数。
- en: Some of you may be wondering why we don’t use the target window (*x*[4] to *x*[6])
    during decoding as well. In fact, this is a valid way of training the model and
    is called **teacher forcing** in the literature. This has strong connections to
    maximum likelihood and is explained well in the *Deep Learning* book by Goodfellow
    et al. (see the *Further reading* section). So, instead of feeding in the output
    of the model from the previous timestep as the input to the RNN at the current
    timestep, we feed in the real observation, thereby eliminating the error that
    might have crept in in the previous timestep.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 你们可能会想知道，为什么在解码时不使用目标窗口（*x*[4] 到 *x*[6]）。事实上，这是一种有效的训练模型的方法，在文献中称为 **教师强制**。这种方法与最大似然估计有很强的联系，并且在
    Goodfellow 等人的《深度学习》一书中有很好的解释（见《进一步阅读》部分）。因此，代替将模型在前一个时间步的输出作为当前时间步 RNN 的输入，我们将真实观察值作为输入，从而消除了前一个时间步可能引入的错误。
- en: While this sounds like the most straightforward thing to do, it does come with
    a few disadvantages as well. The main one is that the kinds of inputs that the
    decoder sees during training may not be the same as the ones it will see during
    actual prediction. During prediction, we will still be feeding the output of the
    model in the previous step to the decoder. This is because in the inference mode,
    we do not have access to real observations in the future. This can cause problems
    in some cases. One way to mitigate this problem is to randomly choose between
    the model’s output at the previous timestep and real observation while training
    (Bengio et al., 2015).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这看起来是最直接的做法，但它也有一些缺点。最主要的缺点是解码器在训练过程中看到的输入类型，可能与实际预测过程中看到的输入类型不同。在预测过程中，我们仍然会将前一步模型的输出作为解码器的输入。这是因为在推理模式下，我们无法访问未来的真实观察值。这在某些情况下可能会引发问题。解决这个问题的一种方法是在训练过程中随机选择模型在前一个时间步的输出和真实观察值之间进行选择（Bengio
    等人，2015）。
- en: '**Reference check:**'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考检查：**'
- en: The research paper by Bengio et al., which proposed teacher forcing, is cited
    in reference *1*.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Bengio 等人提出的教师强制方法在文献 *1* 中有引用。
- en: Now, let’s see how we can code the `forward` method for both of these cases
    using a parameter called `teacher_forcing_ratio`, which is a decimal from 0 to
    1\. This decides how frequently teacher forcing is implemented. For instance,
    if `teacher_forcing_ratio` = 0, then teacher forcing is never done, and if `teacher_forcing_ratio`
    = 1, then teacher forcing is always done.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何通过一个名为 `teacher_forcing_ratio` 的参数来编写 `forward` 方法，这个参数是一个从 0 到 1
    的小数，决定教师强制的实施频率。例如，如果 `teacher_forcing_ratio` = 0，则从不使用教师强制；如果 `teacher_forcing_ratio`
    = 1，则始终使用教师强制。
- en: 'The following code block has all the code necessary for decoding, and it comes
    with line numbers so that we can go line by line and explain what we are doing:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块包含了解码所需的所有代码，并附有行号，以便我们可以逐行解释我们正在做什么：
- en: '[PRE29]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The first thing we need to do is declare a placeholder to store the desired
    output during decoding. In *line number 1*, we do that by using `zeros_like`,
    which generates a tensor with all zeros with the same dimension as `y`, and in
    *line number 2*, we set the initial input to the decoder as the last timestep
    in the input window. Now, we are all set to start the decoding process, and for
    that, in *line number 3*, we start a loop to run `y.size(1)` times. If you remember
    the dimensions of `y`, the second dimension was the sequence length, so we need
    to run the decoding process that many times.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是声明一个占位符，用于在解码过程中存储期望的输出。在*第1行*，我们通过使用`zeros_like`来实现，它会生成一个与`y`具有相同维度的全零张量；在*第2行*，我们将解码器的初始输入设置为输入窗口中的最后一个时间步。现在，我们已经准备好开始解码过程，为此，在*第3行*，我们开始一个循环，运行`y.size(1)`次。如果你记得`y`的维度，第二个维度是序列长度，因此我们需要解码这么多次。
- en: In *line number 4*, we pass in the last input from the input window and the
    hidden state from the encoder to the decoder, and it returns the current output
    and the hidden state. We capture the current hidden state in the same variable,
    overwriting the old one. If you remember, the output from the RNN is the hidden
    state, and we will need to pass it through a fully connected layer for the prediction.
    So, in *line number 5*, we do just that. In *line number 6*, we store the output
    from the fully connected layer to the *i*-th timestep in `y_hat`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第4行*，我们将输入窗口中的最后一个输入和编码器的隐藏状态传递给解码器，解码器返回当前输出和隐藏状态。我们将当前的隐藏状态存储在相同的变量中，覆盖掉旧的状态。如果你记得，RNN的输出就是隐藏状态，我们将需要将它传递通过一个全连接层来进行预测。因此，在*第5行*，我们就是这么做的。在*第6行*，我们将全连接层的输出存储到`y_hat`的第*i*个时间步中。
- en: Now, we just have one more thing to do—decide whether to use teacher forcing
    or not and move on to decoding the next timestep. This we can do by generating
    a random number between *0* and *1* and checking whether that number is less than
    the `teacher_forcing_ratio` parameter or not. `random.random()` samples a number
    from a uniform distribution between *0* and *1*. If the `teacher_forcing_ratio`
    parameter is *0.5*, checking whether `random.random()`<`teacher_forcing_ratio`
    automatically ensures we only do teacher forcing 50% of the time. So, in *line
    number 8*, we do this check and get a Boolean output, `teacher_force`, which tells
    us whether we need to do teacher forcing in the next timestep or not. For teacher
    forcing, we store the current timestep from `y` as `dec_input` (*line number 10*).
    Otherwise, we store the current output as `dec_input` (*line number 12*), and
    this `dec_input` parameter is used as the input to the RNN in the next timestep.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们只需要做一件事——决定是否使用教师强制（teacher forcing），然后继续解码下一个时间步。我们可以通过生成一个介于*0*和*1*之间的随机数，并检查该数字是否小于`teacher_forcing_ratio`参数来实现这一点。`random.random()`从*0*到*1*的均匀分布中抽取一个数字。如果`teacher_forcing_ratio`参数是*0.5*，那么检查`random.random()`<`teacher_forcing_ratio`就能自动确保我们只有50%的时间使用教师强制。因此，在*第8行*，我们进行这个检查，并得到一个布尔值输出`teacher_force`，它告诉我们是否需要在下一个时间步使用教师强制。对于教师强制，我们将当前时间步的`y`存储为`dec_input`（*第10行*）。否则，我们将当前输出存储为`dec_input`（*第12行*），并且这个`dec_input`参数将作为下一个时间步RNN的输入。
- en: 'Now, all of this (both the fully connected decoder and the RNN decoder) has
    been put together into a single class called `Seq2SeqModel` in `src/dl/models.py`,
    and a config class (`Seq2SeqConfig`) has also been defined that has all the options
    and hyperparameters of the models. Let’s take a look at the different parameters
    in the config:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，所有这些（包括全连接解码器和RNN解码器）已经被整合到一个名为`Seq2SeqModel`的类中，该类位于`src/dl/models.py`中，并且还定义了一个配置类（`Seq2SeqConfig`），其中包含了模型的所有选项和超参数。让我们来看看配置中不同的参数：
- en: '`encoder_type`: A string parameter that takes in one of three values: `RNN`,
    `LSTM`, or `GRU`. This decides the sequence model we need to use as the encoder.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_type`：一个字符串参数，可以取以下三个值之一：`RNN`、`LSTM`或`GRU`。它决定了我们需要作为编码器使用的序列模型。'
- en: '`decoder_type`: A string parameter that takes in one of four values: `RNN`,
    `LSTM`, `GRU`, or `FC` (for *fully connected*). This decides the sequence model
    we need to use as the decoder.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_type`：一个字符串参数，可以取以下四个值之一：`RNN`、`LSTM`、`GRU`或`FC`（代表*全连接*）。它决定了我们需要作为解码器使用的序列模型。'
- en: '`encoder_params` and `decoder_params`: These parameters take a dictionary of
    key-value pairs as the input. These are the hyperparameters of the encoder and
    the decoder, respectively. For the RNN family of models, there is another config
    class, `RNNConfig`, which sets standard hyperparameters such as `hidden_size`
    and `num_layers`. And for the `FC` decoder, we need to give two parameters: `window_size`
    as the number of timesteps included in the input window, and `horizon` as the
    number of timesteps ahead we want to be forecasting.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_params` 和 `decoder_params`：这些参数接受一个包含键值对的字典作为输入。它们分别是编码器和解码器的超参数。对于
    RNN 系列的模型，还有另一个配置类 `RNNConfig`，它设置了标准的超参数，如 `hidden_size` 和 `num_layers`。对于 `FC`
    解码器，我们需要提供两个参数：`window_size`，即输入窗口中包含的时间步数，以及 `horizon`，即我们希望预测的未来时间步数。'
- en: '`decoder_use_all_hidden`: We discussed two ways we can use the fully connected
    decoder. This parameter is a flag that switches between the two. If `True`, the
    fully connected decoder will flatten the hidden states of all timesteps and use
    them for the prediction, and if `False`, it will just use the last hidden state.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_use_all_hidden`：我们讨论了两种使用全连接解码器的方法。这个参数是一个标志，用于在两者之间切换。如果设置为`True`，全连接解码器将扁平化所有时间步的隐藏状态，并将它们用于预测；如果设置为`False`，它只会使用最后一个隐藏状态。'
- en: '`teacher_forcing_ratio`: We discussed teacher forcing earlier, and this parameter
    decided the strength of teacher forcing while training. If *0*, there will be
    no teacher forcing, and if *1*, every timestep will be teacher-forced.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`teacher_forcing_ratio`：我们之前讨论过教师强制，这个参数决定了训练时教师强制的强度。如果是 *0*，则没有教师强制；如果是 *1*，每个时间步都会进行教师强制。'
- en: '`optimizer_params`, `lr_scheduler`, and `lr_scheduler_params`: These are parameters
    that let us tweak the optimization procedure. Let’s not worry about these for
    now because all of them have been set to intelligent defaults.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizer_params`，`lr_scheduler` 和 `lr_scheduler_params`：这些是让我们调整优化过程的参数。暂时不必担心这些，因为它们都已设置为智能默认值。'
- en: 'Now, with this config and the model, let’s run a few experiments. These work
    exactly the same as the set of experiments we ran in the previous section. The
    exact code for the experiments is available in the accompanying notebook. So,
    we ran the following experiments:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用这个配置和模型，让我们进行几个实验。这些实验与我们在上一节中进行的一组实验完全相同。实验的具体代码可以在附带的笔记本中找到。所以，我们进行了以下实验：
- en: '`LSTM_FC_last_hidden`: Encoder = LSTM/Decoder = Fully Connected, using just
    the last hidden state'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LSTM_FC_last_hidden`：编码器 = LSTM / 解码器 = 全连接，只使用最后一个隐藏状态'
- en: '`LSTM_FC_all_hidden`: Encoder = LSTM/Decoder = Fully Connected, using all the
    hidden states'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LSTM_FC_all_hidden`：编码器 = LSTM / 解码器 = 全连接，使用所有隐藏状态'
- en: '`LSTM_LSTM`: Encoder = LSTM/Decoder = LSTM'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LSTM_LSTM`：编码器 = LSTM / 解码器 = LSTM'
- en: 'Let’s see how they performed on the metrics we have been tracking:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它们在我们一直跟踪的指标上的表现：
- en: '![Figure 13.10 – Metrics for Seq2Seq models on MAC000193 household ](img/B22389_13_10.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.10 – MAC000193 家庭的 Seq2Seq 模型指标](img/B22389_13_10.png)'
- en: 'Figure 13.10: Metrics for Seq2Seq models on MAC000193 household'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.10：MAC000193 家庭的 Seq2Seq 模型指标
- en: The Seq2Seq models seem to be performing better on the metrics and the `LSTM_LSTM`model
    is even better than the Random Forest model.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: Seq2Seq 模型似乎在指标上表现得更好，而 `LSTM_LSTM` 模型甚至比随机森林模型更好。
- en: 'There are visualizations of each of these forecasts in the notebook. I urge
    you to look at those visualizations, zoom in, look at different places in the
    horizon, and so on. The astute observers among you must have figured out something
    weird with the forecast. Let’s look at a zoomed-in version (on one day) of the
    forecasts we generated to make that point clear:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中有这些预测的可视化。我建议你查看那些可视化，放大，查看地平线的不同地方，等等。你们中精明的观察者一定已经发现预测中有一些奇怪的地方。为了让这个点更清楚，我们来看看我们生成的预测的放大版本（一天的情况）：
- en: '![Figure 13.11 – Single-step-ahead Seq2Seq predictions for MAC000193 household
    (1 day) ](img/B22389_13_11.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.11 – MAC000193 家庭的单步预测 Seq2Seq（1天）](img/B22389_13_11.png)'
- en: 'Figure 13.11: Single-step-ahead Seq2Seq predictions for MAC000193 household
    (one day)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.11：MAC000193 家庭的单步预测 Seq2Seq（一天）
- en: What do you see now? Focus on the peaks in the time series. Are they aligned
    or do they seem at an offset? This phenomenon that you are seeing now is when
    a model learns to mimic the last seen timestep (like the naïve forecast) rather
    than learn the true pattern in the data. We will be getting good metrics and we
    might be happy with the forecast, but upon investigation, we can see that this
    is not the forecast we want. This is especially true in the case of single-step-ahead
    models where we are just optimizing to predict the next timestep. Therefore, the
    model has no real incentive to learn long-term patterns, such as seasonality and
    so on, and ends up learning a model like the naïve forecast.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你看到什么了？关注时间序列中的峰值。它们是对齐的吗？还是看起来有偏移？你现在看到的现象，是当模型学会模仿上一个时间步（如同朴素预测）而不是学习数据中的真实模式时发生的。我们可能会得到好的指标，并且可能会对预测感到满意，但经过检查后我们会发现，这并不是我们想要的预测。这在单步预测模型中特别明显，因为我们仅仅是在优化预测下一个时间步。因此，模型没有真正的动力去学习长期模式，比如季节性等，最终学到的模型就像朴素预测一样。
- en: Models that are trained to predict longer horizons overcome this problem because,
    in this scenario, the model is forced to learn the longer-term patterns in the
    model. Although multi-step forecasting is a topic that will be covered in detail
    in *Chapter 18*, *Multi-Step Forecasting*, let’s get a little bit of a sneak peek
    now. In the notebook, we also train multi-step models using the Seq2Seq models.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 训练用来预测更长时间范围的模型能够克服这个问题，因为在这种情形下，模型被迫学习更长期的模式。虽然多步预测是*第18章：多步预测*中将详细讨论的话题，我们现在先提前看一点。在笔记本中，我们还使用Seq2Seq模型训练了多步预测模型。
- en: 'The only changes we need to make are these:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的唯一改变就是：
- en: The horizon we define in the datamodule and the models should change.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`datamodule`和模型中定义的预测范围应该进行调整。
- en: The way we evaluate the models should also have a small change.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们评估模型的方式也应该有一些小的改变。
- en: 'Let’s see how we can define a `datamodule` for multi-step forecasting. We have
    chosen to forecast a complete day, which is 48 timesteps. And as an input window,
    we are giving `2 X 48` timesteps:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何为多步预测定义`datamodule`。我们选择预测完整的一天，即48个时间步。作为输入窗口，我们给出了`2 X 48`个时间步：
- en: '[PRE30]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Now that we have the `datamodule`, we can initialize the models just like before
    and train them. The only change we have to make now is while predicting.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了`datamodule`，可以像以前一样初始化模型并进行训练。现在我们需要做的唯一改变是在预测时。
- en: 'In the single-step setting, at each timestep, we were predicting the next one.
    But now, we are predicting the next 48 timesteps at each step. There are multiple
    ways to look at this and measure the metrics, which we will cover in detail in
    *Part 3*. For now, let’s choose a heuristic and say that we are considering that
    we are running this model only once a day, and each such prediction has 48 timesteps.
    But the test dataloader is still incremented by one—in other words, the test dataloader
    still gives us the next 48 timesteps, for each timestep. So, executing the following
    code, we will get a prediction array with dimensions (*timesteps*, *horizon*):'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在单步预测的设置中，每次时间步我们都在预测下一个时间步。但是现在，我们在每一步预测下一个48个时间步。我们可以从多个角度来看待这个问题并衡量相关指标，我们将在*第3部分*中详细讨论。现在，我们可以选择一种启发式方法，假设我们每天只运行一次这个模型，每次预测包含48个时间步。但测试数据加载器仍然是按每次增加一个时间步来处理——换句话说，测试数据加载器仍然给我们每个时间步的下一个48个时间步。因此，执行以下代码时，我们会得到一个维度为（*时间步*，*预测范围*）的预测数组：
- en: '[PRE31]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The predictions start at `2014, Jan 1 00:00:00`. So, if we select the 48 timesteps,
    every 48 timesteps apart, it’ll be like considering only predictions that are
    made at the beginning of the day. Using a bit of fancy indexing `numpy` provides
    us, it is easy to do just that:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 预测从`2014年1月1日 00:00:00`开始。所以，如果我们选择每48个时间步作为一个周期，那么每48个时间步间隔进行选择，就像只考虑每天开始时做出的预测。借助`numpy`提供的一些高级索引，我们很容易做到这一点：
- en: '[PRE32]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We start at index 0, which is the first prediction of 48 timesteps, and pick
    every 48 indices (which are timesteps) and just flatten the array. We will get
    an array of predictions with the desired shape, and then the standard procedure
    of inverse transformation and metric calculation, and so on, proceeds.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从索引0开始，这是48个时间步的第一次预测，然后选择每隔48个索引（即时间步），并将数组拉平成一维。我们将得到一个具有所需形状的预测数组，然后按照标准程序进行逆变换和指标计算等操作。
- en: 'The notebook has the code to do the following experiments:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这个笔记本包含了进行以下实验的代码：
- en: '`MultiStep LSTM_FC_last_hidden`: Encoder = LSTM/Decoder = Fully Connected Layer,
    using only the last hidden state'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiStep LSTM_FC_last_hidden`：编码器 = LSTM / 解码器 = 全连接层，仅使用最后一个隐藏状态'
- en: '`MultiStep LSTM_FC_all_hidden`: Encoder = LSTM/Decoder = Fully Connected Layer,
    using all the hidden states'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiStep LSTM_FC_all_hidden`：编码器 = LSTM / 解码器 = 全连接层，使用所有隐藏状态'
- en: '`MultiStep LSTM_LSTM_teacher_forcing_0.0`: Encoder = LSTM/ Decoder = LSTM,
    using no teacher forcing'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiStep LSTM_LSTM_teacher_forcing_0.0`：编码器 = LSTM / 解码器 = LSTM，不使用教师强制'
- en: '`MultiStep LSTM_LSTM_teacher_forcing_0.5`: Encoder = LSTM/ Decoder = LSTM,
    using stochastic teacher forcing (randomly, 50% of the time teacher forcing is
    enabled)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiStep LSTM_LSTM_teacher_forcing_0.5`：编码器 = LSTM / 解码器 = LSTM，使用随机教师强制（随机地，50%的时间启用教师强制）'
- en: '`MultiStep LSTM_LSTM_teacher_forcing_1.0`: Encoder = LSTM/ Decoder = LSTM,
    using complete teacher forcing'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiStep LSTM_LSTM_teacher_forcing_1.0`：编码器 = LSTM / 解码器 = LSTM，使用完整的教师强制'
- en: 'Let’s look at the metrics of these experiments:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些实验的指标：
- en: '![Figure 13.12 – Metrics for multi-step Seq2Seq models on MAC000193 household](img/B22389_13_12.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.12 – MAC000193家庭多步Seq2Seq模型的指标](img/B22389_13_12.png)'
- en: 'Figure 13.12: Metrics for multi-step Seq2Seq models on MAC000193 household'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.12：MAC000193家庭多步Seq2Seq模型的指标
- en: 'Although we cannot compare single-step-ahead accuracy to multi-step ones, for
    the time being, let’s suspend that concern and use the single-step metrics as
    in the best-case scenario. So, we can see that our model that predicts one day
    ahead (48 timesteps) is not such a bad model after all, and if we visualize the
    predictions, the problem of imitating naïve forecasts is also not present because
    now the model is forced to learn long-term models and forecasts:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们无法将单步预测准确度与多步预测准确度进行比较，但暂时先不考虑这个问题，将单步预测的指标作为最理想情况。由此可见，我们预测一天（48个时间步）的模型其实并不是那么差，如果我们将预测结果可视化，也不会出现模仿天真预测的情况，因为现在模型被迫学习长期模型和预测：
- en: '![Figure 13.13 – Multi-step-ahead Seq2Seq predictions for MAC000193 household
    (1 day) ](img/B22389_13_13.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.13 – MAC000193家庭的多步预测Seq2Seq（1天）](img/B22389_13_13.png)'
- en: 'Figure 13.13: Multi-step-ahead Seq2Seq predictions for MAC000193 household
    (one day)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.13：MAC000193家庭的多步预测Seq2Seq（一天）
- en: We can see that the model has tried to learn the daily patterns because it is
    forced to predict the next 48 timesteps. With some tuning and other training tricks,
    we might get a better model as well. But running a separate model for all `LCLid`
    (consumer ID) instances in the dataset may not be the best option, both from an
    engineering and a modeling perspective. We will tackle strategies for global modeling
    in *Chapter 15*, *Strategies for Global Deep Learning Forecasting Models.*
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到模型已经尝试学习每日模式，因为它被迫预测接下来的48个时间步。通过一些调整和其他训练技巧，我们也许能得到一个更好的模型。但从工程和建模的角度来看，为数据集中的每个`LCLid`（消费者ID）实例训练单独的模型可能不是最佳选择。我们将在*第15章*，*全球深度学习预测模型策略*中讨论全球建模的策略。
- en: '**Things to try:**'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '**尝试的方向：**'
- en: Can you train a better model? Tweak the hyperparameters and try to get better
    performance. Use GRUs or combine a GRU with an LSTM—the possibilities are endless.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 你能训练出一个更好的模型吗？调整超参数，尝试提高性能。使用GRU或将GRU与LSTM结合——可能性是无限的。
- en: 'Congratulations on getting through yet another hands-on and practical chapter.
    If this is the first time you are training NNs, I hope this lesson has made you
    confident enough to try more: trying and experimenting with these techniques is
    the best way to learn. There is no silver bullet for all datasets in ML, and therefore
    it is up to us practitioners to keep our options open and choose the right algorithm/model
    that suits our use case and works well in it. In this dataset, we can see that
    for single-step forecasting, LightGBM works really well. But the LSTM Seq2Seq
    model worked almost as well. When we extend to the multi-step forecasting scenario,
    the advantage of having a single model doing multi-step forecast with good enough
    performance may beat managing multiple ML models (more on this in *Chapter 18*).
    The techniques we learned are still considered basic in the DL world and in the
    subsequent chapters, we will dive deeper into the DL sea and learn about more
    sophisticated approaches.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您又完成了另一个动手实践的实用章节。如果这是您第一次训练神经网络，希望这一课程让您有足够的信心去尝试更多：尝试和实验这些技术是学习的最佳方式。在机器学习中，并没有适用于所有数据集的灵丹妙药，因此我们从业者需要保持开放的选择权，并选择适合我们用例并在其中表现良好的正确算法/模型。在这个数据集中，我们可以看到，对于单步预测，LightGBM效果非常好。但是LSTM
    Seq2Seq模型的效果几乎一样好。当我们扩展到多步预测的情况时，拥有一个单一模型执行多步预测并具有足够好的性能的优势可能会超过管理多个机器学习模型（关于这一点将在*第18章*详细介绍）。我们学习的技术在深度学习领域仍被认为是基础的，在接下来的章节中，我们将深入探讨深度学习的更复杂的方法。
- en: Summary
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Although we learned about the basic blocks of DL in the previous chapter, we
    put all of that into action while we used those blocks in common modeling patterns
    using PyTorch.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在上一章节学习了深度学习的基本组成部分，但我们在使用PyTorch将所有这些内容付诸实践时，将这些组件应用于常见的建模模式。
- en: We saw how standard sequence models such as RNN, LSTM, and GRU can be used for
    time series prediction, and then we moved on to another paradigm of models, called
    Seq2Seq models. Here, we talked about how we can mix and match encoders and decoders
    to get the model we want. Encoders and decoders can be arbitrarily complex. Although
    we looked at simple encoders and decoders, it is certainly possible to have something
    like a combination of a convolution block and an LSTM block working together for
    the encoder. Last but not least, we talked about teacher forcing and how it can
    help models train and converge faster and also with some performance boost.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了标准的序列模型如RNN、LSTM和GRU如何用于时间序列预测，然后我们转向了另一种模型范式，称为Seq2Seq模型。在这里，我们讨论了如何混合和匹配编码器和解码器以获得我们想要的模型。编码器和解码器可以是任意复杂的。虽然我们看了简单的编码器和解码器，但肯定可以有像卷积块和LSTM块的组合一起工作的东西作为编码器。最后但并非最不重要的，我们谈到了教师强制及其如何帮助模型更快地训练和收敛，以及一些性能提升。
- en: 'In the next chapter, we will be tackling a subject that has captured a lot
    of attention (pun intended) in the past few years: attention and transformers.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨过去几年引起广泛关注的一个主题（双关语）：注意力和Transformer。
- en: Reference
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: 'Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer (2015). *Scheduled
    Sampling for Sequence Prediction with Recurrent Neural Networks*. *Proceedings
    of the 28th International Conference on Neural Information Processing Systems—Volume
    1* (*NIPS’15*): [https://proceedings.neurips.cc/paper/2015/file/e995f98d56967d946471af29d7bf99f1-Paper.pdf](https://proceedings.neurips.cc/paper/2015/file/e995f98d56967d946471af29d7bf99f1-Paper.pdf).'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Samy Bengio，Oriol Vinyals，Navdeep Jaitly 和 Noam Shazeer（2015）。*用于序列预测的定时采样*。*第28届国际神经信息处理系统大会论文集—第1卷*（*NIPS’15*）：[https://proceedings.neurips.cc/paper/2015/file/e995f98d56967d946471af29d7bf99f1-Paper.pdf](https://proceedings.neurips.cc/paper/2015/file/e995f98d56967d946471af29d7bf99f1-Paper.pdf)。
- en: Further reading
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Check out the following sources for further reading:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下来源以进一步阅读：
- en: '*From PyTorch to PyTorch Lightning*—Alfredo Canziani and William Falcon: [https://www.youtube.com/watch?v=DbESHcCoWbM](https://www.youtube.com/watch?v=DbESHcCoWbM)'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*从PyTorch到PyTorch Lightning* — Alfredo Canziani 和 William Falcon：[https://www.youtube.com/watch?v=DbESHcCoWbM](https://www.youtube.com/watch?v=DbESHcCoWbM)'
- en: '*Deep Learning*—Ian Goodfellow, Yoshua Bengio, and Aaron Courville (pages 376-377):
    [https://www.deeplearningbook.org/contents/rnn.html](https://www.deeplearningbook.org/contents/rnn.html)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深度学习* — Ian Goodfellow，Yoshua Bengio 和 Aaron Courville（第376-377页）：[https://www.deeplearningbook.org/contents/rnn.html](https://www.deeplearningbook.org/contents/rnn.html)'
- en: '*A Short Chronology Of Deep Learning For Tabular Data* by Sebastian Raschka:
    [https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html](https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html)'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**《表格数据的深度学习简史》**由塞巴斯蒂安·拉什卡（Sebastian Raschka）编写：[https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html](https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html)'
- en: Join our community on Discord
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with authors and other readers:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者一起讨论：
- en: '[https://packt.link/mts](https://packt.link/mts)'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/mts](https://packt.link/mts)'
- en: '![](img/QR_Code15080603222089750.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code15080603222089750.png)'
