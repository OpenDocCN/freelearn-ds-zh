- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Organizing and Displaying Content with Columns, Expanders, and NLP Techniques
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用列、扩展器和NLP技术组织和显示内容
- en: In this chapter, we will develop all the business logic required for the skeleton
    app we implemented in [*Chapter 4*](B21147_04.xhtml#_idTextAnchor045). We are
    going to learn about some extremely important features of Streamlit.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将开发所有实现[*第4章*](B21147_04.xhtml#_idTextAnchor045)中所构建的骨架应用所需的业务逻辑。我们将学习Streamlit的一些极其重要的功能。
- en: Columns and expanders are two layout features in the Streamlit framework that
    allow for more flexible and organized display of content in a web application.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 列和扩展器是Streamlit框架中的两个布局功能，它们允许在Web应用程序中更灵活、有序地显示内容。
- en: Columns allow for dividing the screen horizontally into multiple sections, each
    with its own content. This is useful for displaying multiple visualizations or
    data tables side by side, or for separating different parts of the app’s interface.
    Expanders, on the other hand, allow for collapsing and expanding sections of content
    within a column. This is useful for hiding less important or less frequently used
    parts of the app’s interface, and allowing users to expand them only when needed.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 列允许将屏幕水平分为多个部分，每个部分包含自己的内容。这对于并排显示多个可视化图表或数据表，或将应用程序界面的不同部分分开非常有用。扩展器则允许在列内折叠和展开内容部分。这对于隐藏不太重要或不常用的应用界面部分非常有用，用户只有在需要时才会展开它们。
- en: In NLP, tokens are individual text units segmented by white space or punctuation.
    Lemmas, on the other hand, are the base or dictionary form of a word, which may
    differ from the inflected or derived form found in the text.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在NLP中，标记是通过空格或标点符号分割的单个文本单元。词元则是单词的基本或词典形式，它可能与文本中出现的屈折或派生形式不同。
- en: By the end of the chapter, our first web application should appear much more
    complete and you should have a wider understanding of how to build a Python web
    application using Streamlit.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们的第一个Web应用应该看起来更加完整，您也应该对如何使用Streamlit构建Python Web应用有更广泛的了解。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主要主题：
- en: Organizing and arranging content in a web app
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Web应用程序中组织和排列内容
- en: Hiding and showing parts depending on importance
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据重要性隐藏和显示内容
- en: Introducing NLP concepts – tokens and lemmas
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍NLP概念——标记和词元
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will use the following libraries, packages, and tools:'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下库、包和工具：
- en: Sublime Text
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sublime Text
- en: Python 3
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3
- en: '`pipenv`'
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pipenv`'
- en: Streamlit
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Streamlit
- en: Spacy
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spacy
- en: '`neattext`'
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`neattext`'
- en: '`matplotlib`'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib`'
- en: 'Code in the chapter can be accessed through the following GitHub link: [https://github.com/PacktPublishing/Web-App-Development-Made-Simple-with-Streamlit/tree/bd70c6ee45d046134e71c3c8a93c3d97172bf3f9/Chapter05](https://github.com/PacktPublishing/Web-App-Development-Made-Simple-with-Streamlit/tree/bd70c6ee45d046134e71c3c8a93c3d97172bf3f9/Chapter05)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的代码可以通过以下GitHub链接访问：[https://github.com/PacktPublishing/Web-App-Development-Made-Simple-with-Streamlit/tree/bd70c6ee45d046134e71c3c8a93c3d97172bf3f9/Chapter05](https://github.com/PacktPublishing/Web-App-Development-Made-Simple-with-Streamlit/tree/bd70c6ee45d046134e71c3c8a93c3d97172bf3f9/Chapter05)
- en: Organizing and arranging content in a web app
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Web应用程序中组织和排列内容
- en: 'In [*Chapter 4*](B21147_04.xhtml#_idTextAnchor045), we built the foundations
    of our first web application and wrote some Python code that, once executed, gives
    us the following result:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第4章*](B21147_04.xhtml#_idTextAnchor045)中，我们建立了第一个Web应用的基础，并编写了一些Python代码，执行后会得到以下结果：
- en: '![Figure 5.1: Chapter 5 starting point](img/B21147_05_01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1: 第5章起始点](img/B21147_05_01.jpg)'
- en: 'Figure 5.1: [*Chapter 5*](B21147_05.xhtml#_idTextAnchor053) starting point'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '图5.1: [*第5章*](B21147_05.xhtml#_idTextAnchor053)起始点'
- en: We completed the **About** section, made some decorations in terms of colors,
    and added an icon (the so-called *favicon*) and a title to the web browser page.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们完成了**关于**部分，对颜色进行了一些装饰，并为Web浏览器页面添加了一个图标（即所谓的*favicon*）和标题。
- en: 'It’s time to complete the three remaining voices of the menu: **Text Analysis**,
    **Translation**, and **Sentiment Analysis**.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候完成菜单中的三个剩余功能：**文本分析**、**翻译**和**情感分析**。
- en: Adding decorations
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加装饰
- en: Before completing the three voices of the menu, however, let’s add a nice decoration
    to the sidebar of our web app. So, once again, open the Sublime Text editor and
    restart coding.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在完成菜单中的三个功能之前，让我们先给Web应用的侧边栏添加一些装饰。因此，再次打开Sublime Text编辑器并重新开始编写代码。
- en: 'We need to add an image to the sidebar immediately after the second HTML of
    the title on *lines 35-36* of our code. This is an easy coding task, and it is
    shown in the following figure:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在代码中 *第 35-36 行* 的标题后立即向侧边栏添加一张图片。这是一个简单的编码任务，如下图所示：
- en: '![Figure 5.2: st.sidebar.image](img/B21147_05_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2: st.sidebar.image](img/B21147_05_02.jpg)'
- en: 'Figure 5.2: st.sidebar.image'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5.2: st.sidebar.image'
- en: 'The process is extremely easy: we are adding to the sidebar `(st.sidebar)`
    an image. We just wrote `NLP` in Google and downloaded an image, saving it as
    `nlp.jpg` in the same folder as our Python script. Since we are setting the `unsafe_allow_width`
    argument to `True`, the width of our image will be exactly the same as that of
    all other elements in the sidebar. If you want, instead of `unsafe_allow_width`,
    you can use the `width` one in the following way:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程非常简单：我们正在将一个图片添加到侧边栏 `(st.sidebar)` 中。我们只需要在 Google 中输入 `NLP`，下载一张图片，并将其保存为
    `nlp.jpg`，放在与 Python 脚本相同的文件夹中。由于我们将 `unsafe_allow_width` 参数设置为 `True`，所以图片的宽度将与侧边栏中所有其他元素的宽度完全相同。如果你愿意，可以使用
    `width` 参数来代替 `unsafe_allow_width`，具体方式如下：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You can try with different widths (100, 300, etc.) and observe the different
    results.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试不同的宽度（如 100、300 等）并观察不同的效果。
- en: 'In *Figure 5**.3*, we can see the result of the last decoration:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 5.3* 中，我们可以看到上次装饰的结果：
- en: '![Figure 5.3: A picture in the sidebar](img/B21147_05_03.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.3: 侧边栏中的图片](img/B21147_05_03.jpg)'
- en: 'Figure 5.3: A picture in the sidebar'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5.3: 侧边栏中的图片'
- en: Our web application is starting to look appealing! Now we can move on to the
    text analysis part.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 web 应用开始变得吸引人了！现在我们可以进入文本分析部分了。
- en: Adding the Text Analysis part
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加文本分析部分
- en: In this part, we will use `textblob`, a Python library for processing textual
    data. It provides a simple API for diving into common NLP tasks such as part-of-speech
    tagging, sentiment analysis, classification, and more. For more details, visit
    [pypi.org](http://pypi.org) (the famous Python Package Index).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将使用 `textblob`，一个处理文本数据的 Python 库。它提供了一个简单的 API，可以处理常见的自然语言处理任务，如词性标注、情感分析、分类等。欲了解更多详情，请访问
    [pypi.org](http://pypi.org)（著名的 Python 包索引）。
- en: 'As usual, we need to install the package in our virtual environment by just
    typing the following command:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们需要通过输入以下命令来在我们的虚拟环境中安装该包：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And then, we import it into our Python script, adding the following line at
    the very beginning in the `importing` `libraries` part:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将其导入到 Python 脚本中，在 `importing` `libraries` 部分的最开头添加以下行：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Anyway, if you followed [*Chapter 4*](B21147_04.xhtml#_idTextAnchor045) carefully,
    you have already done this, but it’s better to repeat it just in case.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，如果你仔细阅读了 [*第 4 章*](B21147_04.xhtml#_idTextAnchor045)，你应该已经完成了这部分，但为了保险起见，还是最好再重复一遍。
- en: Let’s jump to the *Text Analysis* part of our script and finally add its specific
    business logic. *Text Analysis*, as we will see during the coding, is a function
    focused on text stats (length, number of words, etc.), wordstopping, lemmas and
    tokens, and so on. We will quickly explain these concepts one by one in the next
    pages. Besides NLP concepts, what is very important here is to understand how
    to use the various Streamlit widgets, functions, and technicalities in order to
    create and build up solid and well-performing web applications.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们跳转到脚本中的 *文本分析* 部分，最终添加其特定的业务逻辑。正如我们在编码过程中看到的那样，*文本分析* 是一个专注于文本统计（如长度、单词数等）、停用词、词干和标记等功能的函数。我们将在接下来的页面中快速解释这些概念。此外，除了自然语言处理（NLP）概念之外，这里非常重要的是理解如何使用各种
    Streamlit 小部件、函数和技术细节，以便创建和构建稳健、高效的 Web 应用。
- en: Adding a text area
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加文本框
- en: 'Currently, in this part, we just have a header and a subheader. In order to
    perform text analysis, for sure we need some text, so as the very first operation,
    let’s add a text area where we can input all the text we want:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，在这一部分，我们只有一个标题和一个子标题。为了进行文本分析，我们当然需要一些文本，因此作为第一步，让我们添加一个文本框，以便输入所有我们想要的文本：
- en: '![Figure 5.4: st.text_area](img/B21147_05_04.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.4: st.text_area](img/B21147_05_04.jpg)'
- en: 'Figure 5.4: st.text_area'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5.4: st.text_area'
- en: We are using `text_area` to get some text and put it in a variable named `raw_text`.
    Try to play with `st.text_area` arguments a little, and especially try to discover
    what happens if you don’t use *height*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `text_area` 获取一些文本，并将其存储在名为 `raw_text` 的变量中。尝试稍微调整 `st.text_area` 的参数，特别是试试看如果不使用
    *height* 会发生什么。
- en: Adding the Analyze button
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加分析按钮
- en: 'We want to do something with the text typed in this `text_area` so, just to
    understand better how it works, let’s add a button named **Analyze** that, when
    pushed, writes our text on the screen. The code is quite simple, as shown in the
    following figure:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想对在 `text_area` 中输入的文本做点什么。所以，为了更好地理解它是如何工作的，我们来添加一个名为 **Analyze** 的按钮，当点击该按钮时，会将我们的文本显示在屏幕上。代码非常简单，如下图所示：
- en: '![Figure 5.5: A button to show our text](img/B21147_05_05.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.5：用于显示文本的按钮](img/B21147_05_05.jpg)'
- en: 'Figure 5.5: A button to show our text'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5：用于显示文本的按钮
- en: 'To keep it very neat and clean, we write something in the text area – for example,
    `Hello everybody!` – click on the button, and see what we wrote on the screen.
    This is the result:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持界面的整洁，我们在文本区域输入一些内容——例如 `Hello everybody!`——然后点击按钮，看看我们写的内容显示在屏幕上。结果如下：
- en: '![Figure 5.6: Hello everybody!](img/B21147_05_06.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.6：大家好！](img/B21147_05_06.jpg)'
- en: 'Figure 5.6: Hello everybody!'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6：大家好！
- en: To perform any NLP task, TextBlob needs to convert any text into a `Blob` object,
    something specific to this nice package. Let us see how.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行任何自然语言处理任务，TextBlob 需要将任何文本转换为一个 `Blob` 对象，这是这个优秀库的一个特定功能。让我们来看看如何操作。
- en: Creating the Blob object
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 Blob 对象
- en: To perform all our NLP tasks with TextBlob, we have to be sure that this Blob
    can be created, and it can be created only if the text area contains some text
    – in other words, if the text area is not empty.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 TextBlob 执行所有自然语言处理任务，我们必须确保能够创建这个 Blob 对象，而 Blob 只有在文本区域包含一些文本时才能创建——换句话说，文本区域不能是空的。
- en: 'Let’s modify the preceding code a bit, just to be sure that the text area is
    not empty and that the `Blob` object will be created without issues:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微修改一下前面的代码，确保文本区域不是空的，并且 `Blob` 对象可以顺利创建：
- en: '![Figure 5.7: TextBlob in action](img/B21147_05_07.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.7：TextBlob 在实际应用中](img/B21147_05_07.jpg)'
- en: 'Figure 5.7: TextBlob in action'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7：TextBlob 在实际应用中
- en: So, *if* there is no text in the `text_area`, its length (`len`) is equal to
    zero and we display a warning message; otherwise (`else`) we create a `TextBlob`
    object, save it as a variable named `blob`, and display a confirmation message
    (`OK`).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，*如果* `text_area` 中没有文本，它的长度（`len`）就为零，我们会显示一个警告信息；否则（`else`），我们会创建一个 `TextBlob`
    对象，将其保存为名为 `blob` 的变量，并显示一个确认信息（`OK`）。
- en: And now, we have our `TextBlob` object working.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的 `TextBlob` 对象已经开始工作了。
- en: Adding basic functions
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加基本功能
- en: 'Up to now, we have edited all code properly and we are ready to implement some
    real text analysis functions. In fact, we will be using `TextBlob` later on for
    the sentiment analysis function. Now, we just use it to check that the application
    runs correctly, so if you want, you can comment on the following line of code,
    like this:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经正确编辑了所有代码，准备实现一些真正的文本分析功能。实际上，我们稍后会使用 `TextBlob` 来进行情感分析功能。现在，我们只是用它来检查应用程序是否正常运行，如果你愿意，可以像这样注释掉下面这一行代码：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let’s get started with `st.write("OK")` line with the following:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 `st.write("OK")` 这一行开始，代码如下：
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'So far, we are at the stage shown in the following screenshot:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们处于如下截图所示的阶段：
- en: '![Figure 5.8: Basic functions](img/B21147_05_08.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.8：基本功能](img/B21147_05_08.jpg)'
- en: 'Figure 5.8: Basic functions'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8：基本功能
- en: It’s time to understand how to show and hide information on the screen using
    columns, expanders, and more advanced coding.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候理解如何使用列、展开器和更高级的编码来在屏幕上显示和隐藏信息了。
- en: Hiding and showing parts depending on importance
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 根据重要性隐藏和显示部分内容
- en: From a very broad point of view, an application is just a way to visualize,
    transform, and save information. Not always showing all the available information
    at the same time is a winning idea. For example, having all the information on
    a unique screen could make our app very crowded. In other cases, we are not interested
    in visualizing all the information simultaneously because we want to see only
    a specific piece of information that is of our interest. So, hiding and properly
    showing information in our web application is a very valuable skill to acquire.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 从一个非常广泛的角度来看，应用程序只是用来可视化、转换和保存信息的一种方式。并非总是同时显示所有可用信息是一个明智的做法。例如，将所有信息显示在一个屏幕上可能会让我们的应用程序显得非常拥挤。在其他情况下，我们并不希望同时展示所有信息，因为我们只想看到某个特定的信息，这些信息是我们关心的。因此，在我们的
    web 应用中隐藏和正确显示信息是一项非常有价值的技能。
- en: Adding columns, expanders, and a textbox
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加列、展开器和文本框
- en: Columns are very useful because they allow us to create some *layers* or *different
    parts*. This means that by using columns, we can divide the screen into as many
    vertical sections as we want and use these sections (or columns) for any kind
    of specific purpose we think should be in a specific – or let’s say dedicated
    – container. All we need to do is create or declare these widgets.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 列非常有用，因为它们允许我们创建一些*层*或*不同的部分*。这意味着，通过使用列，我们可以将屏幕分成任意多的垂直部分，并将这些部分（或列）用于我们认为应该在特定——或者说专用——容器中展示的任何特定目的。我们需要做的就是创建或声明这些小部件。
- en: 'We start using them by adopting the `with` instruction. Let’s see it in detail:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用`with`指令开始使用它们。让我们详细看看：
- en: '![Figure 5.9: Columns and expanders](img/B21147_05_09.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.9：列和扩展器](img/B21147_05_09.jpg)'
- en: 'Figure 5.9: Columns and expanders'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9：列和扩展器
- en: 'The `col1, col2 = st.columns(2)` line just creates two columns named `col1`
    and `col2`. In the two `with` lines, we use these columns. In each of the columns,
    we create an *expander*; any expander has its own label (`Basic Info` and `Processed
    Text`). Expanders are clickable since they have an *up arrow* and *down arrow*
    symbol. Clicking on these symbols, we *expand* or *collapse* these widgets to
    reveal their content – in our example, just `st.write` and `st.success` instructions.
    The effect in the browser is very beautiful:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`col1, col2 = st.columns(2)`这一行仅仅创建了两个名为`col1`和`col2`的列。在接下来的两行`with`中，我们使用这些列。在每一列中，我们创建一个*扩展器*；每个扩展器都有自己的标签（`Basic
    Info`和`Processed Text`）。扩展器是可点击的，因为它们有*上箭头*和*下箭头*符号。点击这些符号，我们可以*展开*或*收起*这些小部件以显示它们的内容——在我们的示例中，仅包含`st.write`和`st.success`指令。浏览器中的效果非常漂亮：'
- en: '![Figure 5.10: Columns and expanders in our web application](img/B21147_05_10.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.10：我们网页应用中的列和扩展器](img/B21147_05_10.jpg)'
- en: 'Figure 5.10: Columns and expanders in our web application'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10：我们网页应用中的列和扩展器
- en: 'Since we want to also include a couple of *Advanced Features* in our web app,
    let’s copy the latest part of the code in order to create another couple of columns
    and expanders, plus an `info` text box:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们还希望在我们的网页应用中包含一些*高级功能*，让我们复制最新的代码部分，以便创建另外一对列和扩展器，再加上一个`info`文本框：
- en: '![Figure 5.11: New columns and expanders](img/B21147_05_11.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.11：新的列和扩展器](img/B21147_05_11.jpg)'
- en: 'Figure 5.11: New columns and expanders'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11：新的列和扩展器
- en: 'The code we added is the same as we already commented previously. Its impact
    on the web application is the following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加的代码与之前已经评论过的相同。它对网页应用的影响如下：
- en: '![Figure 5.12: Our application layout is going to be completed](img/B21147_05_12.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.12：我们的应用布局即将完成](img/B21147_05_12.jpg)'
- en: 'Figure 5.12: Our application layout is going to be completed'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12：我们的应用布局即将完成
- en: 'To summarize, up to now we have two layers, two expanders, and two columns
    for every layer; the effect is very clean and well-balanced. Now we can take care
    of the four functions: two basic and two advanced.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，到目前为止我们已经有了两层、两个扩展器和每层两个列；效果非常干净且平衡。现在我们可以处理四个功能：两个基本功能和两个高级功能。
- en: Adding the two basic functions
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加两个基本功能
- en: 'Let’s start with the first basic function: `neattext` package, which is very
    useful for our statistics as it has a function named `word_stats`. If you haven’t
    already imported it, it’s time to do so.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一个基本功能开始：`neattext`包，它对我们的统计非常有用，因为它有一个名为`word_stats`的函数。如果你还没有导入它，是时候这么做了。
- en: '`word_stats` returns a dictionary, so a `key:value` data structure; all we
    need to do is to get the information from it (putting in the `word_desc` variable),
    then write everything on the screen in the proper column. The following screenshot
    shows the code that obviously is part of `col1`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`word_stats`返回一个字典，所以是一个`key:value`数据结构；我们需要做的就是从中获取信息（将其放入`word_desc`变量中），然后将所有内容在适当的列中显示。以下截图显示的代码显然属于`col1`：'
- en: '![Figure 5.13: Text Stats](img/B21147_05_13.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.13：文本统计信息](img/B21147_05_13.jpg)'
- en: 'Figure 5.13: Text Stats'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13：文本统计信息
- en: 'We can access the stats using a simple key:value combination. However, the
    logic of the required code is outside the scope of this book, which focuses on
    Streamlit. The important thing to understand is that any specific function must
    be coded in the correct column section. This is what we see in our web application:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过一个简单的`key:value`组合来访问统计信息。然而，所需代码的逻辑超出了本书的范围，本书专注于Streamlit。需要理解的关键点是，任何特定的功能必须在正确的列部分中进行编码。这就是我们在网页应用中看到的：
- en: '![Figure 5.14: Text Stats function effect on the screen](img/B21147_05_14.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.14：文本统计功能在屏幕上的效果](img/B21147_05_14.jpg)'
- en: 'Figure 5.14: Text Stats function effect on the screen'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.14：文本统计功能在屏幕上的效果
- en: 'Now, let’s add the second basic function: `nexttext` library is also very useful
    for **Processed Text** and this task is quite easy. We can jump to the **Processed
    Text** part of the code and add a very simple instruction, as illustrated in the
    following figure:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加第二个基本功能：`nexttext`库对**处理过的文本**也非常有用，且这个任务相当简单。我们可以跳到代码的**处理过的文本**部分，并添加一个非常简单的指令，如下图所示：
- en: '![Figure 5.15: The Processed Text expander](img/B21147_05_15.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.15：处理过的文本扩展器](img/B21147_05_15.jpg)'
- en: 'Figure 5.15: The Processed Text expander'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.15：处理过的文本扩展器
- en: 'We can use `neattext`’s `remove_stopwords()` to get the text we input without
    the stopwords, then cast it to a string (`str`), and save it in a variable named
    `processed_text`; finally, we write the processed text on the screen. This is
    the result:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`neattext`的`remove_stopwords()`方法去除输入文本中的停用词，然后将其转换为字符串（`str`），并保存在名为`processed_text`的变量中；最后，我们将处理过的文本显示在屏幕上。结果如下：
- en: '![Figure 5.16: The Processed Text function effect on the screen](img/B21147_05_16.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.16：处理过的文本功能在屏幕上的效果](img/B21147_05_16.jpg)'
- en: 'Figure 5.16: The Processed Text function effect on the screen'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.16：处理过的文本功能在屏幕上的效果
- en: The result is nice, but we can do even better – for example, writing on the
    screen the list of the stopwords we removed from the text. Please note that stopwords
    are, let’s say, *common words* that don’t add any information to our original
    text.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 结果很好，但我们还可以做得更好——例如，在屏幕上显示我们从文本中移除的停用词列表。请注意，停用词是指那些*常见的单词*，它们并没有为我们的原始文本添加任何信息。
- en: 'We can add this list into the first column, adding to it a second expander
    exactly below the first one; this is the code:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个列表添加到第一列，再添加一个扩展器，正好位于第一个扩展器下方；以下是代码：
- en: '![Figure 5.17: The code to extract the stopwords](img/B21147_05_17.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.17：提取停用词的代码](img/B21147_05_17.jpg)'
- en: 'Figure 5.17: The code to extract the stopwords'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.17：提取停用词的代码
- en: 'So, we add a second expander `(st.expander()"Stopwords")` and, once again using
    `neattext`, we extract `stopwords (extract_stopwords)` and put them into a variable
    `(stop_w)`, then print this variable on the screen, this time using `st.error`.
    Here is the result:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们添加了第二个扩展器`(st.expander()"Stopwords")`，并再次使用`neattext`提取`stopwords (extract_stopwords)`并将其放入一个变量`(stop_w)`中，然后使用`st.error`在屏幕上打印这个变量。结果如下：
- en: "![Figure 5.18: \uFEFFStopwords visualization](img/B21147_05_18.jpg)"
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.18：停用词可视化](img/B21147_05_18.jpg)'
- en: 'Figure 5.18: Stopwords visualization'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.18：停用词可视化
- en: 'Everything is working fine: **Text Stats** tells us how many stopwords we have,
    **Stop Words List** shows us those stopwords in a list, and **Processed Text**
    shows the text without these items.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一切正常：**文本统计**告诉我们有多少停用词，**停用词列表**以列表形式显示这些停用词，而**处理后的文本**则显示去除这些项后的文本。
- en: Adding a wordcloud
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加词云
- en: 'Since the `Wordcloud` library, as suggested in [*Chapter 4*](B21147_04.xhtml#_idTextAnchor045).
    This time, we can add another expander into the second column and write a few
    lines of code, as illustrated in the following figure:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`Wordcloud`库，如[*第 4 章*](B21147_04.xhtml#_idTextAnchor045)中所建议的那样。这一次，我们可以在第二列中再添加一个扩展器，并编写几行代码，如下图所示：
- en: '![Figure 5.19: Wordcloud plotting code](img/B21147_05_19.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.19：词云绘制代码](img/B21147_05_19.jpg)'
- en: 'Figure 5.19: Wordcloud plotting code'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.19：词云绘制代码
- en: 'A few lines of code and a wordcloud will appear! So, we add another expander,
    then create a wordcloud from the original text using the `generate` method, and
    then define a figure with its size. Finally, use `plt` (we already imported `pyplot`)
    to plot the wordcloud without `axis`. We used a longer original text for a richer
    wordcloud. The bigger the words appear, the more often they occur in the text.
    This is the result:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 几行代码后，词云就会出现！所以，我们添加了另一个扩展器，然后使用`generate`方法从原始文本中创建词云，再定义一个图形及其大小。最后，使用`plt`（我们已导入`pyplot`）绘制不带`轴`的词云。我们使用了更长的原始文本，以便生成更丰富的词云。词云中出现的单词越大，说明它们在文本中出现得越频繁。结果如下：
- en: '![Figure 5.20: Wordcloud on the screen](img/B21147_05_20.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.20：屏幕上的词云](img/B21147_05_20.jpg)'
- en: 'Figure 5.20: Wordcloud on the screen'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.20：屏幕上的词云
- en: Now our **Basic Functions** part really is finished. We have a beautiful text
    that shows the beginning of the section and two columns, and in each of them,
    two expanders, with everything working well and fluidly. It’s time to address
    the advanced features, such as handling tokens, lemmas, and summarization. We
    will discuss these in detail further in this chapter.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的**基础功能**部分真的完成了。我们有一段美观的文本，展示了章节的开始，以及两列内容，每列中有两个展开器，所有功能都运行良好且流畅。现在是时候处理一些高级功能了，如处理令牌、词元和摘要功能。我们将在本章稍后详细讨论这些内容。
- en: Introducing NLP concepts – tokens and lemmas
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入 NLP 概念——令牌和词元
- en: Let’s begin exploring **Advanced Features** by creating a simple summarization
    function in Python and Streamlit. Although many packages and libraries offer powerful
    summarization capabilities, this book focuses on web application development rather
    than NLP or summarization.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过在 Python 和 Streamlit 中创建一个简单的摘要函数来开始探索**高级功能**。尽管许多包和库提供强大的摘要功能，本书更侧重于
    web 应用开发，而非 NLP 或摘要技术。
- en: Adding the summarization function
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加摘要函数
- en: 'Though the name is self-explanatory, a `summarization` function is a piece
    of code that summarizes a sentence or a text, extracting only the most important
    part of it. This task can be achieved in many ways – some very easy, like the
    one we are proposing just to show how to develop complex web applications with
    Streamlit, and some very sophisticated, leveraging artificial intelligence and
    neural networks. *Figure 5**.21* shows the code where we add the `summarize_text`
    function:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然名字很直观，`summarization` 函数是一个用来总结句子或文本的代码段，它只提取最重要的部分。这项任务可以通过许多方法实现——一些非常简单，比如我们提出的这个函数，旨在展示如何使用
    Streamlit 开发复杂的 web 应用，而一些方法则非常复杂，利用人工智能和神经网络。*图 5.21* 展示了我们如何添加 `summarize_text`
    函数的代码：
- en: '![Figure 5.21: The summarize_text function](img/B21147_05_21.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.21：summarize_text 函数](img/B21147_05_21.jpg)'
- en: 'Figure 5.21: The summarize_text function'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.21：summarize_text 函数
- en: 'An attention point is that after the NLP packages, we imported two new libraries:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一个注意点是，在引入 NLP 包后，我们导入了两个新库：
- en: '[PRE5]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Both of them are Python standard packages; the first one is a set of collections
    that includes a counter and the second is the regular expressions package.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 它们都是 Python 标准库；第一个是包含计数器的集合，第二个是正则表达式包。
- en: 'After this import activity, we defined the `summarize_text` function by writing
    the following code:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这个导入操作后，我们通过编写以下代码来定义 `summarize_text` 函数：
- en: '[PRE6]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This function is very simple: it takes text as input, cleans the text by lowercasing
    it, splits everything into words, calculates the frequency of each word (that’s
    why we need the counter), sorts the words according to their frequency, extracts
    the most frequent, and then creates a summary just by joining the top words.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数非常简单：它接受文本作为输入，通过将其转换为小写来清洗文本，接着将文本分割为单词，计算每个单词的频率（这就是我们需要计数器的原因），根据频率对单词进行排序，提取最频繁的单词，然后通过将这些高频词汇连接起来生成总结。
- en: 'This function can be used inside the expander of the summarization as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数可以在摘要的展开器中使用，示例如下：
- en: '![Figure 5.22: The Summarize expander](img/B21147_05_22.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.22：Summarize 展开器](img/B21147_05_22.jpg)'
- en: 'Figure 5.22: The Summarize expander'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.22：Summarize 展开器
- en: 'In the expander of `col4`, we are just using the `summarize_text` function
    with the input text (`raw_text`) and showing the result on the screen, as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `col4` 的展开器中，我们只是使用 `summarize_text` 函数，传入文本 (`raw_text`)，并将结果显示在屏幕上，如下所示：
- en: '![Figure 5.23: Summarize in action](img/B21147_05_23.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.23：总结操作](img/B21147_05_23.jpg)'
- en: 'Figure 5.23: Summarize in action'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.23：总结操作
- en: OK, this feature is not the best, but why don’t you try to improve it by yourself?
    For example, you could add some advanced summarization features offered online
    by many companies via API calls.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这个功能并不是最完美的，但为什么不尝试自己改进它呢？例如，你可以通过 API 调用，添加许多公司在线提供的高级摘要功能。
- en: Next, let us learn what tokens and lemmas are.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们了解什么是令牌和词元。
- en: Tokens and lemmas
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 令牌和词元
- en: '**Tokens** and **lemmas** are quite classical concepts of NLP. Tokens are the
    smallest *units* of a text and are usually identified with words. So, if we say
    *I write code*, we have three tokens: *I*, *write*, and *code*. Depending on the
    granularity level, things can get more complex because sometimes tokens can be
    identified with single letters. We don’t consider the letters, just the words.
    Please note that even with words, tokenization can be challenging; for example,
    in the sentence *I’m writing code*, we have many tokens – three or four. In the
    first case, *I’m* is a unique token, while in the second case, we can consider
    *I’m* as two words, with two different tokens.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**Tokens** 和 **lemmas** 是 NLP 中非常经典的概念。Tokens 是文本中最小的 *单位*，通常用单词来表示。所以，如果我们说
    *I write code*，我们有三个 tokens：*I*、*write* 和 *code*。根据粒度的不同，事情可能变得更复杂，因为有时 tokens
    可以由单个字母表示。但我们并不考虑字母，只关注单词。请注意，即使是单词，tokenization 也可能充满挑战；例如，在句子 *I’m writing code*
    中，我们有多个 tokens —— 三个或四个。在第一种情况下，*I’m* 是一个独特的 token，而在第二种情况下，我们可以将 *I’m* 视为两个单词，拥有两个不同的
    tokens。'
- en: There is no right or wrong approach but everything depends on the language and
    the use case to be considered. Lemmas are made of so-called *plain text*, so if
    we say *code*, *coding*, or *coder*, we can assume that for all these three words,
    the lemma is just *code*.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 其实并没有标准的对错方法，所有的东西都取决于语言和要考虑的使用场景。Lemmas 是由所谓的 *纯文本* 组成的，所以如果我们说 *code*、*coding*
    或 *coder*，我们可以假设这三个词的词根都是 *code*。
- en: For *Tokens&Lemmas*, we can use `spacy`, a very powerful NLP package we imported
    in [*Chapter 4*](B21147_04.xhtml#_idTextAnchor045). Maybe you remember that, in
    [*Chapter 4*](B21147_04.xhtml#_idTextAnchor045), we also downloaded the English
    model used by spaCy (`en_core_web_sm`). Now we are using both the library and
    the model.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 *Tokens&Lemmas*，我们可以使用 `spacy`，这是一个非常强大的 NLP 库，之前在 [*第 4 章*](B21147_04.xhtml#_idTextAnchor045)
    中我们已经导入了它。也许你还记得，在 [*第 4 章*](B21147_04.xhtml#_idTextAnchor045) 中，我们还下载了 spaCy
    使用的英文模型（`en_core_web_sm`）。现在，我们正在同时使用这个库和模型。
- en: 'As we did for summarization, let’s write a function that takes care of tokens
    and lemmas. We can write, immediately after the summarization function, something
    like this:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们做总结时一样，让我们编写一个函数来处理 tokens 和 lemmas。我们可以在总结函数后立即写下类似的代码：
- en: '![Figure 5.24: Lemmas and tokens function](img/B21147_05_24.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.24：Lemmas 和 tokens 功能](img/B21147_05_24.jpg)'
- en: 'Figure 5.24: Lemmas and tokens function'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.24：Lemmas 和 tokens 功能
- en: First of all, we load in spaCy the English model, then create an `nlp` object
    (an object specific to the `spacy` library) from a text (`doc=nlp(text)`), and
    thanks to this object, we can extract tokens and lemmas (`token.text and token.lemma_`),
    saving them into a dictionary (a key:value data structure) named `allData`. At
    the very end, we return this `allData` variable.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们加载 spaCy 的英文模型，然后从文本中创建一个 `nlp` 对象（这是 `spacy` 库特有的对象）（`doc=nlp(text)`），通过这个对象，我们可以提取
    tokens 和 lemmas（`token.text` 和 `token.lemma_`），并将它们保存到一个字典中（键值对结构），命名为 `allData`。最后，我们返回这个
    `allData` 变量。
- en: Please note the strange `@st.cache_data` at the beginning of our function. It’s
    a *decorator* that tells Streamlit to save in a cache the data managed by this
    function, so unless the function’s input doesn’t change, any time we select the
    function, the response will be very fast.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意我们函数开头的奇怪 `@st.cache_data`。这是一个 *装饰器*，它告诉 Streamlit 将此函数管理的数据保存到缓存中，因此除非函数的输入发生变化，否则每次我们调用这个函数时，响应都会非常快速。
- en: 'Please check Streamlit’s official documentation about caching ([https://docs.streamlit.io/library/advanced-features/caching](https://docs.streamlit.io/library/advanced-features/caching))
    because it’s really something that can help a lot with response time:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看 Streamlit 的官方文档关于缓存的内容（[https://docs.streamlit.io/library/advanced-features/caching](https://docs.streamlit.io/library/advanced-features/caching)），因为这确实是一个可以大大提升响应速度的功能：
- en: '![Figure 5.25: Streamlit’s official documentation on caching](img/B21147_05_25.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.25：Streamlit 官方文档关于缓存的内容](img/B21147_05_25.jpg)'
- en: 'Figure 5.25: Streamlit’s official documentation on caching'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.25：Streamlit 官方文档关于缓存的内容
- en: Our *Tokens&Lemmas* function is ready so we can use it inside our final expander.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 *Tokens&Lemmas* 函数已经准备好，可以在我们的最终扩展器中使用。
- en: Using the text_analysis function
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 text_analysis 函数
- en: 'Before using the *Tokens&Lemmas* function, we will clean the text a little
    bit; let’s see how to do it:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 *Tokens&Lemmas* 功能之前，我们先稍微清理一下文本；让我们看看如何操作：
- en: '![Figure 5.26: Tokens&Lemmas expander](img/B21147_05_26.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.26：*Tokens&Lemmas* 扩展器](img/B21147_05_26.jpg)'
- en: 'Figure 5.26: Tokens&Lemmas expander'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.26：*Tokens&Lemmas* 扩展器
- en: Before using the `text_analysis` function we just discussed, we will clean the
    text with `neattext`. First of all, we will remove stopwords from it, then we
    will remove the punctuation, and finally, we will remove special characters such
    as `"@"`, `"#"`, and so on.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用我们刚才讨论的`text_analysis`函数之前，我们将使用`neattext`来清理文本。首先，我们将删除停用词，然后删除标点符号，最后删除特殊字符，如`"@"`、`"#"`等。
- en: We will pass this cleaned text to `text_analyzer` and then print the result
    on the screen.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把清理后的文本传递给`text_analyzer`，然后将结果打印到屏幕上。
- en: 'Please note that, since the `text_analyzer` function returns a dictionary –
    or better, a list of dictionaries – we are printing it in the JSON format (`st.json(tandl)`);
    this is the result:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于`text_analyzer`函数返回的是一个字典——更确切地说，是一个字典的列表——我们以 JSON 格式打印它（`st.json(tandl)`）；这是结果：
- en: '![Figure 5.27: Tokens&Lemmas on the screen](img/B21147_05_27.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.27：屏幕上的 Tokens&Lemmas](img/B21147_05_27.jpg)'
- en: 'Figure 5.27: Tokens&Lemmas on the screen'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.27：屏幕上的 Tokens&Lemmas
- en: To make it very clear, tokens are the words of our text after we clean it, while
    lemmas are something called *the normal shape* of the words; for example, we can
    see that the word *spending* has *spend* as a lemma, the token *traveling* has
    *travel* as a lemma, and so on.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更清楚地说明，tokens 是我们清理文本后的单词，而 lemmas 是被称为*标准形态*的单词；例如，我们可以看到单词*spending*的 lemma
    是*spend*，token*traveling*的 lemma 是*travel*，依此类推。
- en: 'Finally, to test that everything works properly, we can copy some text from
    the web – for example, an extract from some article from the CNN website – and
    put it in our web application. This is the result in the case of an article about
    traveling and journeys:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了测试一切是否正常工作，我们可以从网络上复制一些文本——例如，来自 CNN 网站的某篇文章摘录——并将其放入我们的网络应用程序中。这是关于旅行和旅程的文章的结果：
- en: '![Figure 5.28: Text Analysis test](img/B21147_05_28.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.28：文本分析测试](img/B21147_05_28.jpg)'
- en: 'Figure 5.28: Text Analysis test'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.28：文本分析测试
- en: The result is quite impressive; please consider that by using only Python, Streamlit,
    and some libraries, we’ve already got a very good-looking, working web application
    that can be used directly online. All we need is a browser!
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 结果相当令人印象深刻；请注意，使用仅仅是 Python、Streamlit 和一些库，我们已经制作出了一个非常漂亮且可用的 web 应用程序，可以直接在线使用。我们所需要的只是一个浏览器！
- en: 'If possible, try to use the application from a device – for example, a tablet
    or smartphone – that is on the same (Wi-Fi) network as the computer from which
    you are coding. This is the great point of these web applications: immediately
    accessible from everywhere! We write code once and can use it from everywhere,
    with no need to install locally, manage patches, manage new versions, and so on.
    Everything stays in one place and it’s accessed by a web browser. In case of changes
    or new versions, we only need to update the code *server*-side, meaning no pain
    for users. Smooth, clean, and easy!'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，尽量从设备上使用应用程序——例如，平板电脑或智能手机——并且确保它们和你编码的计算机在同一个（Wi-Fi）网络上。这就是这些 web 应用程序的优点：可以随时随地访问！我们一次编写代码，随时随地使用，无需本地安装、管理补丁、更新版本等等。一切都在一个地方，用户通过浏览器访问。如果有变更或新版本，我们只需更新服务器端的代码，这样用户就不用为此操心了。顺畅、简洁、易用！
- en: 'As usual, here are the screenshots of the code produced up to now:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，下面是到目前为止所写代码的截图：
- en: '![Figure 5.29: Code – part 1](img/B21147_05_29.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.29：代码 – 第1部分](img/B21147_05_29.jpg)'
- en: 'Figure 5.29: Code – part 1'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.29：代码 – 第1部分
- en: In part 1, we imported the packages, set the page configuration, and defined
    the `"summarize_text"` and `"``text_analyzer"` functions.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1部分中，我们导入了相关包，设置了页面配置，并定义了`"summarize_text"`和`"text_analyzer"`函数。
- en: '![Figure 5.30: Code – part 2](img/B21147_05_30.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.30：代码 – 第2部分](img/B21147_05_30.jpg)'
- en: 'Figure 5.30: Code – part 2'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.30：代码 – 第2部分
- en: In part 2, we wrote the `"main"` function that visualizes the main title of
    the application, the menu in the sidebar that uses an `IF` clause to make the
    menu’s voices selection possible, and used some interesting widgets such as columns
    and expanders.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在第2部分中，我们编写了`"main"`函数，用来可视化应用程序的主标题，侧边栏中的菜单使用`IF`语句使得菜单选项能够被选择，并使用了一些有趣的小部件，例如列和展开器。
- en: '![Figure 5.31: Code – part 3](img/B21147_05_31.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.31：代码 – 第3部分](img/B21147_05_31.jpg)'
- en: 'Figure 5.31: Code – part 3'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.31：代码 – 第3部分
- en: In part 3, we completed the `"main"` function, then created placeholders for
    the **Translation** and **Sentiment Analysis** features, and finally, created
    a beautiful **About** section, leveraging simple markdown.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3部分，我们完成了`"main"`函数，然后为**翻译**和**情感分析**功能创建了占位符，最后利用简单的 Markdown 创建了一个美丽的**关于**部分。
- en: Let’s underline once again how powerful Streamlit can be, since with a few lines
    of code, we are able to create a complete web application made of both back and
    frontend parts.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次强调 Streamlit 的强大，因为只需要几行代码，我们就能创建一个完整的包含后端和前端部分的网页应用。
- en: Summary
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we started completing the decorations by adding a beautiful
    picture in the sidebar. The application should always work correctly but giving
    it a quite beautiful *shape* is always a good idea.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们开始通过在侧边栏添加一张美丽的图片来完成装饰。应用程序应始终正常工作，但赋予它一个相当美观的*外观*总是一个不错的主意。
- en: 'After decoration, we focused on the first voice of the menu: **Text Analysis**.
    **Text Analysis** is a quite complex section and in order to make it clear, good-looking,
    and well-performing, we decided to arrange our web application into different
    sections that cover different topics. The best solution to make this possible
    is to learn how to use columns and expanders. The **Text Analysis** section we
    created has two layers, one for **Basic Functions** and another for **Advanced
    Features**, and by using columns and expanders, we can manage both layers in a
    very effective and elegant way.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 装饰完成后，我们集中关注菜单的第一个选项：**文本分析**。**文本分析**是一个相当复杂的部分，为了使其既清晰、美观又高效，我们决定将我们的网页应用分为不同的部分，每个部分覆盖不同的主题。实现这一目标的最佳方法是学习如何使用列和扩展器。我们创建的**文本分析**部分有两层，一层是**基础功能**，另一层是**高级功能**，通过使用列和扩展器，我们可以以非常有效和优雅的方式管理这两层。
- en: Columns allow us to place everything we want into pillars, while expanders allow
    us to *expand* or *collapse* anything we want to show or hide.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 列允许我们将任何内容放置到不同的列中，而扩展器则允许我们*展开*或*收起*任何想要展示或隐藏的内容。
- en: Having good-looking sections and well-arranged topics in our application is
    very important, but an extremely important point is having very well-performing
    code.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有外观美观且布局合理的部分和主题对我们的应用程序非常重要，但一个极为重要的点是拥有性能优良的代码。
- en: Code should run in a fast and smooth way, without taking a long time to load
    and show information on the screen. This is the reason why we also had a first
    look at caching in Streamlit.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 代码应该以快速、流畅的方式运行，加载并展示信息的时间不应过长。这也是我们在 Streamlit 中首次考虑缓存的原因。
- en: 'In the next chapter, we are going to complete the two remaining voices of our
    menu: **Translation** and **Sentiment Analysis**.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将完成菜单中剩余的两个选项：**翻译**和**情感分析**。
