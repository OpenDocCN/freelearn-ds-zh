- en: Chapter 8. Mahout Changes in the Upcoming Release
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章：即将发布的 Mahout 变更
- en: 'Mahout is a community-driven project and its community is very strong. This
    community decided on some of the major changes in the upcoming 1.0 release. In
    this chapter, we will explore the upcoming changes and developments in Apache
    Mahout. We will look at the following topics in brief:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout 是一个社区驱动的项目，其社区非常强大。这个社区决定了一些即将在 1.0 版本中发布的重大变更。在本章中，我们将探讨 Apache Mahout
    即将到来的变更和发展。我们将简要介绍以下主题：
- en: New changes due in Mahout 1.0
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahout 1.0 中的新变更
- en: Apache Spark
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Spark
- en: H20-platform-related work in Apache Mahout
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Mahout 中的 H20-platform 相关工作
- en: Mahout new changes
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mahout 的新变更
- en: Mahout was using the map reduce programming model to handle large datasets.
    From the end of April 2014, the community decided to stop the implementation of
    the new map reduce algorithm. This decision has a valid reason. Mahout's codebase
    will be moving to modern data processing systems that offer a richer programming
    model and more efficient execution than Hadoop's MapReduce.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout 之前使用 MapReduce 编程模型来处理大数据集。从 2014 年 4 月底开始，社区决定停止实施新的 MapReduce 算法。这个决定有合理的理由。Mahout
    的代码库将迁移到提供更丰富编程模型和比 Hadoop MapReduce 更高效执行的现代数据处理系统。
- en: Mahout has started its implementation on the top of **Domain Specific Language**
    (**DSL**) for linear algebraic operations. Programs written in this DSL are automatically
    optimized and executed in parallel on Apache Spark. Scala DSL and algebraic optimizer
    is Scala and Spark binding for Mahout.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout 已经开始在 **领域特定语言**（**DSL**）的顶部实现线性代数操作。用这种 DSL 编写的程序将自动优化并在 Apache Spark
    上并行执行。Scala DSL 和代数优化器是 Mahout 的 Scala 和 Spark 绑定。
- en: Mahout Scala and Spark bindings
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mahout Scala 和 Spark 绑定
- en: With Mahout Scala bindings and Mahout Spark bindings for linear algebra subroutines,
    developers in Mahout are trying to bring semantic explicitness to Mahout's in-core
    and out-of-core linear algebra subroutines. They are doing this while adding the
    benefits of the strong programming environment of Scala and capitalizing on scalability
    benefits of Spark and GraphX. Scala binding is used to provide support for Scala
    DSL, and this will make writing machine learning programs easier.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Mahout Scala 绑定和 Mahout Spark 绑定线性代数子程序，Mahout 中的开发者试图将语义明确性引入 Mahout 的内存和内存外线性代数子程序。他们在添加
    Scala 强大编程环境的好处的同时，利用 Spark 和 GraphX 的可扩展性优势。Scala 绑定用于提供对 Scala DSL 的支持，这将使编写机器学习程序变得更加容易。
- en: 'Mahout Scala and Spark bindings are packages that aim to provide an R-like
    look and feel to Mahout''s in-core and out-of-core Spark-backed linear algebra.
    An important part of Spark bindings is the expression optimizer. This optimizer
    looks at the entire expression and decides on how it can be simplified and which
    physical operators should be picked. A high-level diagram of the binding stack
    is shown in the following figure ([https://issues.apache.org/jira/secure/attachment/12638098/BindingsStack.jpg](https://issues.apache.org/jira/secure/attachment/12638098/BindingsStack.jpg)):'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout 的 Scala 和 Spark 绑定是旨在为 Mahout 的内存和内存外 Spark 支持的线性代数提供类似 R 语言外观和感觉的包。Spark
    绑定的重要组成部分是表达式优化器。这个优化器会查看整个表达式，并决定如何简化它以及应该选择哪些物理操作符。绑定堆栈的高级图示如下所示（[https://issues.apache.org/jira/secure/attachment/12638098/BindingsStack.jpg](https://issues.apache.org/jira/secure/attachment/12638098/BindingsStack.jpg)）：
- en: '![Mahout Scala and Spark bindings](img/4959OS_08_01.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![Mahout Scala 和 Spark 绑定](img/4959OS_08_01.jpg)'
- en: The Spark binding shell has also been implemented in Mahout 1.0\. Let's understand
    the Apache Spark project first and then we will revisit the Spark binding shell
    in Mahout.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout 1.0 中也实现了 Spark 绑定 shell。让我们首先了解 Apache Spark 项目，然后我们将重新审视 Mahout 中的
    Spark 绑定 shell。
- en: Apache Spark
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark
- en: Apache Spark is an open source, in-memory, general-purpose computing system.
    Spark's in-memory technique provides performance that is 100 times faster. Instead
    of Hadoop-like disk-based computation, Spark uses cluster memory to upload all
    the data into the memory, and this data can be queried repeatedly.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 是一个开源的、内存中的通用计算系统。Spark 的内存技术提供了比传统基于磁盘的计算快 100 倍的性能。Spark 不同于
    Hadoop 类似的基于磁盘的计算，它使用集群内存将所有数据上传到内存中，并且这些数据可以被重复查询。
- en: 'Apache Spark provides high-level APIs in Java, Python, and Scala and an optimized
    engine that supports general execution graphs. It provides the following high-level
    tools:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 提供了 Java、Python 和 Scala 的高级 API 以及支持通用执行图的高级优化引擎。它提供了以下高级工具：
- en: '**Spark SQL**: This is for SQL and structured data processing.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark SQL**：这是用于 SQL 和结构化数据处理的功能。'
- en: '**MLib**: This is Spark''s scalable machine learning library that consists
    of common learning algorithms and utilities, including classification, regression,
    clustering, collaborative filtering, dimensionality reduction, as well as the
    underlying optimization primitives.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLib**：这是 Spark 的可扩展机器学习库，包括常见的学习算法和实用工具，如分类、回归、聚类、协同过滤、降维以及底层的优化原语。'
- en: '**GraphX**: This is the new Spark API for graphs and graph-parallel computation.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GraphX**：这是 Spark 的新图和图并行计算 API。'
- en: '**Spark streaming**: This can collect data from many sources and after processing
    this data, it uses complex algorithms and can push the data to filesystems, databases,
    and live dashboards.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark streaming**：这可以从多个来源收集数据，在处理这些数据后，它使用复杂算法并将数据推送到文件系统、数据库和实时仪表板。'
- en: As Spark is gaining popularity among data scientists, the Mahout community is
    also quickly working on making Mahout algorithms function on Spark's execution
    engine to speed up its calculation 10 to 100 times faster. Mahout provides several
    important building blocks to create recommendations using Spark. Spark-item similarity
    can be used to create *other people also liked these things* kind of recommendations
    and when paired with a search engine can personalize recommendations for individual
    users. Spark-row similarity can provide non-personalized content based on recommendations
    and when paired with a search engine can be used to personalize content based
    on recommendations ([http://comments.gmane.org/gmane.comp.apache.mahout.scm/6513](http://comments.gmane.org/gmane.comp.apache.mahout.scm/6513)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 Spark 在数据科学家中的流行，Mahout 社区也在迅速努力使 Mahout 算法在 Spark 的执行引擎上运行，以加快其计算速度 10 到
    100 倍。Mahout 提供了几个重要的构建块，用于使用 Spark 创建推荐。Spark-item 相似度可以用于创建 *其他人也喜欢这些内容* 类型的推荐，并且当与搜索引擎配合使用时，可以为单个用户个性化推荐。Spark-row
    相似度可以根据推荐提供非个性化内容，并且当与搜索引擎配合使用时，可以用于根据推荐个性化内容 ([http://comments.gmane.org/gmane.comp.apache.mahout.scm/6513](http://comments.gmane.org/gmane.comp.apache.mahout.scm/6513))).
- en: Using Mahout's Spark shell
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Mahout 的 Spark shell
- en: 'You can use Mahout''s Spark shell by referring to the following steps:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下步骤使用 Mahout 的 Spark shell：
- en: Download Spark from [http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html).
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)
    下载 Spark。
- en: 'Create a new folder with the name `spark` using the following command and move
    the downloaded file there:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建一个名为 `spark` 的新文件夹，并将下载的文件移动到该文件夹中：
- en: '[PRE0]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Unpack the archived file in a folder using the following command:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在文件夹中解压归档文件：
- en: '[PRE1]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This will unzip the file `under/tmp/spark/spark-1.1.1`. Now, move to the newly
    created folder and run the following command:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将解压 `under/tmp/spark/spark-1.1.1` 中的文件。现在，移动到新创建的文件夹并运行以下命令：
- en: '[PRE2]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will build Spark on your system as shown in the following screenshot:'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将在您的系统上构建 Spark，如下截图所示：
- en: '![Using Mahout''s Spark shell](img/4959OS_08_02.jpg)'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用 Mahout 的 Spark shell](img/4959OS_08_02.jpg)'
- en: 'Now create a Mahout directory and move the file to it using the following command:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在创建一个 Mahout 目录，并使用以下命令将文件移动到该目录：
- en: '[PRE3]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Check out the master branch of Mahout from GitHub using the following command:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令从 GitHub 检出 Mahout 的主分支：
- en: '[PRE4]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output of the preceding command is shown in the following screenshot:'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下截图所示：
- en: '![Using Mahout''s Spark shell](img/4959OS_08_03.jpg)'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用 Mahout 的 Spark shell](img/4959OS_08_03.jpg)'
- en: 'Change your directory to the newly created Mahout directory and build Mahout:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的目录切换到新创建的 Mahout 目录，并构建 Mahout：
- en: '[PRE5]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output of the preceding command is shown in the following screenshot:'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下截图所示：
- en: '![Using Mahout''s Spark shell](img/4959OS_08_04.jpg)'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用 Mahout 的 Spark shell](img/4959OS_08_04.jpg)'
- en: 'Move to the directory where you unpacked Spark and type the following command
    to start Spark locally:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移动到您解压 Spark 的目录，并输入以下命令以在本地启动 Spark：
- en: '[PRE6]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output of the preceding command is shown in the following screenshot:'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下截图所示：
- en: '![Using Mahout''s Spark shell](img/4959OS_08_05.jpg)'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用 Mahout 的 Spark shell](img/4959OS_08_05.jpg)'
- en: Open a browser; point it to `http://localhost:8080/` to check whether Spark
    has successfully started. Copy the URL of the Spark master at the top of the page
    (it starts with `spark://`).
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开浏览器；将其指向 `http://localhost:8080/` 以检查 Spark 是否已成功启动。复制页面顶部 Spark 主机的 URL（以
    `spark://` 开头）。
- en: 'Define the following environment variables:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义以下环境变量：
- en: '[PRE7]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Finally, change to the directory where you unpacked Mahout and type `bin/mahout
    spark-shell`; you should see the shell starting and get the `mahout>` prompt.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，切换到您解压Mahout的目录，并输入`bin/mahout spark-shell`；您应该看到shell启动并出现`mahout>`提示符。
- en: Now your Mahout Spark shell is ready and you can start playing with data. For
    more information on this topic, see the implementation section at [https://mahout.apache.org/users/sparkbindings/play-with-shell.html](https://mahout.apache.org/users/sparkbindings/play-with-shell.html).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您的Mahout Spark shell已经准备好了，您可以从数据处理开始。有关此主题的更多信息，请参阅[https://mahout.apache.org/users/sparkbindings/play-with-shell.html](https://mahout.apache.org/users/sparkbindings/play-with-shell.html)中的实现部分。
- en: H2O platform integration
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: H2O平台集成
- en: As discussed earlier, an experimental work to integrate Mahout and the H2O platform
    is also in progress. The integration provides an H2O backend to the Mahout algebra
    DSL.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，将Mahout和H2O平台集成的实验性工作也在进行中。该集成为Mahout代数DSL提供了H2O后端。
- en: H2O makes Hadoop do math! H2O scales statistics, machine learning, and math
    over big data. It is extensible and users can build blocks using simple math legos
    in the core. H2O keeps familiar interfaces such as R, Excel, and JSON so that
    big data enthusiasts and experts can explore, munge, model, and score datasets
    using a range of simple-to-advanced algorithms. Data collection is easy, while
    decision making is hard. H2O makes it fast and easy to derive insights from your
    data through faster and better predictive modeling. It also has a vision of online
    scoring and modeling in a single platform ([http://0xdata.com/download/](http://0xdata.com/download/)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: H2O让Hadoop做数学！H2O在大数据上扩展统计、机器学习和数学。它是可扩展的，用户可以使用核心中的简单数学积木构建块。H2O保留了熟悉的接口，如R、Excel和JSON，以便大数据爱好者和专业人员可以使用一系列简单到高级的算法来探索、处理、建模和评分数据集。数据收集容易，而决策困难。H2O通过更快、更好的预测建模使从数据中提取见解变得快速且简单。它还拥有在线评分和建模的单平台愿景（[http://0xdata.com/download/](http://0xdata.com/download/)）。
- en: H2O is fundamentally a peer-to-peer system. H2O nodes join together to form
    a cloud on which high-performance distributed math can be executed. Each node
    joins a cloud of a given name. Multiple clouds can exist on the same network at
    the same time as long as their names are different. Multiple nodes can exist on
    the same server as well (they can even belong to the same cloud).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: H2O本质上是一个对等网络系统。H2O节点联合起来形成一个云，可以在其上执行高性能分布式数学运算。每个节点加入一个具有特定名称的云。只要它们的名称不同，同一网络中可以同时存在多个云。同样，同一服务器上也可以存在多个节点（它们甚至可以属于同一个云）。
- en: The Mahout H2O integration is fit into this model by having N-1 worker nodes
    and one driver node, all belonging to the same cloud name. The default cloud name
    used for the integration is `mah2out`. Clouds have to be spun up as per their
    task/job.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout H2O集成通过具有N-1个工作节点和一个驱动节点，所有节点都属于同一个云名称来适应此模型。用于集成的默认云名称是`mah2out`。云必须根据其任务/作业启动。
- en: More details can be found at [https://issues.apache.org/jira/browse/MAHOUT-1500](https://issues.apache.org/jira/browse/MAHOUT-1500).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 更多详细信息可以在[https://issues.apache.org/jira/browse/MAHOUT-1500](https://issues.apache.org/jira/browse/MAHOUT-1500)中找到。
- en: Summary
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the upcoming release of Mahout 1.0, and the changes
    that are currently going on. We also glanced through Spark, Scala binding, and
    Apache Spark. We also discussed a high-level overview of H2O Mahout integration.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了即将发布的Mahout 1.0版本，以及目前正在进行的更改。我们还简要介绍了Spark、Scala绑定和Apache Spark。我们还讨论了H2O
    Mahout集成的概述。
- en: Now let's move on to the final chapter of this book where we will develop a
    production-ready classifier.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续到这本书的最后一章，我们将开发一个生产就绪的分类器。
