- en: Building Machine Learning Systems with Decision Tree and Ensemble Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用决策树和集成模型构建机器学习系统
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Getting and preparing real-world medical data for exploring Decision Trees and
    Ensemble models in Spark 2.0
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取和准备真实世界的医疗数据，以探索Spark 2.0中的决策树和集成模型
- en: Building a classification system with Decision Trees in Spark 2.0
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中使用决策树构建分类系统
- en: Solving regression problems with Decision Trees in Spark 2.0
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中使用决策树解决回归问题
- en: Building a classification system with Random Forest Trees in Spark 2.0
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中使用随机森林树构建分类系统
- en: Solving regression problems with Random Forest Trees in Spark 2.0
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中使用随机森林树解决回归问题
- en: Building a classification system with Gradient Boosted Trees (GBT) in Spark
    2.0
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中使用梯度提升树（GBT）构建分类系统
- en: Solving regression problems with Gradient Boosted Trees (GBT) in Spark 2.0
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中使用梯度提升树（GBT）解决回归问题
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Decision trees are one of the oldest and more widely used methods of machine
    learning in commerce. What makes them popular is not only their ability to deal
    with more complex partitioning and segmentation (they are more flexible than linear
    models) but also their ability to explain how we arrived at a solution and as
    to "why" the outcome is predicated or classified as a class/label.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是商业中最古老和广泛使用的机器学习方法之一。它们受欢迎的原因不仅在于它们处理更复杂的分区和分割的能力（它们比线性模型更灵活），还在于它们解释我们是如何得出解决方案以及“为什么”结果被预测或分类为类/标签的能力。
- en: Apache Spark provides a good mix of decision tree based algorithms fully capable
    of taking advantage of parallelism in Spark. The implementation ranges from the
    straight forward Single Decision Tree (the CART type algorithm) to Ensemble Trees,
    such as Random Forest Trees and **GBT** (**Gradient Boosted Tree**). They all
    have both the variant flavors to facilitate classification (for example, categorical,
    such as height = short/tall) or regression (for example, continuous, such as height
    = 2.5 meters).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark提供了一系列基于决策树的算法，完全能够利用Spark中的并行性。实现范围从直接的单决策树（CART类型算法）到集成树，例如随机森林树和梯度提升树（GBT）。它们都有变体风味，以便进行分类（例如，分类，例如，身高=矮/高）或回归（例如，连续，例如，身高=2.5米）的便利。
- en: 'The following figure depicts a mind map that shows Spark ML library coverage
    of decision tree algorithms, as at the time of writing:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图描述了一个思维导图，显示了决策树算法在Spark ML库中的覆盖范围，截至撰写时：
- en: '![](img/00242.jpeg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00242.jpeg)'
- en: A quick way to think about the decision tree algorithm is as a smart partitioning
    algorithm that tries to minimize a loss function (for example, L2 or least square)
    as it partitions the ranges to come up with a segmented space which are best fitted
    decision boundaries to the data. The algorithm gets more sophisticated through
    the application of sampling the data and trying a combination of features to assemble
    a more complex ensemble model in which each learner (partial sample or feature
    combination) gets to vote toward the final outcome.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 快速理解决策树算法的一种方法是将其视为一种智能分区算法，它试图最小化损失函数（例如，L2或最小二乘），因为它将范围划分为最适合数据的分段空间。通过对数据进行采样并尝试组合特征，该算法变得更加复杂，从而组装出更复杂的集成模型，其中每个学习者（部分样本或特征组合）都对最终结果进行投票。
- en: 'The following figure depicts a simplified version in which a simple binary
    tree (stumping) is trained to classify the data into segments belonging to two
    different colors (for example, healthy patient/sick patient). The figure depicts
    a simple algorithm that just breaks the x/y feature space to one-half every time
    it establishes a decision boundary (hence classifying) while minimizing the number
    of errors (for example, a L2 least square measure):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图描述了一个简化版本，其中一个简单的二叉树（树桩）被训练为将数据分类为属于两种不同颜色的段（例如，健康患者/患病患者）。该图描述了一个简单的算法，每次建立决策边界（因此分类）时，它只是将x/y特征空间分成一半，同时最小化错误的数量（例如，L2最小二乘测量）：
- en: '![](img/00243.jpeg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00243.jpeg)'
- en: 'The following figure provides a corresponding tree so we can visualize the
    algorithm (in this case, a simple divide and conquer) against the proposed segmentation
    space. What makes decision tree algorithms popular is their ability to show their
    classification result in a language that can easily be communicated to a business
    user without much math:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图提供了相应的树，以便我们可以可视化算法（在这种情况下，简单的分而治之）针对提出的分割空间。决策树算法受欢迎的原因是它们能够以一种易于向业务用户沟通的语言显示其分类结果，而无需太多数学：
- en: '![](img/00244.gif)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00244.gif)'
- en: A decision tree in Spark is a parallel algorithm designed to fit and grow a
    single tree into a dataset that can be categorical (classification) or continuous
    (regression). It is a greedy algorithm based on stumping (binary split, and so
    on) that partitions the solution space recursively while attempting to select
    the best split among all possible splits using Information Gain Maximization (entropy
    based).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Spark中的决策树是一种并行算法，旨在将单个树拟合和生长到可以是分类（分类）或连续（回归）的数据集中。它是一种贪婪算法，基于树桩（二进制分割等），通过递归地划分解空间，尝试使用信息增益最大化（基于熵）来选择所有可能分割中的最佳分割。
- en: Ensemble models
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成模型
- en: The other way to look at Spark's offering for decision trees is to think of
    the algorithm as belonging to two camps. The first camp, which we saw earlier
    in the introduction, concerns itself with single trees that attempt to find various
    techniques to find the best single tree for the dataset. While this is OK for
    a lot of datasets, the greedy nature of the algorithm can lead to unintended consequences,
    such as overfitting and going too deep to be able to capture all the boundaries
    within the training data (that is, it is over optimized).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 观察Spark对决策树的另一种方式是将算法视为属于两个阵营。第一个阵营，我们在介绍中看到过，关注于试图找到各种技术来为数据集找到最佳的单棵树。虽然这对许多数据集来说是可以的，但算法的贪婪性质可能会导致意想不到的后果，比如过拟合和过度深入以能够捕捉训练数据中的所有边界（即过度优化）。
- en: 'To overcome the overfitting problem and to increase accuracy and the quality
    of predictions, Spark has implemented two classes of ensemble decision tree models
    that attempt to create many imperfect learners that either see a subset of data
    (sampling with or without substitution) and/or a subset of features. While each
    individual tree is less accurate, the collection of the trees'' assembled votes
    (or the average probability in the case of continuous variables) and the resultant
    averaging is much more accurate than any individual tree:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服过拟合问题并提高准确性和预测质量，Spark实现了两类集成决策树模型，试图创建许多不完美的学习器，这些学习器要么看到数据的子集（有或没有替换地采样），要么看到特征的子集。虽然每棵单独的树不太准确，但树的集合组装的投票（或在连续变量的情况下的平均概率）和由此产生的平均值比任何单独的树更准确：
- en: '**Random Forest**: This method creates many trees in parallel and then votes/averages
    the outcome to minimize the overfitting problem prone in single tree algorithms.
    They are capable of capturing non-linearity and feature interaction without any
    scaling. They should be seriously considered at least as one of the first toolsets
    used to dissect the data and understand its makeup. The following figure provides
    a visual guideline for this implementation in Spark:'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林**：这种方法并行创建许多树，然后投票/平均结果以最小化单棵树算法中容易出现的过拟合问题。它们能够捕捉非线性和特征交互而无需任何缩放。它们应该至少被认真考虑为用于解剖数据并了解其构成的第一工具集之一。以下图提供了Spark中此实现的可视化指南：'
- en: '![](img/00245.gif)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00245.gif)'
- en: '**Gradient Boosted Trees**:This method is another ensemble model in which an
    average of many trees (even though they are less perfect) improves the accuracy
    and quality of the prediction. They differ from Random Forest in that they build
    one tree at a time and each tree tries to learn from the shortcomings of the previous
    tree by minimizing the loss function. They are similar to the concept of gradient
    descent, but they use the minimization (similar to gradient) to select and improve
    the next tree (they walk in the direction of the tree which creates the best accuracy).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度提升树**：这种方法是另一种集成模型，通过许多树的平均值（即使它们不太完美）来提高预测的准确性和质量。它们与随机森林的不同之处在于，它们一次构建一棵树，每棵树都试图从前一棵树的缺点中学习，通过最小化损失函数来改进。它们类似于梯度下降的概念，但它们使用最小化（类似于梯度）来选择和改进下一棵树（它们沿着创建最佳准确性的树的方向前进）。'
- en: 'The three options for the loss function are:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数的三个选项是：
- en: '**Log loss**: Negative likelihood for classification'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对数损失**：分类的负对数似然'
- en: '**L2**: Least square for regression'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L2**：回归的最小二乘'
- en: '**L1**: Absolute error for regression'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L1**：回归的绝对误差'
- en: 'The following figure provides an easy-to-use visualization reference:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图提供了一个易于使用的可视化参考：
- en: '![](img/00246.gif)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00246.gif)'
- en: 'The main packages for Decision Trees in Spark are in ML and are as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Spark中决策树的主要包在ML中，如下所示：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Measures of impurity
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不纯度的度量
- en: 'With all machine learning algorithms, we are trying to minimize a set of cost
    functions which help us to select the best move. Spark uses three possible selections
    for maximization functions. The following figure depicts the alternatives:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有的机器学习算法，我们都试图最小化一组成本函数，这些函数帮助我们选择最佳的移动。Spark使用三种可能的最大化函数选择。以下图描述了这些替代方案：
- en: '![](img/00247.gif)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00247.gif)'
- en: 'In this section, we will discuss each of the three possible alternatives:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论三种可能的替代方案：
- en: '**Information gain**:Loosely speaking, this measures the level of impurity
    in a group based on the concept of entropy--see the Shannon information theory
    and then as later suggested by Quinlan in his ID3 algorithm.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息增益**：粗略地说，这是根据熵的概念来衡量群体中不纯度的水平--参见香农信息理论，然后后来由Quinlan在他的ID3算法中建议。'
- en: 'The calculation of entropy is shown in the following equation:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 熵的计算如下方程所示：
- en: '![](img/00248.jpeg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00248.jpeg)'
- en: Information gain helps us to select an attribute in each feature vector space
    that can best help to separate the classes from each other. We use this attribute
    to decide how to order the attributes (thus, affecting the decision boundaries)
    in the nodes of a given tree.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 信息增益帮助我们在每个特征向量空间中选择一个属性，这个属性可以最好地帮助我们将类别彼此分开。我们使用这个属性来决定如何对节点中的属性进行排序（从而影响决策边界）。
- en: 'The following figure depicts the calculation visually for easy understanding.
    In the first step, we want to select an attribute so that we maximize the IG (information
    gain) in the root or parent node, then build our child nodes for each value of
    the selected attribute (their associated vectors). We keep repeating the algorithm
    recursively untill we can no longer see any gains:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图形以易于理解的方式描述了计算。在第一步中，我们希望选择一个属性，以便在根节点或父节点中最大化IG（信息增益），然后为所选属性的每个值构建我们的子节点（它们的关联向量）。我们不断递归地重复算法，直到我们再也看不到任何收益：
- en: '![](img/00249.gif)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00249.gif)'
- en: '**Gini Index: **This attempts to improve the IG (information gain) by isolating
    the classes so that the largest class is separated from the population. The Gini
    Index is a bit different to entropy, in that you try to have a 50/50 split and
    then apply further splits to infer the solution. It is meant to reflect the effect
    of one variable and it does not extend its reach to multi-attribute states. It
    uses a simple frequency count against the population. Use Gini for higher-dimensional
    and more noisy data.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基尼指数：** 这试图通过隔离类别来改进信息增益（IG），以便最大的类别与总体分离。基尼指数与熵有些不同，因为您尝试实现50/50的分割，然后应用进一步的分割来推断解决方案。它旨在反映一个变量的影响，并且不会扩展其影响到多属性状态。它使用简单的频率计数来对总体进行评估。用于更高维度和更多噪音数据的基尼指数。'
- en: Use Gini Impurity where you have complex multi-dimensional data and you are
    trying to dissect a simple signal from the set.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在您拥有复杂的多维数据并且正在尝试从中解剖简单信号的情况下，请使用基尼不纯度。
- en: 'On the other hand, use information gain (or any entropy-based system) where
    you have a cleaner and low dimensional dataset, but you are looking for a more
    complex (in terms of accuracy and quality) dataset:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在您拥有更清洁和低维数据集的情况下，可以使用信息增益（或任何基于熵的系统），但您正在寻找更复杂（在准确性和质量方面）的数据集：
- en: '![](img/00250.gif)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00250.gif)'
- en: '**Variance**: The variance is used to signal the regression model for the tree
    algorithm. In short, we still try to minimize an L2 function, but the difference
    is that here we seek to minimize the distance-squared of the observation and mean
    of the node (segment) being considered.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方差**：方差用于信号树算法的回归模型。简而言之，我们仍然试图最小化L2函数，但不同之处在于这里我们试图最小化观察值与被考虑的节点（段）的平均值之间的距离的平方。'
- en: 'The following figure depicts a simplified version for visualization:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了可视化的简化版本：
- en: '![](img/00251.jpeg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00251.jpeg)'
- en: 'The Spark Model Evaluation Tools for evaluation classification and regression
    with tree models are as listed here:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 用于评估树模型的Spark模型评估工具包括以下内容：
- en: 'The confusion matrix is a table that is used to describe the performance of
    a classification model, out of the test dataset that the true values are known.
    The confusion matrix itself is relatively simple; it is a 2 x 2 matrix:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵是用来描述分类模型性能的表格，其中真实值已知的测试数据集。混淆矩阵本身相对简单；它是一个2x2的矩阵：
- en: '|  |  | **Prediction** | ** Value** |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  |  | **预测** | **值** |'
- en: '|  |  | Yes | No |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 是 | 否 |'
- en: '| **Actual** | Yes | True Positive (TP) | False Negative (FN) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| **实际** | 是 | 真正例（TP） | 假反例（FN） |'
- en: '| **Value** | No | False Positive (FP) | True Negative (TN) |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| **值** | 否 | 假正例（FP） | 真反例（TN） |'
- en: 'For our cancer dataset:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的癌症数据集：
- en: '**True Positives (TP):** Those are cases we predicted yes, and they did have
    breast cancer'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正例（TP）：** 预测为是，且他们确实患有乳腺癌'
- en: '**True Negative (TN):** Those are cases we predicted no, and they didn''t have
    breast cancer'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真反例（TN）：** 预测为否，且他们没有乳腺癌'
- en: '**False Positives (FP):** We predicted yes, but they didn''t have breast cancer'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假正例（FP）：** 我们预测为是，但他们没有乳腺癌'
- en: '**False Negatives (FN):** We predicted no, but they did have breast cancer'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假反例（FN）：** 我们预测为否，但他们确实患有乳腺癌'
- en: A good classification system should match the reality closely with good TP and
    TN values, while having fewer FP and FN values.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一个良好的分类系统应该与现实情况密切匹配，具有良好的TP和TN值，同时具有较少的FP和FN值。
- en: 'Overall, the following terms are also used as markers for a classification
    model:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，以下术语也被用作分类模型的标记：
- en: '**Accuracy**: The correctness ratio of the model:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准确性**：模型的正确率：'
- en: '*(TP + TN)/Total*'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*(TP + TN)/总数*'
- en: '**Error**: Overall, the percentage that the model is wrong:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**错误**：总体上，模型错误的百分比：'
- en: '*(FP+FN)/Total*'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*(FP+FN)/总数*'
- en: Also equals to 1 - Accuracy
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 也等于1-准确性
- en: 'In the Spark Machine Learning Library, there is a utility class to handle the
    calculation for the aforementioned common matrix:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark机器学习库中，有一个实用程序类来处理上述常见矩阵的计算：
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We will use the utility class in the following sample code.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在以下示例代码中使用实用程序类。
- en: 'Similarly, for the regression algorithm, **Mean Squared Error (MSE),** or average
    of the squares of the errors, is well utilized as a key parameter for the measurement
    of a model. In the Spark Machine Learning Library, there is also a utility class
    for it and it will provide the key indicator of a regression model:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，对于回归算法，**均方误差（MSE）** 或误差平方的平均值，被广泛用作模型测量的关键参数。在Spark机器学习库中，也有一个实用程序类，它将提供回归模型的关键指标：
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Documentation for the Spark Matrix Evaluator can be found at [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics)
    and [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics)[.](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Spark矩阵评估器的文档可以在[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics)和[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics)找到。
- en: Getting and preparing real-world medical data for exploring Decision Trees and
    Ensemble models in Spark 2.0
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取和准备真实世界的医学数据，以探索Spark 2.0中的决策树和集成模型
- en: The dataset used depicts a real-life application of Decision Trees in machine
    learning. We used a cancer dataset to predict what makes a patient's case malignant
    or not. To explore the real power of decision trees, we use a medical dataset
    that exhibits real life non-linearity with a complex error surface.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用决策树在机器学习中的真实应用。我们使用了一个癌症数据集来预测患者病例是恶性还是良性。为了探索决策树的真正威力，我们使用了一个展现真实生活非线性和复杂误差表面的医学数据集。
- en: How to do it...
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: The **Wisconsin Breast Cancer** dataset was obtained from the University of
    Wisconsin Hospital from Dr. William H Wolberg. The dataset was gained periodically
    as Dr. Wolberg reported his clinical cases.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**威斯康星乳腺癌**数据集是从威斯康星大学医院的William H Wolberg博士处获得的。该数据集是定期获得的，因为Wolberg博士报告了他的临床病例。'
- en: The dataset can be retrieved from multiple sources, and is available directly
    from the University of California Irvine's web server [http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data](http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集可以从多个来源检索，并且可以直接从加州大学尔湾分校的网络服务器 [http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data](http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data) 获取。
- en: The data is also available from the University of Wisconsin's web server [ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer1/datacum](ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer1/datacum)
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 数据也可以从威斯康星大学的网络服务器 [ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer1/datacum](ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer1/datacum) 获取。
- en: The dataset currently contains clinical cases from 1989 to 1991\. It has 699
    instances, with 458 classified as benign tumors and 241 as malignant cases. Each
    instance is described by nine attributes with an integer value in the range of
    1 to 10 and a binary class label. Out of the 699 instances, there are 16 instances
    that are missing some attributes.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集目前包含1989年至1991年的临床病例。它有699个实例，其中458个被分类为良性肿瘤，241个被分类为恶性病例。每个实例由九个属性描述，属性值在1到10的范围内，并带有二进制类标签。在这699个实例中，有16个实例缺少一些属性。
- en: We will remove these 16 instances from the memory and process the rest (in total,
    683 instances) for the model calculations.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从内存中删除这16个实例，并处理其余的（总共683个实例）进行模型计算。
- en: 'The sample raw data looks like the following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 样本原始数据如下所示：
- en: '[PRE3]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The attribute information is as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 属性信息如下：
- en: '| **#** | **Attribute** | **Domain** |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| **#** | **属性** | **域** |'
- en: '| 1 | Sample code number | ID number |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 样本编号 | ID编号 |'
- en: '| 2 | Clump Thickness | 1 - 10 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 块厚度 | 1 - 10 |'
- en: '| 3 | Uniformity of Cell Size | 1 - 10 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 细胞大小的均匀性 | 1 - 10 |'
- en: '| 4 | Uniformity of Cell Shape | 1 - 10 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 细胞形态的均匀性 | 1 - 10 |'
- en: '| 5 | Marginal Adhesion | 1 - 10 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 边缘粘附 | 1 - 10 |'
- en: '| 6 | Single Epithelial Cell Size | 1 - 10 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 单个上皮细胞大小 | 1 - 10 |'
- en: '| 7 | Bare Nuclei | 1 - 10 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 裸核 | 1 - 10 |'
- en: '| 8 | Bland Chromatin | 1 - 10 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 淡染色质 | 1 - 10 |'
- en: '| 9 | Normal Nucleoli | 1 - 10 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 正常核仁 | 1 - 10 |'
- en: '| 10 | Mitoses | 1 - 10 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 有丝分裂 | 1 - 10 |'
- en: '| 11 | Class | (2 for benign, 4 for Malignant) |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 类别 | (2表示良性，4表示恶性) |'
- en: 'If presented in the correct columns, it will look like the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果以正确的列呈现，将如下所示：
- en: '| **ID Number** | **Clump Thickness** | **Uniformity of Cell Size** | **Uniformity
    of Cell Shape** | **Marginal Adhesion** | **Single Epithelial Cell Size** | **Bare
    Nucleoli** | **Bland Chromatin** | **Normal Nucleoli** | **Mitoses** | **Class**
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| **ID编号** | **块厚度** | **细胞大小的均匀性** | **细胞形态的均匀性** | **边缘粘附** | **单个上皮细胞大小**
    | **裸核** | **淡染色质** | **正常核仁** | **有丝分裂** | **类别** |'
- en: '| 1000025 | 5 | 1 | 1 | 1 | 2 | 1 | 3 | 1 | 1 | 2 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 1000025 | 5 | 1 | 1 | 1 | 2 | 1 | 3 | 1 | 1 | 2 |'
- en: '| 1002945 | 5 | 4 | 4 | 5 | 7 | 10 | 3 | 2 | 1 | 2 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 1002945 | 5 | 4 | 4 | 5 | 7 | 10 | 3 | 2 | 1 | 2 |'
- en: '| 1015425 | 3 | 1 | 1 | 1 | 2 | 2 | 3 | 1 | 1 | 2 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 1015425 | 3 | 1 | 1 | 1 | 2 | 2 | 3 | 1 | 1 | 2 |'
- en: '| 1016277 | 6 | 8 | 8 | 1 | 3 | 4 | 3 | 7 | 1 | 2 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 1016277 | 6 | 8 | 8 | 1 | 3 | 4 | 3 | 7 | 1 | 2 |'
- en: '| 1017023 | 4 | 1 | 1 | 3 | 2 | 1 | 3 | 1 | 1 | 2 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 1017023 | 4 | 1 | 1 | 3 | 2 | 1 | 3 | 1 | 1 | 2 |'
- en: '| 1017122 | 8 | 10 | 10 | 8 | 7 | 10 | 9 | 7 | 1 | 4 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 1017122 | 8 | 10 | 10 | 8 | 7 | 10 | 9 | 7 | 1 | 4 |'
- en: '| 1018099 | 1 | 1 | 1 | 1 | 2 | 10 | 3 | 1 | 1 | 2 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 1018099 | 1 | 1 | 1 | 1 | 2 | 10 | 3 | 1 | 1 | 2 |'
- en: '| 1018561 | 2 | 1 | 2 | 1 | 2 | 1 | 3 | 1 | 1 | 2 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 1018561 | 2 | 1 | 2 | 1 | 2 | 1 | 3 | 1 | 1 | 2 |'
- en: '| 1033078 | 2 | 1 | 1 | 1 | 2 | 1 | 1 | 1 | 5 | 2 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 1033078 | 2 | 1 | 1 | 1 | 2 | 1 | 1 | 1 | 5 | 2 |'
- en: '| 1033078 | 4 | 2 | 1 | 1 | 2 | 1 | 2 | 1 | 1 | 2 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 1033078 | 4 | 2 | 1 | 1 | 2 | 1 | 2 | 1 | 1 | 2 |'
- en: '| 1035283 | 1 | 1 | 1 | 1 | 1 | 1 | 3 | 1 | 1 | 2 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 1035283 | 1 | 1 | 1 | 1 | 1 | 1 | 3 | 1 | 1 | 2 |'
- en: '| 1036172 | 2 | 1 | 1 | 1 | 2 | 1 | 2 | 1 | 1 | 2 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 1036172 | 2 | 1 | 1 | 1 | 2 | 1 | 2 | 1 | 1 | 2 |'
- en: '| 1041801 | 5 | 3 | 3 | 3 | 2 | 3 | 4 | 4 | 1 | 4 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 1041801 | 5 | 3 | 3 | 3 | 2 | 3 | 4 | 4 | 1 | 4 |'
- en: '| 1043999 | 1 | 1 | 1 | 1 | 2 | 3 | 3 | 1 | 1 | 2 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 1043999 | 1 | 1 | 1 | 1 | 2 | 3 | 3 | 1 | 1 | 2 |'
- en: '| 1044572 | 8 | 7 | 5 | 10 | 7 | 9 | 5 | 5 | 4 | 4 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 1044572 | 8 | 7 | 5 | 10 | 7 | 9 | 5 | 5 | 4 | 4 |'
- en: '| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |'
- en: There's more...
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The Wisconsin Breast Cancer dataset is widely used in the machine learning community.
    The dataset contains limited attributes and most of them are discrete numbers.
    It's very easy to apply a classification algorithm and regression model to the
    dataset.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 威斯康星乳腺癌数据集在机器学习社区中被广泛使用。该数据集包含有限的属性，其中大部分是离散数字。非常容易将分类算法和回归模型应用于该数据集。
- en: More than 20 research papers and publications already cite this dataset, and
    it is available publicly and very easy to use.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 已经有20多篇研究论文和出版物引用了这个数据集，它是公开可用的，非常容易使用。
- en: The dataset has the multivariate datatype, where attributes are integers, and
    the number of attributes are only 10\. This makes it one of the typical datasets
    for classification and regression analysis for this chapter.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集具有多变量数据类型，其中属性为整数，属性数量仅为10。这使得它成为本章分类和回归分析的典型数据集之一。
- en: Building a classification system with Decision Trees in Spark 2.0
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中构建决策树分类系统
- en: In this recipe, we will use the breast cancer data and use classifications to
    demonstrate the Decision Tree implantation in Spark. We will use the IG and Gini
    to show how to use the facilities already provided by Spark to avoid redundant
    coding. This recipe attempts to fit a single tree using a binary classification
    to train and predict the label (benign (0.0) and malignant (1.0)) for the dataset.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将使用乳腺癌数据并使用分类来演示Spark中的决策树实施。我们将使用IG和Gini来展示如何使用Spark已经提供的设施，以避免冗余编码。此示例尝试使用二进制分类来拟合单棵树，以训练和预测数据集的标签（良性（0.0）和恶性（1.0））。
- en: How to do it
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure the necessary
    JAR files are included.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动新项目。确保包含必要的JAR文件。
- en: 'Set up the package location where the program will reside:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置程序所在的包位置：
- en: '[PRE4]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Import the necessary packages for the Spark context to get access to the cluster
    and `Log4j.Logger` to reduce the amount of output produced by Spark:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入Spark上下文所需的必要包，以便访问集群和`Log4j.Logger`以减少Spark产生的输出量：
- en: '[PRE5]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create Spark''s configuration and the Spark session so we can have access to
    the cluster:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Spark的配置和Spark会话，以便我们可以访问集群：
- en: '[PRE6]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We read in the original raw data file:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们读取原始原始数据文件：
- en: '[PRE7]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We pre-process the dataset:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们预处理数据集：
- en: '[PRE8]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: First, we trim the line and remove any empty spaces. Once the line is ready
    for the next step, we remove the line if it's empty, or if it contains missing
    values ("?"). After this step, the 16 rows with missing data will be removed from
    the dataset in the memory.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们修剪行并删除任何空格。一旦行准备好进行下一步，如果行为空或包含缺失值（“?”），则删除行。在此步骤之后，内存中的数据集将删除16行缺失数据。
- en: 'We then read the comma separated values into RDD. Since the first column in
    the dataset only contains the instance''s ID number, it is better to remove this
    column from the real calculation. We slice it out with the following command,
    which will remove the first column from the RDD:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将逗号分隔的值读入RDD。由于数据集中的第一列只包含实例的ID号，最好将此列从实际计算中删除。我们使用以下命令切片，将从RDD中删除第一列：
- en: '[PRE9]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We then put the rest of the numbers into a dense vector.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将其余数字放入密集向量。
- en: 'Since the Wisconsin Breast Cancer dataset''s classifier is either benign cases
    (last column value = 2) or malignant cases (last column value = 4), we convert
    the preceding value using the following command:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 由于威斯康星州乳腺癌数据集的分类器要么是良性病例（最后一列值=2），要么是恶性病例（最后一列值=4），我们使用以下命令转换前面的值：
- en: '[PRE10]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'So the benign case 2 is converted to 0, and the malignant case value 4 is converted
    to 1, which will make the later calculations much easier. We then put the preceding
    row into a `Labeled Points`:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，良性病例2转换为0，恶性病例值4转换为1，这将使后续计算更容易。然后将前一行放入`Labeled Points`：
- en: '[PRE11]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We verify the raw data count and process the data count:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们验证原始数据计数并处理数据计数：
- en: '[PRE12]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And you will see the following on the console:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后您将在控制台上看到以下内容：
- en: '[PRE13]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We split the whole dataset into training data (70%) and test data (30%) randomly.
    Please note that the random split will generate around 211 test datasets. It is
    approximately but NOT exactly 30% of the dataset:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将整个数据集随机分成训练数据（70%）和测试数据（30%）。请注意，随机拆分将生成大约211个测试数据集。这大约是但并非完全是数据集的30%：
- en: '[PRE14]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We define a metrics calculation function, which utilizes the Spark `MulticlassMetrics`:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义一个度量计算函数，它利用Spark的`MulticlassMetrics`：
- en: '[PRE15]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This function will read in the model and test dataset, and create a metric which
    contains the confusion matrix mentioned earlier. It will contain the model accuracy,
    which is one of the indicators for the classification model.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将读取模型和测试数据集，并创建一个包含前面提到的混淆矩阵的度量。它将包含模型准确性，这是分类模型的指标之一。
- en: 'We define an evaluate function, which can take some tunable parameters for
    the Decision Tree model, and do the training for the dataset:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义一个评估函数，它可以接受一些可调参数用于决策树模型，并对数据集进行训练：
- en: '[PRE16]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The evaluate function will read in several parameters, including the impurity
    type (Gini or Entropy for the model) and generate the metrics for evaluations.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 评估函数将读取几个参数，包括不纯度类型（模型的基尼或熵）并生成评估指标。
- en: 'We set the following parameters:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们设置以下参数：
- en: '[PRE17]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Since we only have benign (0.0) and malignant (1.0), we put numClasses as 2\.
    The other parameters are tunable, and some of them are algorithm stop criteria.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只有良性（0.0）和恶性（1.0），我们将numClasses设置为2。其他参数是可调的，其中一些是算法停止标准。
- en: 'We evaluate the Gini impurity first:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先我们评估基尼不纯度：
- en: '[PRE18]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'From the console output:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '[PRE19]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We evaluate the Entropy impurity:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们评估熵不纯度：
- en: '[PRE20]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'From the console output:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '[PRE21]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We then close the program by stopping the session:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后通过停止会话来关闭程序：
- en: '[PRE22]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How it works...
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '它是如何工作的... '
- en: 'The dataset is a bit more complex than usual, but apart from some extra steps,
    parsing it remains the same as other recipes presented in previous chapters. The
    parsing takes the data in its raw form and turns it into an intermediate format
    which will end up as a LabelPoint data structure which is common in Spark ML schemes:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集比通常更复杂，但除了一些额外步骤外，解析它与前几章介绍的其他示例相同。解析将数据以原始形式转换为中间格式，最终将成为Spark ML方案中常见的LabelPoint数据结构：
- en: '[PRE23]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We use `DecisionTree.trainClassifier()` to train the classifier tree on the
    training set. We follow that by examining the various impurity and confusion matrix
    measurements to demonstrate how to measure the effectiveness of a tree model.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`DecisionTree.trainClassifier()`在训练集上训练分类器树。然后通过检查各种不纯度和混淆矩阵测量来演示如何衡量树模型的有效性。
- en: The reader is encouraged to look at the output and consult additional machine
    learning books to understand the concept of the confusion matrix and impurity
    measurement to master Decision Trees and variations in Spark.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励读者查看输出并参考其他机器学习书籍，以了解混淆矩阵和不纯度测量的概念，以掌握Spark中决策树和变体。
- en: There's more...
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: To visualize it better, we included a sample decision tree work flow in Spark
    which will read the data into Spark first. In our case, we create the RDD from
    the file. We then split the dataset into training data and test data using a random
    sampling function.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地可视化，我们在Spark中包含了一个样本决策树工作流程，它将首先将数据读入Spark。在我们的情况下，我们从文件创建RDD。然后我们使用随机抽样函数将数据集分为训练数据和测试数据。
- en: 'After the dataset is split, we use the training dataset to train the model,
    followed by test data to test the accuracy of the model. A good model should have
    a meaningful accuracy value (close to 1). The following figure depicts the workflow:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集分割后，我们使用训练数据集来训练模型，然后使用测试数据来测试模型的准确性。一个好的模型应该有一个有意义的准确度值（接近1）。下图描述了工作流程：
- en: '![](img/00252.jpeg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00252.jpeg)'
- en: 'A sample tree was generated based on the Wisconsin Breast Cancer dataset. The
    red spot represents malignant cases, and the blue ones the benign cases. We can
    examine the tree visually in the following figure:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 基于威斯康星乳腺癌数据集生成了一棵样本树。红点代表恶性病例，蓝点代表良性病例。我们可以在下图中直观地检查这棵树：
- en: '![](img/00253.jpeg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00253.jpeg)'
- en: See also
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for the constructor can be found at: [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree) and [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.DecisionTreeModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.DecisionTreeModel)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可以在以下网址找到：[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree)
    和 [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.DecisionTreeModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.DecisionTreeModel)
- en: Documentation for the Spark Matrix Evaluator can be found at [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics)
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark矩阵评估器的文档可以在以下网址找到：[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics)
- en: Solving Regression problems with Decision Trees in Spark 2.0
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中使用决策树解决回归问题
- en: Similar to the previous recipe, we will use the `DecisionTree()` class to train
    and predict an outcome using a regression tree model. To refresh all these models
    is a variation on **CART** (**Classification and Regression Tree**), which comes
    in two modes. In this recipe, we explore the regression API for the decision tree
    implementation in Spark.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的示例类似，我们将使用`DecisionTree()`类来训练和预测使用回归树模型的结果。刷新所有这些模型是**CART**（**分类和回归树**）的一个变体，有两种模式。在这个示例中，我们探索了Spark中决策树实现的回归API。
- en: How to do it...
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure the necessary
    JAR files are included.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Set up the package location where the program will reside:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置程序所在的包位置：
- en: '[PRE24]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Import the necessary packages for the Spark context to get access to the cluster
    and `Log4j.Logger` to reduce the amount of output produced by Spark:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入Spark上下文所需的必要包，以便访问集群和`Log4j.Logger`以减少Spark产生的输出量：
- en: '[PRE25]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Create Spark''s configuration and Spark session so we can have access to the
    cluster:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Spark的配置和Spark会话，以便我们可以访问集群：
- en: '[PRE26]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We read in the original raw data file:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们读取原始的原始数据文件：
- en: '[PRE27]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We pre-process the dataset (see the preceding code for details):'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们预处理数据集（详细信息请参见前面的代码）：
- en: '[PRE28]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We verify the raw data count and process the data count:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们验证原始数据计数并处理数据计数：
- en: '[PRE29]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'And you will see the following on the console:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在控制台上你会看到以下内容：
- en: '[PRE30]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We split the whole dataset into training data (70%) and test data (30%) sets:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将整个数据集分为训练数据（70%）和测试数据（30%）集：
- en: '[PRE31]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We define a metrics calculation function, which utilizes the Spark `RegressionMetrics`:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义一个度量计算函数，该函数利用Spark的`RegressionMetrics`：
- en: '[PRE32]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We set the following parameters:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们设置以下参数：
- en: '[PRE33]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We evaluate the Gini impurity first:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先评估基尼不纯度：
- en: '[PRE34]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'From the console output:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '[PRE35]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We then close the program by stopping the Spark session:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后通过停止Spark会话来关闭程序：
- en: '[PRE36]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: How it works...
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'We use the same dataset, but this time we use a Decision Tree to solve the
    regression problem with the data. Noteworthy is the creation of a metrics calculation
    function, which utilizes the Spark `RegressionMetrics()`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用相同的数据集，但这次我们使用决策树来解决数据的回归问题。值得注意的是创建一个度量计算函数，该函数利用Spark的`RegressionMetrics()`：
- en: '[PRE37]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We then proceed to perform the actual regression using `DecisionTree.trainRegressor()`
    and obtain the impurity measurement (GINI). We then proceed to output the actual
    regression, which is a series of decision nodes/branches and the value used to
    make a decision at the given branch:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们继续使用`DecisionTree.trainRegressor()`来执行实际的回归，并获得不纯度测量（GINI）。然后我们继续输出实际的回归，这是一系列决策节点/分支和用于在给定分支上做出决策的值：
- en: '[PRE38]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: See also
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for the constructor can be found in the following URLs [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree) and [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.DecisionTreeModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.DecisionTreeModel)
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可以在以下网址找到：[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree)
    和 [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.DecisionTreeModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.DecisionTreeModel)
- en: Documentation for the Spark Matrix Evaluator can be found at [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics)
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark Matrix Evaluator的文档可以在[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics)找到。
- en: Building a classification system with Random Forest Trees in Spark 2.0
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中使用随机森林树构建分类系统
- en: In this recipe, we will explore Random Forest implementation in Spark. We will
    use the Random Forest technique to solve a discrete classification problem. We
    found random forest implementation very fast due to Spark's exploitation of parallelism
    (growing many trees at once). We also do not need to worry too much about the
    hyper-parameters and technically we can get away with just setting the number
    of trees.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将探讨Spark中随机森林的实现。我们将使用随机森林技术来解决离散分类问题。由于Spark利用并行性（同时生长许多树），我们发现随机森林的实现非常快。我们也不需要太担心超参数，技术上我们只需设置树的数量。
- en: How to do it...
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure the necessary
    JAR files are included.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Set up the package location where the program will reside:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置程序将驻留的包位置：
- en: '[PRE39]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Import the necessary packages for the Spark context to get access to the cluster
    and `Log4j.Logger` to reduce the amount of output produced by Spark:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入Spark上下文所需的包，以便访问集群和`Log4j.Logger`以减少Spark产生的输出量：
- en: '[PRE40]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Create Spark''s configuration and Spark session so we can have access to the
    cluster:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Spark的配置和Spark会话，以便我们可以访问集群：
- en: '[PRE41]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We read in the original raw data file:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们读取原始原始数据文件：
- en: '[PRE42]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We pre-process the dataset (see the preceding session for details):'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对数据集进行预处理（有关详细信息，请参见前面的部分）：
- en: '[PRE43]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We verify the raw data count and process the data count:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们验证原始数据计数并处理数据计数：
- en: '[PRE44]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'And you will see the following in the console:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在控制台中看到以下内容：
- en: '[PRE45]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We split the whole dataset into training data (70%) and test data (30%) randomly:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将整个数据集随机分为训练数据（70%）和测试数据（30%）：
- en: '[PRE46]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We define a metrics calculation function, which utilizes the Spark `MulticlassMetrics`:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了一个度量计算函数，它利用了Spark的`MulticlassMetrics`：
- en: '[PRE47]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This function will read in the model and the test dataset, and create metrics
    that contain the confusion matrix mentioned earlier. It will contain model accuracy,
    which is one of the indicators for the classification model.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将读取模型和测试数据集，并创建包含先前提到的混淆矩阵的度量。它将包含模型准确性，这是分类模型的指标之一。
- en: 'We define an evaluate function, which can take some tunable parameters for
    the Random Forest model, and do the training for the dataset:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了一个评估函数，该函数可以接受一些可调参数，用于随机森林模型，并对数据集进行训练：
- en: '[PRE48]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The evaluate function will read in several parameters, including the impurity
    type (Gini or Entropy for the model) and generate the metrics for evaluations.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 评估函数将读取几个参数，包括不纯度类型（模型的基尼或熵）并生成用于评估的度量。
- en: 'We set the following parameters:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们设置了以下参数：
- en: '[PRE49]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We evaluate the Gini impurity first:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先评估基尼不纯度：
- en: '[PRE50]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'From the console output:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '[PRE51]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We evaluate the Entropy impurity:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们评估熵不纯度：
- en: '[PRE52]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'From the console output:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '[PRE53]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We then close the program by stopping the Spark session:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后通过停止Spark会话来关闭程序：
- en: '[PRE54]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: How it works...
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The data is the same as the data in the previous recipe, but we use Random
    Forest and the Multi metrics API to solve the classification problem:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 数据与前一个示例中的数据相同，但我们使用随机森林和多指标API来解决分类问题：
- en: '`RandomForest.trainClassifier()`'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RandomForest.trainClassifier()`'
- en: '`MulticlassMetrics()`'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MulticlassMetrics()`'
- en: 'We have a lot of options with Random Forest Trees that we can adjust to get
    the right edges for classifying complex surfaces. Some of the parameters are listed
    here:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有很多选项可以调整随机森林树，以获得分类复杂表面的正确边缘。这里列出了一些参数：
- en: '[PRE55]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Noteworthy is the confusion matrix in this recipe. The confusion matrix is
    obtained via the `MulticlassMetrics()` API call. To interpret the preceding confusion
    metrics, accuracy is equal to (118+ 59)/ 182 for all test cases, and error is
    equal to 1 -accuracy:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是这个示例中的混淆矩阵。混淆矩阵是通过`MulticlassMetrics()` API调用获得的。要解释前面的混淆度量，准确度等于（118+
    59）/ 182，对于所有测试案例，错误等于1-准确度：
- en: '[PRE56]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: See also
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for the constructor can be found in the following URLs [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest$](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest%24) [and ](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest%24)[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.RandomForestModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.RandomForestModel)
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可以在以下URL中找到 [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest$](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest%24) [和 ](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest%24)[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.RandomForestModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.RandomForestModel)
- en: Documentation for the Spark Matrix Evaluator can be found at [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics)
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark Matrix Evaluator的文档可以在[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics)找到。
- en: Solving regression problems with Random Forest Trees in Spark 2.0
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中使用随机森林树解决回归问题
- en: 'This is similar to the previous recipes, but we use Random Forest Trees to
    solve a regression problem (continuous). The following parameter is used to direct
    the algorithm to apply regression rather than classification. We again limit the
    number of classes to two:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这与之前的步骤类似，但我们使用随机森林树来解决回归问题（连续）。以下参数用于指导算法应用回归而不是分类。我们再次将类的数量限制为两个：
- en: '[PRE57]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: How to do it...
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure the necessary
    JAR files are included.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Set up the package location where the program will reside:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置程序所在的包位置：
- en: '[PRE58]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Import the necessary packages from Spark:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Spark中导入必要的包：
- en: '[PRE59]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Create Spark''s configuration and Spark session:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Spark的配置和Spark会话：
- en: '[PRE60]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'We read in the original raw data file:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们读取原始的原始数据文件：
- en: '[PRE61]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'We pre-process the dataset (see the preceding session for details):'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们预处理数据集（详情请参阅前面的部分）：
- en: '[PRE62]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We split the whole dataset into training data (70%) and test data (30%) randomly:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们随机将整个数据集分为训练数据（70%）和测试数据（30%）：
- en: '[PRE63]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'And you will see the following on the console:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在控制台上看到以下内容：
- en: '[PRE64]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'We define a metrics calculation function, which utilizes the Spark `RegressionMetrics`:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义一个度量计算函数，它利用Spark的`RegressionMetrics`：
- en: '[PRE65]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'We set the following parameters:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们设置以下参数：
- en: '[PRE66]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'From the console output:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '[PRE67]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'We then close the program by stopping the Spark session:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后通过停止Spark会话来关闭程序：
- en: '[PRE68]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: How it works...
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'We use the dataset and Random Forest Tree to solve a regression problem with
    the data. The mechanics of parsing and separating remains the same, but we use
    the following two APIs to do the tree regression and evaluate the results:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用数据集和随机森林树来解决数据的回归问题。解析和分离的机制仍然相同，但我们使用以下两个API来进行树回归和评估结果：
- en: '`RandomForest.trainRegressor()`'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RandomForest.trainRegressor()`'
- en: '`RegressionMetrics()`'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RegressionMetrics()`'
- en: 'Noteworthy is the definition of the `getMetrics()` function to utilize the
    `RegressionMetrics()` facility in Spark:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是定义`getMetrics()`函数以利用Spark中的`RegressionMetrics()`功能：
- en: '[PRE69]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'We also set the impurity value to "variance" so we can use the variance for
    measuring errors:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将杂质值设置为“方差”，以便我们可以使用方差来测量错误：
- en: '[PRE70]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: See also
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for the constructor can be found at the following URLs [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest$](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest%24) and [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.RandomForestModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.RandomForestModel)
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可以在以下网址找到：[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest$](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest%24)
    和 [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.RandomForestModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.RandomForestModel)
- en: Documentation for Spark Matrix Evaluator: [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics)
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark矩阵评估器的文档：[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics)
- en: Building a classification system with Gradient Boosted Trees (GBT) in Spark
    2.0
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中构建使用梯度提升树（GBT）的分类系统
- en: In this recipe, we will explore the Gradient Boosted Tree (GBT) classification
    implementation in Spark. The GBT requires more care with hyper-parameters and
    several tries before deciding the final outcome. One must remember that it is
    completely OK to grow shorter trees if using GBT.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个步骤中，我们将探讨Spark中梯度提升树（GBT）分类的实现。GBT在决定最终结果之前需要更多的超参数和多次尝试。必须记住，如果使用GBT，完全可以种植较短的树。
- en: How to do it...
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure the necessary
    JAR files are included.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Set up the package location where the program will reside:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置程序所在的包位置：
- en: '[PRE71]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Import the necessary packages for the Spark context:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为Spark上下文导入必要的包：
- en: '[PRE72]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Create Spark''s configuration and Spark session so we can have access to the
    cluster:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Spark的配置和Spark会话，以便我们可以访问集群：
- en: '[PRE73]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'We read in the original raw data file:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们读取原始的原始数据文件：
- en: '[PRE74]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'We pre-process the dataset (see the preceding session for details):'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们预处理数据集（详情请参阅前面的部分）：
- en: '[PRE75]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'We split the whole dataset into training data (70%) and test data (30%) randomly.
    Please note that the random split will generate around 211 test datasets. It''s
    approximately but NOT exactly 30% of the dataset:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们随机将整个数据集分为训练数据（70%）和测试数据（30%）。请注意，随机分割将生成大约211个测试数据集。这大约但并非完全是数据集的30%：
- en: '[PRE76]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'And you will see the on the console:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在控制台上看到：
- en: '[PRE77]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'We define a metrics calculation function, which utilizes the Spark `MulticlassMetrics`:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义一个度量计算函数，它利用Spark的`MulticlassMetrics`：
- en: '[PRE78]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'We define an evaluate function, which can take some tunable parameters for
    the Gradient Boosted Trees model, and do the training for the dataset:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义一个评估函数，该函数可以接受一些可调参数用于梯度提升树模型，并对数据集进行训练：
- en: '[PRE79]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'We set the following parameters:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们设置以下参数：
- en: '[PRE80]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'We evaluate the model using the preceding Strategy parameters:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用前面的策略参数评估模型：
- en: '[PRE81]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'From the console output:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '[PRE82]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'We then close the program by stopping the Spark session:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后通过停止Spark会话来关闭程序：
- en: '[PRE83]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: How it works....
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'We skip the data ingestion and parsing since it is similar to previous recipes,
    but what is different is how we set up the parameters, especially the use of "classification"
    as a parameter that we pass into `BoostingStrategy.defaultParams()`:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 我们跳过数据摄取和解析，因为这与之前的步骤类似，但不同的是我们如何设置参数，特别是将“classification”作为参数传递给`BoostingStrategy.defaultParams()`：
- en: '[PRE84]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'We also use the `evaluate()` function to evaluate the parameters by looking
    at impurity and the confusion matrix:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用`evaluate()`函数通过查看不纯度和混淆矩阵来评估参数：
- en: '[PRE85]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: There's more...
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: It is important to remember that the GBT is a multi-generational algorithm with
    the twist that we grow one tree at the time, learn from our mistakes, and then
    build the next tree in an iterative way.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住GBT是一个多代算法，我们一次生长一棵树，从错误中学习，然后以迭代的方式构建下一棵树。
- en: See also
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for the constructor can be found at the following URLs [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.GradientBoostedTrees](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.GradientBoostedTrees),
     [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.configuration.BoostingStrategy](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.configuration.BoostingStrategy) and [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.GradientBoostedTreesModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.GradientBoostedTreesModel)
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可以在以下网址找到：[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.GradientBoostedTrees](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.GradientBoostedTrees)、[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.configuration.BoostingStrategy](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.configuration.BoostingStrategy)和[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.GradientBoostedTreesModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.GradientBoostedTreesModel)
- en: Documentation for the Spark Matrix Evaluator can be found at [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics)
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark矩阵评估器的文档可以在[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.MulticlassMetrics)找到
- en: Solving regression problems with Gradient Boosted Trees (GBT) in Spark 2.0
  id: totrans-347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中使用Gradient Boosted Trees（GBT）解决回归问题
- en: 'This recipe is similar to the GBT classification problem, but we will use regression
    instead. We will use `BoostingStrategy.defaultParams()` to direct the GBT to use
    regression:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例与GBT分类问题类似，但我们将使用回归。我们将使用`BoostingStrategy.defaultParams()`来指示GBT使用回归：
- en: '[PRE87]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: How to do it...
  id: totrans-350
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure the necessary
    JAR files are included.
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Set up the package location where the program will reside:'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置程序所在的包位置：
- en: '``package spark.ml.cookbook.chapter10``.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '``package spark.ml.cookbook.chapter10``。'
- en: 'Import the necessary packages for the Spark context:'
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入Spark上下文所需的包：
- en: '[PRE88]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Create Spark''s configuration and Spark session:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Spark的配置和Spark会话：
- en: '[PRE89]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'We read in the original raw data file:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在原始的原始数据文件中阅读：
- en: '[PRE90]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'We pre-process the dataset (see the preceding session for details):'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对数据集进行预处理（有关详细信息，请参见前面的会话）：
- en: '[PRE91]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'We split the whole dataset into training data (70%) and test data (30%) randomly:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将整个数据集随机分为训练数据（70%）和测试数据（30%）：
- en: '[PRE92]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'And you will see the following in the console:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在控制台中看到以下内容：
- en: '[PRE93]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'We define a metrics calculation function, which utilizes the Spark `RegressionMetrics`:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义一个度量计算函数，它利用Spark的`RegressionMetrics`：
- en: '[PRE94]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'We set the following parameters:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们设置以下参数：
- en: '[PRE95]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'We evaluate the model using the preceding Strategy parameters:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用前面的策略参数评估模型：
- en: '[PRE96]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'From the console output:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '[PRE97]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'We then close the program by stopping the Spark session:'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们通过停止Spark会话来关闭程序：
- en: '[PRE98]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: How it works...
  id: totrans-376
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'We used the same GBT tree as the previous recipe, but we adjusted the parameters
    to direct the GBT API to perform regression as opposed to classification. It is
    noteworthy to compare the following code with the previous recipe. "Regression"
    is used to direct the GBT to perform regression on the data:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用与上一个示例相同的GBT树，但我们调整了参数，以指示GBT API执行回归而不是分类。值得注意的是将以下代码与上一个示例进行比较。 "回归"用于指示GBT对数据执行回归：
- en: '[PRE99]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'We use the following API to train and evaluate the metrics from the model:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下API来训练和评估模型的指标：
- en: '`GradientBoostedTrees.train()`'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GradientBoostedTrees.train()`'
- en: '`getMetrics()`'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getMetrics()`'
- en: 'The following snippet shows a typical output needed to examine the model:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了检查模型所需的典型输出：
- en: '[PRE100]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: There's more...
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: GBT can capture non-linearity and variable interaction in the same manner as
    Random Forest and can deal with multi-class labels as well.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: GBT可以像随机森林一样捕捉非线性和变量交互，并且可以处理多类标签。
- en: See also
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for the constructor can be found at the following URLs: [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.GradientBoostedTrees](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.GradientBoostedTrees), [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.configuration.BoostingStrategy](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.configuration.BoostingStrategy),
    and [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.GradientBoostedTreesModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.GradientBoostedTreesModel)
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可以在以下网址找到：[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.GradientBoostedTrees](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.GradientBoostedTrees)、[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.configuration.BoostingStrategy](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.configuration.BoostingStrategy)和[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.GradientBoostedTreesModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.GradientBoostedTreesModel)
- en: Documentation for the Spark Matrix Evaluator can be found at [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics)
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark Matrix Evaluator的文档可以在[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RegressionMetrics)找到。
