- en: Practical Machine Learning with Spark Using Scala
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Scala进行实用机器学习与Spark
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Downloading and installing the JDK
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载和安装JDK
- en: Downloading and installing IntelliJ
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载和安装IntelliJ
- en: Downloading and installing Spark
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载和安装Spark
- en: Configuring IntelliJ to work with Spark and run Spark ML sample codes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置IntelliJ以与Spark配合并运行Spark ML示例代码
- en: Running a sample ML code from Spark
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark运行示例ML代码
- en: Identifying data sources for practical machine learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定实际机器学习的数据来源
- en: Running your first program using Apache Spark 2.0 with the IntelliJ IDE
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用IntelliJ IDE运行第一个程序的Apache Spark 2.0
- en: How to add graphics to your Spark program
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将图形添加到您的Spark程序中
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: With the recent advancements in cluster computing coupled with the rise of big
    data, the field of machine learning has been pushed to the forefront of computing.
    The need for an interactive platform that enables data science at scale has long been
    a dream that is now a reality.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '随着集群计算的最新进展以及大数据的崛起，机器学习领域已经被推到了计算的前沿。长期以来，实现大规模数据科学的交互平台一直是一个现实的梦想。 '
- en: 'The following three areas together have enabled and accelerated interactive
    data science at scale:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 以下三个领域共同促成并加速了大规模交互式数据科学：
- en: '**Apache Spark**: A unified technology platform for data science that combines
    a fast compute engine and fault-tolerant data structures into a well-designed
    and integrated offering'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Spark**：一个统一的数据科学技术平台，将快速计算引擎和容错数据结构结合成一个设计良好且集成的产品'
- en: '**Machine learning**: A field of artificial intelligence that enables machines
    to mimic some of the tasks originally reserved exclusively for the human brain'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习**：一种人工智能领域，使机器能够模仿一些最初仅由人脑执行的任务'
- en: '**Scala**: A modern JVM-based language that builds on traditional languages,
    but unites functional and object-oriented concepts without the verboseness of
    other languages'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scala**：一种现代的基于JVM的语言，它建立在传统语言的基础上，但将函数式和面向对象的概念结合起来，而不像其他语言那样冗长。'
- en: 'First, we need to set up the development environment, which will consist of
    the following components:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要设置开发环境，其中将包括以下组件：
- en: Spark
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark
- en: IntelliJ community edition IDE
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IntelliJ社区版IDE
- en: Scala
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scala
- en: The recipes in this chapter will give you detailed instructions for installing
    and configuring the IntelliJ IDE, Scala plugin, and Spark. After the development
    environment is set up, we'll proceed to run one of the Spark ML sample codes to
    test the setup.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的配方将为您提供安装和配置IntelliJ IDE、Scala插件和Spark的详细说明。设置开发环境后，我们将继续运行Spark ML示例代码之一，以测试设置。
- en: Apache Spark
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark
- en: Apache Spark is emerging as the de facto platform and trade language for big
    data analytics and as a complement to the **Hadoop** paradigm. Spark enables a
    data scientist to work in the manner that is most conducive to their workflow
    right out of the box. Spark's approach is to process the workload in a completely
    distributed manner without the need for **MapReduce** (**MR**) or repeated writing
    of the intermediate results to a disk.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark正在成为大数据分析的事实标准平台和交易语言，作为**Hadoop**范例的补充。Spark使数据科学家能够立即按照最有利于其工作流程的方式工作。Spark的方法是在完全分布式的方式处理工作负载，而无需**MapReduce**（**MR**）或将中间结果重复写入磁盘。
- en: Spark provides an easy-to-use distributed framework in a unified technology
    stack, which has made it the platform of choice for data science projects, which
    more often than not require an iterative algorithm that eventually merges toward
    a solution. These algorithms, due to their inner workings, generate a large amount
    of intermediate results that need to go from one stage to the next during the
    intermediate steps. The need for an interactive tool with a robust native distributed
    **machine learning library** (**MLlib**) rules out a disk-based approach for most
    of the data science projects.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供了一个易于使用的统一技术堆栈中的分布式框架，这使得它成为数据科学项目的首选平台，这些项目往往需要一个最终朝着解决方案合并的迭代算法。由于其内部工作原理，这些算法生成大量中间结果，这些结果需要在中间步骤中从一阶段传递到下一阶段。对于大多数数据科学项目来说，需要一个具有强大本地分布式**机器学习库**（**MLlib**）的交互式工具，这排除了基于磁盘的方法。
- en: Spark has a different approach toward cluster computing. It solves the problem
    as a technology stack rather than as an ecosystem. A large number of centrally
    managed libraries combined with a lightning-fast compute engine that can support
    fault-tolerant data structures has poised Spark to take over Hadoop as the preferred
    big data platform for analytics.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Spark对集群计算有不同的方法。它解决问题的方式是作为技术堆栈而不是生态系统。大量集中管理的库与一个快速的计算引擎相结合，可以支持容错数据结构，这使得Spark成为首选的大数据分析平台，取代了Hadoop。
- en: 'Spark has a modular approach, as depicted in the following diagram:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Spark采用模块化方法，如下图所示：
- en: '![](img/00005.jpeg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00005.jpeg)'
- en: Machine learning
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: The aim of machine learning is to produce machines and devices that can mimic
    human intelligence and automate some of the tasks that have been traditionally
    reserved for a human brain. Machine learning algorithms are designed to go through
    very large data sets in a relatively short time and approximate answers that would
    have taken a human much longer to process.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的目标是生产可以模仿人类智能并自动执行一些传统上由人脑保留的任务的机器和设备。机器学习算法旨在在相对较短的时间内处理非常大的数据集，并近似得出人类需要更长时间处理的答案。
- en: The field of machine learning can be classified into many forms and at a high
    level, it can be classified as supervised and unsupervised learning. Supervised
    learning algorithms are a class of ML algorithms that use a training set (that
    is, labeled data) to compute a probabilistic distribution or graphical model that
    in turn allows them to classify the new data points without further human intervention.
    Unsupervised learning is a type of machine learning algorithm used to draw inferences
    from datasets consisting of input data without labeled responses.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习领域可以分为许多形式，从高层次上来看，可以分为监督学习和无监督学习。监督学习算法是一类使用训练集（即标记数据）来计算概率分布或图形模型的机器学习算法，从而使它们能够对新数据点进行分类，而无需进一步的人为干预。无监督学习是一种用于从不带标记响应的输入数据集中推断的机器学习算法。
- en: 'Out of the box, Spark offers a rich set of ML algorithms that can be deployed
    on large datasets without any further coding. The following figure depicts Spark''s
    MLlib algorithms as a mind map. Spark''s MLlib is designed to take advantage of
    parallelism while having fault-tolerant distributed data structures. Spark refers
    to such data structures as **Resilient Distributed Datasets** or **RDDs**:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供了丰富的机器学习算法，可以在大型数据集上部署，无需进一步编码。下图描述了Spark的MLlib算法作为思维导图。Spark的MLlib旨在利用并行性，同时具有容错的分布式数据结构。Spark将这些数据结构称为**弹性分布式数据集**或**RDDs**：
- en: '![](img/00006.jpeg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00006.jpeg)'
- en: Scala
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala
- en: '**Scala** is a modern programming language that is emerging as an alternative
    to traditional programming languages such as **Java** and **C++**. Scala is a
    JVM-based language that not only offers a concise syntax without the traditional
    boilerplate code, but also incorporates both object-oriented and functional programming
    into an extremely crisp and extraordinarily powerful type-safe language.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**Scala**是一种现代编程语言，正在成为传统编程语言（如**Java**和**C++**）的替代品。Scala是一种基于JVM的语言，不仅提供了简洁的语法，而且还将面向对象和函数式编程结合到了一个极其简洁和非常强大的类型安全语言中。'
- en: Scala takes a flexible and expressive approach, which makes it perfect for interacting
    with Spark's MLlib. The fact that Spark itself is written in Scala provides a
    strong evidence that the Scala language is a full-service programming language
    that can be used to create sophisticated system code with heavy performance needs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Scala采用灵活和富有表现力的方法，使其非常适合与Spark的MLlib交互。Spark本身是用Scala编写的事实证明了Scala语言是一种全方位的编程语言，可以用来创建具有重大性能需求的复杂系统代码。
- en: Scala builds on Java's tradition by addressing some of its shortcomings, while
    avoiding an all-or-nothing approach. Scala code compiles into Java bytecode, which
    in turn makes it possible to coexist with rich Java libraries interchangeably.
    The ability to use Java libraries with Scala and vice versa provides continuity
    and a rich environment for software engineers to build modern and complex machine
    learning systems without being fully disconnected from the Java tradition and
    code base.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Scala通过解决一些Java的缺点，同时避免了全有或全无的方法，继承了Java的传统。Scala代码编译成Java字节码，从而使其能够与丰富的Java库互换使用。能够在Scala和Java之间使用Java库提供了连续性和丰富的环境，使软件工程师能够构建现代和复杂的机器学习系统，而不必完全脱离Java传统和代码库。
- en: Scala fully supports a feature-rich functional programming paradigm with standard
    support for lambda, currying, type interface, immutability, lazy evaluation, and
    a pattern-matching paradigm reminiscent of Perl without the cryptic syntax. Scala
    is an excellent match for machine learning programming due to its support for
    algebra-friendly data types, anonymous functions, covariance, contra-variance,
    and higher-order functions.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Scala完全支持功能丰富的函数式编程范式，标准支持lambda、柯里化、类型接口、不可变性、惰性求值和一种类似Perl的模式匹配范式，而不带有神秘的语法。由于Scala支持代数友好的数据类型、匿名函数、协变、逆变和高阶函数，因此Scala非常适合机器学习编程。
- en: 'Here''s a hello world program in Scala:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是Scala中的hello world程序：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Compiling and running `HelloWorld` in Scala looks like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在Scala中编译和运行`HelloWorld`看起来像这样：
- en: '![](img/00007.jpeg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00007.jpeg)'
- en: 'The Apache Spark Machine Learning Cookbook takes a practical approach by offering
    a multi-disciplinary view with the developer in mind. This book focuses on the
    interactions and cohesiveness of **machine learning**, **Apache Spark**, and **Scala**.
    We also take an extra step and teach you how to set up and run a comprehensive
    development environment familiar to a developer and provide code snippets that
    you have to run in an interactive shell without the modern facilities that an
    IDE provides:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 《Apache Spark机器学习食谱》采用实用的方法，以开发人员为重点提供多学科视角。本书侧重于**机器学习**、**Apache Spark**和**Scala**的交互和凝聚力。我们还采取额外步骤，教您如何设置和运行开发环境，使其熟悉开发人员，并提供必须在交互式shell中运行的代码片段，而不使用现代IDE提供的便利设施：
- en: '![](img/00008.jpeg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00008.jpeg)'
- en: Software versions and libraries used in this book
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书中使用的软件版本和库
- en: 'The following table provides a detailed list of software versions and libraries
    used in this book. If you follow the installation instructions covered in this
    chapter, it will include most of the items listed here. Any other JAR or library
    files that may be required for specific recipes are covered via additional installation
    instructions in the respective recipes:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格提供了本书中使用的软件版本和库的详细列表。如果您按照本章中的安装说明进行安装，将包括此处列出的大部分项目。可能需要特定配方的任何其他JAR或库文件都将通过各自配方中的额外安装说明进行覆盖：
- en: '| **Core systems** | **Version** |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| **核心系统** | **版本** |'
- en: '| Spark | 2.0.0 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| Spark | 2.0.0 |'
- en: '| Java | 1.8 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| Java | 1.8 |'
- en: '| IntelliJ IDEA | 2016.2.4 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| IntelliJ IDEA | 2016.2.4 |'
- en: '| Scala-sdk | 2.11.8 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| Scala-sdk | 2.11.8 |'
- en: 'Miscellaneous JARs that will be required are as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 将需要的其他JAR如下：
- en: '| **Miscellaneous JARs** | **Version** |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| **其他JAR** | **版本** |'
- en: '| `bliki-core` | 3.0.19 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `bliki-core` | 3.0.19 |'
- en: '| `breeze-viz` | 0.12 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `breeze-viz` | 0.12 |'
- en: '| `Cloud9` | 1.5.0 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| `Cloud9` | 1.5.0 |'
- en: '| `Hadoop-streaming` | 2.2.0 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| `Hadoop-streaming` | 2.2.0 |'
- en: '| `JCommon` | 1.0.23 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| `JCommon` | 1.0.23 |'
- en: '| `JFreeChart` | 1.0.19 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| `JFreeChart` | 1.0.19 |'
- en: '| `lucene-analyzers-common` | 6.0.0 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| `lucene-analyzers-common` | 6.0.0 |'
- en: '| `Lucene-Core` | 6.0.0 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| `Lucene-Core` | 6.0.0 |'
- en: '| `scopt` | 3.3.0 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| `scopt` | 3.3.0 |'
- en: '| `spark-streaming-flume-assembly` | 2.0.0 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| `spark-streaming-flume-assembly` | 2.0.0 |'
- en: '| `spark-streaming-kafka-0-8-assembly` | 2.0.0 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| `spark-streaming-kafka-0-8-assembly` | 2.0.0 |'
- en: We have additionally tested all the recipes in this book on Spark 2.1.1 and
    found that the programs executed as expected. It is recommended for learning purposes
    you use the software versions and libraries listed in these tables.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在Spark 2.1.1上测试了本书中的所有配方，并发现程序按预期执行。建议您在学习目的上使用这些表中列出的软件版本和库。
- en: To stay current with the rapidly changing Spark landscape and documentation,
    the API links to the Spark documentation mentioned throughout this book point
    to the latest version of Spark 2.x.x, but the API references in the recipes are
    explicitly for Spark 2.0.0.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟上快速变化的Spark领域和文档，本书中提到的Spark文档的API链接指向Spark 2.x.x的最新版本，但是配方中的API引用明确是针对Spark
    2.0.0的。
- en: 'All the Spark documentation links provided in this book will point to the latest
    documentation on Spark''s website. If you prefer to look for documentation for
    a specific version of Spark (for example, Spark 2.0.0), look for relevant documentation
    on the Spark website using the following URL:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 本书提供的所有Spark文档链接都将指向Spark网站上的最新文档。如果您希望查找特定版本的Spark文档（例如，Spark 2.0.0），请使用以下URL在Spark网站上查找相关文档：
- en: '[https://spark.apache.org/documentation.html](https://spark.apache.org/documentation.html)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/documentation.html](https://spark.apache.org/documentation.html)'
- en: We've made the code as simple as possible for clarity purposes rather than demonstrating
    the advanced features of Scala.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将代码尽可能简化，以便清晰地展示，而不是展示Scala的高级功能。
- en: Downloading and installing the JDK
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载和安装JDK
- en: The first step is to download the JDK development environment that is required
    for Scala/Spark development.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是下载Scala/Spark开发所需的JDK开发环境。
- en: Getting ready
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'When you are ready to download and install the JDK, access the following link:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当您准备好下载和安装JDK时，请访问以下链接：
- en: '[http://www.oracle.com/technetwork/java/javase/downloads/index.html](http://www.oracle.com/technetwork/java/javase/downloads/index.html)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.oracle.com/technetwork/java/javase/downloads/index.html](http://www.oracle.com/technetwork/java/javase/downloads/index.html)'
- en: How to do it...
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: After successful download, follow the on-screen instructions to install the
    JDK.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下载成功后，请按照屏幕上的说明安装JDK。
- en: Downloading and installing IntelliJ
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载和安装IntelliJ
- en: IntelliJ Community Edition is a lightweight IDE for Java SE, Groovy, Scala,
    and Kotlin development. To complete setting up your machine learning with the
    Spark development environment, the IntelliJ IDE needs to be installed.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: IntelliJ Community Edition是用于Java SE、Groovy、Scala和Kotlin开发的轻量级IDE。为了完成设置您的机器学习与Spark开发环境，需要安装IntelliJ
    IDE。
- en: Getting ready
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'When you are ready to download and install IntelliJ, access the following link:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当您准备好下载和安装IntelliJ时，请访问以下链接：
- en: '[https://www.jetbrains.com/idea/download/](https://www.jetbrains.com/idea/download/)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.jetbrains.com/idea/download/](https://www.jetbrains.com/idea/download/)'
- en: How to do it...
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'At the time of writing, we are using IntelliJ version 15.x or later (for example,
    version 2016.2.4) to test the examples in the book, but feel free to download
    the latest version. Once the installation file is downloaded, double-click on
    the downloaded file (`.exe`) and begin to install the IDE. Leave all the installation
    options at the default settings if you do not want to make any changes. Follow
    the on-screen instructions to complete the installation:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，我们使用的是IntelliJ 15.x或更高版本（例如，版本2016.2.4）来测试本书中的示例，但是请随时下载最新版本。下载安装文件后，双击下载的文件（.exe）并开始安装IDE。如果您不想进行任何更改，请将所有安装选项保持默认设置。按照屏幕上的说明完成安装：
- en: '![](img/00009.jpeg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00009.jpeg)'
- en: Downloading and installing Spark
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载和安装Spark
- en: We now proceed to download and install Spark.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们继续下载和安装Spark。
- en: Getting ready
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'When you are ready to download and install Spark, access the Apache website
    at this link:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当您准备好下载和安装Spark时，请访问Apache网站上的此链接：
- en: '[http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)'
- en: How to do it...
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Go to the Apache website and select the required download parameters, as shown
    in this screenshot:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 转到Apache网站并选择所需的下载参数，如此屏幕截图所示：
- en: '![](img/00010.jpeg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00010.jpeg)'
- en: Make sure to accept the default choices (click on Next) and proceed with the
    installation.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 确保接受默认选择（点击下一步）并继续安装。
- en: Configuring IntelliJ to work with Spark and run Spark ML sample codes
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置IntelliJ以便与Spark一起工作并运行Spark ML示例代码
- en: We need to run some configurations to ensure that the project settings are correct
    before being able to run the samples that are provided by Spark or any of the
    programs listed this book.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在能够运行Spark提供的示例或本书中列出的任何程序之前，我们需要运行一些配置以确保项目设置正确。
- en: Getting ready
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We need to be particularly careful when configuring the project structure and
    global libraries. After we set everything up, we proceed to run the sample ML
    code provided by the Spark team to verify the setup. Sample code can be found
    under the Spark directory or can be obtained by downloading the Spark source code
    with samples.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置项目结构和全局库时，我们需要特别小心。设置好一切后，我们继续运行Spark团队提供的示例ML代码以验证设置。示例代码可以在Spark目录下找到，也可以通过下载带有示例的Spark源代码获得。
- en: How to do it...
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The following are the steps for configuring IntelliJ to work with Spark MLlib
    and for running the sample ML code provided by Spark in the examples directory.
    The examples directory can be found in your home directory for Spark. Use the
    Scala samples to proceed:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是配置IntelliJ以使用Spark MLlib并在示例目录中运行Spark提供的示例ML代码的步骤。示例目录可以在Spark的主目录中找到。使用Scala示例继续：
- en: 'Click on the Project Structure... option, as shown in the following screenshot,
    to configure project settings:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击“Project Structure...”选项，如下截图所示，以配置项目设置：
- en: '![](img/00011.jpeg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00011.jpeg)'
- en: 'Verify the settings:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证设置：
- en: '![](img/00012.jpeg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00012.jpeg)'
- en: 'Configure Global Libraries. Select Scala SDK as your global library:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置全局库。选择Scala SDK作为全局库：
- en: '![](img/00013.jpeg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00013.jpeg)'
- en: 'Select the JARs for the new Scala SDK and let the download complete:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择新的Scala SDK的JAR文件并让下载完成：
- en: '![](img/00014.jpeg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00014.jpeg)'
- en: 'Select the project name:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择项目名称：
- en: '![](img/00015.jpeg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00015.jpeg)'
- en: 'Verify the settings and additional libraries:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证设置和额外的库：
- en: '![](img/00016.jpeg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00016.jpeg)'
- en: 'Add dependency JARs. Select modules under the Project Settings in the left-hand
    pane and click on dependencies to choose the required JARs, as shown in the following
    screenshot:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加依赖的JAR文件。在左侧窗格的项目设置下选择模块，然后单击依赖项选择所需的JAR文件，如下截图所示：
- en: '![](img/00017.jpeg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00017.jpeg)'
- en: 'Select the JAR files provided by Spark. Choose Spark''s default installation
    directory and then select the `lib` directory:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择Spark提供的JAR文件。选择Spark的默认安装目录，然后选择`lib`目录：
- en: '![](img/00018.jpeg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00018.jpeg)'
- en: We then select the JAR files for examples that are provided for Spark out of
    the box.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们选择提供给Spark的示例JAR文件。
- en: '![](img/00019.jpeg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00019.jpeg)'
- en: 'Add required JARs by verifying that you selected and imported all the JARs
    listed under `External Libraries` in the the left-hand pane:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过验证在左侧窗格中选择并导入所有列在`External Libraries`下的JAR文件来添加所需的JAR文件：
- en: '![](img/00020.jpeg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00020.jpeg)'
- en: 'Spark 2.0 uses Scala 2.11\. Two new streaming JARs, Flume and Kafka, are needed
    to run the examples, and can be downloaded from the following URLs:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spark 2.0使用Scala 2.11。运行示例需要两个新的流JAR文件，Flume和Kafka，并可以从以下URL下载：
- en: '[https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-flume-assembly_2.11/2.0.0/spark-streaming-flume-assembly_2.11-2.0.0.jar](https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-flume-assembly_2.11/2.0.0/spark-streaming-flume-assembly_2.11-2.0.0.jar)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-flume-assembly_2.11/2.0.0/spark-streaming-flume-assembly_2.11-2.0.0.jar](https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-flume-assembly_2.11/2.0.0/spark-streaming-flume-assembly_2.11-2.0.0.jar)'
- en: '[https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-8-assembly_2.11/2.0.0/spark-streaming-kafka-0-8-assembly_2.11-2.0.0.jar](https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-8-assembly_2.11/2.0.0/spark-streaming-kafka-0-8-assembly_2.11-2.0.0.jar)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-8-assembly_2.11/2.0.0/spark-streaming-kafka-0-8-assembly_2.11-2.0.0.jar](https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-8-assembly_2.11/2.0.0/spark-streaming-kafka-0-8-assembly_2.11-2.0.0.jar)'
- en: 'The next step is to download and install the Flume and Kafka JARs. For the
    purposes of this book, we have used the Maven repo:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是下载并安装Flume和Kafka的JAR文件。出于本书的目的，我们使用了Maven存储库：
- en: '![](img/00021.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00021.jpeg)'
- en: 'Download and install the Kafka assembly:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并安装Kafka组件：
- en: '![](img/00022.jpeg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00022.jpeg)'
- en: 'Download and install the Flume assembly:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并安装Flume组件：
- en: '![](img/00023.jpeg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00023.jpeg)'
- en: 'After the download is complete, move the downloaded JAR files to the `lib`
    directory of Spark. We used the `C` drive when we installed Spark:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载完成后，将下载的JAR文件移动到Spark的`lib`目录中。我们在安装Spark时使用了`C`驱动器：
- en: '![](img/00024.jpeg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00024.jpeg)'
- en: 'Open your IDE and verify that all the JARs under the `External Libraries` folder
    on the left, as shown in the following screenshot, are present in your setup:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开您的IDE并验证左侧的`External Libraries`文件夹中的所有JAR文件是否存在于您的设置中，如下截图所示：
- en: '![](img/00025.jpeg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00025.jpeg)'
- en: 'Build the example projects in Spark to verify the setup:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建Spark中的示例项目以验证设置：
- en: '![](img/00026.jpeg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00026.jpeg)'
- en: 'Verify that the build was successful:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证构建是否成功：
- en: '![](img/00027.jpeg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00027.jpeg)'
- en: There's more...
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Prior to Spark 2.0, we needed another library from Google called **Guava**
    for facilitating I/O and for providing a set of rich methods of defining tables
    and then letting Spark broadcast them across the cluster. Due to dependency issues
    that were hard to work around, Spark 2.0 no longer uses the Guava library. Make
    sure you use the Guava library if you are using Spark versions prior to 2.0 (required
    in version 1.5.2). The Guava library can be accessed at the following URL:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark 2.0之前，我们需要来自Google的另一个名为**Guava**的库来促进I/O并提供一组丰富的方法来定义表，然后让Spark在集群中广播它们。由于依赖问题很难解决，Spark
    2.0不再使用Guava库。如果您使用的是2.0之前的Spark版本（1.5.2版本需要），请确保使用Guava库。Guava库可以在以下URL中访问：
- en: '[https://github.com/google/guava/wiki](https://github.com/google/guava/wiki)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/google/guava/wiki](https://github.com/google/guava/wiki)'
- en: 'You may want to use Guava version 15.0, which can be found here:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想使用版本为15.0的Guava，可以在这里找到：
- en: '[https://mvnrepository.com/artifact/com.google.guava/guava/15.0](https://mvnrepository.com/artifact/com.google.guava/guava/15.0)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://mvnrepository.com/artifact/com.google.guava/guava/15.0](https://mvnrepository.com/artifact/com.google.guava/guava/15.0)'
- en: If you are using installation instructions from previous blogs, make sure to
    exclude the Guava library from the installation set.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用以前博客中的安装说明，请确保从安装集中排除Guava库。
- en: See also
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'If there are other third-party libraries or JARs required for the completion
    of the Spark installation, you can find those in the following Maven repository:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果还有其他第三方库或JAR文件需要完成Spark安装，您可以在以下Maven存储库中找到：
- en: '[https://repo1.maven.org/maven2/org/apache/spark/](https://repo1.maven.org/maven2/org/apache/spark/)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://repo1.maven.org/maven2/org/apache/spark/](https://repo1.maven.org/maven2/org/apache/spark/)'
- en: Running a sample ML code from Spark
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Spark运行示例ML代码
- en: We can verify the setup by simply downloading the sample code from the Spark
    source tree and importing it into IntelliJ to make sure it runs.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过简单地从Spark源树下载示例代码并将其导入到IntelliJ中来验证设置，以确保其运行。
- en: Getting ready
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: We will first run the logistic regression code from the samples to verify installation.
    In the next section, we proceed to write our own version of the same program and
    examine the output in order to understand how it works.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先运行逻辑回归代码从样本中验证安装。在下一节中，我们将继续编写同样程序的我们自己的版本，并检查输出以了解其工作原理。
- en: How to do it...
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Go to the source directory and pick one of the ML sample code files to run.
    We've selected the logistic regression example.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到源目录并选择要运行的ML样本代码文件。我们选择了逻辑回归示例。
- en: If you cannot find the source code in your directory, you can always download
    the Spark source, unzip, and then extract the examples directory accordingly.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在您的目录中找不到源代码，您可以随时下载Spark源代码，解压缩，然后相应地提取示例目录。
- en: 'After selecting the example, select Edit Configurations..., as shown in the
    following screenshot:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择示例后，选择编辑配置...，如下面的截图所示：
- en: '![](img/00028.jpeg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00028.jpeg)'
- en: 'In the Configurations tab, define the following options:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在配置选项卡中，定义以下选项：
- en: 'VM options: The choice shown allows you to run a standalone Spark cluster'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VM选项：所示的选择允许您运行独立的Spark集群
- en: 'Program arguments: What we are supposed to pass into the program'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序参数：我们应该传递给程序的内容
- en: '![](img/00029.jpeg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00029.jpeg)'
- en: 'Run the logistic regression by going to Run ''LogisticRegressionExample'',
    as shown in the following screenshot:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过转到运行'LogisticRegressionExample'来运行逻辑回归，如下面的截图所示：
- en: '![](img/00030.jpeg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00030.jpeg)'
- en: 'Verify the exit code and make sure it is as shown in the following screenshot:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证退出代码，并确保其如下面的截图所示：
- en: '![](img/00031.jpeg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00031.jpeg)'
- en: Identifying data sources for practical machine learning
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别实际机器学习的数据来源
- en: Getting data for machine learning projects was a challenge in the past. However,
    now there is a rich set of public data sources specifically suitable for machine
    learning.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 过去获取机器学习项目的数据是一个挑战。然而，现在有一套丰富的公共数据源，专门适用于机器学习。
- en: Getting ready
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: In addition to the university and government sources, there are many other open
    sources of data that can be used to learn and code your own examples and projects.
    We will list the data sources and show you how to best obtain and download data
    for each chapter.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 除了大学和政府来源外，还有许多其他开放数据源可用于学习和编写自己的示例和项目。我们将列出数据来源，并向您展示如何最好地获取和下载每一章的数据。
- en: How to do it...
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The following is a list of open source data worth exploring if you would like
    to develop applications in this field:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些值得探索的开源数据列表，如果您想在这个领域开发应用程序：
- en: '*UCI machine learning repository*: This is an extensive library with search
    functionality. At the time of writing, there were more than 350 datasets. You
    can click on the [https://archive.ics.uci.edu/ml/index.html](https://archive.ics.uci.edu/ml/index.html)
    link to see all the datasets or look for a specific set using a simple search
    (*Ctrl* + *F*).'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*UCI机器学习库*：这是一个具有搜索功能的广泛库。在撰写本文时，有超过350个数据集。您可以单击[https://archive.ics.uci.edu/ml/index.html](https://archive.ics.uci.edu/ml/index.html)链接查看所有数据集，或使用简单搜索（*Ctrl*
    + *F*）查找特定集。'
- en: '*Kaggle datasets*: You need to create an account, but you can download any
    sets for learning as well as for competing in machine learning competitions. The
    [https://www.kaggle.com/competitions](https://www.kaggle.com/competitions) link
    provides details for exploring and learning more about Kaggle, and the inner workings
    of machine learning competitions.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kaggle数据集*：您需要创建一个帐户，但您可以下载任何用于学习以及参加机器学习竞赛的数据集。 [https://www.kaggle.com/competitions](https://www.kaggle.com/competitions)链接提供了有关探索和了解Kaggle以及机器学习竞赛内部运作的详细信息。'
- en: '*MLdata.org*: A public site open to all with a repository of datasets for machine
    learning enthusiasts.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLdata.org*：一个向所有人开放的公共网站，其中包含机器学习爱好者的数据集存储库。'
- en: '*Google Trends*: You can find statistics on search volume (as a proportion
    of total search) for any given term since 2004 on [http://www.google.com/trends/explore](http://www.google.com/trends/explore).'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Google趋势*：您可以在[http://www.google.com/trends/explore](http://www.google.com/trends/explore)上找到自2004年以来任何给定术语的搜索量统计（作为总搜索量的比例）。'
- en: '*The CIA World Factbook*: The [https://www.cia.gov/library/publications/the-world-factbook/](https://www.cia.gov/library/publications/the-world-factbook/) link
    provides information on the history, population, economy, government, infrastructure,
    and military of 267 countries.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*中央情报局世界概况*：[https://www.cia.gov/library/publications/the-world-factbook/](https://www.cia.gov/library/publications/the-world-factbook/)链接提供了有关267个国家的历史、人口、经济、政府、基础设施和军事的信息。'
- en: See also
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'Other sources for machine learning data:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习数据的其他来源：
- en: 'SMS spam data: [http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 短信垃圾邮件数据：[http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)
- en: Financial dataset from Lending Club [https://www.lendingclub.com/info/download-data.action](https://www.lendingclub.com/info/download-data.action)
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自Lending Club的金融数据集[https://www.lendingclub.com/info/download-data.action](https://www.lendingclub.com/info/download-data.action)
- en: Research data from Yahoo [http://webscope.sandbox.yahoo.com/index.php](http://webscope.sandbox.yahoo.com/index.php)
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自Yahoo的研究数据[http://webscope.sandbox.yahoo.com/index.php](http://webscope.sandbox.yahoo.com/index.php)
- en: Amazon AWS public dataset [http://aws.amazon.com/public-data-sets/](http://aws.amazon.com/public-data-sets/)
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊AWS公共数据集[http://aws.amazon.com/public-data-sets/](http://aws.amazon.com/public-data-sets/)
- en: Labeled visual data from Image Net [http://www.image-net.org](http://www.image-net.org)
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自Image Net的标记视觉数据[http://www.image-net.org](http://www.image-net.org)
- en: Census datasets [http://www.census.gov](http://www.census.gov)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口普查数据集[http://www.census.gov](http://www.census.gov)
- en: Compiled YouTube dataset [http://netsg.cs.sfu.ca/youtubedata/](http://netsg.cs.sfu.ca/youtubedata/)
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译的YouTube数据集[http://netsg.cs.sfu.ca/youtubedata/](http://netsg.cs.sfu.ca/youtubedata/)
- en: Collected rating data from the MovieLens site [http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从MovieLens网站收集的评分数据[http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)
- en: Enron dataset available to the public [http://www.cs.cmu.edu/~enron/](http://www.cs.cmu.edu/~enron/)
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Enron数据集对公众开放[http://www.cs.cmu.edu/~enron/](http://www.cs.cmu.edu/~enron/)
- en: Dataset for the classic book elements of statistical learning [http://statweb.stanford.edu/~tibs/ElemStatLearn/data.htmlIMDB](http://statweb.stanford.edu/~tibs/ElemStatLearn/data.htmlIMDB)
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经典书籍《统计学习要素》的数据集[http://statweb.stanford.edu/~tibs/ElemStatLearn/data.htmlIMDB](http://statweb.stanford.edu/~tibs/ElemStatLearn/data.htmlIMDB)
- en: Movie dataset [http://www.imdb.com/interfaces](http://www.imdb.com/interfaces)
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影数据集[http://www.imdb.com/interfaces](http://www.imdb.com/interfaces)
- en: Million Song dataset [http://labrosa.ee.columbia.edu/millionsong/](http://labrosa.ee.columbia.edu/millionsong/)
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 百万歌曲数据集[http://labrosa.ee.columbia.edu/millionsong/](http://labrosa.ee.columbia.edu/millionsong/)
- en: Dataset for speech and audio [http://labrosa.ee.columbia.edu/projects/](http://labrosa.ee.columbia.edu/projects/)
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音和音频数据集[http://labrosa.ee.columbia.edu/projects/](http://labrosa.ee.columbia.edu/projects/)
- en: Face recognition data [http://www.face-rec.org/databases/](http://www.face-rec.org/databases/)
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸识别数据[http://www.face-rec.org/databases/](http://www.face-rec.org/databases/)
- en: Social science data [http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies](http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies)
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会科学数据[http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies](http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies)
- en: Bulk datasets from Cornell University [http://arxiv.org/help/bulk_data_s3](http://arxiv.org/help/bulk_data_s3)
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 康奈尔大学的大量数据集[http://arxiv.org/help/bulk_data_s3](http://arxiv.org/help/bulk_data_s3)
- en: Project Guttenberg datasets [http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs](http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs)
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guttenberg项目数据集[http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs](http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs)
- en: Datasets from World Bank [http://data.worldbank.org](http://data.worldbank.org)
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 世界银行的数据集[http://data.worldbank.org](http://data.worldbank.org)
- en: Lexical database from World Net [http://wordnet.princeton.edu](http://wordnet.princeton.edu)
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自World Net的词汇数据库[http://wordnet.princeton.edu](http://wordnet.princeton.edu)
- en: Collision data from NYPD [http://nypd.openscrape.com/#/](http://nypd.openscrape.com/#/)
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纽约市警察局的碰撞数据[http://nypd.openscrape.com/#/](http://nypd.openscrape.com/#/)
- en: Dataset for congressional row calls and others [http://voteview.com/dwnl.htm](http://voteview.com/dwnl.htm)
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 国会投票和其他数据集[http://voteview.com/dwnl.htm](http://voteview.com/dwnl.htm)
- en: Large graph datasets from Stanford [http://snap.stanford.edu/data/index.html](http://snap.stanford.edu/data/index.html)
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斯坦福大学的大型图数据集[http://snap.stanford.edu/data/index.html](http://snap.stanford.edu/data/index.html)
- en: Rich set of data from datahub [https://datahub.io/dataset](https://datahub.io/dataset)
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自datahub的丰富数据集[https://datahub.io/dataset](https://datahub.io/dataset)
- en: Yelp's academic dataset [https://www.yelp.com/academic_dataset](https://www.yelp.com/academic_dataset)
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yelp的学术数据集[https://www.yelp.com/academic_dataset](https://www.yelp.com/academic_dataset)
- en: Source of data from GitHub [https://github.com/caesar0301/awesome-public-datasets](https://github.com/caesar0301/awesome-public-datasets)
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自GitHub的数据来源[https://github.com/caesar0301/awesome-public-datasets](https://github.com/caesar0301/awesome-public-datasets)
- en: Dataset archives from Reddit [https://www.reddit.com/r/datasets/](https://www.reddit.com/r/datasets/)
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reddit的数据集存档[https://www.reddit.com/r/datasets/](https://www.reddit.com/r/datasets/)
- en: 'There are some specialized datasets (for example, text analytics in Spanish,
    and gene and IMF data) that might be of some interest to you:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些专门的数据集（例如，西班牙文本分析和基因和IMF数据）可能会引起您的兴趣：
- en: 'Datasets from Colombia (in Spanish): [http://www.datos.gov.co/frm/buscador/frmBuscador.aspx](http://www.datos.gov.co/frm/buscador/frmBuscador.aspx)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哥伦比亚的数据集（西班牙语）：[http://www.datos.gov.co/frm/buscador/frmBuscador.aspx](http://www.datos.gov.co/frm/buscador/frmBuscador.aspx)
- en: Dataset from cancer studies [http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi](http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi)
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 癌症研究数据集[http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi](http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi)
- en: Research data from Pew [http://www.pewinternet.org/datasets/](http://www.pewinternet.org/datasets/)
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pew的研究数据[http://www.pewinternet.org/datasets/](http://www.pewinternet.org/datasets/)
- en: Data from the state of Illinois/USA [https://data.illinois.gov](https://data.illinois.gov)
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自伊利诺伊州/美国的数据[https://data.illinois.gov](https://data.illinois.gov)
- en: Data from freebase.com [http://www.freebase.com](http://www.freebase.com)
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自freebase.com的数据[http://www.freebase.com](http://www.freebase.com)
- en: Datasets from the UN and its associated agencies [http://data.un.org](http://data.un.org)
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联合国及其相关机构的数据集[http://data.un.org](http://data.un.org)
- en: International Monetary Fund datasets [http://www.imf.org/external/data.htm](http://www.imf.org/external/data.htm)
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 国际货币基金组织数据集[http://www.imf.org/external/data.htm](http://www.imf.org/external/data.htm)
- en: UK government data [https://data.gov.uk](https://data.gov.uk)
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英国政府数据[https://data.gov.uk](https://data.gov.uk)
- en: Open data from Estonia [http://pub.stat.ee/px-web.2001/Dialog/statfile1.asp](http://pub.stat.ee/px-web.2001/Dialog/statfile1.asp)
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自爱沙尼亚的开放数据[http://pub.stat.ee/px-web.2001/Dialog/statfile1.asp](http://pub.stat.ee/px-web.2001/Dialog/statfile1.asp)
- en: Many ML libraries in R containing data that can be exported as CSV [https://www.r-project.org](https://www.r-project.org)
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R中的许多ML库包含可以导出为CSV的数据[https://www.r-project.org](https://www.r-project.org)
- en: Gene expression datasets [http://www.ncbi.nlm.nih.gov/geo/](http://www.ncbi.nlm.nih.gov/geo/)
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基因表达数据集[http://www.ncbi.nlm.nih.gov/geo/](http://www.ncbi.nlm.nih.gov/geo/)
- en: Running your first program using Apache Spark 2.0 with the IntelliJ IDE
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用IntelliJ IDE运行您的第一个Apache Spark 2.0程序
- en: The purpose of this program is to get you comfortable with compiling and running
    a recipe using the Spark 2.0 development environment you just set up. We will
    explore the components and steps in later chapters.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序的目的是让您熟悉使用刚刚设置的Spark 2.0开发环境编译和运行配方。我们将在后面的章节中探讨组件和步骤。
- en: We are going to write our own version of the Spark 2.0.0 program and examine
    the output so we can understand how it works. To emphasize, this short recipe
    is only a simple RDD program with Scala sugar syntax to make sure you have set
    up your environment correctly before starting to work with more complicated recipes.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将编写我们自己的版本的Spark 2.0.0程序，并检查输出，以便我们了解它是如何工作的。需要强调的是，这个简短的示例只是一个简单的RDD程序，使用Scala语法糖，以确保在开始处理更复杂的示例之前，您已经正确设置了环境。
- en: How to do it...
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: Download the sample code for the book, find the `myFirstSpark20.scala` file,
    and place the code in the following directory.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载本书的示例代码，找到`myFirstSpark20.scala`文件，并将代码放在以下目录中。
- en: We installed Spark 2.0 in the `C:\spark-2.0.0-bin-hadoop2.7\` directory on a
    Windows machine.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在Windows机器上的`C:\spark-2.0.0-bin-hadoop2.7\`目录中安装了Spark 2.0。
- en: 'Place the `myFirstSpark20.scala` file in the `C:\spark-2.0.0-bin-hadoop2.7\examples\src\main\scala\spark\ml\cookbook\chapter1` directory:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`myFirstSpark20.scala`文件放在`C:\spark-2.0.0-bin-hadoop2.7\examples\src\main\scala/spark/ml/cookbook/chapter1`目录中：
- en: '![](img/00032.jpeg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00032.jpeg)'
- en: Mac users note that we installed Spark 2.0 in the `/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/`
    directory on a Mac machine.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Mac用户在Mac机器上的`/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/`目录中安装了Spark
    2.0。
- en: Place the `myFirstSpark20.scala` file in the `/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/examples/src/main/scala/spark/ml/cookbook/chapter1`
    directory.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 将`myFirstSpark20.scala`文件放在`/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/examples/src/main/scala/spark/ml/cookbook/chapter1`目录中。
- en: 'Set up the package location where the program will reside:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置程序所在的包位置：
- en: '[PRE1]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Import the necessary packages for the Spark session to gain access to the cluster
    and `log4j.Logger` to reduce the amount of output produced by Spark:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入Spark会话所需的必要包，以便访问集群和`log4j.Logger`来减少Spark产生的输出量：
- en: '[PRE2]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Set output level to `ERROR` to reduce Spark''s logging output:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输出级别设置为`ERROR`以减少Spark的日志输出：
- en: '[PRE3]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Initialize a Spark session by specifying configurations with the builder pattern,
    thus making an entry point available for the Spark cluster:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用构建器模式指定配置来初始化Spark会话，从而使Spark集群的入口点可用：
- en: '[PRE4]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `myFirstSpark20` object will run in local mode. The previous code block
    is a typical way to start creating a `SparkSession` object.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '`myFirstSpark20`对象将在本地模式下运行。上一个代码块是开始创建`SparkSession`对象的典型方式。'
- en: 'We then create two array variables:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们创建了两个数组变量：
- en: '[PRE5]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We then let Spark create two RDDs based on the array created before:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后让Spark基于之前创建的数组创建两个RDD：
- en: '[PRE6]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we let Spark operate on the `RDD`; the `zip()` function will create a
    new `RDD` from the two RDDs mentioned before:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让Spark在`RDD`上操作；`zip()`函数将从之前提到的两个RDD创建一个新的`RDD`：
- en: '[PRE7]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the console output at runtime (more details on how to run the program in
    the IntelliJ IDE in the following steps), you will see this:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行时的控制台输出中（有关如何在IntelliJ IDE中运行程序的更多详细信息），您将看到这个：
- en: '![](img/00033.gif)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00033.gif)'
- en: 'Now, we sum up the value for `xRDD` and `yRDD` and calculate the new `zipedRDD`
    sum value. We also calculate the item count for `zipedRDD`:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们对`xRDD`和`yRDD`的值进行求和，并计算新的`zipedRDD`的总值。我们还计算了`zipedRDD`的项目计数：
- en: '[PRE8]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We print out the value calculated previously in the console:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在控制台中打印出先前计算的值：
- en: '[PRE9]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here''s the console output:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这是控制台输出：
- en: '![](img/00034.gif)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00034.gif)'
- en: 'We close the program by stopping the Spark session:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过停止Spark会话来关闭程序：
- en: '[PRE10]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Once the program is complete, the layout of `myFirstSpark20.scala` in the IntelliJ
    project explorer will look like the following:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序完成后，IntelliJ项目资源管理器中的`myFirstSpark20.scala`布局将如下所示：
- en: '![](img/00035.jpeg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00035.jpeg)'
- en: 'Make sure there is no compiling error. You can test this by rebuilding the
    project:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保没有编译错误。您可以通过重新构建项目来测试：
- en: '![](img/00036.jpeg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00036.jpeg)'
- en: 'Once the rebuild is complete, there should be a build completed message on
    the console:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 重建完成后，控制台上应该会有一个构建完成的消息：
- en: '[PRE11]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You can run the previous program by right-clicking on `the myFirstSpark20` object
    in the project explorer and selecting the context menu option (shown in the next
    screenshot) called `Run myFirstSpark20`.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过右键单击项目资源管理器中的`myFirstSpark20`对象，并选择上下文菜单选项（如下一截图所示）`Run myFirstSpark20`来运行上一个程序。
- en: You can also use the Run menu from the menu bar to perform the same action.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用菜单栏中的运行菜单执行相同的操作。
- en: '![](img/00037.jpeg)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00037.jpeg)'
- en: 'Once the program is successfully executed, you will see the following message:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序成功执行后，您将看到以下消息：
- en: '[PRE12]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This is also shown in the following screenshot:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这也显示在以下截图中：
- en: '![](img/00038.jpeg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00038.jpeg)'
- en: Mac users with IntelliJ will be able to perform this action using the same context
    menu.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用相同的上下文菜单，Mac用户可以执行此操作。
- en: Place the code in the correct path.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码放在正确的路径中。
- en: How it works...
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this example, we wrote our first Scala program, `myFirstSpark20.scala`, and
    displayed the steps to execute the program in IntelliJ. We placed the code in
    the path described in the steps for both Windows and Mac.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们编写了我们的第一个Scala程序`myFirstSpark20.scala`，并展示了在IntelliJ中执行程序的步骤。我们将代码放在了Windows和Mac的步骤中描述的路径中。
- en: In the `myFirstSpark20` code, we saw a typical way to create a `SparkSession`
    object and how to configure it to run in local mode using the `master()` function.
    We created two RDDs out of the array objects and used a simple `zip()` function
    to create a new RDD.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在`myFirstSpark20`代码中，我们看到了创建`SparkSession`对象的典型方式，以及如何使用`master()`函数将其配置为在本地模式下运行。我们从数组对象中创建了两个RDD，并使用简单的`zip()`函数创建了一个新的RDD。
- en: We also did a simple sum calculation on the RDDs that were created and then
    displayed the result in the console. Finally, we exited and released the resource
    by calling `spark.stop()`.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还对创建的RDD进行了简单的求和计算，然后在控制台中显示了结果。最后，我们通过调用`spark.stop()`退出并释放资源。
- en: There's more...
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Spark can be downloaded from [http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: Spark可以从[http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)下载。
- en: Documentation for Spark 2.0 related to RDD can be found at [http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations](http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 有关与RDD相关的Spark 2.0文档可以在[http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations](http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations)找到。
- en: See also
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: More information about JetBrain IntelliJ can be found at [https://www.jetbrains.com/idea/](https://www.jetbrains.com/idea/).
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关JetBrain IntelliJ的更多信息，请访问[https://www.jetbrains.com/idea/](https://www.jetbrains.com/idea/)。
- en: How to add graphics to your Spark program
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何将图形添加到您的Spark程序
- en: In this recipe, we discuss how to use JFreeChart to add a graphic chart to your
    Spark 2.0.0 program.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们讨论了如何使用JFreeChart将图形图表添加到您的Spark 2.0.0程序中。
- en: How to do it...
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Set up the JFreeChart library. JFreeChart JARs can be downloaded from the [https://sourceforge.net/projects/jfreechart/files/](https://sourceforge.net/projects/jfreechart/files/)
    site.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置JFreeChart库。可以从[https://sourceforge.net/projects/jfreechart/files/](https://sourceforge.net/projects/jfreechart/files/)网站下载JFreeChart
    JAR文件。
- en: 'The JFreeChart version we have covered in this book is JFreeChart 1.0.19, as
    can be seen in the following screenshot. It can be downloaded from the [https://sourceforge.net/projects/jfreechart/files/1.%20JFreeChart/1.0.19/jfreechart-1.0.19.zip/download](https://sourceforge.net/projects/jfreechart/files/1.%20JFreeChart/1.0.19/jfreechart-1.0.19.zip/download) site:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在本书中涵盖的JFreeChart版本是JFreeChart 1.0.19，如下截图所示。可以从[https://sourceforge.net/projects/jfreechart/files/1.%20JFreeChart/1.0.19/jfreechart-1.0.19.zip/download](https://sourceforge.net/projects/jfreechart/files/1.%20JFreeChart/1.0.19/jfreechart-1.0.19.zip/download)网站下载：
- en: '![](img/00039.jpeg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00039.jpeg)'
- en: Once the ZIP file is downloaded, extract it. We extracted the ZIP file under
    `C:\` for a Windows machine, then proceed to find the `lib` directory under the
    extracted destination directory.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦ZIP文件下载完成，解压它。我们在Windows机器上将ZIP文件解压到`C:\`，然后继续找到解压目标目录下的`lib`目录。
- en: 'We then find the two libraries we need (JFreeChart requires JCommon), `JFreeChart-1.0.19.jar`
    and `JCommon-1.0.23`:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后找到我们需要的两个库（JFreeChart需要JCommon），`JFreeChart-1.0.19.jar`和`JCommon-1.0.23`：
- en: '![](img/00040.jpeg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00040.jpeg)'
- en: Now we copy the two previously mentioned JARs into the `C:\spark-2.0.0-bin-hadoop2.7\examples\jars\`
    directory.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将之前提到的两个JAR文件复制到`C:\spark-2.0.0-bin-hadoop2.7\examples\jars\`目录中。
- en: 'This directory, as mentioned in the previous setup section, is in the classpath
    for the IntelliJ IDE project setting:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前面设置部分中提到的，此目录在IntelliJ IDE项目设置的类路径中：
- en: '![](img/00041.jpeg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00041.jpeg)'
- en: In macOS, you need to place the previous two JARs in the `/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/examples\jars\`
    directory.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在macOS中，您需要将前面提到的两个JAR文件放在`/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/examples\jars\`目录中。
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: Download the sample code for the book, find `MyChart.scala`, and place the code
    in the following directory.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载该书的示例代码，找到`MyChart.scala`，并将代码放在以下目录中。
- en: We installed Spark 2.0 in the `C:\spark-2.0.0-bin-hadoop2.7\` directory in Windows.
    Place `MyChart.scala` in the `C:\spark-2.0.0-bin-hadoop2.7\examples\src\main\scala\spark\ml\cookbook\chapter1`
    directory.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在Windows的`C:\spark-2.0.0-bin-hadoop2.7\`目录中安装了Spark 2.0。将`MyChart.scala`放在`C:\spark-2.0.0-bin-hadoop2.7\examples\src\main\scala\spark\ml\cookbook\chapter1`目录中。
- en: 'Set up the package location where the program will reside:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置程序将驻留的包位置：
- en: '[PRE13]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Import the necessary packages for the Spark session to gain access to the cluster
    and `log4j.Logger` to reduce the amount of output produced by Spark.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入Spark会话所需的包，以便访问集群和`log4j.Logger`以减少Spark产生的输出量。
- en: 'Import necessary JFreeChart packages for the graphics:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入用于图形的必要JFreeChart包：
- en: '[PRE14]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Set the output level to `ERROR` to reduce Spark''s logging output:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输出级别设置为`ERROR`以减少Spark的日志输出：
- en: '[PRE15]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Initialize a Spark session specifying configurations with the builder pattern,
    thus making an entry point available for the Spark cluster:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用构建模式指定配置初始化Spark会话，从而为Spark集群提供入口点：
- en: '[PRE16]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `myChart` object will run in local mode. The previous code block is a typical
    start to creating a `SparkSession` object.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`myChart`对象将在本地模式下运行。前面的代码块是创建`SparkSession`对象的典型开始。'
- en: 'We then create an RDD using a random number and ZIP the number with its index:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们使用随机数创建一个RDD，并将数字与其索引进行压缩：
- en: '[PRE17]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We print out the RDD in the console:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在控制台打印出RDD：
- en: '[PRE18]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here is the console output:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 这是控制台输出：
- en: '![](img/00042.gif)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00042.gif)'
- en: 'We then create a data series for JFreeChart to display:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们为JFreeChart创建一个数据系列来显示：
- en: '[PRE19]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next, we create a chart object from JFreeChart''s `ChartFactory` and set up
    the basic configurations:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们从JFreeChart的`ChartFactory`创建一个图表对象，并设置基本配置：
- en: '[PRE20]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We get the plot object from the chart and prepare it to display graphics:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从图表中获取绘图对象，并准备显示图形：
- en: '[PRE21]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We configure the plot first:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先配置绘图：
- en: '[PRE22]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `configurePlot` function is defined as follows; it sets up some basic color
    schema for the graphical part:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`configurePlot`函数定义如下；它为图形部分设置了一些基本的颜色方案：'
- en: '[PRE23]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We now show the `chart`:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们展示`chart`：
- en: '[PRE24]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `show()` function is defined as follows. It is a very standard frame-based
    graphic-displaying function:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`show()`函数定义如下。这是一个非常标准的基于帧的图形显示函数：'
- en: '[PRE25]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Once `show(chart)` is executed successfully, the following frame will pop up:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦`show(chart)`成功执行，将弹出以下窗口：
- en: '![](img/00043.jpeg)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00043.jpeg)'
- en: 'We close the program by stopping the Spark session:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过停止Spark会话来关闭程序：
- en: '[PRE26]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How it works...
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this example, we wrote `MyChart.scala` and saw the steps for executing the
    program in IntelliJ. We placed code in the path described in the steps for both
    Windows and Mac.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们编写了`MyChart.scala`，并看到了在IntelliJ中执行程序的步骤。我们在Windows和Mac的步骤中描述的路径中放置了代码。
- en: In the code, we saw a typical way to create the `SparkSession` object and how
    to use the `master()` function. We created an RDD out of an array of random integers
    in the range of 1 to 15 and zipped it with the Index.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，我们看到了创建`SparkSession`对象的典型方式以及如何使用`master()`函数。我们从1到15范围内的随机整数数组创建了一个RDD，并将其与索引进行了压缩。
- en: We then used JFreeChart to compose a basic chart that contains a simple *x*
    and *y* axis, and supplied the chart with the dataset we generated from the original
    RDD in the previous steps.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用JFreeChart来组合一个基本的图表，其中包含一个简单的*x*和*y*轴，并使用我们在前面步骤中从原始RDD生成的数据集来提供图表。
- en: We set up the schema for the chart and called the `show()` function in JFreeChart
    to show a Frame with the *x* and *y* axes displayed as a linear graphical chart.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为图表设置了架构，并调用了JFreeChart中的`show()`函数，以显示一个带有*x*和*y*轴的线性图表。
- en: Finally, we exited and released the resource by calling `spark.stop()`.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过调用`spark.stop()`退出并释放资源。
- en: There's more...
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'More about JFreeChart can be found here:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 有关JFreeChart的更多信息，请访问以下网站：
- en: '[http://www.jfree.org/jfreechart/](http://www.jfree.org/jfreechart/)'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.jfree.org/jfreechart/](http://www.jfree.org/jfreechart/)'
- en: '[http://www.jfree.org/jfreechart/api/javadoc/index.html](http://www.jfree.org/jfreechart/api/javadoc/index.html)'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.jfree.org/jfreechart/api/javadoc/index.html](http://www.jfree.org/jfreechart/api/javadoc/index.html)'
- en: See also
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'Additional examples about the features and capabilities of JFreeChart can be
    found at the following website:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 'Additional examples about the features and capabilities of JFreeChart can be
    found at the following website:'
- en: "[http://www.jfree.org/jfreechart/samples.html\uFEFF](http://www.jfree.org/jfreechart/samples.html)"
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: "[http://www.jfree.org/jfreechart/samples.html\uFEFF](http://www.jfree.org/jfreechart/samples.html)"
