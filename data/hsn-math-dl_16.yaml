- en: Transfer and Meta Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习与元学习
- en: So far in this book, we have studied a variety of neural networks and, as we
    have seen, each of them has its own strengths and weaknesses with regard to a
    variety of tasks. We have also learned that deep learning architectures require
    a large amount of training data because of their size and their large number of
    trainable parameters. As you can imagine, for a lot of the problems that we want
    to build models for, it may not be possible to collect enough data, and even if
    we are able to do so, this would be very difficult and time-consuming—perhaps
    even costly—to carry out. One way to combat this is to use generative models to
    create synthetic data (something we encountered in [Chapter 8](326a1ff5-cbf9-4318-9d85-8896cd47d0cd.xhtml),
    *Regularization*) that is generated from a small dataset that we collect for our
    task.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本书中，我们已经学习了各种神经网络，正如我们所见，每种神经网络在处理不同任务时都有其自身的优缺点。我们还了解到，深度学习架构由于其庞大的规模和大量可训练参数，往往需要大量的训练数据。正如你可以想象的，对于我们希望为之构建模型的许多问题，收集足够的数据可能是不可能的，即使能够收集到，这也将非常困难、耗时，甚至可能是昂贵的。一种应对之策是使用生成模型来创建合成数据（我们在[第8章](326a1ff5-cbf9-4318-9d85-8896cd47d0cd.xhtml)，*正则化*中提到过），这些数据是从我们为任务收集的小数据集生成的。
- en: In this chapter, we will cover two topics that have recently grown in popularity
    and are likely to continue to be more widely used in the field (and rightfully
    so). They are known as **transfer learning** and **meta learning**. The difference
    between them is that transfer learning is where we try to use what one model has
    learned to try and solve another different—but similar—problem, whereas meta learning
    is where we try to create models that can learn to learn new concepts. The literature
    on transfer learning is very sparse and it is a more hacky practice; we have mostly
    introduced it because it is important to understand the differences between transfer
    and meta learning since they are similar but quite different and are often confused.
    However, the focus of this chapter is meta learning. We will dive deeper into
    their distinctions as we progress through the chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍最近越来越受欢迎的两个主题，这些主题在这一领域的使用将会持续增长，且理应如此。它们分别是**迁移学习**和**元学习**。它们之间的区别在于，迁移学习是指我们尝试利用一个模型学到的知识来解决另一个不同但相似的问题，而元学习是指我们尝试创建可以学习如何学习新概念的模型。关于迁移学习的文献非常少，且其实践更为“黑客式”；我们主要介绍它是因为理解迁移学习和元学习之间的差异非常重要，因为它们看似相似，但本质上是不同的，且常常被混淆。然而，本章的重点是元学习。随着章节的进展，我们将深入探讨它们的区别。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Transfer learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移学习
- en: Meta learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元学习
- en: Transfer learning
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习
- en: We humans have an amazing ability to learn, and then we take what we have learned
    and apply the knowledge to different types of tasks. The more closely related
    the new task is to tasks we already know, the easier it is for us to solve the
    new task. Basically, we never really have to start from scratch when learning
    something new.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们人类有着惊人的学习能力，然后我们将所学的知识应用到不同类型的任务中。新任务与我们已经知道的任务越相似，我们解决新任务的难度就越小。基本上，我们在学习新事物时，几乎从来不需要完全从零开始。
- en: However, neural networks aren't afforded this same luxury; they need to be trained
    from scratch for each individual task we want to apply them to. As we have seen
    in previous chapters, neural networks are very good at learning how to do one
    thing very well, and because they only learn what lies within an interpolation
    of the distribution they have been trained to recognize, they are unable to generalize
    their knowledge to deal with tasks beyond what they have encountered in the training
    dataset.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，神经网络没有这种奢侈的选择；它们需要为我们希望应用的每个任务从零开始进行训练。正如我们在前几章中看到的那样，神经网络非常擅长学习如何做一件事，并且因为它们只学习训练集中的分布插值，因此它们无法将知识推广到训练数据集之外的任务。
- en: In addition, deep neural networks can require tens of millions of data samples
    in order to learn the latent patterns in the data before they are able to perform
    well. For this reason, researchers in the field created transfer learning—a way
    to transfer what one neural network has learned to another neural network, essentially
    bootstrapping the learning process. This is very handy when we have a project
    that we want to build or a hypothesis that we would like to test but we don't
    have the resources (such as GPUs, enough data, and so on) to build and train a
    network from scratch. Instead, we can use an existing model that works on a similar
    task and leverage it for our own task.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，深度神经网络可能需要数千万的数据样本，才能在数据中学习到潜在的模式，然后才有可能表现良好。正因为如此，研究人员在这个领域提出了迁移学习——一种将一个神经网络学到的知识转移到另一个神经网络上的方法，本质上是通过自举学习过程。这在我们有一个项目要构建或者有一个假设要测试，但又没有足够的资源（比如GPU、足够的数据等）从头开始构建和训练网络时，非常有用。相反，我们可以使用一个已经在类似任务上表现良好的现有模型，并将其用于我们自己的任务。
- en: Let's think back to [Chapter 9](2c830a26-9964-47fb-8d69-904e4f087b95.xhtml),
    *Convolutional Neural Networks*, for a moment. The architectures we saw all had
    an input layer that took in images of a certain size (*h* × *w* × *c*), and then
    we had multiple convolutional layers followed by an optional pooling (or subsampling)
    layer. Toward the end of the network, we unrolled the feature map into a fully
    connected layer, and then the output layer had as many nodes as classes we wanted
    to detect. We also learned that **Convolutional Neural Networks** (**CNNs**) can
    extract their own features and each layer learns different kinds or levels of
    features. The layers closer to the input learn very granular features, such as
    edges, curves, color blobs, and so on, while the layers closer to the output learn
    larger features, such as eyes, ears, tails, mouths, and so on.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微回想一下[第9章](2c830a26-9964-47fb-8d69-904e4f087b95.xhtml)，*卷积神经网络*。我们看到的架构都包含一个输入层，该输入层接受一定大小的图像（*h*
    × *w* × *c*），然后有多个卷积层，接着是一个可选的池化（或子采样）层。在网络的末尾，我们将特征图展开成全连接层，然后输出层的节点数与我们想要检测的类别数相同。我们还了解到，**卷积神经网络**（**CNNs**）可以提取自己的特征，每一层学习不同种类或层次的特征。离输入层更近的层学习非常细粒度的特征，例如边缘、曲线、颜色斑块等，而离输出层更近的层学习更大的特征，例如眼睛、耳朵、尾巴、嘴巴等。
- en: What we can do is take an existing trained CNN and remove the last few layers
    (that is, the fully connected layers and the output layer) and treat this CNN
    as a feature extractor for the new dataset we are building a model for. Alternatively,
    what we could also do is use an existing trained CNN for a new problem by fine-tuning
    it on the new dataset we want to create a CNN for. We can do this by freezing
    the earlier layers (since they learn very granular or generic features) and fine-tuning
    the latter layers using backpropagation so that the CNN learns more complex features
    that are specific to the new dataset.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做的是，取一个已经训练好的卷积神经网络（CNN），去掉最后几层（即全连接层和输出层），并将这个CNN作为新数据集的特征提取器，用于我们正在构建的模型。或者，我们还可以通过微调一个已经训练好的CNN，来解决一个新问题，针对我们想要创建CNN的新数据集进行微调。我们可以通过冻结前面的层（因为它们学习的是非常细粒度或通用的特征），然后使用反向传播微调后面的层，这样CNN就能学习到更复杂的特征，这些特征是特定于新数据集的。
- en: Before we get into the details of transfer learning, it is important that we
    have a clear understanding of it. We will use the definition given by Zhuang et
    al; but before that, let's revisit the definitions of a domain and a task.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨迁移学习的细节之前，理解它的定义非常重要。我们将采用Zhuang等人给出的定义；但在此之前，让我们回顾一下“领域”和“任务”的定义。
- en: A **domain**, [![](img/ecdb812d-9f63-4cc4-936a-a46ebdc8f667.png)], is composed
    of two parts; that is, a feature space, [![](img/b22a0031-59f3-49d7-aff3-f1f1ceeb885d.png)]
    , and a marginal distribution, *P(X)*. In other words, [![](img/f4c39005-71bd-4ce1-bd3c-37a3690dd64f.png)],
    where *X* denotes a data sample, which is defined as [![](img/5d9c50e3-d537-4b5a-ad6b-a6e55c947d22.png)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**领域**，[![](img/ecdb812d-9f63-4cc4-936a-a46ebdc8f667.png)]，由两部分组成；即特征空间，[![](img/b22a0031-59f3-49d7-aff3-f1f1ceeb885d.png)]，和边际分布，*P(X)*。换句话说，[![](img/f4c39005-71bd-4ce1-bd3c-37a3690dd64f.png)]，其中*X*表示一个数据样本，定义为[![](img/5d9c50e3-d537-4b5a-ad6b-a6e55c947d22.png)]。'
- en: A **task**, [![](img/646485a7-7078-432b-a0ad-210e59a18fe7.png)], consists of
    a label space, [![](img/6cc27b75-27bf-4f72-b71f-519a01fb5d58.png)], and a mapping
    function, *f*; that is, [![](img/49c753da-aa11-4cfb-9a48-e42c55ba50f3.png)]. The
    mapping function (our model) is an implicit one that is expected to be learned
    from the sample data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**任务**，[![](img/646485a7-7078-432b-a0ad-210e59a18fe7.png)]，由标签空间，[![](img/6cc27b75-27bf-4f72-b71f-519a01fb5d58.png)]，和映射函数，*f*，组成；即，[![](img/49c753da-aa11-4cfb-9a48-e42c55ba50f3.png)]。映射函数（我们的模型）是一个隐式的函数，期望从样本数据中学习。
- en: In the case of transfer learning, we have two distinct domains and tasks—each
    corresponding to a source and a target—where our goal is to transfer what a model
    has learned in the source domain to a model in the target domain in order to improve
    its overall performance.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在迁移学习的情况下，我们有两个不同的领域和任务——每个领域和任务都对应一个源和目标——我们的目标是将模型在源领域学到的知识迁移到目标领域的模型中，以提高其整体性能。
- en: 'Before we go further into the details of this, there are four concepts that
    are important for us to understand. They are as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨这个话题之前，有四个概念是我们必须理解的。它们如下：
- en: The feature space of the target domain, [![](img/0a72c0f6-3a96-4143-8842-bbff752b8afd.png)],
    and the source domain, [![](img/c00984a3-9026-4749-a016-872fe956bf77.png)], are
    not the same.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标领域的特征空间，[![](img/0a72c0f6-3a96-4143-8842-bbff752b8afd.png)]，和源领域的特征空间，[![](img/c00984a3-9026-4749-a016-872fe956bf77.png)]，是不相同的。
- en: The label space of the target domain, [![](img/d75d33b8-41c3-4f7b-a4d8-ec055aa56d6e.png)],
    and source domain, [![](img/e85c128c-f81f-4cc4-a81d-db2c97b521e5.png)], are not
    the same.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标领域的标签空间，[![](img/d75d33b8-41c3-4f7b-a4d8-ec055aa56d6e.png)]，和源领域的标签空间，[![](img/e85c128c-f81f-4cc4-a81d-db2c97b521e5.png)]，是不相同的。
- en: Domain adaptation—this is where the marginal probabilities of the target domain,
    *P(X[t])*, and the source domain, *P(X[s])*, are not equal.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领域自适应——这是指目标领域的边际概率，*P(X[t])*，和源领域的边际概率，*P(X[s])*，是不相等的。
- en: The conditional probabilities of the target domain, *P(Y[t]*|*X[t])*, and the
    source domain, *P(Y[s]*|*X[s])*, are not equal.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标领域的条件概率，*P(Y[t]*|*X[t])*，和源领域的条件概率，*P(Y[s]*|*X[s])*，是不相等的。
- en: As you can imagine, there are some limitations here as to what can be done.
    You cannot use just any pre-trained model of arbitrary size on another task. Consideration
    of the type of pre-trained network to use largely depends on whether the dataset
    we have for our task is similar to the one that the pre-trained model was trained
    on, and on the size of the dataset available to us for the current task at hand.
    For example, if we have an object detection task, we cannot use a pre-trained
    GAN or RNN for it since they are meant for different tasks. Additionally, if the
    model has been trained on images to recognize various farm animals, it will not
    perform well on a new task that wants our network to recognize the make and model
    of aircraft and cars.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所想象的，这里存在一些限制，决定了能够做什么。你不能将任何任意大小的预训练模型应用到另一个任务上。选择使用哪种预训练网络在很大程度上取决于我们当前任务的数据集与预训练模型所用的数据集是否相似，以及我们当前任务的可用数据集的大小。例如，如果我们有一个目标检测任务，我们不能使用预训练的GAN或RNN，因为它们是针对不同任务的。此外，如果模型已经在识别各种农场动物的图像上进行了训练，它在执行一个新任务时（如要求我们的网络识别飞机和汽车的品牌和型号）将表现不佳。
- en: Meta learning
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 元学习
- en: Meta learning—also known as **learning to learn**—is another fascinating topic
    within deep learning and is considered by many to be a promising path toward **Artificial
    General Intelligence** (**AGI**). For those of you who do not know what AGI is,
    it is when artificial intelligence reaches the capacity to understand and learn
    to do any type of intelligent task that a human is capable of doing, which is
    the goal of artificial intelligence.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习——也被称为**学习如何学习**——是深度学习中的另一个迷人话题，被许多人视为通向**人工通用智能**（**AGI**）的有前途的路径。对于那些不知道什么是AGI的人来说，它是指人工智能达到理解并学习执行任何人类能够完成的智能任务的能力，这是人工智能的目标。
- en: Deep neural networks, as we know, are very data-hungry and require a lot of
    training time (depending on the size of the model), which can sometimes be several
    weeks, whereas humans are able to learn new concepts and skills a lot faster and
    more efficiently. For example, as kids, we can quickly learn to tell the difference
    between a donkey, a horse, and a zebra with absolute certainty after only seeing
    them once or a handful of times; however, a neural network would likely need a
    few hundred thousand to 1 million data samples to be able to learn to differentiate
    between the three classes to expert-level accuracy.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所知，深度神经网络非常依赖数据，且需要大量的训练时间（取决于模型的大小），有时可能需要几周的时间，而人类则能更快、更高效地学习新概念和技能。例如，作为孩子，我们只需要看到一次或几次，就能迅速学会分辨驴、马和斑马，并能完全确定它们的区别；然而，神经网络可能需要几十万到一百万个数据样本，才能学习如何区分这三种类别并达到专家级的准确度。
- en: Approaches to meta learning
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 元学习方法
- en: The question we are trying to answer with meta learning is whether we can create
    a model that can learn as we do—that is, learn new concepts and skills to deal
    with new tasks with only a handful of training samples. So, in a nutshell, we
    want to find similarities between what we have learned and use this to learn to
    do new tasks faster. A good meta learning model is one that is trained on a number
    of tasks and has been optimized to perform well on them, as well as on tasks that
    it has not been trained on.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在元学习中试图回答的问题是，是否可以创建一个模型，让它像我们一样学习——也就是说，仅凭少量的训练样本，学习新的概念和技能来应对新任务。因此，简而言之，我们希望找到我们已学到的知识之间的相似性，并用它来加速学习新任务的过程。一个好的元学习模型应该是在多个任务上进行训练，并已优化以在这些任务上表现良好，同时也能在未见过的任务上表现出色。
- en: The deep neural networks that we have seen throughout this book so far all required
    millions of data samples, sometimes even several hundreds of millions. However,
    in meta learning, we want our model to learn using only a few samples; we refer
    to this as few-shot learning.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在本书中看到的深度神经网络都需要数百万个数据样本，有时甚至需要几亿个样本。然而，在元学习中，我们希望我们的模型仅使用少量样本进行学习；我们将其称为少样本学习。
- en: The problem of learning using only a few data samples is known as **few-shot
    learning** or **k-shot learning** (where *k* is the number of data samples for
    each class of the dataset). Suppose we have an image recognition problem with
    three classes—a donkey, a horse, and a zebra. If each class has 10 samples, then
    this is referred to as 10-shot learning. However, if each class has only 1 sample,
    then this is 1-shot learning. There could also be another interesting case where
    we have no data samples, which is known as **zero-shot learning**. (That's right,
    we can train a neural network without any data... just kidding! We use metadata
    instead; we'll learn about this soon.)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用仅有少量数据样本进行学习的问题被称为**少样本学习**或**k-shot学习**（其中*k*是每个类别的数据样本数量）。假设我们有一个图像识别问题，包含三个类别——驴、马和斑马。如果每个类别有10个样本，那么这就是10-shot学习。然而，如果每个类别只有1个样本，那么这就是1-shot学习。还有一种有趣的情况是，我们没有任何数据样本，这种情况被称为**零样本学习**。（没错，我们可以在没有数据的情况下训练神经网络...开个玩笑！我们会用元数据代替，稍后我们会学习到这部分内容。）
- en: If we have multiple classes in our dataset and we want to carry out few-shot
    learning, this is known as **n-way k-shot learning**, where *n* is the number
    of classes. In our case, we have 3 classes and 10 samples for each, so we are
    carrying out 3-way 10-shot learning.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的数据集中有多个类别，并且我们希望进行少样本学习，那么这就是**n类k-shot学习**，其中*n*是类别的数量。在我们的例子中，我们有3个类别，每个类别有10个样本，因此我们进行的是3类10-shot学习。
- en: 'Each of the preceding tasks will have an associated dataset, [![](img/3e14a459-4b46-4b59-866d-8e77f94da3fb.png)]
    (consisting of the data samples and the respective labels). As we know, our model,
    *f*, has trainable parameters, θ, so we can represent the model as learning the
    following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 每个前述任务都会有一个相关的数据集，[![](img/3e14a459-4b46-4b59-866d-8e77f94da3fb.png)]（包含数据样本和相应的标签）。如我们所知，我们的模型，*f*，有可训练的参数θ，因此我们可以将模型表示为学习以下内容：
- en: '![](img/89747e70-3e01-413a-a86f-6b50a854f36b.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/89747e70-3e01-413a-a86f-6b50a854f36b.png)'
- en: Here, [![](img/f5251024-813f-45c1-9aa3-98df285bcdd1.png)].
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，[![](img/f5251024-813f-45c1-9aa3-98df285bcdd1.png)]。
- en: For meta learning, we split our dataset into two portions—a support set, *S*,
    and a query set, *B*—such that [![](img/8da431f6-b85f-49ef-8f3c-68f33e00970b.png)].
    Then, we take a subset of the [![](img/f59a5a73-2b47-4d9b-9d2a-add6ce005c24.png)]
    labels, such that [![](img/ea8599d6-798e-4210-883c-15641271b9e4.png)]. We then
    train our model on the support set while testing on the query set, which we do
    in an episodic fashion. The support set is built through sampling from each of
    the classes of [![](img/5179ede3-ae6b-42fd-9ca4-6162de594436.png)] and the prediction
    set is built similarly using other samples from the same dataset. By using this
    method, our model gradually learns to learn from smaller datasets. We then calculate
    the loss of the model and optimize it using backpropagation using the training
    set, exactly as we did before.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于元学习，我们将数据集分为两部分——支持集，*S*，和查询集，*B*——使得[![](img/8da431f6-b85f-49ef-8f3c-68f33e00970b.png)]。然后，我们从[![](img/f59a5a73-2b47-4d9b-9d2a-add6ce005c24.png)]标签中提取一个子集，使得[![](img/ea8599d6-798e-4210-883c-15641271b9e4.png)]。接着，我们在支持集上训练模型，并在查询集上测试模型，采取的是一种情节式的方式。支持集是通过从[![](img/5179ede3-ae6b-42fd-9ca4-6162de594436.png)]的每个类别中采样来构建的，而预测集是通过使用同一数据集中的其他样本类似地构建的。通过这种方法，我们的模型逐渐学会从较小的数据集中学习。然后，我们计算模型的损失并使用反向传播优化它，正如我们之前所做的那样。
- en: 'The objective now looks as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的目标如下所示：
- en: '![](img/657b0bb3-059c-4fc1-8571-18726fdcc388.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/657b0bb3-059c-4fc1-8571-18726fdcc388.png)'
- en: As you can see, this is somewhat similar to transfer learning, except it goes
    a step further by optimizing to perform well over several tasks instead of just
    one.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这与迁移学习有些相似，不同之处在于它更进一步，优化以便能够在多个任务上表现良好，而不仅仅是一个任务。
- en: 'There are three types of meta learning approaches used in practice, as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 实践中使用了三种元学习方法，如下所示：
- en: Model-based
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于模型的
- en: Metric-based
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于度量的
- en: Optimization-based
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于优化的
- en: Model-based meta learning
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于模型的元学习
- en: In model-based meta learning, we want to create a model that is able to learn
    and update its parameters quickly using only a handful of training steps. We can
    do this internally (within the model) or externally (using another model). Let's
    now explore some of the methods.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于模型的元学习中，我们希望创建一个能够快速学习和更新其参数的模型，使用的训练步骤仅限于少数几步。我们可以在模型内部（模型内）或外部（使用另一个模型）执行此操作。现在让我们来探讨一些方法。
- en: Memory-augmented neural networks
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增强记忆的神经网络
- en: As the name suggests, **Memory-Augmented Neural Networks** (**MANNs**) are augmented
    using external memory (a storage buffer), which makes it easier for the model
    to learn and retain new information so as to not forget it later on. One of the
    approaches that is used is training a **Neural Turing Machine** (**NTM**) to learn
    a learning algorithm by altering the training setup and memory retrieval.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，**增强记忆神经网络**（**MANNs**）通过外部记忆（存储缓冲区）进行增强，这使得模型能够更容易地学习并保留新信息，从而避免之后遗忘。使用的一种方法是训练**神经图灵机**（**NTM**），通过改变训练设置和记忆检索来学习学习算法。
- en: 'To adapt an NTM for meta learning, we need it to be able to encode information
    related to new tasks quickly, while also ensuring that the stored information
    can be accessed quickly. The way this works is we pass the information at the
    present time step and the corresponding label at the next time step, which forces
    the network to retain information for longer. So, at each time step, the network
    receives the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将NTM应用于元学习，我们需要它能够快速编码与新任务相关的信息，同时确保存储的信息能够迅速被访问。其工作原理是，我们传递当前时间步的信息以及下一个时间步的相应标签，这迫使网络保持更长时间的信息。因此，在每个时间步，网络接收到以下内容：
- en: '![](img/211c364a-ba91-46e3-bfc7-12476389d646.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/211c364a-ba91-46e3-bfc7-12476389d646.png)'
- en: 'In the following diagram, we can observe what the network looks like:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们可以观察到网络的结构：
- en: '![](img/2c70726a-25f5-408f-aafc-2cacea4955a3.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2c70726a-25f5-408f-aafc-2cacea4955a3.png)'
- en: By providing the label later, the network is forced to memorize information
    so that when it is given the label, it can look back and recall the data to make
    a prediction. To ensure the model is best suited for meta learning, the reading
    and writing mechanisms have also been altered.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通过稍后提供标签，网络被迫记住信息，以便当给定标签时，它可以回顾并回忆数据进行预测。为了确保模型最适合元学习，读写机制也已被改变。
- en: 'Reading works using content similarity, as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 读取过程通过内容相似性来进行，如下所示：
- en: '![](img/ef80545a-3c43-4f8a-8908-d46fede66f9f.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef80545a-3c43-4f8a-8908-d46fede66f9f.png)'
- en: Here, [![](img/b48b2175-5db5-4b09-ba4d-766caeb7cf3a.png)], *k[t]* is a key feature
    vector output by the controller at the *t^(th)* time step, [![](img/813aced3-fc3d-442b-a971-17473301f348.png)]
    is a read weight over *N* elements calculated through the cosine similarity between
    each of the rows in memory, *k[t]* and *r[t]* are the sum of the weighted memory
    records, and *M[t]* is the memory matrix (while *M[t](i)* is its *i^(th)* row).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，[![](img/b48b2175-5db5-4b09-ba4d-766caeb7cf3a.png)]，*k[t]* 是控制器在 *t^(th)*
    时间步输出的关键特征向量，[![](img/813aced3-fc3d-442b-a971-17473301f348.png)] 是通过计算记忆中每一行与
    *k[t]* 和 *r[t]* 的余弦相似度来得到的 *N* 元素的读取权重，*k[t]* 和 *r[t]* 是加权记忆记录的总和，*M[t]* 是记忆矩阵（而
    *M[t](i)* 是它的 *i^(th)* 行）。
- en: Now, to write to memory, we use **Least Recently Used Access** (**LRUA**), which
    writes new information to the location where either the **Least Recently Used**
    (**LRU**) memory or **Most Frequently Used** (**MRU**) memory is stored. The reasoning
    for this is that by replacing the LRU memory, we will be able to maintain information
    that is used more frequently, and once the MRU memory is retrieved, it likely
    won't be needed for a while, so we can write over it.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了写入记忆，我们使用**最近最少使用访问** (**LRUA**)，它将新信息写入存储**最近最少使用** (**LRU**) 或**最常使用**
    (**MRU**) 内存的位置。这样做的原因是，通过替换LRU内存，我们能够保持更频繁使用的信息，而一旦MRU内存被检索，它可能很长一段时间都不需要，因此我们可以覆盖它。
- en: 'We compute LRUA using the following equations:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过以下公式计算LRUA：
- en: '[![](img/aa17376c-21bd-4235-9e8b-eccdb52733a3.png)]'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/aa17376c-21bd-4235-9e8b-eccdb52733a3.png)]'
- en: '[![](img/7905aa3d-1592-4b46-924a-9d88122cffc2.png)]'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/7905aa3d-1592-4b46-924a-9d88122cffc2.png)]'
- en: '[![](img/8518df2d-27ee-4355-b34c-b2fb3f41a7bb.png)]'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/8518df2d-27ee-4355-b34c-b2fb3f41a7bb.png)]'
- en: '[![](img/4c4e5760-0ea9-46d8-b78b-89cc6bace217.png)], where [![](img/faa1a309-c2b8-457b-ae46-14d8b529ccae.png)]
    is the *n^(th)* smallest element in [![](img/73327a01-6ae7-41bb-a471-698181df4224.png)]'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/4c4e5760-0ea9-46d8-b78b-89cc6bace217.png)]，其中 [![](img/faa1a309-c2b8-457b-ae46-14d8b529ccae.png)]
    是 [![](img/73327a01-6ae7-41bb-a471-698181df4224.png)] 中的 *n^(th)* 最小元素'
- en: 'In the last update equations, when the LRU memory is set to 0, each of the
    rows in memory is updated using the following equation:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后的更新公式中，当LRU内存设置为0时，记忆中的每一行都通过以下公式进行更新：
- en: '![](img/335ec747-d88d-443f-9596-c4e864759e77.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/335ec747-d88d-443f-9596-c4e864759e77.png)'
- en: Now that we have seen how meta learning can work using external memory to learn
    new information by overriding the information it hasn't used in a while, we will
    move on to another model-based meta learning approach, which uses its internal
    architecture to rapidly learn new information.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到如何通过使用外部记忆来进行元学习，通过覆盖一段时间未使用的信息来学习新信息，接下来我们将讨论另一种基于模型的元学习方法，该方法利用内部架构迅速学习新信息。
- en: Meta Networks
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 元网络
- en: '**Meta Networks** (**MetaNet**) is an architecture created to generalize across
    tasks quickly; it uses fast weights to do so. The reason they are called fast
    weights is that instead of using gradient descent to update weights as we normally
    do, we use a neural network to predict the weights for another neural network.
    The weights the other neural network generates are referred to as fast weights,
    while the weights that rely on gradient descent are referred to as slow weights.
    The effect of this is that it supports meta-level continual learning.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**元网络** (**MetaNet**) 是一种旨在快速泛化任务的架构；它使用快速权重来实现这一点。之所以称其为快速权重，是因为我们不再像通常那样使用梯度下降来更新权重，而是使用一个神经网络来预测另一个神经网络的权重。另一个神经网络生成的权重被称为快速权重，而依赖于梯度下降的权重则被称为慢速权重。这样做的效果是，它支持元级持续学习。'
- en: 'In the following figure, you can see the overall architecture of MetaNet:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，你可以看到MetaNet的整体架构：
- en: '![](img/7fa791b8-5de8-42b9-a0f7-2655055f620e.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7fa791b8-5de8-42b9-a0f7-2655055f620e.png)'
- en: MetaNet is comprised of two components—a meta learner, which learns an embedding
    function, *f[θ]*, to help determine the similarity between two data inputs and
    verify whether both inputs belong to the same class, and a base learner, *g[φ]*,
    which carries out the actual learning. As you can see in the preceding diagram,
    both the fast weights and the slow weights are summed together and input back
    into the model. Both the meta learner and the base learner have their own respective
    fast weights.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: MetaNet由两个组件组成——一个元学习者，它学习一个嵌入函数 *f[θ]*，帮助确定两个数据输入之间的相似性，并验证这两个输入是否属于同一类；另一个是基础学习者
    *g[φ]*，它执行实际的学习。正如前面的图示所示，快速权重和慢速权重都会加在一起并重新输入到模型中。元学习者和基础学习者都有各自的快速权重。
- en: This requires two neural networks—*F[w]* (an LSTM whose inputs are the embedding
    loss of *f*) and *G[v]* (an ANN)—each of which outputs the fast weights for *f[θ]*
    and *g[φ]*. The fast weights corresponding to *f[θ]* and *g[θ]* are *θ^** and
    *φ^**, respectively. The difference between the two is that the input to *F[w]*
    is the gradient of the embedding loss of *f*, while *G[v]* learns using the gradients
    of the loss of *g*.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要两个神经网络——*F[w]*（一个LSTM，其输入为*f*的嵌入损失）和*G[v]*（一个ANN）——它们分别输出*f[θ]*和*g[φ]*的快速权重。对应于*f[θ]*和*g[θ]*的快速权重分别是*θ^*和*φ^*。两者的区别在于，*F[w]*的输入是*f*的嵌入损失的梯度，而*G[v]*则通过*g*的损失梯度进行学习。
- en: As you can see, this means we have to learn four different sets of parameters
    [![](img/73ea5643-3927-46cd-8e40-e3cd9150e7be.png)]. To train our networks, we
    make use of two datasets—a training set, [![](img/65ca0144-fc10-4a84-9d09-3075799f9a69.png)],
    and a support set, [![](img/e1370139-fef0-403c-b8fa-6f85fda53800.png)].
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这意味着我们需要学习四组不同的参数[![](img/73ea5643-3927-46cd-8e40-e3cd9150e7be.png)]。为了训练我们的网络，我们使用两个数据集——一个训练集[![](img/65ca0144-fc10-4a84-9d09-3075799f9a69.png)]和一个支持集[![](img/e1370139-fef0-403c-b8fa-6f85fda53800.png)]。
- en: 'The overall training of this network can be broken down into three distinct
    parts:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 该网络的整体训练可以分为三个不同的部分：
- en: Acquiring the meta information
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取元信息
- en: Generating the fast weights
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成快速权重
- en: Optimizing the slow weights
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化慢权重
- en: We start by creating a sequence of tasks, each of which has a training set and
    a support set, and randomly sample *T* input pairs, [![](img/b644ea5c-647b-4f8b-b430-88e2669a1375.png)]
    and [![](img/dc36b543-4375-4d44-bd45-a5c1928eb437.png)], from the support—where
    *T < N*—and then calculate the cross-entropy loss for the embeddings for the verification
    task.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一系列任务，每个任务都有一个训练集和一个支持集，并随机从支持集中采样*T*个输入对，[![](img/b644ea5c-647b-4f8b-b430-88e2669a1375.png)]和[![](img/dc36b543-4375-4d44-bd45-a5c1928eb437.png)]，其中*T
    < N*，然后计算验证任务的嵌入的交叉熵损失。
- en: We then compute the fast weights for the task level, [![](img/6f5ca367-b136-481a-8879-5e1e95c0cb03.png)].
    Once this is complete, we compute the fast weights at the example level, [![](img/2184f5e9-dd5e-4d11-9f92-10c0165f6a8c.png)],
    from the support set and update the *i^(th)* location of the value memory, *M*,
    (for the meta learned) with [![](img/255a91ae-6744-4a88-8790-84ad258c6c36.png)].
    Then, we encode the sampled point from the support set into the task space with
    fast and slow weights using [![](img/6ae3456b-c75c-4095-b43a-01b6f93e13a4.png)],
    which is updated at the *i**^(th)* location of the key memory, *R* (for the base
    learner).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们计算任务级别的快速权重，[![](img/6f5ca367-b136-481a-8879-5e1e95c0cb03.png)]。完成此步骤后，我们从支持集计算示例级别的快速权重，[![](img/2184f5e9-dd5e-4d11-9f92-10c0165f6a8c.png)]，并更新值记忆的第*i^(th)*位置，*M*（对于元学习）为[![](img/255a91ae-6744-4a88-8790-84ad258c6c36.png)]。然后，我们使用[![](img/6ae3456b-c75c-4095-b43a-01b6f93e13a4.png)]将支持集中采样的点通过快速和慢权重编码到任务空间中，该权重在第*i^(th)*位置的关键记忆*R*（对于基础学习者）中更新。
- en: Once this is done, we sample from the test set and encode them into the task
    space using [![](img/9b120196-d062-405e-8e32-c9d25799e747.png)], then we calculate
    the cosine similarity to find out how similar the memory index and the input embedding
    are.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此步骤后，我们从测试集中进行采样，并使用[![](img/9b120196-d062-405e-8e32-c9d25799e747.png)]将其编码到任务空间中，然后计算余弦相似度，以确定记忆索引和输入嵌入的相似性。
- en: Metric-based meta learning
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于度量的元学习
- en: 'Metric-based meta learning uses a concept similar to what is used in clustering,
    where we try to learn the distance between objects. This is similar to kernel
    density estimation, where we use a kernel function, *k[θ]*, to calculate weight
    or how similar two samples are, then find the predicted probability over the labels:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 基于度量的元学习使用与聚类中类似的概念，在这种方法中，我们尝试学习对象之间的距离。这类似于核密度估计，其中我们使用核函数*k[θ]*来计算权重或两个样本的相似度，然后计算标签上的预测概率：
- en: '![](img/618676bb-4cec-49c6-bf99-1d1e4fdf8b74.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/618676bb-4cec-49c6-bf99-1d1e4fdf8b74.png)'
- en: This class of meta learning algorithms explicitly learns the embedding of the
    data to create optimal kernels.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这一类元学习算法显式地学习数据的嵌入，以创建最优的核。
- en: Prototypical networks
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原型网络
- en: 'Prototypical networks are a type of meta learning algorithm used for few-shot
    learning. The way this works is we use an encoding function, *f[θ]*, to encode
    each of the *D*-dimensional inputs into an *M*-dimensional vector. This prototype
    vector is defined as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 原型网络是一种用于少样本学习的元学习算法。其工作方式是我们使用编码函数*f[θ]*将每个*D*维输入编码成一个*M*维向量。这个原型向量定义如下：
- en: '![](img/9f9e78df-2a8c-48d9-99dc-af47d9385d78.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9f9e78df-2a8c-48d9-99dc-af47d9385d78.png)'
- en: 'This is the case for each class of ![](img/8d1f81cb-e366-4365-8a2d-1f1b8791fe61.png).
    We then calculate the distance, [![](img/2b5615fc-8936-4ea1-8b31-ee759df5c7af.png)],
    between the embedding of the test data and the prototype vector, then use it to
    calculate the probability distribution over the classes, as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个类的情况，![](img/8d1f81cb-e366-4365-8a2d-1f1b8791fe61.png)也是如此。我们计算测试数据嵌入与原型向量之间的距离，[![](img/2b5615fc-8936-4ea1-8b31-ee759df5c7af.png)]，然后用它来计算类的概率分布，如下所示：
- en: '![](img/bcef8ca0-3935-4db0-8f89-a8d15711ebd2.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bcef8ca0-3935-4db0-8f89-a8d15711ebd2.png)'
- en: Here, *d[φ]* is the distance function, but φ must be differentiable.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*d[φ]* 是距离函数，但φ必须是可微的。
- en: 'In the following diagram, we can see the prototypical network compute the few-shot
    prototypes and the zero-shot prototypes:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图示中，我们可以看到原型网络计算了少样本原型和零样本原型：
- en: '![](img/e1944b16-bc7f-49b2-b7ea-a60d4a135481.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e1944b16-bc7f-49b2-b7ea-a60d4a135481.png)'
- en: Siamese neural networks
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 孪生神经网络
- en: The Siamese neural network is an architecture that is comprised of two identical
    neural networks with shared weights, and their parameters are trained to determine
    the similarity between two data samples using a distance metric on the embeddings.
    This architecture has proven to be effective for one-shot image classification
    where the network learns to tell whether or not two images belong to the same
    class.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 孪生神经网络是一种由两个相同的神经网络组成的架构，这些网络共享权重，它们的参数经过训练来确定两个数据样本之间的相似度，使用嵌入的距离度量。这种架构已被证明对一-shot图像分类有效，在这种分类中，网络学习判断两张图片是否属于同一类别。
- en: 'In the following diagram, we can see that the network takes in two images and
    each passes through an identical CNN (*f[θ]*) to generate feature vectors (the
    embeddings):'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图示中，我们可以看到网络接收两张图像，并且每张图像都通过一个相同的CNN (*f[θ]*) 来生成特征向量（嵌入）：
- en: '![](img/a32043c8-2695-4fd3-957f-78a0771b9db0.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a32043c8-2695-4fd3-957f-78a0771b9db0.png)'
- en: 'Once the embeddings are calculated, we can then calculate the distance between
    the two embeddings, as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦计算出嵌入，我们就可以计算两个嵌入之间的距离，如下所示：
- en: '![](img/c80bb938-b24c-4384-b671-45cdf7023a03.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c80bb938-b24c-4384-b671-45cdf7023a03.png)'
- en: The output from the distance is passed through a **multilayer perceptron** (**MLP**)
    with a sigmoid function to compute the probability of whether the two inputs belong
    to the same class.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从距离计算的输出会通过一个**多层感知机**（**MLP**）与Sigmoid函数，以计算两个输入是否属于同一类的概率。
- en: 'Since the labels for the image are binary (*1* for yes and *0* for no), we
    calculate the loss using cross-entropy:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像的标签是二元的（*1*表示是，*0*表示否），我们使用交叉熵计算损失：
- en: '![](img/7a0a1901-b47c-4488-88c7-f120b4133533.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7a0a1901-b47c-4488-88c7-f120b4133533.png)'
- en: 'We calculate the probability of which class it belongs to using the following:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下方式计算它属于哪个类的概率：
- en: '![](img/7d97572b-37a9-4c70-b133-e11ac9cccc61.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7d97572b-37a9-4c70-b133-e11ac9cccc61.png)'
- en: Here, *S* is a support set, *x* is a test image, *c(x)* is the label corresponding
    to the image, and [![](img/ff769b17-331c-4e89-bd96-283fa7cd35f0.png)] is the class
    prediction.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*S* 是支持集，*x* 是测试图像，*c(x)* 是与图像对应的标签，而[![](img/ff769b17-331c-4e89-bd96-283fa7cd35f0.png)]
    是类的预测。
- en: Optimization-based meta learning
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于优化的元学习
- en: In [Chapter 7](e1f37008-1ad5-49f6-a229-4d6249c2d7e3.xhtml), *Feedforward Neural
    Networks*, we covered backpropagation and gradient descent as a way to optimize
    the parameters of our model to reduce the loss; but we also saw that it is quite
    slow and requires a lot of training samples and so a lot of compute power. To
    overcome this, we use optimization-based meta learning, where we learn the optimization
    process. But how do we do that?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第七章](e1f37008-1ad5-49f6-a229-4d6249c2d7e3.xhtml)《前馈神经网络》中，我们介绍了反向传播和梯度下降方法，作为优化模型参数以减少损失的手段；但我们也看到，这种方法相对较慢，并且需要大量的训练样本和计算资源。为了克服这一点，我们采用了基于优化的元学习，其中我们学习优化过程。但我们该如何做呢？
- en: Long Short-Term Memory meta learners
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 长短期记忆元学习器
- en: Let's think back to when we learned about gradient-based optimization for a
    moment. What happened there? We started at an initial point in the parameter space
    and then calculated the gradient and took a step toward the local/global minima,
    then repeated these steps. In gradient descent, with momentum, we used the history
    of previous updates to guide the next one. If you think about it carefully, this
    is slightly similar to RNNs and **Long Short-Term Memory** (**LSTM**), so we can
    just replace the entire process of gradient descent with an RNN. This approach
    is known as **learning to learn by gradient descent**. The reasoning behind this
    name is that we train RNNs using gradient descent and then we use the RNN to perform
    the gradient descent. In this scenario, we call the RNN the optimizer and the
    base model the optimizee.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回想一下，当我们学习基于梯度的优化时，发生了什么？我们从参数空间中的一个初始点开始，然后计算梯度，并朝着局部/全局最小值迈出一步，接着重复这些步骤。在带动量的梯度下降中，我们利用之前更新的历史信息来指导下一步的更新。如果仔细想想，这与RNN和**长短期记忆**（**LSTM**）有些相似，因此我们可以用RNN替代整个梯度下降的过程。这种方法被称为**通过梯度下降学习学习**。这个名字的背后原因是我们使用梯度下降训练RNN，然后用RNN来执行梯度下降。在这种情况下，我们将RNN称为优化器，而基础模型称为优化对象。
- en: 'As we know, vanilla RNNs have their problems (vanishing gradient), so here,
    we are going to cover optimizing the model using LSTM cells. But first, let''s
    revisit how parameter optimization works. It looks as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所知，普通的RNN存在一些问题（梯度消失），因此在这里，我们将介绍如何使用LSTM单元来优化模型。但在此之前，让我们先回顾一下参数优化是如何工作的。其过程如下：
- en: '![](img/3c259c7a-a1f0-4b27-a1d8-1e62e88532c3.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c259c7a-a1f0-4b27-a1d8-1e62e88532c3.png)'
- en: 'Let''s compare this with the updates in an LSTM cell:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将其与LSTM单元中的更新进行比较：
- en: '![](img/0544de67-fda1-4930-ad5c-e82b1aa82b38.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0544de67-fda1-4930-ad5c-e82b1aa82b38.png)'
- en: 'Here, [![](img/18ee349b-ac5d-4582-a8ca-0876d8d06400.png)], [![](img/3808b60a-c4d3-496c-95d3-294dec9ef860.png)],
    [![](img/7a9dcafe-d986-42c7-bbd4-e869a633c650.png)] and [![](img/fc5efa4d-a79f-4646-a901-15931f8b6f52.png)].
    However, the forget gate and input gate do not have to be fixed; they can be learned
    so that we can adapt them for other tasks. The calculations for the forget gate,
    input gate, candidate layer, and memory state now become the following, respectively:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，[![](img/18ee349b-ac5d-4582-a8ca-0876d8d06400.png)]、[![](img/3808b60a-c4d3-496c-95d3-294dec9ef860.png)]、[![](img/7a9dcafe-d986-42c7-bbd4-e869a633c650.png)]
    和 [![](img/fc5efa4d-a79f-4646-a901-15931f8b6f52.png)]。然而，遗忘门和输入门不必是固定的；它们可以被学习，以便我们能够将其适应其他任务。遗忘门、输入门、候选层和记忆状态的计算分别如下：
- en: '[![](img/315de60a-48ff-4fcb-acf0-df63a9a6aba1.png)]'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/315de60a-48ff-4fcb-acf0-df63a9a6aba1.png)]'
- en: '[![](img/ade581b4-4231-4cbe-ae54-26c6197f1ab0.png)]'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/ade581b4-4231-4cbe-ae54-26c6197f1ab0.png)]'
- en: '[![](img/72bb6f71-baf3-45cc-b7a3-23b5052555e6.png)]'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/72bb6f71-baf3-45cc-b7a3-23b5052555e6.png)]'
- en: '[![](img/e4400363-463d-4b9f-a9c7-dbbb8f2646a3.png)]'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[![](img/e4400363-463d-4b9f-a9c7-dbbb8f2646a3.png)]'
- en: 'In the following diagram, we can see how the LSTM meta learner is structured:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们可以看到LSTM元学习器的结构：
- en: '![](img/0e36128a-2683-4530-afbe-16076f0cd6be.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0e36128a-2683-4530-afbe-16076f0cd6be.png)'
- en: 'During the training process, we want to try and mimic what will happen during
    the testing process, and during training, we sample a dataset as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们希望尽量模拟测试过程中会发生的情况，在训练期间，我们按如下方式采样数据集：
- en: '![](img/349cd6dc-8852-486f-8093-cf36818bfeb1.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/349cd6dc-8852-486f-8093-cf36818bfeb1.png)'
- en: Following this, we sample from [![](img/e79f6f58-c0f9-49f0-ad80-26f4f71b7a26.png)]
    to update the parameters of the model by a total number of *T* iterations and
    calculate the loss with respect to the weights of the base model (θ), as well
    as feeding the loss, gradients, and meta learner parameter (φ) to the optimizer
    (meta learner). The meta learner will then output the new cell state, which we
    use to update the parameters of the base model.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们从[![](img/e79f6f58-c0f9-49f0-ad80-26f4f71b7a26.png)]中进行采样，通过*T*次迭代来更新模型的参数，并计算基模型（θ）权重的损失，同时将损失、梯度和元学习器参数（φ）传递给优化器（元学习器）。然后，元学习器将输出新的单元状态，我们用它来更新基模型的参数。
- en: Once we have completed *T* iterations, we can expect to have found an optimal
    parameter for the base model. To test the goodness of *θ[T]* and update the parameters
    of the meta learner, we find the loss on the test data with respect to *θ[T]*,
    then find the gradients of the test loss with respect to φ, to perform updates
    to φ for *N* iterations.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们完成了 *T* 次迭代，我们可以期待找到一个最优的基础模型参数。为了测试 *θ[T]* 的优良性并更新元学习者的参数，我们需要根据 *θ[T]*
    在测试数据上找到损失，然后计算测试损失对 φ 的梯度，进而对 φ 执行 *N* 次迭代更新。
- en: Model-agnostic meta learning
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型无关元学习
- en: '**Model-Agnostic Meta Learning** (**MAML**) is an optimization algorithm that
    can work on any type of neural network that is trained using gradient descent.
    Suppose we have a model, *f*, with parameters, θ, and a task, *τ[i]*, that has
    a corresponding dataset [![](img/301eb65d-08ff-4919-9f71-33809910f9eb.png)]. Then,
    we can make updates to the model using a single or several gradient descent steps.
    A single step in this algorithm works as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型无关元学习**（**MAML**）是一种优化算法，可以在任何通过梯度下降训练的神经网络中使用。假设我们有一个模型 *f*，它的参数为 *θ*，并且有一个任务
    *τ[i]*，它对应一个数据集 [![](img/301eb65d-08ff-4919-9f71-33809910f9eb.png)]。然后，我们可以通过单步或多步梯度下降更新模型。这个算法的单步操作如下：'
- en: '![](img/3b665474-9a7f-4d7f-a503-5260f6559108.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3b665474-9a7f-4d7f-a503-5260f6559108.png)'
- en: 'The preceding step learns to optimize a single task, but we would like to optimize
    multiple tasks. So, we can change the task to find the optimal parameters over
    multiple tasks as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 上述步骤学习了如何优化单一任务，但我们希望优化多个任务。因此，我们可以通过改变任务来寻找在多个任务上优化的参数，如下所示：
- en: '![](img/de93df36-ea22-4b2c-b23e-74b709a8517a.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/de93df36-ea22-4b2c-b23e-74b709a8517a.png)'
- en: Here, *L^((0))* is the loss corresponding to the initial training batch and
    *L^((1))* is the loss for the next training batch.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*L^((0))* 是对应于初始训练批次的损失，*L^((1))* 是下一批次训练的损失。
- en: This looks pretty similar to the gradient descent we know, so what's special
    about it? What this is doing is learning the parameters associated with other
    tasks and attempting to learn the best initial parameters to use for the next
    task to reduce the training time. However, this uses second-order optimization,
    which is a bit more computationally intensive, so instead, we can use a first-order
    method, which is more feasible. This method is known as **First-Order Model-Agnostic
    Meta Learning** (**FOMAML**). Let's see the difference between the two in the
    following calculations.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来与我们熟悉的梯度下降非常相似，那么它有什么特别之处呢？其实，这个方法是在学习与其他任务相关的参数，并尝试学习出最适合用于下一个任务的初始参数，从而减少训练时间。然而，它使用了二阶优化，这在计算上稍显复杂，因此我们可以改用一种计算更加可行的一级方法。这种方法被称为**一阶模型无关元学习**（**FOMAML**）。让我们在接下来的计算中看看这两者的区别。
- en: 'Let''s consider a case where we perform *n* gradient descent steps, where *n
    ≥ 1*. Our starting point is *θ[meta]* and the steps are as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们执行了 *n* 步梯度下降，其中 *n ≥ 1*。我们的起始点是 *θ[meta]*，步骤如下：
- en: '![](img/b6fa45f1-2c0e-4d24-92ea-640cf8d84e0b.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b6fa45f1-2c0e-4d24-92ea-640cf8d84e0b.png)'
- en: 'Once *n* steps are computed, we sample the next batch and perform updates over
    it. This then becomes the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦计算了 *n* 步，我们就可以抽取下一批次并对其进行更新。这样就变成了以下内容：
- en: '![](img/de6c4eac-2fd2-41b2-be9c-552c01fa4b81.png)![](img/e451043a-95d5-47e7-94d5-a9f0b3768b6c.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/de6c4eac-2fd2-41b2-be9c-552c01fa4b81.png)![](img/e451043a-95d5-47e7-94d5-a9f0b3768b6c.png)'
- en: Here,[![](img/f0929297-80a7-4429-844c-0ca4a737d1b1.png)].
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，[![](img/f0929297-80a7-4429-844c-0ca4a737d1b1.png)]。
- en: 'However, the gradient in FOMAML is as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在 FOMAML 中的梯度如下：
- en: '![](img/f1a9cb83-f2b3-4c45-8284-0162d4755e78.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f1a9cb83-f2b3-4c45-8284-0162d4755e78.png)'
- en: Congratulations—you have now completed this chapter on transfer learning and
    meta learning!
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你——你已经完成了本章关于迁移学习和元学习的内容！
- en: Summary
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered two very fascinating areas within the field of deep
    learning—transfer learning and meta learning—both of which hold the promise of
    furthering the field of not only deep learning but also artificial intelligence
    by enabling neural networks to learn additional tasks and generalize over unseen
    distributions. We explored several meta learning approaches, including model-based,
    metric-based, and optimization-based, and explored how they differ.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了深度学习领域内两个非常有趣的方向——迁移学习和元学习——这两者都承诺能够推动深度学习甚至人工智能领域的发展，通过使神经网络能够学习额外的任务并在未见过的分布上进行泛化。我们还探索了几种元学习方法，包括基于模型的方法、基于度量的方法和基于优化的方法，并分析了它们之间的区别。
- en: In the next chapter, we will learn about geometric deep learning.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习几何深度学习。
