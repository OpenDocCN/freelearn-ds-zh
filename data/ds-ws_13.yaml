- en: 13\. Imbalanced Datasets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 13\. 不平衡数据集
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: By the end of this chapter, you will be able to identify use cases where datasets
    are likely to be imbalanced; formulate strategies for dealing with imbalanced
    datasets; build classification models, such as logistic regression models, after
    balancing datasets; and analyze classification metrics to validate whether adopted
    strategies are yielding the desired results.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将能够识别数据集可能不平衡的用例；制定处理不平衡数据集的策略；在平衡数据集后构建分类模型，例如逻辑回归模型；并分析分类指标以验证所采用的策略是否产生了期望的结果。
- en: In this chapter, you will be dealing with imbalanced datasets, which are very
    prevalent in real-life scenarios. You will be using techniques such as `SMOTE`,
    `MSMOTE`, and random undersampling to address imbalanced datasets.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将处理非常常见于现实场景中的不平衡数据集。您将使用`SMOTE`、`MSMOTE`和随机欠采样等技术来解决不平衡数据集问题。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapter, *Chapter 12*, *Feature Engineering*, where we dealt
    with data points related to dates, we were addressing scenarios pertaining to
    features. In this chapter, we will deal with scenarios where the proportions of
    examples in the overall dataset pose challenges.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章节*第12章*，*特征工程*中，我们处理与日期相关的数据点，我们正在处理与特征相关的场景。在本章中，我们将处理整体数据集中例子比例构成挑战的情况。
- en: Let's revisit the dataset we dealt with in *Chapter 3*, *Binary Classification*,
    in which the examples pertaining to 'No' for term deposits far outnumbered the
    ones with 'Yes' with a ratio of 88% to 12%. We also determined that one reason
    for suboptimal results with a logistic regression model on that dataset was the
    skewed proportion of examples. Datasets like the one we analyzed in *Chapter 3*,
    *Binary Classification,* which are called imbalanced datasets, are very common
    in real-world use cases.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新审视我们在*第三章*，*二元分类*中处理的数据集，即针对'否'存款的例子远远超过了'是'的例子，比例为88%对12%。我们还确定，导致该数据集上逻辑回归模型表现不佳的原因之一是示例的倾斜比例。像我们在*第三章*，*二元分类*中分析过的那种数据集，称为不平衡数据集，在真实世界的用例中非常普遍。
- en: 'Some of the use cases where we encounter imbalanced datasets include the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遇到不平衡数据集的一些用例包括以下情况：
- en: Fraud detection for credit cards or insurance claims
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用卡或保险理赔的欺诈检测
- en: Medical diagnoses where we must detect the presence of rare diseases
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在医疗诊断中，我们必须检测罕见疾病的存在
- en: Intrusion detection in networks
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络入侵检测
- en: In all of these use cases, we can see that what we really want to detect will
    be minority cases. For instance, in domains such as the medical diagnosis of rare
    diseases, examples where rare diseases exist could even be less than 1% of the
    total examples. One inherent characteristic of use cases with imbalanced datasets
    is that the quality of the classifier is not apparent if the right metric is not
    used. This makes the problem of imbalanced datasets really challenging.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些用例中，我们可以看到我们真正想要检测的将是少数情况。例如，在医疗诊断罕见疾病的领域，存在罕见疾病的例子甚至可能少于总例子的1%。不平衡数据集用例的一个固有特征是，如果没有使用正确的度量标准，分类器的质量并不明显。这使得不平衡数据集的问题确实具有挑战性。
- en: In this chapter, we will discuss strategies for identifying imbalanced datasets
    and ways to mitigate the effects of imbalanced datasets.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论识别不平衡数据集的策略以及缓解不平衡数据集影响的方法。
- en: Understanding the Business Context
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解业务背景
- en: The business head of the bank for which you are working as a data scientist
    recently raised the alarm about the results of the term deposit propensity model
    that you built in *Chapter 3*, *Binary Classification*. It has been observed that
    a large proportion of customers who were identified as potential cases for targeted
    marketing for term deposits have turned down the offer. This has made a big dent
    in the sales team's metrics on upselling and cross-selling. The business team
    urgently requires your help in fixing the issue to meet the required sales targets
    for the quarter. Don't worry, though – this is the problem that we will be solving
    later in this chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家为一家银行工作，最近业务负责人对您在*第三章*，*二元分类*中构建的存款倾向模型的结果提出了警告。观察到，大部分被识别为潜在目标市场的客户，最终拒绝了提供的服务。这已经对销售团队的交叉销售和增值销售的业绩指标造成了重大影响。业务团队急需您的帮助来解决这个问题，以达到本季度的销售目标。不过，别担心，这是我们将在本章后期解决的问题。
- en: First, we begin with an analysis of the issue.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从分析问题开始。
- en: 'Exercise 13.01: Benchmarking the Logistic Regression Model on the Dataset'
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 13.01：对数据集上的逻辑回归模型进行基准测试
- en: 'In this exercise, we will be analyzing the problem of predicting whether a
    customer will buy a term deposit. For this, you will be fitting a logistic regression
    model, as you did in *Chapter 3*, *Binary Classification*, and you will look closely
    at the metrics:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将分析预测客户是否会购买定期存款的问题。为此，你将拟合一个逻辑回归模型，就像在*第3章*，*二元分类*中做的那样，并且你将仔细观察各项指标：
- en: Note
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The dataset you will be using in this exercise can be found on our GitHub repository:
    [https://packt.live/2twFgIM](https://packt.live/2twFgIM).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本练习中使用的数据集可以在我们的 GitHub 仓库找到：[https://packt.live/2twFgIM](https://packt.live/2twFgIM)。
- en: Open a new notebook in Google Colab.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Google Colab 中打开一个新的笔记本。
- en: 'Next, import `pandas` and load the data from the GitHub repository:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，`import` `pandas` 并从 GitHub 仓库加载数据：
- en: '[PRE0]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, load the data using `pandas`
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `pandas` 加载数据
- en: '[PRE1]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Your output would be as follows:'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出将如下所示：
- en: '![Figure 13.1: The first 5 rows of bankData'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 13.1：bankData 的前五行'
- en: '](img/B15019_13_01.jpg)'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_01.jpg)'
- en: 'Figure 13.1: The first 5 rows of bankData'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.1：bankData 的前五行
- en: Now, to break the dataset down further, let's perform some feature-engineering
    steps.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，为了进一步分解数据集，让我们执行一些特征工程步骤。
- en: 'Normalize the numerical features (age, balance, and duration) through scaling,
    which was covered in *Chapter 3*, *Binary Classification*. Enter the following
    code:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过缩放对数值特征（年龄、余额和时长）进行归一化，这在*第3章*，*二元分类*中已经讲解过。请输入以下代码：
- en: '[PRE2]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the preceding code snippet, we used a scaling function called `RobustScaler()`
    to scale the numerical data. `RobustScaler()` is a scaling function similar to
    `MinMaxScaler` in *Chapter 3*, *Binary Classification*.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在上面的代码片段中，我们使用了一个名为 `RobustScaler()` 的缩放函数来缩放数值数据。`RobustScaler()` 是一个类似于*第3章*，*二元分类*中的
    `MinMaxScaler` 的缩放函数。
- en: 'After scaling the numerical data, we convert each of the columns to a scaled
    version, as in the following code snippet:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在缩放数值数据后，我们将每一列转换为缩放版，如下所示的代码片段：
- en: '[PRE3]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, drop the original features after we introduce the scaled features using
    the `.drop()` function:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `.drop()` 函数删除原始特征，然后引入缩放特征：
- en: '[PRE4]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Display the first five columns using the `.head()` function:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.head()` 函数显示前五列：
- en: '[PRE5]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output is as follows:'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '![Figure 13.2: bankData with scaled features'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 13.2：带有缩放特征的 bankData'
- en: '](img/B15019_13_02.jpg)'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_02.jpg)'
- en: 'Figure 13.2: bankData with scaled features'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.2：带有缩放特征的 bankData
- en: The categorical features in the dataset must be converted into numerical values
    by transforming them into dummy values, which was covered in *Chapter 3*, *Binary
    Classification*.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集中的分类特征必须通过将其转换为虚拟变量来转换为数值，这在*第3章*，*二元分类*中已经介绍过。
- en: 'Convert all the categorical variables to dummy variables using the `.get_dummies()`
    function:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.get_dummies()` 函数将所有分类变量转换为虚拟变量：
- en: '[PRE6]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Separate the numerical data and observe the shape:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分离数值数据并观察其形状：
- en: '[PRE7]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output would be as follows:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE8]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: After the categorical values are transformed, they must be combined with the
    scaled numerical values of the data frame to get the feature-engineered dataset.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在转换分类变量后，必须将其与数据框的缩放数值结合，以获得特征工程化的数据集。
- en: 'Create the independent variables, `X`, and dependent variables, `Y`, from the
    combined dataset for modeling, as in the following code snippet:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从合并的数据集中创建独立变量 `X` 和依赖变量 `Y` 以供建模，如下代码片段所示：
- en: '[PRE9]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is as follows:'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '![Figure 13.3: The independent variables and the combined data (truncated)'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 13.3：独立变量和合并数据（截断）'
- en: '](img/B15019_13_03.jpg)'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_03.jpg)'
- en: 'Figure 13.3: The independent variables and the combined data (truncated)'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.3：独立变量和合并数据（截断）
- en: We are now ready for the modeling task. Let's first import the necessary packages.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们现在已经准备好进行建模任务。让我们首先导入所需的包。
- en: 'Now, `import` the necessary functions of `train_test_split()` and `LogisticRegression`
    from `sklearn`:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，从 `sklearn` 中 `import` 所需的 `train_test_split()` 和 `LogisticRegression` 函数：
- en: '[PRE10]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Split the data into train and test sets at a `test_size = 0.3` variable in
    the splitting function. We also set `random_state` for the reproducibility of
    the code:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在拆分函数中将数据分为训练集和测试集，设置 `test_size = 0.3`。我们还设置了 `random_state` 来确保代码的可重复性：
- en: '[PRE11]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, fit the model using `.fit` on the training data:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `.fit` 在训练数据上拟合模型：
- en: '[PRE12]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Your output should be as follows:'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出应如下所示：
- en: '![Figure 13.4: Fitting the model'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.4：拟合模型'
- en: '](img/B15019_13_04.jpg)'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_04.jpg)'
- en: 'Figure 13.4: Fitting the model'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.4：拟合模型
- en: Now that the model is fit, let's now predict the test set and generate the metrics.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在模型已经拟合，接下来我们对测试集进行预测并生成指标。
- en: 'Next, find the prediction on the test set and print the accuracy scores:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，找到测试集上的预测结果并打印准确度分数：
- en: '[PRE13]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You should get the following output:'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '[PRE14]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, use both the `confusion_matrix()` and `classification_report()` functions
    to generate the metrics for further analysis, which we will cover in the *Analysis
    of the Result* section:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `confusion_matrix()` 和 `classification_report()` 两个函数生成进一步分析的指标，详细内容将在*结果分析*部分中讨论：
- en: '[PRE15]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'You should get the following output:'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 13.5: Metrics showing the accuracy result along with the confusion
    matrix'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.5：显示准确度结果及混淆矩阵的指标'
- en: '](img/B15019_13_05.jpg)'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_05.jpg)'
- en: 'Figure 13.5: Metrics showing the accuracy result along with the confusion matrix'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5：显示准确度结果及混淆矩阵的指标
- en: Note
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You will get metrics similar to the following. However, the values will vary
    due to the variability in the modeling process.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你将得到类似以下的指标。然而，由于建模过程中的变异性，数值会有所不同。
- en: In this exercise, we have found a report that may have caused the issue with
    the number of customers expected to purchase the term deposit plan. From the metrics,
    we can see that the number of values for `No` is relatively higher than that for
    `Yes`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次练习中，我们发现了一份报告，可能导致了预期购买定期存款计划的客户数量出现问题。从指标中，我们可以看到 `No` 的值相对比 `Yes` 的值要高。
- en: Note
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3hapnvB](https://packt.live/3hapnvB).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/3hapnvB](https://packt.live/3hapnvB)。
- en: You can also run this example online at [https://packt.live/3hh6Xta](https://packt.live/3hh6Xta).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个例子，访问 [https://packt.live/3hh6Xta](https://packt.live/3hh6Xta)。
- en: To understand more about the reasons behind the skewed results, we will analyze
    these metrics in detail in the following section.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解结果偏差的原因，我们将在接下来的部分详细分析这些指标。
- en: Analysis of the Result
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果分析
- en: 'To analyze the results obtained in the previous section, let''s expand the
    confusion matrix in the form:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析在上一部分中获得的结果，让我们将混淆矩阵扩展成以下形式：
- en: '![Figure 13.6: Confusion matrix of the resulting metrics obtained'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.6：结果指标的混淆矩阵'
- en: '](img/B15019_13_06.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_06.jpg)'
- en: 'Figure 13.6: Confusion matrix of the resulting metrics obtained'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.6：结果指标的混淆矩阵
- en: 'We enter the values `11707`, `291`, `1060`, and `506` from the output we got
    from the previous exercise. We then place these values as shown in the diagram.
    We will represent the propensity to take a term deposit (`No`) as the positive
    class and the other as the negative class. So, from the confusion matrix, we can
    calculate the accuracy measures, which were covered in *Chapter 3*, *Binary Classification*.
    The accuracy of the model is given by:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从前一个练习中获得的输出中输入了值 `11707`、`291`、`1060` 和 `506`。然后我们将这些值按图示方式排列。我们将表示选择定期存款（`No`）的倾向作为正类，其他作为负类。因此，从混淆矩阵中，我们可以计算出准确度度量，这些内容在*第3章*，*二元分类*中有介绍。模型的准确度由以下公式给出：
- en: '![Figure 13.7: Accuracy of a model'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.7：模型的准确度'
- en: '](img/B15019_13_07.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_07.jpg)'
- en: 'Figure 13.7: Accuracy of a model'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.7：模型的准确度
- en: In our case, it will be (11707 + 506) / (11707 + 1060 + 291 + 506), or 90%.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，它将是（11707 + 506）/（11707 + 1060 + 291 + 506），即 90%。
- en: From the accuracy perspective, the model would seem like it is doing a reasonable
    job. However, the reality might be quite different. To find out what's really
    the case, let's look at the precision and recall values, which are available from
    the classification report we obtained. The formulae for precision for any class
    was covered in *Chapter 3*, *Binary Classification*
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 从准确度的角度来看，模型似乎做得不错。然而，现实可能大不相同。为了找出实际情况，我们来看看精确度和召回率值，这些值可以从我们获得的分类报告中得到。任何类别的精确度公式在*第3章*，*二元分类*中有介绍。
- en: 'The precision value of any class is given by:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 任何类别的精确度值由以下公式给出：
- en: '![Figure 13.8: Precision of a model'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.8：模型的精确度'
- en: '](img/B15019_13_08.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_08.jpg)'
- en: 'Figure 13.8: Precision of a model'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.8：模型的精确度
- en: In our case, for the positive class, the precision is *TP/(TP + FP)*, which
    is 11707/ (11707 + 1060), which comes to approximately 92%.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，对于正类，精确度是 *TP/(TP + FP)*，即 11707 / (11707 + 1060)，大约为 92%。
- en: In the case of the negative class, the precision could be written as *TN / (TN
    + FN)*, which is 506 / (506 + 291), which comes to approximately 63%.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对于负类，精度可以写作 *TN / (TN + FN)*，即 506 / (506 + 291)，大约为 63%。
- en: 'Similarly, the recall value for any class can be represented as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，任何类别的召回率都可以表示如下：
- en: '![Figure 13.9: Recalling a model'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.9：召回模型'
- en: '](img/B15019_13_09.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_09.jpg)'
- en: 'Figure 13.9: Recalling a model'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.9：召回模型
- en: The recall value for the positive class, *TP / (TP + FN)* = 11707 / (11707 +
    291), comes to approximately 98%.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 正类的召回率，*TP / (TP + FN)* = 11707 / (11707 + 291)，大约为 98%。
- en: The recall value for the negative class, *TN / (TN + FP)* = 506 / (506 + 1060),
    comes to approximately 32%.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 负类的召回率，*TN / (TN + FP)* = 506 / (506 + 1060)，大约为 32%。
- en: Recall indicates the ability of the classifier to correctly identify the respective
    classes. From the metrics, we see that the model that we built does a good job
    of identifying the positive classes, but does a very poor job of correctly identifying
    the negative class.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率表示分类器正确识别各类别的能力。从这些指标中我们可以看到，我们构建的模型在识别正类方面表现良好，但在正确识别负类方面表现很差。
- en: Why do you think that the classifier is biased toward one class? The answer
    to this can be unearthed by looking at the class balance in the training set.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为分类器为什么会偏向于某一类？这个问题的答案可以通过查看训练集中各类别的平衡情况来揭示。
- en: 'The following code will generate the percentages of the classes in the training
    data:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将生成训练数据中各类别的百分比：
- en: '[PRE16]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You should get the following output:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE17]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: From this, we can see that the majority of the training set (88%) is made up
    of the positive class. This imbalance is one of the major reasons behind the poor
    metrics that we have had with the logistic regression classifier we have selected.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 从中我们可以看到，大多数训练集（88%）由正类组成。这种不平衡是我们选择的逻辑回归分类器表现不佳的主要原因之一。
- en: Now, let's look at the challenges of imbalanced datasets.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下不平衡数据集的挑战。
- en: Challenges of Imbalanced Datasets
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不平衡数据集的挑战
- en: As seen from the classifier example, one of the biggest challenges with imbalanced
    datasets is the bias toward the majority class, which ended up being 88% in the
    previous example. This will result in suboptimal results. However, what makes
    such cases even more challenging is the deceptive nature of results if the right
    metric is not used.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 从分类器的例子中可以看出，不平衡数据集的最大挑战之一是对多数类的偏向，在上一个例子中这个偏向为 88%。这将导致次优的结果。然而，更具挑战性的是，如果不使用正确的指标，结果会具有欺骗性。
- en: Let's take, for example, a dataset where the negative class is around 99% and
    the positive class is 1% (as in a use case where a rare disease has to be detected,
    for instance).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个数据集，其中负类约占 99%，正类约占 1%（例如，用于检测一种罕见疾病的情况）。
- en: 'Have a look at the following code snippet:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下下面的代码片段：
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Suppose we had a poor classifier that was capable of only predicting the negative
    class; we would get the following confusion matrix:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个差的分类器，它只能预测负类；我们将得到如下的混淆矩阵：
- en: '![Figure 13.10: Confusion matrix of the poor classifier'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.10：差的分类器的混淆矩阵'
- en: '](img/B15019_13_10.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_10.jpg)'
- en: 'Figure 13.10: Confusion matrix of the poor classifier'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.10：差的分类器的混淆矩阵
- en: 'From the confusion matrix, let''s calculate the accuracy measures. Have a look
    at the following code snippet:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 从混淆矩阵中，我们来计算准确性指标。看一下下面的代码片段：
- en: '[PRE19]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: With such a classifier, if we were to use a metric such as accuracy, we still
    would get a result of around 99%, which, in normal circumstances, would look outstanding.
    However, in this case, the classifier is doing a bad job. Think of the real-life
    impact of using such a classifier and a metric such as accuracy. The impact on
    patients who have rare diseases and who get wrongly classified as not having the
    disease could be fatal.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这样的分类器，如果我们使用像准确率这样的指标，我们仍然会得到大约 99% 的结果，在正常情况下这看起来很出色。然而，在这种情况下，分类器的表现很差。想一想使用这样的分类器和像准确率这样的指标的现实影响。对于罕见疾病的患者，错误地将其分类为没有疾病可能是致命的。
- en: 'Therefore, it is important to identify cases with imbalanced datasets and equally
    important to pick the right metric for analyzing such datasets. The right metric
    in this example would have been to look at the recall values for both the classes:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，识别不平衡数据集的情况非常重要，同时选择正确的度量标准来分析这些数据集同样重要。在本例中，正确的度量标准应该是查看两个类别的召回值：
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: From the recall values, we could have identified the bias of the classifier
    toward the majority class, prompting us to look at strategies for mitigating such
    biases, which is the next topic we will focus on.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 从召回值来看，我们本可以识别出分类器对多数类的偏倚，这促使我们查看缓解此类偏倚的策略，这是我们接下来要关注的主题。
- en: Strategies for Dealing with Imbalanced Datasets
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应对不平衡数据集的策略
- en: 'Now that we have identified the challenges of imbalanced datasets, let''s look
    at strategies for combatting imbalanced datasets:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经识别出不平衡数据集的挑战，接下来让我们看一下应对不平衡数据集的策略：
- en: '![Figure 13.11: Strategies for dealing with imbalanced datasets'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.11：应对不平衡数据集的策略'
- en: '](img/B15019_13_11.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_11.jpg)'
- en: 'Figure 13.11: Strategies for dealing with imbalanced datasets'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.11：应对不平衡数据集的策略
- en: Collecting More Data
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收集更多数据
- en: Having encountered an imbalanced dataset, one of the first questions you need
    to ask is whether it is possible to get more data. This might appear naïve, but
    collecting more data, especially from the minority class, and then balancing the
    dataset should be the first strategy for addressing the class imbalance.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在遇到不平衡数据集时，你需要问的第一个问题是，是否有可能获取更多的数据。这看起来可能有些天真，但收集更多的数据，尤其是来自少数类的数据，然后再平衡数据集，应该是解决类别不平衡的首要策略。
- en: Resampling Data
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重采样数据
- en: In many circumstances, collecting more data, especially from minority classes,
    can be challenging as data points for the minority class will be very minimal.
    In such circumstances, we need to adopt different strategies to work with our
    constraints and still strive to balance our dataset. One effective strategy is
    to resample our dataset to make the dataset more balanced. Resampling would mean
    taking samples from the available dataset to create a new dataset, thereby making
    the new dataset balanced.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，收集更多的数据，尤其是来自少数类的数据，可能是一个挑战，因为少数类的数据点通常非常稀少。在这种情况下，我们需要采用不同的策略来应对我们的约束条件，并努力平衡数据集。一种有效的策略是对数据集进行重采样，使数据集更加平衡。重采样意味着从现有数据集中提取样本，以创建一个新的数据集，从而使新数据集更加平衡。
- en: 'Let''s look at the idea in detail:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细了解一下这个思想：
- en: '![Figure 13.12: Random undersampling of the majority class'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.12：对多数类进行随机欠采样'
- en: '](img/B15019_13_12.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_12.jpg)'
- en: 'Figure 13.12: Random undersampling of the majority class'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.12：对多数类进行随机欠采样
- en: As seen in *Figure 13.8*, the idea behind resampling is to randomly pick samples
    from the majority class to make the final dataset more balanced. In the diagram,
    we can see that the minority class has the same number of examples as the original
    dataset and that the majority class is under-sampled to make the final dataset
    more balanced. Resampling examples of this type is called random undersampling
    as we are undersampling the majority class. We will perform random undersampling
    in the following exercise.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图13.8*所示，重采样的思想是从多数类中随机选取样本，以使最终的数据集更加平衡。在该图中，我们可以看到少数类的样本数量与原始数据集相同，而多数类则被欠采样，从而使最终的数据集更加平衡。这种类型的重采样被称为随机欠采样，因为我们是在对多数类进行欠采样。在接下来的练习中，我们将执行随机欠采样。
- en: 'Exercise 13.02: Implementing Random Undersampling and Classification on Our
    Banking Dataset to Find the Optimal Result'
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习13.02：在我们的银行数据集上实现随机欠采样和分类，以找到最佳结果
- en: 'In this exercise, you will undersample the majority class (propensity `''No''`)
    and then make the dataset balanced. On the new balanced dataset, you will fit
    a logistic regression model and then analyze the results:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，你将对多数类（倾向性为 `'No'`）进行欠采样，然后使数据集平衡。在新的平衡数据集上，你将拟合一个逻辑回归模型，并分析结果：
- en: Note
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The dataset you will be using in this exercise can be found on our GitHub repository:
    [https://packt.live/2twFgIM](https://packt.live/2twFgIM).'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本次练习中使用的数据集可以在我们的 GitHub 仓库中找到：[https://packt.live/2twFgIM](https://packt.live/2twFgIM)。
- en: Open a new Colab notebook for this exercise.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为本次练习打开一个新的 Colab 笔记本。
- en: Perform the initial 12 steps of *Exercise 13.01*, *Benchmarking the Logistic
    Regression Model on the Dataset*, such that the dataset is split into training
    and testing sets.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行 *练习13.01* 的前12步，*在数据集上对逻辑回归模型进行基准测试*，以便将数据集拆分为训练集和测试集。
- en: 'Now, join the `X` and `y` variables for the training set before resampling:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，先将 `X` 和 `y` 变量合并成训练集，之后再进行重采样：
- en: '[PRE21]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In this step, we concatenated the `X_train` and `y_train` datasets to one single
    dataset. This is done to make the resampling process in the subsequent steps easier.
    To concatenate the two datasets, we use the `.concat()` function from `pandas`.
    In the code, we use `axis = 1` to indicate that the concatenation is done horizontally,
    which is along the columns.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在此步骤中，我们将 `X_train` 和 `y_train` 数据集合并为一个数据集。这是为了使后续的重采样过程更简单。合并这两个数据集时，我们使用
    `pandas` 中的 `.concat()` 函数。在代码中，我们使用 `axis = 1` 表示沿列方向水平合并。
- en: 'Now, display the new data with the `.head()` function:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `.head()` 函数显示新数据：
- en: '[PRE22]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: You should get the following output
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 13.13: Displaying the first five rows of the dataset using .head()'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.13：使用 .head() 显示数据集的前五行'
- en: '](img/B15019_13_13.jpg)'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_13.jpg)'
- en: 'Figure 13.13: Displaying the first five rows of the dataset using .head()'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.13：使用 .head() 显示数据集的前五行
- en: The preceding output shows some of the columns of the dataset.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述输出显示了数据集中的一些列。
- en: Now, let's move onto separating the minority and majority classes into separate
    datasets.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，让我们开始将少数类别和多数类别分开到不同的数据集中。
- en: What we will do next is separate the minority class and the majority class.
    This is required because we have to sample separately from the majority class
    to make a balanced dataset. To separate the minority class, we have to identify
    the indexes of the dataset where the dataset has 'yes.' The indexes are identified
    using `.index()` function.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们将分离少数类别和多数类别。这是必要的，因为我们必须分别从多数类别中采样，以构建平衡的数据集。要分离少数类别，我们必须识别数据集中标记为“yes”的索引。可以使用
    `.index()` 函数来识别这些索引。
- en: 'Once those indexes are identified, they are separated from the main dataset
    using the `.loc()` function and stored in a new variable for the minority class.
    The shape of the minority dataset is also printed. A similar process is followed
    for the majority class and, after these two steps, we have two datasets: one for
    the minority class and one for the majority class.'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦识别出这些索引，它们将被从主数据集中分离出来，并使用 `.loc()` 函数存储在一个新的变量中，表示少数类别。少数类别数据集的形状也会被打印出来。对于多数类别，执行类似的过程，完成这两个步骤后，我们将得到两个数据集：一个是少数类别数据集，一个是多数类别数据集。
- en: 'Next, find the indexes of the sample dataset where the propensity is `yes`:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，找到样本数据集中倾向为 `yes` 的索引：
- en: '[PRE23]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You should get the following output:'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE24]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Separate by the minority class as in the following code snippet:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下代码片段分离少数类别：
- en: '[PRE25]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You should get the following output:'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE26]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, find the indexes of the majority class:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，找到多数类别的索引：
- en: '[PRE27]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You should get the following output:'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE28]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Separate by the majority class as in the following code snippet:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下代码片段分离多数类别：
- en: '[PRE29]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You should get the following output:'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 13.14: Output after separating the majority classes'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.14：分离大多数类别后的输出'
- en: '](img/B15019_13_14.jpg)'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_14.jpg)'
- en: 'Figure 13.14: Output after separating the majority classes'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.14：分离多数类别后的输出
- en: Once the majority class is separated, we can proceed with sampling from the
    majority class. Once the sampling is done, the shape of the majority class dataset
    and its head are printed.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦大多数类别被分离出来，我们就可以开始从大多数类别中进行采样。一旦采样完成，大多数类别数据集的形状及其头部将被打印出来。
- en: Take a random sample equal to the length of the minority class to make the dataset
    balanced.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随机采样的数量应与少数类别的长度相等，以使数据集保持平衡。
- en: 'Extract the samples using the `.sample()` function:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.sample()` 函数提取样本：
- en: '[PRE30]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The number of examples that are sampled is equal to the number of examples in
    the minority class. This is implemented with the parameters `(n=len(ind))`.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 采样的例子数量等于少数类别的例子数量。这是通过参数 `(n=len(ind))` 实现的。
- en: 'Now that sampling is done, the shape of the majority class dataset and its
    head is printed:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，采样完成后，大多数类别数据集的形状及其头部将被打印出来：
- en: '[PRE31]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'You should get the following output:'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 13.15: Output showing the shape of the majority class dataset'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.15：显示多数类别数据集的形状'
- en: '](img/B15019_13_15.jpg)'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_15.jpg)'
- en: 'Figure 13.15: Output showing the shape of the majority class dataset'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.15：显示多数类数据集形状的输出
- en: Now, we move onto preparing the new training data
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们继续准备新的训练数据
- en: 'After preparing the individual dataset, we can now concatenate them together
    using the `pd.concat()` function:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备好各个数据集后，我们可以使用`pd.concat()`函数将它们连接在一起：
- en: '[PRE32]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: In this case, we are concatenating in the vertical direction and, therefore,
    `axis = 0` is used.
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这种情况下，我们是在垂直方向上进行连接，因此使用`axis = 0`。
- en: 'Now, shuffle the dataset so that both the minority and majority classes are
    evenly distributed using the `shuffle()` function:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`shuffle()`函数打乱数据集，使少数类和多数类均匀分布：
- en: '[PRE33]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'You should get the following output:'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该得到以下输出：
- en: '![Figure 13.16: Output after shuffling the dataset'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.16：打乱数据集后的输出'
- en: '](img/B15019_13_16.jpg)'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_16.jpg)'
- en: 'Figure 13.16: Output after shuffling the dataset'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.16：打乱数据集后的输出
- en: 'Now, separate the shuffled dataset into the independent variables, `X_trainNew`,
    and dependent variables, `y_trainNew`. The separation is to be done using the
    index features `0` to `51` for the dependent variables using the `.iloc()` function
    in `pandas`. The dependent variables are separated by sub-setting with the column
    name `''y''`:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，将打乱的数据集分为自变量`X_trainNew`和因变量`y_trainNew`。可以使用`.iloc()`函数，在`pandas`中通过索引特征`0`到`51`来分离因变量。因变量通过子集化列名`'y'`来分离：
- en: '[PRE34]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You should get the following output:'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该得到以下输出：
- en: '![Figure 13.17: Shuffling the dataset into independent variables'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.17：将数据集打乱为自变量'
- en: '](img/B15019_13_17.jpg)'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_17.jpg)'
- en: 'Figure 13.17: Shuffling the dataset into independent variables'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.17：将数据集打乱为自变量
- en: Now, fit the model on the new data and generate the confusion matrix and classification
    report for our analysis.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，将模型拟合到新数据上，并生成混淆矩阵和分类报告供我们分析。
- en: 'First, define the `LogisticRegression` function with the following code snippet:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，定义`LogisticRegression`函数，代码如下：
- en: '[PRE35]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'You should get the following output:'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该得到以下输出：
- en: '![Figure 13.18: Fitting the model'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.18：拟合模型'
- en: '](img/B15019_13_18.jpg)'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_18.jpg)'
- en: 'Figure 13.18: Fitting the model'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.18：拟合模型
- en: 'Next, perform the prediction on the test with the following code snippet:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用以下代码片段对测试数据进行预测：
- en: '[PRE36]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'You should get the following output:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该得到以下输出：
- en: '[PRE37]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '`{:.2f}''.format` is used to print the string values along with the accuracy
    score, which is output from `bankModel1.score(X_test, y_test)`. In this, `2f`
    means a numerical score with two decimals.'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`''{:.2f}''.format`用于打印字符串值以及准确率分数，这是通过`bankModel1.score(X_test, y_test)`输出的。在这里，`2f`表示带有两位小数的数值分数。'
- en: 'Now, generate the confusion matrix for the model and print the results:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，生成模型的混淆矩阵并打印结果：
- en: '[PRE38]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'You should get the following output:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该得到以下输出：
- en: '![Figure 13.19: Confusion matrix for the model obtained'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.19：模型的混淆矩阵'
- en: '](img/B15019_13_19.jpg)'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_19.jpg)'
- en: 'Figure 13.19: Confusion matrix for the model obtained'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.19：模型的混淆矩阵
- en: Note
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The values can vary in the output as the modeling process is subject to variation.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 输出中的值可能会有所不同，因为建模过程会受到变化的影响。
- en: To access the source code for this specific section, please refer to [https://packt.live/348njjY](https://packt.live/348njjY).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该特定部分的源代码，请参阅[https://packt.live/348njjY](https://packt.live/348njjY)。
- en: You can also run this example online at [https://packt.live/318R81I](https://packt.live/318R81I).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在线运行此示例，网址为[https://packt.live/318R81I](https://packt.live/318R81I)。
- en: Analysis
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析
- en: Let's analyze the results and compare them with those of the benchmark logistic
    regression model that we built at the beginning of this chapter. In the benchmark
    model, we had the problem of the model being biased toward the majority class
    with a very low recall value for the `yes` cases.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析结果并与我们在本章开始时构建的基准逻辑回归模型进行比较。在基准模型中，我们面临着模型偏向于多数类，且`yes`类的召回率非常低的问题。
- en: Now, by balancing the dataset, we have seen that the recall for the minority
    class has improved tremendously, from a low of `0.32` to around `0.82`. This means
    that by balancing the dataset, the classifier has improved its ability to identify
    negative cases.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 通过平衡数据集，我们发现少数类的召回率大幅提高，从`0.32`增加到大约`0.82`。这意味着通过平衡数据集，分类器在识别负例方面的能力得到了提升。
- en: However, we can see that our overall accuracy has taken a hit. From a high of
    around 90%, it has come down to around 85%. One major area where accuracy has
    taken a hit is the number of false positives, which are those `No` cases that
    were wrongly predicted as `Yes`.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以看到整体准确率出现了下降。从大约90%的高准确率下降到约85%。准确率下降的一个主要原因是虚假正例的数量增加了，即那些错误地预测为`Yes`的`No`案例。
- en: Analyzing the result from a business perspective, this is a much better scenario
    than the one we got in the benchmark model. In the benchmark model, out of the
    total 1,566 `Yes` cases, only 506 were correctly identified. However, after balancing,
    we were able to identify 1,277 out of 1,566 customers from the dataset who were
    likely to buy term deposits, which can potentially result in a better conversion
    rate. However, the flip side of this is that the sales team will also have to
    spend a lot of time on customers who are unlikely to buy term deposits. From the
    confusion matrix, we can see that false negatives have gone up to 1,795 from the
    earlier 291 we got in the benchmark model. Ideally, we would want quadrants 2
    and 3 to come down in favor of the other two quadrants.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 从业务角度分析结果，这比我们在基准模型中得到的结果要好得多。在基准模型中，1,566个`Yes`案例中，只有506个被正确识别。然而，在平衡数据集后，我们能够从1,566个数据中识别出1,277个可能购买定期存款的客户，这可能带来更高的转化率。然而，另一方面，销售团队还需要花费大量时间处理那些不太可能购买定期存款的客户。从混淆矩阵中，我们可以看到虚假负例的数量从基准模型中的291个上升到了1,795个。理想情况下，我们希望第二和第三象限的数量下降，以便有利于另外两个象限。
- en: Generating Synthetic Samples
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成合成样本
- en: In the previous section, we looked at the undersampling method, where we downsized
    the majority class to make the dataset balanced. However, when undersampling,
    we reduced the size of the dataset. In many circumstances, downsizing the dataset
    can have adverse effects on the predictive power of the classifier. An effective
    way to counter the downsizing of the dataset is to oversample the minority class.
    Oversampling is done by generating new synthetic data points similar to those
    of the minority class, thereby balancing the dataset.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一部分中，我们讨论了欠采样方法，通过缩小多数类样本来平衡数据集。然而，使用欠采样时，我们减少了数据集的大小。在许多情况下，缩小数据集可能会对分类器的预测能力产生不利影响。应对数据集缩小的有效方法是过采样少数类。过采样是通过生成类似于少数类的合成数据点来实现，从而平衡数据集。
- en: 'Two very popular methods for generating such synthetic points are:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 生成此类合成点的两种非常流行的方法是：
- en: '**Synthetic Minority Oversampling Technique** (**SMOTE**)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合成少数类过采样技术** (**SMOTE**)'
- en: '**Modified SMOTE** (**MSMOTE**)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修改后的 SMOTE** (**MSMOTE**)'
- en: 'The way the `SMOTE` algorithm generates synthetic data is by looking at the
    neighborhood of minority classes and generating new data points within the neighborhood:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '`SMOTE`算法生成合成数据的方式是通过观察少数类的邻域，并在邻域内生成新的数据点：'
- en: '![Figure 13.20: Dataset with two classes'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.20：包含两类数据集](img/B15019_13_20.jpg)'
- en: '](img/B15019_13_20.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_20.jpg)'
- en: 'Figure 13.20: Dataset with two classes'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.20：包含两类数据集
- en: 'Let''s explain the concept of generating synthetic datasets with a pictorial
    representation. Let''s assume that *Figure 13.15* represents a dataset with two
    classes: the grey circles represent the minority class, and the black circles
    represent the majority class.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过图示来解释生成合成数据集的概念。假设*图 13.15*表示一个包含两类的 dataset：灰色圆圈代表少数类，黑色圆圈代表多数类。
- en: 'In creating synthetic points, an imaginary line connecting all the minority
    samples in the neighborhood is created and new data points are generated on this
    line, as shown in *Figure 13.16*, thereby balancing the dataset:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建合成点时，会创建一条连接所有少数类样本的假想线，并在这条线上生成新的数据点，如*图 13.16*所示，从而平衡数据集：
- en: '![Figure 13.21: Connecting samples in a neighborhood'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.21：连接邻域中的样本](img/B15019_13_21.jpg)'
- en: '](img/B15019_13_21.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_21.jpg)'
- en: 'Figure 13.21: Connecting samples in a neighborhood'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.21：连接邻域中的样本
- en: 'However, `MSMOTE` is an advancement over the `SMOTE` algorithm and has a different
    approach to generating synthetic points. `MSMOTE` classifies the minority class
    into three distinct groups: **security samples**, **border samples**, and **latent
    noise samples**. Different strategies are adopted to generate neighborhood points
    based on the group each minority class falls into.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`MSMOTE`是对`SMOTE`算法的改进，并且在生成合成点的方式上有所不同。`MSMOTE`将少数类分为三组：**安全样本**、**边界样本**和**潜在噪声样本**。根据每个少数类所属的组，采用不同的策略来生成邻域点。
- en: We will see the implementation of both `SMOTE` and `MSMOTE` in the following
    section.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的部分中看到`SMOTE`和`MSMOTE`的实现。
- en: Implementation of SMOTE and MSMOTE
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现SMOTE和MSMOTE
- en: '`SMOTE` and `MSMOTE` can be implemented from a package called `smote-variants`
    in Python. The library can be installed through `pip install` in the Colab notebook
    as shown here:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`SMOTE`和`MSMOTE`可以通过一个名为`smote-variants`的包在Python中实现。该库可以通过在Colab笔记本中使用`pip
    install`进行安装，如下所示：'
- en: '[PRE39]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: More details on the package and its different variations can be obtained at
    [https://packt.live/2QsNhat](https://packt.live/2QsNhat).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于该包及其不同版本的详细信息，请访问 [https://packt.live/2QsNhat](https://packt.live/2QsNhat)。
- en: Let's now implement both these methods and analyze the results.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们实现这两种方法并分析结果。
- en: 'Exercise 13.03: Implementing SMOTE on Our Banking Dataset to Find the Optimal
    Result'
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 13.03：在我们的银行数据集上实现SMOTE，以找到最佳结果
- en: 'In this exercise, we will generate synthetic samples of the minority class
    using `SMOTE` and then make the dataset balanced. Then, on the new balanced dataset,
    we will fit a logistic regression model and analyze the results:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用`SMOTE`生成少数类的合成样本，并使数据集达到平衡。然后，在新的平衡数据集上，我们将拟合一个逻辑回归模型并分析结果：
- en: Implement all the steps of *Exercise 13.01*, *Benchmarking the Logistic Regression
    Model on the Dataset*, until the splitting of the train and test sets (*Step 12*).
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现*练习 13.01*、*在数据集上基准化逻辑回归模型*的所有步骤，直到拆分训练集和测试集（*步骤12*）。
- en: 'Now, print the count of both the classes before we oversample:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在我们进行过采样之前，打印两个类的计数：
- en: '[PRE40]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You should get the following output:'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会看到以下输出：
- en: '[PRE41]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Note
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The counts mentioned in this output can vary because of a variability in the
    sampling process.
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个输出中提到的计数可能会有所不同，因为采样过程具有变异性。
- en: Next, we will be oversampling the training set using `SMOTE`.
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们将使用`SMOTE`对训练集进行过采样。
- en: 'Begin by importing `sv` and `numpy`:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先导入`sv`和`numpy`：
- en: '[PRE42]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The library files that are required for oversampling the training set include
    the `smote_variants` library, which we installed earlier. This is imported as
    `sv`. The other library that is required is `numpy`, as the training set will
    have to be given a `numpy` array for the `smote_variants` library.
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用于对训练集进行过采样的库文件包括我们之前安装的`smote_variants`库，它被导入为`sv`。另一个需要的库是`numpy`，因为训练集必须提供一个`numpy`数组给`smote_variants`库。
- en: 'Now, instantiate the `SMOTE` library to a variable called `oversampler` using
    the `sv.SMOTE()` function:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`sv.SMOTE()`函数将`SMOTE`库实例化为一个名为`oversampler`的变量：
- en: '[PRE43]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: This is a common way of instantiating any of the variants of `SMOTE` from the
    `smote_variants` library.
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是实例化`smote_variants`库中任何`SMOTE`变体的常见方式。
- en: 'Now, sample the process using the `.sample()` function of `oversampler`:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`oversampler`的`.sample()`函数对过程进行采样：
- en: '[PRE44]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Note
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Both the `X` and `y` variables are converted to `numpy` arrays before applying
    the `.sample()` function.
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在应用`.sample()`函数之前，`X`和`y`变量都已转换为`numpy`数组。
- en: 'Now, print the shapes of the new `X` and `y` variables and the `counts` of
    the classes. You will note that the size of the overall dataset has increased
    from the earlier count of around 31,647 (3694 + 27953) to 55,906\. The increase
    in size can be attributed to the fact that the minority class has been oversampled
    from 3,694 to 27,953:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，打印新`X`和`y`变量的形状，以及各类的`counts`。你会注意到，整体数据集的大小从先前约31,647（3694 + 27953）增加到了55,906。大小的增加可以归因于少数类的过采样，从3,694增加到27,953：
- en: '[PRE45]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'You should get the following output:'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会看到以下输出：
- en: '[PRE46]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Note
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The counts mentioned in this output can vary because of variability in the sampling
    process.
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个输出中提到的计数可能会有所不同，因为采样过程具有变异性。
- en: Now that we have generated synthetic points using `SMOTE` and balanced the dataset,
    let's fit a logistic regression model on the new sample and analyze the results
    using a confusion matrix and a classification report.
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们使用`SMOTE`生成了合成点并平衡了数据集，让我们在新的样本上拟合逻辑回归模型，并使用混淆矩阵和分类报告分析结果。
- en: 'Define the `LogisticRegression` function:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`LogisticRegression`函数：
- en: '[PRE47]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Now, predict using `.predict` on the test set, as mentioned in the following
    code snippet:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在测试集上使用`.predict`进行预测，如以下代码片段所示：
- en: '[PRE48]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Next, `print` the accuracy values:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，`print`准确度值：
- en: '[PRE49]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Your output should be as follows:'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出应如下所示：
- en: '[PRE50]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Then, generate `ConfusionMatrix` for the model:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，为模型生成`ConfusionMatrix`：
- en: '[PRE51]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The matrix is as follows:'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 矩阵如下所示：
- en: '[PRE52]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Generate `Classification_report` for the model:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为模型生成`Classification_report`：
- en: '[PRE53]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'You should get the following output:'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 13.22: Classification report for the model'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 13.22：模型的分类报告](img/B15019_13_22.jpg)'
- en: '](img/B15019_13_22.jpg)'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_22.jpg)'
- en: 'Figure 13.22: Classification report for the model'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.22：模型的分类报告
- en: From the generated metrics, we can see that the results are very similar to
    the undersampling results, with the exception that the recall value of the `'Yes'`
    cases has reduced from `0.82` to around `0.80`. The results that are generated
    vary from one use case to the next. `SMOTE` and its variants have been proven
    to have robust results in balancing data and are therefore the most popular methods
    used when encountering use cases with highly imbalanced data.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 从生成的指标中，我们可以看到结果与欠采样结果非常相似，唯一不同的是，`'Yes'`类的召回值从`0.82`下降到了大约`0.80`。生成的结果会因使用案例的不同而有所变化。`SMOTE`及其变种已被证明在数据平衡方面具有强大的效果，因此在遇到高度不平衡数据的使用案例时，成为最受欢迎的方法。
- en: Note
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The values can vary in the output as the modeling process is subject to variation.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 输出值可能有所变化，因为建模过程本身会有波动。
- en: To access the source code for this specific section, please refer to [https://packt.live/2Ycxu34](https://packt.live/2Ycxu34).
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该特定部分的源代码，请参考[https://packt.live/2Ycxu34](https://packt.live/2Ycxu34)。
- en: You can also run this example online at [https://packt.live/2FDvTgo](https://packt.live/2FDvTgo).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行此示例，访问[https://packt.live/2FDvTgo](https://packt.live/2FDvTgo)。
- en: In the next exercise, we will be implementing `MSMOTE`.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，我们将实现`MSMOTE`。
- en: 'Exercise 13.04: Implementing MSMOTE on Our Banking Dataset to Find the Optimal
    Result'
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 13.04：在我们的银行数据集上实现MSMOTE以找到最佳结果
- en: In this exercise, we will generate synthetic samples of the minority class using
    `MSMOTE` and then make the dataset balanced. Then, on the new balanced dataset,
    we will fit a logistic regression model and analyze the results. This exercise
    will be very similar to the previous one.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用`MSMOTE`生成少数类的合成样本，然后使数据集平衡。接着，在新的平衡数据集上，我们将拟合一个逻辑回归模型并分析结果。这个练习将与之前的练习非常相似。
- en: Implement all the steps of *Exercise 13.01*, *Benchmarking the Logistic Regression
    Model on the Dataset*, until the splitting of the train and test sets (*Step 12*).
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现*练习 13.01*的所有步骤，*基准化逻辑回归模型在数据集上的表现*，直到训练集和测试集的拆分（*步骤 12*）。
- en: 'Now, print the count of both the classes before we oversample:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，打印我们进行过采样前两类的计数：
- en: '[PRE54]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'You should get the following output:'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE55]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Note
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The counts mentioned in this output can vary because of variability in the sampling
    process.
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出中提到的计数值可能会有所不同，因为采样过程具有变异性。
- en: Next, we will be oversampling the training set using `MSMOTE`.
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们将使用`MSMOTE`对训练集进行过采样。
- en: 'Begin by importing the `sv` and `numpy`:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始时导入`sv`和`numpy`：
- en: '[PRE56]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The library files that are required for oversampling the training set include
    the `smote_variants` library, which we installed earlier. This is imported as
    `sv`. The other library that is required is `numpy`, as the training set will
    have to be given a `numpy` array for the `smote_variants` library.
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用于对训练集进行过采样的库文件包括我们之前安装的`smote_variants`库，已作为`sv`导入。另一个必需的库是`numpy`，因为训练集需要提供`numpy`数组供`smote_variants`库使用。
- en: 'Now, instantiate the `MSMOTE` library to a variable called `oversampler` using
    the `sv.MSMOTE()` function:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，通过`sv.MSMOTE()`函数将`MSMOTE`库实例化为一个名为`oversampler`的变量：
- en: '[PRE57]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Now, sample the process using the `.sample()` function of `oversampler`:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`oversampler`的`.sample()`函数对过程进行采样：
- en: '[PRE58]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'You should get the following output:'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE59]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Now that we have generated synthetic points using `MSMOTE` and balanced the
    dataset, let's fit a logistic regression model on the new sample and analyze the
    results using a confusion matrix and a classification report.
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们已经使用`MSMOTE`生成了合成样本并平衡了数据集，接下来让我们在新样本上拟合逻辑回归模型，并使用混淆矩阵和分类报告分析结果。
- en: 'Define the `LogisticRegression` function:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`LogisticRegression`函数：
- en: '[PRE60]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Now, predict using `.predict` on the test set as in the following code snippet:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，像下面的代码片段一样，在测试集上使用`.predict`进行预测：
- en: '[PRE61]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Next, `print` the accuracy values:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，`print`精度值：
- en: '[PRE62]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'You should get the following output:'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE63]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Generate the `ConfusionMatrix` for the model:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为模型生成`ConfusionMatrix`：
- en: '[PRE64]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The matrix should be as follows:'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 矩阵应如下所示：
- en: '[PRE65]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Generate the `Classification_report` for the model:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为模型生成`Classification_report`：
- en: '[PRE66]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'You should get the following output:'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 13.23: Classification report for the model'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 13.23：模型的分类报告'
- en: '](img/B15019_13_23.jpg)'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_13_23.jpg)'
- en: 'Figure 13.23: Classification report for the model'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.23：模型的分类报告
- en: Note
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The values can vary in the output as the modeling process is subject to variation.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 由于建模过程存在变动，输出的值可能会有所不同。
- en: To access the source code for this specific section, please refer to [https://packt.live/34bCWHd](https://packt.live/34bCWHd).
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/34bCWHd](https://packt.live/34bCWHd)。
- en: You can also run this example online at [https://packt.live/2Edccvh](https://packt.live/2Edccvh).
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行此示例，网址是 [https://packt.live/2Edccvh](https://packt.live/2Edccvh)。
- en: From the implementation of `MSMOTE`, it is seen that the metrics have degraded
    compared to the `SMOTE` implementation from *Exercise 13.03*, *Implementing SMOTE
    on Our Banking Dataset to Find the Optimal Result*. We can then conclude that
    `MSMOTE` might not be the best method for this use case.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 从`MSMOTE`的实现中可以看出，与*练习 13.03*中实现的`SMOTE`方法相比，指标有所下降，*练习 13.03*是*在我们的银行数据集上实现SMOTE以找到最佳结果*。因此，我们可以得出结论，`MSMOTE`可能不是该用例的最佳方法。
- en: Applying Balancing Techniques on a Telecom Dataset
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在电信数据集上应用平衡技术
- en: 'Now that we have seen different balancing techniques, let''s apply these techniques
    to a new dataset that is related to the churn of telecom customers. This dataset
    is available at the following link: [https://packt.live/37IvqSX](https://packt.live/37IvqSX).'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了不同的平衡技术，接下来让我们将这些技术应用到一个与电信客户流失相关的新数据集上。该数据集可以通过以下链接获取：[https://packt.live/37IvqSX](https://packt.live/37IvqSX)。
- en: This dataset has various variables related to the usage level of a mobile connection,
    such as total call minutes, call charges, calls made during certain periods of
    the day, details of international calls, and details of calls to customer services.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含与移动连接使用水平相关的各种变量，如总通话时长、通话费用、在某些时间段内拨打的电话、国际电话的详细信息以及拨打客户服务电话的详细信息。
- en: The problem statement is to predict whether a customer will churn. This dataset
    is a highly imbalanced one, with the cases where customers churn being the minority.
    You will be using this dataset in the following activity.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 问题陈述是预测客户是否会流失。这个数据集是高度不平衡的，其中客户流失的案例占少数。你将在接下来的活动中使用这个数据集。
- en: 'Activity 13.01: Finding the Best Balancing Technique by Fitting a Classifier
    on the Telecom Churn Dataset'
  id: totrans-358
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 13.01：通过在电信流失数据集上拟合分类器来寻找最佳平衡技术
- en: You are working as a data scientist for a telecom company. You have encountered
    a dataset that is highly imbalanced, and you want to correct the class imbalance
    before fitting the classifier to analyze the churn. You know different methods
    for correcting the imbalance in datasets and you want to compare them to find
    the best method before fitting the model.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 你在一家电信公司担任数据科学家。你遇到了一个高度不平衡的数据集，你希望在拟合分类器进行流失分析之前，先纠正类不平衡。你知道不同的纠正数据集不平衡的方法，并且你希望比较它们，以找出最适合的最佳方法，之后再拟合模型。
- en: In this activity, you need to implement all of the three methods that you have
    come across so far and compare the results.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，你需要实现到目前为止遇到的所有三种方法，并比较结果。
- en: Note
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You will be using the telecom churn dataset that you used in *Chapter 10*, *Analyzing
    a Dataset*.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用你在*第 10 章*，*分析数据集*中使用的电信流失数据集。
- en: Use the `MinMaxscaler` function to scale the dataset instead of the robust scaler
    function you have been using so far. Compare the methods based on the results
    you get by fitting a logistic regression model on the dataset.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`MinMaxscaler`函数来缩放数据集，而不是你一直使用的鲁棒缩放器函数。通过拟合逻辑回归模型比较两种方法的结果。
- en: 'The steps are as follows:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下：
- en: Implement all the initial steps, which include installing smote-variants and
    loading the data using pandas.
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现所有初始步骤，包括安装smote-variants并使用pandas加载数据。
- en: Normalize the numerical raw data using the `MinMaxScaler()` function we learned
    about in *Chapter 3, Binary Classification*.
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们在*第 3 章，二元分类*中学习的`MinMaxScaler()`函数规范化数值原始数据。
- en: Create dummy data for the categorical variables using the `pd.get_dummies()`
    function.
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pd.get_dummies()`函数为分类变量创建虚拟数据。
- en: Separate the numerical data from the original data frame.
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从原始数据框中分离数值数据。
- en: Concatenate numerical data and dummy categorical data using the `pd.concat()`
    function.
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pd.concat()`函数连接数值数据和虚拟分类数据。
- en: Split the earlier dataset into train and test sets using the `train_test_split()`
    function.
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split()`函数将早期的数据集拆分为训练集和测试集。
- en: Since the dataset is imbalanced, you need to perform the various techniques
    mentioned in the following steps.
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于数据集不平衡，你需要执行以下步骤中提到的各种技术。
- en: For the undersampling method, find the index of the minority class using the
    `.index()` function and separate the minority class. After that, sample the majority
    class and make the majority dataset equal to the minority class using the `.sample()`
    function. Concatenate both the minority and under-sampled majority class to form
    a new dataset. Shuffle the dataset and separate the `X` and `Y` variables.
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于欠采样方法，使用`.index()`函数找到少数类的索引并分离少数类。然后，采样多数类并使用`.sample()`函数将多数数据集调整为与少数类相同的大小。将少数类和欠采样后的多数类合并，形成一个新的数据集。打乱数据集并分离`X`和`Y`变量。
- en: Fit a logistic regression model on the under-sampled dataset and name it `churnModel1`.
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在欠采样的数据集上拟合一个逻辑回归模型，并命名为`churnModel1`。
- en: For the `SMOTE` method, create the oversampler using the `sv.SMOTE()` function
    and create the new `X` and `Y` training sets.
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`SMOTE`方法，使用`sv.SMOTE()`函数创建过采样器，并创建新的`X`和`Y`训练集。
- en: Fit a logistic regression model using `SMOTE` and name it `churnModel2`.
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`SMOTE`拟合逻辑回归模型，并命名为`churnModel2`。
- en: Import the `smote-variant` library and instantiate the `MSMOTE` algorithm using
    the `sv.MSMOTE()` function.
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`smote-variant`库并使用`sv.MSMOTE()`函数实例化`MSMOTE`算法。
- en: Create the oversampled data using the oversampler. Please note that the `X`
    and `y` variables have to be converted to a `numpy` array before oversampling
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用过采样器创建过采样数据。请注意，`X`和`y`变量在过采样之前必须转换为`numpy`数组。
- en: Fit the logistic regression model using the `MSMOTE` dataset and name the model
    `churnModel3`.
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`MSMOTE`数据集拟合逻辑回归模型，并将模型命名为`churnModel3`。
- en: Generate the three separate predictions for each model.
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个模型生成三个独立的预测。
- en: Generate separate accuracy metrics, classification reports, and confusion matrices
    for each of the predictions.
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个预测生成单独的准确性度量、分类报告和混淆矩阵。
- en: Analyze the results and select the best method.
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析结果并选择最佳方法。
- en: '**Expected Output**:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: The final metrics that you can expect will be similar to what you see here.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以期待的最终指标将与这里看到的类似。
- en: '**Undersampling Output**'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '**欠采样输出**'
- en: '![Figure 13.24: Undersampling output report'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.24：欠采样输出报告'
- en: '](img/B15019_13_24.jpg)'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_24.jpg)'
- en: 'Figure 13.24: Undersampling output report'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.24：欠采样输出报告
- en: '**SMOTE Output**'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '**SMOTE 输出**'
- en: '![Figure 13.25: SMOTE output report'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.25：SMOTE 输出报告'
- en: '](img/B15019_13_25.jpg)'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_25.jpg)'
- en: 'Figure 13.25: SMOTE output report'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.25：SMOTE 输出报告
- en: '**MSMOTE Output**'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '**MSMOTE 输出**'
- en: '![Figure 13.26: MSMOTE output report'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.26：MSMOTE 输出报告'
- en: '](img/B15019_13_26.jpg)'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_13_26.jpg)'
- en: 'Figure 13.26: MSMOTE output report'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.26：MSMOTE 输出报告
- en: Note
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You will have different output as the modeling is stochastic in nature.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 由于建模是随机性的，你将获得不同的输出。
- en: 'The solution to the activity can be found here: [https://packt.live/2GbJloz](https://packt.live/2GbJloz).'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在此处找到：[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。
- en: Summary
  id: totrans-399
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about imbalanced datasets and strategies for addressing
    imbalanced datasets. We introduced the use cases where imbalanced datasets would
    be encountered. We looked at the challenges posed by imbalanced datasets and we
    were introduced to the metrics that should be used in the case of an imbalanced
    dataset. We formulated strategies for dealing with imbalanced datasets and implemented
    different strategies, such as random undersampling and oversampling, for balancing
    datasets. We then fit different models after balancing the datasets and analyzed
    the results.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了不平衡数据集和解决不平衡数据集的策略。我们介绍了会遇到不平衡数据集的应用场景。我们探讨了不平衡数据集所带来的挑战，并介绍了在不平衡数据集的情况下应使用的评估指标。我们制定了处理不平衡数据集的策略，并实现了不同的策略，如随机欠采样和过采样，用于平衡数据集。然后，在平衡数据集后，我们训练了不同的模型并分析了结果。
- en: Balancing datasets is a very effective way to improve the performance of your
    classifiers. However, it should be noted that there could be a degradation of
    overall accuracy measures for the majority class due to balancing. What strategies
    to adopt in what situations should be arrived at based on the problem statement
    and also after rigorous experiments for those problem statements.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 平衡数据集是一种提高分类器性能的非常有效的方法。然而，应该注意的是，平衡数据集可能会导致大类的整体准确度下降。应该根据问题陈述以及在这些问题陈述下进行严格实验后，来确定在不同情况下采取哪些策略。
- en: Having learned about methods for dealing with imbalanced datasets, we will now
    be introduced to another important technique that is prevalent in many modern
    datasets called dimensionality reduction. Different techniques for dimensionality
    reduction will be addressed in *Chapter 14*, *Dimensionality Reduction*.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 学习了处理不平衡数据集的方法后，我们将介绍另一种在许多现代数据集中常见的重要技术——**降维**。降维的不同技术将在*第14章*，*降维*中讨论。
