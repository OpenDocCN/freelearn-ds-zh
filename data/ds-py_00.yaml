- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序言
- en: '|   | *"Developers are the most-important, most-valuable constituency in business
    today, regardless of industry."* |   |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '|   | *"开发者是当今商业中最重要、最有价值的群体，无论在哪个行业。"* |   |'
- en: '|   | --*Stephen O''Grady, author of The New Kingmakers* |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|   | --*斯蒂芬·奥格雷迪，《新王makers》一书的作者* |'
- en: First, let me thank you and congratulate you, the reader, for the decision to
    invest some of your valuable time to read this book. Throughout the chapters to
    come, I will take you on a journey of discovering or even re-discovering data
    science from the perspective of a developer and will develop the theme of this
    book which is that data science is a team sport and that if it is to be successful,
    developers will have to play a bigger role in the near future and better collaborate
    with data scientists. However, to make data science more inclusive to people of
    all backgrounds and trades, we first need to *democratize it by making data simple
    and accessible*—this is in essence what this book is about.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我要感谢并祝贺你，亲爱的读者，做出决定，投资宝贵的时间来阅读这本书。在接下来的章节中，我将带领你从开发者的角度来发现或重新发现数据科学，并阐述本书的主题，即数据科学是一项团队运动，如果它要成功，开发者将在不久的将来扮演更重要的角色，并且与数据科学家更好地合作。然而，为了使数据科学更加包容各行各业的人，我们首先需要通过让数据变得简单和可访问来*让它民主化*——这实际上就是本书的核心内容。
- en: Why am I writing this book?
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我为什么要写这本书？
- en: As I'll explain in more detail in [Chapter 1](ch01.xhtml "Chapter 1. Programming
    and Data Science – A New Toolset"), *Programming and Data Science – A New Toolset*,
    I am first and foremost a developer with over 20 years, experience of building
    software components of a diverse nature; frontend, backend, middleware, and so
    on. Reflecting back on this time, I realize how much getting the algorithms right
    always came first in my mind; data was always somebody else's problem. I rarely
    had to analyze it or extract insight from it. At best, I was designing the right data
    structure to load it in a way that would make my algorithm run more efficiently
    and the code more elegant and reusable.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我将在[第一章](ch01.xhtml "第一章. 编程与数据科学 – 一套新工具")中详细解释的那样，*编程与数据科学 – 一套新工具*，我首先是一名开发者，拥有超过20年的多样化软件组件构建经验；包括前端、后端、中间件等等。回顾这段时光，我意识到，每当我思考时，正确的算法总是放在首位；数据总是别人的问题。我很少需要分析数据或从中提取洞察。充其量，我只是设计合适的数据结构，以便以一种更高效、更优雅且可复用的方式加载数据，进而使我的算法运行得更加顺畅。
- en: However, as the Artificial Intelligence and data science revolution got under
    way, it became obvious to me that developers like myself needed to get involved,
    and so 7 years ago in 2011, I jumped at the opportunity to become the lead architect
    for the IBM Watson core platform UI & Tooling. Of course, I don't pretend to have
    become an expert in machine learning or NLP, far from it. Learning through practice
    is not a substitute for getting a formal academic background.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着人工智能和数据科学革命的展开，我很明显地意识到像我这样的开发者需要参与其中，因此，7年前的2011年，我抓住机会成为IBM Watson核心平台UI与工具的首席架构师。当然，我并不自称已成为机器学习或自然语言处理领域的专家，远非如此。通过实践学习并不能替代获得正式的学术背景。
- en: However, a big part of what I want to demonstrate in this book is that, with
    the right tools and approach, someone equipped with the right mathematical foundations
    (I'm only talking about high-school level calculus concepts really) can quickly
    become a good practitioner in the field. A key ingredient to being successful
    is to simplify as much as possible the different steps of building a data pipeline;
    from acquiring, loading, and cleaning the data, to visualizing and exploring it,
    all the way to building and deploying machine learning models.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我在本书中想要展示的一个重要观点是，凭借正确的工具和方法，拥有合适数学基础的人（我这里只谈高中的微积分概念）可以迅速成为这一领域的优秀从业者。成功的关键之一是尽可能简化构建数据管道的不同步骤；从获取、加载、清洗数据，到可视化和探索，再到构建和部署机器学习模型。
- en: It was with an eye to furthering this idea of making data simple and accessible
    to a community beyond data scientists that, 3 years ago, I took on a leading role
    at the IBM Watson Data Platform team with the mission of expanding the community
    of developers working with data with a special focus on education and activism
    on their behalf. During that time as the lead developer advocate, I started to
    talk openly about the need for developers and data scientists to better collaborate
    in solving complex data problems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正是出于让数据更简单、让数据科学家之外的社区也能接触到数据的想法，三年前，我在 IBM Watson 数据平台团队中担任领导角色，致力于扩大开发者社区，专注于教育和为开发者争取权益。在那个时期，作为首席开发者倡导者，我开始公开讨论开发者和数据科学家在解决复杂数据问题时需要更好地协作。
- en: Note
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: During discussions at conferences and meetups, I would sometimes get
    in to trouble with data scientists who would get upset because they interpreted
    my narrative as me saying that data scientists are not good software developers.
    I want to set the record straight, including with you, the data scientist reader,
    that this is far from the case.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：在会议和聚会上讨论时，我有时会与数据科学家产生矛盾，因为他们误解了我的叙述，以为我在说数据科学家不是优秀的软件开发人员。我想澄清一下，包括对你——数据科学家的读者——说，这绝对不是我的意思。'
- en: The majority of data scientists are excellent software developers with a comprehensive
    knowledge of computer science concepts. However, their main objective is to solve
    complex data problems which require rapid, iterative experimentations to try new
    things, not to write elegant, reusable components.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据科学家都是优秀的软件开发人员，具备全面的计算机科学知识。然而，他们的主要目标是解决复杂的数据问题，这需要快速、反复试验新事物，而不是编写优雅、可重用的组件。
- en: But I didn't want to only talk the talk; I also wanted to walk the walk and
    started the PixieDust open source project as my humble contribution to solving
    this important problem. As the PixieDust work progressed nicely, the narrative
    became crisper and easier to understand with concrete example applications that developers
    and data scientists alike could become excited about.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但我不想只是空谈，我还希望有所行动，便启动了PixieDust开源项目，作为我为解决这个重要问题所做的微薄贡献。随着PixieDust的工作进展顺利，叙述变得更加简洁易懂，开发者和数据科学家们都能为之兴奋。
- en: 'When I was presented with the opportunity to write a book about this story,
    I hesitated for a long time before embarking on this adventure for mainly two reasons:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当我被提供机会写一本关于这个故事的书时，由于两个主要原因，我犹豫了很久才开始这次冒险：
- en: 'I have written extensively in blogs, articles, and tutorials about my experience
    as a data science practitioner with Jupyter Notebooks. I also have extensive experience
    as a speaker and workshop moderator at a variety of conferences. One good example
    is the keynote speech I gave at ODSC London in 2017 titled, *The Future of Data
    Science: Less Game of Thrones, More Alliances* ([https://odsc.com/training/portfolio/future-data-science-less-game-thrones-alliances](https://odsc.com/training/portfolio/future-data-science-less-game-thrones-alliances)).
    However, I had never written a book before and had no idea of how big a commitment
    it would be, even though I was warned many times by friends that had authored
    books before.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我在博客、文章和教程中广泛写过我作为数据科学从业者使用 Jupyter Notebooks 的经验。我还在各种会议中担任过演讲者和工作坊主持人。一个很好的例子是我在
    2017 年的 ODSC 伦敦大会上发表的主题演讲，《数据科学的未来：少一些权力的游戏，多一些联盟》（[https://odsc.com/training/portfolio/future-data-science-less-game-thrones-alliances](https://odsc.com/training/portfolio/future-data-science-less-game-thrones-alliances)）。然而，我从未写过书，完全不知道这会是多么大的承诺，尽管许多曾经写过书的朋友多次提醒过我。
- en: I wanted this book to be inclusive and target equally the developer, the data
    scientist, and the line of business user, but I was struggling to find the right
    content and tone to achieve that goal.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我希望这本书能够包容不同的读者，平等地面向开发者、数据科学家以及业务线用户，但我在寻找合适的内容和语气时感到困惑。
- en: In the end, the decision to embark on this adventure came pretty easily. Having
    worked on the PixieDust project for 2 years, I felt we had made terrific progress
    with very interesting innovations that generated lots of interest in the open-source
    community and that writing a book would complement nicely our advocacy work on helping
    developers get involved in data science.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，决定踏上这段冒险之旅变得相当容易。经过两年的PixieDust项目工作，我觉得我们在这个项目中取得了非常好的进展，做出了许多有趣的创新，引起了开源社区的广泛关注，写一本书将会很好地补充我们在帮助开发者参与数据科学方面的倡导工作。
- en: As a side note, for the reader who is thinking about writing a book and who
    has similar concerns, I can only advise on the first one with a big, "Yes, go
    for it." For sure, it is a big commitment that requires a substantial amount of
    sacrifice but provided that you have a good story to tell with solid content,
    it is really worth the effort.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作为旁注，对于那些有写书打算并有类似顾虑的读者，我只能大声地建议：“是的，去做吧。”当然，这是一项需要付出巨大承诺的工作，需要大量的牺牲，但只要你有一个好的故事要讲，且内容扎实，这绝对值得付出努力。
- en: Who this book is for
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适合谁阅读
- en: This book will serve the budding data scientist and developer with an interest
    in developing their skills or anyone wishing to become a professional data scientist.
    With the introduction of PixieDust from its creator, the book will also be a great
    desk companion for the already accomplished Data Scientist.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将帮助有志于提升技能的初学数据科学家和开发者，或任何希望成为专业数据科学家的读者。由于书中引入了PixieDust的创造者，这本书还将成为已经成就非凡的数据科学家的优秀桌面伴侣。
- en: No matter the individual's level of interest, the clear, easy-to-read text and
    real-life scenarios would suit those with a general interest in the area, since
    they get to play with Python code running in Jupyter Notebooks.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 无论个人的兴趣程度如何，简洁易读的文本和现实生活中的案例都适合那些对该领域有一般兴趣的人，因为他们可以在Jupyter Notebooks中运行Python代码进行实践。
- en: To produce a functioning PixieDust dashboard, only a modicum of HTML and CSS is
    required. Fluency in data interpretation and visualization is also necessary since
    this book addresses data professionals such as business and general data analysts.
    The later chapters also have much to offer.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要制作一个功能完备的PixieDust仪表盘，只需要掌握少量的HTML和CSS。数据解读和可视化的流利性也是必不可少的，因为本书面向的数据专业人士包括商业和一般数据分析师。后面的章节也有很多内容值得学习。
- en: What this book covers
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容概述
- en: The book contains two logical parts of roughly equal length. In the first half,
    I lay down the theme of the book which is the need to bridge the gap between data
    science and engineering, including in-depth details about the Jupyter + PixieDust
    solution I'm proposing. The second half is dedicated to applying what we learned
    in the first half, to four industry cases.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本书分为两个逻辑部分，长度大致相等。在前半部分，我阐述了本书的主题，即需要弥合数据科学与工程之间的鸿沟，详细介绍了我提出的Jupyter + PixieDust解决方案。后半部分则专注于将我们在前半部分学到的内容应用于四个行业案例。
- en: '[Chapter 1](ch01.xhtml "Chapter 1. Programming and Data Science – A New Toolset"),
    *Programming and Data Science – A New Toolset*, I attempt to provide a definition
    of data science through the prism of my own experience, building a data pipeline
    that performs sentiment analysis on Twitter posts. I defend the idea that it is
    a team sport and that most often, silos exist between the data science and engineering
    teams that cause unnecessary friction, inefficiencies and, ultimately, a failure
    to realize its full potential. I also argue the point of view that data science
    is here to stay and that eventually, it will become an integral part of what is
    known today as computer science (I like to think that someday new terms will emerge,
    such as *computer data science* that better capture this duality).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[第1章](ch01.xhtml "第1章 编程与数据科学——一套新工具"), *编程与数据科学——一套新工具*，在这一章中，我试图通过自己的经验来定义数据科学，建立一个对Twitter帖子进行情感分析的数据管道。我为这个观点辩护——数据科学是一项团队运动，通常，数据科学团队和工程团队之间存在隔阂，这会导致不必要的摩擦、低效，最终无法充分发挥其潜力。我还提出数据科学将会长期存在，并且最终它将成为今天所称计算机科学的一个组成部分（我喜欢认为，总有一天会出现一些新术语，比如*计算机数据科学*，来更好地体现这一双重性）。'
- en: '[Chapter 2](ch02.xhtml "Chapter 2. Python and Jupyter Notebooks to Power your
    Data Analysis"), *Python and Jupyter Notebooks to Power your Data Analysis*, I
    start diving into popular data science tools such as Python and its ecosystem
    of open-source libraries dedicated to data science, and of course Jupyter Notebooks.
    I explain why I think Jupyter Notebooks will become the big winner in the next
    few years. I also introduce the PixieDust open-source library capabilities starting
    from the simple `display()` method that lets the user visually explore data in
    an interactive user interface by building compelling charts. With this API, the
    user can choose from multiple rendering engines such as Matplotlib, Bokeh, Seaborn,
    and Mapbox. The `display()` capability was the only feature in the PixieDust MVP
    (minimum viable product) but, over time, as I was interacting with a lot of data
    science practitioners, I added new features to what would quickly become the PixieDust
    toolbox:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[第2章](ch02.xhtml "第2章。用Python和Jupyter Notebooks推动数据分析")，*用Python和Jupyter Notebooks推动数据分析*，我开始深入探讨流行的数据科学工具，如Python及其专注于数据科学的开源库生态系统，当然还有Jupyter
    Notebooks。我解释了为什么我认为Jupyter Notebooks将在未来几年成为大赢家。我还介绍了PixieDust开源库的功能，从简单的`display()`方法开始，用户可以通过构建引人入胜的图表，在交互式用户界面中直观地探索数据。通过此API，用户可以选择多个渲染引擎，如Matplotlib、Bokeh、Seaborn和Mapbox。`display()`功能是PixieDust
    MVP（最小可行产品）中唯一的特性，但随着时间的推移，随着我与许多数据科学从业者的互动，我添加了新功能，迅速形成了PixieDust工具箱：'
- en: '**sampleData()**: A simple API for easily loading data into pandas and Apache
    Spark DataFrames'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**sampleData()**：一个简单的API，用于轻松地将数据加载到pandas和Apache Spark数据框中。'
- en: '**wrangle_data()**: A simple API for cleaning and massaging datasets. This
    capability includes the ability to destructure columns into new columns using
    regular expressions to extract content from unstructured text. The `wrangle_data()`
    API can also make recommendations based on predefined patterns.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**wrangle_data()**：一个简单的API，用于清理和处理数据集。此功能包括使用正则表达式将列拆解为新列，以提取非结构化文本中的内容。`wrangle_data()`
    API还可以根据预定义的模式提供建议。'
- en: '**PackageManager**: Lets the user install third-party Apache Spark packages
    inside a Python Notebook.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**包管理器**：允许用户在Python Notebook中安装第三方Apache Spark包。'
- en: '**Scala Bridge**: Enables the user to run the Scala code inside a Python Notebook.
    Variables defined in the Python side are accessible in Scala and vice-versa.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scala桥接**：使用户能够在Python Notebook中运行Scala代码。在Python端定义的变量可以在Scala中访问，反之亦然。'
- en: '**Spark Job Progress Monitor**: Lets you track the status of your Spark Job
    with a real-time progress bar that displays directly in the output cell of the
    code being executed.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark作业进度监控**：让你通过实时进度条跟踪Spark作业的状态，进度条直接显示在执行代码的输出单元中。'
- en: '**PixieApp**: Provides a programming model centered around HTML/CSS that lets
    developers build sophisticated dashboards to operationalize the analytics built
    in the Notebook. PixieApps can run directly in the Jupyter Notebook or be deployed
    as analytic web applications using the PixieGateway microservice. PixieGateway
    is an open-source companion project to PixieDust.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PixieApp**：提供以HTML/CSS为中心的编程模型，允许开发者构建复杂的仪表板，以将Notebook中构建的分析操作化。PixieApps可以直接在Jupyter
    Notebook中运行，也可以使用PixieGateway微服务作为分析Web应用程序进行部署。PixieGateway是PixieDust的开源配套项目。'
- en: 'The following diagram summarizes the PixieDust development journey, including
    recent additions such as the PixieGateway and the PixieDebugger which is the first
    visual Python debugger for Jupyter Notebooks:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表总结了PixieDust的发展历程，包括最近添加的PixieGateway和PixieDebugger，后者是Jupyter Notebooks中的第一个可视化Python调试器：
- en: '![What this book covers](img/B09699_preface_01.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![本书涵盖的内容](img/B09699_preface_01.jpg)'
- en: PixieDust journey
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: PixieDust历程
- en: One key message to take away from this chapter is that PixieDust is first and
    foremost an open-source project that lives and breathes through the contributions
    of the developer community. As is the case for countless open-source projects,
    we can expect many more breakthrough features to be added to PixieDust over time.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从本章中要记住的一个关键点是，PixieDust首先是一个开源项目，它通过开发者社区的贡献而生生不息。与无数开源项目一样，我们可以预期PixieDust在未来会加入更多突破性的功能。
- en: '[Chapter 3](ch03.xhtml "Chapter 3. Accelerate your Data Analysis with Python
    Libraries"), *Accelerate your Data Analysis with Python Libraries*, I take the
    reader through a deep dive of the PixieApp programming model, illustrating each
    concept along the way with a sample application that analyzes GitHub data. I start
    with a high-level description of the anatomy of a PixieApp including its life
    cycle and the execution flow with the concept of routes. I then go over the details
    of how developers can use regular HTML and CSS snippets to build the UI of the
    dashboard, seamlessly interacting with the analytics and leveraging the PixieDust
    `display()` API to add sophisticated charts.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[第3章](ch03.xhtml "第3章：使用Python库加速数据分析")，*使用Python库加速数据分析*，我将带领读者深入了解PixieApp编程模型，沿途通过一个分析GitHub数据的示例应用程序来阐明每个概念。我从PixieApp的基本结构入手，描述其生命周期和执行流程，并结合路由概念进行讲解。接着，我介绍开发者如何使用常规的HTML和CSS代码片段构建仪表盘的UI，实现与分析结果的无缝交互，并利用PixieDust的`display()`
    API添加复杂的图表。'
- en: The PixieApp programming model is the cornerstone of the tooling strategy for
    bridging the gap between data science and engineering, as it streamlines the process
    of operationalizing the analytics, thereby increasing collaboration between data
    scientists and developers and reducing the time-to-market of the application.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: PixieApp编程模型是连接数据科学与工程之间的工具策略的基石，因为它简化了将分析成果转化为可操作应用的过程，从而促进了数据科学家与开发者之间的协作，并减少了应用的上市时间。
- en: '[Chapter 4](ch04.xhtml "Chapter 4. Publish your Data Analysis to the Web -
    the PixieApp Tool"), *Publish your Data Analysis to the Web - the PixieApp Tool*,
    I discuss the PixieGateway microservice which enables developers to publish PixieApps
    as analytical web applications. I start by showing how to quickly deploy a PixieGateway
    microservice instance both locally and on the cloud as a Kubernetes container.
    I then go over the PixieGateway admin console capabilities, including the various
    configuration profiles and how to live-monitor the deployed PixieApps instances
    and the associated backend Python kernels. I also feature the chart sharing capability
    of the PixieGateway that lets the user turn a chart created with the PixieDust
    `display()` API into a web page accessible by anyone on the team.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4章](ch04.xhtml "第4章：将数据分析发布到Web - PixieApp工具")，*将数据分析发布到Web - PixieApp工具*，我讨论了PixieGateway微服务，它使开发者能够将PixieApps发布为分析型Web应用程序。我首先展示了如何在本地和云端快速部署PixieGateway微服务实例，作为Kubernetes容器。然后，我介绍了PixieGateway管理员控制台的功能，包括各种配置文件以及如何实时监控已部署的PixieApps实例和相关的Python后端内核。我还介绍了PixieGateway的图表共享功能，允许用户将使用PixieDust的`display()`
    API创建的图表转换为网页，供团队中的任何人访问。'
- en: The PixieGateway is a ground-breaking innovation with the potential of seriously
    speeding up the operationalization of analytics—which is sorely needed today—to
    fully capitalize on the promise of data science. It represents an open-source
    alternative to similar products that already exist on the market, such as the
    Shiny Server from R-Studio ([https://shiny.rstudio.com/deploy](https://shiny.rstudio.com/deploy))
    and Dash from Plotly ([https://dash.plot.ly](https://dash.plot.ly))
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: PixieGateway是一项突破性的创新，具有显著加速分析操作化的潜力——这是当今非常需要的——以充分实现数据科学的潜力。它代表了一个开源替代方案，可以与市场上已有的类似产品竞争，如R-Studio的Shiny
    Server（[https://shiny.rstudio.com/deploy](https://shiny.rstudio.com/deploy)）和Plotly的Dash（[https://dash.plot.ly](https://dash.plot.ly)）。
- en: '[Chapter 5](ch05.xhtml "Chapter 5. Python and PixieDust Best Practices and
    Advanced Concepts"), *Python and PixieDust Best Practices and Advanced Concepts*,
    I complete the deep-dive of the PixieDust toolbox by going over advanced concepts
    of the PixieApp programming model:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[第5章](ch05.xhtml "第5章：Python和PixieDust最佳实践与高级概念")，*Python和PixieDust最佳实践与高级概念*，我通过深入探讨PixieApp编程模型的高级概念，完成了对PixieDust工具箱的深度剖析：'
- en: '**@captureOutput decorator**: By default, PixieApp routes require developers
    to provide an HTML fragment that will be injected in the application UI. This is
    a problem when we want to call a third-party Python library that is not aware
    of the PixieApp architecture and directly generate the output to the Notebook.
    `@captureOutput` solves this problem by automatically redirecting the content
    generated by the third-party Python library and encapsulating it into a proper
    HTML fragment.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**@captureOutput 装饰器**：默认情况下，PixieApp 路由要求开发者提供一个将被注入到应用 UI 中的 HTML 片段。当我们想调用一个第三方
    Python 库，而该库不了解 PixieApp 架构并直接生成输出到 Notebook 时，就会出现问题。`@captureOutput` 通过自动重定向第三方
    Python 库生成的内容并将其封装成一个合适的 HTML 片段来解决这个问题。'
- en: '**Leveraging Python class inheritance for greater modularity and code reuse**:
    Breaks down the PixieApp code into logical classes that can be composed together
    using the Python class inheritance capability. I also show how to call an external
    PixieApp using the `pd_app` custom attribute.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**利用 Python 类继承提高模块化和代码重用性**：将 PixieApp 代码拆解成逻辑类，并利用 Python 类继承功能将其组合在一起。我还展示了如何通过
    `pd_app` 自定义属性调用外部 PixieApp。'
- en: '**PixieDust support for streaming data**: Shows how PixieDust `display()` and PixieApp
    can also handle streaming data.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PixieDust 对流式数据的支持**：展示了 PixieDust 的 `display()` 和 PixieApp 如何处理流式数据。'
- en: '**Implementing Dashboard drill-down with PixieApp events**: Provides a mechanism
    for letting PixieApp components publish and subscribe to events generated when
    the user interacts with the UI (for example, charts, and buttons).'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过 PixieApp 事件实现仪表盘深入分析**：提供了一种机制，让 PixieApp 组件能够发布和订阅当用户与 UI 交互时生成的事件（例如，图表和按钮）。'
- en: '**Building a custom display renderer for the PixieDust display() API**: Walks through
    the code of a simple renderer that extends the PixieDust menus. This renderer
    displays a custom HTML table showing the selected data.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**为 PixieDust display() API 构建自定义显示渲染器**：演示了一个简单渲染器的代码，扩展了 PixieDust 菜单。该渲染器展示了一个自定义的
    HTML 表格，显示所选数据。'
- en: '**Debugging techniques**: Go over the various debugging techniques that PixieDust
    offers including the visual Python debugger called PixieDebugger and the `%%PixiedustLog`
    magic for displaying Python logging messages.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调试技巧**：介绍 PixieDust 提供的各种调试技巧，包括名为 PixieDebugger 的可视化 Python 调试器，以及用于显示 Python
    日志消息的`%%PixiedustLog`魔法命令。'
- en: '**Ability to run Node.js code**: We discuss the `pixiedust_node` extension
    that manages the life cycle of a Node.js process responsible for executing arbitrary
    Node.js scripts directly from within the Python Notebook.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运行 Node.js 代码的能力**：我们讨论了 `pixiedust_node` 扩展，它管理一个 Node.js 进程的生命周期，该进程负责直接从
    Python Notebook 中执行任意的 Node.js 脚本。'
- en: Thanks to the open-source model with its transparent development process and
    a growing community of users who provided some valuable feedback, we were able
    to prioritize and implement a lot of these advanced features over time. The key
    point I'm trying to make is that following an open-source model with an appropriate
    license (PixieDust uses the Apache 2.0 license available here [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0))
    does work very well. It helped us grow the community of users, which in turn provided
    us with the necessary feedback to prioritize new features that we knew were high
    value, and in some instances contributed code in the form of GitHub pull requests.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了开放源代码模型，凭借其透明的开发过程和日益增长的用户社区提供的一些宝贵反馈，我们能够随着时间的推移优先实施许多先进的功能。我想表达的关键点是，遵循一个合适的开源模型并采用适当的许可证（PixieDust
    使用的是 Apache 2.0 许可证，详情请见 [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)）是非常有效的。它帮助我们壮大了用户社区，而社区又为我们提供了必要的反馈，帮助我们优先开发那些我们知道具有高价值的新特性，在某些情况下，甚至贡献了代码，形式为
    GitHub 拉取请求。
- en: '[Chapter 6](ch06.xhtml "Chapter 6. Analytics Study: AI and Image Recognition
    with TensorFlow"), *Analytics Study: AI and Image Recognition with TensorFlow*,
    I dive into the first of four industry cases. I start with a high-level introduction
    to machine learning, followed by an introduction to deep learning—a subfield of
    machine learning—and the TensorFlow framework that makes it easier to build neural
    network models. I then proceed to build an image recognition sample application
    including the associated PixieApp in four parts:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](ch06.xhtml "第6章：分析研究：AI与图像识别与TensorFlow")，*分析研究：AI与图像识别与TensorFlow*，我深入讲解了四个行业案例中的第一个。我从机器学习的高级介绍开始，接着介绍了深度学习——机器学习的一个子领域——以及使得构建神经网络模型更简单的TensorFlow框架。然后，我继续构建一个图像识别示例应用程序，并在四个部分中包括相关的PixieApp：'
- en: '*Part 1*: Builds an image recognition TensorFlow model by using the pretrain ImageNet
    model. Using the TensorFlow for poets tutorial, I show how to build analytics
    to load and score a neural network model.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第1部分*：使用预训练的ImageNet模型构建一个图像识别的TensorFlow模型。通过《TensorFlow for poets》教程，我展示了如何构建分析功能来加载和评分神经网络模型。'
- en: '*Part 2*: Creates a PixieApp that operationalizes the analytics created in
    *Part 1*. This PixieApp scrapes the images from a web page URL provided by the
    user, scores them against the TensorFlow model and then graphically shows the
    results.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第2部分*：创建一个PixieApp，将*第1部分*中创建的分析功能投入实际应用。这个PixieApp从用户提供的网页URL中抓取图像，将它们与TensorFlow模型进行评分，并以图形方式展示结果。'
- en: '*Part 3*: I show how to integrate the TensorBoard Graph Visualization component
    directly in the Notebook, providing the ability to debug the neural network model.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第3部分*：我展示了如何将TensorBoard图形可视化组件直接集成到Notebook中，以提供调试神经网络模型的能力。'
- en: '*Part 4*: I show how to retrain the model with custom training data and update the
    PixieApp to show the results from both models.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第4部分*：我展示了如何使用自定义训练数据重新训练模型，并更新PixieApp以展示来自两个模型的结果。'
- en: I decided to start the series of sample applications with deep learning image
    recognition with TensorFlow because it's an important use case that is growing
    in popularity and demonstrating how we can build the models and deploy them in an
    application in the same Notebook represents a powerful statement toward the theme
    of bridging the gap between data science and engineering.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定以深度学习图像识别为主题开始这一系列示例应用程序，因为这是一个日益流行的重要用例，展示了我们如何构建模型并将其部署到同一个Notebook中的应用程序，这一做法为弥合数据科学与工程之间的鸿沟提供了有力的支持。
- en: '[Chapter 7](ch07.xhtml "Chapter 7. Analytics Study: NLP and Big Data with Twitter
    Sentiment Analysis"), *Analytics Study: NLP and Big Data with Twitter Sentiment
    Analysis*, I talk about doing natural language processing at Twitter scale. In
    this chapter, I show how to use the IBM Watson Natural Language Understanding
    cloud-based service to perform a sentiment analysis of the tweets. This is very
    important because it reminds the reader that reusing managed hosted services rather
    building the capability in-house can sometimes be an attractive option.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](ch07.xhtml "第7章：分析研究：NLP与大数据——Twitter情感分析")，*分析研究：NLP与大数据——Twitter情感分析*，我谈到了在Twitter规模上进行自然语言处理。在这一章中，我展示了如何使用IBM
    Watson自然语言理解的云服务对推文进行情感分析。这一点非常重要，因为它提醒读者，有时候复用托管服务而不是自己构建能力，可能是一个更具吸引力的选择。'
- en: 'I start with an introduction to the Apache Spark parallel computing framework,
    and then move on to building the application in four parts:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我首先介绍了Apache Spark并行计算框架，然后分四部分开始构建应用程序：
- en: '*Part 1*: Acquiring the Twitter data with Spark Structured Streaming'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第1部分*：使用Spark结构化流处理获取Twitter数据。'
- en: '*Part 2*: Enriching the data with sentiment and most relevant entity extracted
    from the text'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第2部分*：通过提取文本中的情感和最相关的实体来丰富数据。'
- en: '*Part 3*: Operationalizing the analytics by creating a real-time dashboard
    PixieApp.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第3部分*：通过创建一个实时仪表盘PixieApp来实现分析功能。'
- en: '*Part 4*: An optional section that re-implements the application with Apache Kafka
    and IBM Streaming Designer hosted service to demonstrate how to add greater scalability.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第4部分*：这是一个可选部分，重新实现该应用程序，使用Apache Kafka和IBM Streaming Designer托管服务，展示如何提高可扩展性。'
- en: I think the reader, especially those who are not familiar with Apache Spark,
    will enjoy this chapter as it is a little easier to follow than the previous one.
    The key takeaway is how to build analytics that scale with Jupyter Notebooks that
    are connected to a Spark cluster.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为读者，尤其是那些不熟悉 Apache Spark 的读者，会喜欢这一章，因为它比前一章稍微容易跟随。关键的收获是如何构建可扩展的分析，利用连接到
    Spark 集群的 Jupyter Notebooks。
- en: '[Chapter 8](ch08.xhtml "Chapter 8. Analytics Study: Prediction - Financial
    Time Series Analysis and Forecasting"), *Analytics Study: Prediction - Financial
    Time Series Analysis and Forecasting*, I talk about time series analysis which
    is a very important field of data science with lots of practical applications
    in the industry. I start the chapter with a deep dive into the NumPy library which
    is foundational to so many other libraries, such as pandas and SciPy. I then proceed
    with the building of the sample application, which analyzes a time series comprised
    of historical stock data, in two parts:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[第8章](ch08.xhtml "第8章. 分析研究：预测 - 财务时间序列分析与预测")，*分析研究：预测 - 财务时间序列分析与预测*，我谈到了时间序列分析，这是数据科学中一个非常重要的领域，在工业界有许多实际应用。我从深入探讨
    NumPy 库开始，NumPy 是许多其他库（如 pandas 和 SciPy）的基础。接着，我开始构建示例应用程序，分析一个由历史股票数据组成的时间序列，分为两个部分：'
- en: '*Part 1*: Provides a statistical exploration of the time series including various
    charts such as autocorrelation function (ACF) and partial autocorrelation function
    (PACF)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第一部分*：提供了时间序列的统计探索，包括各种图表，如自相关函数（ACF）和偏自相关函数（PACF）。'
- en: '*Part 2*: Builds a predictive model based on the ARIMA algorithms using the `statsmodels`
    Python library'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第二部分*：基于 ARIMA 算法使用 `statsmodels` Python 库构建预测模型。'
- en: Time series analysis is such an important field of data science that I consider
    to be underrated. I personally learned a lot while writing this chapter. I certainly
    hope that the reader will enjoy it as well and that reading it will spur an interest
    to know more about this great topic. If that's the case, I also hope that you'll
    be convinced to try out Jupyter and PixieDust on your next learnings about time
    series analysis.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列分析是数据科学中一个非常重要的领域，我认为它被低估了。在写这章时，我个人学到了很多东西。我真心希望读者也能喜欢它，并且阅读它能够激发对这个伟大主题的兴趣。如果真是这样，我也希望你会被说服，尝试在下次学习时间序列分析时使用
    Jupyter 和 PixieDust。
- en: '[Chapter 9](ch09.xhtml "Chapter 9. Analytics Study: Graph Algorithms - US Domestic
    Flight Data Analysis"), *Analytics Study: Graph Algorithms - US Domestic Flight
    Data Analysis*, I complete this series of industry use cases with the study of
    Graphs. I chose a sample application that analyzes flight delays because the data
    is readily available, and it''s a good fit for using graph algorithms (well, for
    full disclosure, I may also have chosen it because I had already written a similar
    application to predict flight delays based on weather data where I used Apache
    Spark MLlib: [https://developer.ibm.com/clouddataservices/2016/08/04/predict-flight-delays-with-apache-spark-mllib-flightstats-and-weather-data](https://developer.ibm.com/clouddataservices/2016/08/04/predict-flight-delays-with-apache-spark-mllib-flightstats-and-weather-data)).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](ch09.xhtml "第9章. 分析研究：图算法 - 美国国内航班数据分析")，*分析研究：图算法 - 美国国内航班数据分析*，我通过研究图形算法来完成这一系列的行业应用案例。我选择了一个分析航班延误的示例应用程序，因为数据是现成的，而且非常适合使用图算法（老实说，我也可能是因为我已经写过一个类似的应用程序，基于天气数据预测航班延误，那个应用程序使用了
    Apache Spark MLlib：[https://developer.ibm.com/clouddataservices/2016/08/04/predict-flight-delays-with-apache-spark-mllib-flightstats-and-weather-data](https://developer.ibm.com/clouddataservices/2016/08/04/predict-flight-delays-with-apache-spark-mllib-flightstats-and-weather-data)）。'
- en: I start with an introduction to graphs and associated graph algorithms including
    several of the most popular graph algorithms such as Breadth First Search and
    Depth First Search. I then proceed with an introduction to the `networkx` Python
    library that is used to build the sample application.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我首先介绍了图形及其相关的图算法，包括一些最流行的图算法，如广度优先搜索（Breadth First Search）和深度优先搜索（Depth First
    Search）。接着，我介绍了用于构建示例应用程序的 `networkx` Python 库。
- en: 'The application is made of four parts:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序由四个部分组成：
- en: '*Part 1*: Shows how to load the US domestic flight data into a graph.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第一部分*：展示了如何将美国国内航班数据加载到图中。'
- en: '*Part 2*: Creates the `USFlightsAnalysis` PixieApp that lets the user select
    an origin and destination airport and then display a Mapbox map of the shortest
    path between the two airports according to a selected centrality'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第 2 部分*：创建 `USFlightsAnalysis` PixieApp，允许用户选择起点和目的地机场，然后根据选定的中心性展示两机场之间的最短路径的
    Mapbox 地图。'
- en: '*Part 3*: Adds data exploration to the PixieApp that includes various statistics
    for each airline that flies out of the selected origin airport'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第 3 部分*：为 PixieApp 添加数据探索功能，包括针对每个航司的各种统计数据，统计的是从所选起点机场起飞的航班。'
- en: '*Part 4*: Use the techniques learned in [Chapter 8](ch08.xhtml "Chapter 8. Analytics
    Study: Prediction - Financial Time Series Analysis and Forecasting"), *Analytics
    Study: Prediction - Financial Time Series Analysis and Forecasting* to build an
    ARIMA model for predicting flight delays'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第 4 部分*：使用在[第 8 章](ch08.xhtml "第 8 章. 分析学习：预测 – 财务时间序列分析与预测")，*分析学习：预测 – 财务时间序列分析与预测*
    中学到的技术，构建一个 ARIMA 模型来预测航班延误。'
- en: Graph theory is also another important and growing field of data science and
    this chapter nicely rounds up the series, which I hope provides a diverse and
    representative set of industry use cases. For readers who are particularly interested
    in using graph algorithms with big data, I recommend looking at Apache Spark GraphX
    ([https://spark.apache.org/graphx](https://spark.apache.org/graphx)) which implements
    many of the graph algorithms using a very flexible API.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图论也是数据科学中一个重要且不断发展的领域，本章很好地总结了这一系列内容，我希望它提供了一个多样且具有代表性的行业案例集。对于那些特别感兴趣于使用图算法处理大数据的读者，我建议查看
    Apache Spark GraphX ([https://spark.apache.org/graphx](https://spark.apache.org/graphx))，它通过一个非常灵活的
    API 实现了许多图算法。
- en: '[Chapter 10](ch10.xhtml "Chapter 10. The Future of Data Analysis and Where
    to Develop your Skills"), *The Future of Data Analysis and Where to Develop your
    Skills*, I end the book by giving a brief summary and explaining my take on Drew''s
    Conway Venn Diagram. Then I talk about the future of AI and data science and how
    companies could prepare themselves for the AI and data science revolution. Also,
    I have listed some great references for further learning.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 10 章](ch10.xhtml "第 10 章. 数据分析的未来及如何发展你的技能")，*数据分析的未来及如何发展你的技能*，我通过简要总结并解释
    Drew Conway 的 Venn 图来结束本书。接着我会谈到人工智能和数据科学的未来，以及公司如何为人工智能和数据科学的革命做好准备。此外，我还列出了一些有助于进一步学习的优秀参考资料。'
- en: '[Appendix](apa.xhtml "Appendix A. PixieApp Quick-Reference"), *PixieApp Quick-Reference*,
    is a developer quick-reference guide that provides a summary of all the PixieApp
    attributes. This explains the various annotations, custom HTML attributes, and
    methods with the help of appropriate examples.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[附录](apa.xhtml "附录 A. PixieApp 快速参考")，*PixieApp 快速参考*，是为开发者提供的快速参考指南，概述了所有
    PixieApp 属性。这本指南通过适当的示例解释了各种注释、自定义 HTML 属性和方法。'
- en: 'But enough about the introduction: let''s get started on our journey with the
    first chapter titled *Programming and Data Science – A New Toolset*.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 但介绍部分说得够多了：让我们从第一章开始，标题为 *编程与数据科学 – 新工具集*。
- en: To get the most out of this book
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了最大程度地从本书中受益
- en: Most of the software needed to follow the example is open source and therefore
    free to download. Instructions are provided throughout the book, starting with
    installing anaconda which includes the Jupyter Notebook server.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大部分跟随本书示例所需的软件是开源的，因此可以免费下载安装。书中提供了详细的安装说明，首先从安装 Anaconda 开始，Anaconda 包含了 Jupyter
    Notebook 服务器。
- en: 'In [Chapter 7](ch07.xhtml "Chapter 7. Analytics Study: NLP and Big Data with
    Twitter Sentiment Analysis"), *Analytics Study: NLP and Big Data with Twitter
    Sentiment Analysis*, the sample application requires the use of IBM Watson cloud
    services including NLU and Streams Designer. These services come with a free tier
    plan, which is sufficient to follow the example along.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第 7 章](ch07.xhtml "第 7 章. 分析学习：NLP 和大数据与 Twitter 情感分析")，*分析学习：NLP 和大数据与 Twitter
    情感分析*，示例应用程序需要使用 IBM Watson 云服务，包括 NLU 和 Streams Designer。这些服务提供免费的计划层，足以让你跟随本书的示例。
- en: Download the example code files
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from your account at [http://www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从 [http://www.packtpub.com](http://www.packtpub.com) 账户下载本书的示例代码文件。如果你是从其他地方购买的这本书，可以访问
    [http://www.packtpub.com/support](http://www.packtpub.com/support)，注册后文件会直接通过电子邮件发送给你。
- en: 'You can download the code files by following these steps:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照以下步骤下载代码文件：
- en: Log in or register at [http://www.packtpub.com](http://www.packtpub.com).
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录或注册 [http://www.packtpub.com](http://www.packtpub.com)
- en: Select the **SUPPORT** tab.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**支持**标签。
- en: Click on **Code Downloads & Errata**.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载与勘误**。
- en: Enter the name of the book in the **Search** box and follow the on-screen instructions.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**搜索**框中输入书名，并按照屏幕上的指示操作。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文件下载完成，请确保使用以下最新版本解压或提取文件夹：
- en: WinRAR / 7-Zip for Windows
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows版WinRAR / 7-Zip
- en: Zipeg / iZip / UnRarX for Mac
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mac版Zipeg / iZip / UnRarX
- en: 7-Zip / PeaZip for Linux
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux版7-Zip / PeaZip
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Thoughtful-Data-Science](https://github.com/PacktPublishing/Thoughtful-Data-Science).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码包也托管在GitHub上，地址是[https://github.com/PacktPublishing/Thoughtful-Data-Science](https://github.com/PacktPublishing/Thoughtful-Data-Science)。我们还有其他来自丰富书籍和视频目录的代码包，地址是[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)。快来看看吧！
- en: Download the color images
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载彩色图片
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [http://www.packtpub.com/sites/default/files/downloads/ThoughtfulDataScience_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/ThoughtfulDataScience_ColorImages.pdf).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一个PDF文件，里面有本书中使用的截图/图表的彩色图片。你可以在这里下载：[http://www.packtpub.com/sites/default/files/downloads/ThoughtfulDataScience_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/ThoughtfulDataScience_ColorImages.pdf)。
- en: Conventions used
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了多种文本约定。
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
    For example: "You can use the `{%if ...%}...{%elif ...%}...{%else%}…{%endif%}`
    notation to conditionally output text."'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`CodeInText`：表示文本中的代码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter用户名。例如：“你可以使用`{%if
    ...%}...{%elif ...%}...{%else%}…{%endif%}`符号来有条件地输出文本。”'
- en: 'A block of code is set as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块的格式如下：
- en: '[PRE0]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望特别提醒你注意代码块中的某一部分时，相关行或项会以粗体显示：
- en: '[PRE1]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出都如下所示：
- en: '[PRE2]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see on
    the screen, for example, in menus or dialog boxes, also appear in the text like
    this. For example: " The next step is to create a new route that takes the user
    value and returns the results. This route will be invoked by the **Submit Query**
    button."'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示一个新术语、重要词汇或你在屏幕上看到的词汇，例如在菜单或对话框中，也会在文本中像这样出现。例如：“下一步是创建一个新的路由，该路由接受用户值并返回结果。这个路由将通过**提交查询**按钮触发。”'
- en: Note
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Warnings or important notes appear like this.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要提示如下所示。
- en: Tip
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Tips and tricks appear like this.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和技巧如下所示。
- en: Get in touch
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们非常欢迎读者的反馈。
- en: '**General feedback**: Email `<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`,
    and mention the book''s title in the subject of your message. If you have questions
    about any aspect of this book, please email us at `<[questions@packtpub.com](mailto:questions@packtpub.com)>`.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：电子邮件`<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`，并在邮件主题中提到书籍的标题。如果你有关于本书的任何问题，请通过电子邮件联系我们`<[questions@packtpub.com](mailto:questions@packtpub.com)>`。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book we would
    be grateful if you would report this to us. Please visit, [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the **Errata Submission Form** link, and entering
    the details.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已尽一切努力确保内容的准确性，但错误仍然可能发生。如果你在本书中发现错误，我们将非常感激你能报告给我们。请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择你的书籍，点击**勘误提交表单**链接，输入相关细节。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`
    with a link to the material.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上发现任何形式的非法复制我们作品的情况，我们将非常感激您能提供该材料的地址或网站名称。请通过`<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`与我们联系，并附上相关链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [http://authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个领域有专长，并且有兴趣写书或为书籍贡献内容，请访问 [http://authors.packtpub.com](http://authors.packtpub.com)。'
- en: Reviews
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评论
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 请留下评论。在阅读和使用本书后，为什么不在您购买它的网站上留下评论呢？潜在的读者可以看到并参考您的客观意见来做出购买决策，我们在Packt也能了解您对我们产品的看法，作者们也能看到您对他们书籍的反馈。谢谢！
- en: For more information about Packt, please visit [packtpub.com](http://packtpub.com).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多关于Packt的信息，请访问 [packtpub.com](http://packtpub.com)。
