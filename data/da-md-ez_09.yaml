- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Extending Your Toolbox
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展你的工具箱
- en: Getting up to speed with the latest tools and novel techniques in data analytics
    is surely a never-ending process. In this field, you need to be ready to update
    and expand your knowledge continuously. So far in this book, we have acquired
    a number of vital, application-agnostic data techniques such as data cleaning
    and modeling, machine learning, data visualization, and storytelling. We have
    also learned how to apply them through a solid application toolbox made of KNIME
    and Power BI. As we approach the end of our journey, we should see what else is
    available and how to integrate all the applications together to make the best
    out of all of them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 迅速掌握最新的数据分析工具和新颖技术无疑是一个永无止境的过程。在这个领域，你需要时刻准备好不断更新和扩展你的知识。到目前为止，本书已经涵盖了许多至关重要、与应用无关的数据技术，如数据清理与建模、机器学习、数据可视化和讲故事技巧。我们还学会了如何通过一个由KNIME和Power
    BI组成的坚实应用工具箱来应用这些技术。随着我们接近旅程的尽头，我们应该看看还有哪些工具可用，并且如何将所有应用整合在一起，充分发挥它们的最大潜力。
- en: 'In particular, we will cover the following questions:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将特别讨论以下问题：
- en: What is Tableau, and how can I use it for visualization and storytelling?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是Tableau，我如何使用它进行可视化和讲故事？
- en: What is Python, and how do I get started with it?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是Python，我如何开始使用它？
- en: How can I boost my workflows by integrating Python or any other code?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我如何通过集成Python或其他代码来提升我的工作流？
- en: How can I use KNIME extension packages to add functionalities?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用KNIME扩展包来增加功能？
- en: What is automated machine learning, and what should I expect from its future
    business applications?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是自动化机器学习，我应该对其未来的商业应用有何期待？
- en: This chapter is not meant to make you an autonomous user of Python, Tableau,
    and other tools. There is no need for it at this stage. Your initial toolbox (KNIME
    and Power BI) covers your essential analytical needs well. The point of this chapter
    is to show you what *else* is available and make you curious and excited about
    the many directions you can take to expand your abilities in data analytics from
    now on.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章并不是为了让你成为Python、Tableau和其他工具的自主使用者。此阶段并不需要这样。你最初的工具箱（KNIME和Power BI）已经很好地满足了你的基本分析需求。本章的重点是向你展示*其他*可用的工具，并激发你对数据分析未来各种扩展方向的好奇心和兴奋感。
- en: 'We will first look at Tableau, another data visualization tool: by means of
    a simple example, we will see how what we learned for Power BI can be easily applied
    in Tableau as well. Then, we will learn about Python and get a friendly introduction
    to how it is used in analytics. We will see how to integrate Python code into
    KNIME through extension packages. Lastly, we will learn about automated machine
    learning and see the concept in action with the help of the H2O.ai platform. All
    the tools in this chapter are either open source or provide free trial options
    so that you have the opportunity to put your hands on them and evaluate by yourself
    how they can help you and your business.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先介绍Tableau，另一个数据可视化工具：通过一个简单的例子，我们将看到如何将我们在Power BI中学到的知识轻松应用到Tableau中。接下来，我们将学习Python，并获得如何在分析中使用它的友好介绍。我们将看到如何通过扩展包将Python代码集成到KNIME中。最后，我们将了解自动化机器学习，并借助H2O.ai平台看到这一概念的实际应用。本章中的所有工具要么是开源的，要么提供免费试用选项，因此你有机会亲自尝试并评估它们如何帮助你和你的业务。
- en: Getting started with Tableau
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用Tableau
- en: Founded as a Stanford University spin-off, Tableau has pioneered in the data
    visualization arena for nearly two decades and is now regarded as one of the leading
    business intelligence platforms. Its straightforward drag-and-drop user interface,
    the integration with many data platforms, and its highly customizable, high-quality
    chart types have made Tableau very popular among business professionals, analysts,
    and data journalists.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Tableau作为斯坦福大学的衍生公司，已经在数据可视化领域开创了近二十年的先河，现在被认为是领先的商业智能平台之一。其直观的拖放式用户界面、与多种数据平台的集成以及高度可定制、高质量的图表类型，使得Tableau在商业专业人士、分析师和数据记者中非常受欢迎。
- en: 'Similar to Power BI, Tableau comes in different versions. In this chapter,
    we will use **Tableau Public**: this is a free desktop application (you can download
    it from [public.tableau.com](http://public.tableau.com)) that has nearly all the
    functionalities included in the full version (called **Desktop Professional**)
    but also a couple of important limitations. First, it relies on local data, so
    you cannot connect to remote data sources. Additionally, the public version lets
    you save your result solely on the public Tableau server, which is open to everyone:
    this means you cannot save your work on your computer. Given its lack of privacy
    protection, Tableau Public is not viable for day-to-day business needs, but we
    can still use it for exploring Tableau functionalities and comparing them with
    Power BI''s.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Power BI 类似，Tableau 有不同版本。本章我们将使用 **Tableau Public**：这是一款免费的桌面应用程序（您可以从 [public.tableau.com](http://public.tableau.com)
    下载），它几乎包含了完整版（名为 **Desktop Professional**）中的所有功能，但也有一些重要的限制。首先，它依赖本地数据，因此您无法连接到远程数据源。此外，公共版本仅允许将结果保存在公共
    Tableau 服务器上，该服务器对所有人开放：这意味着您无法将工作保存在计算机上。由于缺乏隐私保护，Tableau Public 不适用于日常业务需求，但我们仍然可以用它来探索
    Tableau 的功能，并与 Power BI 进行对比。
- en: You can publish dashboards online using the cloud-based service called **Tableau
    Server**. You can also design dashboards just using your browser and avoid the
    installation of new software. To do so, you will need to register with the Tableau
    Public website mentioned above, go to your profile, and click on **Create a Viz**.
    The user interface on the web app is very similar to the one you could find in
    the desktop application, which we will use in this chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用基于云的服务 **Tableau Server** 在线发布仪表板。您还可以仅通过浏览器设计仪表板，避免安装新软件。为此，您需要在上述 Tableau
    Public 网站注册，进入个人资料页面，点击 **Create a Viz**。网页版应用的用户界面与我们将在本章中使用的桌面应用非常相似。
- en: 'Following the spirit we kept throughout the book, let''s explore Tableau through
    practice by getting our hands on it. In this short tutorial, we will create a
    couple of visualizations based on the sales database we leveraged in *Chapter
    6*, *Getting Started with Power BI*: a treemap to display the relative weight
    of categories and a line chart that shows the evolution of sales over time. This
    time, the three tables (Transactions, ProductMD, and CustomerMD) are saved as
    separate sheets in one single Excel file (`SalesDashboardTableau.xlsx`):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 延续本书始终贯穿的精神，让我们通过实践来探索 Tableau。 在这篇简短的教程中，我们将基于第*6章*《Power BI入门》中使用的销售数据库创建几种可视化：一个展示各类别相对权重的树状图和一个展示销售随时间变化的折线图。这次，三个表格（Transactions，ProductMD
    和 CustomerMD）保存在一个单独的 Excel 文件 (`SalesDashboardTableau.xlsx`) 的不同工作表中：
- en: Open Tableau Public. In the first screen (which looks similar to what you see
    in *Figure 9.1*), click on **Microsoft Excel** on the left and open the file containing
    our data:![](img/B17125_09_01.png)
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Tableau Public。在第一个屏幕上（看起来类似于*图 9.1*），点击左侧的 **Microsoft Excel**，并打开包含我们数据的文件：![](img/B17125_09_01.png)
- en: 'Figure 9.1: The initial screen of Tableau Public: select the type of files
    you want to use on the left'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.1：Tableau Public 的初始屏幕：在左侧选择您想使用的文件类型
- en: In the next window, called the **Data Source** screen (*Figure 9.2*), you will
    find on the left the three sheets included in the Excel file we just opened. By
    dragging them on the blank area on the top left, you can build an entity-relationship
    diagram that defines the dashboard's underlying data model:![Graphical user interface,
    table
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个窗口，名为 **Data Source** 屏幕（*图 9.2*）中，您将在左侧看到我们刚刚打开的 Excel 文件中的三个工作表。通过将它们拖到左上方的空白区域，您可以构建一个实体关系图，定义仪表板的基础数据模型：![图形用户界面，表格
- en: Description automatically generated](img/B17125_09_02.png)
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_09_02.png)
- en: 'Figure 9.2: The Data Source screen in Tableau: drag and drop your source tables
    and build the data model'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.2：Tableau 中的数据源屏幕：拖放您的源表格并构建数据模型
- en: 'To do so, we need to follow the right order. First, drag the **Transactions**
    table and wait a few seconds for the data to load and the preview to appear on
    the bottom. Then, drag the Customer Master Data (**CustomerMD**) table and drop
    it on the right of the **Transactions** box: the line between the two indicates
    that Tableau will join the two tables. As you release the mouse button, the **Edit
    Relationship** window will appear (*Figure 9.3*): Tableau has successfully identified
    *Customer ID* as the column to be used for matching rows. We can confirm the relationship
    by closing the window, without making any changes to the default settings. Once
    this is done, it''s time to drag also the Product Master Data (**ProductMD**)
    table to the right of **Transactions**, making sure that the resulting connections
    look similar to what you had in *Figure 9.2*. Finally, confirm *StockCode* as
    the matching column by closing the window that pops up: your data model is good
    to go:'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们需要按照正确的顺序操作。首先，拖动**交易（Transactions）**表并等待几秒钟，直到数据加载并且预览出现在底部。然后，拖动客户主数据（**CustomerMD**）表并将其放置在**交易**框的右侧：两者之间的线表明
    Tableau 将连接这两个表。当你释放鼠标按钮时，**编辑关系（Edit Relationship）**窗口将出现（*图 9.3*）：Tableau 成功识别出*客户
    ID（Customer ID）*作为用于匹配行的列。我们可以通过关闭窗口来确认该关系，而不对默认设置进行任何更改。一旦完成此操作，就可以将产品主数据（**ProductMD**）表拖动到**交易**右侧，确保结果连接与*图
    9.2*中的相似。最后，通过关闭弹出的窗口确认*StockCode*作为匹配列：你的数据模型准备就绪。
- en: '![Graphical user interface, application'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序'
- en: Description automatically generated](img/B17125_09_03.png)
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_09_03.png)
- en: 'Figure 9.3: Edit Relationship window: select one or more matching conditions
    for your joins'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.3：编辑关系窗口：为你的连接选择一个或多个匹配条件
- en: 'To proceed further, click on the **Sheet 1** tab on the bottom left: you will
    land in the main interface of Tableau, called **Workspace** (*Figure 9.4*). Let''s
    explore the four fundamental sections in the workspace:'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了继续，点击底部左侧的**工作表 1**标签：你将进入 Tableau 的主界面，称为**工作区（Workspace）**（*图 9.4*）。让我们来探索工作区中的四个基本部分：
- en: A. The **Data Panel** is where you find all your data columns, organized by
    table. From here, you will drag the quantities you wish to use in a visualization
    or create calculated fields. This is similar to the **Fields** section in Power
    BI.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**数据面板（Data Panel）**是你找到所有数据列的地方，按表格进行组织。在这里，你可以拖动你希望在可视化中使用的量，或者创建计算字段。这类似于
    Power BI 中的**字段（Fields）**部分。'
- en: B. The **Visualization View** is where you can build your visuals. From here,
    you can connect the fields available in the data panel with the visual attributes
    in a visual, which in Tableau are called **Shelves**. For example, the height
    of bars, the position of points, their color, size, and the text appearing on
    the labels are all controlled through the **Rows**, **Columns** and **Marks**
    shelves that you find in the visualization view (their usage will become clearer
    as we go through the tutorial). From the same view, you can also implement pagination
    and split one visual into multiple pages, each one showing different values for
    a given column (that you have to drop in the **Pages** shelf). Additionally, from
    the visualization view, you can decide which fields to use for limiting the data
    to be visualized (**Filters** shelf).
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**可视化视图**是你可以构建可视化内容的地方。在这里，你可以将数据面板中可用的字段与可视化中的视觉属性连接，在 Tableau 中，这些视觉属性被称为**架子（Shelves）**。例如，条形图的高度、点的位置、它们的颜色、大小以及标签上显示的文本，都是通过**行（Rows）**、**列（Columns）**和**标记（Marks）**架子来控制的（它们的使用将在我们进行教程时变得更加清晰）。在同一视图中，你还可以实现分页功能，并将一个可视化拆分为多个页面，每个页面显示给定列的不同值（你需要将该列拖到**页面（Pages）**架子上）。此外，在可视化视图中，你可以决定使用哪些字段来限制要显示的数据（**筛选器（Filters）**架子）。'
- en: C. The **Show Me Panel** is where you can select the type of chart to use, such
    as line charts, treemaps, histograms, or geographic maps.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**显示面板（Show Me Panel）**是你可以选择使用的图表类型的地方，比如折线图、树形图、直方图或地理图。'
- en: 'D. The bar at the bottom lets you add **Sheet tabs** and navigate through them.
    In Tableau, every sheet can be one among three different types: a Worksheet (a
    single chart), a Dashboard (a composition of multiple charts), or a Story (a controlled
    sequence of worksheets or dashboards that progress to convey a data story, as
    you learned to do in *Chapter 8*, *Telling Stories with Data*):'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 底部的条形图让你添加**工作表标签**并在它们之间进行导航。在 Tableau 中，每个工作表可以是三种不同类型之一：工作表（一个单独的图表）、仪表板（多个图表的组合）或故事（一个受控的工作表或仪表板序列，旨在传达数据故事，如你在*第8章*《用数据讲故事》中学到的那样）：
- en: '![](img/B17125_09_04.png)'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B17125_09_04.png)'
- en: 'Figure 9.4: The Workspace screen in Tableau: drag and drop columns to the visualization
    features, pick chart types, and move across visuals, dashboards, and stories'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.4：Tableau中的工作区界面：将列拖放到可视化特性中，选择图表类型，并在可视化、仪表板和故事之间切换
- en: Now that we are acquainted with the workspace interface, we can build our first
    chart to show the relative size of each category and subcategory in terms of sales.
    However, we do not yet have a column carrying the revenues generated by each transaction
    and, so, we need to first add a calculated field that does the math for us.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们已经熟悉了工作区界面，可以构建我们的第一个图表，以展示每个类别和子类别在销售额方面的相对大小。然而，我们还没有包含每笔交易生成的收入的列，因此，我们需要首先添加一个计算字段来为我们进行数学计算。
- en: Right click on the *Price* column available in the **Data Panel** and then select
    **Create** | **Calculated Field…** as shown in *Figure 9.5*:![Graphical user interface,
    application
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击**数据面板**中的*价格*列，然后选择**创建** | **计算字段…**，如*图9.5*所示：![图形用户界面，应用程序
- en: Description automatically generated](img/B17125_09_05.png)
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_09_05.png)
- en: 'Figure 9.5: Creating a calculated field in Tableau: we can add math formulas
    and generate new quantities to be visualized'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.5：在Tableau中创建计算字段：我们可以添加数学公式并生成新的量来进行可视化
- en: 'You will be prompted with a dialog (*Figure 9.6*) that lets you enter the name
    of the new column (in the text box on the top left—we are going for `Sales` in
    this case) and the mathematical expression to be used, where fields are indicated
    through square brackets. Click on the little arrow showing on the far right of
    the window. You will open an extra panel that, similarly to what we had in the
    **Math Formula** node in KNIME, provides many logical and mathematical functions
    to be used, together with a textual description on the right. In our case, the
    expression `[Price]*[Quantity]` will do: write it in the box on the left (Tableau
    will help by attempting to autocomplete the names of the columns as you type them)
    and then click on **OK** to move on. The new calculated field will appear in the
    **Data Panel** and can now be used as we wish:'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 系统会弹出一个对话框（*图9.6*），让你输入新列的名称（在左上角的文本框中——在本例中我们使用`Sales`），以及要使用的数学表达式，其中字段通过方括号表示。点击窗口最右侧的小箭头。你将打开一个额外的面板，类似于我们在KNIME的**数学公式**节点中看到的那样，提供许多可用的逻辑和数学函数，并且右侧有文本描述。在我们的案例中，表达式`[Price]*[Quantity]`就可以：将其写入左侧的框中（Tableau会在你输入列名时帮助自动补全），然后点击**确定**继续。新的计算字段将出现在**数据面板**中，之后可以根据需要使用：
- en: '![](img/B17125_09_06.png)'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B17125_09_06.png)'
- en: 'Figure 9.6: Defining a calculated field: add the math expression that combines
    columns as you need'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.6：定义计算字段：根据需要添加合并列的数学表达式
- en: 'We now have all the ingredients to bake our first visual: having learned in
    *Chapter 7,* *Visualizing Data Effectively**BI*, how to resist the sweet temptation
    of using pie charts, we want to build a nice treemap that shows the relative magnitude
    of sales by category and subcategory. Building a visual in Tableau requires dragging
    the data fields of interest (the columns listed in the data panel on the left)
    and dropping them to some visual attributes (the shelves appearing in the visualization
    view). In the case of the treemap, you can follow the arrows in *Figure 9.7* as
    a guide. Start by dropping *Category* (first) and *Subcategory* (second) in the
    box called **Text** (it will be automatically renamed to **Label** later, when
    the chart type is established). Then, take the newly created *Sales* field and
    drop it in the **Size** box. Lastly, get the *Category* field to also control
    the color of the areas by dropping it to the **Color** box:![](img/B17125_09_07.png)'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在拥有了制作第一个可视化所需的所有元素：在*第7章*中学习了如何抵制使用饼图的甜蜜诱惑后，我们希望构建一个漂亮的树形图，展示按类别和子类别的销售相对大小。
    在Tableau中构建可视化需要将感兴趣的数据字段（左侧数据面板中列出的列）拖放到一些可视化属性（在可视化视图中显示的货架）。对于树形图，你可以按照*图9.7*中的箭头作为指南。首先将*类别*（第一个）和*子类别*（第二个）拖到名为**文本**的框中（稍后在确定图表类型时，它会自动重命名为**标签**）。然后，将新创建的*销售额*字段拖到**大小**框中。最后，将*类别*字段也拖到**颜色**框中，以控制区域的颜色：![](img/B17125_09_07.png)
- en: 'Figure 9.7: Building a treemap in Tableau: take the fields on the left and
    drop them to the right box in the Marks shelf'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.7：在Tableau中构建树形图：将左侧的字段拖放到标记架右侧的框中
- en: After you build a visual in Tableau, you can easily explore alternative versions
    where different chart types are applied to the same data. To try this, click on
    the various boxes you find in the **Show Me** panel on the right. The chart types
    that cannot be rendered given the current data are grayed out, and you cannot
    select them. Tableau might also recommend one specific chart type and highlight
    its border in orange. I recommend you choose the chart type by always keeping
    the business question in mind, as you learned in *Chapter 7*, *Visualizing Data
    Effectively*.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在Tableau中构建可视化图表后，你可以轻松地探索不同版本，其中将不同的图表类型应用于相同的数据。要尝试这个操作，请点击右侧**Show Me**面板中的各种框。那些由于当前数据无法渲染的图表类型会被灰显，且无法选择。Tableau还可能推荐一种特定的图表类型，并用橙色突出其边框。我建议你在选择图表类型时始终牢记商业问题的背景，正如你在*第7章*中学到的那样，*有效地可视化数据*。
- en: Well done! With just four drag and drops, you have built your first visual in
    Tableau. We can easily see how the "Home" *Category* (and—within it—the "Kitchen"
    *Subcategory*) generates the biggest revenue bucket in our business.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 做得好！只需四次拖放，你就已在Tableau中构建了第一个可视化图表。我们可以轻松地看到“家居”*类别*（以及其中的“厨房”*子类别*）为我们的业务创造了最大的一块收入。
- en: 'Let''s move to the second business question: this time, we want to focus our
    message on the trend of *Sales* by *Category*. We decide to put together a line
    chart as it is our natural chart type for communicating insights related to the
    evolution of quantities over time.'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来是第二个商业问题：这次，我们希望将信息重点放在按*类别*划分的*销售额*趋势上。我们决定创建一个折线图，因为它是我们用来传达与数量随时间变化相关的见解的自然图表类型。
- en: 'To create a new visual, click on the first small **+** icon on the right of
    the **Sheet 1** tab at the bottom (alternatively, you can click on **Worksheet
    | New Worksheet** from the top menu, or just press *CTRL* + *M*). By doing this,
    a blank **Sheet 2** appears: this is the space to draw our line chart on.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建一个新的可视化图表，点击底部**Sheet 1**标签右侧的第一个小**+**图标（或者，你可以点击顶部菜单中的**工作表 | 新建工作表**，或者直接按*CTRL*
    + *M*）。这样会出现一个空白的**Sheet 2**：这是我们绘制折线图的空间。
- en: 'The first field to drag is *Invoice time*: drop it to the **Columns** shelf.
    Given its type (carrying the date and time of each transaction), we need to tell
    Tableau at which level of granularity (years, quarters, months, weeks, and so
    on) we want to aggregate. In this case, we want to visualize one data point for
    every month of transactions: right-click on the field as it appears on the shelf,
    and then select the second **Month** entry in the pop-up menu (use *Figure 9.8*
    as a guide):![Graphical user interface, application'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个拖动的字段是*发票时间*：将其拖到**列**架上。考虑到其类型（包含每个交易的日期和时间），我们需要告诉Tableau我们希望按哪个粒度级别（年、季度、月、周等）进行聚合。在此情况下，我们希望可视化每个月交易的一个数据点：右键单击该字段在架上的显示方式，然后在弹出菜单中选择第二个**月**项（参考*图9.8*作为指导）：![图形用户界面，应用程序
- en: Description automatically generated](img/B17125_09_08.png)
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_09_08.png)
- en: 'Figure 9.8: Using a date field for a line chart: right-click on the field and
    select the time granularity you need. In this case, we go for months'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.8：使用日期字段进行折线图：右键单击该字段并选择所需的时间粒度。在本例中，我们选择按月份进行聚合。
- en: 'Let''s move on to implementing the other fields we want to use, following the
    drag and drops you see in *Figure 9.9*. Drop *Sales* to the **Rows** shelf (by
    default, the aggregation by sum is applied, but you can change it easily by right-clicking
    on the field and picking the proper function in the **Measure** submenu). The
    following field to move is *Category*. Drop it twice: first to the **Color** box
    (so we differentiate lines by *Category*) and then to the **Label** box (so we
    show a direct label for each line):![](img/B17125_09_09.png)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们实现我们想要使用的其他字段，按照*图9.9*中的拖放操作进行。将*销售额*拖到**行**架上（默认情况下会应用求和聚合，但你可以通过右键单击该字段并在**度量**子菜单中选择适当的函数轻松更改）。下一个要移动的字段是*类别*。将其拖放两次：首先拖到**颜色**框（这样我们就可以按*类别*区分线条），然后拖到**标签**框（这样我们就可以为每条线显示直接标签）：![](img/B17125_09_09.png)
- en: 'Figure 9.9: Building a line chart in Tableau: the columns and rows shelves
    control the x- and the y-axis, respectively'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.9：在Tableau中构建折线图：列和行架分别控制x轴和y轴
- en: Before composing our dashboard, we can edit the sheet names at the bottom by
    right-clicking on each tab and selecting **Rename**. We can go for something more
    meaningful like `Business by category` and `Sales trend` for the first and the
    second visualizations, respectively.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在编排仪表板之前，我们可以通过右键点击每个标签并选择**Rename**来编辑底部的工作表名称。我们可以为第一个和第二个可视化选择更有意义的名称，比如`Business
    by category`和`Sales trend`。
- en: It's time to build the dashboard by combining the two visuals. Click on the
    second **+** icon in the **Sheets** tab at the bottom or select **Dashboard |
    New Dashboard** from the top menu.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是通过组合这两个可视化来构建仪表板的时机。点击底部**Sheets**选项卡中的第二个**+**图标，或者从顶部菜单中选择**Dashboard |
    New Dashboard**。
- en: On the left of the new dashboard view, you will find a list of the two worksheets
    we built, one for each chart we created. To create a dashboard, you will just
    need to drag and drop the worksheets in the blank area on the right, as you can
    see in *Figure 9.10*:![Chart
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新仪表板视图的左侧，您会找到我们构建的两个工作表列表，每个工作表对应一个我们创建的图表。要创建仪表板，只需将工作表拖放到右侧的空白区域，就像在*图 9.10*中看到的那样：![图表
- en: Description automatically generated](img/B17125_09_10.png)
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_09_10.png)
- en: 'Figure 9.10: Building a dashboard in Tableau: drag and drop the visualizations
    to their positions'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.10：在 Tableau 中构建仪表板：将可视化拖放到它们的位置
- en: On the bottom left of the dashboard view, you find several icons that you can
    drag and drop to your dashboard to add additional objects, such as text labels,
    images, web pages, or extensions. Check it out.
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在仪表板视图的左下方，你会找到几个图标，可以将它们拖放到仪表板中，添加额外的对象，比如文本标签、图片、网页或扩展程序。试试看吧。
- en: 'Before publishing the dashboard, let''s configure the interactions across visuals.
    If you click on any empty space of the first visual, you will select it, and its
    borders get highlighted (letting you adjust its shape, if you wish). Also, a few
    icons will appear on the top right of the selected visual, as you can see in *Figure
    9.11*. If you click on the filter icon, as the arrow in the picture indicates,
    you will set that visual as a filter for every other visual in the dashboard.
    You can quickly test that this works properly: if you click on any subcategory
    in the treemap (you can select more than one at once by keeping the *CTRL* key
    pressed), you will notice that the line chart updates accordingly, showing only
    the trend of the selection portion of business. This is exactly what we were after:![Chart,
    treemap chart'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在发布仪表板之前，让我们配置各可视化之间的交互。如果你点击第一个可视化的任何空白区域，它将被选中，且其边框会高亮（让你可以调整形状，如果需要的话）。同时，几个图标会出现在选中可视化的右上角，正如在*图
    9.11*中看到的那样。如果你点击过滤器图标，正如图中的箭头所示，你将把该可视化设置为仪表板中所有其他可视化的过滤器。你可以快速测试这个功能是否正常工作：如果你点击矩形树图中的任何子类别（你可以按住*CTRL*键一次选择多个子类别），你会注意到折线图会相应更新，只显示所选部分的趋势。这正是我们所期待的：![图表，矩形树图
- en: Description automatically generated](img/B17125_09_11.png)
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_09_11.png)
- en: 'Figure 9.11: Use a visual for filtering subsequent charts in a Tableau dashboard.Click
    on the filter icon in the top right'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.11：在 Tableau 仪表板中使用可视化过滤后续图表。点击右上角的过滤器图标
- en: 'We can now publish our work on the server: just open the **File** menu at the
    top and then click on **Save to Tableau Public…**. Next, pick a name (I went for
    `Ecom Sales Dashboard`), click on **OK**, and wait for a few seconds for the data
    to upload. Your browser will open up and show your published dashboard in all
    its grace (you can check my version out at [tiny.cc/ecomdashboard](http://tiny.cc/ecomdashboard)
    and in *Figure 9.12*):![Chart, treemap chart'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以将工作发布到服务器：只需打开顶部的**File**菜单，然后点击**Save to Tableau Public...**。接下来，选择一个名称（我选择了`Ecom
    Sales Dashboard`），点击**OK**，并等待几秒钟，直到数据上传完成。浏览器将自动打开并显示发布的仪表板，尽显优雅（你可以在 [tiny.cc/ecomdashboard](http://tiny.cc/ecomdashboard)
    查看我的版本，并在*图 9.12*中看到）：![图表，矩形树图
- en: Description automatically generated](img/B17125_09_12.png)
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B17125_09_12.png)
- en: 'Figure 9.12: The dashboard published on the Tableau Public server: let others
    access your work and interact with it'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.12：发布在 Tableau Public 服务器上的仪表板：让其他人访问并与之互动
- en: 'In the last few pages, we ran through the fundamental functionalities of Tableau:
    we have learned how to load data, combine it in a simple data model, created calculated
    fields, and built visuals and combined them in an interactive dashboard. I am
    sure you noticed the extensive similarities between Tableau and what we have learned
    on Power BI. We could carry on in the exploration of other business intelligence
    platforms such as Qlik, MicroStrategy, and TIBCO Spotfire, to mention a few. The
    (exciting) reality is that the *bulk* of how they work is very similar, and the
    last few chapters have equipped you with all you need to get started and create
    value for your business, irrespective of the tool you used.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几页中，我们快速浏览了 Tableau 的基本功能：我们学习了如何加载数据，如何在一个简单的数据模型中组合数据，创建计算字段，构建可视化并将它们结合在一个交互式仪表板中。我相信你已经注意到
    Tableau 与我们在 Power BI 上所学内容之间的相似性。我们本可以继续探索其他商业智能平台，如 Qlik、MicroStrategy 和 TIBCO
    Spotfire，仅举几例。令人（兴奋的）现实是，它们的工作原理大致相同，最后几章已经为你提供了开始并为你的业务创造价值所需的一切，无论你使用哪个工具。
- en: Let's now move to the next "expansion" phase of our data analytics toolbox with
    Python.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们进入数据分析工具箱的下一个“扩展”阶段，继续使用 Python。
- en: Python for data analytics
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于数据分析的 Python
- en: Python is an increasingly popular high-level programming language that is particularly
    well suited for data analytics and machine learning applications. The ample availability
    of analytics-related libraries and its easy-to-learn syntax make it the preferred
    choice for many data science practitioners.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是一种日益流行的高级编程语言，特别适用于数据分析和机器学习应用。丰富的数据分析相关库的可用性以及易学的语法，使其成为许多数据科学从业者的首选。
- en: The story behind Python's name has nothing to do with snakes. Its creator, Dutch
    programmer Guido van Rossum, was a big fan of the 1970s BBC comedy series "Monty
    Python's Flying Circus." So he picked Python as the name of the project to honor
    the irreverent genius of the British comedy troupe running that show.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Python 名字背后的故事与蛇无关。它的创造者，荷兰程序员 Guido van Rossum，是 1970 年代 BBC 喜剧系列《Monty Python's
    Flying Circus》的忠实粉丝。所以他为这个项目选择了 Python 这个名字，以此向那个节目中英国喜剧团体的不拘一格的天才致敬。
- en: As this book focuses on visual programming, we will not go through any thorough
    explanation of coding principles. Instead, the purpose of this section is to let
    you see Python in action on a familiar problem and get some perspective on how
    it can be used in our everyday work. We will first go through a script that repeats
    the exact same regression tutorial we saw in *Chapter 5*, *Applying Machine Learning
    at Work*. Then, we will see how Python can smoothly integrate with KNIME to make
    the best out of the two complementary approaches to programming for analytics.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书侧重于可视化编程，我们不会深入讲解编程原理。相反，本节的目的是让你看到 Python 在熟悉的问题上的实际应用，并了解它如何在我们的日常工作中使用。我们将首先通过一个脚本，重复我们在*第
    5 章*，*在工作中应用机器学习*中看到的回归教程。然后，我们将看到 Python 如何与 KNIME 平滑集成，以充分发挥两种互补的分析编程方法的优势。
- en: A gentle introduction to the Python language
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python 语言的温和介绍
- en: 'To use Python, you can either install a development platform like Anaconda
    (we will do this later) or leverage a web-based interface such as Colab. Google
    Colab (short for Colaboratory) is a free cloud service that lets you write and
    run Python code without any setup being needed: you can access it at [colab.research.google.com](http://colab.research.google.com).'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Python，你可以安装像 Anaconda 这样的开发平台（我们稍后会做这个），或者利用基于网页的界面，如 Colab。Google Colab（Colaboratory
    的简称）是一个免费的云服务，允许你编写并运行 Python 代码，而无需任何设置：你可以通过 [colab.research.google.com](http://colab.research.google.com)
    访问它。
- en: 'As you can see in *Figure 9.13*, the user interface of Colab is an interactive
    web page where you can add text and code and then run it, line by line:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图 9.13*中看到的，Colab 的用户界面是一个交互式网页，你可以在其中添加文本和代码，然后逐行运行：
- en: '![Graphical user interface, text, application, email'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_09_13.png)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_09_13.png)
- en: 'Figure 9.13: The welcome screen of Google Colab: get some Python going without
    installing any software'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.13：Google Colab 欢迎界面：无需安装任何软件即可开始使用 Python
- en: To simplify the comparison with KNIME, let's use Colab on the same Rome housing
    business case we encountered in *Chapter 5*, *Applying Machine Learning at Work*.
    As a reminder, the objective is to predict rental prices by applying the linear
    regression learning algorithm to the database of historical rental agreements.
    You can follow step by step the full Colab script by connecting to [tiny.cc/romecolab](https://colab.research.google.com/github/laibniz/AnalyticsMadeEasy/blob/main/Rome_housing.ipynb).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化与 KNIME 的比较，让我们使用 Colab 来处理我们在*第 5 章*《在工作中应用机器学习》中遇到的同一个罗马住房商业案例。作为提醒，目标是通过将线性回归学习算法应用于历史租赁协议数据库来预测租金价格。你可以通过连接到
    [tiny.cc/romecolab](https://colab.research.google.com/github/laibniz/AnalyticsMadeEasy/blob/main/Rome_housing.ipynb)
    来一步步跟随完整的 Colab 脚本。
- en: 'Let''s go through the code and, for each portion, understand what is going
    on:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步分析代码，并理解每一部分的作用：
- en: '[PRE0]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The first step is to import some useful libraries into the Python environment.
    This will make a few extra functionalities (like loading Excel files and calculating
    a linear regression) available for us to leverage in our code. In particular,
    in the preceding code, we use a few `import` statements to include some of the
    most popular Python libraries used for data analytics, namely: **Pandas** for
    data manipulation, **NumPy** for numerical routines and array calculations, **Statsmodels**
    for hardcore statistics, and **Scikit-learn** (`sklearn` in the code) for machine
    learning:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将一些有用的库导入到 Python 环境中。这将使得我们能够利用一些额外的功能（例如加载 Excel 文件和计算线性回归）。特别是在前面的代码中，我们使用了几条`import`语句来引入一些最流行的
    Python 库，这些库广泛用于数据分析，具体包括：**Pandas** 用于数据处理，**NumPy** 用于数值运算和数组计算，**Statsmodels**
    用于硬核统计分析，**Scikit-learn**（代码中为`sklearn`）用于机器学习：
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As a next step, we read the data stored in an Excel file by using the `pd.read_excel()`
    function and assign its content to the `full_data` variable. We can then check
    the imported data by visualizing its top five rows, using the function `head()`,
    producing the output shown in *Figure 9.14*:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤，我们通过使用`pd.read_excel()`函数读取存储在 Excel 文件中的数据，并将其内容分配给`full_data`变量。然后，我们可以通过可视化数据的前五行来检查导入的数据，使用`head()`函数，输出如*图
    9.14*所示：
- en: '![Table'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![Table'
- en: Description automatically generated](img/B17125_09_14.png)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Description automatically generated](img/B17125_09_14.png)
- en: 'Figure 9.14: The output of the head() function as displayed in Colab:a useful
    peek into the top five rows in our dataset'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.14：head() 函数在 Colab 中显示的输出：我们数据集的前五行，是一个非常有用的预览
- en: 'The data we obtain is exactly what we encountered at the beginning of the first
    tutorial in *Chapter 5*, *Applying Machine Learning at Work* (see the first rows
    in *Figure 5.2*). We can move on and proceed with the first step of every supervised
    machine learning procedure, that is partitioning:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的数据正是我们在*第 5 章*《在工作中应用机器学习》教程开始时遇到的数据（见*图 5.2*中的前几行）。我们可以继续进行每个监督式机器学习过程的第一步，即数据划分：
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'With the help of the `train_test_split()` function, we apply a random sampling
    to our full data and obtain the training and the test set (which we set to be
    30% of the total), which are stored in the `train_set` and `test_set` variables.
    This line of Python code implements what the **Partitioning** node did for us
    in KNIME. We now have all we need to learn the model using the training set:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在`train_test_split()`函数的帮助下，我们对完整数据集进行了随机抽样，并获得了训练集和测试集（我们将其设为总数据的 30%），这些数据分别存储在`train_set`和`test_set`变量中。这行
    Python 代码实现了 KNIME 中 **Partitioning** 节点为我们做的操作。现在，我们已经拥有了使用训练集来训练模型所需的一切：
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Leveraging the function `smf.ols()`, this code portion trains an Ordinary Least
    Square regression model (OLS, which we encountered in *Chapter 5*, *Applying Machine
    Learning at Work*) using the `train_set` variable as an input. The output model
    is stored in an object called `model`. As we train the model, we can edit the
    formula string you see in the code (`Rent ~ Rooms + Surface + ...`) to select
    which column is the target (in our case `Rent`, which appears before the `~` sign)
    and which other columns should be used as predictors (the ones that go after the
    `~` symbol, separated by a `+` sign) in the linear regression. Categorical columns
    need to be encapsulated by the `C()` function (like in `C(Neighborhood)`): by
    doing so, Python converts them into multiple numerical columns (dummy variables)
    that are compatible with a linear regression model. The definition of the linear
    regression formula and the conversion of the nominal variable were done "under
    the hood" by the **Linear Regression Learner** node in KNIME, while in Python,
    they need to be specified in the code. Finally, the `summary()` function summarizes
    the regression results, including coefficients and p-values for each feature.
    If you compare the output obtained in Python (*Figure 9.15*) with the one obtained
    as an output of the **Linear Regression Learner** node in KNIME (*Figure 5.9*),
    you will find different numbers (of course, the random sampling will always produce
    slightly different results), but they are consistent. For instance, we notice
    that Piazza Navona is a pricey neighborhood (since its coefficient, displayed
    in the `coef` column, is higher than all others) and that the presence of elevators
    can be ignored (high p-value, as you can see in the `P>|t|` column):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 `smf.ols()` 函数，这段代码训练了一个普通最小二乘回归模型（OLS，正如我们在 *第5章*，*在工作中应用机器学习* 中遇到的那样），使用
    `train_set` 变量作为输入。输出模型存储在一个名为 `model` 的对象中。在训练模型时，我们可以编辑代码中看到的公式字符串（`Rent ~ Rooms
    + Surface + ...`），以选择哪个列作为目标变量（在我们的案例中是 `Rent`，出现在 `~` 符号之前）以及其他哪些列应作为预测变量（它们出现在
    `~` 符号后，并由 `+` 符号分隔）。类别列需要被 `C()` 函数封装（如 `C(Neighborhood)`）：通过这样做，Python 会将它们转换为多个数值列（虚拟变量），这些列与线性回归模型兼容。线性回归公式的定义和名义变量的转换是由
    KNIME 中的 **线性回归学习器** 节点在“幕后”完成的，而在 Python 中，它们需要在代码中明确指定。最后，`summary()` 函数总结了回归结果，包括每个特征的系数和
    p 值。如果将 Python 中获得的输出（*图9.15*）与 KNIME 中 **线性回归学习器** 节点的输出（*图5.9*）进行比较，你会发现数字有所不同（当然，随机抽样总会产生略微不同的结果），但它们是一致的。例如，我们注意到，Piazza
    Navona 是一个高档社区（因为它的系数，在 `coef` 列中显示，高于所有其他地区），而电梯的存在可以忽略不计（高 p 值，如你在 `P>|t|` 列中看到的）：
- en: '![Table'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![表格'
- en: Description automatically generated](img/B17125_09_15.png)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[描述自动生成](img/B17125_09_15.png)'
- en: 'Figure 9.15: The summary output of the OLS regression in Colab: you will get
    different numbers as the randomized portioning makes each specific model unique'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.15：Colab 中 OLS 回归的总结输出：由于随机分割，每个特定的模型都是唯一的，因此你会得到不同的数字
- en: 'We can now move the final bit of our machine learning procedures: predicting
    on the test set and scoring the results:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进行机器学习过程的最后一步：在测试集上进行预测并对结果进行评分：
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Similar to what we would do with the **Regression Predictor** node in KNIME,
    we need to apply the regression model to `test_set` and obtain some `predictions`:
    as you can see in the first line of the code, we use the function `predict()`
    to do exactly that. Afterward, we need to calculate two metrics for scoring our
    regression by comparing the real rent values in the test set (`test_set.Rent`)
    with our predictions, similar to what we did with the **Numeric Scorer** node
    KNIME tutorial. Specifically, we calculate the two main summary metrics for assessing
    regression accuracy, which we introduced in *Chapter 4*, *What is Machine Learning?*:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在 KNIME 中使用 **回归预测器** 节点的操作类似，我们需要将回归模型应用于 `test_set` 并获取一些 `predictions`：正如代码的第一行所示，我们使用
    `predict()` 函数来完成这一操作。随后，我们需要通过将测试集中的真实租金值（`test_set.Rent`）与我们的预测结果进行比较，计算两个评分指标，以评估回归的效果，这与我们在
    **数值评分器** 节点的 KNIME 教程中所做的类似。具体来说，我们计算评估回归准确性的两个主要汇总指标，这些指标我们在 *第4章*，*什么是机器学习？*
    中介绍过：
- en: The **Coefficient of Determination**, R², using the function `r2_score()`, which
    takes as parameters the two columns to compare.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决定系数**，R²，使用 `r2_score()` 函数，该函数以两个列作为参数进行比较。'
- en: The **Root Mean Squared Error** (**RMSE**), which gives us an idea of the level
    of error to expect in the predictions. To calculate this metric, we need to combine
    the functions `mean_squared_error()` to get the average of the squared residuals
    and `np.sqrt()` to obtain its square root.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均方根误差**（**RMSE**）为我们提供了一个关于预测误差水平的概念。为了计算这一指标，我们需要结合使用`mean_squared_error()`函数来获取残差的平方平均值，以及`np.sqrt()`来获得其平方根。'
- en: 'When we run this last portion of code, the output we obtain confirms that we
    have built quite a robust model as R² nears 0.91 and the RMSE is around €118 (of
    course, you will obtain slightly different values):'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这段代码的最后部分时，我们得到的输出确认我们已经构建了一个相当稳健的模型，因为R²接近0.91，而RMSE约为€118（当然，你会得到略有不同的值）：
- en: '[PRE5]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'New tools, same story: by writing around a dozen lines of Python code, we replicated
    the bulk of what we did in KNIME. Have a look at *Figure 9.16*: the gray boxes
    contain the key Python functions that do the same job as the KNIME nodes we met
    earlier in our journey:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 新工具，同样的故事：通过编写大约十行Python代码，我们复现了在KNIME中所做的大部分工作。看看*图9.16*：灰色的框包含了关键的Python函数，它们完成了与我们之前在KNIME中遇到的节点相同的任务：
- en: '![](img/B17125_09_16.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_09_16.png)'
- en: 'Figure 9.16: A comparison view showing Python''s key functions together with
    the corresponding KNIME nodes required for linear regression: the fundamental
    steps are exactly the same'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.16：对比视图，展示了Python的关键函数与进行线性回归所需的相应KNIME节点：基本步骤完全相同
- en: 'This exercise has clarified the differences between visual programming (what
    you can do in KNIME) and traditional programming by coding (which you can do using
    Python or any other language). There are pros and cons to each approach, and it
    is natural to have personal preferences toward any of the two routes. The good
    news is…you don''t have to make a definitive choice among the alternatives. In
    fact, visual programming and coding can also be mixed together, making a powerful
    potion for your data analytics magic to shine. In the following few pages, you
    will learn how to embed pieces of Python code into a KNIME workflow. This is a
    valuable trick to know, as it allows you to "make the best" out of the joint power
    of KNIME accessibility and "Python''s" breadth of functionalities. Even if you
    are not interested at this stage in the integration of KNIME and Python, I would
    suggest you go through the next few pages anyway. They will give you the opportunity
    to acquaint yourself with two powerful features you should know: KNIME extensions
    and KNIME Hub.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习澄清了可视化编程（你在KNIME中可以做的事情）与传统编程（你可以使用Python或任何其他语言来编写代码）之间的区别。每种方法都有其优缺点，个人偏好选择其中任何一种都是很自然的事情。好消息是……你不必在这两种选择之间做出最终决定。实际上，可视化编程和编码可以结合使用，这样就能为你的数据分析魔法创造出强大的效果。在接下来的几页中，你将学习如何将Python代码片段嵌入到KNIME工作流中。这是一个非常有价值的技巧，因为它能让你最大程度地利用KNIME的易用性与Python的广泛功能的结合。即使你此时不打算将KNIME与Python集成，我也建议你还是浏览接下来的几页。它们将让你有机会了解两个你应该知道的重要功能：KNIME扩展和KNIME
    Hub。
- en: Integrating Python with KNIME
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python与KNIME的集成
- en: 'First, you need to make sure you have a local installation of Python up and
    running on your computer. The easiest way to procure one is to install **Anaconda
    Individual Edition**, one of the most popular Python distribution platforms for
    data analytics. Download and install the latest version of the software, available
    for free at [anaconda.com/download](http://anaconda.com/download). Anaconda comes
    packed with several applications for coding both in Python and in R. An example
    is **Jupyter Notebook,** which lets you create Python scripts using a web browser—similarly
    to what we did in Colab but without any restrictions. From the welcome page of
    **Anaconda Navigator** (*Figure 9.17*), you can launch Jupyter Notebook or install
    additional applications, like RStudio for developing in R:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要确保你的计算机上已经安装并运行了本地版本的Python。获取它最简单的方法是安装**Anaconda个人版**，这是一个非常流行的Python数据分析分发平台。下载并安装最新版本的软件，免费提供，下载地址为[anaconda.com/download](http://anaconda.com/download)。Anaconda内置了多个用于Python和R编程的应用程序。例如，**Jupyter
    Notebook**，它让你可以通过Web浏览器创建Python脚本——就像我们在Colab中做的一样，但没有任何限制。在**Anaconda Navigator**的欢迎页面中（*图9.17*），你可以启动Jupyter
    Notebook或安装其他应用程序，如RStudio，用于R开发：
- en: '![](img/B17125_09_17.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_09_17.png)'
- en: 'Figure 9.17: The welcome screen of Anaconda Navigator: from here, you can launch
    Jupyter notebooks for coding in Python or install additional free packages'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.17：Anaconda Navigator的欢迎屏幕：从这里，你可以启动Jupyter笔记本进行Python编程，或者安装额外的免费包。
- en: 'As anticipated in *Chapter 2*, *Getting Started with KINME*, you can expand
    KNIME functionalities by installing additional extensions. To embed Python in
    our workflows, we need to install the **KNIME Python Integration** extension.
    To do so, open KNIME, go to **File** | **Install KNIME Extensions...** in the
    top bar and search for the right extension by typing `python` in the text box
    at the top (*Figure 9.18*). Check the box for the **KNIME Python integration**
    option, click on **Next**, and follow the installation process:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如*第2章*《*KNIME入门*》所述，你可以通过安装额外的扩展来扩展KNIME的功能。为了在我们的工作流中嵌入Python，我们需要安装**KNIME
    Python集成**扩展。操作步骤是：打开KNIME，点击顶部栏的**文件** | **安装KNIME扩展...**，然后在顶部的文本框中输入`python`进行搜索
    (*图9.18*)。勾选**KNIME Python集成**选项，点击**下一步**，然后按照安装过程进行操作：
- en: '![Graphical user interface, text, application, email'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_09_18.png)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_09_18.png)
- en: 'Figure 9.18: The dialog for installing extensions in KNIME. Look at the list
    of available packages: you can easily extend your analytical toolkit with thousands
    of new KNIME nodes'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.18：在KNIME中安装扩展的对话框。看看可用的包列表：你可以轻松地通过成千上万个新的KNIME节点扩展你的分析工具包。
- en: 'Once finished, you will be prompted with a message asking to restart KNIME
    to apply the software update. After the restart, go to the node repository and
    open the **Scripting > Python** folder. As you can see in *Figure 9.19*, you have
    gained several new nodes to be used in your workflows by installing the extension:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，系统会提示你重启KNIME以应用软件更新。重启后，去节点库并打开**脚本 > Python**文件夹。正如你在*图9.19*中看到的，通过安装该扩展，你将获得几个可以在工作流中使用的新节点：
- en: '![Graphical user interface, application'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，应用程序'
- en: Description automatically generated](img/B17125_09_19.png)
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_09_19.png)
- en: 'Figure 9.19: The Node Repository after installing the KNIME Python Integration
    extension:several new nodes have materialized'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.19：安装KNIME Python集成扩展后的节点库：几个新节点已经显示出来
- en: 'Before getting there, let''s perform the last step needed to set KNIME up so
    it can connect with the Python environment that came with Anaconda. To do so,
    go to **File | Preferences** in KNIME. Then, in the menu appearing on the left,
    go to **KNIME > Python** or use the text box on the left to look up the Python
    preferences window, which you can see in *Figure 9.20*. You should find the path
    to your Anaconda installation directory prepopulated (if that''s not the case,
    you will have to set it up by clicking on the **Browse...** button). Once done,
    click on the second **New environment...** button in the **Python 3 (Default)**
    section, as you can see in the following figure: this will create a new Python
    environment with all the packages needed for integration with KNIME:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，让我们完成设置KNIME与Anaconda自带的Python环境连接所需的最后一步。操作是：在KNIME中点击**文件 | 首选项**，然后在左侧出现的菜单中，选择**KNIME
    > Python**，或者使用左侧的文本框搜索Python首选项窗口，正如你在*图9.20*中看到的那样。你应该能看到预先填充的Anaconda安装目录路径（如果没有，你需要通过点击**浏览...**按钮来设置）。设置完成后，点击**Python
    3 (默认)**部分中的第二个**新建环境...**按钮，正如下图所示：这将创建一个新的Python环境，包含所有与KNIME集成所需的包：
- en: '![Graphical user interface, text, application, email'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_09_20.png)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_09_20.png)
- en: 'Figure 9.20: The Python window within the KNIME preferences: you need to tell
    KNIME where the local Python environment lies'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.20：KNIME首选项中的Python窗口：你需要告诉KNIME本地Python环境的位置
- en: 'In the next window (*Figure 9.21*), click on **Create new environment** and
    wait patiently for the environment to be generated. After this, you are done and
    all set up for enriching your KNIME workflows with all the Python you need:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个窗口中 (*图9.21*)，点击**创建新环境**，并耐心等待环境生成。完成后，你就完成了所有设置，准备好将你所需的Python功能集成到KNIME工作流中了：
- en: '![Graphical user interface, text, application, email'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序，电子邮件'
- en: Description automatically generated](img/B17125_09_21.png)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_09_21.png)
- en: 'Figure 9.21: New environment dialog: the final step for getting up and running
    with Python in KNIME'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.21：新环境对话框：在KNIME中启动Python的最后一步
- en: 'If, instead of Python, you want to use R in your KNIME workflows, you will
    have to install the **KNIME Interactive R Statistics Integration** and set up
    the R environment from the preferences menu, similar to what we did for Python.
    KNIME also allows you to run some Java code for every row of a table: check the
    **Java Snippet** node to find out more.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望在 KNIME 工作流中使用 R 而不是 Python，你需要安装**KNIME 互动式 R 统计集成**，并通过首选项菜单设置 R 环境，类似于我们为
    Python 所做的设置。KNIME 还允许你对表格的每一行运行一些 Java 代码：查看**Java 片段**节点了解更多信息。
- en: 'Among the new nodes you acquired by installing the Python extension (*Figure
    9.19*), **Python Script** is certainly the most versatile one: the node lets you
    embed a sequence of Python code that gets applied to the data stored in the input
    table (generically called `input_table_1`) to generate one or more output tables
    (called `output_table_1`). You can refer to these tables in your script and freely
    utilize them as you would do with any data frame in Python. For instance, if you
    wanted to apply a simple multiplication across two columns (*Quantity* and *Price*)
    and output an additional column (*Sales*) with the result, the Python script to
    be used with this node will be:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在你通过安装 Python 扩展获得的新节点中（*图 9.19*），**Python 脚本**无疑是最通用的：该节点允许你嵌入一系列 Python 代码，应用于存储在输入表格中的数据（通常称为
    `input_table_1`），以生成一个或多个输出表格（称为 `output_table_1`）。你可以在脚本中引用这些表格，并像使用 Python 中的任何数据框一样自由使用它们。例如，如果你想对两列（*数量*
    和 *价格*）进行简单的乘法运算，并输出一个附加列（*销售额*）作为结果，使用此节点的 Python 脚本将如下所示：
- en: '[PRE6]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The first line of code is just copying the input table to the output one, leaving
    it unchanged. The second line is applying the multiplication across the two columns—that's
    it. We could have imported any library (provided that they are installed in the
    Python environment within Anaconda) and leveraged it to perform any operation
    we need.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行代码只是将输入表复制到输出表中，保持不变。第二行代码应用了对两个列的乘法——就这么简单。我们本可以导入任何库（前提是它们已安装在 Anaconda
    的 Python 环境中），并利用它执行我们需要的任何操作。
- en: 'Let''s look at a simple workflow that illustrates the power of integrating
    Python in our analytical workflows. Instead of building this workflow from scratch,
    we can find it already available in **KNIME Hub**, the online repository of workflows,
    extensions, components, and nodes. As depicted in *Figure 9.22*, open the **KNIME
    Hub** panel (you''ll find it beside the **Node Description** tab in the top right)
    and type `Python Gaussian Fit` in the search box. Among the many alternatives,
    you should find a workflow with my name and picture on it: this is the workflow
    I have prepared for you. To import it into your KNIME installation, you can just
    drag the box (highlighted in the figure) and drop it onto your workflow editor.
    An alternative approach would be to import the KNIME workflow (**File** | **Import
    KNIME Workflow...**) that you will find in the GitHub repository:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个简单的工作流，展示在我们的分析工作流中集成 Python 的强大功能。我们无需从头开始构建这个工作流，而是可以在**KNIME Hub**中找到已经存在的版本，KNIME
    Hub 是一个在线工作流、扩展、组件和节点的资源库。如*图 9.22*所示，打开**KNIME Hub**面板（你会在右上角的**节点描述**标签旁找到它），然后在搜索框中输入
    `Python Gaussian Fit`。在众多选项中，你应该能找到一个包含我的名字和照片的工作流：这就是我为你准备的工作流。要将其导入到你的 KNIME
    安装中，你只需将框（如图所示）拖动并放到你的工作流编辑器中。另一种方法是导入**KNIME 工作流**（**文件** | **导入 KNIME 工作流...**），你可以在
    GitHub 仓库中找到它：
- en: '![Graphical user interface'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面'
- en: Description automatically generated](img/B17125_09_22.png)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/B17125_09_22.png)
- en: 'Figure 9.22: The KNIME Hub panel: search for the workflows, nodes, or components
    you need and drop them onto your workspace'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.22：KNIME Hub 面板：搜索你需要的工作流、节点或组件，并将它们拖放到你的工作区
- en: 'If you open the configuration dialog of the **Python View** node, you will
    find the code window shown in *Figure 9.23*. The large text box in the middle
    is where you can write your Python code. On the left, you have the list of columns
    available in the input table: by double-clicking on them, the corresponding Python
    data frames are added to the code. You can also test your code by clicking on
    the **Execute Script** or **Execute selected lines** buttons and checking whether
    it works fine. If you receive any warnings or errors during the execution of the
    script, they will be conveniently displayed in the console box at the bottom of
    the window:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打开**Python View**节点的配置对话框，你将看到如*图 9.23*所示的代码窗口。中间的文本框是你可以编写 Python 代码的地方。在左侧，你会看到输入表中可用的列列表：通过双击它们，相关的
    Python 数据框将被添加到代码中。你还可以通过点击**执行脚本**或**执行选定行**按钮来测试你的代码，检查其是否正常运行。如果在执行脚本时遇到任何警告或错误，它们会方便地显示在窗口底部的控制台框中：
- en: '![Graphical user interface, text, application'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，文本，应用程序'
- en: Description automatically generated](img/B17125_09_23.png)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[自动生成的描述](img/B17125_09_23.png)'
- en: 'Figure 9.23: Configuration window of the Python View node: use Python graphic
    libraries to generate any chart you like'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.23：Python View 节点的配置窗口：使用 Python 图形库生成任何你喜欢的图表
- en: 'In this specific case, we leverage the **Python View** node to fit a Gaussian
    function (the famous bell curve) to the distribution of Rome rental prices and
    return the histogram with the fitting curve. Going through the details of the
    code is not needed at this stage. However, you will notice that the *Rent* column
    has been referred to in the code with the name `input_table[''Rent'']` while the
    generated chart has been saved to the variable called `output_image`: you find
    the final result in *Figure 9.24*:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定案例中，我们利用**Python View**节点将高斯函数（著名的钟形曲线）拟合到罗马租金价格的分布，并返回带有拟合曲线的直方图。在此阶段无需详细了解代码，但你会注意到，代码中通过`input_table['Rent']`引用了*Rent*列，而生成的图表被保存在名为`output_image`的变量中：你可以在*图
    9.24*中看到最终结果：
- en: '![](img/B17125_09_24.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_09_24.png)'
- en: 'Figure 9.24: The output of the Python View node: rent prices in Rome are centered
    around €1,000'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.24：Python View 节点的输出：罗马的租金价格约为 €1,000
- en: 'This gives you an illustration of how Python nodes work: the data at the input
    port is translated into input variables, and, at the end of the script, whatever
    is assigned to the output variables gets returned at the output port of the node.
    In the same workflow you downloaded from KNIME Hub, you will also see an example
    of a **Python Script** node: essentially, both nodes run Python code on the input
    data, but the **Python View** node is "specialized" in outputting images.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这为你展示了 Python 节点是如何工作的：输入端口的数据被转换为输入变量，在脚本的末尾，分配给输出变量的内容会被返回到节点的输出端口。在你从 KNIME
    Hub 下载的相同工作流中，你还会看到一个**Python Script**节点的示例：本质上，两个节点都在输入数据上运行 Python 代码，但**Python
    View**节点“专门”用于输出图像。
- en: Interlacing code within a workflow has massive potential. If you want to apply
    some complex logic or reuse specialized code that has been developed outside of
    KNIME for solving your specific business need, you can now seamlessly integrate
    it all and significantly expand the power of your toolbox.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作流中交织代码具有巨大的潜力。如果你想应用一些复杂的逻辑或重用在 KNIME 之外开发的专用代码来解决你的特定业务需求，你现在可以将这些代码无缝集成进来，极大地扩展你的工具箱功能。
- en: 'After seeing Python in action, let''s go back to the world of codeless analytics
    and meet one of the promising directions of advanced analytics: automated machine
    learning.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到 Python 实际操作后，让我们回到无代码分析的世界，了解高级分析的一个有前景的方向：自动化机器学习。
- en: Automated machine learning
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化机器学习
- en: '"Brute-force patterns finding": this is how we can briefly (and colorfully)
    summarize what **Automated Machine Learning** or, for short, **AutoML**, is all
    about. As you saw in *Chapters 4* and *5*, building a machine learning model is
    far from being a linear, single-attempt endeavor. The usual procedure for obtaining
    high-performing supervised models is to go through a series of "back and forth"
    attempts: each time, we apply some "tuning" to the model or its features and check
    whether the predictive performance increases or not. We have seen already some
    of these mechanisms in action:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: “暴力模式发现”：这可以简洁（且生动）地概括**自动化机器学习**，简称**AutoML**，的核心内容。正如你在*第4章*和*第5章*中看到的，构建一个机器学习模型远不是一个线性、单次尝试的过程。获得高性能监督学习模型的常规过程是经历一系列的“反复”尝试：每次我们都会对模型或其特征进行一些“调优”，并检查预测性能是否有所提升。我们已经看到过一些这些机制的实际应用：
- en: '**Hyperparameters optimization**: this is when you apply changes to the way
    the learning algorithm operates, like when we activated pruning in decision trees
    or changed the degree of a polynomial regression. In more complex models (like
    in the case of deep neural networks), changing parameters (for instance, the number
    of neurons in the network) can make a significant difference to performance.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超参数优化**：这是对学习算法的操作方式进行调整，比如我们在决策树中启用了剪枝，或改变了多项式回归的次数。在更复杂的模型（如深度神经网络）中，改变参数（例如网络中的神经元数量）可能会显著影响性能。'
- en: '**Feature selection**: by selecting a subset of features (and removing the
    redundant ones), you make your model learning focus on what matters most, increasing
    its ability to predict. We did this when we decided to remove some high p-value
    features from regression models. Additionally, making a model run on fewer features
    means saving time and computing resources.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征选择**：通过选择特征的子集（并去除冗余特征），使模型学习集中在最重要的部分，从而提升其预测能力。我们在决定从回归模型中移除一些高p值特征时就做了这一操作。此外，减少模型运行所需的特征意味着节省时间和计算资源。'
- en: '**Feature engineering**: you can generate new features by combining or transforming
    the original ones to make them more informative for the model. For instance, this
    is what we did when we created dummy variables in regression.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程**：通过组合或转换原始特征来生成新的特征，使其对模型更具信息量。例如，这就是我们在回归中创建虚拟变量时所做的。'
- en: '**Stacking**: we said that sometimes we could combine different algorithms
    together in a single learning procedure. Think of predicting rental prices using
    five different intermediate regression models and then adopting the average of
    the five intermediate predictions as the overall prediction: by collating alternative
    models together, you might obtain a more robust one.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成学习**：我们曾提到， 有时可以将不同的算法组合在一个学习过程中。想象一下，预测租金时，使用五个不同的回归模型，然后将这五个中间预测值的平均值作为整体预测：通过将替代模型组合在一起，你可能获得一个更强健的模型。'
- en: 'Instead of manually checking the effect of each tuning step one by one, we
    can build a procedure that leverages all the available computing power to find
    the way to the best possible model. This is what the AutoML approach promises
    to do: automating the "trial and error" process of identifying parameters, features,
    and model combinations that maximize the overall performance (and—hopefully—the
    business impact) of our machine learning procedure.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 与其手动逐一检查每个调整步骤的效果，不如构建一个程序，利用所有可用的计算能力来找到通向最佳模型的路径。这正是AutoML方法所承诺的目标：自动化识别最大化整体性能（并且——希望——能够带来业务影响）的参数、特征和模型组合的“试错”过程。
- en: 'AutoML is currently a trending topic in business-applied AI, and there is a
    growing number of products and open-source libraries available out there for applying
    AutoML to real-world tasks, including H2O.ai, DataRobot, auto-sklearn, Google
    Cloud AutoML, IBM AutoAI, Amazon AutoGluon, and Azure AutomatedML. As we explore
    ways to expand our analytics toolbox, let''s see one of these products in action:
    this will give you an idea of what is already available and what''s to come from
    our companies in the next few years.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML目前是商业应用AI中的热门话题，市面上已有越来越多的产品和开源库，支持将AutoML应用于实际任务，包括H2O.ai、DataRobot、auto-sklearn、Google
    Cloud AutoML、IBM AutoAI、Amazon AutoGluon和Azure AutomatedML。随着我们不断扩展分析工具箱，让我们看看其中一款产品的实际应用：这将给你一个关于目前已有的产品及未来几年内我们公司可能推出的产品的了解。
- en: We will explore **H2O Driverless AI**, a cloud-based service that lets you use
    a web interface to upload data, run AutoML to make predictions, and interpret
    results. If you want to test it yourself, go to [h2o.ai/products/h2o-driverless-ai](http://h2o.ai/products/h2o-driverless-ai),
    register for a free account, and create an instance of Driverless AI.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探索 **H2O Driverless AI**，一个基于云的服务，允许你使用网页界面上传数据，运行 AutoML 进行预测，并解释结果。如果你想亲自测试，可以访问
    [h2o.ai/products/h2o-driverless-ai](http://h2o.ai/products/h2o-driverless-ai)，注册一个免费帐户，并创建一个
    Driverless AI 实例。
- en: 'AutoML in action: an example with H2O.ai'
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoML 实践：一个 H2O.ai 的示例
- en: 'In this example, we will reuse the Rome housing business case once again: this
    time, we will upload the Excel dataset and create a new experiment. *Figure 9.25*
    shows what the interface looks like: you can select the **Target Column** (*Rent*,
    in our case), pick a metric for the **Scorer** (in the figure, you can see we
    picked RMSE), and then turn the three knobs at the bottom to set the expected
    level of prediction **Accuracy**, the **Time** required for training the model,
    and the level of human **Interpretability**. This bit is fascinating: as you operate
    the knobs, the system updates its "trial and error" strategy (you can see a dynamic
    summary on the left) to be performed during the AutoML search routine. If you
    go for high accuracy and low interpretability, you will end up with high-performing
    black-box models, while if you set interpretability to a high level, you will
    obtain simpler models with fewer features so that you can explain to your business
    partners how it works:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将再次使用罗马住房的业务案例：这次，我们将上传 Excel 数据集并创建一个新的实验。*图 9.25* 显示了界面的样子：你可以选择
    **目标列**（在我们的案例中是 *租金*），为 **评分器** 选择一个指标（在图中，你可以看到我们选择了 RMSE），然后调节底部的三个旋钮，设置期望的预测
    **准确性**、训练模型所需的 **时间** 和 **可解释性** 水平。这部分非常有趣：当你操作旋钮时，系统会更新其“试错”策略（你可以在左侧看到一个动态摘要），并在
    AutoML 搜索过程中执行。如果你选择高准确性和低可解释性，你最终将得到高性能的黑箱模型，而如果将可解释性设置为较高水平，你将得到特征较少、便于解释的简单模型，以便向你的业务伙伴解释它是如何工作的：
- en: '![A screenshot of a computer'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![计算机截图'
- en: Description automatically generated with medium confidence](img/B17125_09_25.png)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成，信心值中等](img/B17125_09_25.png)
- en: 'Figure 9.25: The experiment setup page in H2O Driverless AI: play with the
    knobs to determine how you would like your generated model to be cooked'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.25：H2O Driverless AI 中的实验设置页面：通过调节旋钮，确定你希望生成的模型如何被“烹饪”
- en: 'After clicking on **Launch Experiment**, the remote computing power will do
    the hard work for you while you grab something to drink. The following view shows
    you the live evolution of the score metrics as more and more models are iteratively
    tried and, when completed, will display the best results (*Figure 9.26*):'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 点击 **启动实验** 后，远程计算资源将为你完成繁重的工作，而你可以去拿点喝的。下图显示了随着越来越多的模型被迭代尝试，得分指标的实时演变，完成后将显示最佳结果（*图
    9.26*）：
- en: '![A screenshot of a computer'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![计算机截图'
- en: Description automatically generated with medium confidence](img/B17125_09_26.png)
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成，信心值中等](img/B17125_09_26.png)
- en: 'Figure 9.26: The results of an AutoML routine:at the bottom left, you can see
    how the scoring metric changes as the search iteration progresses'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.26：AutoML 例程的结果：在左下角，你可以看到随着搜索迭代的进行，评分指标是如何变化的
- en: 'As part of the AuotML procedure, we also get some useful views that equip us
    for understanding how the model works. Have a look at the interpretation dashboard
    generated for our rental price predictions (*Figure 9.27*):'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 AutoML 过程的一部分，我们还获得了一些有用的视图，帮助我们理解模型的工作原理。请看看为我们的租金预测生成的解释仪表盘（*图 9.27*）：
- en: 'At the top right, we see a bar chart displaying **Features importance**: unsurprisingly,
    *Neighborhood* is the single most useful column when predicting the rent, followed
    by the *Surface* of the property.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在右上角，我们看到一个条形图显示 **特征重要性**：毫不奇怪，*邻里*是预测租金时最有用的单一列，紧随其后的是物业的 *面积*。
- en: 'At the bottom left, we have a tree-based **Surrogate model**: this is the "minimalist"
    version of the actual, full-on prediction model generated by the AutoML routine.
    By looking at the first three levels of this tree, we get a high-level, easy-to-explain
    view of the patterns that link the most important features to the rental price.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在左下角，我们有一个基于树的 **替代模型**：这是 AutoML 例程生成的实际预测模型的“简约”版本。通过查看这个树的前三个层次，我们可以得到一个高层次、易于解释的视图，展示了将最重要特征与租金联系起来的模式。
- en: 'At the bottom right, we find the **Partial dependence** plot: this shows us
    the marginal effect of a specific feature (*Surface*, in the case of *Figure 9.27*)
    on the predicted outcome (*Rent*). This chart provides us with an additional interpretation
    key, revealing "how" the rent increases as the surface grows:![A screenshot of
    a computer'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在右下角，我们可以看到**部分依赖**图：它展示了特定特征（在*图 9.27*中为*Surface*）对预测结果（*Rent*）的边际影响。此图为我们提供了一个额外的解释关键，揭示了“租金”如何随着“面积”的增加而上升：![A
    screenshot of a computer
- en: Description automatically generated with medium confidence](img/B17125_09_27.png)
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 描述自动生成，信心中等](img/B17125_09_27.png)
- en: 'Figure 9.27: The model interpretation dashboard: get some hints on how the
    prediction model works'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.27：模型解释仪表板：获取有关预测模型如何工作的提示
- en: 'With this example, we have admired the AutoML approach in all its potential.
    With only a few clicks, we obtained a robust predictive model (that can be exported
    and deployed for further use) and a simple framework for explaining its results.
    It''s important to make a further consideration: although it looks like the "holy
    grail" of machine learning, leveraging AutoML in a business context will still
    require its users to always "know what they are doing." This means that building
    machine learning expertise and, in general, data analytics fluency (like you did
    in this book) is and still will be crucial for making the best of this technology,
    however automated and easy to use it looks.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个例子，我们充分欣赏了 AutoML 方法的所有潜力。只需几次点击，我们便获得了一个强大的预测模型（可以导出并部署以供进一步使用），以及一个简单的框架来解释其结果。需要进一步考虑的是：尽管它看起来像是机器学习的“圣杯”，但在商业环境中使用
    AutoML 仍然需要用户始终“知道自己在做什么”。这意味着，构建机器学习专业知识，并且总体上提高数据分析能力（就像在本书中所做的那样），对于充分利用这项技术至关重要，尽管它看起来已变得自动化且易于使用。
- en: 'AutoML can be another valuable tool to keep in our data analytics kit. The
    good news is that you find this approach nicely implemented in KNIME as well,
    so you can connect it with everything else you have learned in the book. If you
    open the example workflow called H2O AutoML for Regression (you will find it in
    the Examples server in **KNIME Explorer** or by searching in **KNIME Hub**), you
    will be asked to install a new extension: **KNIME H2O Machine Learning Integration**.
    By installing this extension, you make many of the AutoML functionalities we have
    seen in H2O Driverless AI available to you in KNIME. Look at the sample workflow
    mentioned earlier (*Figure 9.28*): by employing a few H2O nodes—organized as per
    the usual supervised machine learning structure with partitioning, learner, predictor,
    and scorer—you get the full power of AutoML directly in KNIME:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML 可以成为我们数据分析工具包中的另一个宝贵工具。好消息是，你会发现这个方法在 KNIME 中也得到了很好的实现，因此你可以将其与本书中所学的其他内容连接起来。如果你打开名为
    H2O AutoML for Regression 的示例工作流（你可以在 **KNIME Explorer** 中的示例服务器或在 **KNIME Hub**
    中搜索到它），你将被要求安装一个新的扩展：**KNIME H2O 机器学习集成**。通过安装这个扩展，你可以在 KNIME 中使用我们在 H2O Driverless
    AI 中看到的许多 AutoML 功能。看一下前面提到的示例工作流（*图 9.28*）：通过使用一些 H2O 节点—按照常见的监督学习结构（包括划分、学习者、预测器和评分器）组织—你可以直接在
    KNIME 中获得 AutoML 的全部功能：
- en: '![](img/B17125_09_28.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17125_09_28.png)'
- en: 'Figure 9.28: The H2O AutoML for Regression KNIME workflow: use AutoML to find
    the best model for you'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.28：H2O AutoML 回归 KNIME 工作流：使用 AutoML 为你找到最佳模型
- en: Summary
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: I hope this final chapter got you excited about all the directions you can take
    to further expand your data analytics toolbox. We took our first steps in Tableau
    and realized how similar it is, in its fundamental features, to Power BI. We have
    also gone through a friendly introduction to Python, the ubiquitous programming
    language in data science. As we integrated Python in KNIME, we have seen how to
    take the best from both the visual and coding programming worlds. As we did so,
    we took the opportunity to learn how to expand KNIME further by using its vast
    extensions base and leveraging the public KNIME Hub environment. Lastly, we got
    a quick tour through the attractive land of AutoML, being exposed to its promising
    ability to simplify the process of building high-performing machine learning models
    considerably.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这最后一章能让你对进一步扩展数据分析工具箱的各种方向感到兴奋。我们在Tableau中迈出了第一步，意识到它在基本功能上与Power BI是如此相似。我们还通过对Python的友好介绍，了解了这一在数据科学中无处不在的编程语言。当我们将Python集成到KNIME中时，我们看到了如何从可视化和编码编程两个世界中获取最佳成果。与此同时，我们借此机会学习了如何通过利用KNIME庞大的扩展库以及公共的KNIME
    Hub环境来进一步扩展KNIME。最后，我们对AutoML的迷人领域进行了简短的探索，了解了它简化构建高性能机器学习模型过程的强大能力。
- en: 'In this chapter, we extended our toolbox by exploring new tools and approaches
    to run better data analytics in our everyday work. My advice is to make this a
    habit. One limitation I have seen in many data practitioners is to think that
    the few tools they feel comfortable with will *always* be the best for them, falling
    in the limiting bias of self-sufficiency. So instead, don''t feel satisfied with
    the toolbox we have just built—be ready to explore continuously: stay curious,
    as the expanding world of data analytics will have a lot to offer!'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们通过探索新的工具和方法，扩展了我们的工具箱，以便在日常工作中更好地进行数据分析。我的建议是把这变成一个习惯。我在许多数据从业者中看到的一个局限性是，他们认为自己熟悉的少数工具
    *永远* 是最适合他们的，从而陷入了自给自足的局限性偏见。所以，别对我们刚刚建立的工具箱感到满足——要做好持续探索的准备：保持好奇心，因为数据分析的不断扩展世界将提供许多精彩的东西！
