- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Eigenvalues and Eigenvectors
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值和特征向量
- en: 'So far, we have seen three sides of linear transformations: functions, matrices,
    and transforms that distort the grid of the underlying vector space. In the Euclidean
    plane, we saw some examples (Section [4.3](ch010.xhtml#linear-transformations-in-the-euclidean-plane))
    that shed some light on the geometric nature of them.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了线性变换的三个方面：函数、矩阵和扭曲底层向量空间网格的变换。在欧几里得平面中，我们看到了一些示例（第[4.3](ch010.xhtml#linear-transformations-in-the-euclidean-plane)节），这些示例为它们的几何性质提供了一些启示。
- en: Following this line of thought, let’s consider the linear transformation given
    by the matrix
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 延续这个思路，让我们考虑由矩阵给出的线性变换
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(12).png)6.1'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '![L(U,V ) = {f : U → V | f 是线性映射}](img/equation_(12).png)6.1'
- en: Since the columns of A are the images of the standard basis vectors e[1] = (1,0)
    and e[2] = (0,1), we can visualize the effect of A on Figure [6.1](#). (Check
    Section [4.1.1](ch010.xhtml#linear-transformations-and-matrices) if you don’t
    recall this fact.)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 由于A的列是标准基向量e[1] = (1,0)和e[2] = (0,1)的像，我们可以通过图[6.1](#)来直观地理解A的作用。（如果你不记得这个事实，请查看第[4.1.1](ch010.xhtml#linear-transformations-and-matrices)节。）
- en: This seems to shear, stretch, and rotate the entire grid. However, there are
    special directions along which A is simply a stretching. For instance, consider
    the vector u[1] = (1,1). By a simple calculation, you can verify that Au[1] =
    3u[1].
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎是剪切、拉伸并旋转了整个网格。然而，有些特殊方向下，A只是一个拉伸。例如，考虑向量u[1] = (1,1)。通过简单的计算，你可以验证Au[1]
    = 3u[1]。
- en: Because of the linearity, this means that if a vector x is in span(u[1]), its
    image under A is 3x.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由于线性性，这意味着如果一个向量x在span(u[1])中，那么它在A作用下的像是3x。
- en: '![PIC](img/file578.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file578.png)'
- en: 'Figure 7.1: Images of the standard basis vectors under the linear transformation
    given by A'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1：A给出的线性变换下标准基向量的像
- en: Another one is u[2] = (−1,1), where we have Au[2] = u[2]. Thus, any x ∈ span(u[2])
    is left in place.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个是u[2] = (−1,1)，我们有Au[2] = u[2]。因此，任何x ∈ span(u[2])都会保持不变。
- en: If we select u[1],u[2] as our base, the matrix of this transformation is
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择u[1]，u[2]作为基础，那么该变换的矩阵是
- en: '![ ⌊ ⌋ Au ,u = ⌈3 0⌉ , 1 2 0 1 ](img/file579.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ Au ,u = ⌈3 0⌉ , 1 2 0 1 ](img/file579.png)'
- en: that is, A[u[1],u[2]] is diagonal.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，A[u[1],u[2]]是对角化的。
- en: '![PIC](img/file580.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file580.png)'
- en: 'Figure 7.2: Images of u[1] = (1,1) and u[2] = (−1,1) under the linear transformation
    given by A'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2：A给出的线性变换下u[1] = (1,1)和u[2] = (−1,1)的像
- en: We love diagonal matrices in practice because multiplication with a diagonal
    matrix is much faster, as it requires O(n) operations, opposed to O(n²).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们喜欢对角矩阵，因为与对角矩阵的乘法要快得多，它只需要O(n)次操作，相对于O(n²)的操作复杂度。
- en: Is this a general phenomena? Are these even useful? The answer is yes to both
    questions. What we have just seen is formalized by the concept of eigenvalues
    and eigenvectors. The terminology originates from the german word “eigen” meaning
    “own,” resulting in one of the ugliest naming conventions in mathematics.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个普遍现象吗？这些有用吗？答案是对这两个问题都回答“是”。我们刚才看到的内容通过特征值和特征向量的概念得到了形式化。这个术语来源于德语单词“eigen”，意思是“自己的”，也因此导致了数学中最丑陋的命名约定之一。
- en: Definition 23\. (Eigenvalues and eigenvectors)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 23.（特征值和特征向量）
- en: 'Let f : V → V be an arbitrary linear transformation. We say that the λ scalar
    and the x ∈V ∖{0} nonzero vector is an eigenvalue-eigenvector pair of f if f(x)
    = λx holds.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '设f : V → V为任意线性变换。如果f(x) = λx成立，那么标量λ和x ∈V ∖{0}非零向量就是f的特征值-特征向量对。'
- en: 6.1 Eigenvalues of matrices
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 矩阵的特征值
- en: Although we have formally defined eigenvalues and eigenvectors for linear transformations,
    we often talk about them in context of matrices. (Because, as we have seen, matrices
    and linear transformations are two faces of the same coin.) Let’s start by translating
    the definition into the language of matrices.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经正式定义了线性变换的特征值和特征向量，但我们通常在矩阵的上下文中讨论它们。（因为，正如我们所见，矩阵和线性变换是同一事物的两种不同表现形式。）让我们从将定义转换为矩阵语言开始。
- en: 'If A ∈ℝ^(n×n) is a matrix, Definition [23](ch012.xhtml#x1-105003r23) translates
    to the following: the scalar λ and the vector x ∈ℝ ∖{0} is an eigenvalue-eigenvector
    pair of the matrix if'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果A ∈ℝ^(n×n)是一个矩阵，则定义[23](ch012.xhtml#x1-105003r23)可转化为以下内容：标量λ和向量x ∈ℝ ∖{0}是矩阵的特征值-特征向量对，如果
- en: A**x** = λ**x**
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: A**x** = λ**x**
- en: (6.2)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: (6.2)
- en: 'holds. This can be simplified: as the linear transformation x→λx corresponds
    to the matrix λI, ([6.2](ch012.xhtml#eigenvalues-of-matrices)) is equivalent to'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以简化：线性变换x→λx对应的矩阵是λI，([6.2](ch012.xhtml#eigenvalues-of-matrices))等价于
- en: (A − λI)**x** = **0**
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: (A − λI)**x** = **0**
- en: (6.3)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: (6.3)
- en: 'If you recall Chapter [4](ch010.xhtml#linear-transformations), Section [4.1.1](ch010.xhtml#linear-transformations-and-matrices),
    where we learned how matrices arise from linear transformations, you might ask
    the question: won’t the eigenvalues depend on the choice of the matrix?'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回忆起第[4章](ch010.xhtml#linear-transformations)，第[4.1.1节](ch010.xhtml#linear-transformations-and-matrices)，我们在那一节中学到了矩阵是如何从线性变换中产生的，你可能会问：特征值不会依赖于矩阵的选择吗？
- en: 'The following theorem states that this is not the case: the eigenvalues of
    a linear transformation and its matrices are the same.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下定理指出情况并非如此：线性变换及其矩阵的特征值是相同的。
- en: Theorem 36\. (Eigenvalues of similar matrices)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 定理36.（相似矩阵的特征值）
- en: Let A,B ∈ℝ^(n×n) be two similar matrices, that is, suppose that there exists
    an invertible T ∈ℝ^(n×n) such that B = T^(−1)AT. Then, if Ax = λx holds for some
    scalar λ and vector x ∈ℝ^n,
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 设A,B ∈ℝ^(n×n)是两个相似矩阵，即假设存在一个可逆矩阵T ∈ℝ^(n×n)，使得B = T^(−1)AT。那么，如果对于某个标量λ和向量x ∈ℝ^n，有Ax
    = λx，
- en: then
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 则：
- en: '![ ′ ′ Bx = λx ](img/file582.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![ ′ ′ Bx = λx ](img/file582.png)'
- en: holds for some x^′∈ℝ^n as well.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对某些 x^′∈ℝ^n 同样成立。
- en: Proof. Let’s massage the eigenvalue ([6.3](ch012.xhtml#eigenvalues-of-matrices))
    a bit! We have
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。让我们稍微调整一下特征值 ([6.3](ch012.xhtml#eigenvalues-of-matrices))！我们有：
- en: '![ −1 (A − λI)x = (A − λT T )x = T (T−1AT − λI)T −1x = 0\. ](img/file583.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![ −1 (A − λI)x = (A − λT T )x = T (T−1AT − λI)T −1x = 0\. ](img/file583.png)'
- en: 'Since T is invertible, T[(T^(−1)AT −λI)T^(−1)x] = 0 can only happen if (T^(−1)AT
    −λI)T^(−1)x = 0\. (Recall the relation of the kernel and invertibility in Theorem [20](ch010.xhtml#x1-70003r20).)
    This looks almost like ([6.3](ch012.xhtml#eigenvalues-of-matrices)), just a bit
    more complicated. Let me use some suggestive parentheses to highlight the similarities:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于T是可逆的，T[(T^(−1)AT −λI)T^(−1)x] = 0 只有在 (T^(−1)AT −λI)T^(−1)x = 0 时才成立。（回顾定理[20](ch010.xhtml#x1-70003r20)中关于核与可逆性的关系。）这看起来几乎和
    ([6.3](ch012.xhtml#eigenvalues-of-matrices)) 一样，只是稍微复杂了一点。让我用一些提示性的括号来突出相似之处：
- en: '![ −1 − 1 [T AT − λI ][T x] = 0\. ](img/file586.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![ −1 − 1 [T AT − λI ][T x] = 0\. ](img/file586.png)'
- en: So, with the selection x^′ = T^(−1)x, we have
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，使用选择 x^′ = T^(−1)x，我们有：
- en: '![ −1 ′ ′ T AT x = λx , ](img/file587.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![ −1 ′ ′ T AT x = λx , ](img/file587.png)'
- en: which is what we had to show.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们需要证明的。
- en: In other words, the eigenvalues of similar matrices are the same. Consequently,
    we can talk about the eigenvalues of matrices, not just linear transformations.
    The above theorem implies that the eigenvalues of a transformation and its corresponding
    matrix are the same. Moreover, the eigenvalues of the matrix don’t depend on the
    choice of basis.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，相似矩阵的特征值是相同的。因此，我们可以谈论矩阵的特征值，而不仅仅是线性变换的特征值。上述定理意味着变换及其对应矩阵的特征值是相同的。而且，矩阵的特征值不依赖于基的选择。
- en: 'To be more precise, suppose that A : U →U is a linear transformation and P,Q
    are bases of U. The matrix of A in some basis S is denoted by A[Q]. We know that
    there is a transformation matrix T ∈ℝ^(n×n) such that'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '更精确地说，假设A : U →U 是一个线性变换，P，Q是U的基。A在某个基S中的矩阵表示为A[Q]。我们知道，存在一个变换矩阵T ∈ℝ^(n×n)，使得：'
- en: '![ −1 AQ = T AP T. ](img/file588.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![ −1 AQ = T AP T. ](img/file588.png)'
- en: So, the eigenvalues are the same.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，特征值是相同的。
- en: 'All of the above begs the question: how do we actually find eigenvalues? Let’s
    talk about this next.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 上述所有内容都引出了一个问题：我们到底该如何实际找到特征值呢？接下来我们就来讨论这个问题。
- en: 6.2 Finding eigenvalue-eigenvector pairs
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 查找特征值-特征向量对
- en: Even though the definition of eigenvalue-eigenvector pairs is easy to understand
    given the geometric interpretation we just saw, it does not give us any tools
    to find them in practice. Using them to get simpler representations of matrices
    is one thing, but we are stuck at square one without a method to find them.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管从几何解释来看，特征值-特征向量对的定义很容易理解，但它并没有为我们提供实际寻找它们的工具。利用它们来获得矩阵的简化表示是其中的一项应用，但如果没有方法来寻找它们，我们还是停留在原点。
- en: 'First, let’s focus on the eigenvalues. Suppose that for some λ, there is a
    nonzero vector x such that Ax = λx. The transformation defined by x →λx is a linear
    one, and its matrix is diagonal:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们关注特征值。假设对于某个λ，存在一个非零向量x使得Ax = λx。由x →λx定义的变换是线性的，其矩阵是对角矩阵：
- en: '![ ⌊ λ 0 ... 0⌋ ⌊ x ⌋ | | | 1| || 0 λ ... 0|| || x2|| λx = || .. .. .. ..||
    || .. || , ⌈ . . . .⌉ ⌈ . ⌉ 0 0 ... λ xn ](img/file589.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ λ 0 ... 0⌋ ⌊ x ⌋ | | | 1| || 0 λ ... 0|| || x2|| λx = || .. .. .. ..||
    || .. || , ⌈ . . . .⌉ ⌈ . ⌉ 0 0 ... λ xn ](img/file589.png)'
- en: where the matrix with λ-s in the diagonal is λI, that is, λ times the identity
    matrix.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中对角线上是λ的矩阵就是λI，也就是λ倍的单位矩阵。
- en: Because linear transformations can be added and subtracted (as we saw in Section [4.1.2](ch010.xhtml#matrix-operations-revisited)),
    the defining equation Ax = λx is equivalent to
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 因为线性变换可以相加和相减（正如我们在第[4.1.2](ch010.xhtml#matrix-operations-revisited)节中看到的），所以定义方程Ax
    = λx等价于
- en: '![(A − λI)x = 0, ](img/file590.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![(A − λI)x = 0, ](img/file590.png)'
- en: 'where I denotes the identity transformation, as defined by equation (4.3).
    In other words, the transformation A−λI maps a nonzero vector to 0, meaning that
    it is not invertible, as Theorem [20](ch010.xhtml#x1-70003r20) implies. We can
    characterize this with determinants: we need to find all λ-s such that'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 其中I表示单位变换，如公式（4.3）所定义。换句话说，变换A−λI将一个非零向量映射到0，这意味着它是不可逆的，正如定理[20](ch010.xhtml#x1-70003r20)所暗示的那样。我们可以用行列式来表征这一点：我们需要找到所有λ，使得
- en: '![det(A − λI ) = 0\. ](img/file591.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![det(A − λI ) = 0\. ](img/file591.png)'
- en: We can summarize the above findings in the following theorem.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将上述结论总结为以下定理。
- en: Theorem 37\.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 37\.
- en: 'Let ![A : U → U ](img/file592.png) be an arbitrary linear transformation. Then
    ![λ ](img/file593.png) is its eigenvalue if and only if'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '设![A : U → U ](img/file592.png)是一个任意的线性变换。那么![λ ](img/file593.png)是其特征值，当且仅当'
- en: '![det(A − λI ) = 0\. ](img/file594.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![det(A − λI ) = 0\. ](img/file594.png)'
- en: Although we are one step closer, finding eigenvalues based on this still seems
    complicated. In the following, we are going to see what det(A−λI) really is and
    how we can find the solutions of det(A −λI) = 0 in practice.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们已经更进一步，但基于这个方法找到特征值仍然看起来很复杂。接下来，我们将看看det(A−λI)到底是什么，以及我们如何在实际中找到det(A −λI)
    = 0的解。
- en: Before going into the generalities, let’s revisit the example ([6.1](ch012.xhtml#eigenvalues-and-eigenvectors)).
    There, we have
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入讨论一般情况之前，让我们回顾一下例子（[6.1](ch012.xhtml#eigenvalues-and-eigenvectors)）。在这个例子中，我们有
- en: '![ | | | | det(A − λI) = ||2 − λ 1 || || 1 2− λ|| = (2 − λ)2 − 1 = λ2 − 4λ
    + 3\. ](img/file595.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![ | | | | det(A − λI) = ||2 − λ 1 || || 1 2− λ|| = (2 − λ)2 − 1 = λ2 − 4λ
    + 3\. ](img/file595.png)'
- en: To find the eigenvalues, we have to solve the quadratic equation
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到特征值，我们必须解这个二次方程
- en: '![λ2 − 4λ + 3 = 0, ](img/file596.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![λ2 − 4λ + 3 = 0, ](img/file596.png)'
- en: which we can do easily. Recall that the solutions of any quadratic equation
    ax² + bx + c = 0 are
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们可以轻松做到的。回想一下，任何二次方程ax² + bx + c = 0的解是
- en: '![ √ 2------- x1,2 = − b-±--b-−-4ac. 2a ](img/file597.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![ √ 2------- x1,2 = − b-±--b-−-4ac. 2a ](img/file597.png)'
- en: Applying this, we have λ[1] = 3 and λ[2] = 1 as solutions. There are no other
    ones, so 1 and 3 are the only two eigenvalues for A.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 应用这一点，我们得到λ[1] = 3 和 λ[2] = 1作为解。没有其他解，因此1和3是A的唯一两个特征值。
- en: Let’s see what happens in the general case!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在一般情况下会发生什么！
- en: 6.2.1 The characteristic polynomial
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 特征多项式
- en: As the example above suggests, if the underlying vector space U is n-dimensional,
    that is, A is an n ×n matrix, det(A −λI) is an n-th degree polynomial in λ.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如上面的例子所示，如果底层向量空间U是n维的，也就是说A是一个n ×n的矩阵，那么det(A −λI)是λ的n次多项式。
- en: To see this, let’s write det(A−λI) explicitly in terms of matrices. With this
    in mind, we have
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看清这一点，让我们显式地将det(A−λI)写成矩阵的形式。考虑到这一点，我们得到
- en: '![ | | |a − λ a ... a | ||11 12 1n || || a21 a22 − λ ... a2n || det(A − λI)
    = || .. .. .. .. ||. || . . . . || | an1 an2 ... ann − λ | ](img/file598.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![ | | |a − λ a ... a | ||11 12 1n || || a21 a22 − λ ... a2n || det(A − λI)
    = || .. .. .. .. ||. || . . . . || | an1 an2 ... ann − λ | ](img/file598.png)'
- en: If you consider the formula to calculate the determinant given by ([4.12](ch010.xhtml#x1-81006r20)),
    you can see that every term is a polynomial. Depending on how many fixed points
    σ has (that is, points where σ(i) = i), the degree of this polynomial varies between
    0 and n.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你考虑计算行列式的公式（[4.12](ch010.xhtml#x1-81006r20)），你会发现每一项都是一个多项式。根据σ的固定点数（即σ(i)
    = i的点有多少），这个多项式的次数介于0和n之间。
- en: (Alternatively, you can see that det(A−λI) is a polynomial of degree n by using
    the recursive formula ([4.13](ch010.xhtml#x1-81009r21)) and applying induction.)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: （或者，你可以通过使用递归公式（[4.13](ch010.xhtml#x1-81009r21)）并应用归纳法，看到det(A−λI)是一个n次的多项式。）
- en: Definition 24\. (Characteristic polynomial of matrices)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 24\. （矩阵的特征多项式）
- en: Let A ∈ℝ^(n×n) be an arbitrary matrix. The polynomial
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 设A ∈ℝ^(n×n)是任意矩阵。多项式
- en: '![p(λ) = det(A − λI) ](img/file599.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![p(λ) = det(A − λI) ](img/file599.png)'
- en: is called the characteristic polynomial of A.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 被称为A的特征多项式。
- en: The roots of the characteristic polynomial are the eigenvalues. If U is an n-dimensional
    complex vector space (that is, the set of scalars is ℂ), the fundamental theorem
    of algebra (Theorem [156](ch038.xhtml#x1-385002r156)) guarantees that det(A −λI)
    = 0 has exactly n roots.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 特征多项式的根就是特征值。如果 U 是一个 n 维复向量空间（即标量集是 ℂ），代数基本定理（定理[156](ch038.xhtml#x1-385002r156)）保证
    det(A −λI) = 0 有正好 n 个根。
- en: As a consequence, every matrix A ∈ℂ^(n×n) has at least one eigenvalue. Note
    that roots can have higher algebraic multiplicity. For instance, the characteristic
    polynomial for the matrix
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，任何矩阵 A ∈ℂ^(n×n) 至少有一个特征值。注意，根可以具有更高的代数重数。例如，矩阵的特征多项式
- en: '![ ⌊ ⌋ | 1 0 0| B = | 0 1 0| ⌈ ⌉ 0 0 2 ](img/file600.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ | 1 0 0| B = | 0 1 0| ⌈ ⌉ 0 0 2 ](img/file600.png)'
- en: is (1 −λ)²(2 −λ). So, its roots are 1 (with algebraic multiplicity 2) and 2.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为 (1 −λ)²(2 −λ)。所以，它的根是 1（代数重数为 2）和 2。
- en: If we restrict ourselves to real matrices and real vector spaces, the existence
    of eigenvalues and eigenvectors are not guaranteed. For instance, consider
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只局限于实矩阵和实向量空间，那么特征值和特征向量的存在并不能得到保证。例如，考虑
- en: '![ ⌊ ⌋ 0 − 1 C = ||1 0 ||. ⌈ ⌉ ](img/file601.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ 0 − 1 C = ||1 0 ||. ⌈ ⌉ ](img/file601.png)'
- en: 'Its characteristic polynomial is λ² + 1, which doesn’t have any real roots,
    only complex ones: λ[1] = i and λ[2] = −i. Mathematically speaking, if we want
    to stay within the confines of real vector spaces, C has no eigenvalues. However,
    we are here to do machine learning, not algebra. Thus, we are going to be a bit
    imprecise and treat real matrices as complex ones. We don’t often need complex
    numbers to describe mathematical models of a dataset, but they frequently appear
    during the analysis of matrices.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 它的特征多项式是 λ² + 1，它没有实数根，只有复数根：λ[1] = i 和 λ[2] = −i。从数学上讲，如果我们想在实向量空间的范围内停留，C
    没有特征值。然而，我们现在是在做机器学习，而不是代数。因此，我们将稍微不精确一些，将实数矩阵视为复数矩阵。我们通常不需要复数来描述数据集的数学模型，但它们在矩阵分析过程中经常出现。
- en: 6.2.2 Finding eigenvectors
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 寻找特征向量
- en: When an eigenvalue λ is identified, we can set out to find the corresponding
    eigenvectors; that is, vectors x where (A−λI)x = 0\. In more precise terms, we
    are looking for ker(A −λI).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个特征值 λ 被识别时，我们可以开始寻找对应的特征向量；即，寻找向量 x，使得 (A−λI)x = 0。更精确地说，我们在寻找 ker(A −λI)。
- en: As we have mentioned before in Section [4.1.4](ch010.xhtml#the-kernel-and-the-image),
    the kernel of any linear transformation is a subspace. As it might be more than
    one-dimensional, identifying it often involves an implicit description like x[1]
    + x[2] = 0.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第[4.1.4](ch010.xhtml#the-kernel-and-the-image)节中提到的，任何线性变换的核是一个子空间。由于它可能是多维的，因此确定它通常需要像
    x[1] + x[2] = 0 这样的隐式描述。
- en: Let’s check what happens with our recurring example
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下我们反复出现的例子
- en: '![ ⌊ ⌋ 2 1 A = ⌈ ⌉ . 1 2 ](img/file602.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ 2 1 A = ⌈ ⌉ . 1 2 ](img/file602.png)'
- en: Previously, we have seen that λ[1] = 3 and λ[2] = 1 are the eigenvalues. To
    identify the corresponding eigenvectors for, say, λ[1], we have to find all solutions
    for the linear equation (A −λ[1]I)x = 0\. Expanding this, we have
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们已经看到 λ[1] = 3 和 λ[2] = 1 是特征值。为了识别对应的特征向量，例如 λ[1]，我们必须找到线性方程 (A −λ[1]I)x
    = 0 的所有解。展开后，我们有
- en: '![− x1 + x2 = 0 x1 − x2 = 0\. ](img/file603.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![− x1 + x2 = 0 x1 − x2 = 0\. ](img/file603.png)'
- en: Both equations imply that all x = (x[1],x[2]) are solutions where x[1] = x[2].
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 两个方程意味着所有 x = (x[1],x[2]) 是解，其中 x[1] = x[2]。
- en: 6.3 Eigenvectors, eigenspaces, and their bases
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 特征向量、特征空间及其基
- en: Definition 25\. (Eigenspaces)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 25.（特征空间）
- en: 'Let f : V →V be an arbitrary linear transformation, and λ its eigenvalue. The
    subspace of eigenvectors defined by'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '设 f : V →V 是一个任意的线性变换，λ 是它的特征值。由此定义的特征向量子空间'
- en: '![Uλ = {x : Ax = λx} ](img/file604.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![Uλ = {x : Ax = λx} ](img/file604.png)'
- en: is called the eigenspace of λ.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 称为 λ 的特征空间。
- en: Eigenspaces play an important role in understanding the structure of linear
    transformations. First, we note that a linear transformation keeps its eigenspaces
    invariant. (That is, if x is in the U[λ] eigenspace, then f(x) ∈U[λ] as well.)
    This property makes it possible for us to restrict linear transformations to their
    eigenspaces.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 特征空间在理解线性变换的结构中起着重要作用。首先，我们注意到线性变换保持其特征空间不变。（也就是说，如果 x 属于 U[λ] 特征空间，那么 f(x)
    也属于 U[λ]。）这一性质使我们能够将线性变换限制在其特征空间内。
- en: To illustrate the concept of eigenspaces, let’s revisit the already familiar
    matrix
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明特征空间的概念，让我们回顾一下已经熟悉的矩阵
- en: '![ ⌊ ⌋ 2 1 A = ⌈ ⌉ 1 2 ](img/file605.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ 2 1 A = ⌈ ⌉ 1 2 ](img/file605.png)'
- en: one more time. Its eigenvalues are λ[1] = 3 and λ[2] = 1, and by solving the
    equation (A −λ[1]I)x = 0, we get that the eigenspace of λ[1] is
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 再次考虑。它的特征值为λ[1] = 3和λ[2] = 1，通过解方程(A −λ[1]I)x = 0，我们得到λ[1]的特征空间是
- en: '![U = {x ∈ ℝ2 : x = x }. λ1 1 2 ](img/file606.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![U = {x ∈ ℝ2 : x = x }. λ1 1 2 ](img/file606.png)'
- en: 'Similarly, you can check that U[λ[2]] = {x ∈ℝ² : x[1] = −x[2]}. (If you go
    back to Figure 6.2, you can visualize U[λ[1]] and U[λ[2]].)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '同样，你可以检查U[λ[2]] = {x ∈ ℝ² : x[1] = −x[2]}。（如果你回到图6.2，可以直观地看到U[λ[1]]和U[λ[2]]。）'
- en: Eigenspaces are not necessarily one-dimensional. For instance, consider one
    of the the previous examples
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 特征空间不一定是一维的。例如，考虑前面提到的一个例子
- en: '![ ⌊ ⌋ 1 0 0 || || B = ⌈0 1 0⌉ , 0 0 2 ](img/file607.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ 1 0 0 || || B = ⌈0 1 0⌉ , 0 0 2 ](img/file607.png)'
- en: with two eigenvalues λ[1] = 1 and λ[2] = 2\. Substituting λ[1] back into the
    equation and solving for (B −I)x = 0 for x, we obtain that
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 具有两个特征值λ[1] = 1和λ[2] = 2。将λ[1]代入方程并解方程(B −I)x = 0，得到
- en: '![U = {x ∈ ℝ3 : x = 0}, λ1 3 ](img/file608.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![U = {x ∈ ℝ3 : x = 0}, λ1 3 ](img/file608.png)'
- en: which is simply the plane determined by the first two axes.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是由前两个坐标轴确定的平面。
- en: The structure of eigenspaces determines whether or not we can diagonalize the
    matrix A with a change of basis (Section [4.2](ch010.xhtml#change-of-basis)) transformation
    Λ = T^(−1)AU. The following general theorem establishes this connection.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 特征空间的结构决定了我们是否可以通过基变换对矩阵A进行对角化（第[4.2](ch010.xhtml#change-of-basis)节）。以下的定理建立了这种联系。
- en: Theorem 38\. (Diagonalization and eigenspaces)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 定理38。（对角化与特征空间）
- en: 'Let f : V → V be a linear transformation, let A ∈ ℝ^(n×n) be its matrix in
    some basis, and let U[λ1,…,U]{λ[k]} be the eigenspaces of f. The following are
    equivalent.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '设f : V → V为线性变换，A ∈ ℝ^(n×n)是其在某个基下的矩阵，U[λ1,…,U]{λ[k]}是f的特征空间。以下是等价的。'
- en: (a) There is a matrix T ∈ℝ^(n×n) such that
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: （a）存在一个矩阵T ∈ ℝ^(n×n)，使得
- en: '![ −1 Λ = T AT, ](img/file609.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![ −1 Λ = T AT, ](img/file609.png)'
- en: where Λ is a diagonal matrix.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 其中Λ是一个对角矩阵。
- en: (b) There is a basis u[1],…,u[n] for V that can be selected from the eigenvectors
    of f.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: （b）存在一个基u[1],…,u[n]，它可以从f的特征向量中选取。
- en: (c) V can be written as the direct sum of the eigenspaces, that is,
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: （c）V可以表示为特征空间的直和，即，
- en: '![V = Uλ1 + ⋅⋅⋅+ Uλk. ](img/file610.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![V = Uλ1 + ⋅⋅⋅+ Uλk. ](img/file610.png)'
- en: (Note that k, the number of eigenspaces, is not necessarily n.)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: （注意，k，即特征空间的数量，不一定等于n。）
- en: Proof. (a) ⇒ (b). If ![A ](img/file612.png) is the matrix of ![f ](img/file613.png)
    in some basis, then a similarity transformation is equivalent to a change of basis.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。（a）⇒（b）。如果![A ](img/file612.png)是某个基下的![f ](img/file613.png)矩阵，那么相似变换等同于基的变化。
- en: That is, the new matrix Λ = T^(−1)AT is the matrix of f in a different basis,
    say u[1],…,u[n].
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，新的矩阵Λ = T^(−1)AT是f在不同基下的矩阵，例如u[1],…,u[n]。
- en: If Λ is diagonal, it can be written in the form
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Λ是对角矩阵，它可以写成以下形式
- en: '![ ⌊ ⌋ |λ1 0 ... 0 | || 0 λ2 ... 0 || Λ = | . . . .| . |⌈ .. .. .. ..|⌉ 0 0
    ... λ n ](img/file614.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ |λ1 0 ... 0 | || 0 λ2 ... 0 || Λ = | . . . .| . |⌈ .. .. .. ..|⌉ 0 0
    ... λ n ](img/file614.png)'
- en: (Note that the λ[i]-s are not necessarily mutually different.) Thus, Λu[i] =
    λ[i]u[i], meaning that u[1],…,u[n] is a basis from the eigenvectors of f.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: （注意，λ[i] 不一定彼此不同。）因此，Λu[i] = λ[i]u[i]，这意味着u[1],…,u[n]是f的特征向量所组成的基。
- en: (b) ⇒ (a). If u[1],…,u[n] is a basis from the eigenvectors of f, then its matrix
    Λ in that basis is diagonal. Thus, A is similar to Λ, which is what we had to
    show.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: （b）⇒（a）。如果u[1],…,u[n]是f的特征向量所组成的基，那么在该基下它的矩阵Λ是对角的。因此，A与Λ相似，这就是我们需要证明的。
- en: (b) ⇒ (c). By definition, the direct sum (Definition [6](ch007.xhtml#x1-29004r6))
    of the eigenspaces contains all linear combinations of the form
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: （b）⇒（c）。根据定义，特征空间的直和（定义[6](ch007.xhtml#x1-29004r6)）包含所有形式的线性组合
- en: '![ n x = ∑ xu . i i i=1 ](img/file617.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![ n x = ∑ xu . i i i=1 ](img/file617.png)'
- en: Since u[1],…,u[n] is a basis, V = U[λ[1]] + ⋅⋅⋅ + U[λ[k]] holds.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 由于u[1],…,u[n]是一个基，V = U[λ[1]] + ⋅⋅⋅ + U[λ[k]]成立。
- en: (c) ⇒ (b). From each eigenspace U[λ[i]], we can select a basis. Due to the construction
    of U[λ[i]], its basis will consist of eigenvectors.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: （c）⇒（b）。从每个特征空间U[λ[i]]中，我们可以选择一个基。由于U[λ[i]]的构造，其基将由特征向量组成。
- en: Since V = U[λ[1]] + ⋅⋅⋅ + U[λ[k]], the union of of such bases u[1],…,u[n] will
    be a basis for V .
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 由于V = U[λ[1]] + ⋅⋅⋅ + U[λ[k]]，这些基u[1],…,u[n]的并集将是V的基。
- en: 'Even though this theorem does not give us any useful recipes on how to diagonalize
    a matrix, it provides us with an extremely valuable insight: diagonalization is
    equivalent to finding an eigenvector basis. This is not always possible, but when
    it is, we are cooking with gas.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个定理没有给我们任何有用的矩阵对角化的具体方法，但它为我们提供了一个极为宝贵的见解：对角化等价于找到一个特征向量基。并非总是可能做到这一点，但一旦能够实现，我们就可以大展拳脚了。
- en: In the next chapter, we will take a deep dive into this topic, providing multiple
    ways to simplify matrices. If our journey in linear algebra is akin to a mountain
    climb, we will reach the peak soon.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将深入探讨这一主题，提供多种简化矩阵的方法。如果我们的线性代数之旅像登山一样，我们很快就会到达巅峰。
- en: 6.4 Summary
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 小结
- en: In this chapter, we’ve veered into the theory side of math once again. This
    time, it was about eigenvalues and eigenvectors of a matrix, that is, scalars
    λ and vectors x for which
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们再次进入了数学的理论领域。这一次，我们探讨了矩阵的特征值和特征向量，即标量 λ 和向量 x，其中
- en: '![ n×n Ax = λx, A ∈ ℝ ](img/file621.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![ n×n Ax = λx, A ∈ ℝ ](img/file621.png)'
- en: hold.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 保持。
- en: Just like most mathematical objects, this might seem daunting at first, but
    geometrically, this means that in the direction x, the linear transformation A
    is the same as a stretching by λ. In practice, we can find eigenvectors by solving
    the so-called characteristic equation
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 就像大多数数学对象一样，这一概念开始可能让人感到畏惧，但从几何角度来看，这意味着在线性变换 A 的方向 x 上，A 就是对 λ 的拉伸。实际上，我们可以通过解所谓的特征方程来找到特征向量。
- en: '![det(A − λI) = 0 ](img/file622.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![det(A − λI) = 0 ](img/file622.png)'
- en: for λ.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 λ。
- en: 'What are eigenvalues used for? There are tons of applications, but one stands
    out: according to Theorem [38](ch012.xhtml#x1-110004r38), if you can build a basis
    from the eigenvectors of the matrix A ∈ℝ^(n×n), then you can find a T ∈ℝ^(n×n)
    such that T^(−1)AT is diagonal. This process is extremely useful. For one, multiplication
    with diagonal matrices is fast and simple, and we prefer to do it whenever we
    can. For another, diagonalization reveals a ton about the internal structure of
    the underlying linear transformation.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值有什么用？应用非常广泛，但有一个尤为突出：根据定理[38](ch012.xhtml#x1-110004r38)，如果你能通过矩阵 A ∈ℝ^(n×n)
    的特征向量构建一个基，那么你可以找到一个 T ∈ℝ^(n×n)，使得 T^(−1)AT 是对角矩阵。这个过程非常有用。首先，与对角矩阵的乘法运算快速且简单，我们在可能的情况下都倾向于使用它。其次，对角化揭示了关于底层线性变换的许多内部结构。
- en: We’ve left this chapter with a multitude of questions. How do we find eigenvalues?
    What kind of matrices are diagonalizable? If a matrix is diagonalizable, how can
    we find such a form?
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这一章结束时提出了许多问题。我们如何找到特征值？哪些矩阵是可对角化的？如果一个矩阵是可对角化的，我们该如何找到这样的形式？
- en: 'We’ll answer all of these in the next chapter. Be warned: we are approaching
    the pinnacle of linear algebra. The next chapter might be our heaviest one yet.
    Just like the final stretch before reaching the peaks of Mount Everest. However,
    you have my total confidence. If you are here, you can climb it.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章回答所有这些问题。请注意：我们正接近线性代数的巅峰。下一章可能是我们最难的一章，就像攀登珠穆朗玛峰的最后一段路程一样。然而，你完全可以相信我。如果你能来到这里，你一定能征服它。
- en: Let’s go!
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 加油！
- en: 6.5 Problems
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.5 问题
- en: Problem 1\. Compute the eigenvalues of the matrices
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 1\. 计算矩阵的特征值
- en: '![ ⌊ ⌋ ⌊ ⌋ | 4 1 − 1| | 2 1 1| A = |⌈ 1 3 1 |⌉ , B = |⌈ 1 2 1|⌉, − 1 1 2 1
    1 2 ](img/file623.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌊ ⌋ | 4 1 − 1| | 2 1 1| A = |⌈ 1 3 1 |⌉ , B = |⌈ 1 2 1|⌉, − 1 1 2 1
    1 2 ](img/file623.png)'
- en: and find an eigenvector for every eigenvalue.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 并为每个特征值找到一个特征向量。
- en: Problem 2\. Let A ∈ℝ^(n×n) be an upper or lower triangular matrix. Show that
    the eigenvalues of A are its diagonal elements.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 2\. 设 A ∈ℝ^(n×n) 为上三角矩阵或下三角矩阵。证明 A 的特征值是其对角线元素。
- en: Problem 3\. Let A ∈ℝ^(n×n) be a square matrix. Show that
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 3\. 设 A ∈ℝ^(n×n) 为一个方阵。证明
- en: '![det(A − λI ) ](img/file624.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![det(A − λI ) ](img/file624.png)'
- en: is a polynomial of degree n in λ.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 是一个关于 λ 的 n 次多项式。
- en: This is the characteristic polynomial that we have talked about, and we have
    even mentioned this fact. However, we omitted the proof, so here’s your chance
    to fill the gap.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们之前谈到的特征多项式，我们甚至提到过这个事实。不过，我们省略了证明，所以这是你填补空白的机会。
- en: Problem 4\. Let A ∈ℝ^(n×n), B ∈ℝ^(n×m), and C ∈ℝ^(m×m) arbitrary matrices, and
    we define the so-called block matrix
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 4\. 设 A ∈ℝ^(n×n)、B ∈ℝ^(n×m)，C ∈ℝ^(m×m) 为任意矩阵，我们定义所谓的块矩阵
- en: '![ ⌊ ⌋ ⌈A B ⌉ (n+m )× (n+m ) D = 0 C ∈ ℝ . ](img/file625.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌈A B ⌉ (n+m )× (n+m ) D = 0 C ∈ ℝ . ](img/file625.png)'
- en: Show that if λ is an eigenvalue of A or an eigenvalue of B, then it’s also an
    eigenvalue of C.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 证明如果 λ 是 A 或 B 的特征值，那么它也是 C 的特征值。
- en: Join our community on Discord
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: Read this book alongside other users, Machine Learning experts, and the author
    himself. Ask questions, provide solutions to other readers, chat with the author
    via Ask Me Anything sessions, and much more. Scan the QR code or visit the link
    to join the community. [https://packt.link/math](https://packt.link/math)
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他读者、机器学习专家以及作者本人一起阅读本书。提出问题，提供解决方案，参与与作者的“问我任何问题”环节，等等。扫描二维码或访问链接加入社区。[https://packt.link/math](https://packt.link/math)
- en: '![PIC](img/file1.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1.png)'
