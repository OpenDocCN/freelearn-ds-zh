- en: '*Chapter 8*: Experimenting with Python Code'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*：使用 Python 代码进行实验'
- en: In this chapter, you will understand how to train `scikit-learn` library, which
    is commonly referred to as `sklearn`. You will understand how you can keep track
    of the training metrics using the **Azure** **Machine Learning** (**AzureML**)
    **SDK** and **MLflow**. Then, you will see how you can scale out the training
    process in compute clusters.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解如何训练 `scikit-learn` 库，它通常被称为 `sklearn`。你将了解如何使用**Azure** **机器学习**（**AzureML**）**SDK**
    和 **MLflow** 来跟踪训练指标。接着，你将看到如何在计算集群中扩展训练过程。
- en: 'In this chapter, we are going to cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Training a simple `sklearn` model within notebooks
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在笔记本中训练一个简单的 `sklearn` 模型
- en: Tracking metrics in Experiments
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实验中跟踪指标
- en: Scaling the training process with compute clusters
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展训练过程与计算集群
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need to have access to an Azure subscription. Within that subscription,
    you will need a `packt-azureml-rg`. You will need to have either a `Contributor`
    or `Owner` `packt-learning-mlw`. These resources should be already available to
    you if you followed the instructions in [*Chapter 2*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026),
    *Deploying Azure Machine Learning Workspace Resources*.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要有一个 Azure 订阅。在该订阅下，你需要有一个 `packt-azureml-rg`。你还需要有 `Contributor` 或 `Owner`
    权限的 `packt-learning-mlw`。如果你按照[*第2章*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026)《部署
    Azure 机器学习工作区资源》中的说明进行操作，这些资源应该已经为你准备好了。
- en: You will also need to have a basic understanding of the Python language. The
    code snippets target Python 3.6 or newer versions. You should also be familiar
    with working in the notebook experience within AzureML Studio, which was covered
    in the previous chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要具备 Python 语言的基础知识。本章中的代码片段适用于 Python 3.6 或更高版本。你还应熟悉在 AzureML Studio 中使用笔记本的操作体验，这部分内容已在上一章中讲解过。
- en: This chapter assumes you have registered the `scikit-learn` `diabetes` dataset
    in your AzureML workspace and you have created a compute cluster named `cpu-sm-cluster`,
    as described in the *Defining datastores*, *Working with datasets*, and *Working
    with compute targets* sections in [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102),
    *The AzureML Python SDK*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章假设你已经在 AzureML 工作区中注册了 `scikit-learn` 的 `diabetes` 数据集，并且已经创建了一个名为 `cpu-sm-cluster`
    的计算集群，正如在[*第7章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)《AzureML Python
    SDK》中的 *定义数据存储*、*处理数据集* 和 *使用计算目标* 部分所描述的那样。
- en: You can find all notebooks and code snippets for this chapter in GitHub at [http://bit.ly/dp100-ch08](http://bit.ly/dp100-ch08).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 GitHub 上找到本章的所有笔记本和代码片段，链接：[http://bit.ly/dp100-ch08](http://bit.ly/dp100-ch08)。
- en: Training a simple sklearn model within notebooks
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在笔记本中训练一个简单的 sklearn 模型
- en: 'The goal of this section is to create a Python script that will produce a simple
    model on top of the `diabetes` dataset that you registered in *Working with datasets*
    in [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102), *The AzureML
    Python SDK*. The model will be getting numeric inputs and will be predicting a
    numeric output. To create this model, you will need to prepare the data, train
    the model, evaluate how the trained model performs, and then store it so that
    you will be able to reuse it in the future, as seen in *Figure 8.1*:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是创建一个 Python 脚本，在你在[*第7章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)中注册的`diabetes`数据集上，训练出一个简单的模型，*《AzureML
    Python SDK》*。该模型将获取数字输入，并预测一个数字输出。为了创建这个模型，你需要准备数据、训练模型、评估训练模型的表现，然后将其存储，以便未来可以重用，正如在*图8.1*中所示：
- en: '![Figure 8.1 – Process to produce the diabetes-predicting model'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.1 - 生成糖尿病预测模型的过程'
- en: '](img/B16777_08_001.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_001.jpg)'
- en: Figure 8.1 – Process to produce the diabetes-predicting model
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 - 生成糖尿病预测模型的过程
- en: Let's start by understanding the dataset you will be working with. The `diabetes`
    dataset consists of data from 442 `diabetes` patients. Each row represents one
    patient. Each row consists of 10 features (`target`, is the quantitative measure
    of the `diabetes` disease progression 1 year after the features were recorded.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从了解你将要使用的数据集开始。`diabetes` 数据集包含442名`diabetes`患者的数据。每一行代表一个患者。每一行包含10个特征（`target`，是记录特征后1年糖尿病病情发展的定量指标）。
- en: 'You can explore the dataset further within the AzureML Studio interface as
    seen in *Figure 8.2*:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 AzureML Studio 界面中进一步探索数据集，正如在*图8.2*中所示：
- en: '![Figure 8.2 – The registered diabetes dataset'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.2 – 注册的糖尿病数据集'
- en: '](img/B16777_08_002.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_002.jpg)'
- en: Figure 8.2 – The registered diabetes dataset
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – 已注册的糖尿病数据集
- en: 'Normally in the preparation phase, you load the raw data, curate rows that
    have missing values, normalize feature values, and then split the dataset into
    train and validation data. Since the data is already preprocessed, you will just
    need to load the data and split it into two:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通常在准备阶段，您会加载原始数据，处理缺失值的行，规范化特征值，然后将数据集分为训练数据和验证数据。由于数据已经预处理，您只需加载数据并将其拆分为两个部分：
- en: Navigate to the `chapter08` and then create a notebook named `chapter08.ipynb`:![Figure
    8.3 – Creating the chapter08 notebook you will be working on
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到`chapter08`，然后创建一个名为`chapter08.ipynb`的笔记本：![图 8.3 – 创建您将要使用的chapter08笔记本
- en: '](img/B16777_08_003.jpg)'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_08_003.jpg)'
- en: Figure 8.3 – Creating the chapter08 notebook you will be working on
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.3 – 创建您将要使用的chapter08笔记本
- en: 'In the first cell of the notebook, add the following code:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在笔记本的第一个单元格中，添加以下代码：
- en: '[PRE0]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In this code snippet, you get a reference to your workspace and retrieve the
    dataset named `diabetes`. Then you split it into two `TabularDataset` using the
    `random_split()` method. The first dataset is `training_data`, which contains
    80% of the data, while the `validation_data` dataset references the other 20%
    of the data. These datasets contain both the features and the label you want to
    predict. Using the `drop_columns()` and `keep_columns()` methods of `TabularDataset`,
    you can separate the features from the `label` columns. You then load the data
    in memory in a `to_pandas_dataframe()` method of `TabularDataset`. You end up
    with four pandas DataFrames:'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在此代码片段中，您获取工作区的引用并检索名为`diabetes`的数据集。然后，您使用`random_split()`方法将其拆分为两个`TabularDataset`。第一个数据集是`training_data`，它包含80%的数据，而`validation_data`数据集引用其余20%的数据。这些数据集包含您要预测的特征和标签。使用`TabularDataset`的`drop_columns()`和`keep_columns()`方法，您可以将特征与`label`列分开。然后，您通过`TabularDataset`的`to_pandas_dataframe()`方法将数据加载到内存中。最终，您将得到四个pandas数据框：
- en: '`X_train`: Contains 80% of the rows. Each row has 10 columns (`0` to `9`).'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X_train`：包含80%的行，每行有10列（`0`到`9`）。'
- en: '`y_train`: Contains 80% of the rows. Each row has 1 column (`target`).'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_train`：包含80%的行，每行有1列（`target`）。'
- en: '`X_validate`: Contains 20% of the rows. Each row has 10 columns (`0` to `9`).'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X_validate`：包含20%的行，每行有10列（`0`到`9`）。'
- en: '`y_validate`: Contains 20% of the rows. Each row has 1 column (`target`).'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_validate`：包含20%的行，每行有1列（`target`）。'
- en: The `diabetes` dataset is very popular in scientific literature. It is used
    as an example to train *regression* models. The `scikit-learn` library offers
    a dedicated module named `sklearn.linear_model` containing a lot of linear regression
    models we can use. Now that you have prepared the data, your next task is to train
    the model.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`diabetes`数据集在科学文献中非常流行。它被用作训练*回归*模型的示例。`scikit-learn`库提供了一个名为`sklearn.linear_model`的专用模块，包含许多线性回归模型可供我们使用。现在您已经准备好了数据，接下来的任务是训练模型。'
- en: In this step, you are going to train a `LassoLars` model, which is an abbreviation
    for `LassoLars` class accepts a float parameter named `alpha`, which is known
    as a *regularization parameter* or *penalty term*. Its primary purpose is to protect
    the model from overfitting to the training dataset. Since this parameter controls
    the training process, it is referred to as being a *hyperparameter*. This parameter
    cannot be changed once the model has been trained. In this code block, you are
    instantiating an untrained model, setting `0.1` for the `alpha` parameter. In
    the next chapter, [*Chapter 9*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136),
    *Optimizing the ML Model*, you will tune this parameter and try to locate the
    best value for your dataset.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此步骤中，您将训练一个`LassoLars`模型，它是`LassoLars`类的缩写，该类接受一个名为`alpha`的浮动参数，该参数被称为*正则化参数*或*惩罚项*。它的主要目的是保护模型免受训练数据集的过拟合。由于该参数控制训练过程，因此被称为*超参数*。一旦模型训练完成，这个参数不能再更改。在这个代码块中，您正在实例化一个未训练的模型，并将`alpha`参数设置为`0.1`。在下一章，[*第9章*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136)，*优化机器学习模型*，您将调整此参数，并尝试为您的数据集找到最佳值。
- en: Then, you are using the `X_train` and `y_train` DataFrames to fit() the model,
    which means you are training the model against the training dataset. After this
    process, the `model` variable references a trained model that you can use to make
    predictions.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，您将使用`X_train`和`y_train`数据框来fit()模型，这意味着您正在用训练数据集训练模型。经过这个过程后，`model`变量引用一个已训练的模型，您可以使用该模型进行预测。
- en: 'The next task is to evaluate the model you produced based on a metric. The
    most common metrics to evaluate a regression model are as follows:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来的任务是基于某个指标评估你所生成的模型。评估回归模型时最常用的指标如下：
- en: Mean or median absolute error.
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均或中位数绝对误差。
- en: Mean squared error or log error. Another common variation of this metric is
    the `mean_squared_error` method of the `sklearn.metrics` package. A common issue
    with this metric is that a model trained on data with a larger range of values
    has a higher rate of error than the same model trained on data with a smaller
    range. You are going to use a technique called *metric normalization* that basically
    divides the metric by the range of the data. The resulting metric is known as
    the `X_validate` DataFrame. You calculate the RMSE, comparing the predictions
    with the ground truth stored in the `y_validate` DataFrame. Then, you calculate
    the range of values (maximum minus minimum) using the `ptp()` method of `0.2`.
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均方误差或对数误差。该指标的另一种常见变体是`sklearn.metrics`包中的`mean_squared_error`方法。该指标的常见问题是，当模型在具有更大值范围的数据上训练时，相比于在较小值范围的数据上训练的同一模型，其误差率更高。你将使用一种称为*指标归一化*的技术，该技术基本上是将指标除以数据的范围。计算得到的指标被称为`X_validate`数据框。你通过将预测结果与存储在`y_validate`数据框中的真实值进行比较，来计算RMSE。接着，你使用`ptp()`方法计算值的范围（最大值减去最小值），得到`0.2`。
- en: The last step is to store the trained model to be able to reuse it in the future.
    You are going to create a folder named `outputs`, and you are going to persist
    the model to a file. The persistence of a Python object to a file is done using
    the `dump()` method of the `joblib` library.
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后一步是将训练好的模型存储起来，以便将来能够重用。你将创建一个名为`outputs`的文件夹，并将模型持久化到一个文件中。Python对象的持久化通过`joblib`库的`dump()`方法完成。
- en: 'In a new notebook cell, input the following source code:'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在新的笔记本单元格中，输入以下源代码：
- en: '[PRE1]'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You create the `outputs` folder if it does not exist. Then, you store the model
    in a filename containing the `model_` prefix, followed by the NRMSE metric calculated
    in *Step 4*, followed by an `_`, and then the `alpha` parameter used to instantiate
    the model. You should be able to see the serialized model in the file explorer,
    as seen in *Figure 8.4*:'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果`outputs`文件夹不存在，你需要先创建它。然后，将模型存储在包含`model_`前缀的文件名中，后跟在*步骤 4*中计算的NRMSE指标，再加上一个`_`，然后是用于实例化模型的`alpha`参数。你应该能够在文件资源管理器中看到序列化的模型，如*图
    8.4*所示：
- en: '![Figure 8.4 – Serialized model stored in the outputs folder'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.4 – 序列化模型存储在输出文件夹中'
- en: '](img/B16777_08_004.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_004.jpg)'
- en: Figure 8.4 – Serialized model stored in the outputs folder
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 序列化模型存储在输出文件夹中
- en: The naming convention you used in *Step 5* helps you keep track of how well
    the model performs and tracks the parameter you used in this run. The AzureML
    SDK offers various methods to monitor, organize, and manage your training runs,
    something you will explore in the next section.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你在*步骤 5*中使用的命名规范帮助你跟踪模型的表现，以及记录你在本次运行中使用的参数。AzureML SDK提供了多种方法来监控、组织和管理你的训练过程，这些内容你将在下一节中探讨。
- en: Tracking metrics in Experiments
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在实验中跟踪指标
- en: When you are training a model, you are performing a trial and you are logging
    various aspects of that process, including metrics such as the NRMSE that you
    need to compare model performance. The AzureML workspace offers the concept of
    **Experiments** – that is, a container to group such trials/runs together.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当你训练一个模型时，你是在进行一个试验，并且你正在记录该过程的各个方面，包括你需要比较模型表现的NRMSE等指标。AzureML工作区提供了**实验**的概念——即用于将这些试验/运行归类的容器。
- en: 'To create a new Experiment, you just need to specify the workspace you will
    use and provide a name that contains up to 36 letters, numbers, underscores, and
    dashes. If the Experiment already exists, you will get a reference to it. Add
    a cell in your `chapter08.ipynb` notebook and add the following code:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个新的实验，只需要指定你将使用的工作区，并提供一个包含最多36个字母、数字、下划线和破折号的名称。如果实验已经存在，你将获得对它的引用。在你的`chapter08.ipynb`笔记本中添加一个单元格，并添加以下代码：
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You start by getting a reference to the existing AzureML workspace and then
    create the `chapter08` Experiment if it doesn''t already exist. If you navigate
    to the **Assets** | **Experiments** section of the Studio interface you will notice
    an empty Experiment appears in the list, as seen in *Figure 8.5*:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先获取现有AzureML工作区的引用，然后创建`chapter08`实验（如果它还不存在的话）。如果你导航到Studio界面中的**资产** | **实验**部分，你会注意到列表中会出现一个空的实验，如*图
    8.5*所示：
- en: '![Figure 8.5 – Empty Experiment created with the SDK'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.5 – 使用SDK创建的空实验'
- en: '](img/B16777_08_005.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_005.jpg)'
- en: Figure 8.5 – Empty Experiment created with the SDK
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – 使用SDK创建的空实验
- en: 'To create a run under the `chapter08` Experiment, you can add the following
    code in a new cell:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要在`chapter08`实验下创建一个`run`，你可以在新的单元格中添加以下代码：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `run` variable gives you access to an instance of the `Run` class of the
    AzureML SDK, which represents a single trial of an Experiment. Each `run` instance
    has a unique ID that identifies the specific run in the workspace.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`run`变量允许你访问AzureML SDK的`Run`类实例，该实例代表实验的单个试验。每个`run`实例都有一个唯一的ID，用于标识工作区中特定的运行。'
- en: Important note
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In the *Scaling the training process with compute clusters* section, you will
    use the `get_context` method of the `Run` class to get a reference to the `run`
    instance where the Python script is being executed. The `run` is normally automatically
    created when you submit a script to execute under an Experiment. The `start_logging`
    method is used rarely and only when you want to manually create a `run` and log
    metrics. The most common cases are when you are using notebook cells to train
    a model or when you are training a model on a remote compute such as your local
    computer or a **Databricks** workspace.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在*扩展训练过程与计算集群*部分中，你将使用`Run`类的`get_context`方法来获取当前执行Python脚本的`run`实例的引用。通常，当你提交脚本在实验下执行时，`run`会自动创建。`start_logging`方法较少使用，仅在你需要手动创建一个`run`并记录度量时使用。最常见的情况是你使用笔记本单元格来训练模型，或者在远程计算环境（如本地计算机或**Databricks**工作区）上训练模型时。
- en: 'The `run` class offers a rich logging API. The most frequent method used is
    the generic `log()` one, which allows you to log metrics with the following code:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`run`类提供了丰富的日志记录API。最常用的方法是通用的`log()`方法，它允许你通过以下代码记录度量：'
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this code, you log the value `0.01` for the `nrmse` metric, and then you
    log the value `0.015` for the same metric, passing the optional `description`
    parameter.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，你记录了`nrmse`度量的值`0.01`，然后记录了同一度量的值`0.015`，并传递了可选的`description`参数。
- en: 'If you navigate to the `chapter08` Experiment, you will notice there is a single
    `run` that is currently `run` and navigate to the **Metrics** tab, you will be
    able to notice the two measurements of the **nrmse** metric, depicted either as
    a chart or a table, as seen in *Figure 8.6*:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你进入`chapter08`实验，你会注意到目前有一个正在运行的`run`，并且当你切换到**Metrics**标签时，你会看到**nrmse**度量的两个测量值，以图表或表格的形式呈现，正如*图
    8.6*所示：
- en: '![Figure 8.6 – The two measurements of nrmse as seen in the Studio experience'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.6 – 在Studio体验中看到的nrmse的两个测量值'
- en: '](img/B16777_08_006.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_006.jpg)'
- en: Figure 8.6 – The two measurements of nrmse as seen in the Studio experience
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – 在Studio体验中看到的nrmse的两个测量值
- en: 'The `Run` class offers a rich list of logging methods, including the following
    ones:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`Run`类提供了丰富的日志记录方法，包括以下几种：'
- en: 'The `log_list` method allows you to log a list of values for the specific metric.
    An example of this method is the following code:'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log_list`方法允许你为特定度量记录一系列值。该方法的示例如下代码：'
- en: '[PRE5]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This code will produce *Figure 8.7* in the *Metrics* section of the run:'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码将在`run`的*Metrics*部分生成*图 8.7*：
- en: '![Figure 8.7 – Graph representing three values logged with the log_list method'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.7 – 使用log_list方法记录的三个值的图表'
- en: '](img/B16777_08_007.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_007.jpg)'
- en: Figure 8.7 – Graph representing three values logged with the log_list method
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – 使用log_list方法记录的三个值的图表
- en: 'The `log_table` and `log_row` methods allow you to log tabular data. Note that,
    with this method, you can specify the labels in the *x* axis in contrast to the
    `log_list` method:'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log_table`和`log_row`方法允许你记录表格数据。请注意，使用此方法时，你可以指定与`log_list`方法不同的*X*轴标签：'
- en: '[PRE6]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This code snippet will produce *Figure 8.8* in the *Metrics* section of the
    run:'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码片段将在`run`的*Metrics*部分生成*图 8.8*：
- en: '![Figure 8.8 – Tabular metric logged using the log_table and log_row methods'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.8 – 使用log_table和log_row方法记录的表格度量'
- en: '](img/B16777_08_008.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_008.jpg)'
- en: Figure 8.8 – Tabular metric logged using the log_table and log_row methods
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 – 使用log_table和log_row方法记录的表格度量
- en: Specialized methods such as `log_accuracy_table`, `log_confusion_matrix`, `log_predictions`,
    and `log_residuals` provide a custom rendering of the logged data.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专门的方法如`log_accuracy_table`、`log_confusion_matrix`、`log_predictions`和`log_residuals`提供了日志数据的自定义呈现。
- en: The `log_image` method allows you to log graphs or images from the well-known
    `matplotlib` Python library or other plotting libraries.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log_image`方法允许你从著名的`matplotlib` Python库或其他绘图库记录图形或图像。'
- en: The `upload_file`, `upload_files`, and `upload_folder` methods allow you to
    upload Experiment residuals and associate them with the current run. These methods
    are commonly used to upload various binary artifacts that can be produced during
    the `run` execution, such as interactive HTML graphs created by open source libraries
    such as `plotly`.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upload_file`、`upload_files`和`upload_folder`方法允许你上传实验残留文件并将其与当前运行关联。这些方法通常用于上传在`run`执行过程中生成的各种二进制工件，例如由开源库如`plotly`创建的交互式HTML图形。'
- en: 'You can optionally create child runs to isolate a subsection of the trial.
    Child runs log their own metrics, and you can optionally log in to the parent
    run as well. For example, the following code snippet creates a child run, logs
    a metric named `child_metric` (which is only visible within that run), and then
    logs in the parent''s metrics `metric_from_child`:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以选择创建子运行以隔离试验的一个子部分。子运行记录它们自己的度量指标，你也可以选择登录到父运行。例如，以下代码段创建一个子运行，记录一个名为`child_metric`的度量（该度量仅在该运行中可见），然后在父运行的度量中记录`metric_from_child`：
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Once you have completed the run, you need to change its **Running** status.
    You can use one of the following methods:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你完成了运行，你需要更改其**运行中**状态。你可以使用以下方法之一：
- en: The `complete` method indicates that the run was completed successfully. This
    method also uploads the `outputs` folder (if it exists) to the `runs` artifacts
    without needing to explicitly call the `upload_folder` method of the `Run` class.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`complete`方法表示运行已成功完成。此方法还会将`outputs`文件夹（如果存在）上传到`runs`工件中，而无需显式调用`Run`类的`upload_folder`方法。'
- en: The `cancel` method indicates that the job was canceled. You will notice runs
    being canceled in AutoML Experiments because the timeout period was reached.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cancel`方法表示作业已被取消。你会注意到在AutoML实验中运行被取消，因为超出了超时限制。'
- en: The deprecated `fail` method indicates an error occurred.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已弃用的`fail`方法表示发生了错误。
- en: 'The following code snippet cancels the child run and completes the root run,
    printing the status, which should read **Completed**:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码段取消了子运行并完成了根运行，打印状态，应该显示**已完成**：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In this section, you got an overview of the logging capabilities of AzureML.
    In the next section, you will refactor the code you created in the *Training a
    simple sklearn model within notebooks* section and add logging capabilities.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你了解了AzureML的日志记录功能。在下一部分，你将重构你在*在笔记本中训练简单的sklearn模型*部分编写的代码，并添加日志记录功能。
- en: Tracking model evolution
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪模型演化
- en: 'In the previous section, you may have noticed that the `outputs` folder that
    you created in the *Training a simple sklearn model within notebooks* section
    of this chapter was automatically uploaded to the run when you executed the `complete`
    method. To avoid uploading those stale artifacts, you will need to delete the
    `outputs` folder:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分，你可能已经注意到，当你执行`complete`方法时，本章*在笔记本中训练简单的sklearn模型*部分中创建的`outputs`文件夹会自动上传到运行中。为了避免上传那些过时的工件，你需要删除`outputs`文件夹：
- en: 'Add a cell in your `chapter08.ipynb` notebook and delete the `outputs` folder
    using the following code snippet:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的`chapter08.ipynb`笔记本中添加一个单元格，并使用以下代码段删除`outputs`文件夹：
- en: '[PRE9]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As a next step, you will refactor the training and evaluation code to a single
    method, passing in the `alpha` parameter and the `training` and `validation` datasets:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步，你将把训练和评估的代码重构为一个单独的方法，传入`alpha`参数以及`training`和`validation`数据集：
- en: '[PRE10]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This code is the exact equivalent of the code you wrote in the *Training a simple
    sklearn model within notebooks* section. You can now train multiple models using
    `train_and_evaluate` and passing different values for the `alpha` parameter, a
    process referred to as *hyperparameter tuning*. In the last line of this code
    snippet, you get a reference to the resulting trained model and its NRMSE metric.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码与你在*在笔记本中训练简单的sklearn模型*部分编写的代码完全相同。现在，你可以通过使用`train_and_evaluate`并传入不同的`alpha`参数值来训练多个模型，这个过程被称为*超参数调优*。在这段代码的最后一行，你将获得训练好的模型及其NRMSE度量的引用。
- en: Important note
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'If you get an error as follows: `NameError: name ''X_train'' is not defined`,
    you will need to rerun the cell of your notebook where you defined the `X_train`,
    `y_train`, `X_validate`, and `y_validate` variables. This is an indication that
    the Python kernel has restarted, and all the variables have been lost from memory.'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '如果你遇到以下错误：`NameError: name ''X_train'' is not defined`，你需要重新运行你定义了`X_train`、`y_train`、`X_validate`和`y_validate`变量的单元格。这表示Python内核已经重启，所有变量都已从内存中丢失。'
- en: So far, you have refactored the existing code and kept the same functionality.
    To enable logging through the `Run` class you explored in the previous section,
    you will need to pass the reference to the current run instance to the `train_and_evaluate`
    method.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 到目前为止，你已经重构了现有代码并保持了相同的功能。为了启用通过前一部分中探索的`Run`类进行日志记录，你需要将当前运行实例的引用传递给`train_and_evaluate`方法。
- en: 'In a new cell, add the following snippet, which will override the existing
    declaration of the `train_and_evaluate` method:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个新的单元格中，添加以下代码片段，它将覆盖现有的`train_and_evaluate`方法声明：
- en: '[PRE11]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Having this `train_and_evaluate` method, you can do a hyperparameter tuning
    and train multiple models for multiple values of the `α` (`alpha`) parameter,
    using the following code:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拥有这个`train_and_evaluate`方法后，你可以进行超参数调优，并为多个`α`（`alpha`）参数值训练多个模型，使用以下代码：
- en: '[PRE12]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note that instead of calling the `complete` method, we use the `with .. as`
    Python design pattern. As the `run` variables move out of scope, it is automatically
    marked as completed.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，我们没有调用`complete`方法，而是使用了`with .. as`的Python设计模式。随着`run`变量超出作用域，它会自动标记为已完成。
- en: 'Using the `get_portal_url` in *Step 4*, you printed the link to the studio''s
    `log` method calls, while the `α` (`alpha`) parameter, something you logged using
    the `log_row` method. You should see graphs similar to the ones shown in *Figure
    8.9*:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*步骤4*中使用`get_portal_url`，你打印了指向工作室的`log`方法调用的链接，而`α`（`alpha`）参数是你使用`log_row`方法记录的内容。你应该看到类似于*图8.9*所示的图表：
- en: '![Figure 8.9 – Evolution of the nrmse metric for the diabetes model'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.9 – 糖尿病模型的nrmse指标演变]'
- en: '](img/B16777_08_009.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_009.jpg)'
- en: Figure 8.9 – Evolution of the nrmse metric for the diabetes model
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9 – 糖尿病模型的nrmse指标演变
- en: Important note
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In this section, you are just storing the metrics on the `Run` instance and
    not the actual trained models. You could have stored the generated models by generating
    the `.pkl` file and then using the `upload_file` method to upload it in the run's
    artifacts. In [*Chapter 12*](B16777_12_Final_VK_ePub.xhtml#_idTextAnchor171),
    *Operationalizing Models with Code*, you are going to learn about the model registry
    capabilities of the AzureML SDK, which provides a superior experience to keep
    track of the actual models.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你仅仅将指标存储在`Run`实例中，而不是实际的训练模型。你本可以通过生成`.pkl`文件并使用`upload_file`方法将其上传到运行的工件中来存储生成的模型。在[*第12章*](B16777_12_Final_VK_ePub.xhtml#_idTextAnchor171)，*使用代码实现模型操作*，你将学习AzureML
    SDK的模型注册功能，它提供了一种更优的体验来跟踪实际模型。
- en: In this section, you saw how you can enable metric logging using the AzureML
    SDK. When it comes to tracking Experiment metrics, the data science community
    is using a popular open source framework called MLflow. In the next section, you
    will learn how to use that library to track metrics in the AzureML workspace.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你看到了如何使用AzureML SDK启用指标日志记录。在跟踪实验指标方面，数据科学界使用了一个流行的开源框架——MLflow。在下一节中，你将学习如何使用该库在AzureML工作区中跟踪指标。
- en: Using MLflow to track Experiments
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用MLflow跟踪实验
- en: 'The MLflow library is a popular open source library for managing the life cycle
    of your data science Experiments. This library allows you to store artifacts and
    metrics locally or on a server. The AzureML workspace provides an MLflow server
    that you can use to do the following:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow库是一个流行的开源库，用于管理数据科学实验的生命周期。该库允许你将工件和指标存储在本地或服务器上。AzureML工作区提供了一个MLflow服务器，你可以用它来做以下事情：
- en: Track and log Experiment metrics through the **MLflow** **Tracking** component.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过**MLflow** **跟踪**组件跟踪和记录实验指标。
- en: Orchestrate code execution on AzureML compute clusters through the **MLflow**
    **Projects** component (similar to the pipelines you will see in [*Chapter 11*](B16777_11_Final_VK_ePub.xhtml#_idTextAnchor160),
    *Working with Pipelines*).
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过**MLflow** **项目**组件在AzureML计算集群上协调代码执行（类似于你将在[*第11章*](B16777_11_Final_VK_ePub.xhtml#_idTextAnchor160)中看到的管道，*与管道合作*）。
- en: Manage models in the AzureML model registry, which you will see in [*Chapter
    12*](B16777_12_Final_VK_ePub.xhtml#_idTextAnchor171), *Operationalizing Models
    with Code*.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 AzureML 模型注册表中管理模型，你将在[*第 12 章*](B16777_12_Final_VK_ePub.xhtml#_idTextAnchor171)《用代码实现模型运营化》中看到该内容。
- en: 'In this section, you will focus on the MLflow Tracking component to track metrics.
    The following snippet uses the `MLflow` library to track the parameters and the
    metrics of the `diabetes` model you have created in the previous section under
    an Experiment named `chapter08-mlflow`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍 MLflow Tracking 组件，用于跟踪度量。以下代码片段使用`MLflow`库跟踪你在前一节中创建的`diabetes`模型的参数和度量，实验名称为`chapter08-mlflow`：
- en: '[PRE13]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: One of the most well-known features of the MLflow Tracking component is the
    automatic logging capabilities it provides. Calling the `mlflow.sklearn.autolog()`
    method before your training code enables automatic logging of `sklearn` metrics,
    params, and produced models. Similar to the `autolog` method specific to `sklearn`,
    there are packages for most of the common training frameworks, such as PyTorch,
    fast.ai, Spark, and others.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow Tracking 组件最著名的特点之一是其提供的自动日志记录功能。在训练代码之前调用`mlflow.sklearn.autolog()`方法，可以自动记录`sklearn`的度量、参数和生成的模型。类似于`sklearn`特定的`autolog`方法，常见训练框架（如
    PyTorch、fast.ai、Spark 等）也有对应的包。
- en: Using the `log_metric` method, you explicitly ask the MLflow library to log
    a metric. In this case, you log the NRMSE metric, which is not captured automatically
    by the automatic logging capability.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`log_metric`方法，你显式地要求 MLflow 库记录一个度量。在此示例中，你记录了 NRMSE 度量，该度量不会通过自动日志记录功能自动捕获。
- en: 'As you can see in *Figure 8.10* the MLflow Tracking component logs all artifacts
    and the trained model in a folder structure under the `mlruns` folder next to
    the notebook:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如*图 8.10*所示，MLflow Tracking 组件将所有工件和训练模型以文件夹结构记录在`mlruns`文件夹中，紧邻笔记本文件。
- en: '![Figure 8.10 – Tracking metrics using the local FileStore mode of the MLflow
    Tracking component'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.10 – 使用 MLflow Tracking 组件的本地 FileStore 模式跟踪度量'
- en: '](img/B16777_08_010.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_010.jpg)'
- en: Figure 8.10 – Tracking metrics using the local FileStore mode of the MLflow
    Tracking component
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10 – 使用 MLflow Tracking 组件的本地 FileStore 模式跟踪度量
- en: This is the default setting, referred to as `local FileStore`. You can use the
    AzureML workspace as a *remote tracking server*. To do so, you need to use the
    `mlflow.set_tracking_uri()` method to connect to a tracking URI.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这是默认设置，称为`本地 FileStore`。你可以将 AzureML 工作区用作*远程跟踪服务器*。为此，你需要使用`mlflow.set_tracking_uri()`方法连接到一个跟踪
    URI。
- en: To enable the MLflow to AzureML integration, you need to ensure that your environment
    has the `azureml-mlflow` Python library. This package is already present in the
    AzureML compute instances. If you were working on a Databricks workspace, you
    would need to install it manually using the `pip install azureml-mlflow` command.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用 MLflow 与 AzureML 的集成，你需要确保环境中安装了`azureml-mlflow` Python 库。该库已包含在 AzureML
    计算实例中。如果你在 Databricks 工作区中工作，则需要通过`pip install azureml-mlflow`命令手动安装。
- en: 'To get the tracking **URI** and run the same Experiment using AzureML as the
    remote tracking server, use the following code snippet:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取跟踪**URI**并使用 AzureML 作为远程跟踪服务器运行相同的实验，请使用以下代码片段：
- en: '[PRE14]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `get_mlflow_tracking_uri` method of the `Workspace` class returns a URL
    that is valid for 1 hour. If your Experiment takes more than an hour to complete,
    you will need to generate a new URI and assign it using the `set_tracking_uri`
    method, as seen in the preceding snippet.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`Workspace`类的`get_mlflow_tracking_uri`方法返回一个有效期为 1 小时的 URL。如果你的实验超过一小时仍未完成，你将需要生成新的
    URI，并使用`set_tracking_uri`方法将其分配，如前面代码片段所示。'
- en: 'You should be able to see the run and the tracked metrics in the Studio experience,
    as seen in *Figure 8.11*:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够在 Studio 界面中看到运行情况和已跟踪的度量，如*图 8.11*所示：
- en: '![Figure 8.11 – Metrics logged using the MLflow library with AzureML as the
    remote tracking server'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.11 – 使用 MLflow 库并将 AzureML 用作远程跟踪服务器时记录的度量'
- en: '](img/B16777_08_011.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_011.jpg)'
- en: Figure 8.11 – Metrics logged using the MLflow library with AzureML as the remote
    tracking server
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11 – 使用 MLflow 库并将 AzureML 用作远程跟踪服务器时记录的度量
- en: So far, you have been using the compute instance in the AzureML workspace, and
    you were training ML models in the **Notebook** kernel. This approach works well
    for small models or rapid prototypes over sample data. At some point, you will
    need to handle more demanding workloads, either with bigger memory requirements
    or even distributed training capabilities in multiple computer nodes. This can
    be achieved by delegating the training process to the compute clusters you created
    in [*Chapter 4*](B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053), *Configuring
    the Workspace*. In the next section, you will learn how to execute Python scripts
    in your AzureML compute clusters.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你一直在使用 AzureML 工作区中的计算实例，并且你是在**Notebook**内核中训练 ML 模型。对于小型模型或在示例数据上快速原型开发，这种方法效果很好。但在某些时候，你将需要处理更高负载的工作负载，这可能涉及更大的内存要求，甚至是在多个计算节点上进行分布式训练。你可以通过将训练过程委托给在[*第
    4 章*](B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053)中创建的计算集群来实现这一目标，*配置工作区*。在下一节中，你将学习如何在
    AzureML 计算集群中执行 Python 脚本。
- en: Scaling the training process with compute clusters
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用计算集群扩展训练过程
- en: In [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102), *The AzureML
    Python SDK*, you created a compute cluster named `cpu-sm-cluster`. In this section,
    you are going to submit a training job to be executed on that cluster. To do that,
    you will need to create a Python script that will be executed on the remote compute
    target.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 7 章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)，*AzureML Python SDK*中，你创建了一个名为`cpu-sm-cluster`的计算集群。在这一节中，你将提交一个训练任务以在该集群上执行。为此，你需要创建一个将在远程计算目标上执行的
    Python 脚本。
- en: 'Navigate to the `greeter-job` under the `chapter08` folder you have been working
    with so far. Add a Python file named `greeter.py`:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到你迄今为止正在使用的`chapter08`文件夹中的`greeter-job`。添加一个名为`greeter.py`的 Python 文件：
- en: '![Figure 8.12 – Adding a simple Python script to execute on a remote compute
    cluster'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.12 – 向远程计算集群添加简单的 Python 脚本以执行'
- en: '](img/B16777_08_012.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_012.jpg)'
- en: Figure 8.12 – Adding a simple Python script to execute on a remote compute cluster
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12 – 向远程计算集群添加简单的 Python 脚本以执行
- en: 'Open that file and add the following code in it:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 打开该文件并添加以下代码：
- en: '[PRE15]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This script uses the `ArgumentParser` class from the `argparse` module to parse
    the parameters passed to the script. It is trying to locate a `--greet-name` parameter
    and assign the discovered value to the `name` attribute of the object it returns
    (`args.name`). Then, it prints a greeting message for the given name. To try the
    script, open a terminal and type the following:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本使用`argparse`模块中的`ArgumentParser`类来解析传递给脚本的参数。它试图查找一个`--greet-name`参数，并将找到的值分配给它返回的对象的`name`属性（`args.name`）。然后，它会打印出给定名称的问候消息。要尝试这个脚本，请打开终端并输入以下命令：
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This command will produce the output seen in *Figure 8.13*:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令将产生如下所示的输出，如*图 8.13*所示：
- en: '![Figure 8.13 – Testing the simple script you will execute on a remote compute'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.13 – 测试你将在远程计算机上执行的简单脚本'
- en: '](img/B16777_08_013.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_013.jpg)'
- en: Figure 8.13 – Testing the simple script you will execute on a remote compute
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13 – 测试你将在远程计算机上执行的简单脚本
- en: 'To execute this simple Python script on a remote compute cluster, go back to
    the `chapter08.ipynb` notebook, add a new cell, and type the following code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在远程计算集群上执行这个简单的 Python 脚本，请返回到`chapter08.ipynb`笔记本，添加一个新单元，并输入以下代码：
- en: '[PRE17]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In this code, you are doing the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，你正在执行以下操作：
- en: Get a reference to the workspace, and then you assign to the `target` variable
    a reference to the `cpu-sm-cluster` cluster.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取工作区的引用，然后将`target`变量分配给`cpu-sm-cluster`集群的引用。
- en: Create a `ScriptRunConfig` to execute the `greeter.py` script that is located
    in the `greeter-job` folder. This script will execute in the `target` compute
    passing the `--greet-name` and `packt` arguments, which are going to be concatenated
    with a space between them.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`ScriptRunConfig`，以执行位于`greeter-job`文件夹中的`greeter.py`脚本。该脚本将在`target`计算机上执行，并传递`--greet-name`和`packt`参数，它们将通过空格连接起来。
- en: Create an Experiment called `greet-packt`, and you submit the script configuration
    to execute under this Experiment. The `submit` method creates a new `Run` instance.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`greet-packt`的实验，并将脚本配置提交以在该实验下执行。`submit`方法创建了一个新的`Run`实例。
- en: You use the `get_portal_url` method to get the portal URL for the specific `Run`
    instance. You then call the `wait_for_completion` method, setting the `show_output`
    parameter to `True`. To wait for the run to complete, turn on verbose logging
    and print the logs in the output of the cell.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用`get_portal_url`方法获取特定`Run`实例的门户URL。然后调用`wait_for_completion`方法，将`show_output`参数设置为`True`。为了等待运行完成，开启详细日志记录，并在单元格的输出中打印日志。
- en: Important note
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要说明
- en: In the first version of the AzureML SDK, instead of `ScriptRunConfig`, you would
    have used the `Estimator` class, which is deprecated. Moreover, there are deprecated
    specialized `Estimator` classes for specific frameworks such as the `TensorFlow`
    class that provided a way to run TensorFlow-specific code. This approach has been
    deprecated in favor of the environments you will read about in the *Understanding
    execution environments* section that follows. Nonetheless, the syntax and the
    parameters of those deprecated classes are very similar to `ScriptRunConfig`.
    You should be able to read deprecated code without any issue. Keep that in mind
    if you see an old question in the certification exam referencing these deprecated
    classes.
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在AzureML SDK的第一个版本中，你会使用`Estimator`类，而不是`ScriptRunConfig`，但该类已被弃用。此外，还有一些针对特定框架的已弃用专用`Estimator`类，例如`TensorFlow`类，它提供了一种运行特定于TensorFlow的代码的方式。这种方法已经被弃用，取而代之的是你将在下面的*理解执行环境*部分中阅读到的环境。然而，这些已弃用类的语法和参数与`ScriptRunConfig`非常相似。你应该能够毫无问题地阅读这些已弃用的代码。如果在认证考试中看到关于这些已弃用类的旧问题，记得这一点。
- en: You have successfully completed a remote execution of a run. In the next section,
    you will explore the logs of the run you just completed and understand better
    the mechanics of AzureML.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功完成了远程执行的运行。在下一部分，你将探索刚刚完成的运行日志，更好地理解AzureML的机制。
- en: Exploring the outputs and logs of a run
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索运行的输出和日志
- en: In this section, you are going to explore the outputs of the remote execution
    you performed in the *Scaling the training process with compute clusters* section.
    This will give you insights into how the AzureML platform works and help you troubleshoot
    potential errors you will be facing while developing your training scripts.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你将探索在*使用计算集群扩展训练过程*部分中执行的远程执行输出。这将帮助你深入了解AzureML平台的工作原理，并帮助你排查在开发训练脚本时可能遇到的潜在错误。
- en: 'Open the link you printed in the previous section using the `get_portal_url`
    method or navigate to the `greet-packt` Experiment, and open **Run 1**. Navigate
    to the **Outputs + logs** tab of the run:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`get_portal_url`方法打开你在前一部分中打印的链接，或者导航到`greet-packt`实验并打开**Run 1**。进入该运行的**Outputs
    + logs**标签页：
- en: '![Figure 8.14 – Outputs + logs tab of an Experiment''s run'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.14 – 实验运行的Outputs + logs标签页'
- en: '](img/B16777_08_014.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_014.jpg)'
- en: Figure 8.14 – Outputs + logs tab of an Experiment's run
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.14 – 实验运行的Outputs + logs标签页
- en: These outputs are very helpful in troubleshooting potential script errors. The
    `azureml-logs` folder contains the platform logs. Most of those files are logs
    from the underlying engine. The log that contains the standard output from your
    script is `70_driver_log.txt`. This is the log file you will need to look at first
    to troubleshoot a potential script execution failure. If you have multiple processes,
    you will see multiple files with a numeric suffix such as `70_driver_log_x.txt`.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这些输出对于排查潜在的脚本错误非常有帮助。`azureml-logs`文件夹包含平台日志。这些文件大部分是底层引擎的日志。包含你脚本标准输出的日志是`70_driver_log.txt`。这是你需要首先查看的日志文件，用于排查潜在的脚本执行失败。如果你有多个进程，你会看到多个带有数字后缀的文件，如`70_driver_log_x.txt`。
- en: The `logs` folder is a special folder you can use in your scripts to output
    logs. Everything that the script writes in that folder will automatically be uploaded
    to the run's `outputs` folder you saw in the *Tracking metrics in Experiments*
    section. AzureML also outputs system logs in that folder under the `azureml` folder
    you see in *Figure 8.14*.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`logs`文件夹是你可以在脚本中使用的特殊文件夹，用于输出日志。脚本写入该文件夹的所有内容会自动上传到你在*实验中跟踪指标*部分中看到的运行`outputs`文件夹。AzureML还会在该文件夹下的`azureml`文件夹中输出系统日志，如*图8.14*所示。'
- en: 'Navigate to the `ScriptRunConfig`. This directory can contain up to 300 MB
    and up to 2,000 files. If you need more script files, you can use a datastore.
    If you edited the script file in the `.py` script and a `.amltmp` file, which
    is a temporary file used by the notebook editor:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到`ScriptRunConfig`。该目录可以包含最多300MB的内容和最多2,000个文件。如果需要更多脚本文件，你可以使用数据存储。如果你在`.py`脚本中编辑了脚本文件以及一个`.amltmp`文件，这是由笔记本编辑器使用的临时文件：
- en: '![Figure 8.15 – Temporary file uploaded in the snapshot'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.15 – 临时文件上传至快照中'
- en: '](img/B16777_08_015.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_015.jpg)'
- en: Figure 8.15 – Temporary file uploaded in the snapshot
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.15 – 临时文件上传至快照中
- en: 'To avoid creating snapshots of unwanted files, you can add a `.gitignore` or
    `.amlignore` file in the folder next to the script and exclude files that follow
    a specific pattern. Navigate to the `.amlignore` file in the `greeter-job` folder,
    if the file is not already added when you created the folder, as seen in *Figure
    8.16*:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免创建不需要的文件快照，你可以在脚本旁边的文件夹中添加`.gitignore`或`.amlignore`文件，并排除符合特定模式的文件。导航到`greeter-job`文件夹中的`.amlignore`文件，如果在创建文件夹时尚未添加该文件，如*图8.16*所示：
- en: '![Figure 8.16 – Adding the .amlignore file to exclude temp files from being
    added to the snapshot'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.16 – 添加`.amlignore`文件以排除临时文件被添加到快照中'
- en: '](img/B16777_08_016.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_016.jpg)'
- en: Figure 8.16 – Adding the .amlignore file to exclude temp files from being added
    to the snapshot
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.16 – 添加`.amlignore`文件以排除临时文件被添加到快照中
- en: 'Open the `.amlignore` file and add the following lines in it to exclude all
    files with a .a `mltmp` file extension and the `.amlignore` file that you are
    editing:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 打开`.amlignore`文件，并在其中添加以下行，以排除所有具有`.amltmp`文件扩展名的文件以及你正在编辑的`.amlignore`文件：
- en: '[PRE18]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Open the `chapter08.ipynb` notebook, add a cell, and add the following code
    to resubmit the script:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 打开`chapter08.ipynb`笔记本，添加一个单元，并添加以下代码以重新提交脚本：
- en: '[PRE19]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: You are resubmitting the existing instance of the `ScriptRunConfig` you created
    in the previous step. If you restarted the `exp` and `script` variables once more.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你正在重新提交之前步骤中创建的`ScriptRunConfig`的现有实例。如果你再次重启`exp`和`script`变量。
- en: This time, you are using the `RunDetails` widget provided by the AzureML SDK.
    This is a **Jupyter** **Notebook** widget used to view the progress of a script
    execution. This widget is asynchronous and provides updates until the run finishes.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，你正在使用AzureML SDK提供的`RunDetails`小部件。这是一个**Jupyter** **Notebook**小部件，用于查看脚本执行的进度。这个小部件是异步的，会在运行完成前不断更新。
- en: 'If you want to print the run status, including the contents of the log files,
    you can use the following code snippet:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想打印运行状态，包括日志文件的内容，可以使用以下代码片段：
- en: '[PRE20]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Once the run completes, navigate to the **Snapshot** tab of that run. You will
    notice that the temp files are gone.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦运行完成，导航到该运行的**Snapshot**标签页。你会注意到临时文件已经消失。
- en: 'Notice that the execution of this run took significantly less time to complete.
    Navigate to the run''s log. Notice that the `20_image_build_log.txt` file did
    not appear in the logs this time, as seen in *Figure 8.17*:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这次运行的执行时间显著减少。导航到运行的日志。注意，这次日志中没有出现`20_image_build_log.txt`文件，如*图8.17*所示：
- en: '![Figure 8.17 – Faster run execution and missing the 20_image_build_log.txt
    file'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.17 – 更快的运行执行和缺失的20_image_build_log.txt文件'
- en: '](img/B16777_08_017.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_017.jpg)'
- en: Figure 8.17 – Faster run execution and missing the 20_image_build_log.txt file
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.17 – 更快的运行执行和缺失的20_image_build_log.txt文件
- en: This is the **Docker** image-building log for the environment used to execute
    the scripts. This is a very time-consuming process. These images are built and
    stored in the container registry that got deployed with your AzureML workspace.
    Since you didn't modify the execution environment, AzureML reused the previously
    created image in the follow-up run. In the next section, you will understand better
    what an environment is and how you can modify it.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于执行脚本的环境的**Docker**镜像构建日志。这个过程非常耗时。这些镜像被构建并存储在与您的AzureML工作区一起部署的容器注册表中。由于你没有修改执行环境，AzureML在后续的运行中重新使用了之前创建的镜像。在接下来的部分，你将更好地理解什么是环境以及如何修改它。
- en: Understanding execution environments
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解执行环境
- en: 'In the AzureML workspace terminology, an **Environment** means a list of software
    requirements needed for your scripts to execute. These software requirements include
    the following:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在AzureML工作区的术语中，**环境**意味着执行脚本所需的软件要求列表。这些软件要求包括以下内容：
- en: The Python packages that your code requires to be installed
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的代码需要安装的Python包
- en: The environment variables that may be needed from your code
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能需要的环境变量
- en: Various pieces of auxiliary software, such as GPU drivers or the **Spark** engine,
    that may be required for your code to operate properly
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可能需要的各种辅助软件，如 GPU 驱动程序或 **Spark** 引擎，以确保你的代码能够正常运行。
- en: Environments are *managed* and *versioned* entities that enable reproducible,
    auditable, and portable ML workflows across different compute targets.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 环境是*管理*和*版本化*的实体，它们可以在不同的计算目标之间实现可重复、可审计和可移植的机器学习工作流。
- en: AzureML provides a list of `AzureML-Minimal` curated environment contains just
    the minimal Python package requirements to enable run tracking you saw in the
    *Tracking model evolution* section. The `AzureML-AutoML` environment, on the other
    hand, is a much bigger curated environment and provides the required Python packages
    for your scripts to be able to run an AutoML Experiment.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: AzureML 提供了一个 `AzureML-Minimal` 精选环境列表，包含仅用于启用运行跟踪所需的最小 Python 包，你在*跟踪模型演变*部分看到过。另一方面，`AzureML-AutoML`
    环境是一个更大的精选环境，提供了运行 AutoML 实验所需的 Python 包。
- en: Important note
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: AzureML services are constantly being updated, and old environments are deprecated
    in favor of newer ones. Even if the `AzureML-Minimal` and `AzureML-AutoML` environments
    are not visible in the web interface of AzureML Studio, they should be available
    for you to use. If you encounter any errors, please download the latest code from
    the GitHub repository of this chapter.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: AzureML 服务正在不断更新，旧的环境已经被淘汰，取而代之的是更新的环境。即使在 AzureML Studio 的网页界面中看不到 `AzureML-Minimal`
    和 `AzureML-AutoML` 环境，它们仍然可以供你使用。如果遇到任何错误，请从本章的 GitHub 仓库下载最新的代码。
- en: 'In *Figure 8.18*, you can see how many additional packages are available with
    the `AzureML-AutoML` environment compared to the minimalistic `AzureML-Minimal`
    one:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 8.18*中，你可以看到与简化版的 `AzureML-Minimal` 环境相比，`AzureML-AutoML` 环境提供了多少额外的软件包：
- en: '![Figure 8.18 – Python package difference between the AzureML-Minimal and'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.18 - AzureML-Minimal 和 AzureML-AutoML 环境之间的 Python 包差异'
- en: AzureML-AutoML environments
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: AzureML-AutoML 环境
- en: '](img/B16777_08_018.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_018.jpg)'
- en: Figure 8.18 – Python package difference between the AzureML-Minimal and AzureML-AutoML
    environments
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.18 - AzureML-Minimal 和 AzureML-AutoML 环境之间的 Python 包差异
- en: '*Figure 8.18* shows the `Conda` environment definition for the `AzureML-Minimal`
    environment *version 46* versus the `AzureML-AutoML` environment *version 61*.
    `Conda` takes this YAML file and installs Python *version 3.6.2* and the `pip`
    requirements listed beneath the `- pip:` notation. As you can notice, all `pip`
    packages have specific versions defined using the `==x.x.x` notation. This means
    that the same Python packages will be installed every time you use this YAML file,
    something that helps maintain a stable environment for the repeatability of your
    Experiments.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 8.18* 显示了 `AzureML-Minimal` 环境 *版本 46* 与 `AzureML-AutoML` 环境 *版本 61* 的 `Conda`
    环境定义。`Conda` 使用这个 YAML 文件来安装 Python *版本 3.6.2* 和在 `- pip:` 标记下列出的 `pip` 依赖包。如你所见，所有
    `pip` 包都定义了特定的版本，使用 `==x.x.x` 的标记。这意味着每次使用该 YAML 文件时，都会安装相同的 Python 包，这有助于保持稳定的环境，从而确保实验的可重复性。'
- en: Installing the packages when you create an environment is a time-consuming process.
    This is where the Docker technology you saw in the previous section comes in handy.
    Docker is an open source project for automating the deployment of applications
    as portable, self-sufficient containers. This means that instead of creating a
    new environment every time you want to run a script, you can create a Docker container
    image, also referred to as a Docker image, where all Python dependencies are *baked
    in* the image once. You can reuse the image from that point on to start a container
    and execute your scripts. In fact, all the AzureML-curated environments are available
    as Docker images in the `viennaglobal.azurecr.io` container registry.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 创建环境时安装软件包是一个耗时的过程。这时你在前一部分看到的 Docker 技术就派上用场了。Docker 是一个开源项目，旨在自动化将应用程序部署为便携式、自给自足的容器。这意味着，与你每次想要运行脚本时都创建一个新环境不同，你可以创建一个
    Docker 容器镜像，也称为 Docker 镜像，在这个镜像中，所有的 Python 依赖都*已经内嵌*到镜像中。此后，你可以重复使用该镜像来启动容器并执行脚本。事实上，所有
    AzureML 精选环境都可以作为 Docker 镜像，在 `viennaglobal.azurecr.io` 容器注册表中找到。
- en: Important note
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Although it is common to create Docker images for your environments, it is not
    always required. If you are running the Experiments on your local computer or
    locally on the AzureML compute instance, you can use an existing `Conda` environment
    and avoid using a Docker image. If you are planning to use a remote compute, for
    example, an AzureML compute cluster, a Docker image is required because otherwise,
    you cannot ensure that the provisioned machine will have all the software components
    needed by your code to execute.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管创建 Docker 镜像用于环境的配置是常见的做法，但并非总是必需的。如果你在本地计算机或 AzureML 计算实例上运行实验，你可以使用现有的 `Conda`
    环境，而无需使用 Docker 镜像。如果你打算使用远程计算，例如 AzureML 计算集群，则需要使用 Docker 镜像，因为否则你无法确保所提供的机器会具备你的代码执行所需的所有软件组件。
- en: To better understand what you have read so far, you will rerun the previous
    `greeter.py` script using the `AzureML-Minimal` environmen:.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解到目前为止你所阅读的内容，你将重新运行之前的 `greeter.py` 脚本，并使用 `AzureML-Minimal` 环境：
- en: 'In your notebook, add a new cell and add the following code:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的笔记本中，添加一个新单元并加入以下代码：
- en: '[PRE21]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This code retrieves the `AzureML-Minimal` environment, defined in the AzureML
    workspace referenced by the `ws` variable, which was initialized earlier in the
    notebook. Then, it prints the name and the version of the environment and the
    `Conda` environment YAML definition you saw in *Figure 8.18*.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码检索了 `AzureML-Minimal` 环境，该环境在之前在笔记本中初始化的 `ws` 变量所引用的 AzureML 工作区中定义。然后，它打印环境的名称和版本，以及你在
    *图 8.18* 中看到的 `Conda` 环境 YAML 定义。
- en: 'Add a new cell and type the following:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个新单元，并输入以下内容：
- en: '[PRE22]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Observe the output of the run''s execution. If you look closer, you will see
    the following line:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 查看运行执行的输出。如果你仔细观察，你将看到以下这一行：
- en: '[PRE23]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This line is part of the `55_azureml-execution-something.txt` file in `azureml-logs`.
    The line informs you that it is pulling a Docker image from the `viennaglobal`
    container registry, which **Microsoft** owns. In contrast to that, in the previous
    section, in the run where you didn''t specify a curated environment, the image
    was pulled from your own container registry – the one provisioned with your AzureML
    workspace, as seen in *Figure 8.19*:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这一行是 `azureml-logs` 中 `55_azureml-execution-something.txt` 文件的一部分。该行告知你它正在从
    **Microsoft** 所拥有的 `viennaglobal` 容器注册表中拉取 Docker 镜像。与此相对，上一节中，在没有指定策划环境的运行中，镜像是从你自己的容器注册表中拉取的——即与你的
    AzureML 工作区关联的容器注册表，如 *图 8.19* 所示：
- en: '![Figure 8.19 – Image pulled from your own container registry'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.19 – 从你自己的容器注册表中拉取的镜像'
- en: in the execution without using a curated environment
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有使用策划环境的情况下执行
- en: '](img/B16777_08_019.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_019.jpg)'
- en: Figure 8.19 – Image pulled from your own container registry in the execution
    without using a curated environment
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.19 – 在没有使用策划环境的情况下，从你自己的容器注册表中拉取的镜像
- en: This observation brings us to the next type of AzureML-supported environment,
    the system-managed one – something you will explore in the next section.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这个观察结果引出了下一个类型的 AzureML 支持的环境——系统管理环境——你将在下一节中进行探索。
- en: Defining a system-managed environment
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义系统管理环境
- en: 'S`Conda` environment definition or a simple `pip` `requirements.txt` file.
    In the previous section, where you didn''t define the `environment` argument in
    the `ScriptRunConfig` constructor, a default `Conda` environment definition file
    was used to create the system-managed environment that was stored in your **Azure**
    **Container Registry** associated with your AzureML workspace. Let''s explicitly
    create a system-managed environment to use with your code:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`Conda` 环境定义或简单的 `pip` `requirements.txt` 文件。在上一节中，你没有在 `ScriptRunConfig` 构造函数中定义
    `environment` 参数，因此使用了默认的 `Conda` 环境定义文件来创建存储在与 AzureML 工作区关联的 **Azure** **容器注册表**
    中的系统管理环境。现在，让我们显式地创建一个系统管理环境来与代码一起使用：'
- en: Navigate to the **Notebooks** section of your AzureML workspace and the **Files**
    tree view.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到你 AzureML 工作区的 **笔记本** 部分以及 **文件** 树视图。
- en: Click on the three dots of the `greeter-job` folder to open the context menu
    (or just right-click on the name) and select the `greeter-banner-job`, as seen
    in the following screenshot:![](img/B16777_08_020.jpg)
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `greeter-job` 文件夹的三个点以打开上下文菜单（或者直接右击文件夹名称），然后选择 `greeter-banner-job`，如下面的截图所示：![](img/B16777_08_020.jpg)
- en: Figure 8.20 – Duplicating the greeter-job folder as a new one named greeter-banner-job
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.20 – 将 greeter-job 文件夹复制为一个名为 greeter-banner-job 的新文件夹
- en: 'Open the `greeter.py` file in the new folder and change the code to the following:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开新文件夹中的 `greeter.py` 文件，并将代码更改为以下内容：
- en: '[PRE24]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `asciistuff` package is a pip package that you will need to install in
    your executing environment for your code to work. To define that code dependency,
    you are going to create a `Conda` environment definition file. In the `chapter08`
    folder, add a new file named `greeter-banner-job.yml`. Add the following content
    to it:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`asciistuff` 包是一个 `pip` 包，你需要在执行环境中安装它，以确保代码能够正常运行。为了定义这个代码依赖，你将创建一个 `Conda`
    环境定义文件。在 `chapter08` 文件夹中，添加一个名为 `greeter-banner-job.yml` 的新文件，并在其中添加以下内容：'
- en: '[PRE25]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This YAML file defines a new `Conda` environment named `banner-env`, which is
    based on Python *version 3.6.2* and installs the *1.2.1* version of the `pip`
    package, `asciistuff`.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个 YAML 文件定义了一个新的 `Conda` 环境，名为 `banner-env`，该环境基于 Python *版本 3.6.2*，并安装了 `asciistuff`
    的 *1.2.1* 版本的 `pip` 包。
- en: 'To create an AzureML environment based on the `Conda` environment you just
    defined, you need to go to the `chapter08.ipynb` notebook, add a cell, and type
    the following code:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 若要基于你刚定义的 `Conda` 环境创建一个 AzureML 环境，你需要进入 `chapter08.ipynb` 笔记本，添加一个单元格，并输入以下代码：
- en: '[PRE26]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This code snippet creates an AzureML environment named `banner-env` using the
    `from_conda_specification()` method of the `Environment` class. The `banner_env`
    variable contains the newly defined environment. In the follow-up line, you define
    the `GREET_HEADER` environment variable, and you assign the `Env. var. header:`
    value. This environment is not registered in the workspace, and it doesn't need
    to be registered in order to use it. If you do want to save it in the workspace
    to be able to reference it in the same way you reference the curated environments
    and you want to keep versions of it, you can use the `register()` method, using
    the `banner_env.register(ws)` code where you pass as an argument a variable that
    points to the workspace where the Environment will be registered.
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码创建了一个名为 `banner-env` 的 AzureML 环境，使用了 `Environment` 类的 `from_conda_specification()`
    方法。`banner_env` 变量包含了新定义的环境。在随后的代码行中，你定义了 `GREET_HEADER` 环境变量，并为其赋值为 `Env. var.
    header:`。该环境未在工作区中注册，使用时不需要注册。如果你确实想要将它保存到工作区，以便像引用策划环境一样引用它，并希望保持版本记录，可以使用 `register()`
    方法，使用 `banner_env.register(ws)` 代码，其中你传入一个指向工作区的变量，该工作区将是该环境的注册位置。
- en: Important note
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要说明
- en: If you plan to start working on your local computer and then scale out on more
    powerful compute clusters, you should consider creating and registering a system-managed
    environment that includes all your required Python packages. This will allow you
    to reuse it in both local and remote executions.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你计划先在本地计算机上工作，然后再扩展到更强大的计算集群上，你应考虑创建并注册一个系统管理的环境，包含你所需的所有 Python 包。这样，你可以在本地和远程执行时都重复使用它。
- en: 'To use this newly defined environment, add a new cell in the notebook and type
    the following code:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 若要使用这个新定义的环境，请在笔记本中添加一个新单元格，并输入以下代码：
- en: '[PRE27]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output of this Experiment should look like the one depicted in *Figure
    8.21*:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 该实验的输出应与 *图 8.21* 中所示相似：
- en: '![Figure 8.21 – Header text read from an environment variable and banner-based
    hello greeting'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.21 – 从环境变量读取的头部文本和基于横幅的问候语'
- en: '](img/B16777_08_021.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_021.jpg)'
- en: Figure 8.21 – Header text read from an environment variable and banner-based
    hello greeting
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.21 – 从环境变量读取的头部文本和基于横幅的问候语
- en: As you noticed, in the system-managed environment you just created, you didn't
    specify anything about the base operating system (for example, whetherit's `Conda`
    is already installed in the base system. You just specified the `Conda` dependencies
    that got installed. If you want even bigger flexibility, you can explicitly configure
    the environment and install all your software requirements manually. These environments
    are referred to as **user-managed** environments. Most often, these user-managed
    environments are custom-made Docker images that encapsulate all the required dependencies.
    For example, you may need a custom build of the PyTorch framework or even a custom
    build version of Python. In these cases, you are responsible for installing the
    Python packages and configuring the entire environment. For the purposes of this
    book, you will be working with either curated or system-managed environments.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你注意到的，在你刚刚创建的系统管理环境中，你没有指定任何关于基础操作系统的信息（例如，是否已在基础系统中安装了`Conda`）。你只是指定了已安装的`Conda`依赖项。如果你想要更大的灵活性，你可以显式配置环境并手动安装所有的软件要求。这些环境被称为**用户管理**环境。通常，这些用户管理环境是自定义的
    Docker 镜像，封装了所有必需的依赖项。例如，你可能需要 PyTorch 框架的自定义构建，或者甚至是 Python 的自定义构建版本。在这些情况下，你需要负责安装
    Python 包并配置整个环境。在本书中，你将使用经过精心策划或由系统管理的环境。
- en: So far, you have explored how to execute a simple greeter Python application
    on a remote compute. In the next section, you will resume your `diabetes` model
    training and see how you can train that model on a remote compute cluster.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经探索了如何在远程计算机上执行一个简单的问候程序 Python 应用。在接下来的部分，你将继续训练你的`diabetes`模型，并了解如何在远程计算集群上训练该模型。
- en: Training the diabetes model on a compute cluster
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在计算集群上训练糖尿病模型
- en: 'In the previous section, you learned how you can run a script on a remote compute
    cluster by calling the `exp.submit(script)` method from within a notebook, as
    seen in *Figure 8.22*:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，你了解了如何通过在笔记本中调用`exp.submit(script)`方法在远程计算集群上运行脚本，如*图8.22*所示：
- en: '![Figure 8.22 – Executing a script on a compute cluster'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.22 – 在计算集群上执行脚本'
- en: '](img/B16777_08_022.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_022.jpg)'
- en: Figure 8.22 – Executing a script on a compute cluster
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.22 – 在计算集群上执行脚本
- en: 'When you called the `submit` method, the following actions happened behind
    the scenes:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 当你调用`submit`方法时，后台发生了以下操作：
- en: The AzureML SDK made a `ScriptRunConfig` execution.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AzureML SDK 执行了一个 `ScriptRunConfig`。
- en: The AzureML workspace checked whether a Docker image of the `Environment` already
    exists. If it didn't exist, it was created within Azure Container Registry.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AzureML 工作区检查是否已经存在`Environment`的 Docker 镜像。如果没有，它会在 Azure 容器注册表中创建。
- en: 'The job is submitted to the compute cluster, which scales up to allocate a
    compute node. The following operations are performed within the newly allocated
    compute node:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任务被提交到计算集群，集群会扩展以分配一个计算节点。在新分配的计算节点中执行以下操作：
- en: The Docker image with the Environment is pulled to the compute node.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 带有环境的 Docker 镜像被拉取到计算节点上。
- en: The script referenced by `ScriptRunConfig` is loaded in the running Docker instance.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由`ScriptRunConfig`引用的脚本被加载到正在运行的 Docker 实例中。
- en: Metrics and metadata are stored in the AzureML workspace.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指标和元数据存储在 AzureML 工作区中。
- en: Outputs are stored back in the storage account.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出将存储回存储帐户。
- en: 'In the *Training a simple sklearn model with notebooks* section, you created
    a training script within the `chapter08.ipynb` notebook. The training was happening
    within the Jupyter server''s process, inside your compute instance. To run the
    same training in a compute cluster, you will need to do the following:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在*使用笔记本训练简单的 sklearn 模型*部分中，你在 `chapter08.ipynb` 笔记本中创建了一个训练脚本。训练发生在 Jupyter
    服务器的进程中，位于你的计算实例内部。要在计算集群上运行相同的训练，你需要执行以下操作：
- en: Move the code to a Python script file.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将代码移动到 Python 脚本文件中。
- en: Create an AzureML environment to run the training.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 AzureML 环境来运行训练。
- en: Submit `ScriptRunConfig` in an Experiment.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在实验中提交`ScriptRunConfig`。
- en: In the next sections, you will see how to transform the script you used in the
    *Tracking model evolution* section to be able to execute it on a remote compute
    cluster.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，你将看到如何将你在*跟踪模型演变*部分中使用的脚本转换，以便能够在远程计算集群上执行它。
- en: Moving the code to a Python script file
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将代码移动到 Python 脚本文件中
- en: If you look at the script you created in the *Tracking model evolution* section,
    in the code that was doing the training, you used the `run` variable to log metrics.
    This variable was referencing the `Run` object you got when you called `exp.start_logging()`.
    In the previous section, you learned about `ScriptRunConfig`, which you submitted
    in an Experiment and returned an instance of the `Run` class. This instance is
    created within the notebook of the compute instance. How will the script file
    that is executing on a remote cluster get access to the same `Run` object?
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看你在*跟踪模型演变*部分创建的脚本，在进行训练的代码中，你使用了`run`变量来记录指标。这个变量引用了你在调用`exp.start_logging()`时获得的`Run`对象。在前一部分中，你了解了`ScriptRunConfig`，它在Experiment中提交并返回了一个`Run`类的实例。这个实例是在计算实例的笔记本中创建的。那么，如何让执行在远程集群上的脚本文件访问相同的`Run`对象呢？
- en: 'AzureML''s `Run` class provides a method called `get_context()`, which returns
    the current service execution context. In the case of `ScriptRunConfig`, this
    execution context is the same `Run` that was created when you called `exp.submit(script)`:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: AzureML的`Run`类提供了一个叫做`get_context()`的方法，它返回当前服务执行上下文。对于`ScriptRunConfig`，这个执行上下文就是在调用`exp.submit(script)`时创建的相同`Run`对象：
- en: '[PRE28]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Further to the `run` variable, in the training script, you had the `ws` variable,
    which was a reference to the AzureML workspace. You used that variable to get
    access to the `diabetes` dataset. You got a reference to the workspace by calling
    the `from_config` method. The issue with this approach is that the first time
    you called that method, you needed to manually authenticate and authorize the
    compute to access the workspace on your behalf. This will not be feasible to do
    on the remote compute.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`run`变量，在训练脚本中，你还使用了`ws`变量，它是指向AzureML工作区的引用。你使用该变量来访问`diabetes`数据集。你通过调用`from_config`方法来获取工作区的引用。这个方法的问题在于，当你第一次调用时，你需要手动进行身份验证并授权计算资源代表你访问工作区。这样的方法在远程计算环境中是不可行的。
- en: 'The `run` variable gives you access to the corresponding workspace by navigating
    in the Experiment attribute and then to the workspace attribute of that Experiment:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '`run`变量通过在Experiment属性中导航，再到该Experiment的工作区属性，为你提供了访问对应工作区的方式：'
- en: '[PRE29]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'There is one caveat for these lines of code, though. Your code assumes that
    the Python script was submitted through `ScriptRunConfig`. If you run the Python
    script locally in a terminal, using the following command line, you will get an
    error:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些代码行有一个警告。你的代码假设Python脚本是通过`ScriptRunConfig`提交的。如果你在终端本地运行Python脚本，使用以下命令行，你将会遇到错误：
- en: '[PRE30]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The `get_context()` method will return an object of the `_OfflineRun` class,
    which inherits from the `Run` class. This class provides all logging capabilities
    you saw in the *Tracking metrics in Experiments* section, but instead of uploading
    the metrics or the artifacts to the workspace, it just prints out the attempt
    in the terminal. Obviously, there is no Experiment associated with that run and
    this is going to cause the script to throw an error. Thus, you need to retrieve
    the workspace reference using the `from_config()` method you have been using so
    far. Since the terminal is part of the compute instance, the script will execute
    passing your credentials and will not prompt you to authenticate, as you will
    see later in this section. If you run this code on your local computer, you will
    need to authenticate your device, as you saw in the *Authenticating from your
    device* section of [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102),
    *The AzureML Python SDK*.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_context()`方法将返回一个`_OfflineRun`类的对象，该类继承自`Run`类。这个类提供了你在*实验中跟踪指标*部分看到的所有日志功能，但它并不会将指标或工件上传到工作区，而是直接在终端中打印尝试结果。显然，这个`run`没有关联任何Experiment，这会导致脚本抛出错误。因此，你需要使用你一直在使用的`from_config()`方法来检索工作区引用。由于终端是计算实例的一部分，脚本将在不提示身份验证的情况下执行，并且会传递你的凭据，正如你稍后在本节中看到的那样。如果你在本地计算机上运行这段代码，你将需要进行设备身份验证，正如你在[*第7章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)的*从设备进行身份验证*部分中所看到的，*AzureML
    Python SDK*。'
- en: 'The complete code that allows you to run both offline in a terminal and submitted
    in a compute cluster is the following:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 允许你在终端离线运行并在计算集群中提交的完整代码如下：
- en: '[PRE31]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: These are the only changes you will need to make to your script to submit it
    for remote execution and take advantage of the AzureML SDK capabilities.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这些就是你需要对脚本做出的唯一修改，目的是为了提交到远程执行并利用AzureML SDK的功能。
- en: Important note
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Python developers commonly use an `_` as a prefix for classes, attributes, or
    methods that they want to mark as internal. This means that the marked code is
    for consumption by classes within the `SDK` library and shouldn't be used by external
    developers. The marked code may change in the future without any warning. It is
    considered a bad practice to use classes that start with the `_` prefix. Nonetheless,
    the `_OfflineRun` class is extensively used in the public samples of the AzureML
    SDK and is safe to use.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: Python开发者通常会在他们想标记为内部的类、属性或方法前加一个`_`前缀。这意味着标记的代码是供`SDK`库中的类使用，外部开发者不应该使用这些代码。标记的代码可能在未来发生变化而不会提前通知。通常不推荐使用以`_`开头的类，然而，`_OfflineRun`类在AzureML
    SDK的公共示例中被广泛使用，使用它是安全的。
- en: 'Let''s make those changes in your workspace. In the file tree, create a folder
    under `chapter08` named `diabetes-training` and add a `training.py` file in there,
    as seen in *Figure 8.23*:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在工作区中进行这些更改。在文件树中，在`chapter08`下创建一个名为`diabetes-training`的文件夹，并在其中添加一个`training.py`文件，正如*图
    8.23*所示：
- en: '![Figure 8.23 – Creating the training script for the remote diabetes model
    training'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.23 – 为远程糖尿病模型训练创建训练脚本'
- en: '](img/B16777_08_023.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_023.jpg)'
- en: Figure 8.23 – Creating the training script for the remote diabetes model training
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.23 – 为远程糖尿病模型训练创建训练脚本
- en: 'Add the following code blocks in the `training.py` script. Instead of typing
    all this code, you can download it directly from the GitHub repository mentioned
    in the *Technical requirements* section of this chapter:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在`training.py`脚本中添加以下代码块。你可以直接从本章*技术要求*部分提到的GitHub仓库中下载这些代码，而不需要手动输入：
- en: '[PRE32]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'These are all the imports you will need within the script file. It is a good
    practice to have all your `import` statements on the top of your script files
    to easily discover the required modules needed for your code to execute properly.
    If you use `flake8` to lint your code base, it will complain if you don''t follow
    this best practice:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是脚本文件中所需的所有导入。将所有`import`语句放在脚本文件顶部是一种良好的编程习惯，这样可以方便地发现代码执行所需的模块。如果你使用`flake8`来检查代码，它会提醒你如果没有遵循这一最佳实践：
- en: '[PRE33]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This script file expects an `--alpha` parameter to be passed to it. In this
    code block, this parameter is parsed using the `argparse` module you saw in the
    *Scaling the training process with compute clusters* section, and the `float`
    value is assigned to the `args.alpha` variable, as it is specified in the `dest`
    argument. The `parse_args` method will throw an error if you pass non-defined
    arguments to the script. Some people prefer using `args, unknown_args = parser.parse_known_args()`
    instead of the fourth line of this code block, which allows the script to execute
    even if it receives more than the expected arguments, assigning the unknown ones
    in the `unknown_args` variable:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本文件需要传入`--alpha`参数。在这个代码块中，使用你在*使用计算集群扩展训练过程*部分看到的`argparse`模块解析这个参数，并将`float`类型的值赋给`args.alpha`变量，正如在`dest`参数中指定的那样。如果你传递了未定义的参数给脚本，`parse_args`方法将会抛出错误。有些人更喜欢使用`args,
    unknown_args = parser.parse_known_args()`，代替代码块的第四行，这样即使脚本收到比预期更多的参数，也能执行，并将未知参数赋值给`unknown_args`变量：
- en: '[PRE34]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In this code block, you get a reference to the `Run` object and the `Workspace`
    using the snippet you saw at the beginning of this section. Once you get the reference
    to the `Workspace`, you can load the `diabetes` dataset, as seen in the next script
    block:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码块中，你通过开头部分看到的代码片段获取到`Run`对象和`Workspace`的引用。一旦获得`Workspace`的引用，你就可以加载`diabetes`数据集，正如下一个脚本块所示：
- en: '[PRE35]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'In this block, you get a reference to the `diabetes` dataset and split it to
    the required `X_train`, `y_train`, `X_validate`, and `y_validate` pandas DataFrames
    you saw in the *Training a simple sklearn model within notebooks* section of this
    chapter. Note that you specify the `seed` parameter in the `random_split` method.
    This `seed` parameter is used to initialize the state of the underlying random
    function used by the `split` method to randomly select the rows from the dataset.
    By doing that, the random function will generate the same random numbers every
    time it is invoked. This means that `training_data` and `validation_data` will
    be the same every time you run the script. Having the same training and validation
    dataset will assist in properly comparing multiple executions of the same script
    with different `alpha` parameters:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码块中，您获得 `diabetes` 数据集的引用，并将其拆分为所需的 `X_train`、`y_train`、`X_validate` 和 `y_validate`
    pandas 数据框，这些数据框您在本章的 *在笔记本中训练简单的 sklearn 模型* 部分中看到过。请注意，您在 `random_split` 方法中指定了
    `seed` 参数。这个 `seed` 参数用于初始化 `split` 方法背后使用的随机函数的状态，以便从数据集中随机选择行。这样，每次调用该随机函数时，它都会生成相同的随机数。这意味着
    `training_data` 和 `validation_data` 每次运行脚本时都会保持一致。拥有相同的训练和验证数据集有助于正确比较在不同 `alpha`
    参数下执行相同脚本的多次结果：
- en: '[PRE36]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'In this code block, you define the `train_and_evaluate` method, which is the
    same one used in the *Tracking model evolution* section of this chapter:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码块中，您定义了 `train_and_evaluate` 方法，这与本章 *追踪模型演变* 部分中使用的方法相同：
- en: '[PRE37]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'After the method definition, you invoke the training process passing all the
    required arguments:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义方法后，您调用训练过程并传递所有必需的参数：
- en: '[PRE38]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The last code block stores the model in the `outputs` folder next to the script's
    location.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个代码块将模型存储在 `outputs` 文件夹中，该文件夹位于脚本的同一位置。
- en: 'You can run the script on your local compute instance, and you will notice
    that the model trains as expected and the metrics are logged in the terminal,
    as seen in *Figure 8.24*. This is the expected behavior of the `_OfflineRun` class
    you read about before:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本地计算实例上运行脚本，您会注意到模型按预期进行训练，指标会记录在终端中，如 *图 8.24* 所示。这是您之前阅读过的 `_OfflineRun`
    类的预期行为：
- en: '![Figure 8.24 – Running the training script locally'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.24 – 在本地运行训练脚本'
- en: '](img/B16777_08_024.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_024.jpg)'
- en: Figure 8.24 – Running the training script locally
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.24 – 在本地运行训练脚本
- en: So far, you have created the training script. In the next section, you will
    create the AzureML environment that will contain all the required dependencies
    to execute that script on a remote compute.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经创建了训练脚本。在下一部分中，您将创建 AzureML 环境，该环境将包含执行该脚本所需的所有依赖项，以便在远程计算上运行。
- en: Creating the AzureML environment to run the training script
  id: totrans-302
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建用于运行训练脚本的 AzureML 环境
- en: 'The training script you created in the *Tracking model evolution* section uses
    the `scikit-learn` library, also known as `sklearn`. The Jupyter kernel that you
    are using in the notebook experience already has the `sklearn` library installed.
    To see the version that is currently installed in your kernel, go to the `chapter08.ipynb`
    notebook and add the following code snippet in a new cell:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在*追踪模型演变*部分中创建的训练脚本使用了 `scikit-learn` 库，也称为 `sklearn`。您在笔记本体验中使用的 Jupyter 内核已经安装了
    `sklearn` 库。要查看当前在内核中安装的版本，请转到 `chapter08.ipynb` 笔记本，并在新的单元格中添加以下代码片段：
- en: '[PRE39]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This command will use Python''s `pip` package manager to show the details of
    the currently installed `scikit-learn` package, as seen in *Figure 8.25*:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将使用 Python 的 `pip` 包管理器显示当前安装的 `scikit-learn` 包的详细信息，如 *图 8.25* 所示：
- en: '![Figure 8.25 – Package information for the installed scikit-learn library'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.25 – 安装的 scikit-learn 库的包信息'
- en: '](img/B16777_08_025.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_025.jpg)'
- en: Figure 8.25 – Package information for the installed scikit-learn library
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.25 – 安装的 scikit-learn 库的包信息
- en: Important note
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you are unsure of the library name, you can use the `pip freeze` command
    to get a full list of installed packages in the current Python environment.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不确定库的名称，可以使用 `pip freeze` 命令来获取当前 Python 环境中已安装包的完整列表。
- en: 'You can also find the version of the installed library within a Python script
    using the `sklearn.__version__` attribute (note the two underscores). In a new
    notebook cell, add the following lines of Python code:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过在 Python 脚本中使用 `sklearn.__version__` 属性（注意两个下划线）来查找已安装库的版本。在新的笔记本单元格中，添加以下
    Python 代码行：
- en: '[PRE40]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: You should be able to see exactly the same version printed in the output. Most
    of the Python SDKs and libraries have this `__version__` attribute, such as the
    PyTorch and the TensorFlow frameworks.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够在输出中看到完全相同的版本。大多数Python SDK和库都有这个`__version__`属性，比如PyTorch和TensorFlow框架。
- en: 'There are two ways to install the `scikit-learn` package; as a `Conda` package
    or as a `pip` package. `Conda` offers a curated list of Python packages, and it
    is the recommended approach. In the *Understanding execution environments* section,
    you saw how to create an environment using a `Conda` specification file. In this
    section, you will learn a different approach where you create the environment
    within the Python code. Add a new cell in the `chapter08.ipynb` notebook and type
    the following:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以安装`scikit-learn`包：作为`Conda`包或作为`pip`包。`Conda`提供了一个精选的Python包列表，并且这是推荐的方式。在*理解执行环境*部分，你看到了如何使用`Conda`规范文件创建环境。在本部分，你将学习一种不同的方法，在Python代码中创建环境。在`chapter08.ipynb`笔记本中添加一个新单元格，并输入以下内容：
- en: '[PRE41]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In the preceding code snippet, you create a new system-managed environment
    and then use `add_conda_package` to add the specific version of `scikit-learn`.
    You also use `add_pip_package` to add the `azureml-dataprep[pandas]` package,
    which is required in order to use the `to_pandas_dataframe` method within the
    `training.py` script. You could have added additional pip packages such as the
    `asciistuff` package you installed before. Instead of adding one package at a
    time using the `add_pip_package` method, you can use the `create` method of the
    `CondaDependencies` class, as seen in the following snippet:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，你创建了一个新的系统管理环境，然后使用`add_conda_package`添加了特定版本的`scikit-learn`。你还使用`add_pip_package`添加了`azureml-dataprep[pandas]`包，这是为了在`training.py`脚本中使用`to_pandas_dataframe`方法所必需的。你本可以像之前安装的`asciistuff`包一样，添加其他的pip包。你可以通过使用`CondaDependencies`类的`create`方法来一次性添加多个包，如下面的代码片段所示：
- en: '[PRE42]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: You can request for multiple packages to be present in the environment by adding
    them in the `conda_packages` and `pip_packages` arrays. Note that since you do
    not append packages to the default `CondaDependencies`, you need to manually include
    the `azureml-defaults` package needed for the `training.py` script to access the
    `azureml.core` module.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过将包添加到`conda_packages`和`pip_packages`数组中来要求环境中包含多个包。请注意，由于你没有将包附加到默认的`CondaDependencies`中，因此需要手动添加`azureml-defaults`包，以便`training.py`脚本能够访问`azureml.core`模块。
- en: 'You may be wondering why we haven''t defined `joblib` in the Python dependencies.
    The `scikit-learn` package depends on the `joblib` package, and it will automatically
    be installed in the environment. If you want, you can explicitly specify it in
    the list of dependencies with the following code:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，为什么我们没有在Python依赖项中定义`joblib`。`scikit-learn`包依赖于`joblib`包，它会自动安装在环境中。如果你愿意，可以通过以下代码显式地在依赖项列表中指定它：
- en: '[PRE43]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Important note
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Although it is not mandatory to specify the version of the packages you want
    to add to the environment, it is a good practice. If you wrote `add_conda_package("scikit-learn")`,
    skipping to specify the version of the package, AzureML would assume you are referring
    to the latest version. The first time you would have used the environment in AzureML,
    the Docker image would have been created, installing whatever was the newest version
    of the `scikit-learn` package at the time of the Docker image creation. That version
    may have been more recent than the one you used to create your script, and it
    may be incompatible with the code you wrote. Although minor version differences
    may not affect your code, major versions may introduce breaking changes, as was
    done when TensorFlow moved from *version 1* to *2*.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然不是强制要求指定你要添加到环境中的包的版本，但这是一个好的做法。如果你写了`add_conda_package("scikit-learn")`，没有指定包的版本，AzureML会假定你指的是最新版本。当你第一次在AzureML中使用环境时，Docker镜像会被创建，安装当时最新版本的`scikit-learn`包。那个版本可能比你用于创建脚本的版本更新，且可能与您编写的代码不兼容。虽然次要版本的差异可能不会影响你的代码，但主要版本的变化可能会引入破坏性更改，就像TensorFlow从*版本1*升级到*版本2*时所做的那样。
- en: If you don't want to create a new environment with your code dependencies, you
    can use one of the AzureML-curated environments. You can select either the highly
    specialized GPU-based `AzureML-Scikit-learn0.24-Cuda11-OpenMpi4.1.0-py36` environment
    or you can use the more generic `AzureML-Tutorial` curated environment, which
    contains the most used data science libraries such as `scikit-learn`, `MLflow`,
    and `matplotlib`.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不想创建一个包含代码依赖的全新环境，可以使用其中一个由AzureML精心策划的环境。你可以选择高度专业化的基于GPU的`AzureML-Scikit-learn0.24-Cuda11-OpenMpi4.1.0-py36`环境，或者使用更通用的`AzureML-Tutorial`策划环境，该环境包含了如`scikit-learn`、`MLflow`和`matplotlib`等最常用的数据科学库。
- en: So far, you have written the training script and you defined the AzureML environment
    with the required `sklearn` library. In the next section, you are going to kick
    off the training on a compute cluster.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经编写了训练脚本并定义了包含所需`sklearn`库的AzureML环境。在下一节中，你将启动计算集群上的训练。
- en: Submitting ScriptRunConfig in an Experiment
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Experiment中提交`ScriptRunConfig`
- en: 'Once you have the script and the AzureML environment definition, you can submit
    `ScriptRunConfig` to execute on the remote compute cluster. In a new cell in the
    `chapter08.ipynb` notebook, add the following code:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了脚本和AzureML环境定义，你就可以提交`ScriptRunConfig`以在远程计算集群上执行。在`chapter08.ipynb`笔记本的新单元中，添加以下代码：
- en: '[PRE44]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This code is the same one used to submit the `greeter.py` scripts in the previous
    sections. You get a reference to the AzureML workspace and the compute cluster
    where you will execute the job. You define a `ScriptRunConfig` object where you
    define the location of the script to execute, the environment you defined in the
    previous section, and the target compute. You also pass the `alpha` argument to
    the script. In the last bit of code, you create an Experiment and submit `ScriptRunConfig`
    to execute.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码与之前章节中提交`greeter.py`脚本的代码相同。你获得了对AzureML工作区和你将要执行作业的计算集群的引用。你定义了一个`ScriptRunConfig`对象，在其中定义了要执行的脚本位置、你在前一节中定义的环境和目标计算资源。你还将`alpha`参数传递给了脚本。在代码的最后一部分，你创建了一个Experiment并提交了`ScriptRunConfig`以执行。
- en: With this piece of code, you triggered the flow you saw in *Figure 8.22* in
    the *Training the diabetes model on a compute cluster* section earlier in the
    chapter.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这段代码，你触发了本章中*第8.22图*的流程，该流程出现在*在计算集群上训练糖尿病模型*一节中。
- en: 'Once the training is complete, you will be able to navigate to the Experiment,
    select the run`,` and observe the collected metrics from the training process,
    as seen in *Figure 8.26*:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，你就可以进入Experiment，选择运行任务，并查看从训练过程中收集的指标，如*第8.26图*所示：
- en: '![Figure 8.26 – Logged metrics from a script running on a remote compute cluster'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.26 – 来自远程计算集群上运行脚本的记录指标'
- en: '](img/B16777_08_026.jpg)'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_08_026.jpg)'
- en: Figure 8.26 – Logged metrics from a script running on a remote compute cluster
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.26 – 来自远程计算集群上运行脚本的记录指标
- en: So far, you have managed to execute the `diabetes` model training script in
    a single node on a remote compute cluster, and you have logged the metrics and
    the trained model in the AzureML Experiment's run.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经成功地在远程计算集群的单个节点上执行了`diabetes`模型训练脚本，并且已经在AzureML Experiment的运行记录中记录了指标和训练后的模型。
- en: In the next section, you will discover different ways to scale out your computational
    efforts and take advantage of more than a single node on the compute cluster.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将发现不同的方式来扩展你的计算工作，并充分利用计算集群中不止一个节点。
- en: Utilizing more than a single compute node during model training
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在模型训练过程中利用多个计算节点
- en: 'As you saw in the *Compute clusters* section of [*Chapter 4*](B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053),
    *Configuring the Workspace*, a cluster can scale from 0 compute nodes to as many
    as you like. There are a couple of reasons why you would need more than a single
    node in a cluster during the model training phase. They are as follows:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[*第4章*](B16777_04_Final_VK_ePub.xhtml#_idTextAnchor053)的*配置工作区*部分看到的那样，集群可以从0个计算节点扩展到你需要的任意数量。你需要在模型训练阶段使用多个节点而不仅仅是一个节点的原因有几个，具体如下：
- en: '**Parallel execution of unrelated model training instances**: When you are
    working in a team, it is common to have multiple Experiments running in parallel.
    Each job can run on a single node, as you did in the previous section.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不相关的模型训练实例的并行执行**：当你在团队中工作时，通常会有多个Experiment并行运行。每个作业可以在单个节点上运行，就像你在前一节中所做的那样。'
- en: '**Parallel training of a single model, also known as distributed training**:
    This is an advanced scenario where you are using frameworks such as the **Apache**
    **Horovod** distributed deep learning training framework that PyTorch and TensorFlow
    use. There are two types of distributed training options:'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单一模型的并行训练，也称为分布式训练**：这是一个高级场景，您正在使用如**Apache** **Horovod**的分布式深度学习训练框架，该框架被PyTorch和TensorFlow所使用。分布式训练有两种类型：'
- en: '**Data parallelism**: Where the training data is split into partitions equal
    to the amount of compute nodes you have. Each node performs a training batch of
    the model against the assigned data, and then all nodes synchronize the updated
    model parameters before moving to the next batch.'
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据并行性**：将训练数据分割成与计算节点数量相等的分区。每个节点对分配的数据执行一批模型训练，然后所有节点在进入下一批之前同步更新的模型参数。'
- en: '**Model parallelism**: Where you are training bits of the model on different
    compute nodes. Each node is responsible for training only a small segment of the
    entire model, and the synchronization between nodes occurs every time a propagation
    step is needed.'
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型并行性**：在不同的计算节点上训练模型的不同部分。每个节点只负责训练整个模型的一小段，并且在每次需要传播步骤时，节点之间会进行同步。'
- en: '`alpha` parameter of the `LassoLars` model you trained in the previous section.
    You may want to explore multiple values for those parameters to select the model
    that performs best on the training dataset. This is a process called hyperparameter
    tuning, and you will learn more about it in [*Chapter 9*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136),
    *Optimizing the ML Model*.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您在前一节中训练的`LassoLars`模型的`alpha`参数。您可能希望探索这些参数的多个值，以选择在训练数据集上表现最好的模型。这是一个称为超参数调优的过程，您将在[*第9章*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136)中了解更多关于它的内容，*优化ML模型*。
- en: '**Parallel training of multiple models to select the best alternative**: This
    is the AutoML process you already discovered in [*Chapter 5*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072),
    *Letting the Machines Do the Model Training*. You will also see this method again
    in [*Chapter 9*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136), *Optimizing
    the ML Model,* in the *Running AutoML Experiments with code* section.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行训练多个模型以选择最佳备选方案**：这是您在[*第5章*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072)中已经发现的AutoML过程，*让机器做模型训练*。您还将在[*第9章*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136)中再次看到这种方法，*优化ML模型*，在*使用代码运行AutoML实验*部分。'
- en: In this section, you learned about different approaches to utilize multiple
    nodes in a compute cluster. You will deep dive into the last two methods in [*Chapter
    9*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136), *Optimizing the ML Model*.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您学习了利用计算集群中多个节点的不同方法。您将在[*第9章*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136)中深入探讨最后两种方法，*优化ML模型*。
- en: Summary
  id: totrans-345
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you got an overview of the various ways you can create an ML
    model in the AzureML workspace. You started with a simple regression model that
    was trained within the Jupyter notebook's kernel process. You learned how you
    can keep track of the metrics from the models you train. Then, you scaled the
    training process into the `cpu-sm-cluster` compute cluster you created in [*Chapter
    7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102), *The AzureML Python SDK*.
    While scaling out to a remote compute cluster, you learned what the AzureML environments
    are and how you can troubleshoot remote executions by looking at the logs.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您概览了在AzureML工作区中创建ML模型的各种方式。您从一个简单的回归模型开始，该模型在Jupyter notebook的内核进程中进行训练。您学习了如何跟踪您训练的模型的指标。然后，您将训练过程扩展到在[*第7章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)中创建的`cpu-sm-cluster`计算集群中，*AzureML
    Python SDK*。在扩展到远程计算集群时，您了解了AzureML环境是什么，以及如何通过查看日志来排除远程执行的问题。
- en: In the next chapter, you will build on this knowledge and use multiple computer
    nodes to perform a parallelized *hyperparameter tuning* process, which will locate
    the best parameters for your model. You will also learn how you can completely
    automate the model selection, training, and tuning using the AutoML capabilities
    of the AzureML SDK.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将基于这些知识，使用多个计算节点执行并行的*超参数调优*过程，从而找到适合您模型的最佳参数。您还将学习如何使用AzureML SDK的AutoML功能，完全自动化模型选择、训练和调优。
- en: Questions
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: In each chapter, you will find a couple of questions to check your understanding
    of the topics discussed:.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一章中，您会发现几个问题来检查您对讨论主题的理解：
- en: You want to log the number of validation rows you will use within a script.
    Which method of the `Run` class will you use?
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你想记录你将在脚本中使用的验证行数。你将使用`Run`类中的哪个方法？
- en: a. `log_table`
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. `log_table`
- en: b. `log_row`
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. `log_row`
- en: c. `log`
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. `log`
- en: You want to run a Python script that utilizes `scikit-learn`. How would you
    configure the AzureML environment?
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你想运行一个使用`scikit-learn`的 Python 脚本。你将如何配置 AzureML 环境？
- en: a. Add the `scikit-learn Conda dependency.`
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 添加 `scikit-learn Conda 依赖项。`
- en: b. Add the `sklearn Conda dependency.`
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 添加 `sklearn Conda 依赖项。`
- en: c. Use the AzureML `Azure-Minimal` environment, which already contains the needed
    dependencies.
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用 AzureML 的`Azure-Minimal`环境，该环境已经包含所需的依赖项。
- en: You need to use `MLflow` to track the metrics generated in an Experiment and
    store them in your AzureML workspace. Which two pip packages do you need to have
    in your Conda environment?
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要使用 `MLflow` 跟踪实验中生成的指标，并将其存储在你的 AzureML 工作区中。你需要在 Conda 环境中安装哪两个 pip 包？
- en: a. `mlflow`
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. `mlflow`
- en: b. `azureml-mlflow`
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. `azureml-mlflow`
- en: c. `sklearn`
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. `sklearn`
- en: d. `logger`
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. `logger`
- en: 'You need to use `MLflow` to track the value `0.1` for the `training_rate` metric.
    Which of the following code achieves this requirement? Assume all classes are
    correctly imported at the top of the script:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要使用 `MLflow` 来跟踪 `training_rate` 指标的值 `0.1`。以下哪段代码可以实现此要求？假设所有类已在脚本顶部正确导入：
- en: a. `mlflow.log_metric('training_rate', 0.1)`
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. `mlflow.log_metric('training_rate', 0.1)`
- en: b. `run.log('training_rate', 0.1)`
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. `run.log('training_rate', 0.1)`
- en: c. `logger.log('training_rate', 0.1)`
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. `logger.log('training_rate', 0.1)`
- en: Further reading
  id: totrans-367
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'This section offers a list of web resources to help you augment your knowledge
    of the AzureML SDK and the various code snippets used in this chapter:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了一些网络资源列表，帮助你扩展对 AzureML SDK 和本章中使用的各种代码片段的知识：
- en: 'Source of the diabetes dataset: [https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html)'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 糖尿病数据集来源：[https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html)
- en: '*LassoLars* model documentation on *scikit-learn* website: [https://scikit-learn.org/stable/modules/linear_model.html#lars-lasso](https://scikit-learn.org/stable/modules/linear_model.html#lars-lasso)'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*LassoLars* 模型文档，位于 *scikit-learn* 网站：[https://scikit-learn.org/stable/modules/linear_model.html#lars-lasso](https://scikit-learn.org/stable/modules/linear_model.html#lars-lasso)'
- en: 'The *plotly* open source graphing library: [https://github.com/plotly/plotly.py](https://github.com/plotly/plotly.py)'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*plotly*开源图形库：[https://github.com/plotly/plotly.py](https://github.com/plotly/plotly.py)'
- en: 'MLflow Tracking API reference: [https://mlflow.org/docs/latest/quickstart.html#using-the-tracking-api](https://mlflow.org/docs/latest/quickstart.html#using-the-tracking-api)'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow 跟踪 API 参考：[https://mlflow.org/docs/latest/quickstart.html#using-the-tracking-api](https://mlflow.org/docs/latest/quickstart.html#using-the-tracking-api)
- en: 'Syntax for the `.amlignore` and .`gitignore` files: [https://git-scm.com/docs/gitignore](https://git-scm.com/docs/gitignore)'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.amlignore` 和 `.gitignore` 文件的语法：[https://git-scm.com/docs/gitignore](https://git-scm.com/docs/gitignore)'
- en: '**Flake8** for code linting: [https://flake8.pycqa.org](https://flake8.pycqa.org)'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Flake8** 用于代码检查：[https://flake8.pycqa.org](https://flake8.pycqa.org)'
