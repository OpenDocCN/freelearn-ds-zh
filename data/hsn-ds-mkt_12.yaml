- en: Predicting the Likelihood of Marketing Engagement
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测营销互动的可能性
- en: In this chapter, we are going to expand the knowledge we gained from the previous
    chapter and the customer analytics exercise we conducted in [Chapter 7](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml),
    *Exploratory Analysis for Customer Behavior*. For successful and more intelligent
    marketing strategies, we cannot stop at analyzing customer data. With the advanced
    technology in data science and machine learning, we can now make intelligent guesses
    and estimates on customers' future behaviors, such as what types of customers
    are more likely to engage with marketing efforts, the amount of purchases that
    customers are likely to make, or which customers are likely to churn. These predictions
    or intelligent guesses that are built based on historical customer data can help
    you improve your marketing performance and further tailor your marketing strategies
    for different target audiences. In this chapter, we are going to learn how we
    can utilize data science and machine learning to predict future outcomes and how
    this can help your future marketing efforts.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将扩展上一章的知识以及我们在[第7章](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml)中进行的客户分析练习，*客户行为的探索性分析*。为了实现更成功、更智能的营销策略，我们不能仅仅停留在分析客户数据这一层面。借助数据科学和机器学习的先进技术，我们现在可以对客户的未来行为做出智能的猜测和估计，例如哪些类型的客户更可能参与营销活动，客户可能购买多少商品，或者哪些客户可能会流失。这些基于历史客户数据建立的预测或智能猜测可以帮助你提升营销表现，并进一步为不同目标受众量身定制营销策略。在本章中，我们将学习如何利用数据科学和机器学习来预测未来的结果，以及这些预测如何帮助你的未来营销工作。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Predictive analytics in marketing
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 营销中的预测分析
- en: Evaluating classification models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估分类模型
- en: Predicting the likelihood of marketing engagement with Python
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python预测营销互动的可能性
- en: Predicting the likelihood of marketing engagement with R
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用R预测营销互动的可能性
- en: Predictive analytics in marketing
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 营销中的预测分析
- en: '**Predictive analytics** is a process of analyzing and extracting information
    from historical data to identify patterns and make predictions about future outcomes.
    Numerous statistical and machine learning models are typically used to find the
    relationship between the attributes or features in the dataset and the target
    variable or behavior that you would like to predict. Predictive analytics can
    be utilized and applied in many different industries.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测分析**是一个分析并从历史数据中提取信息的过程，旨在识别模式并对未来结果做出预测。通常会使用大量的统计和机器学习模型，找出数据集中属性或特征与目标变量或行为之间的关系。这些预测分析可以在许多不同行业中得到应用。'
- en: For example, it is often used in the financial industry for fraud detection,
    where machine learning models are trained to detect and prevent potential fraudulent
    transactions. The healthcare industry can also benefit from predictive analytics
    to help physicians in their decision-making processes. Furthermore, there are
    various parts of marketing that can also benefit from predictive analytics, such
    as customer acquisition, customer retention, and up-selling and cross-selling,
    to name a few.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，它常常被用于金融行业的欺诈检测，其中机器学习模型被训练来检测和防止潜在的欺诈交易。医疗行业也可以从预测分析中受益，帮助医生做出决策。此外，营销的各个方面也能从预测分析中获益，例如客户获取、客户保持以及追加销售和交叉销售等。
- en: 'In predictive analytics, broadly speaking, there are two types of problems:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测分析中，广义上讲，存在两种类型的问题：
- en: '**Classification problems**: A classification problem is where there is a set
    of categories an observation can belong to. For example, predicting whether a
    customer is going to open a marketing email or not is a classification problem.
    There are only two possible outcomes—opening the marketing email or not opening
    the email.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类问题**：分类问题是指观察值可以属于一组类别。例如，预测客户是否会打开一封营销邮件就是一个分类问题。只有两种可能的结果——打开营销邮件或不打开邮件。'
- en: '**Regression problems**: A regression problem, on the other hand, is where
    the outcome can take on any range of real numbers. For example, predicting customer
    lifetime value is a regression problem. One customer can have a lifetime value
    of $0 and another customer can have a lifetime value of $10,000\. This type of
    problem, where the outcome can take continuous values, is called a regression
    problem.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归问题**：另一方面，回归问题是指结果可以取任何实数范围的情况。例如，预测客户终身价值就是一个回归问题。一个客户的终身价值可能是 $0，而另一个客户的终身价值可能是
    $10,000。这种结果可以取连续值的问题，称为回归问题。'
- en: In this chapter, we are going to focus on one of the common classification problems
    in the marketing industry—predicting the likelihood of customer engagement. In
    the following chapter, [Chapter 9](9b3d36ba-d690-491c-9a6f-b8c00f59cfb4.xhtml),
    *Customer Lifetime Value*, we are going to tackle one of the frequently appearing
    regression problems within the marketing industry.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点讨论营销行业中常见的分类问题之一——预测客户参与的可能性。在下一章，[第九章](9b3d36ba-d690-491c-9a6f-b8c00f59cfb4.xhtml)，*客户终身价值*，我们将探讨营销行业中经常出现的回归问题。
- en: Applications of predictive analytics in marketing
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测分析在营销中的应用
- en: 'As briefly mentioned previously, there are numerous ways of applying and utilizing
    predictive analytics in marketing. In this section, we are going to discuss four
    popular use cases of predictive analytics in marketing:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，预测分析在营销中的应用方式多种多样。本节中，我们将讨论预测分析在营销中的四个常见应用案例：
- en: '**Likelihood of engagement**: Predictive analytics can help marketers forecast
    the likelihood of customer engagements with their marketing strategies. For example,
    if your marketing happens a lot in the email space, you can utilize predictive
    analytics to forecast which customers have a high likelihood of opening your marketing
    emails and custom-tailor your marketing strategies to those high-likelihood customers
    to maximize your marketing results. For another example, if you are displaying
    advertisements on social media, predictive analytics can help you identify certain
    types of customers that are likely to click on the ads.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户参与的可能性**：预测分析可以帮助营销人员预测客户与他们的营销策略互动的可能性。例如，如果你的营销活动主要通过电子邮件进行，你可以利用预测分析来预测哪些客户有较高的可能性打开你的营销邮件，并根据这些高可能性客户定制营销策略，从而最大化营销效果。再举一个例子，如果你在社交媒体上展示广告，预测分析可以帮助你识别那些可能点击广告的客户类型。'
- en: '**Customer lifetime value**: Predictive analytics can help you forecast the
    expected lifetime values of your customers. Using historical transactional data,
    predictive analytics can help you identify high-value customers within your customer
    base. With these predictions, you and your firm can focus more on building healthy
    relationships with those high-value customers. We are going to discuss in more detail
    how to build predictive models for customer lifetime value forecasts in the following
    chapter.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户终身价值**：预测分析可以帮助你预测客户的预期终身价值。通过历史交易数据，预测分析可以帮助你识别客户群体中的高价值客户。通过这些预测，你和你的公司可以更加专注于与这些高价值客户建立良好的关系。我们将在下一章中更详细地讨论如何为客户终身价值预测构建预测模型。'
- en: '**Recommending the right products and contents**: As we have already discussed
    in [Chapter 6](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml), *Recommending the
    Right Products*, we can use data science and machine learning to predict which
    customers are likely to purchase products or view contents. Using these predictions,
    you can improve customer conversion rates by recommending the right products and
    contents for individual customers.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推荐正确的产品和内容**：正如我们在[第六章](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml)，*推荐正确的产品*中所讨论的那样，我们可以利用数据科学和机器学习来预测哪些客户可能购买产品或查看内容。通过这些预测，你可以通过向个人客户推荐合适的产品和内容来提高客户转化率。'
- en: '**Customer acquisition and retention**: Predictive analytics has also been
    heavily used for customer acquisition and retention. Based on the profile data
    you gathered about your prospects or leads and the historical data of your existing
    customers, you can apply predictive analytics to identify high-quality leads or
    rank the leads by their likelihood of being converted into active customers. On
    the other hand, you can use the customer churn data and the historical data of
    your existing customers to develop predictive models to forecast which customers
    are likely to leave or unsubscribe from your products. We are going to discuss
    in more detail applying predictive analytics for customer retention in [Chapter
    11](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml), *Retaining Customers*.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户获取与保持**：预测分析也在客户获取和保持方面得到了广泛应用。根据你收集的潜在客户资料和现有客户的历史数据，你可以应用预测分析来识别高质量的潜在客户，或者根据潜在客户转化为活跃客户的可能性对其进行排名。另一方面，你可以使用客户流失数据以及现有客户的历史数据，开发预测模型来预测哪些客户可能会流失或取消订阅你的产品。我们将在[第11章](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml)《客户保持》中详细讨论如何将预测分析应用于客户保持，*保持客户*。'
- en: On top of these four common use cases of predictive analytics in marketing,
    there are many other ways you can utilize predictive analytics for your marketing
    strategies. You should get creative on how and where to use predictive analytics
    for your future marketing strategies.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这四种常见的市场营销预测分析应用外，还有许多其他方法可以将预测分析应用于你的营销策略。你应该发挥创意，思考如何以及在哪些方面将预测分析运用于未来的营销策略。
- en: Evaluating classification models
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估分类模型
- en: 'When developing predictive models, it is important to know how to evaluate
    those models. In this section, we are going to discuss five different ways to
    evaluate the performance of classification models. The first metric that can be
    used to measure prediction performance is **accuracy**. Accuracy is simply the
    percentage of correct predictions out of all predictions, as shown in the following
    formula:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发预测模型时，了解如何评估这些模型非常重要。在本节中，我们将讨论五种评估分类模型性能的不同方法。第一个可用于衡量预测性能的指标是**准确度**。准确度就是所有预测中正确预测的百分比，如下所示的公式所示：
- en: '![](img/84ed1d1c-4cfa-42b1-bbc9-378337f43d0a.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84ed1d1c-4cfa-42b1-bbc9-378337f43d0a.png)'
- en: 'The second metric that is commonly used for classification problems is **precision**.
    Precision is defined as the number of true positives divided by the total number
    of true positives and false positives. True positives are cases where the model
    correctly predicted as positive, while false positives are cases where the model
    was predicted as positive, but the true label was negative. The formula looks
    as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个常用于分类问题的指标是**精确度**。精确度定义为真正例的数量除以真正例和假正例的总数。真正例是指模型正确预测为正的情况，而假正例是指模型预测为正，但真实标签为负的情况。公式如下所示：
- en: '![](img/ae4af65b-cc35-401a-938e-d5da51b56c4d.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ae4af65b-cc35-401a-938e-d5da51b56c4d.png)'
- en: 'Along with precision, **recall** is also commonly used to evaluate the performances
    of classification models. Recall is defined as the number of true positives divided
    by the number of true positives plus false negatives. False negatives are cases
    where the model was predicted as negative, but the true label was positive. Recall
    can be thought of as a measure of how much of the positive cases are retrieved
    or found by the model. The formula looks as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 除了精确度，**召回率**也是评估分类模型性能的常用指标。召回率定义为真正例的数量除以真正例加上假负例的数量。假负例是指模型预测为负，但真实标签为正的情况。召回率可以看作是模型找回或发现正例的程度。公式如下所示：
- en: '![](img/7aef9390-c65f-4cf2-91f2-2c2f5a1d4a58.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7aef9390-c65f-4cf2-91f2-2c2f5a1d4a58.png)'
- en: 'The final two metrics we are going to discuss are the **receiver operating
    characteristic** (**ROC**) curve and the **area under the curve** (**AUC**). The
    ROC curve shows how true positive rates and false positive rates change at different
    thresholds. The AUC is simply the total area under the ROC curve. The AUC ranges
    from 0 to 1 and a higher AUC number suggests better model performance. A random
    classifier has an AUC of 0.5, so any classifier with an AUC higher than 0.5 suggests
    that the model performs better than random predictions. A typical ROC curve looks
    as in the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要讨论的最后两个指标是**接收者操作特征**（**ROC**）曲线和**曲线下面积**（**AUC**）。ROC 曲线展示了在不同阈值下，真正率和假正率的变化。AUC
    只是 ROC 曲线下的总面积。AUC 的值范围从 0 到 1，AUC 数值越高，表示模型性能越好。随机分类器的 AUC 值为 0.5，因此任何 AUC 高于
    0.5 的分类器都表明该模型的表现优于随机预测。典型的 ROC 曲线如下所示：
- en: '![](img/8b7e03bd-8eec-49a7-8c05-138ca8798c0a.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b7e03bd-8eec-49a7-8c05-138ca8798c0a.png)'
- en: In the following programming exercise, we are going to use these five metrics
    that we have just discussed to evaluate the performance of the model we build
    in Python and R. Let's now dive into building machine learning models to predict
    the likelihood of marketing engagement!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的编程练习中，我们将使用我们刚刚讨论的这五个指标来评估我们在 Python 和 R 中构建的模型的性能。现在让我们开始构建机器学习模型，以预测市场营销参与的可能性！
- en: Predicting the likelihood of marketing engagement with Python
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 预测市场营销参与的可能性
- en: In this section, we are going to discuss how to build predictive models using
    machine learning algorithms in Python. More specifically, we will learn how to
    build a predictive model using the random forest algorithm, as well as how to
    tune the random forest model and evaluate the performance of the model. We will
    be mainly using the `pandas`, `matplotlib`, and `scikit-learn` packages to analyze,
    visualize, and build machine learning models that predict the likelihood of customer
    marketing engagement. For those readers who would like to use R instead of Python
    for this exercise, you can skip to the next section.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论如何使用 Python 中的机器学习算法构建预测模型。更具体地，我们将学习如何使用随机森林算法构建预测模型，以及如何调整随机森林模型并评估模型性能。我们将主要使用
    `pandas`、`matplotlib` 和 `scikit-learn` 包来分析、可视化和构建预测客户市场营销参与可能性的机器学习模型。对于那些希望使用
    R 而非 Python 进行本次练习的读者，可以跳到下一节。
- en: 'For this exercise, we will be using one of the publicly available datasets
    from IBM, which can be found at this link: [https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/).
    You can follow this link and download the data that is available in CSV format,
    named `WA_Fn UseC_ Marketing Customer Value Analysis.csv`. Once you have downloaded
    this data, you can load it into your Jupyter notebook by running the following
    command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将使用 IBM 提供的一个公开数据集，您可以通过以下链接找到该数据集：[https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/)。您可以访问此链接并下载以
    CSV 格式提供的数据，文件名为 `WA_Fn UseC_ Marketing Customer Value Analysis.csv`。下载数据后，您可以通过运行以下命令将其加载到您的
    Jupyter notebook 中：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `df` DataFrame looks as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`df` 数据框如下所示：'
- en: '![](img/63a2f76d-29f3-443a-a327-34ab8b596ffd.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/63a2f76d-29f3-443a-a327-34ab8b596ffd.png)'
- en: As you might have noticed, this is the same dataset that we used in the previous
    chapter, where we conducted customer analytics. With the knowledge we gained about
    this dataset from the previous chapter, we are going to first prepare our data
    by encoding the target variable and other categorical variables that we are going
    to use as features for our machine learning models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这是我们在上一章中使用的相同数据集，当时我们进行了客户分析。通过上一章所学到的关于该数据集的知识，我们将首先通过对目标变量和其他将用作机器学习模型特征的分类变量进行编码来准备我们的数据。
- en: Variable encoding
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量编码
- en: In order to build machine learning models using the `scikit-learn` package in
    Python, all the features in the dataset need to have numerical values. However,
    in the dataset, we have numerous columns that have non-numerical values. For example,
    the target variable, `Response`, which is what we are going to try to predict
    with machine learning models, is non-numeric. It contains two string values—`Yes`
    and `No`. We will need to encode this `Response` target variable with numerical
    values in order to be able to build machine learning models. For another example,
    the column `Gender`, which we can use as one of the features for our predictive
    model, also does not have numerical values. It contains two string values—`F`
    for female and `M` for male. In this section, we are going to discuss how we can
    encode these non-numeric columns so that we can use them as features for machine
    learning models.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用Python中的`scikit-learn`包构建机器学习模型，数据集中的所有特征必须具有数值型值。然而，在数据集中，我们有许多列具有非数值型值。例如，目标变量`Response`，我们将使用机器学习模型预测的内容，是非数值型的。它包含两个字符串值——`Yes`和`No`。为了能够构建机器学习模型，我们需要用数值型值对这个`Response`目标变量进行编码。再举一个例子，`Gender`列，我们可以将其作为预测模型的特征之一，也没有数值型值。它包含两个字符串值——`F`表示女性，`M`表示男性。在本节中，我们将讨论如何对这些非数值型列进行编码，以便可以将它们用作机器学习模型的特征。
- en: Response variable encoding
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应变量编码
- en: 'The first thing we are going to do is encode the response variable `Response`.
    We are going to encode `Yes` values with `1`s and `No` values with `0`s. Take
    a look at the following code:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的第一件事是对响应变量`Response`进行编码。我们将`Yes`值编码为`1`，`No`值编码为`0`。看看以下代码：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As you can see from this code, we are using the `apply` function of the `pandas`
    `DataFrame` to apply our `lambda` function on the `Response` column, so that it
    encodes `Yes` values with `1` and `No` values with `0`. We then store these encoded
    values in a newly-created column, `Engaged`. In order to get the overall response
    or engagement rate using this newly-created column, you can use the following
    code:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，从这段代码中，我们使用`pandas` `DataFrame`的`apply`函数来对`Response`列应用我们的`lambda`函数，以便将`Yes`值编码为`1`，将`No`值编码为`0`。然后，我们将这些编码后的值存储在新创建的列`Engaged`中。为了使用这个新创建的列来获取整体响应或参与率，你可以使用以下代码：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The overall engagement rate looks as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 整体参与率如下所示：
- en: '![](img/90aabaf8-3052-4f9f-a47f-57daf049fbe0.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/90aabaf8-3052-4f9f-a47f-57daf049fbe0.png)'
- en: Categorical variable encoding
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类变量编码
- en: 'If you look closely at the data, the following variables are categorical variables:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细观察数据，以下变量是分类变量：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: These variables have a set of different values they can take and those values
    do not necessarily have orders that differentiate one from another.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变量具有一组可以取值的不同值，而这些值之间不一定有区分顺序。
- en: 'If you recall from [Chapter 4](a9f09970-4826-46d0-8bfd-5796702c5629.xhtml),
    *From Engagement to Conversion*, there is more than one way to encode categorical
    variables. In this chapter, the method we are going to use is to create dummy
    variables for each category of individual categorical variables, using the `get_dummies`
    function in the `pandas` package. Take a look at the following code:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得[第4章](a9f09970-4826-46d0-8bfd-5796702c5629.xhtml)《从参与到转化》中提到的内容，*从参与到转化*，其实有不止一种方法可以对分类变量进行编码。在本章中，我们将使用的方法是为每个单独的分类变量类别创建虚拟变量，方法是使用`pandas`包中的`get_dummies`函数。看看以下代码：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As you can see from this code snippet, we are iterating through the list of
    column names of categorical variables, defined in `columns_to_encode`. Then, for
    each column, we are using the `get_dummies` function in the `pandas` package to
    build dummy variables. In order to make things clear and cause less confusion,
    we are renaming the columns of the newly-created and encoded `DataFrame` `encoded_df`,
    where each column contains information about the original column name and the
    category it represents. As an example, for the  `Sale Channel` column, the newly-created
    DataFrame `encoded_df` will look as in the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在这段代码片段中，我们正在遍历定义在`columns_to_encode`中的分类变量列名列表。然后，对于每一列，我们使用`pandas`包中的`get_dummies`函数来构建虚拟变量。为了使事情更清楚并减少混淆，我们正在重命名新创建的和编码过的`DataFrame`
    `encoded_df`中的列，其中每一列包含关于原始列名和它所表示的类别的信息。例如，对于`Sale Channel`列，新创建的`encoded_df`将如下所示：
- en: '![](img/cea74d25-63a1-4b68-b9be-1041261dea91.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cea74d25-63a1-4b68-b9be-1041261dea91.png)'
- en: As you can see from this example, each column of this new `DataFrame` represents
    each category in the original `Sales Channel` column and the values are one-hot
    encoded, meaning it assigns a value of `1` if the given record belongs to the
    given category, and `0` otherwise.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从这个例子中所见，新的`DataFrame`的每一列代表原始`Sales Channel`列中的每个类别，值是经过独热编码的，这意味着如果给定记录属于某个类别，则该列值为`1`，否则为`0`。
- en: Once we have created dummy variables for the given column, we then store the
    newly-created columns into a variable named `categorical_features`. Lastly, we
    concatenate this newly-created `DataFrame` to the original `DataFrame`, by using
    the `concat` function of the `pandas` package. One of the parameters in the concat
    function, `axis=1`, tells `pandas` to concatenate the two `DataFrames` by the
    column.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们为给定的列创建了虚拟变量，我们将把新创建的列存储到一个名为`categorical_features`的变量中。最后，我们使用`pandas`包的`concat`函数将这个新创建的`DataFrame`与原始的`DataFrame`进行拼接。`concat`函数的一个参数`axis=1`告诉`pandas`通过列来拼接这两个`DataFrame`。
- en: 'By now, we have successfully encoded all the categorical variables except `Gender`.
    Since we do not need to create two dummy variables for the `Gender` column, as
    there can only be two genders, we are going to create one variable that contains
    information about the gender of a given record. Take a look at the following code:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经成功编码了除了`Gender`之外的所有分类变量。由于`Gender`列只包含两种性别，因此我们不需要为该列创建两个虚拟变量。我们将创建一个包含给定记录性别信息的变量。请看下面的代码：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you can see from this code, we are creating a new column named `Is.Female`.
    We are using the apply function of the `pandas` `DataFrame` and encoding all females
    with the value of `1` and all males with the value of `0`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从这段代码中所见，我们正在创建一个名为`Is.Female`的新列。我们使用`pandas`的`DataFrame`的`apply`函数，将所有女性编码为`1`，所有男性编码为`0`。
- en: Building predictive models
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建预测模型
- en: 'We are almost ready to start building and training machine learning models
    to predict customer responses or engagements. There are a few things to clean
    up in our data. Take a look at the following code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎准备好开始构建和训练机器学习模型，以预测客户的响应或参与度了。在此之前，我们的数据还有一些需要清理的地方。请看下面的代码：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As you can see from this code, we are creating a new `DataFrame` `sample_df`,
    which contains all the features, `all_features`, and the response variable, `response`.
    Then, we are cleaning up the column and feature names by replacing all the spaces
    in the names with dots. After these cleanups, DataFrame `sample_df` now looks
    as in the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从这段代码中看到的，我们正在创建一个新的`DataFrame` `sample_df`，它包含了所有的特征`all_features`和响应变量`response`。然后，我们通过将列名和特征名中的所有空格替换为点号，来清理列名和特征名。经过这些清理后，`DataFrame`
    `sample_df`现在如下所示：
- en: '![](img/eb370c76-2e57-4457-a963-d7d7e9995c9f.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb370c76-2e57-4457-a963-d7d7e9995c9f.png)'
- en: 'Now that we have a sample set that we can train and test our machine learning
    models with, let''s split this sample set into two subsets—one for training the
    models and another for testing and evaluating the trained models. The Python machine
    learning package, `scikit-learn`, has a function that splits a given sample set
    into train and test sets. Take a look at the following code:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了一个可以用来训练和测试机器学习模型的样本集，接下来我们将把这个样本集分成两个子集——一个用于训练模型，另一个用于测试和评估训练好的模型。Python机器学习包`scikit-learn`有一个函数，可以将给定的样本集拆分成训练集和测试集。请看下面的代码：
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the `model_selection` module of the `scikit-learn` package, there is a function
    named `train_test_split`. This function takes the sample set and the desired breakdown
    between train and test set sizes as input parameters and returns train and test
    sets that are randomly split. As you can see from this code snippet, we are using
    `70%` of the sample set for training and the remaining `30%` for testing. The
    following shows the breakdowns of train and test sets from the sample set:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在`scikit-learn`包的`model_selection`模块中，有一个名为`train_test_split`的函数。这个函数接受样本集和所需的训练集和测试集大小的划分作为输入参数，并返回随机划分的训练集和测试集。从这段代码中可以看到，我们使用`70%`的样本集进行训练，剩下的`30%`用于测试。以下是样本集的训练集和测试集的划分情况：
- en: '![](img/b4bae11b-4c12-4301-a00b-a4d6616a5795.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b4bae11b-4c12-4301-a00b-a4d6616a5795.png)'
- en: As you can see here, there are a total of `9,134` records in `sample_df`, `6,393`
    records in `x_train`, and `2,741` records in `x_test`, meaning that roughly `70%`
    of the sample set went into the train set and the remaining `30%` of the sample
    set went into the test set. We will be using these train and test sets for building
    and evaluating models in the following sections.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`sample_df` 中共有 `9,134` 条记录，`x_train` 中有 `6,393` 条记录，`x_test` 中有 `2,741`
    条记录，这意味着大约 `70%` 的样本集用于训练集，剩余的 `30%` 样本集用于测试集。我们将在接下来的章节中使用这些训练集和测试集来构建和评估模型。
- en: Random forest model
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林模型
- en: 'With the data that we have prepared so far, we are going to build a predictive
    model, using a random forest algorithm, which predicts whether a customer is going
    to respond or engage with the marketing campaign. In Python''s `scikit-learn`
    package, the random forest algorithm is implemented in the `ensemble` module and
    you can import the random forest class using the following code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们目前准备好的数据，我们将构建一个预测模型，使用随机森林算法，预测客户是否会响应或参与市场营销活动。在 Python 的 `scikit-learn`
    包中，随机森林算法被实现于 `ensemble` 模块，您可以使用以下代码导入随机森林类：
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can create a random forest classifier using the following code:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下代码创建一个随机森林分类器：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: However, there are many hyperparameters you can tune for random forest models.
    Hyperparameters are the parameters you define before you train a machine learning
    model. For example, in the case of a random forest algorithm, you can define the
    number of trees you want in your random forest model. As another example, you
    can define the maximum depth of each tree in the forest, so that you can limit
    how big each tree in the forest can grow.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您可以调整许多超参数来优化随机森林模型。超参数是您在训练机器学习模型之前定义的参数。例如，在随机森林算法中，您可以定义您希望在随机森林模型中使用的树木数量。另一个例子是，您可以定义森林中每棵树的最大深度，从而限制每棵树的最大生长深度。
- en: 'There are numerous hyperparameters you can define in `scikit-learn`''s `RandomForestClassifier`
    class. We will take a look at the following few examples of hyperparameters:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `scikit-learn` 的 `RandomForestClassifier` 类中，您可以定义许多超参数。我们将查看以下几个超参数的例子：
- en: '`n_estimators`: This defines the number of trees you want to build in the forest.
    Generally speaking, more trees mean better performance results. However, the amount
    of performance gain for each additional tree decreases as the number of trees
    in the forest increases. Since having more trees in a forest means higher cost
    in computations for training additional trees, you should try to find the balance
    and stop adding trees when the computational cost from training additional trees
    outweighs the performance gain.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_estimators`：该参数定义了您希望在森林中构建的树木数量。一般来说，树木越多，性能表现越好。然而，随着森林中树木数量的增加，每增加一棵树带来的性能提升会逐渐减少。由于森林中树木的增加意味着训练额外树木的计算成本更高，您应该尝试找到平衡点，并在训练额外树木的计算成本超过性能提升时停止添加树木。'
- en: '`max_depth`: This parameter defines the maximum depth of individual trees.
    The larger the depth is, the more information your tree can capture from the train
    set, meaning larger trees learn the train set better than smaller trees. However,
    the larger the tree grows, the more likely it is going to overfit the train set.
    This means that the trained tree performs and predicts well within the train set,
    but predicts poorly in the dataset that it has not seen before. In order to avoid
    overfitting, we would want to limit the depth of the tree to a point where it
    does not overfit to the train set, but predicts the outcomes well enough.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_depth`：该参数定义了单棵树的最大深度。深度越大，树可以从训练集捕获的信息越多，这意味着较大的树比较小的树学习训练集的能力更强。然而，树的深度越大，它就越可能会过拟合训练集。这意味着训练好的树在训练集中的表现和预测很好，但在未见过的数据集上预测较差。为了避免过拟合，我们希望限制树的深度，确保它不会对训练集过拟合，同时能够足够好地预测结果。'
- en: '`min_samples_split`: This defines the minimum number of data points required
    to split a node of the tree. For example, if you defined `min_samples_split` to
    be `50`, but the node only has `40` records, then it will not split the node any
    further. On the other hand, if the node has more than the predefined minimum number
    of samples, then it will split the node into child nodes. Similar to the `max_depth`
    hyperparameter, this helps you manage the amount of overfitting happening in the
    tree.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_samples_split`：此参数定义了拆分树节点所需的最小数据点数量。例如，如果您将`min_samples_split`设置为`50`，但节点只有`40`个记录，那么该节点将不会进一步拆分。另一方面，如果节点的样本数超过预定义的最小值，那么它将拆分成子节点。类似于`max_depth`超参数，这有助于管理树中发生的过拟合程度。'
- en: '`max_features`: This defines the maximum number of features to be considered
    for splitting a node. This parameter creates the *randomness* in random forest
    models. Given the maximum number of features to be considered for a split, the
    random forest algorithm randomly chooses a subset of the features up to the maximum
    number and decides how to split a given node of a tree. This helps each tree of
    a random forest model to learn different information from the train set. When
    these trees that have learned the train set with slightly different set of features
    are bagged or ensembled all together, then the resulting forest will become more
    accurate and robust in its predictions.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_features`：此参数定义了拆分节点时考虑的最大特征数。这个参数在随机森林模型中创造了*随机性*。在考虑拆分节点的最大特征数的情况下，随机森林算法会随机选择一个特征子集，最多为指定的最大特征数，并决定如何拆分树的某个节点。这样可以让每棵树从训练集中学习到不同的信息。当这些从略有不同特征集的训练集中学习到信息的树进行集成（bagging）或集成（ensemble）时，最终的森林将变得更加准确且具有鲁棒性。'
- en: For a more detailed description and information on other hyperparameters, you
    can refer to their official documentation, which can be found at the following
    link: [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 若要获取更详细的描述和其他超参数的信息，您可以参考其官方文档，链接如下：[https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)。
- en: Training a random forest model
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练随机森林模型
- en: 'Training a random forest model using `scikit-learn` is simple. Take a look
    at the following code:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`scikit-learn`训练随机森林模型非常简单。请查看以下代码：
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Using the `RandomforestClasifier` class in the `scikit-learn` package's `ensemble`
    module, you first need to create a `RandomforestClasifier` object with the hyperparameters.
    For illustration purposes, we are instructing the model to build `200` trees,
    where each tree can only grow up to the depth of `5`. Then, you can train this
    model with the `fit` function, which takes two parameters, `X` and `y`, where
    `X` is for the training samples and `y` is for the training labels or target values.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`scikit-learn`包的`ensemble`模块中的`RandomforestClasifier`类，您首先需要创建一个带有超参数的`RandomforestClasifier`对象。为了演示，我们指示模型构建`200`棵树，每棵树的深度最大为`5`。然后，您可以使用`fit`函数训练该模型，该函数接受两个参数，`X`和`y`，其中`X`是训练样本，`y`是训练标签或目标值。
- en: 'When you run this code, you will see an output that looks as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行此代码时，您将看到如下输出：
- en: '![](img/eb29841c-0a3c-423b-8568-410014d5215e.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb29841c-0a3c-423b-8568-410014d5215e.png)'
- en: 'Once a random forest model is trained or fitted, the model object contains
    a lot of useful information. One of the useful attributes you can extract from
    a trained `scikit-learn` random forest model is the information about individual
    trees in the forest. Using the `estimators_` attribute, you can retrieve the individual
    trees that are built within the forest. Take a look at the following output:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦随机森林模型训练或拟合完成，模型对象将包含许多有用的信息。您可以从训练好的`scikit-learn`随机森林模型中提取一个有用的属性，那就是关于森林中各个单独树的信息。通过使用`estimators_`属性，您可以检索森林中构建的单独树。请查看以下输出：
- en: '![](img/08d11a03-fa14-417c-aa6e-c7f2b7750427.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/08d11a03-fa14-417c-aa6e-c7f2b7750427.png)'
- en: 'As you can see from this output, the `estimators_` attribute returns a list
    of sub-estimators, which are decision trees. With this information, you can simulate
    what each of these sub-estimators predicts for each input. For example, the following
    code shows how you can get the predictions from the first sub-estimator in the
    forest:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中可以看出，`estimators_` 属性返回的是一个子估计器列表，这些子估计器是决策树。通过这些信息，你可以模拟每个子估计器对每个输入的预测。例如，以下代码展示了如何获取森林中第一个子估计器的预测：
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following output shows some of the predictions from the first five sub-estimators:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示了前五个子估计器的一些预测：
- en: '![](img/db72f840-2ef0-4e2f-a4c0-8526c150a6c1.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/db72f840-2ef0-4e2f-a4c0-8526c150a6c1.png)'
- en: As you can see from this output, different trees predict differently for each
    record of the test set. This is because each tree is trained with different subsets
    of features that are randomly selected. Let's take a quick look at the predictions
    of these individual sub-estimators. The first tree predicts the `6th` record in
    the test set to be a class of `1` and the rest to be a class of `0`. On the other
    hand, the second tree predicts that the first 10 records of the test set to be
    a class of `0`. Using this information, you can see how the final predictions
    from the random forest model are formed from these individual sub-estimators or
    trees.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中可以看出，不同的树对测试集中的每一条记录的预测是不同的。这是因为每棵树是通过随机选择不同的特征子集进行训练的。我们来看一下这些单独子估计器的预测结果。第一棵树预测测试集中的第`6`条记录为`1`类，其他则为`0`类。而第二棵树则预测测试集前10条记录为`0`类。通过这些信息，你可以看到随机森林模型的最终预测是如何由这些独立的子估计器或树形成的。
- en: 'Other useful information that we can gain from the trained `RandomForestClassifier`
    object is the feature importances, with which we can understand the importance
    or the impact of each feature on the final predictions. You can get the feature
    importances for each feature using the following code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练好的 `RandomForestClassifier` 对象中，我们还可以获得特征重要性信息，这能帮助我们理解每个特征对最终预测的影响。你可以通过以下代码获取每个特征的重要性：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output of this code looks as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的输出结果如下：
- en: '![](img/1b9b3774-34bf-4bb3-8431-5be4b5e0c88f.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1b9b3774-34bf-4bb3-8431-5be4b5e0c88f.png)'
- en: 'In order to associate these feature importances with the corresponding features,
    you can use the following code:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将这些特征重要性与对应的特征关联起来，你可以使用以下代码：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The result looks as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![](img/9482caaa-0e7e-418d-a0fc-eaa2ca7edc89.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9482caaa-0e7e-418d-a0fc-eaa2ca7edc89.png)'
- en: As you can see from this output, the `EmploymentStatus.Retired` feature seems
    to be the most important factor in making the final prediction and the `Income`,
    `Total.Claim.Amount`, and `Customer.Lifetime.Value` features follow as the second,
    third, and fourth most important features.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中可以看出，`EmploymentStatus.Retired` 特征似乎是做出最终预测的最重要因素，`Income`、`Total.Claim.Amount`
    和 `Customer.Lifetime.Value` 特征依次排在第二、第三和第四重要特征的位置。
- en: Evaluating a classification model
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估分类模型
- en: Earlier in this chapter, we have discussed five different ways to look at the
    performance of a classification model. In this section, we are going to learn
    how we can compute and visualize the metrics for evaluating a classification model
    in Python using the random forest model we have just built.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章早些时候，我们讨论了五种不同的方式来评估分类模型的性能。在这一节中，我们将学习如何在Python中计算并可视化评估分类模型的指标，使用的是我们刚刚建立的随机森林模型。
- en: 'The first three metrics that we are going to look at are accuracy, precision,
    and recall. Python''s `scikit-learn` package has implemented functions for these
    three metrics. You can import these functions using the following line of code:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要查看的前三个指标是准确率、精确率和召回率。Python的 `scikit-learn` 包已经实现了这些指标的函数。你可以通过以下代码行导入这些函数：
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see from this code snippet, the `metrics` module of the `scikit-learn`
    package has an `accuracy_score` function for calculating the accuracy of a model,
    a `precision_score` function for the precision, and a `recall_score` function
    for the recall.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码中可以看到，`scikit-learn` 包的 `metrics` 模块有一个 `accuracy_score` 函数用于计算模型的准确率，一个
    `precision_score` 函数用于精确率计算，还有一个 `recall_score` 函数用于计算召回率。
- en: 'Before we go ahead and evaluate the model performance, we will need the model
    prediction results. In order to have the random forest model we have built in
    the previous section to make predictions on a dataset, we can simply use the `predict`
    function of the model. Take a look at the following code:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续评估模型性能之前，我们需要模型的预测结果。为了让我们在前一部分中构建的随机森林模型对数据集进行预测，我们可以简单地使用模型的`predict`函数。看看以下代码：
- en: '[PRE15]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'With these prediction results, we are going to evaluate how well our random
    forest model performs in the train and test sets. The following code shows how
    we can use the `accuracy_score`, `precision_score`, and `recall_score` functions
    in the `scikit-learn` package:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这些预测结果，我们将评估随机森林模型在训练集和测试集上的表现。以下代码展示了如何在`scikit-learn`包中使用`accuracy_score`、`precision_score`和`recall_score`函数：
- en: '[PRE16]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As you can see from this code, the `accuracy_score`, `precision_score`, and
    `recall_score` functions all take two parameters—truth labels and predicted labels.
    Take a look at the following output:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`accuracy_score`、`precision_score`和`recall_score`函数都接受两个参数——真实标签和预测标签。看看以下输出：
- en: '![](img/d6d2fa84-f2c8-4adc-95d2-47d878b3792f.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d6d2fa84-f2c8-4adc-95d2-47d878b3792f.png)'
- en: This output gives us a brief overview of how well our model performs at predicting
    the responses. For the train set, the accuracy of the overall prediction was `0.8724`,
    meaning the model prediction was correct for about `87%` of the time. For the
    test set, the accuracy of the overall prediction was `0.8818`, which is roughly
    on the same line with the prediction accuracy within the train set. You can also
    see that the precision for in-sample and out-of-sample predictions were `0.9919`
    and `0.9423` respectively, and the recalls were `0.1311` and `0.1324`. Due to
    the randomness and the different hyperparameters you might have used, you can
    get different results.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 该输出简要概述了我们模型在预测响应方面的表现。对于训练集，整体预测的准确率为`0.8724`，这意味着模型预测正确的概率约为`87%`。对于测试集，整体预测的准确率为`0.8818`，大致与训练集中的预测准确率相当。你还可以看到，样本内和样本外预测的精度分别为`0.9919`和`0.9423`，召回率分别为`0.1311`和`0.1324`。由于随机性和可能使用的不同超参数，你可能会得到不同的结果。
- en: 'The next set of metrics we are going to look at are the ROC curve and the AUC. The
    `metrics` module in the `scikit-learn` package has handy functions for the ROC
    curve and the AUC. Take a look at the following line of code:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们要查看的指标是ROC曲线和AUC。`scikit-learn`包中的`metrics`模块为ROC曲线和AUC提供了方便的函数。看看以下代码行：
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The `roc_curve` function in the metrics module of the `scikit-learn` package
    computes the ROC, and the `auc` function computes the AUC. In order to compute
    the ROC and AUC using these functions, we need to first get the prediction probabilities
    from our random forest model. The following code shows how we can get the random
    forest model''s prediction probabilities for both the train and test sets:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn`包中的`metrics`模块中的`roc_curve`函数计算ROC，而`auc`函数计算AUC。为了使用这些函数计算ROC和AUC，我们需要首先从我们的随机森林模型中获取预测概率。以下代码展示了如何获得随机森林模型在训练集和测试集上的预测概率：'
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see from this code, we are using the `predict_proba` function of
    the random forest model, `rf_model`. This function outputs the predicted probabilities
    of the given record belonging to each class. Since we only have two possible classes
    in our case, `0` for no responses and `1` for responses, the output of the `predict_proba`
    function has two columns, where the first column represents the predicted probability
    of a negative class, meaning no response for each record, and the second column
    represents the predicted probability of a positive class, meaning a response for
    each record. Since we are only interested in the likelihood of responding to the
    marketing effort, we can take the second column for the predicted probabilities
    of the positive class.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们正在使用随机森林模型`rf_model`的`predict_proba`函数。该函数输出每个记录属于每个类别的预测概率。由于我们的情况只有两个可能的类别，`0`代表无响应，`1`代表有响应，因此`predict_proba`函数的输出有两列，其中第一列代表负类的预测概率，即每个记录无响应的概率，第二列代表正类的预测概率，即每个记录有响应的概率。由于我们只关心响应营销活动的概率，因此我们可以选择第二列作为正类的预测概率。
- en: 'With these predicted probabilities of the positive class for both the train
    and test sets, we can now compute the ROC curve and AUC. Let''s first take a look
    at how we can compute the ROC curve using the `roc_curve` function in the following
    code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两个训练集和测试集的正类预测概率，我们现在可以计算 ROC 曲线和 AUC。让我们首先看看如何通过以下代码使用 `roc_curve` 函数计算
    ROC 曲线：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As you can see from this code snippet, the `roc_curve` function takes two parameters—observed
    labels and predicted probabilities. This function returns three variables, `fpr`,
    `tpr`, and `thresholds`. The `fpr` values represent the false positive rates for
    each given threshold and the `tpr` values represent the true positive rates for
    each given threshold. The `thresholds` values represent the actual thresholds
    at which `fpr` and `tpr` are measured.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码中可以看出，`roc_curve` 函数接受两个参数——观测标签和预测概率。该函数返回三个变量，`fpr`、`tpr` 和 `thresholds`。`fpr`
    值代表每个给定阈值的假阳性率，`tpr` 值代表每个给定阈值的真正阳性率。`thresholds` 值代表在这些阈值下测量的 `fpr` 和 `tpr`。
- en: 'Next, with these `fpr` and `tpr` values, we can compute the AUC using the following
    code:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用这些 `fpr` 和 `tpr` 值，我们可以通过以下代码计算 AUC：
- en: '[PRE20]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'As you can see from this code, the `auc` function takes two parameters—`fpr`
    and `tpr`. Using the previously calculated `fpr` and `tpr` values from the `roc_curve`
    function, we can easily compute the AUC numbers for both the train and test sets.
    The output looks as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码中可以看到，`auc` 函数接受两个参数——`fpr` 和 `tpr`。利用之前通过 `roc_curve` 函数计算得到的 `fpr` 和
    `tpr` 值，我们可以轻松计算出训练集和测试集的 AUC 数值。输出结果如下所示：
- en: '![](img/0bd94f4b-6d28-4250-a692-262db25c71ae.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0bd94f4b-6d28-4250-a692-262db25c71ae.png)'
- en: Depending on the hyperparameters and the randomness within the random forest
    algorithm, your AUC numbers can look different from these examples. However, in
    our case, the in-sample train set AUC was `0.8745` and the out-of-sample test
    set AUC was `0.8425`. If you see a big gap between these two numbers, it is a
    sign of overfitting and you should try to address it by pruning the trees in the
    forest by tuning the hyperparameters, such as the maximum depth and minimum number
    of samples to split.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 根据超参数和随机森林算法中的随机性，你的 AUC 数值可能与这些示例不同。然而，在我们的例子中，样本内训练集的 AUC 为 `0.8745`，样本外测试集的
    AUC 为 `0.8425`。如果你看到这两个数字之间有很大的差距，那是过拟合的迹象，你应该通过修剪森林中的树木来调整超参数，例如最大深度和分裂所需的最小样本数，从而解决这个问题。
- en: 'The last thing we are going to look at for evaluating machine learning models
    is the actual ROC curve. With the output of the `roc_curve` function, we can plot
    the actual ROC curves using the `matplotlib` package. Take a look at the following
    code:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在评估机器学习模型时，最后看一下实际的 ROC 曲线。通过 `roc_curve` 函数的输出，我们可以使用 `matplotlib` 包绘制实际的
    ROC 曲线。请查看以下代码：
- en: '[PRE21]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As you can see from this code, we are plotting three line plots—one for the
    out-of-sample test set ROC curve, another for the in-sample train set ROC curve,
    and lastly one for a straight line for the benchmark. The result looks as in the
    following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码中可以看出，我们绘制了三条折线图——一条是样本外测试集的 ROC 曲线，另一条是样本内训练集的 ROC 曲线，最后一条是基准的直线。结果如下所示：
- en: '![](img/0a2dedf6-0a8c-4f20-909b-6d231c502508.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0a2dedf6-0a8c-4f20-909b-6d231c502508.png)'
- en: As you can see from this plot, it is easier to see and compare the overall performance
    of the model between the train and test sets with ROC curves. The larger the gap
    between the in-sample ROC curve and the out-of-sample ROC curve, the more the
    model is overfitting to the train set and fails to generalize the findings for
    unforeseen data.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图中可以看出，通过 ROC 曲线，更容易观察和比较模型在训练集和测试集之间的整体表现。训练集 ROC 曲线和测试集 ROC 曲线之间的差距越大，模型越有可能对训练集过拟合，无法将发现推广到未知数据中。
- en: The full code for this Python exercise can be found at the following link: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/python/PredictingEngagement.ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/python/PredictingEngagement.ipynb)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Python 练习的完整代码可以在以下链接找到： [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/python/PredictingEngagement.ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/python/PredictingEngagement.ipynb)
- en: Predicting the likelihood of marketing engagement with R
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 R 预测营销参与的可能性
- en: In this section, we are going to discuss how to build predictive models using
    machine learning algorithms in R. More specifically, we will learn how to build
    a predictive model using a random forest algorithm, as well as how to tune the
    random forest model, and evaluate the performance of the model. We will be mainly
    using the `caTools`, `ROCR`, and `randomForest` packages to evaluate, visualize,
    and build machine learning models that predict the likelihood of customer marketing
    engagement. For those readers who would like to use Python instead of R for this
    exercise, you can refer to the previous section.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论如何使用 R 中的机器学习算法构建预测模型。更具体地说，我们将学习如何使用随机森林算法构建预测模型，如何调整随机森林模型，并评估模型的性能。我们将主要使用
    `caTools`、`ROCR` 和 `randomForest` 包来评估、可视化和构建预测客户营销参与度的机器学习模型。如果读者希望使用 Python
    而非 R 来进行此练习，可以参考前一节内容。
- en: 'For this exercise, we will be using one of the publicly available datasets
    from **IBM**, which can be found at this link: [https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/).
    You can follow this link and download the data that is available in CSV format,
    named `WA_Fn UseC_ Marketing Customer Value Analysis.csv`. Once you have downloaded
    this data, you can load it into your RStudio by running the following command:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用 **IBM** 提供的公开数据集，链接如下：[https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/)。你可以点击这个链接下载以
    CSV 格式提供的数据，文件名为 `WA_Fn UseC_ Marketing Customer Value Analysis.csv`。下载数据后，你可以通过运行以下命令将其加载到
    RStudio 中：
- en: '[PRE22]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`df` looks as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`df` 看起来如下：'
- en: '![](img/5ae79a64-9bbd-424d-9259-21bdec131954.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ae79a64-9bbd-424d-9259-21bdec131954.png)'
- en: As you might have noticed, this is the same dataset that we used in the previous
    chapter, where we conducted customer analytics. With the knowledge we gained about
    this dataset from the previous chapter, we are going to first prepare our data
    by encoding the target variable and other categorical variables that we are going
    to use as features for our machine learning models.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经注意到的，这是我们在上一章中使用的相同数据集，在那一章中我们进行了客户分析。借助上一章中我们对该数据集的了解，我们将首先通过编码目标变量和其他作为特征的分类变量来准备数据，以便应用于我们的机器学习模型。
- en: Variable encoding
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量编码
- en: In order to build machine learning models in R, all the features in the dataset
    need to have numerical values. However, in the dataset we have numerous columns
    that have non-numerical values. For example, the target variable, `Response`,
    which is what we are going to try to predict with our machine learning models,
    is non-numeric. It contains two string values—`Yes` or `No`. We will need to encode
    this `Response` target variable with numerical values in order to be able to build
    machine learning models. For another example, the `Gender` column, which we can
    use as one of the features for our predictive model, also does not have numerical
    values. It contains two string values—`F` for female and `M` for male. In this
    section, we are going to discuss how we can encode these non-numeric columns,
    so that we can use them as features in machine learning models.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 R 中构建机器学习模型，数据集中的所有特征必须具有数值型数据。然而，在我们拥有的数据集中，有许多列包含非数值型数据。例如，目标变量 `Response`，即我们将尝试使用机器学习模型预测的内容，是非数值型的。它包含两个字符串值——`Yes`
    或 `No`。我们需要将这个 `Response` 目标变量编码为数值，以便能够构建机器学习模型。另一个例子是 `Gender` 列，它可以作为预测模型的特征之一，也没有数值型数据。它包含两个字符串值——`F`
    表示女性，`M` 表示男性。在这一节中，我们将讨论如何编码这些非数值列，以便我们能够将它们用作机器学习模型的特征。
- en: Response variable encoding
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应变量编码
- en: 'The first thing we are going to do is encode the response variable, `Response`.
    We are going to encode `Yes` values with `1`s and `No` values with `0`s. Take
    a look at the following code:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的第一件事是编码响应变量 `Response`。我们将 `Yes` 值编码为 `1`，将 `No` 值编码为 `0`。请看以下代码：
- en: '[PRE23]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'As you can see from this code, we are simply casting the values of the `Response`
    column to integer values using the `as.integer` function. The reason why we are
    subtracting by `1` is because it encodes values into `1` for `No` and `2` for
    `Yes`, instead of `0` for `No` and `1` for `Yes`, as we wanted. We then store
    these encoded values in a newly-created column, `Engaged`. In order to get the
    overall response or engagement rate using this newly-created column, you can use
    the following code:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码可以看出，我们只是使用`as.integer`函数将`Response`列的值转换为整数值。之所以减去`1`，是因为它将值编码为`1`表示`No`，`2`表示`Yes`，而不是将`No`编码为`0`，`Yes`编码为`1`，这是我们所期望的。然后我们将这些编码后的值存储在新创建的列`Engaged`中。为了使用这个新创建的列获取整体响应或参与率，可以使用以下代码：
- en: '[PRE24]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The overall engagement rate looks as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 整体参与率如下所示：
- en: '![](img/aa44411e-2bd6-4206-938f-11a79d3908ec.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aa44411e-2bd6-4206-938f-11a79d3908ec.png)'
- en: Categorical variable encoding
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类变量编码
- en: 'If you look closely at the data, the following columns are categorical variables
    in our dataset:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仔细查看数据，以下列是我们数据集中的分类变量：
- en: '[PRE25]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: These variables have a set of different values they can take and these values
    do not necessarily have orders that differentiate one from another.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变量具有一组不同的值，这些值之间不一定有顺序来区分它们。
- en: 'If you recall from [Chapter 4](a9f09970-4826-46d0-8bfd-5796702c5629.xhtml),
    *From Engagement to Conversion*, we discussed how we can create factor variables
    for such categorical variables in R. In this chapter, the method we are going
    to use is to create dummy variables for each category of individual categorical
    variables, using the `model.matrix` function in R. Take a look at the following
    code:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得[第4章](a9f09970-4826-46d0-8bfd-5796702c5629.xhtml)《从参与到转化》中的内容，我们讨论了如何在R中为这些分类变量创建因子变量。在本章中，我们将使用的方法是为每个类别的单独分类变量创建虚拟变量，使用R中的`model.matrix`函数。请看以下代码：
- en: '[PRE26]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As you can see from this code, it is simple to create dummy variables for categorical
    variables in R. All you need to do is to apply the `model.matrix` function on
    the R `DataFrame`''s categorical variable columns. If you look closely at the
    code, you will notice the `~.-1` formula that we are using here. Without this
    formula, the `model.matrix` function will create an unnecessary column named `Intercept` in
    the output matrix. In order to avoid having this unnecessary column, we can use
    the formula in this code example. The first few columns of the newly-created `DataFrame` `encodedDf` now
    look as in the following:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码可以看到，在R中为分类变量创建虚拟变量非常简单。你需要做的就是对R `DataFrame`的分类变量列应用`model.matrix`函数。如果仔细查看代码，你会注意到我们在这里使用的`~.-1`公式。如果没有这个公式，`model.matrix`函数将在输出矩阵中创建一个名为`Intercept`的多余列。为了避免出现这个不必要的列，我们可以在这段代码示例中使用这个公式。现在，新创建的`DataFrame`
    `encodedDf`的前几列如下所示：
- en: '![](img/b03f57a2-e6e4-43cd-9918-6b10293bf4b2.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b03f57a2-e6e4-43cd-9918-6b10293bf4b2.png)'
- en: As you can see from this output, each column of this new `DataFrame` represents
    each category in the original column. For example, the first column, `Sales.ChannelAgent`,
    is encoded with `1` if the given record or customer was reached out by a sales
    agent and `0` otherwise. For another example, the fifth column, `Vehicle.SizeMedsize`,
    is encoded with `1` if the given record or customer has medium-size vehicles and
    `0` otherwise.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出可以看到，这个新`DataFrame`的每一列代表了原始列中的每个类别。例如，第一列`Sales.ChannelAgent`如果给定的记录或客户是由销售代理联系的，则编码为`1`，否则为`0`。再比如，第五列`Vehicle.SizeMedsize`如果给定的记录或客户拥有中型车辆，则编码为`1`，否则为`0`。
- en: 'Now that we have successfully encoded all the categorical variables with numerical
    values, we need to append the continuous variables to this newly-created `DataFrame`,
    `encodedDF`. Take a look at the following code:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功地用数值编码了所有的分类变量，我们需要将连续变量附加到这个新创建的`DataFrame`，`encodedDF`。请看以下代码：
- en: '[PRE27]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: As you can see from this code, we are using the `cbind` R function, which combines
    two DataFrames by columns. We are combining the previously-created DataFrame `encodedDF`,
    which contains all the encoded categorical variables with the DataFrame with continuous
    variables. Then, we are storing this combined `DataFrame` back to the `encodedDF` variable.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码可以看出，我们正在使用`cbind` R函数，它通过列将两个DataFrame结合在一起。我们正在将之前创建的包含所有编码过的分类变量的DataFrame
    `encodedDF`与包含连续变量的DataFrame结合在一起。然后，我们将这个合并后的`DataFrame`存回`encodedDF`变量中。
- en: Building predictive models
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建预测模型
- en: 'We are almost ready to start building and training machine learning models
    to predict customer responses or engagements. There is one thing we need to do
    before we start training a random forest model. We need to split the sample set,
    the `encodedDF` variable, into two subsets—one for training the models and another
    for testing and evaluating the trained models. The `caTools` R package has a handy
    function that splits a given sample set into train and test sets. If you do not
    have this library installed in your R environment, you can install it using the
    following command:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经几乎准备好开始构建和训练机器学习模型来预测客户的响应或参与情况。在我们开始训练随机森林模型之前，有一件事需要做。我们需要将样本集`encodedDF`变量拆分成两个子集——一个用于训练模型，另一个用于测试和评估训练好的模型。`caTools`
    R包提供了一个便捷的函数，可以将给定的样本集拆分成训练集和测试集。如果您的R环境中未安装此库，可以使用以下命令进行安装：
- en: '[PRE28]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, take a look at the following code on how to split the sample set into
    training and testing:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，看看下面的代码，了解如何将样本集拆分为训练集和测试集：
- en: '[PRE29]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Let's take a closer look at this code. The `sample.split` function in the `caTools`
    package lets us split the dataset into a proportion we would like. As you can
    see from this code, we defined `SplitRatio` to be `0.7`, which means we are taking
    `70%` of the sample set as a training set and the remaining `30%` of the `sample`
    set as a test set. The resulting variable, sample, now has an array of Boolean
    values, `TRUE` or `FALSE`, where `70%` of the arrays are `TRUE` and the remaining `30%`
    are `FALSE`.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看一下这段代码。`caTools`包中的`sample.split`函数允许我们将数据集按我们希望的比例拆分。从这段代码可以看到，我们将`SplitRatio`定义为`0.7`，这意味着我们将`70%`的样本集作为训练集，剩余的`30%`作为测试集。生成的变量`sample`现在包含一个布尔值数组，`TRUE`或`FALSE`，其中`70%`的数组为`TRUE`，其余的`30%`为`FALSE`。
- en: 'With this data, we can create train and test sets. As you can see from the
    code, we are using the `subset` function in R to create train and test sets. First,
    we take those records that correspond to `TRUE` values in the `sample` variable as
    the train set. Then, we take those records whose indexes correspond to `FALSE`
    values in the `sample` variable as the test set. The following shows the breakdown
    of train and test sets from the sample set:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些数据，我们可以创建训练集和测试集。如您所见，我们在R中使用`subset`函数来创建训练集和测试集。首先，我们将对应`sample`变量中`TRUE`值的记录作为训练集。然后，我们将对应`sample`变量中`FALSE`值的记录作为测试集。以下显示了样本集的训练集和测试集的划分：
- en: '![](img/9b3580ee-87ad-4281-9f57-cc83a7323b88.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9b3580ee-87ad-4281-9f57-cc83a7323b88.png)'
- en: As you can see here, there are a total of `9,134` records in `encodedDF`, `6,393` records
    in `trainX`, and `2,741` records in `testX`, meaning that roughly `70%` of the
    sample set went into the the train set and the remaining `30%` of the sample set
    went into the test set. We will be using these train and test sets for building
    and evaluating models in the following sections.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`encodedDF`中总共有`9,134`条记录，`trainX`中有`6,393`条记录，`testX`中有`2,741`条记录，这意味着大约`70%`的样本集进入了训练集，剩下的`30%`样本集进入了测试集。我们将在接下来的部分使用这些训练集和测试集来构建和评估模型。
- en: Random forest model
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林模型
- en: 'With the data that we have prepared so far, we are going to build a predictive
    model using a random forest algorithm, which predicts whether a customer is going
    to respond or engage with the marketing campaign. We are going to use the `randomForest` R
    library. If you do not have this library installed in your R environment, you
    can install it using the following command:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们目前准备的数据，我们将使用随机森林算法构建一个预测模型，该模型预测客户是否会对营销活动做出回应或参与。我们将使用`randomForest` R库。如果您的R环境中未安装此库，可以使用以下命令进行安装：
- en: '[PRE30]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once you have this package installed, you can use the following code to build
    a random forest model:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了这个包，您可以使用以下代码来构建随机森林模型：
- en: '[PRE31]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: However, there are many hyperparameters you can tune for random forest models.
    Hyperparameters are the parameters you define before you train a machine learning
    model. For example, in the case of a random forest algorithm, you can define the
    number of trees you want in your random forest model. As another example, you
    can define the maximum number of terminal nodes for each tree in the forest, so
    that you can limit how big each tree in the forest can grow.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随机森林模型有许多超参数可以调优。超参数是在训练机器学习模型之前你所定义的参数。例如，在随机森林算法中，你可以定义想要在随机森林模型中使用的树的数量。另一个例子是，你可以定义每棵树的最大终端节点数量，从而限制森林中每棵树的生长大小。
- en: 'There are numerous hyperparameters you can define and fine-tune. We will take
    a look at a few of these hyperparameters:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以定义并微调许多超参数。我们将看看其中的一些超参数：
- en: '**ntree:** This defines the number of trees you want to build in the forest.
    Generally speaking, more trees mean better performance results. However, the amount
    of performance gain for each additional tree decreases as the number of trees
    in the forest increases. Since having more trees in a forest means higher cost
    in computations for training additional trees, you should try to find the balance
    and stop adding trees when the computational cost from training additional trees
    outweighs the performance gain.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ntree**：此参数定义了你想要在森林中构建的树的数量。一般来说，更多的树意味着更好的性能。然而，随着树的数量增加，每增加一棵树带来的性能提升会逐渐减小。由于在森林中增加更多的树意味着在训练额外的树时需要更高的计算成本，因此你应该尝试找到平衡点，当训练额外树木的计算成本超过性能提升时，就停止增加树木。'
- en: '**sampsize**: This parameter defines the size of the sample to draw for training
    each tree. This introduces randomness in the forest, while training a random forest
    model. Having a high sample size results in a less random forest and has a higher
    chance of overfitting. This means that the trained tree performs and predicts
    well within the train set, but predicts poorly in the dataset that it has not
    seen before. Decreasing the sample size can help you avoid overfitting, but the
    performance of your model usually decreases as you decrease the sample size.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**sampsize**：此参数定义了为训练每棵树所抽取的样本大小。在训练随机森林模型时，这会引入森林中的随机性。较大的样本大小会导致森林的随机性较小，且更容易发生过拟合。这意味着训练出来的树在训练集中的表现和预测效果良好，但在未见过的数据集上预测效果较差。减小样本大小可以帮助避免过拟合，但通常会导致模型性能下降。'
- en: '**nodesize**: This parameter defines the minimum size of the terminal nodes,
    which means how many samples each terminal node needs to have at the very least.
    The larger this number is, the smaller the tree can grow. As you increase this
    number, you can mitigate the overfitting issues, but at the expense of the model
    performance.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nodesize**：此参数定义了终端节点的最小样本数，意味着每个终端节点至少需要有多少样本。这个数字越大，树可以生长得越小。随着这个数字的增加，你可以缓解过拟合问题，但代价是模型性能的下降。'
- en: '**maxnodes**: This parameter defines the maximum number of terminal nodes each
    tree in the forest can have. If you do not set this number, the algorithm is going
    to grow the tree to the fullest. This can result in overfitting the train set.
    Reducing the maximum number of terminal nodes can help you overcome overfitting
    issues.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**maxnodes**：此参数定义了森林中每棵树可以拥有的最大终端节点数量。如果不设置此参数，算法会将树生长到最大程度。这可能导致训练集过拟合。减少终端节点的最大数量有助于解决过拟合问题。'
- en: 'For a more detailed description and information on other hyperparameters, you
    can refer to the official documentation that can be found at the following link:
    [https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest](https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更详细的描述和其他超参数的信息，你可以参考官方文档，文档地址为：[https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest](https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest)。
- en: Training a random forest model
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练一个随机森林模型
- en: 'Training a random forest model using the `randomForest` package is simple.
    Take a look at the following code:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`randomForest`包训练一个随机森林模型非常简单。请看以下代码：
- en: '[PRE32]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Using the `randomForest` function in the `randomForest` package, you can easily
    train a random forest model. You just need to supply the train set to the function.
    For illustration purposes, we are instructing the model to build `200` trees,
    where each tree can only grow up to `24` terminal nodes.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `randomForest` 包中的 `randomForest` 函数，你可以轻松训练一个随机森林模型。你只需将训练集传递给该函数。为了说明，我们让模型构建
    `200` 棵树，每棵树最多只能生长到 `24` 个终端节点。
- en: 'When you run this code, your model object will look as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，你的模型对象将如下所示：
- en: '![](img/9c563e81-5c46-48cd-a297-3f7600443bca.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9c563e81-5c46-48cd-a297-3f7600443bca.png)'
- en: 'Once a random forest model is trained or fitted, the model object contains
    a lot of useful information. One of the useful attributes you can extract from
    a trained random forest model is the information about individual trees in the
    forest. Using the `getTree` function, you can retrieve how the individual trees
    are built within the forest. Take a look at the following example:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦随机森林模型被训练或拟合，模型对象会包含大量有用的信息。你可以从训练好的随机森林模型中提取出关于森林中单棵树的信息。通过使用 `getTree` 函数，你可以查看森林中各个树是如何构建的。看看以下示例：
- en: '![](img/d829463f-5d3e-40ad-9886-e52700eec057.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d829463f-5d3e-40ad-9886-e52700eec057.png)'
- en: Here we are looking at the information about the first tree in the forest. This
    gives us some information about the structure of the tree. The `left daughter`
    and `right daughter` columns tell us the location of this node in the given tree.
    The `status` column tells us whether the node is terminal (`-1`) or not (`1`).
    The `prediction` column tells us the prediction from this node.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们查看的是关于森林中第一棵树的信息。这些信息告诉我们树的结构。`left daughter` 和 `right daughter` 列告诉我们该节点在树中的位置。`status`
    列告诉我们该节点是否是终端节点（`-1`）或非终端节点（`1`）。`prediction` 列则告诉我们该节点的预测结果。
- en: 'Other information we can get from the fitted random forest model is the prediction
    from each tree in the forest. Take a look at the following code:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以从拟合的随机森林模型中获取每棵树的预测结果。看看以下代码：
- en: '[PRE33]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'By using the `predict.all=TRUE` flag, the `prediction` function returns the
    predictions from each tree in the forest. Take a look at the following output:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 `predict.all=TRUE` 参数，`prediction` 函数将返回森林中每棵树的预测结果。看看以下输出：
- en: '![](img/09bc2153-ddd4-4d9c-bcd7-64668f852017.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/09bc2153-ddd4-4d9c-bcd7-64668f852017.png)'
- en: This output is showing the first 20 trees' predictions for the first five records
    in the train set. As you can see from this output, the `10^(th)` tree in the forest
    predicted the `5^(th)` record in the train set to be a class of `1`, but all the
    other 19 trees predicted the `5^(th)` record in the train set to be a class of
    `0`. As you can see from this output, different trees predict differently for
    each record of the test set. This is because each tree is trained with different
    subsets of features that are randomly selected. Using this information, you can
    see how the final predictions from the random forest model are formed from these
    individual sub-estimators or trees.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 该输出展示了前 20 棵树对训练集前五个记录的预测结果。正如你从输出中看到的，森林中的第 `10^(th)` 棵树预测训练集中的第 `5^(th)` 条记录属于
    `1` 类，但其他 19 棵树都预测该记录属于 `0` 类。从输出中可以看到，每棵树对测试集中的每个记录的预测不同。这是因为每棵树都是用随机选择的不同特征子集进行训练的。利用这些信息，你可以看到随机森林模型的最终预测是如何由这些单独的子估计器或树组成的。
- en: 'Other useful information that we can gain from a trained `randomForest` object
    is the feature importances, with which we can understand the importance or the
    impact of each feature on the final predictions. You can get the feature importances
    for each feature using the following code:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练好的 `randomForest` 对象中，我们还可以获得特征重要性，从而了解每个特征对最终预测的影响或重要性。你可以使用以下代码获取每个特征的特征重要性：
- en: '[PRE34]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Part of the output of this code looks as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的输出部分如下所示：
- en: '![](img/14bab6a6-f5a2-4ff3-9c5c-b40bb0a74b48.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/14bab6a6-f5a2-4ff3-9c5c-b40bb0a74b48.png)'
- en: As you can see from this output, the `EmploymentStatusRetired` feature seems
    to be the most important factor in making the final prediction and the `Income`, `Total.Claim.Amount`,
    and `Customer.Lifetime.Value` features follow as the second, third, and fourth
    most important features.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从输出中看到的，`EmploymentStatusRetired` 特征似乎是最终预测中最重要的因素，而 `Income`、`Total.Claim.Amount`
    和 `Customer.Lifetime.Value` 特征分别位列第二、第三和第四重要特征。
- en: Evaluating a classification model
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估分类模型
- en: Earlier in this chapter, we discussed five different ways to look at the performance
    of a classification model. In this section, we are going to learn how we can compute
    and visualize the metrics for evaluating a classification model in R using the
    random forest model we have just built.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章之前，我们讨论了五种不同的方法来评估分类模型的性能。在本节中，我们将学习如何使用我们刚刚构建的随机森林模型来计算和可视化评估分类模型的度量标准。
- en: 'The first three metrics that we are going to look at are accuracy, precision,
    and recall. Before we go ahead and evaluate the model performance, we will need
    the model prediction results. In order to have the random forest model we have
    built in the previous section make predictions on a dataset, we can simply use
    the `predict` function. Take a look at the following code:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要查看的前三个度量标准是准确率、精确度和召回率。在我们继续评估模型性能之前，我们需要模型的预测结果。为了让我们在前一节中构建的随机森林模型对数据集进行预测，我们可以简单地使用`predict`函数。请查看以下代码：
- en: '[PRE35]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'With these prediction results, we are going to evaluate how well our random
    forest model performs in the train and test sets. The following code shows how
    we can compute accuracy, precision, and recall in R:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些预测结果，我们将评估我们的随机森林模型在训练集和测试集中的表现。以下代码展示了如何在R中计算准确率、精确度和召回率：
- en: '[PRE36]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Using this method, we can compare the in-sample train set `accuracy`, `precision`,
    and `recall` against the out-of-sample test set''s `accuracy`, `precision`, and
    `recall`. Take a look at the following output:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，我们可以将样本内训练集的`accuracy`（准确率）、`precision`（精确度）和`recall`（召回率）与样本外测试集的`accuracy`、`precision`和`recall`进行比较。请查看以下输出：
- en: '![](img/cc2daec3-a359-482b-b2d6-c4f83f2803b4.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cc2daec3-a359-482b-b2d6-c4f83f2803b4.png)'
- en: This output gives us a brief overview of how well our model performs at predicting
    the responses. For the train set, the accuracy of the overall prediction was `0.8756`,
    meaning the model prediction was correct for about `88%` of the time. For the
    test set, the accuracy of the overall prediction was `0.8636`. You can also find
    that the precisions for in-sample and out-of-sample predictions were `0.9717` and `0.8980` respectively,
    and the recalls were `0.1151` and `0.1065`. Due to the randomness and the different
    hyperparameters you might have used, you might get different results.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 该输出为我们提供了模型在预测响应时表现的简要概述。对于训练集，整体预测的准确率为`0.8756`，意味着模型的预测在大约`88%`的时间内是正确的。对于测试集，整体预测的准确率为`0.8636`。你还可以发现样本内和样本外预测的精确度分别为`0.9717`和`0.8980`，召回率分别为`0.1151`和`0.1065`。由于随机性和你可能使用的不同超参数，你可能会得到不同的结果。
- en: 'The next set of metrics we are going to look at are the ROC curve and the AUC. We
    are going to use the `ROCR` R package. If you do not have this package installed
    in your R environment, you can install it using the following command:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们要看的度量标准是ROC曲线和AUC值。我们将使用`ROCR` R包。如果你的R环境中尚未安装该包，可以使用以下命令进行安装：
- en: '[PRE37]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Take a look at the following code for the ROC curve and the AUC number first:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 首先查看以下关于ROC曲线和AUC值的代码：
- en: '[PRE38]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The first thing we need to do is to get the predicted probabilities from the
    model we have built. Using the `predict` function and the `type='prob'` flag,
    we can get the predicted probabilities from the random forest model. Then, we
    are using the `prediction` function in the `ROCR` package. This function computes
    the number of true positives and false positives at different probability cutoffs
    that we need for the ROC curve. Using the output of the `prediction` function,
    we can then get the true positive rates and false positive rates at different
    probability cutoffs with the `performance` function in the `ROCR` package. Lastly,
    in order to get the AUC number, we can use the same `performance` function with
    a different flag, `measure='auc'`.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是从我们构建的模型中获取预测概率。使用`predict`函数和`type='prob'`标志，我们可以从随机森林模型中获取预测概率。然后，我们使用`ROCR`包中的`prediction`函数。这个函数会计算在不同概率阈值下的真正例和假正例数量，这是我们绘制ROC曲线所需要的。使用`prediction`函数的输出，我们可以通过`ROCR`包中的`performance`函数，获取不同概率阈值下的真正例率和假正例率。最后，为了获得AUC值，我们可以使用相同的`performance`函数，只需使用不同的标志`measure='auc'`。
- en: 'With this data, we can now plot the ROC curve. Using the `plot` function and
    the `perf` variable, which is the output of the `performance` function, we can
    plot the ROC curve. The plot looks as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些数据，我们现在可以绘制ROC曲线。使用`plot`函数和`perf`变量（它是`performance`函数的输出），我们可以绘制ROC曲线。绘图如下所示：
- en: '![](img/6e8169d1-ce56-4e05-b2af-e80266d6f90a.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6e8169d1-ce56-4e05-b2af-e80266d6f90a.png)  '
- en: As you can see from this plot, the AUC of our random forest model was `0.76`.
    Compared to the benchmark straight line, which represents the random line, the
    model performs much better, and this shows that the model predictions are much
    better than random predictions.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '从这个图表中可以看到，我们的随机森林模型的AUC为`0.76`。与代表随机线的基准直线相比，该模型表现得要好得多，这表明模型的预测远优于随机预测。  '
- en: 'The full code for this R exercise can be found at the following link: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/R/PredictingEngagement.R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/R/PredictingEngagement.R).'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '该R练习的完整代码可以通过以下链接找到：[https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/R/PredictingEngagement.R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/R/PredictingEngagement.R)。  '
- en: Summary
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '概述  '
- en: In this chapter, we discussed predictive analytics and its applications in marketing.
    We first discussed what predictive analytics is and how it is used in various
    other industries, such as in the financial and healthcare industries. Then we
    discussed four common use cases of predictive analytics in marketing—likelihood
    of engagement, customer lifetime value, recommending the right products and contents,
    and customer acquisition and retention. There can be numerous other use cases
    of predictive analytics in marketing, so we recommend you keep up with the latest
    news on how predictive analytics can be used in marketing industries. We then
    discussed five different ways to evaluate the performances of predictive models—accuracy,
    precision, recall, the ROC curve, and the AUC.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们讨论了预测分析及其在营销中的应用。我们首先讨论了什么是预测分析，以及它在金融和医疗等其他行业中的应用。然后我们讨论了预测分析在营销中的四个常见应用场景——参与可能性、客户生命周期价值、推荐合适的产品和内容，以及客户获取和保持。预测分析在营销中还有许多其他应用场景，因此我们建议您跟进最新的新闻，了解预测分析在营销行业中的应用。接着我们讨论了评估预测模型表现的五种不同方法——准确度、精确度、召回率、ROC曲线和AUC。
- en: In the following chapter, we are going to expand our knowledge of predictive
    analytics. We are going to discuss the concept and importance of measuring customer
    lifetime value, as well as building machine learning models for customer lifetime
    value predictions.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '在接下来的章节中，我们将扩展我们对预测分析的知识。我们将讨论衡量客户生命周期价值的概念和重要性，以及为客户生命周期价值预测构建机器学习模型。  '
