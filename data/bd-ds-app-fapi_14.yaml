- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Introduction to Data Science in Python
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 数据科学入门
- en: In recent years, Python has gained a lot of popularity in the data science field.
    Its very efficient and readable syntax makes the language a very good choice for
    scientific research, while still being suitable for production workloads; it’s
    very easy to deploy research projects into real applications that will bring value
    to users. Thanks to this growing interest, a lot of specialized Python libraries
    have emerged and are now standards in the industry. In this chapter, we’ll introduce
    the fundamental concepts of machine learning before diving into the Python libraries
    used daily by data scientists.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，Python 在数据科学领域获得了广泛的关注。其高效且易读的语法使得该语言成为科学研究的一个非常好的选择，同时仍然适用于生产工作负载；它非常容易将研究项目部署到能为用户带来价值的实际应用中。由于这种日益增长的兴趣，许多专门的
    Python 库应运而生，并且现在已经成为行业标准。在本章中，我们将介绍机器学习的基本概念，然后再深入了解数据科学家日常使用的 Python 库。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主要内容：
- en: Understanding the basic concepts of machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解机器学习的基本概念
- en: Creating and manipulating NumPy arrays and pandas datasets
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和操作 NumPy 数组和 pandas 数据集
- en: Training and evaluating machine learning models with scikit-learn
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 训练和评估机器学习模型
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you’ll require a Python virtual environment, just as we set
    up in [*Chapter 1*](B19528_01.xhtml#_idTextAnchor024), *Python Development* *Environment
    Setup*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，你将需要一个 Python 虚拟环境，正如我们在[*第 1 章*](B19528_01.xhtml#_idTextAnchor024)中所设置的，*Python
    开发* *环境设置*。
- en: You’ll find all the code examples for this chapter in the dedicated GitHub repository
    at [https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的专用 GitHub 仓库中找到所有代码示例，网址为[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11)。
- en: What is machine learning?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: '**Machine learning** (**ML**) is often seen as a subfield of artificial intelligence.
    While this categorization is the subject of debate, ML has had a lot of exposure
    in recent years due to its vast and visible field of applications, such as spam
    filters, natural language processing, and image generation.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）通常被视为人工智能的一个子领域。虽然这种分类仍然存在争议，但由于机器学习在垃圾邮件过滤、自然语言处理和图像生成等广泛而显著的应用领域中得到了广泛应用，近年来它的曝光率非常高。'
- en: ML is a field where we build mathematical models from existing data so that
    the machine can understand this data by itself. The machine is “learning” in the
    sense that the developer doesn’t have to program a step-by-step algorithm to solve
    the problem, which would be impossible for complex tasks. Once a model has been
    “trained” on existing data, it can be used to predict new data or understand new
    observations.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个从现有数据中构建数学模型的领域，使得机器能够自行理解这些数据。机器是“学习”的，因为开发者不需要为复杂任务编写逐步算法，来解决问题，这是不可能的。一旦模型在现有数据上“训练”完成，它就可以用来预测新数据或理解新的观察结果。
- en: 'Consider the spam filter example: if we have a sufficiently large collection
    of emails manually labeled “spam” or “not spam,” we can use ML techniques to build
    a model that can tell us whether a new incoming email is spam or not.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以垃圾邮件过滤器为例：如果我们有一个足够大的电子邮件集合，手动标记为“垃圾邮件”或“非垃圾邮件”，我们可以使用机器学习技术构建一个模型，来判断新收到的电子邮件是否为垃圾邮件。
- en: In this section, we’ll review the most fundamental concepts of ML.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾机器学习的最基本概念。
- en: Supervised versus unsupervised learning
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习与非监督学习
- en: 'ML techniques can be divided into two main categories: **supervised learning**
    and **unsupervised learning**.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习技术可以分为两大类：**监督学习**和**非监督学习**。
- en: 'With supervised learning, the existing dataset is already labeled, which means
    we have both the input (the characteristics of an observation), known as **features**,
    and the output. If we consider the spam filter example here, the features could
    be the frequencies of each word and the **label** could be the category – that
    is, “spam” or “not spam.” Supervised learning is subdivided into two groups:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，现有的数据集已经标记好，这意味着我们既有输入（观察的特征），称为**特征**，也有输出。如果我们以垃圾邮件过滤器为例，特征可以是每个单词的频率，而**标签**则是类别——也就是说，“垃圾邮件”或“非垃圾邮件”。监督学习分为两个组：
- en: '**Classification problems**, to classify data with a finite set of categories
    – for example, the spam filter'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类问题**，将数据分类到有限的类别中——例如，垃圾邮件过滤器。'
- en: '**Regression problems**, to predict continuous numerical values – for example,
    the number of rented electric scooters, given the day of the week, the weather,
    and the location'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归问题**，预测连续的数值——例如，根据星期几、天气和位置预测租用的电动滑板车数量。'
- en: 'Unsupervised learning, on the other hand, operates on data without any reference
    to a label. The goal here is to discover interesting patterns from the features
    themselves. The two main problems that unsupervised learning tries to solve are
    as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习，另一方面，是在没有标签参考的数据上进行操作。其目标是从特征本身发现有趣的模式。无监督学习试图解决的两个主要问题如下：
- en: '**Clustering**, where we want to find groups of similar data points – for example,
    a recommender system to suggest products that you might like, given what other
    people similar to you like.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**，我们想要找到一组相似的数据点——例如，一个推荐系统，根据其他类似你的人喜欢的商品来推荐你可能喜欢的商品。'
- en: '**Dimensionality reduction**, where the goal is to find a more compact representation
    of datasets that contain a lot of different features. Doing this will allow us
    to keep only the most meaningful and discriminant features while working with
    smaller dataset dimensions.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降维**，目标是找到更紧凑的数据集表示，这些数据集包含了很多不同的特征。通过这样做，我们可以只保留最有意义和最具辨别力的特征，同时在较小的数据集维度下工作。'
- en: Model validation
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型验证
- en: One of the key aspects of ML is evaluating whether your model is performing
    well or not. How can you say that your model will perform well on newly observed
    data? When building your model, how can you tell whether one algorithm performs
    better than another? All of these questions can and should be answered with model
    validation techniques.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的一个关键方面是评估模型是否表现良好。我们如何确定模型在新观察到的数据上也会表现良好？在构建模型时，如何判断一个算法是否优于另一个算法？所有这些问题都可以并且应该通过模型验证技术来回答。
- en: As we mentioned previously, ML methods start with an existing set of data that
    we’ll use to train a model.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，机器学习方法是从一个现有的数据集开始的，我们将用它来训练模型。
- en: Intuitively, we may want to use all the data we have to train our model. Once
    done, what can we do to test it? We could apply our model to the same data and
    see whether the output was correct... and we would get a surprisingly good result!
    Here, we are testing the model with the same data we used to train it. Obviously,
    the model will overperform on this data because it has already seen it. As you
    may have guessed, this is not a reliable way to measure the accuracy of our model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地，我们可能想要使用所有可用的数据来训练我们的模型。一旦完成，如何测试模型呢？我们可以将模型应用到相同的数据上，看看输出是否正确……结果可能会非常好！在这里，我们用相同的训练数据来测试模型。显然，由于模型已经见过这些数据，它在这些数据上的表现会特别好。正如你可能猜到的，这并不是一个可靠的衡量模型准确性的方法。
- en: 'The right way to validate a model is to split the data into two: we keep one
    part for training the data and another for testing it. This is known as the **holdout
    set**. This way, we’ll test the model on data that it has never seen before and
    compare the result that’s predicted by the model with the real value. Hence, the
    accuracy we are measuring is much more sensible.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 验证模型的正确方法是将数据分成两部分：一部分用于训练数据，另一部分用于测试数据。这被称为**保留集**。通过这种方式，我们将在模型从未见过的数据上进行测试，并将模型预测的结果与真实值进行比较。因此，我们测量的准确性要更加合理。
- en: 'This technique works well; however, it poses a problem: by retaining some data,
    we are losing precious information that could have helped us build a better model.
    This is especially true if our initial dataset is small. To solve this, we can
    use **cross-validation**. With this method, we once again split the data into
    two sets. This time, we are training the model twice, using each set as training
    and testing sets. You can see a schematic representation of this operation in
    the following diagram:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术效果很好；然而，它也带来一个问题：通过保留一些数据，我们丧失了本可以帮助我们构建更好模型的宝贵信息。如果我们的初始数据集较小，这一点尤其明显。为了解决这个问题，我们可以使用**交叉验证**。通过这种方法，我们再次将数据分成两个集合。这一次，我们训练模型两次，分别使用每个集合作为训练集和测试集。你可以在下图中看到这一操作的示意图：
- en: '![Figure 11.1 – Two-fold cross-validation](img/Figure_11.1_B19528.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1 – 二折交叉验证](img/Figure_11.1_B19528.jpg)'
- en: Figure 11.1 – Two-fold cross-validation
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – 二折交叉验证
- en: 'At the end of the operation, we obtain two accuracies, which will give us a
    better overview of how our model performs on the whole dataset. This technique
    can be applied to help us perform more trials with a smaller testing set, as shown
    in the following diagram:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在操作结束时，我们得到两个准确度指标，这将使我们更好地了解模型在整个数据集上的表现。这项技术可以帮助我们在较小的测试集上进行更多的试验，如下图所示：
- en: '![Figure 11.2 – Five-fold cross-validation](img/Figure_11.2_B19528.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.2 – 五折交叉验证](img/Figure_11.2_B19528.jpg)'
- en: Figure 11.2 – Five-fold cross-validation
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – 五折交叉验证
- en: 'We’ll stop here regarding this very quick introduction to ML. We’ve barely
    scratched the surface: ML is a vast and complex field, and there are lots of books
    dedicated to this subject. Still, this information should be sufficient to help
    you understand the basic concepts we’ll show throughout the rest of this chapter.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 关于机器学习的这个简短介绍我们就讲到这里。我们仅仅触及了表面：机器学习是一个庞大而复杂的领域，专门讨论这一主题的书籍有很多。不过，这些信息足以帮助你理解我们在本章其余部分展示的基本概念。
- en: Manipulating arrays with NumPy and pandas
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用NumPy和pandas操作数组
- en: As we said in the introduction, numerous Python libraries have been developed
    to help with common data science tasks. The most fundamental ones are probably
    NumPy and pandas. Their goal is to provide a set of tools to manipulate a big
    set of data in an efficient way, much more than what we could actually achieve
    with standard Python, and we’ll show how and why in this section. NumPy and pandas
    are at the heart of most data science applications in Python; knowing about them
    is therefore the first step on your journey into Python for data science.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在介绍中所说，许多Python库已经被开发出来，以帮助处理常见的数据科学任务。最基础的库可能是NumPy和pandas。它们的目标是提供一套工具，用高效的方式操作大量数据，远远超过我们使用标准Python所能实现的功能，我们将在这一部分展示如何做到以及为什么要这样做。NumPy和pandas是大多数Python数据科学应用的核心；因此，了解它们是你进入Python数据科学领域的第一步。
- en: 'Before starting to use them, let’s explain why such libraries are needed. In
    [*Chapter 2*](B19528_02.xhtml#_idTextAnchor032), *Python Programming Specificities*,
    we stated that Python is a dynamically typed language. This means that the interpreter
    automatically detects the type of a variable at runtime, and this type can even
    change throughout the program. For example, you can do something like this in
    Python:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始使用它们之前，让我们解释一下为什么需要这些库。在[*第2章*](B19528_02.xhtml#_idTextAnchor032)，《Python编程特性》中，我们提到过Python是一种动态类型语言。这意味着解释器在运行时自动检测变量的类型，而且这个类型甚至可以在程序中发生变化。例如，你可以在Python中做如下操作：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The interpreter was able to determine the type of `x` at each assignation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 解释器能够在每次赋值时确定`x`的类型。
- en: 'Under the hood, the standard implementation of Python, CPython, is written
    in C. The C language is a compiled and statically typed language. This means that
    the nature of the variables is fixed at compile time, and they can’t change during
    execution. Thus, in the Python implementation, a variable doesn’t only consist
    of its value: it’s actually a structure containing information about the variable,
    including its type and size, in addition to its value.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，Python的标准实现——CPython，是用C语言编写的。C语言是一种编译型且静态类型的语言。这意味着变量的类型在编译时就已经确定，并且在执行过程中不能改变。因此，在Python实现中，变量不仅仅包含它的值：它实际上是一个结构体，包含有关变量的信息，包括类型、大小以及它的值。
- en: 'Thanks to this, we can manipulate variables very dynamically in Python. However,
    it comes at a cost: each variable has a significantly higher memory footprint
    to store all its metadata than just the plain value.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了这一点，我们可以在Python中非常动态地操作变量。然而，这也有代价：每个变量的内存占用会显著更大，因为它需要存储所有的元数据，而不仅仅是简单的值。
- en: 'This is particularly true for data structures. Say we consider a simple list
    like this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于数据结构尤其适用。假设我们考虑一个简单的列表，例如：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Each item in the list is a Python integer, with all the metadata associated.
    In a statically typed language such as C, the same list would only be a suite
    of values in memory sharing the same type.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 列表中的每个项都是一个Python整数，并带有所有相关的元数据。在像C这样的静态类型语言中，相同的列表只会是内存中一组共享相同类型的值。
- en: 'Let’s now imagine a big set of data, like the kind we usually encounter in
    data science: the cost of storing it in memory would be huge. That’s exactly the
    purpose of NumPy: to provide a powerful and efficient array structure for manipulating
    a big set of data. Under the hood, it uses a fixed-type array, meaning all elements
    of the structure are of the same type, which allows NumPy to get rid of the costly
    metadata of every single element. Moreover, common arithmetic operations, such
    as additions or multiplications, are much faster. In the *Manipulating arrays
    with NumPy – computation, aggregations, and comparisons* section, we’ll make a
    speed comparison to show you the difference with standard Python lists.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们想象一下一个大型数据集，比如我们在数据科学中经常遇到的那种：将其存储在内存中的成本将是巨大的。这正是NumPy的目的：提供一个强大且高效的数组结构来处理大型数据集。在底层，它使用固定类型的数组，这意味着结构中的所有元素都是相同类型的，这使得NumPy能够摆脱每个元素的昂贵元数据。此外，常见的算术操作，例如加法或乘法，也会更快。在*使用NumPy操作数组
    – 计算、聚合和比较*这一部分中，我们将进行速度比较，以展示与标准Python列表的差异。
- en: Getting started with NumPy
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用NumPy
- en: 'Let’s see how NumPy works! The first thing is to install it using the following
    command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看NumPy是如何工作的！首先需要使用以下命令安装它：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In a Python interpreter, we can now import the library:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python解释器中，我们现在可以导入该库：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice that, by convention, *NumPy is generally imported with the alias* `np`.
    Let’s now discover its basic features!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，按照惯例，*NumPy通常以别名* `np` 导入。现在让我们来发现它的基本功能！
- en: Creating arrays
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建数组
- en: 'To create an array with NumPy, we can simply use the `array` function and pass
    it a Python list:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用NumPy创建数组，我们可以简单地使用`array`函数，并传入一个Python列表：
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'NumPy will detect the nature of the Python list. However, we can force the
    resulting type by using the `dtype` argument:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy会自动检测Python列表的类型。然而，我们可以通过使用`dtype`参数来强制指定结果类型：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'All elements were upcasted to the specified type. It is key to remember that
    a *NumPy array is of a fixed type*. This means that every element will have the
    same type and NumPy will silently cast a value to the `array` type. For example,
    let’s consider an integer list into which we want to insert a floating-point value:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 所有元素都被提升为指定的类型。关键是要记住，*NumPy数组是固定类型的*。这意味着每个元素将具有相同的类型，NumPy会默默地将值转换为`array`类型。例如，假设我们有一个整数列表，想要插入一个浮动点值：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `13.37` value has been truncated to fit into an integer.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`13.37`的值已经被截断以适应整数类型。'
- en: 'If the value cannot be cast to the type of array, an error is raised. For example,
    let’s try to change the first element with a string:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果无法将值转换为数组类型，则会引发错误。例如，让我们尝试用一个字符串改变第一个元素：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As we said in the introduction to this section, Python lists are not very efficient
    for large datasets. This is why it’s generally more efficient to use NumPy functions
    to create arrays. The most commonly used ones are generally the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本节介绍中所说，Python列表对于大型数据集效率较低。这就是为什么通常使用NumPy函数创建数组更为高效。最常用的函数通常是以下几种：
- en: '`np.zeros`, to create an array filled with zeros'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`np.zeros`，用于创建一个填充了0的数组'
- en: '`np.ones`, to create an array filled with ones'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`np.ones`，用于创建一个填充了1的数组'
- en: '`np.empty`, to create an empty array of the desired size in memory, without
    initializing the values'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`np.empty`，用于创建一个空的数组，指定内存中的大小，但不初始化值'
- en: '`np.arange`, to create an array with a range of elements'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`np.arange`，用于创建一个包含一系列元素的数组'
- en: 'Let’s see them in action:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它们如何工作：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Notice that the result of `np.empty` can vary: since the values in the array
    are not initialized, *they take whatever value there is currently in this memory
    block*. The main motivation behind this function is speed, allowing you to quickly
    allocate memory, but don’t forget to fill every element after.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`np.empty` 的结果可能会有所不同：由于数组中的值未初始化，*它们会采用当前内存块中的任何值*。这个函数的主要动机是速度，它允许你快速分配内存，但不要忘记在后续填充每个元素。
- en: 'By default, NumPy creates arrays with a floating-point type (`float64`). Once
    again, by using the `dtype` argument, you can force another type to be used:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，NumPy 创建的数组使用浮点类型（`float64`）。同样，使用 `dtype` 参数，你可以强制使用其他类型：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'NumPy provides a wide range of types, allowing you to finely optimize the memory
    consumption of your program by selecting the right type for your data. You can
    find the whole list of types supported by NumPy in the official documentation:
    [https://numpy.org/doc/stable/reference/arrays.scalars.html#sized-aliases](https://numpy.org/doc/stable/reference/arrays.scalars.html#sized-aliases).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 提供了广泛的类型选择，通过为数据选择合适的类型，你可以精细地优化程序的内存消耗。你可以在官方文档中找到 NumPy 支持的所有类型列表：[https://numpy.org/doc/stable/reference/arrays.scalars.html#sized-aliases](https://numpy.org/doc/stable/reference/arrays.scalars.html#sized-aliases)。
- en: 'NumPy also proposes a function to create an array with random values:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 还提供了一个创建随机值数组的函数：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The first argument is the maximum range of the random value, and the `size`
    argument sets the number of values to generate.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数是随机值的最大范围，`size` 参数设置生成的值的数量。
- en: 'Until now, we showed how to create one-dimensional arrays. However, the great
    strength of NumPy is that it natively handles multi-dimensional arrays! For example,
    let’s create a *3 x* *4* matrix:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们展示了如何创建一维数组。然而，NumPy 的强大之处在于它原生支持多维数组！例如，创建一个 *3 x* *4* 矩阵：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'NumPy did create an array with three rows and four columns! All we had to do
    was to pass a tuple to the NumPy function to specify our dimensions. When having
    such an array, NumPy gives us access to properties for knowing the number of dimensions,
    as well as the shape and size of it:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 确实创建了一个三行四列的数组！我们所做的只是将一个元组传递给 NumPy 函数来指定我们的维度。拥有这样的数组时，NumPy 为我们提供了访问数组属性的方法，用于了解数组的维度数、形状和大小：
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Accessing elements and sub-arrays
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 访问元素和子数组
- en: 'NumPy arrays closely follow the standard Python syntax to manipulate lists.
    Therefore, to access an element in a one-dimensional array, just do the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 数组紧密遵循标准 Python 语法来操作列表。因此，要访问一维数组中的元素，只需执行以下操作：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'For multi-dimensional arrays, we just have to add another index:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多维数组，我们只需再添加一个索引：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Of course, this can be used to re-assign elements:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这也可以用来重新赋值元素：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'But that’s not all. Thanks to the slicing syntax, we can access sub-arrays
    with a start index, an end index, and even a step. For example, on a one-dimensional
    array, we can do the following:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 但这还不是全部。得益于切片语法，我们可以通过起始索引、结束索引，甚至步长来访问子数组。例如，在一维数组中，我们可以做如下操作：
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This is exactly what we saw for standard Python lists in [*Chapter 2*](B19528_02.xhtml#_idTextAnchor032),
    *Python Programming Specificities*. Of course, it also works for multi-dimensional
    arrays, with one slice for each dimension:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们在 [*第 2 章*](B19528_02.xhtml#_idTextAnchor032) 中看到的标准 Python 列表操作，*Python
    编程特性*。当然，这同样适用于多维数组，每个维度都用一个切片表示：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You can assign those sub-arrays to variables. However, for performance reasons,
    NumPy doesn’t copy the values by default: it’s only a **view** (or shallow copy),
    a representation of the existing data. This is important to bear in mind because
    if you change a value in the view, it will also change the value in the original
    array:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将这些子数组赋值给变量。然而，出于性能考虑，NumPy 默认不会复制值：它仅仅是一个 **视图**（或浅拷贝），即现有数据的表示。记住这一点很重要，因为如果你在视图中更改了某个值，它也会更改原始数组中的值：
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If you need to really `copy` method on the array:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要对数组进行真正的 `copy` 操作：
- en: '[PRE19]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '`m2` is now a separate copy of `m`, and changes in its values won’t change
    the values in `m`.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`m2` 现在是 `m` 的一个独立副本，`m2` 中的值变化不会影响 `m` 中的值。'
- en: 'You now have the basics for handling arrays with NumPy. As we’ve seen, the
    syntax is very similar to standard Python. The key points to remember when working
    with NumPy are the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经掌握了使用 NumPy 处理数组的基础知识。正如我们所见，语法与标准 Python 非常相似。使用 NumPy 时需要记住的关键点如下：
- en: NumPy arrays are of fixed types, meaning all items in the array are of the same
    type
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 数组具有固定类型，这意味着数组中的所有项都是相同的类型
- en: NumPy natively handles multi-dimensional arrays and allows us to subset them
    using the standard slicing notation
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 原生支持多维数组，并允许我们使用标准切片符号对其进行子集化
- en: 'Of course, NumPy can do much more than that: actually, it can apply common
    computations to those arrays in a very performant way.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，NumPy 能做的远不止这些：实际上，它可以以非常高效的方式对这些数组执行常见的计算。
- en: Manipulating arrays with NumPy – computation, aggregations, and comparisons
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 NumPy 操作数组——计算、聚合和比较
- en: 'As we said, NumPy is all about manipulating large arrays with great performance
    and controlled memory consumption. Let’s say, for example, that we want to compute
    the double of each element in a large array. In the following example, you can
    see an implementation of such a function with a standard Python loop:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所说，NumPy 的核心是操作大型数组，并提供出色的性能和可控的内存消耗。假设我们想要计算一个大数组中每个元素的双倍。在下面的示例中，你可以看到使用标准
    Python 循环实现此功能的代码：
- en: chapter11_compare_operations.py
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: chapter11_compare_operations.py
- en: '[PRE20]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_compare_operations.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_compare_operations.py)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_compare_operations.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_compare_operations.py)'
- en: We instantiate an array with a million random integers. Then, we have our function
    building an array with the double of each element. Basically, we first instantiate
    an empty array of the same size before looping over each element to set the double.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实例化了一个包含百万个随机整数的数组。然后，我们的函数创建了一个包含每个元素双倍值的数组。基本上，我们首先实例化一个大小相同的空数组，然后遍历每个元素，设置其双倍值。
- en: 'Let’s measure the performance of this function. In Python, there is a standard
    module, `timeit`, dedicated to this purpose. We can use it directly from the command
    line and pass valid Python statements we want to measure performance for. The
    following command will measure the performance of `standard_double` with our big
    array:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来衡量这个函数的性能。在 Python 中，有一个标准模块 `timeit`，专门用于此目的。我们可以直接从命令行使用它，并传入我们想要测量性能的有效
    Python 语句。以下命令将测量我们的大数组上 `standard_double` 函数的性能：
- en: '[PRE21]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The results will vary depending on your machine, but the magnitude should be
    equivalent. What `timeit` does is repeat your code a certain number of times and
    measure its execution time. Here, our function took around 150 milliseconds to
    compute the double of each element in our array. For such simple computations
    on a modern computer, that’s not very impressive.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 结果会根据你的机器有所不同，但规模应该是相同的。`timeit` 的作用是重复执行你的代码若干次，并测量其执行时间。在这里，我们的函数计算每个数组元素的双倍花费了大约
    150 毫秒。对于现代计算机上这样简单的计算来说，这并不算特别令人印象深刻。
- en: 'Let’s compare this with the equivalent operation using NumPy syntax. You can
    see it in the next sample:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将此操作与使用 NumPy 语法的等效操作进行比较。你可以在下一个示例中看到：
- en: chapter11_compare_operations.py
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: chapter11_compare_operations.py
- en: '[PRE22]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_compare_operations.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_compare_operations.py)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_compare_operations.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_compare_operations.py)'
- en: 'The code is much shorter! NumPy implements the basic arithmetic operations
    and can apply them to each element of the array. By multiplying the array by a
    value directly, we implicitly tell NumPy to multiply each element by this value.
    Let’s measure the performance with `timeit`:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 代码要短得多！NumPy 实现了基本的算术运算，并可以将它们应用到数组的每个元素上。通过直接将数组乘以一个值，我们实际上是在告诉 NumPy 将每个元素乘以这个值。让我们使用`timeit`来衡量性能：
- en: '[PRE23]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Here, the best loop achieved the computation in 600 microseconds! That’s 250
    times faster than the previous function! How can we explain such a variation?
    In a standard loop, Python (because of its dynamic nature) has to check for the
    type of value at each iteration to apply the right function for this type, which
    adds significant overhead. With NumPy, the operation is deferred to an optimized
    and compiled loop where types are known ahead of time, which saves a lot of useless
    checks.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，最佳循环在600微秒内完成了计算！这比以前的函数快了250倍！我们如何解释这样的变化？在标准循环中，Python（因为其动态性质）必须在每次迭代时检查值的类型以应用正确的函数，这增加了显著的开销。而使用NumPy，操作被延迟到一个优化和编译的循环中，在这里类型是预先知道的，这节省了大量无用的检查。
- en: 'We once again see here the benefits of NumPy arrays over standard lists when
    working on a large dataset: it implements operations natively to help you make
    computations very fast.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理大型数据集时，NumPy数组比标准列表有更多的优势：它本地实现操作以帮助您快速进行计算。
- en: Adding and multiplying arrays
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加和乘以数组
- en: As you saw in the previous example, NumPy supports the arithmetic operators
    to make operations over arrays.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在前面的例子中看到的那样，NumPy支持算术运算符以在数组上执行操作。
- en: 'This means that you can operate directly over two arrays of the same dimensions:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着您可以直接操作两个具有相同维度的数组：
- en: '[PRE24]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In this case, NumPy applies the operation element-wise. But it also works in
    certain situations if one of the operands is not of the same shape:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，NumPy逐元素地应用操作。但在某些情况下，如果操作数之一不是相同的形状，它也可以工作：
- en: '[PRE25]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'NumPy automatically understands that it should multiply each element by two.
    This is called **broadcasting**: NumPy “expands” the smaller array to match the
    shape of the larger array. The previous example is equivalent to this one:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy自动理解它应该将每个元素乘以两倍。这被称为**广播**：NumPy“扩展”较小的数组以匹配较大数组的形状。前面的例子等同于这个例子：
- en: '[PRE26]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Note that even if those two examples are conceptually equivalent, the first
    one is more memory-efficient and computationally efficient: NumPy is smart enough
    to use only one `2` value, without having to create a full array of `2`.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，即使这两个例子在概念上是等效的，第一个例子在内存和计算上更加高效：NumPy足够智能，只使用一个`2`值，而不需要创建一个完整的`2`数组。
- en: 'More generally, broadcasting works if the rightmost dimensions of the arrays
    are of the same size or if one of them is `1`. For example, we can add an array
    of dimensions *4 x 3* to an array of dimensions *1* *x 3*:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地说，如果数组的最右维度大小相同或其中一个是`1`，广播就会起作用。例如，我们可以将*4 x 3*维度的数组添加到*1* *x 3*维度的数组中：
- en: '[PRE27]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'However, adding an array of dimensions *4 x 3* to an array of dimensions *1
    x 4* is not possible:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将*4 x 3*维度的数组添加到*1 x 4*维度的数组中是不可能的：
- en: '[PRE28]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'If this sounds complicated or confusing, that’s normal; it takes time to understand
    it conceptually, especially in three or more dimensions. For a more detailed explanation
    of the concept, take time to read the related article in the official documentation:
    [https://numpy.org/doc/stable/user/basics.broadcasting.html](https://numpy.org/doc/stable/user/basics.broadcasting.html).'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这听起来复杂或令人困惑，那是正常的；在概念上理解它需要时间，特别是在三维或更高维度中。要详细了解这个概念，请花时间阅读官方文档中相关文章的详细解释：[https://numpy.org/doc/stable/user/basics.broadcasting.html](https://numpy.org/doc/stable/user/basics.broadcasting.html)。
- en: Aggregating arrays – sum, min, max, mean, and so on
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚合数组 - 求和、最小值、最大值、均值等等
- en: 'When working with arrays, we often need to summarize the data to extract some
    meaningful statistics: the mean, the minimum, the maximum, and so on. Fortunately,
    NumPy also provides those operations natively. Quite simply, they are provided
    as methods that you can call directly from an array:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数组时，我们经常需要汇总数据以提取一些有意义的统计信息：均值、最小值、最大值等。幸运的是，NumPy也提供了这些操作的本地支持。简单来说，它们被提供为您可以直接从数组调用的方法：
- en: '[PRE29]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You can find the whole list of aggregating operations in the official documentation:
    [https://numpy.org/doc/stable/reference/arrays.ndarray.html#calculation](https://numpy.org/doc/stable/reference/arrays.ndarray.html#calculation).'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在官方文档中找到所有聚合操作的完整列表：[https://numpy.org/doc/stable/reference/arrays.ndarray.html#calculation](https://numpy.org/doc/stable/reference/arrays.ndarray.html#calculation)。
- en: Comparing arrays
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比较数组
- en: 'NumPy also implements the standard comparison operators to compare arrays.
    As with arithmetic operators, which we saw in the *Adding and multipl**ying* *arrays*
    section, broadcasting rules apply. This means that you can compare an array with
    a single value:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 也实现了标准的比较运算符来比较数组。与我们在*加法和乘法*数组部分看到的算术运算符一样，广播规则适用。这意味着你可以将数组与单个值进行比较：
- en: '[PRE30]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'And you can also compare arrays with arrays, given that they are compatible
    on the basis of the broadcasting rules:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将数组与数组进行比较，前提是它们在广播规则的基础上兼容：
- en: '[PRE31]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The resulting array is filled with the Boolean result of the comparison for
    each element.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 结果数组会填充每个元素的布尔比较结果。
- en: 'That’s it for this very quick introduction to NumPy. There is a lot more to
    know and discover with this library, so we strongly encourage you to read the
    official user guide: [https://numpy.org/doc/stable/user/index.html](https://numpy.org/doc/stable/user/index.html).'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是对 NumPy 的简短介绍。这个库有很多内容值得学习和探索，因此我们强烈建议你阅读官方用户指南：[https://numpy.org/doc/stable/user/index.html](https://numpy.org/doc/stable/user/index.html)。
- en: 'For the rest of this book, this should be enough for you to understand future
    examples. Let’s now have a look at a library often cited and used alongside NumPy:
    pandas.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本书的其余部分，这些内容应该足以帮助你理解未来的示例。现在，让我们来看看一个与 NumPy 一起常被引用和使用的库：pandas。
- en: Getting started with pandas
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用 pandas
- en: 'In the previous section, we introduced NumPy and its ability to efficiently
    store and work with a large array of data. We’ll now introduce another widely
    used library in data science: pandas. This library is built on top of NumPy to
    provide convenient data structures able to efficiently store large datasets with
    *labeled rows and columns*. This is, of course, especially handy when working
    with most datasets representing real-world data that we want to analyze and use
    in data science projects.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们介绍了 NumPy 及其高效存储和处理大量数据的能力。接下来，我们将介绍另一个在数据科学中广泛使用的库：pandas。这个库是建立在 NumPy
    之上的，提供了方便的数据结构，能够高效存储带有*标签的行和列*的大型数据集。这当然在处理大多数代表现实世界数据的数据集时非常有用，尤其是在数据科学项目中进行分析和使用时。
- en: 'To get started, we will, of course, install the library with the usual command:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始使用，当然，我们需要通过常见的命令安装这个库：
- en: '[PRE32]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Once done, we can start to use it in a Python interpreter:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，我们可以开始在 Python 解释器中使用它：
- en: '[PRE33]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Just like we alias `numpy` as `np`, the convention is to alias `pandas` as `pd`
    when importing it.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们将 `numpy` 别名为 `np` 一样，导入 `pandas` 时的约定是将其别名为 `pd`。
- en: Using pandas Series for one-dimensional data
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 pandas Series 处理一维数据
- en: 'The first pandas data structure we’ll introduce is `Series`. This data structure
    behaves very similarly to a one-dimensional array in NumPy. To create one, we
    can simply initialize it with a list of values:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍的第一个 pandas 数据结构是 `Series`。这个数据结构在行为上与 NumPy 中的一维数组非常相似。要创建一个，我们只需用一个值的列表进行初始化：
- en: '[PRE34]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Under the hood, pandas creates a NumPy array. As such, it uses the same data
    types to store the data. You can verify this by accessing the `values` property
    of the `Series` object and checking its type:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，pandas 创建了一个 NumPy 数组。因此，它使用相同的数据类型来存储数据。你可以通过访问 `Series` 对象的 `values` 属性并检查其类型来验证这一点：
- en: '[PRE35]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Indexing and slicing work exactly the same way as in NumPy:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 索引和切片的工作方式与 NumPy 完全相同：
- en: '[PRE36]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'So far, this is not very different from a regular NumPy array. As we said,
    the main purpose of pandas is to *label the data*. To allow this, pandas data
    structures maintain an index to allow this data labeling. It is accessible through
    the `index` property:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，这与常规的 NumPy 数组没有太大区别。如我们所说，pandas 的主要目的是*标注数据*。为了实现这一点，pandas 数据结构维护一个索引来实现数据标注。可以通过
    `index` 属性来访问：
- en: '[PRE37]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Here, we have a simple range integer index, but we can actually have any arbitrary
    index. In the next example, we create the same series, labeling each value with
    a letter:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了一个简单的整数范围索引，但实际上我们可以使用任何自定义索引。在下一个示例中，我们创建了相同的 series，并用字母标注每个值：
- en: '[PRE38]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The `index` argument on the `Series` initializer allows us to set the list
    of labels. We can now access values with those labels instead:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`Series` 初始化器中的 `index` 参数允许我们设置标签列表。现在我们可以使用这些标签来访问相应的值：'
- en: '[PRE39]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Surprisingly, even slicing notation works with those kinds of labels:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 惊人的是，甚至切片符号也可以与这些标签一起使用：
- en: '[PRE40]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Under the hood, pandas keep the order of the index to allow such useful notations.
    Notice, however, that with this notation, the *last index is inclusive* (`d` is
    included in the result), unlike standard index notation, where the last index
    is exclusive:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，pandas 保留了索引的顺序，以便进行这样的有用标记。然而，请注意，在这种符号中，*最后一个索引是包括在内的*（`d` 包含在结果中），这与标准的索引符号不同，后者的最后一个索引是排除在外的：
- en: '[PRE41]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'To avoid confusion between those two styles, pandas exposes two special notations
    to explicitly indicate which indexing style you wish to use: `loc` (label notation
    with the last index being inclusive) and `iloc` (standard index notation). You
    can read more about this in the official documentation: [https://pandas.pydata.org/docs/user_guide/indexing.html#different-choices-for-indexing](https://pandas.pydata.org/docs/user_guide/indexing.html#different-choices-for-indexing).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这两种风格的混淆，pandas 提供了两种特殊符号，明确表示你希望使用的索引风格：`loc`（标签符号，最后一个索引包括在内）和 `iloc`（标准索引符号）。你可以在官方文档中阅读更多内容：[https://pandas.pydata.org/docs/user_guide/indexing.html#different-choices-for-indexing](https://pandas.pydata.org/docs/user_guide/indexing.html#different-choices-for-indexing)。
- en: '`Series` can also be instantiated directly from dictionaries:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`Series` 也可以直接通过字典来实例化：'
- en: '[PRE42]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In this case, the keys of the dictionaries are used as labels.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，字典的键用作标签。
- en: Of course, in the real world, you’ll more likely have to work with two-dimensional
    (or more!) datasets. This is exactly what DataFrames are for!
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在实际工作中，你更可能需要处理二维（或更多！）数据集。这正是 DataFrame 的用途！
- en: Using pandas DataFrames for multi-dimensional data
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 pandas DataFrame 处理多维数据
- en: Most of the time, datasets consist of two-dimensional data, where you have several
    columns for each row, as in a classic spreadsheet application. In Pandas, DataFrames
    are designed to work with this kind of data. As for `Series`, it can work with
    a large set of data that is labeled both by rows and columns.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，数据集由二维数据组成，其中每一行有多个列，就像经典的电子表格应用程序一样。在 Pandas 中，DataFrame 是专为处理这类数据设计的。至于
    `Series`，它可以处理由行和列都标注的大量数据集。
- en: 'The following examples will use a tiny dataset representing the number of tickets
    (paid and free) delivered in French museums in 2018\. Let’s consider we have this
    data in the form of two dictionaries:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例将使用一个小型数据集，表示 2018 年法国博物馆发放的票务数量（包括付费票和免费票）。假设我们有以下以两个字典形式存储的数据：
- en: '[PRE43]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Each key in those dictionaries is a label for a row. We can build a DataFrame
    directly from those two dictionaries like this:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这些字典中的每个键都是行的标签。我们可以直接从这两个字典构建一个 DataFrame，方法如下：
- en: '[PRE44]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The `DataFrame` initializer accepts a dictionary of dictionaries, where keys
    represent the label for the columns.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataFrame` 初始化器接受一个字典的字典，其中键表示列的标签。'
- en: 'We can have a look at the `index` property, storing the rows index, and the
    `columns` property, storing the columns index:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看 `index` 属性，它存储了行的索引，以及 `columns` 属性，它存储了列的索引：
- en: '[PRE45]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Once again, we can now use indexing and slicing notation to get subsets of
    columns or rows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以再次使用索引和切片符号来获取列或行的子集：
- en: '[PRE46]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Something that is even more powerful: you can write a Boolean condition inside
    the brackets to match some data. This operation is called **masking**:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 更强大的功能是：你可以在括号内写一个布尔条件来匹配某些数据。这种操作称为 **掩码操作**：
- en: '[PRE47]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Finally, you can easily set new columns with this very same indexing notation:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以通过相同的索引符号轻松设置新的列：
- en: '[PRE48]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: As you can see, just like NumPy arrays, pandas fully supports arithmetic operations
    over two DataFrames.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，就像 NumPy 数组一样，pandas 完全支持在两个 DataFrame 上执行算术运算。
- en: 'Of course, all the basic aggregation operations are supported, including `mean`
    and `sum`:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，所有基本的聚合操作都被支持，包括 `mean` 和 `sum`：
- en: '[PRE49]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'You can find the whole list of operations available in the official documentation:
    [https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#descriptive-statistics](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#descriptive-statistics).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在官方文档中找到所有可用操作的完整列表：[https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#descriptive-statistics](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#descriptive-statistics)。
- en: Importing and exporting CSV data
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入和导出 CSV 数据
- en: 'One very common way of sharing datasets is through CSV files. This format is
    very convenient because it only consists of a simple text file, each line representing
    a row of data, with each column separated by a comma. Our simple *museums* dataset
    is available in the examples repository as a CSV file, which you can see in the
    next sample:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 分享数据集的一种非常常见的方式是通过 CSV 文件。这个格式非常方便，因为它只是一个简单的文本文件，每一行代表一行数据，每一列由逗号分隔。我们的简单 *museums*
    数据集作为 CSV 文件在示例库中提供，你可以在下一个示例中看到：
- en: museums.csv
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: museums.csv
- en: '[PRE50]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/museums.csv](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/museums.csv)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/museums.csv](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/museums.csv)'
- en: 'Importing CSV files is so common that pandas provides a function to load a
    CSV file into a DataFrame directly:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 CSV 文件是如此常见，以至于 pandas 提供了一个函数，可以直接将 CSV 文件加载到 DataFrame 中：
- en: '[PRE51]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The function simply expects the path to the CSV file. Several arguments are
    available to finely control the operation: here, we used `index_col` to specify
    the index of the column that should be used as row labels. You can find the whole
    list of arguments in the official documentation: [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数仅仅需要 CSV 文件的路径。提供了多个参数，可以精细控制操作：在这里，我们使用了 `index_col` 来指定应作为行标签的列的索引。你可以在官方文档中找到所有参数的列表：[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)。
- en: 'Of course, the opposite operation exists to export a DataFrame to a CSV file:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，存在相反的操作来将 DataFrame 导出为 CSV 文件：
- en: '[PRE52]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We will conclude this very quick introduction to pandas here. Of course, we’ve
    only covered the tip of the iceberg, and we recommend that you go through the
    official user guide to know more: [https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html).'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里结束对 pandas 的简短介绍。当然，我们仅仅触及了冰山一角，我们建议你通过官方用户指南了解更多：[https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)。
- en: Still, you should now be able to perform basic operations and operate efficiently
    on large datasets. In the next section, we’ll introduce scikit-learn, one of the
    fundamental Python toolkits for data science, and you’ll see that it relies a
    lot on NumPy and pandas.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，你现在应该能够执行基本操作，并在大型数据集上高效地操作。在下一节中，我们将介绍 scikit-learn，它是数据科学中一个基本的 Python
    工具包，你将看到它在很大程度上依赖于 NumPy 和 pandas。
- en: Training models with scikit-learn
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 训练模型
- en: scikit-learn is one of the most widely used Python libraries for data science.
    It implements dozens of classic ML models, but also numerous tools to help you
    while training them, such as preprocessing methods and cross-validation. Nowadays,
    you’ll probably hear about more modern approaches, such as PyTorch, but scikit-learn
    is still a solid tool for a lot of use cases.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 是最广泛使用的 Python 数据科学库之一。它实现了数十种经典的机器学习模型，还提供了许多在训练过程中帮助你的工具，比如预处理方法和交叉验证。如今，你可能会听到更多现代方法的讨论，比如
    PyTorch，但 scikit-learn 仍然是许多用例中一个可靠的工具。
- en: 'The first thing you must do to get started is to install it in your Python
    environment:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 开始之前，首先需要在你的 Python 环境中安装它：
- en: '[PRE53]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: We can now start our scikit-learn journey!
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始我们的 scikit-learn 之旅！
- en: Training models and predicting
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练模型与预测
- en: In scikit-learn, ML models and algorithms are called `fit`, which is used to
    train a model, and `predict`, which is used to run the trained model on new data.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在 scikit-learn 中，机器学习模型和算法被称为 `fit`，用于训练模型，以及 `predict`，用于在新数据上运行训练好的模型。
- en: 'To try this, we’ll load a sample dataset. scikit-learn comes with a few toy
    datasets that are very useful for performing experiments. You can find out more
    about them in the official documentation: [https://scikit-learn.org/stable/datasets.html](https://scikit-learn.org/stable/datasets.html).'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 要尝试这个，我们将加载一个示例数据集。scikit-learn 附带了一些非常有用的玩具数据集，适合用于实验。你可以在官方文档中了解更多信息：[https://scikit-learn.org/stable/datasets.html](https://scikit-learn.org/stable/datasets.html)。
- en: 'Here, we’ll use the *digits* dataset, a collection of pixel matrices representing
    handwritten digits. As you may have guessed, the goal of this dataset is to train
    a model to automatically recognize handwritten digits. The following example shows
    how to load this dataset:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用*digits*数据集，这是一个包含表示手写数字的像素矩阵的集合。正如你可能已经猜到的，这个数据集的目标是训练一个模型来自动识别手写数字。以下示例展示了如何加载这个数据集：
- en: chapter11_load_digits.py
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: chapter11_load_digits.py
- en: '[PRE54]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_load_digits.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_load_digits.py)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_load_digits.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_load_digits.py)'
- en: Notice that the toy dataset’s functions are imported from the `datasets` package
    of scikit-learn. The `load_digits` function returns an object that contains the
    data and some metadata.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个玩具数据集的函数是从scikit-learn的`datasets`包中导入的。`load_digits`函数返回一个包含数据和一些元数据的对象。
- en: The most interesting parts of this object are `data`, which contains the handwritten
    digit pixels matrices, and `targets`, which contains the corresponding label for
    those digits. Both are NumPy arrays.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这个对象最有趣的部分是`data`，它包含了手写数字的像素矩阵，以及`targets`，它包含了这些数字的对应标签。两者都是NumPy数组。
- en: To get a grasp of what this looks like, we will take the first digit in the
    data and reshape it into an 8 x 8 matrix; this is the size of the source images.
    Each value represents a pixel on a grayscale, from 0 to 16.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解这是什么样子，我们将数据中的第一个数字提取出来，并将其重新塑造成一个8 x 8的矩阵；这是源图像的大小。每个值表示一个灰度像素，从0到16。
- en: 'Then, we print the label of this first digit, which is `0`. If you run this
    code, you’ll get the following output:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们打印出第一个数字的标签，即`0`。如果你运行这段代码，你将得到以下输出：
- en: '[PRE55]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Somehow, we can guess the shape of the zero from the matrix.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 通过矩阵，我们可以在某种程度上猜测出零的形状。
- en: 'Now, let’s try to build a model that recognizes handwritten digits. To start
    simple, we’ll use a Gaussian Naive Bayes model, a classic and easy-to-use algorithm
    that can quickly yield good results. The following example shows the entire process:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试构建一个识别手写数字的模型。为了简单起见，我们将使用高斯朴素贝叶斯模型，这是一种经典且易于使用的算法，能够快速得到不错的结果。以下示例展示了整个过程：
- en: chapter11_fit_predict.py
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: chapter11_fit_predict.py
- en: '[PRE56]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_fit_predict.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_fit_predict.py)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_fit_predict.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_fit_predict.py)'
- en: Now that we’ve loaded the dataset, you can see that we take care of splitting
    it into a training and a testing set. As we mentioned in the *Model validation*
    section, this is essential for computing meaningful accuracy scores to check how
    our model performs.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经加载了数据集，你可以看到我们已将其拆分为训练集和测试集。正如我们在*模型验证*部分提到的，这对于计算有意义的准确性评分是必不可少的，以检查我们的模型表现如何。
- en: 'To do this, we can rely on the `train_test_split` function, which is provided
    in the `model_selection` package. It selects random instances from our dataset
    to form the two sets. By default, it keeps 25% of the data to create a testing
    set, but this can be customized. The `random_state` argument allows us to set
    the random seed to make the example reproducible. You can find out more about
    this function in the official documentation: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn-model-selection-train-test-split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn-model-selection-train-test-split).'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们可以依赖`model_selection`包中的`train_test_split`函数。它从我们的数据集中随机选择实例来形成这两个数据集。默认情况下，它将25%的数据保留为测试集，但这可以自定义。`random_state`参数允许我们设置随机种子，以使示例具有可复现性。你可以在官方文档中了解更多关于此函数的信息：[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn-model-selection-train-test-split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn-model-selection-train-test-split)。
- en: Then, we must instantiate the `GaussianNB` class. This class is one of the numerous
    ML estimators that’s implemented in scikit-learn. Each has its own set of parameters,
    to finely tune the behavior of the algorithm. However, scikit-learn is designed
    to provide sensible defaults for all the estimators, so it’s usually good to start
    with the defaults before tinkering with them.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须实例化`GaussianNB`类。这个类是scikit-learn中许多机器学习估计器之一。每个估计器都有自己的一组参数，用于精细调节算法的行为。然而，scikit-learn设计时已经为所有估计器提供了合理的默认值，因此通常建议在进行调试之前先使用默认值。
- en: 'After that, we must call the `fit` method to train our model. It expects an
    argument and two arrays: the first one is the actual data, with all its features,
    while the second one is the corresponding labels. And that’s it! You’ve trained
    your first ML model!'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们必须调用`fit`方法来训练我们的模型。它需要一个参数和两个数组：第一个是实际数据，包含所有特征，第二个是相应的标签。就这样！你已经训练好了你的第一个机器学习模型！
- en: 'Now, let’s see how it behaves: we’ll call `predict` on our model with the testing
    set so that it automatically classifies the digits of the testing set. The result
    of this is a new array with the predicted labels.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看它的表现：我们将用测试集调用模型的`predict`方法，以便它自动分类测试集中的数字。结果将是一个包含预测标签的新数组。
- en: All we have to do now is compare it with the actual labels of our testing set.
    Once again, scikit-learn helps by providing the `accuracy_score` function in the
    `metrics` package. The first argument is the true labels, while the second is
    the predicted labels.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要做的就是将其与测试集的实际标签进行比较。再次，scikit-learn通过在`metrics`包中提供`accuracy_score`函数来提供帮助。第一个参数是实际标签，第二个是预测标签。
- en: If you run this code, you’ll get an accuracy score of around 83%. That isn’t
    too bad for a first approach! As you have seen, training and running prediction
    on an ML model is straightforward with scikit-learn.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行这段代码，你将得到大约83%的准确率。作为初步的尝试，这已经相当不错了！正如你所见，使用scikit-learn训练和运行机器学习模型的预测非常简单。
- en: 'In practice, we often need to perform preprocessing steps on the data before
    feeding it to an estimator. Rather than doing this sequentially by hand, scikit-learn
    proposes a convenient feature that can automate this process: **pipelines**.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们常常需要在将数据输入估计器之前，先对数据进行预处理。为了避免手动按顺序执行这些步骤，scikit-learn提出了一个便捷的功能，可以自动化这个过程：**管道**。
- en: Chaining preprocessors and estimators with pipelines
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用管道链式连接预处理器和估计器
- en: Quite often, you’ll need to preprocess your data so that it can be used by the
    estimator you wish to use. Typically, you’ll want to transform an image into an
    array of pixel values or, as we’ll see in the following example, transform raw
    text into numerical values so that we can apply some math to them.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 很多时候，你需要对数据进行预处理，以便它可以被你希望使用的估计器所使用。通常，你会希望将图像转换为像素值的数组，或者正如我们在下一个例子中看到的那样，将原始文本转换为数值，以便我们可以对其进行数学处理。
- en: 'Rather than writing those steps by hand, scikit-learn proposes a feature that
    can automatically chain preprocessors and estimators: pipelines. Once created,
    they expose the very same interface as any other estimator, allowing you to run
    training and prediction in one operation.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免手动编写这些步骤，scikit-learn提供了一个功能，可以自动链式连接预处理器和估计器：管道。一旦创建，它们会暴露出与任何其他估计器相同的接口，允许你在一次操作中进行训练和预测。
- en: To show you what this looks like, we’ll look at an example of another classic
    dataset, the *20 newsgroups* text dataset. It consists of 18,000 newsgroup articles
    categorized into 20 topics. The goal of this dataset is to build a model that
    will automatically categorize an article in one of those topics.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示这是什么样的，我们来看一个经典数据集的例子——*20 newsgroups*文本数据集。它包含18,000篇新闻组文章，分类为20个主题。这个数据集的目标是构建一个模型，自动将文章归类到其中一个主题。
- en: 'The following example shows how we can load this data thanks to the `fetch_20newsgroups`
    function:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了我们如何利用`fetch_20newsgroups`函数加载该数据：
- en: chapter11_pipelines.py
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: chapter11_pipelines.py
- en: '[PRE57]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py)'
- en: 'Since the dataset is rather large, we’ll only load a subset of the categories.
    Also, notice that it’s already been split into training and testing sets, so we
    only have to load them with the corresponding argument. You can find out more
    about the functionality of this dataset in the official documentation: [https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset).'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集相当大，我们只加载一部分类别。此外，请注意，数据集已经被拆分为训练集和测试集，因此我们只需通过相应的参数加载它们。你可以在官方文档中了解更多关于此数据集的功能：[https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset)。
- en: 'Before moving on, it’s important to understand what the underlying data is.
    Actually, this is the raw text of an article. You can check this by printing one
    of the samples in the data:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，理解底层数据非常重要。实际上，这些是文章的原始文本。你可以通过打印数据中的一个样本来检查这一点：
- en: '[PRE58]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'So, we need to extract some features from this text before feeding it to an
    estimator. A common approach for this when working with textual data is to use
    the **Term Frequency-Inverse Document Frequency (TF-IDF)**. Without going into
    too much detail, this technique will count the occurrences of each word in all
    the documents (term frequency), weighted by the importance of this word in every
    document (inverse document frequency). The idea is to give more weight to rarer
    words, which should convey more sense than frequent words such as “the.” You can
    find out more about this in the scikit-learn documentation: [https://scikit-learn.org/dev/modules/feature_extraction.html#tfidf-term-weighting](https://scikit-learn.org/dev/modules/feature_extraction.html#tfidf-term-weighting).'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在将文本输入到估算器之前，我们需要从中提取一些特征。当处理文本数据时，常用的一种方法是使用**词频-逆文档频率（TF-IDF）**。不深入细节，这项技术将计算每个单词在所有文档中的出现次数（词频），并根据该单词在每个文档中的重要性加权（逆文档频率）。其目的是赋予较少出现的单词更高的权重，这些单词比“the”这类常见单词更有意义。你可以在scikit-learn文档中了解更多相关信息：[https://scikit-learn.org/dev/modules/feature_extraction.html#tfidf-term-weighting](https://scikit-learn.org/dev/modules/feature_extraction.html#tfidf-term-weighting)。
- en: This operation consists of splitting each word in the text samples and counting
    them. Usually, we apply a lot of techniques to refine this, such as removing `TfidfVectorizer`.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作包括将文本样本中的每个单词分开并进行计数。通常，我们会应用许多技术来精细化这个过程，例如移除 `TfidfVectorizer`。
- en: 'This preprocessor can take an array of text, tokenize each word, and compute
    the TF-IDF for each of them. A lot of options are available for finely tuning
    its behavior, but the defaults are a good start for English text. The following
    example shows how to use it with an estimator in a pipeline:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这个预处理器可以接收一个文本数组，对每个单词进行分词，并计算每个单词的TF-IDF。提供了很多选项来精细调整其行为，但默认设置对于英文文本来说已经是一个不错的起点。以下示例展示了如何在管道中将其与估算器一起使用：
- en: chapter11_pipelines.py
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: chapter11_pipelines.py
- en: '[PRE59]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py)'
- en: The `make_pipeline` function accepts any number of preprocessors and an estimator
    in its argument. Here, we’re using the Multinomial Naive Bayes classifier, which
    is suitable for features representing frequency.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '`make_pipeline` 函数接受任意数量的预处理器和一个估算器作为参数。在这里，我们使用的是多项式朴素贝叶斯分类器，这适用于表示频率的特征。'
- en: 'Then, we can simply train our model and run prediction to check its accuracy,
    as we did previously. You can see this in the following example:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以像之前那样简单地训练我们的模型并运行预测来检查其准确性。你可以在以下示例中看到这一点：
- en: chapter11_pipelines.py
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: chapter11_pipelines.py
- en: '[PRE60]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py)'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_pipelines.py)'
- en: 'Notice that we also printed a confusion matrix, which is a very convenient
    representation of the global results. Scikit-learn has a dedicated function for
    this called `confusion_matrix`. Then, we wrap the result in a pandas DataFrame
    so that we can set the axis labels to improve readability. If you run this example,
    you’ll get an output similar to what’s shown in the following screenshot. Depending
    on your machine and system, it could take a couple of minutes to run:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们还打印了一个混淆矩阵，这是一个非常方便的全局结果表示。scikit-learn有一个专门的函数叫做`confusion_matrix`。然后，我们将结果包装在pandas
    DataFrame中，以便可以设置轴标签以提高可读性。如果你运行这个例子，你将获得类似于以下截图的输出。根据你的机器和系统，可能需要几分钟时间才能完成：
- en: '![Figure 11.3 – Confusion matrix on the 20 newsgroups dataset](img/Figure_11.3_B19528.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![图11.3 – 20个新闻组数据集的混淆矩阵](img/Figure_11.3_B19528.jpg)'
- en: Figure 11.3 – Confusion matrix on the 20 newsgroups dataset
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3 – 20个新闻组数据集的混淆矩阵
- en: Here, you can see that our results weren’t too bad for our first try. Notice
    that there is one big area of confusion between the `soc.religion.christian` and
    `talk.religion.misc` categories, which is not very surprising, given their similarity.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到我们第一次尝试的结果并不差。请注意，`soc.religion.christian`和`talk.religion.misc`类别之间存在一个较大的混淆区域，这并不令人意外，考虑到它们的相似性。
- en: As you’ve seen, building a pipeline with a preprocessor is very straightforward.
    The nice thing about this is that it automatically applies it to the training
    data, but also when you’re predicting the results.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，构建一个带有预处理器的流水线非常简单。这样做的好处是，它不仅会自动应用于训练数据，也会在你预测结果时使用。
- en: 'Before moving on, let’s look at one more important feature of scikit-learn:
    cross-validation.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们来看一下scikit-learn的另一个重要功能：交叉验证。
- en: Validating the model with cross-validation
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用交叉验证验证模型
- en: In the *Model validation* section, we introduced the cross-validation technique,
    which allows us to use data in training or testing sets. As you may have guessed,
    this technique is so common that it’s implemented natively in scikit-learn!
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在*模型验证*部分，我们介绍了交叉验证技术，它允许我们在训练集或测试集中使用数据。正如你可能猜到的，这项技术非常常见，scikit-learn本身就实现了它！
- en: 'Let’s take another look at the handwritten digit example and apply cross-validation:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一个手写数字的例子，并应用交叉验证：
- en: chapter11_cross_validation.py
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: chapter11_cross_validation.py
- en: '[PRE61]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_cross_validation.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_cross_validation.py)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_cross_validation.py](https://github.com/PacktPublishing/Building-Data-Science-Applications-with-FastAPI-Second-Edition/tree/main/chapter11/chapter11_cross_validation.py)'
- en: 'This time, we don’t have to split the data ourselves: the `cross_val_score`
    function performs the folds automatically. In argument, it expects the estimator,
    `data`, which contains the handwritten digits’ pixels matrices, and `targets`,
    which contains the corresponding label for those digits. By default, it performs
    five folds.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们不需要自己拆分数据：`cross_val_score`函数会自动执行折叠。在参数中，它期望接收估算器、`data`（包含手写数字的像素矩阵）和`targets`（包含这些数字的对应标签）。默认情况下，它会执行五次折叠。
- en: 'The result of this operation is an array that provides the accuracy score of
    the five folds. To get a global overview of this result, we can take, for example,
    the mean. If you run this example, you’ll get the following output:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作的结果是一个数组，提供了五次折叠的准确度分数。为了获取这些结果的整体概览，我们可以取平均值。例如，如果你运行这个例子，你将获得以下输出：
- en: '[PRE62]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'As you can see, our mean accuracy is around 80%, which is a bit lower than
    the 83% we obtained with single training and testing sets. That’s the main benefit
    of cross-validation: we obtain a more statistically accurate metric regarding
    the performance of our model.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们的平均准确率大约是80%，比我们使用单一训练集和测试集时获得的83%稍低。这就是交叉验证的主要好处：我们能获得更为统计准确的模型性能指标。
- en: With that, you have learned the basics of working with scikit-learn. It’s obviously
    a very quick introduction to this vast framework, but it’ll give you the keys
    to train and evaluate your first ML models.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些，你已经学习了使用scikit-learn的基础知识。显然，这是对这个庞大框架的一个快速介绍，但它将为你提供训练和评估第一个机器学习模型的钥匙。
- en: Summary
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'Congratulations! You’ve discovered the basic concepts of ML and made your first
    experiments with the fundamental toolkits of the data scientist. Now, you should
    be able to explore your first data science problems in Python. Of course, this
    was by no means a complete lesson on ML: the field is vast and there are tons
    of algorithms and techniques to explore. However, I hope that this has sparked
    your curiosity and that you’ll deepen your knowledge of this subject.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经掌握了机器学习的基本概念，并用数据科学家的基础工具包进行了第一次实验。现在，你应该能够在Python中探索你的第一个数据科学问题。当然，这绝不是一节完整的机器学习课程：这个领域广阔，还有大量的算法和技术等待探索。不过，我希望这已经激发了你的好奇心，并且你会深入学习这个领域的知识。
- en: Now, it’s time to get back to FastAPI! With our new ML tools at hand, we’ll
    be able to leverage the power of FastAPI to serve our estimators and propose a
    reliable and efficient prediction API to our users.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候回到FastAPI了！借助我们手头的新ML工具，我们将能够利用FastAPI的强大功能来服务我们的估算器，并为用户提供一个可靠高效的预测API。
