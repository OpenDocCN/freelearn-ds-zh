- en: Predictive Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测模型
- en: In this chapter, we're going to look at what predictive modeling is and how
    it uses statistics to predict outcomes from existing data. We'll cover real world
    examples to understand the concepts better. We'll see what regression analysis
    means and analyze some of its forms in detail. We'll also look at an example which
    predicts the price of a car for us.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨预测建模是什么，以及它如何使用统计数据来预测现有数据的结果。我们将涵盖现实世界的例子，以更好地理解这些概念。我们将了解回归分析的含义，并详细分析其中的一些形式。我们还将看一个预测汽车价格的例子。
- en: 'These are the topics that we''ll cover in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是本章中我们将涵盖的主题：
- en: Linear regression and how to implement it in Python
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归及其在Python中的实现方式
- en: Polynomial regression, its application and examples
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式回归，其应用和示例
- en: Multivariate regression and how to implement it in Python
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多元回归及其在Python中的实现方式
- en: An example we'll build that predicts the price of a car using Python
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将构建一个使用Python预测汽车价格的示例
- en: The concept of multi-level models and some things to know about them
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多层模型的概念和一些需要了解的内容
- en: Linear regression
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归
- en: Let's talk about regression analysis, a very popular topic in data science and
    statistics. It's all about trying to fit a curve or some sort of function, to
    a set of observations and then using that function to predict new values that
    you haven't seen yet. That's all there is to linear regression!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈回归分析，这是数据科学和统计学中非常流行的话题。它的核心是试图将曲线或某种函数拟合到一组观察结果中，然后使用该函数来预测你尚未见过的新值。这就是线性回归的全部内容！
- en: 'So, linear regression is fitting a straight line to a set of observations.
    For example, let''s say that I have a bunch of people that I measured and the
    two features that I measured of these people are their weight and their height:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，线性回归是将一条直线拟合到一组观察结果中。例如，假设我测量了一群人，我测量的两个特征是他们的体重和身高：
- en: '![](img/0c9e8d83-c2cb-419a-a681-48b1790465ed.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0c9e8d83-c2cb-419a-a681-48b1790465ed.png)'
- en: I'm showing the weight on the *x*-axis and the height on the *y*-axis, and I
    can plot all these data points, as in the people's weight versus their height,
    and I can say, "Hmm, that looks like a linear relationship, doesn't it? Maybe
    I can fit a straight line to it and use that to predict new values", and that's
    what linear regression does. In this example, I end up with a slope of 0.6 and
    a *y*-intercept of 130.2 which define a straight line (the equation of a straight
    line is *y=mx+b*, where m is the slope and b is the *y*-intercept). Given a slope
    and a *y*-intercept, that fits the data that I have best, I can use that line
    to predict new values.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我在*x*轴上显示了体重，*y*轴上显示了身高，我可以绘制所有这些数据点，就像人们的体重与身高一样，我可以说，“嗯，这看起来像是一个线性关系，不是吗？也许我可以拟合一条直线并用它来预测新值”，这就是线性回归的作用。在这个例子中，我得到了斜率为0.6和*y*截距为130.2，这定义了一条直线（一条直线的方程是*y=mx+b*，其中m是斜率，b是*y*截距）。给定一个斜率和一个*y*截距，最能适应我拥有的数据，我可以使用这条线来预测新值。
- en: You can see that the weights that I observed only went up to people that weighed
    100 kilograms. What if I had someone who weighed 120 kilograms? Well, I could
    use that line to then figure out where would the height be for someone with 120
    kilograms based on this previous data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我观察到的重量只涵盖了重100公斤的人。如果我有一个重120公斤的人怎么办？嗯，我可以使用这条线来计算基于先前数据的120公斤的人的身高。
- en: I don't know why they call it regression. Regression kind of implies that you're
    doing something backwards. I guess you can think of it in terms of you're creating
    a line to predict new values based on observations you made in the past, backwards
    in time, but it seems like a little bit of a stretch. It's just a confusing term
    quite honestly, and one way that we kind of obscure what we do with very simple
    concepts using very fancy terminology. All it is, is fitting a straight line to
    a set of data points.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我不知道为什么他们称之为回归。回归有点意味着你在做一些事情。我猜你可以把它看作是在根据你过去的观察结果创建一条线来预测新值，时间上倒退，但这似乎有点牵强。说实话，这只是一个令人困惑的术语，我们用非常花哨的术语来掩盖我们用非常简单的概念做的事情的一种方式。它只是将一条直线拟合到一组数据点。
- en: The ordinary least squares technique
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 普通最小二乘法技术
- en: How does linear regression work? Well internally, it uses a technique called
    ordinary least squares; it's also known as, OLS. You might see that term tossed
    around as well. The way it works is it tries to minimize the squared error between
    each point and the line, where the error is just the distance between each point
    and the line that you have.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是如何工作的？在内部，它使用一种称为普通最小二乘法的技术；它也被称为OLS。你可能也会看到这个术语被提及。它的工作方式是试图最小化每个点与直线之间的平方误差，其中误差只是每个点与你所拥有的直线之间的距离。
- en: 'So, we sum up all the squares of those errors, which sounds a lot like when
    we computed variance, right, except that instead of relative to the mean, it''s
    relative to the line that we''re defining. We can measure the variance of the
    data points from that line, and by minimizing that variance, we can find the line
    that fits it the best:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们总结了所有这些错误的平方和，这听起来很像我们计算方差时的情况，对吧，只是不是相对于均值，而是相对于我们定义的直线。我们可以测量数据点相对于该直线的方差，并通过最小化该方差，我们可以找到最适合的直线：
- en: '![](img/4afbc931-a14b-4756-99f7-936312f2fd71.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4afbc931-a14b-4756-99f7-936312f2fd71.png)'
- en: Now you'll never have to actually do this yourself the hard way, but if you
    did have to for some reason, or if you're just curious about what happens under
    the hood, I'll now describe the overall algorithm for you and how you would actually
    go about computing the slope and *y*-intercept yourself the hard way if you need
    to one day. It's really not that complicated.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你永远不必自己费力去做这件事，但如果你因某种原因不得不这样做，或者如果你只是好奇发生了什么，我现在会为你描述整体算法，以及如果有一天你需要自己费力计算斜率和*y*截距，你将如何去做。这真的并不复杂。
- en: Remember the slope-intercept equation of a line? It is *y=mx+c*. The slope just
    turns out to be the correlation between the two variables times the standard deviation
    in *Y* divided by the standard deviation in *X*. It might seem a little bit weird
    that standard deviation just kind of creeps into the math naturally there, but
    remember correlation had standard deviation baked into it as well, so it's not
    too surprising that you have to reintroduce that term.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得线的斜率截距方程吗？它是*y=mx+c*。斜率实际上就是两个变量之间的相关性乘以*Y*的标准差除以*X*的标准差。标准差在数学中自然地出现可能看起来有点奇怪，但是记住相关性也包含了标准差，所以不太奇怪你必须重新引入这个术语。
- en: The intercept can then be computed as the mean of the *Y* minus the slope times
    the mean of *X*. Again, even though that's really not that difficult, Python will
    do it all for you, but the point is that these aren't complicated things to run.
    They can actually be done very efficiently.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，截距可以计算为*Y*的平均值减去斜率乘以*X*的平均值。再次强调，尽管这并不是非常困难，Python会为你完成所有计算，但重点是这些并不是难以运行的复杂事情。它们实际上可以非常高效地完成。
- en: Remember that least squares minimize the sum of squared errors from each point
    to the line. Another way of thinking about linear regression is that you're defining
    a line that represents the maximum likelihood of an observation line there; that
    is, the maximum probability of the *y* value being something for a given *x* value.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，最小二乘法最小化了每个点到线的平方误差的总和。另一种思考线性回归的方式是，你正在定义一条代表观察线的最大可能性的线；也就是说，*y*值在给定*x*值时的最大概率。
- en: People sometimes call linear regression maximum likelihood estimation, and it's
    just another example of people giving a fancy name to something that's very simple,
    so if you hear someone talk about maximum likelihood estimation, they're really
    talking about regression. They're just trying to sound really smart. But now you
    know that term too, so you too can sound smart.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有时人们称线性回归为最大似然估计，这只是人们给一个非常简单的东西起了一个花哨的名字的又一个例子，所以如果你听到有人谈论最大似然估计，他们实际上是在谈论回归。他们只是试图显得很聪明。但现在你也知道了这个术语，所以你也可以显得很聪明。
- en: The gradient descent technique
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度下降技术
- en: There is more than one way to do linear regression. We've talked about ordinary
    least squares as being a simple way of fitting a line to a set of data, but there
    are other techniques as well, gradient descent being one of them, and it works
    best in three-dimensional data. So, it tries to follow the contours of the data
    for you. It's very fancy and obviously a little bit more computationally expensive,
    but Python does make it easy for you to try it out if you want to compare it to
    ordinary least squares.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 进行线性回归有多种方法。我们已经谈到了普通最小二乘法是拟合一组数据的简单方法，但也有其他技术，梯度下降就是其中之一，它在三维数据中效果最好。因此，它试图为你跟随数据的轮廓。这非常高级，显然计算成本更高一些，但是Python确实让你很容易地尝试它，如果你想将其与普通最小二乘法进行比较。
- en: Using the gradient descent technique can make sense when dealing with 3D data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用梯度下降技术在处理三维数据时是有意义的。
- en: Usually though, least squares is a perfectly good choice for doing linear regression,
    and it's always a legitimate thing to do, but if you do run into gradient descent,
    you will know that that is just an alternate way of doing linear regression, and
    it's usually seen in higher dimensional data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，最小二乘法是进行线性回归的一个完全合理的选择，它总是一个合法的事情，但是如果你遇到梯度下降，你会知道那只是进行线性回归的另一种方式，通常在更高维度的数据中看到。
- en: The co-efficient of determination or r-squared
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定系数或R平方
- en: So how do I know how good my regression is? How well does my line fit my data?
    That's where r-squared comes in, and r-squared is also known as the coefficient
    of determination. Again, someone trying to sound smart might call it that, but
    usually it's called r-squared.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我如何知道我的回归有多好？我的线对数据的拟合程度如何？这就是R平方的作用，R平方也被称为确定系数。虽然有人可能会试图显得聪明一点，称其为确定系数，但通常被称为R平方。
- en: It is the fraction of the total variation in Y that is captured by your models.
    So how well does your line follow that variation that's happening? Are we getting
    an equal amount of variance on either side of your line or not? That's what r-squared
    is measuring.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 它是你的模型捕捉到的Y的总变化的分数。你的线有多好地跟随了发生的变化？我们在你的线的两侧是否得到了相等数量的变化？这就是R平方在衡量的。
- en: Computing r-squared
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算R平方
- en: 'To actually compute the value, take 1 minus the sum of the squared errors over
    the sum of the squared variations from the mean:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要实际计算该值，取1减去平方误差的总和除以平方变化的总和：
- en: '![](img/7e97b7c8-9a8b-4799-bc49-c804617cc0aa.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7e97b7c8-9a8b-4799-bc49-c804617cc0aa.png)'
- en: So, it's not very difficult to compute, but again, Python will give you functions
    that will just compute that for you, so you'll never have to actually do that
    math yourself.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，计算起来并不是很困难，但是Python会为你提供函数，可以帮你计算，所以你实际上不需要自己进行数学计算。
- en: Interpreting r-squared
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释R平方
- en: For r-squared, you will get a value that ranges from 0 to 1\. Now 0 means your
    fit is terrible. It doesn't capture any of the variance in your data. While 1
    is a perfect fit, where all of the variance in your data gets captured by this
    line, and all of the variance you see on either side of your line should be the
    same in that case. So 0 is bad, and 1 is good. That's all you really need to know.
    Something in between is something in between. A low r-squared value means it's
    a poor fit, a high r-squared value means it's a good fit.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于R平方，你将得到一个从0到1的值。0意味着你的拟合很糟糕。它没有捕捉到数据的任何变化。而1是完美的拟合，数据的所有变化都被这条线捕捉到，你在线的两侧看到的所有变化应该是相同的。所以0是糟糕的，1是好的。这就是你真正需要知道的。介于两者之间的值就是介于两者之间的值。低R平方值意味着拟合很差，高R平方值意味着拟合很好。
- en: As you'll see in the coming sections, there's more than one way to do regression.
    Linear regression is one of them. It's a very simple technique, but there are
    other techniques as well, and you can use r-squared as a quantitative measure
    of how good a given regression is to a set of data points, and then use that to
    choose the model that best fits your data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你将在接下来的部分中看到的，有多种方法可以进行回归。线性回归是其中之一。这是一种非常简单的技术，但也有其他技术，你可以使用R平方作为一个定量的度量来衡量给定回归对一组数据点的拟合程度，然后使用它来选择最适合你的数据的模型。
- en: Computing linear regression and r-squared using Python
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python计算线性回归和R平方
- en: Let's now play with linear regression and actually compute some linear regression
    and r-squared. We can start by creating a little bit of Python code here that
    generates some *random-ish* data that is in fact linearly correlated.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来玩一下线性回归，实际计算一些线性回归和R平方。我们可以从这里创建一些Python代码，生成一些*随机的*数据，实际上是线性相关的。
- en: 'In this example I''m going to fake some data about page rendering speeds and
    how much people purchase, just like a previous example. We''re going to fabricate
    a linear relationship between the amount of time it takes for a website to load
    and the amount of money people spend on that website:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我将捏造一些关于页面渲染速度和人们购买金额的数据，就像之前的例子一样。我们将捏造网站加载所需时间和人们在该网站上花费的金额之间的线性关系：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'All I''ve done here is I''ve made a random, a normal distribution of page speeds
    centered around 3 seconds with a standard deviation of 1 second. I''ve made the
    purchase amount a linear function of that. So, I''m making it 100 minus the page
    speeds plus some normal random distribution around it, times 3\. And if we scatter
    that, we can see that the data ends up looking like this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里所做的只是制作了一个随机的、以3秒为中心的页面速度的正态分布，标准差为1秒。我将购买金额设为它的线性函数。因此，我将它设为100减去页面速度加上一些围绕它的正态随机分布，乘以3。如果我们散点图，我们可以看到数据最终看起来是这样的：
- en: '![](img/ec49842b-65b9-442d-9ce4-5659794c8e28.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec49842b-65b9-442d-9ce4-5659794c8e28.png)'
- en: You can see just by eyeballing it that there's definitely a linear relationship
    going on there, and that's because we did hardcode a real linear relationship
    in our source data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过肉眼观察到确实存在线性关系，这是因为我们在源数据中硬编码了一个真正的线性关系。
- en: 'Now let''s see if we can tease that out and find the best fit line using ordinary
    least squares. We talked about how to do ordinary least squares and linear regression,
    but you don''t have to do any of that math yourself because the SciPy package
    has a `stats` package that you can import:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看是否可以通过最小二乘法找出最佳拟合线。我们讨论了如何进行最小二乘法和线性回归，但你不必自己进行任何数学计算，因为SciPy包有一个`stats`包，你可以导入：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can import `stats` from `scipy`, and then you can just call `stats.linregress()`
    on your two features. So, we have a list of page speeds (`pageSpeeds`) and a corresponding
    list of purchase amounts (`purchaseAmount`). The `linregress()` function will
    give us back a bunch of stuff, including the slope, the intercept, which is what
    I need to define my best fit line. It also gives us the `r_value`, from which
    we can get r-squared to measure the quality of that fit, and a couple of things
    that we''ll talk about later on. For now, we just need slope, intercept, and `r_value`,
    so let''s go ahead and run these. We''ll begin by finding the linear regression
    best fit:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从`scipy`中导入`stats`，然后你可以在你的两个特征上调用`stats.linregress()`。因此，我们有一个页面速度（`pageSpeeds`）的列表和一个相应的购买金额（`purchaseAmount`）的列表。`linregress()`函数将给我们一堆东西，包括斜率、截距，这是我需要定义最佳拟合线的东西。它还给我们`r_value`，从中我们可以得到R平方来衡量拟合的质量，以及一些我们稍后会讨论的东西。现在，我们只需要斜率、截距和`r_value`，所以让我们继续运行这些。我们将从找到线性回归的最佳拟合开始：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This is what your output should look like:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你的输出应该是这样的：
- en: '![](img/d4cdfbe1-90cf-4adf-8a5c-7b3e986dfc7f.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4cdfbe1-90cf-4adf-8a5c-7b3e986dfc7f.png)'
- en: Now the r-squared value of the line that we got back is 0.99, that's almost
    1.0\. That means we have a really good fit, which isn't too surprising because
    we made sure there was a real linear relationship between this data. Even though
    there is some variance around that line, our line captures that variance. We have
    roughly the same amount of variance on either side of the line, which is a good
    thing. It tells us that we do have a linear relationship and our model is a good
    fit for the data that we have.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们得到的线的R平方值是0.99，几乎是1.0。这意味着我们有一个非常好的拟合，这并不太令人惊讶，因为我们确保这些数据之间存在真正的线性关系。即使在该线周围存在一些方差，我们的线也捕捉到了这些方差。我们在线的两侧大致有相同数量的方差，这是一件好事。这告诉我们我们确实有线性关系，我们的模型很适合我们的数据。
- en: 'Let''s plot that line:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们画出那条线：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following is the output to the preceding code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面代码的输出：
- en: '![](img/bbdc1831-fa60-406a-b31c-2da0b56d83bb.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bbdc1831-fa60-406a-b31c-2da0b56d83bb.png)'
- en: This little bit of code will create a function to draw the best fit line alongside
    the data. There's a little bit more Matplotlib magic going on here. We're going
    to make a `fitLine` list and we're going to use the `predict()` function we wrote
    to take the `pageSpeeds`, which is our *x*-axis, and create the Y function from
    that. So instead of taking the observations for amount spent, we're going to find
    the predicted ones just using the `slope` times `x` plus the `intercept` that
    we got back from the `linregress()` call above. Essentially here, we're going
    to do a scatter plot like we did before to show the raw data points, which are
    the observations.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将创建一个函数来绘制最佳拟合线与数据一起。这里有一些Matplotlib的魔法。我们将创建一个`fitLine`列表，并使用我们编写的`predict()`函数来获取`pageSpeeds`（我们的*x*轴），并从中创建Y函数。因此，我们不是使用花费金额的观察值，而是使用`linregress()`调用返回的`斜率`乘以`x`加上`截距`。基本上在这里，我们将做一个散点图，就像我们以前做的那样，来显示原始数据点，即观察值。
- en: 'Then we''re also going to call `plot` on that same `pyplot` instance using
    our `fitLine` that we created using the line equation that we got back, and show
    them all both together. When we do that, it looks like the following graph:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们还将在同一个`pyplot`实例上调用`plot`，使用我们得到的线方程创建的`fitLine`，并将它们一起显示出来。当我们这样做时，图表看起来像下面这样：
- en: '![](img/101f3d47-4ad7-4857-a725-ee4af55c2d9a.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/101f3d47-4ad7-4857-a725-ee4af55c2d9a.png)'
- en: You can see that our line is in fact a great fit for our data! It goes right
    smack down the middle, and all you need to predict new values is this predict
    function. Given a new previously unseen page speed, we could predict the amount
    spent just using the slope times the page speed plus the intercept. That's all
    there is to it, and I think it's great!
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们的直线实际上非常适合我们的数据！它正好位于中间，你只需要使用这个预测函数来预测新值。给定一个新的之前未见过的页面速度，我们可以使用斜率乘以页面速度加上截距来预测花费的金额。就是这么简单，我觉得很棒！
- en: Activity for linear regression
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归的活动
- en: Time now to get your hands dirty. Try increasing the random variation in the
    test data and see if that has any impact. Remember, the r-squared is a measure
    of the fit, of how much do we capture the variance, so the amount of variance,
    well... why don't you see if it actually makes a difference or not.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候动手了。尝试增加测试数据中的随机变化，并查看是否会产生影响。记住，R平方是拟合程度的一个度量，我们捕捉了多少方差，所以方差的数量，嗯...你看看它是否真的有影响。
- en: That's linear regression, a pretty simple concept. All we're doing is fitting
    a straight line to set of observations, and then we can use that line to make
    predictions of new values. That's all there is to it. But why limit yourself to
    a line? There's other types of regression we can do that are more complex. We'll
    explore these next.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是线性回归，一个非常简单的概念。我们所做的就是将一条直线拟合到一组观察结果，然后我们可以使用这条直线来预测新值。就是这么简单。但是为什么要限制自己只使用一条直线呢？我们可以做其他更复杂的回归。我们接下来会探讨这些。
- en: Polynomial regression
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多项式回归
- en: We've talked about linear regression where we fit a straight line to a set of
    observations. Polynomial regression is our next topic, and that's using higher
    order polynomials to fit your data. So, sometimes your data might not really be
    appropriate for a straight line. That's where polynomial regression comes in.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了线性回归，其中我们将一条直线拟合到一组观察结果。多项式回归是我们接下来要讨论的话题，它使用更高阶的多项式来拟合你的数据。有时候你的数据可能并不适合一条直线。这就是多项式回归的用武之地。
- en: Polynomial regression is a more general case of regression. So why limit yourself
    to a straight line? Maybe your data doesn't actually have a linear relationship,
    or maybe there's some sort of a curve to it, right? That happens pretty frequently.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式回归是回归的更一般情况。那么为什么要限制自己只使用一条直线呢？也许你的数据实际上并没有线性关系，或者可能有某种曲线关系，对吧？这种情况经常发生。
- en: Not all relationships are linear, but the linear regression is just one example
    of a whole class of regressions that we can do. If you remember the linear regression
    line that we ended up with was of the form *y = mx + b*, where we got back the
    values m and b from our linear regression analysis from ordinary least squares,
    or whatever method you choose. Now this is just a first order or a first-degree
    polynomial. The order or the degree is the power of x that you see. So that's
    the first-order polynomial.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有的关系都是线性的，但线性回归只是我们可以做的整个回归类别中的一个例子。如果你还记得我们最终得到的线性回归线的形式是*y = mx + b*，其中m和b是我们从普通最小二乘法线性回归分析中得到的值，或者你选择的任何方法。现在这只是一个一次多项式。阶数或度数就是你看到的x的幂。所以这是一个一次多项式。
- en: Now if we wanted, we could also use a second-order polynomial, which would look
    like *y = ax^2 + bx + c*. If we were doing a regression using a second-order polynomial,
    we would get back values for a, b, and c. Or we could do a third-order polynomial
    that has the form *ax^3 + bx^2 + cx + d*. The higher the orders get, the more
    complex the curves you can represent. So, the more powers of *x* you have blended
    together, the more complicated shapes and relationships you can get.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果我们想的话，我们也可以使用二次多项式，它看起来像*y = ax^2 + bx + c*。如果我们使用二次多项式进行回归，我们会得到a、b和c的值。或者我们可以使用三次多项式，它的形式是*ax^3
    + bx^2 + cx + d*。阶数越高，你可以表示的曲线就越复杂。所以，你将x的更多次幂混合在一起，你就可以得到更复杂的形状和关系。
- en: But more degrees aren't always better. Usually there's some natural relationship
    in your data that isn't really all that complicated, and if you find yourself
    throwing very large degrees at fitting your data, you might be overfitting!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 但并不是阶数越高越好。通常你的数据中有一些自然关系并不是那么复杂，如果你发现自己在拟合数据时使用了非常大的阶数，你可能是在过度拟合！
- en: Beware of overfitting!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意过度拟合！
- en: Don't use more degrees than you need
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要使用比你需要的更多的度数
- en: Visualize your data first to see how complex of a curve there might really be
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先可视化你的数据，看看可能存在多复杂的曲线
- en: Visualize the fit and check if your curve going out of its way to accommodate
    outliers
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化拟合并检查你的曲线是否在努力适应异常值
- en: A high r-squared simply means your curve fits your training data well; it may
    or may not be good predictor
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高R平方仅意味着你的曲线很好地拟合了训练数据；它可能是一个好的预测器，也可能不是
- en: If you have data that's kind of all over the place and has a lot of variance,
    you can go crazy and create a line that just like goes up and down to try to fit
    that data as closely as it can, but in fact that doesn't represent the intrinsic
    relationship of that data. It doesn't do a good job of predicting new values.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据有点乱七八糟，方差很大，你可以疯狂地创建一条上下波动的直线，试图尽可能地拟合数据，但实际上这并不代表数据的内在关系。它不能很好地预测新值。
- en: So always start by just visualizing your data and think about how complicated
    does the curve really needs to be. Now you can use r-squared to measure how good
    your fit is, but remember, that's just measuring how well this curve fits your
    training data—that is, the data that you're using to actually make your predictions
    based off of. It doesn't measure your ability to predict accurately going forward.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，始终从可视化你的数据开始，考虑曲线实际上需要多复杂。现在你可以使用R平方来衡量你的拟合有多好，但要记住，这只是衡量这条曲线有多好地拟合了你的训练数据——也就是说，你用来实际进行预测的数据。它并不衡量你准确预测未来的能力。
- en: Later, we'll talk about some techniques for preventing overfitting called **train/test**,
    but for now you're just going to have to eyeball it to make sure that you're not
    overfitting and throwing more degrees at a function than you need to. This will
    make more sense when we explore an example, so let's do that next.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后，我们将讨论一些防止过拟合的技术，称为**训练/测试**，但现在你只需要用眼睛来确保你没有过拟合，并且不要给函数添加比你需要的更多的度数。当我们探索一个例子时，这将更有意义，所以让我们接着做。
- en: Implementing polynomial regression using NumPy
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用NumPy实现多项式回归
- en: Fortunately, NumPy has a `polyfit` function that makes it super easy to play
    with this and experiment with different results, so let's go take a look. Time
    for fun with polynomial regression. I really do think it's fun, by the way. It's
    kind of cool seeing all that high school math actually coming into some practical
    application. Go ahead and open the `PolynomialRegression.ipynb` and let's have
    some fun.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，NumPy有一个`polyfit`函数，可以让你轻松地玩弄这个并尝试不同的结果，所以让我们去看看。多项式回归的乐趣时刻到了。顺便说一下，我真的觉得这很有趣。实际上看到所有那些高中数学实际上应用到一些实际的场景中，这有点酷。打开`PolynomialRegression.ipynb`，让我们玩得开心一点。
- en: 'Let''s create a new relationship between our page speeds, and our purchase
    amount fake data, and this time we''re going to create a more complex relationship
    that''s not linear. We''re going to take the page speed and make it some function
    of the division of page speed for the purchase amount:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在页面速度和我们的购买金额虚假数据之间创建一个新的关系，这一次我们将创建一个不是线性的更复杂的关系。我们将把页面速度作为购买金额的除法函数的一部分：
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If we do a scatter plot, we end up with the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们做一个散点图，我们得到以下结果：
- en: '![](img/fc603614-4a38-4c85-9ba9-4110bb47373a.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fc603614-4a38-4c85-9ba9-4110bb47373a.png)'
- en: By the way, if you're wondering what the `np.random.seed` line does, it creates
    a random seed value, and it means that when we do subsequent random operations
    they will be deterministic. By doing this we can make sure that, every time we
    run this bit of code, we end up with the same exact results. That's going to be
    important later on because I'm going to suggest that you come back and actually
    try different fits to this data to compare the fits that you get. So, it's important
    that you're starting with the same initial set of points.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，如果你想知道`np.random.seed`这一行是做什么的，它创建一个随机种子值，这意味着当我们进行后续的随机操作时，它们将是确定性的。通过这样做，我们可以确保每次运行这段代码时，我们都得到完全相同的结果。这将在以后变得重要，因为我将建议你回来实际尝试不同的拟合来比较你得到的拟合。所以，重要的是你从相同的初始点开始。
- en: You can see that that's not really a linear relationship. We could try to fit
    a line to it and it would be okay for a lot of the data, maybe down at the right
    side of the graph, but not so much towards the left. We really have more of an
    exponential curve.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到这并不是一个线性关系。我们可以尝试对其进行拟合，对于大部分数据来说可能还可以，也许在图表右侧的下方，但在左侧就不太行了。我们实际上更多的是一个指数曲线。
- en: Now it just happens that NumPy has a `polyfit()` function that allows you to
    fit any degree polynomial you want to this data. So, for example, we could say
    our *x*-axis is an array of the page speeds (`pageSpeeds`) that we have, and our
    *y*-axis is an array of the purchase amounts (`purchaseAmount`) that we have.
    We can then just call `np.polyfit(x, y, 4)`, meaning that we want a fourth degree
    polynomial fit to this data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在碰巧NumPy有一个`polyfit()`函数，允许你对这些数据进行任意次数的多项式拟合。所以，例如，我们可以说我们的*x*轴是我们拥有的页面速度（`pageSpeeds`）的数组，我们的*y*轴是我们拥有的购买金额（`purchaseAmount`）的数组。然后我们只需要调用`np.polyfit(x,
    y, 4)`，意思是我们想要一个四次多项式拟合这些数据。
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Let's go ahead and run that. It runs pretty quickly, and we can then plot that.
    So, we're going to create a little graph here that plots our scatter plot of original
    points versus our predicted points.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续运行。它运行得相当快，然后我们可以绘制出来。所以，我们将在这里创建一个小图表，绘制我们原始点与预测点的散点图。
- en: '[PRE6]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output looks like the following graph:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 输出看起来像下面的图表：
- en: '![](img/be56a569-0f3e-4921-88d8-bfdfa72c018a.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be56a569-0f3e-4921-88d8-bfdfa72c018a.png)'
- en: At this point, it looks like a reasonably good fit. What you want to ask yourself
    though is, "Am I overfitting? Does my curve look like it's actually going out
    of its way to accommodate outliers?" I find that that's not really happening.
    I don't really see a whole lot of craziness going on.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 目前看起来是一个相当好的拟合。不过你要问自己的是，“我是不是过度拟合了？我的曲线看起来是不是真的在努力适应异常值？”我发现实际上并没有发生这种情况。我并没有看到太多疯狂的事情发生。
- en: If I had a really high order polynomial, it might swoop up at the top to catch
    that one outlier and then swoop downwards to catch the outliers there, and get
    a little bit more stable through where we have a lot of density, and maybe then
    it could potentially go all over the place trying to fit the last set of outliers
    at the end. If you see that sort of nonsense, you know you have too many orders,
    too many degrees in your polynomial, and you should probably bring it back down
    because, although it fits the data that you observed, it's not going to be useful
    for predicting data you haven't seen.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我有一个非常高阶的多项式，它可能会在顶部上升以捕捉那个异常值，然后向下下降以捕捉那里的异常值，并且在我们有很多密度的地方会变得更加稳定，也许它最终可能会到处尝试适应最后一组异常值。如果你看到这种无稽之谈，你就知道你的多项式阶数太多了，你应该把它降下来，因为虽然它适合你观察到的数据，但对于预测你没有看到的数据是没有用的。
- en: Imagine I have some curve that swoops way up and then back down again to fit
    outliers. My prediction for something in between there isn't going to be accurate.
    The curve really should be in the middle. Later in this book we'll talk about
    the main ways of detecting such overfitting, but for now, please just observe
    it and know we'll go deeper later.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我有一条曲线，它向上飞起，然后又回到原点以适应异常值。我对中间的某些值的预测不会准确。曲线实际上应该在中间。在本书的后面，我们将讨论检测这种过拟合的主要方法，但现在，请只是观察它，并知道我们以后会更深入地讨论。
- en: Computing the r-squared error
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算r平方误差
- en: Now we can measure the r-squared error. By taking the `y` and the predicted
    values (`p4(x)`) in the `r2_score()` function that we have in `sklearn.metrics`,
    we can compute that.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以测量r平方误差。通过在`sklearn.metrics`中的`r2_score()`函数中取`y`和预测值（`p4(x)`），我们可以计算出来。
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/a18ffeef-c620-42d8-8fea-a2e3b60a3e1d.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/a18ffeef-c620-42d8-8fea-a2e3b60a3e1d.png)
- en: Our code compares a set of observations to a set of predictions and computes
    r-squared for you, and with just one line of code! Our r-squared for this turns
    out to be 0.829, which isn't too bad. Remember, zero is bad, one is good. 0.82
    is to pretty close to one, not perfect, and intuitively, that makes sense. You
    can see that our line is pretty good in the middle section of the data, but not
    so good out at the extreme left and not so good down at the extreme right. So,
    0.82 sounds about right.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的代码将一组观察结果与一组预测进行比较，并为你计算r平方，只需一行代码！我们的r平方结果为0.829，这还不错。记住，零是不好的，一是好的。0.82接近一，不完美，直观上是有道理的。你可以看到我们的线在数据的中间部分非常好，但在极端左侧和极端右侧并不那么好。所以，0.82听起来是合理的。
- en: Activity for polynomial regression
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多项式回归的活动
- en: I recommend that you get down and dirty with this stuff. Try different orders
    of polynomials. Go back up to where we ran the `polyfit()` function and try different
    values there besides 4\. You can use 1, and that would go back to a linear regression,
    or you could try some really high amount like 8, and maybe you'll start to see
    overfitting. So see what effect that has. You're going to want to change that.
    For example, let's go to a third-degree polynomial.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议你深入研究这些东西。尝试不同阶数的多项式。回到我们运行`polyfit()`函数的地方，尝试除了4之外的不同值。你可以使用1，那就会回到线性回归，或者你可以尝试一些非常高的值，比如8，也许你会开始看到过拟合。看看它的影响。你会想要改变它。例如，让我们来看一个三次多项式。
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Just keep hitting run to go through each step and you can see the it's effect
    as...
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 只需不断运行每一步，你就可以看到它的影响...
- en: '![](img/208e9b74-bc29-443a-91b3-88f04c1deff8.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/208e9b74-bc29-443a-91b3-88f04c1deff8.png)
- en: Our third-degree polynomial is definitely not as good a fit as the fourth-degree
    polynomial. If you actually measure the r-squared error, it would actually turn
    out worse, quantitatively; but if I go too high, you might start to see overfitting.
    So just have some fun with that, play around different values, and get a sense
    of what different orders of polynomials do to your regression. Go get your hands
    dirty and try to learn something.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的三次多项式显然不如四次多项式拟合得好。如果你实际测量r平方误差，定量上会更糟，但如果我太高，你可能会开始看到过拟合。所以，只是玩一下，尝试不同的值，了解不同阶数的多项式对回归的影响。去动手尝试学习一些东西。
- en: So that's polynomial regression. Again, you need to make sure that you don't
    put more degrees at the problem than you need to. Use just the right amount to
    find what looks like an intuitive fit to your data. Too many can lead to overfitting,
    while too few can lead to a poor fit... so you can use both your eyeballs for
    now, and the r-squared metric, to figure out what the right number of degrees
    are for your data. Let's move on.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是多项式回归。再次强调，你需要确保你不会给问题增加比你需要的更多的度数。使用恰到好处的数量来找到看起来符合你的数据的直观拟合。太多可能导致过拟合，而太少可能导致拟合不足...所以你现在可以同时使用你的眼睛和r平方指标来找出你的数据的正确度数。让我们继续。
- en: Multivariate regression and predicting car prices
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多元回归和预测汽车价格
- en: What happens then, if we're trying to predict some value that is based on more
    than one other attribute? Let's say that the height of people not only depends
    on their weight, but also on their genetics or some other things that might factor
    into it. Well, that's where multivariate analysis comes in. You can actually build
    regression models that take more than one factor into account at once. It's actually
    pretty easy to do with Python.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果我们试图预测基于多于一个其他属性的值会发生什么？假设人的身高不仅取决于他们的体重，还取决于他们的遗传或其他一些可能影响它的因素。那么，多元分析就派上用场了。你实际上可以构建同时考虑多个因素的回归模型。用Python做起来实际上非常容易。
- en: 'Let''s talk about multivariate regression, which is a little bit more complicated.
    The idea of multivariate regression is this: what if there''s more than one factor
    that influences the thing you''re trying to predict?'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈多元回归，这有点复杂。多元回归的想法是：如果有多个因素影响你要预测的事物会怎么样？
- en: In our previous examples, we looked at linear regression. We talked about predicting
    people's heights based on their weight, for example. We assumed that the weight
    was the only thing that influenced their height, but maybe there are other factors
    too. We also looked at the effect of page speed on purchase amounts. Maybe there's
    more that influences purchase amounts than just page speed, and we want to find
    how these different factors all combine together to influence that value. So that's
    where multivariate regression comes in.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的例子中，我们看了线性回归。例如，我们讨论了基于体重预测人的身高。我们假设体重是影响身高的唯一因素，但也许还有其他因素。我们还研究了页面速度对购买金额的影响。也许影响购买金额的因素不仅仅是页面速度，我们想要找出这些不同因素如何结合在一起影响价值。这就是多元回归的作用。
- en: The example we're going to look at now is as follows. Let's say that you're
    trying to predict the price that a car will sell for. It might be based on many
    different features of that car, such as the body style, the brand, the mileage;
    who knows, even on how good the tires are. Some of those features are going to
    be more important than others toward predicting the price of a car, but you want
    to take into account all of them at once.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在要看的示例是这样的。假设您试图预测汽车的售价。它可能基于该汽车的许多不同特征，例如车身风格、品牌、里程数；谁知道，甚至还取决于轮胎的好坏。其中一些特征对于预测汽车价格更为重要，但您希望一次考虑所有这些特征。
- en: So our way forwards here is still going to use the least-squares approach to
    fit a model to your set of observations. The difference is that we're going to
    have a bunch of coefficients for each different feature that you have.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们在这里前进的方式仍然是使用最小二乘法来拟合模型到您的一组观察结果。不同之处在于，我们将为您拥有的每个不同特征有一堆系数。
- en: 'So, for example, the price model that we end up with might be a linear relationship
    of alpha, some constant, kind of like your y-intercept was, plus some coefficient
    of the mileage, plus some coefficient of the age, plus some coefficient of how
    many doors it has:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，例如，我们最终得到的价格模型可能是alpha的线性关系，一些常数，有点像您的y截距，再加上里程的一些系数，再加上年龄的一些系数，再加上它有多少个门的一些系数：
- en: '![](img/5e0c70c6-ae2c-4435-92e5-e05b7ba56a28.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5e0c70c6-ae2c-4435-92e5-e05b7ba56a28.png)'
- en: Once you end up with those coefficients, from least squares analysis, we can
    use that information to figure out, well, how important are each of these features
    to my model. So, if I end up with a very small coefficient for something like
    the number of doors, that implies that the number of doors isn't that important,
    and maybe I should just remove it from my model entirely to keep it simpler.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您得到了那些最小二乘分析的系数，我们可以利用这些信息来弄清楚，每个特征对我的模型有多重要。因此，如果我得到了某些东西的系数非常小，比如车门数量，那就意味着车门数量并不重要，也许我应该完全将其从我的模型中移除，以使其更简单。
- en: This is something that I really should say more often in this book. You always
    want to do the simplest thing that works in data science. Don't over complicate
    things, because it's usually the simple models that work the best. If you can
    find just the right amount of complexity, but no more, that's usually the right
    model to go with. Anyway, those coefficients give you a way of actually, "Hey
    some of these things are more important than others. Maybe I can discard some
    of these factors."
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我在这本书中应该更经常说的一件事。在数据科学中，您总是希望做最简单有效的事情。不要过于复杂化事情，因为通常简单的模型效果最好。如果您能找到恰到好处的复杂度，但不要过多，那通常就是正确的模型。无论如何，这些系数给了您一种实际的方式，“嘿，有些因素比其他因素更重要。也许我可以丢弃其中一些因素。”
- en: Now we can still measure the quality of a fit with multivariate regression using
    r-squared. It works the same way, although one thing you need to assume when you're
    doing multivariate regression is that the factors themselves are not dependent
    on each other... and that's not always true. So sometimes you need to keep that
    little caveat in the back of your head. For example, in this model we're going
    to assume that mileage and age of the car are not related; but in fact, they're
    probably pretty tightly related! This is a limitation of this technique, and it
    might not be capturing an effect at all.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们仍然可以使用r-squared来衡量多元回归的拟合质量。它的工作方式相同，尽管在进行多元回归时，您需要假设因素本身不相互依赖...而这并不总是正确的。因此，有时您需要将这个小小的警告放在脑后。例如，在这个模型中，我们将假设汽车的里程和年龄不相关；但实际上，它们可能非常紧密相关！这是这种技术的局限性，它可能根本没有捕捉到某种效应。
- en: Multivariate regression using Python
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python进行多元回归
- en: Fortunately there's a `statsmodel` package available for Python that makes doing
    multivariate regression pretty easy. Let's just dive in and see how it works.
    Let's do some multivariate regression using Python. We're going to use some real
    data here about car values from the Kelley Blue Book.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Python有一个名为`statsmodel`的包，可以很容易地进行多元回归。让我们深入了解一下它的工作原理。让我们使用Python进行一些多元回归。我们将使用一些关于凯利蓝皮书中汽车价值的真实数据。
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We're going to introduce a new package here called `pandas`, which lets us deal
    with tabular data really easily. It lets us read in tables of data and rearrange
    them, and modify them, and slice them and dice them in different ways. We're going
    to be using that a lot going forward.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要在这里介绍一个名为`pandas`的新包，它让我们非常容易地处理表格数据。它让我们能够轻松读取表格数据，并以不同的方式重新排列、修改、切片和切块它们。我们将在未来经常使用它。
- en: We're going to import `pandas` as `pd`, and `pd` has a `read_Excel()` function
    that we can use to go ahead and read a Microsoft Excel spreadsheet from the Web
    through HTTP. So, pretty awesome capabilities of pandas there.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将导入`pandas`作为`pd`，`pd`有一个`read_Excel()`函数，我们可以使用它来从Web通过HTTP读取Microsoft Excel电子表格。因此，pandas有非常棒的功能。 '
- en: 'I''ve gone ahead and hosted that file for you on my own domain, and if we run
    that, it will load it into what''s called a `DataFrame` object that we''re referring
    to as `df`. Now I can call `head()` on this `DataFrame` to just show the first
    few lines of it:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经提前为您在我的域上托管了该文件，如果我们运行它，它将加载到我们称之为`df`的`DataFrame`对象中。现在我可以在这个`DataFrame`上调用`head()`，只显示它的前几行：
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following is the output for the preceding code:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面代码的输出：
- en: '![](img/d0288fca-7305-4812-b099-6de8fbea7f8f.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d0288fca-7305-4812-b099-6de8fbea7f8f.png)'
- en: The actual dataset is much larger. This is just the first few samples. So, this
    is real data of mileage, make, model, trim, type, doors, cruise, sound and leather.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 实际数据集要大得多。这只是前几个样本。因此，这是关于里程、制造商、型号、修剪、类型、车门、巡航、音响和皮革的真实数据。
- en: OK, now we're going to use `pandas` to split that up into the features that
    we care about. We're going to create a model that tries to predict the price just
    based on the mileage, the model, and the number of doors, and nothing else.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们要使用`pandas`将其拆分为我们关心的特征。我们将创建一个模型，试图仅基于里程、型号和车门数量来预测价格，没有其他因素。
- en: '[PRE11]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now the problem that I run into is that the model is a text, like Century for
    Buick, and as you recall, everything needs to be a number when I'm doing this
    sort of analysis. In the code, I use this `Categorical() function` in `pandas`
    to actually convert the set of model names that it sees in the `DataFrame` into
    a set of numbers; that is, a set of codes. I'm going to say my input for this
    model on the x-axis is mileage (`Mileage`), model converted to an ordinal value
    (`Model_ord`), and the number of doors (`Doors`). What I'm trying to predict on
    the y-axis is the price (`Price`).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我遇到的问题是，模型是一个文本，比如Buick的世纪，正如您所记得的，当我进行这种分析时，一切都需要是数字。在代码中，我使用`pandas`中的`Categorical()函数`来将`DataFrame`中看到的模型名称转换为一组数字；也就是一组代码。我将说我的模型的x轴输入是里程（`Mileage`），转换为序数值的模型（`Model_ord`），和车门数量（`Doors`）。我试图在y轴上预测的是价格（`Price`）。
- en: 'The next two lines of the code just create a model that I''m calling `est`
    that uses ordinary least squares, OLS, and fits that using the columns that I
    give it, `Mileage`, `Model_ord`, and `Doors`. Then I can use the summary call
    to print out what my model looks like:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/218a51f2-f117-4cdc-b50f-25bd99d8990d.png)'
- en: '![](img/ffce0020-9e84-4ecd-9a73-ac3008463f3a.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ffce0020-9e84-4ecd-9a73-ac3008463f3a.png)'
- en: You can see here that the r-squared is pretty low. It's not that good of a model,
    really, but we can get some insight into what the various errors are, and interestingly,
    the lowest standard error is associated with the mileage.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到这里的R平方值非常低。实际上，这不是一个很好的模型，但我们可以了解各种错误的一些见解，有趣的是，最低的标准误差与里程相关联。
- en: 'Now I have said before that the coefficient is a way of determining which items
    matter, and that''s only true though if your input data is normalized. That is,
    if everything''s on the same scale of 0 to 1\. If it''s not, then these coefficients
    are kind of compensating for the scale of the data that it''s seeing. If you''re
    not dealing with normalized data, as in this case, it''s more useful to look at
    the standard errors. In this case, we can see that the mileage is actually the
    biggest factor of this particular model. Could we have figured that out earlier?
    Well, we could have just done a little bit of slicing and dicing to figure out
    that the number of doors doesn''t actually influence the price much at all. Let''s
    run the following little line:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我之前说过，系数是一种确定哪些项目重要的方法，但前提是您的输入数据已经标准化。也就是说，如果所有数据都在0到1的相同尺度上。如果不是，那么这些系数在一定程度上是在补偿它所看到的数据的尺度。如果您处理的不是标准化数据，就像在这种情况下一样，查看标准误差更有用。在这种情况下，我们可以看到里程实际上是这个特定模型的最大因素。我们早些时候能否已经想到这一点呢？嗯，我们只需稍微切片和切块就能发现车门数量实际上并不会对价格产生太大影响。让我们运行以下小行：
- en: '[PRE12]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'A little bit of `pandas` syntax there. It''s pretty cool that you can do it
    in Python in one line of code! That will print out a new `DataFrame` that shows
    the mean price for the given number of doors:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一点`pandas`的语法。在Python中只需一行代码就能做到这一点，这很酷！这将打印出一个新的`DataFrame`，显示给定车门数量的平均价格：
- en: '![](img/218a51f2-f117-4cdc-b50f-25bd99d8990d.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: 接下来的两行代码只是创建了一个我称之为`est`的模型，它使用普通最小二乘法（OLS），并使用我给它的列`Mileage`，`Model_ord`和`Doors`进行拟合。然后我可以使用summary调用来打印出我的模型是什么样子的：
- en: I can see the average two-door car sells for actually more than the average
    four-door car. If anything there's a negative correlation between number of doors
    and price, which is a little bit surprising. This is a small dataset, though,
    so we can't read a whole lot of meaning into it of course.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以看到平均两门车的售价实际上比平均四门车的售价更高。如果有的话，车门数量和价格之间存在负相关，这有点令人惊讶。不过，这是一个小数据集，所以我们当然不能从中得出太多意义。
- en: Activity for multivariate regression
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多元回归的活动
- en: As an activity, please mess around with the fake input data where you want.
    You can download the data and mess around with the spreadsheet. Read it from your
    local hard drive instead of from HTTP, and see what kind of differences you can
    have. Maybe you can fabricate a dataset that has a different behavior and has
    a better model that fits it. Maybe you can make a wiser choice of features to
    base your model off of. So, feel free to mess around with that and let's move
    on.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个活动，请随意修改假输入数据。您可以下载数据并在电子表格中进行修改。从本地硬盘读取数据，而不是从HTTP读取，看看您可以有什么样的不同。也许您可以制作一个行为不同且拥有更好适合的模型的数据集。也许您可以更明智地选择特征来构建您的模型。所以，请随意尝试一下，然后我们继续。
- en: 'There you have it: multivariate analysis and an example of it running. Just
    as important as the concept of multivariate analysis, which we explored, was some
    of the stuff that we did in that Python notebook. So, you might want to go back
    there and study exactly what''s going on.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是多元分析和其运行示例。和我们探索的多元分析概念一样重要的是我们在Python笔记本中所做的一些事情。所以，您可能需要回到那里，确切地研究发生了什么。
- en: We introduced pandas and the way to work with pandas and DataFrame objects.
    pandas a very powerful tool. We'll use it more in future sections, but make sure
    you're starting to take notice of these things because these are going to be important
    techniques in your Python skills for managing large amounts of data and organizing
    your data.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了pandas和处理pandas和DataFrame对象的方法。pandas是一个非常强大的工具。我们将在未来的章节中更多地使用它，但请确保您开始注意这些事情，因为这些将是您在Python技能中处理大量数据和组织数据的重要技术。
- en: Multi-level models
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多级模型
- en: It makes sense now to talk about multi-level models. This is definitely an advanced
    topic, and I'm not going to get into a whole lot of detail here. My objective
    right now is to introduce the concept of multi-level models to you, and let you
    understand some of the challenges and how to think about them when you're putting
    them together. That's it.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在谈论多层次模型是有意义的。这绝对是一个高级话题，我不会在这里详细讨论。我现在的目标是向你介绍多层次模型的概念，并让你了解一些挑战以及在组合它们时如何思考。就是这样。
- en: The concept of multi-level models is that some effects happen at various levels
    in the hierarchy. For example, your health. Your health might depend on how healthy
    your individual cells are, and those cells might be a function of how healthy
    the organs that they're inside are, and the health of your organs might depend
    on the health of you as a whole. Your health might depend in part on your family's
    health and the environment your family gives you. And your family's health in
    turn might depend on some factors of the city that you live in, how much crime
    is there, how much stress is there, how much pollution is there. And even beyond
    that, it might depend on factors in the entire world that we live in. Maybe just
    the state of medical technology in the world is a factor, right?
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 多层次模型的概念是，一些影响发生在层次结构中的各个层次。例如，你的健康。你的健康可能取决于你的个体细胞的健康程度，而这些细胞可能取决于它们所在的器官的健康程度，而你的器官的健康可能取决于你整体的健康。你的健康可能部分取决于你家庭的健康和你家庭给予你的环境。而你家庭的健康反过来可能取决于你所在城市的一些因素，比如犯罪率、压力和污染程度。甚至超越这些，它可能取决于我们所生活的整个世界的因素。也许世界上医疗技术的状况是一个因素，对吧？
- en: 'Another example: your wealth. How much money do you make? Well, that''s a factor
    of your individual hard work, but it''s also a factor of the work that your parents
    did, how much money were they able to invest into your education and the environment
    that you grew up in, and in turn, how about your grandparents? What sort of environment
    were they able to create and what sort of education were they able to offer for
    your parents, which in turn influenced the resources they have available for your
    own education and upbringing.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子：你的财富。你赚多少钱？这取决于你个人的努力，但也取决于你父母的努力，他们能够为你的教育投入多少钱以及你成长的环境，反过来，你的祖父母呢？他们能够创造什么样的环境，能够为你的父母提供什么样的教育，进而影响他们为你的教育和成长提供的资源。
- en: These are all examples of multi-level models where there is a hierarchy of effects
    that influence each other at larger and larger scales. Now the challenge of multi-level
    models is to try to figure out, "Well, how do I model these interdependencies?
    How do I model all these different effects and how they affect each other?"
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是多层次模型的例子，其中存在一个影响彼此的层次结构。现在多层次模型的挑战是要尝试弄清楚，“我该如何建模这些相互依赖关系？我该如何建模所有这些不同的影响以及它们如何相互影响？”
- en: The challenge here is to identify the factors in each level that actually affect
    the thing you're trying to predict. If I'm trying to predict overall SAT scores,
    for example, I know that depends in part on the individual child that's taking
    the test, but what is it about the child that matters? Well, it might be the genetics,
    it might be their individual health, the individual brain size that they have.
    You can think of any number of factors that affect the individual that might affect
    their SAT score. And then if you go up another level, look at their home environment,
    look at their family. What is it about their families that might affect their
    SAT scores? How much education were they able to offer? Are the parents able to
    actually tutor the children in the topics that are on the SAT? These are all factors
    at that second level that might be important. What about their neighborhood? The
    crime rate of the neighborhood might be important. The facilities they have for
    teenagers and keeping them off the streets, things like that.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的挑战是识别每个层次中实际影响你试图预测的事物的因素。例如，如果我试图预测整体SAT成绩，我知道这部分取决于参加考试的个体孩子，但是孩子的哪些方面很重要呢？可能是基因，可能是他们的个体健康，他们的个体大脑大小。你可以想到任何可能影响个体的因素，可能会影响他们的SAT成绩。然后，如果你再往上看，看看他们的家庭环境，看看他们的家庭。家庭的哪些方面可能会影响他们的SAT成绩？他们能提供多少教育？父母是否能够辅导孩子学习SAT考试中的主题？这些都是第二层次的重要因素。那么他们的社区呢？社区的犯罪率可能很重要。他们为青少年提供的设施以及让他们远离街头的措施等等。
- en: The point is you want to keep looking at these higher levels, but at each level
    identify the factors that impact the thing you're trying to predict. I can keep
    going up to the quality of the teachers in their school, the funding of the school
    district, the education policies at the state level. You can see there are different
    factors at different levels that all feed into this thing you're trying to predict,
    and some of these factors might exist at more than one level. Crime rate, for
    example, exists at the local and state levels. You need to figure out how those
    all interplay with each other as well when you're doing multi-level modeling.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 关键是你想要继续关注这些更高的层次，但在每个层次上识别影响你试图预测的事物的因素。我可以继续上升到学校老师的素质、学区的资金、州级的教育政策。你可以看到不同层次的不同因素都会影响你试图预测的事物，而其中一些因素可能存在于多个层次。例如，犯罪率存在于地方和州级。在进行多层次建模时，你需要弄清楚它们如何相互作用。
- en: As you can imagine, this gets very hard and very complicated very quickly. It
    is really way beyond the scope of this book, or any introductory book in data
    science. This is hard stuff. There are entire thick books about it, you could
    do an entire book about it that would be a very advanced topic.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可以想象的那样，这很快变得非常困难和复杂。这确实远远超出了本书的范围，也超出了任何数据科学入门书籍的范围。这是困难的东西。有整整厚厚的书籍讨论它，你可以写一本完整的书籍，这将是一个非常高级的话题。
- en: So why am I even mentioning multi-level models? It is because I've seen it mentioned
    on job descriptions, in a couple of cases, as something that they want you to
    know about in a couple of cases. I've never had to use it in practice, but I think
    the important thing from the standpoint of getting a career in data science is
    that you at least are familiar with the concept, and you know what it means and
    some of the challenges involved in creating a multi-level model. I hope I've given
    you those concepts. With that, we can move on to the next section.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 那么为什么我要提到多层模型呢？因为我在一些工作描述中看到它被提到，在一些情况下，作为他们希望你了解的内容。我在实践中从未使用过它，但我认为在数据科学职业中重要的是，你至少要熟悉这个概念，知道它的含义以及创建多层模型所涉及的一些挑战。我希望我已经向你介绍了这些概念。有了这些，我们可以继续下一节了。
- en: There you have the concepts of multi-level models. It's a very advanced topic,
    but you need to understand what the concept is, at least, and the concept itself
    is pretty simple. You just are looking at the effects at different levels, different
    hierarchies when you're trying to make a prediction. So maybe there are different
    layers of effects that have impacts on each other, and those different layers
    might have factors that interrelate with each other as well. Multi-level modeling
    tries to take account of all those different hierarchies and factors and how they
    interplay with each other. Rest assured that's all you need to know for now.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是多层模型的概念。这是一个非常高级的话题，但你至少需要了解这个概念，而这个概念本身是相当简单的。当你试图做出预测时，你只是在不同层次、不同层次之间寻找影响。所以也许有不同层次的影响相互影响，而这些不同层次可能有相互关联的因素。多层建模试图考虑所有这些不同的层次和因素以及它们如何相互作用。放心，这就是你现在需要知道的全部。
- en: Summary
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we talked about regression analysis, which is trying to fit
    a curve to a set of training data and then using it to predict new values. We
    saw its different forms. We looked at the concept of linear regression and its
    implementation in Python.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们谈到了回归分析，即试图将曲线拟合到一组训练数据，然后使用它来预测新值。我们看到了它的不同形式。我们看了线性回归的概念及其在Python中的实现。
- en: We learned what polynomial regression is, that is, using higher degree polynomials
    to create better, complex curves for multi-dimensional data. We also saw its implementation
    in Python.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了多项式回归是什么，也就是使用更高次的多项式来为多维数据创建更好、更复杂的曲线。我们还看到了它在Python中的实现。
- en: We then talked about multivariate regression, which is a little bit more complicated.
    We saw how it is used when there are multiple factors affecting the data that
    we're predicting. We looked at an interesting example, which predicts the price
    of a car using Python and a very powerful tool, pandas.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们谈到了多元回归，这是一个稍微复杂一点的概念。我们看到了当有多个因素影响我们要预测的数据时，多元回归是如何使用的。我们看了一个有趣的例子，使用Python和一个非常强大的工具pandas来预测汽车的价格。
- en: Finally, we looked at the concept of multi-level models. We understood some
    of the challenges and how to think about them when you're putting them together.
    In the next chapter, we'll learn some machine learning techniques using Python.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们看了多层模型的概念。我们了解了一些挑战，以及在将它们组合在一起时如何考虑它们。在下一章中，我们将学习一些使用Python的机器学习技术。
