- en: Chapter 8. Spark Graph Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 Spark图处理
- en: A graph is a mathematical concept and a data structure in computer science.
    It has huge applications in many real-world use cases. It is used to model a pair-wise
    relationship between entities. An entity here is known as a vertex and two vertices
    are connected by an edge. A graph comprises a collection of vertices, and the
    edges connecting them.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 图是计算机科学中的一个数学概念和数据结构。它在许多现实世界的用例中有着巨大的应用。它用于模拟实体之间的成对关系。在这里，实体被称为顶点，两个顶点通过边连接。一个图由顶点的集合和连接它们的边组成。
- en: 'Conceptually, it is a deceptively simple abstraction, but when it comes to
    processing a huge number of vertices and edges, it is computationally intensive
    and consumes a lot of processing time and computing resources. Here is a representation
    of a graph with four vertices and three edges:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，这是一个欺骗性的简单抽象，但当涉及到处理大量顶点和边时，它计算密集，消耗大量的处理时间和计算资源。以下是一个具有四个顶点和三条边的图的表示：
- en: '![Spark Graph Processing](img/B05289_08_01_new.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![Spark图处理](img/B05289_08_01_new.jpg)'
- en: Figure 1
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 图1
- en: 'We will cover the following topics in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: Graphs and their uses
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图及其用途
- en: The GraphX library
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GraphX库
- en: The PageRank algorithm
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PageRank算法
- en: The Connected component algorithm
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连通分量算法
- en: GraphFrames
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GraphFrames
- en: Graph Queries
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图查询
- en: Understanding graphs and their usage
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解图及其用法
- en: There are numerous application constructs that can be modeled as graphs. In
    a social networking application, the relationship between users can be modeled
    as a graph in which the users form the vertices of the graph and the relationships
    between users form the edges of the graph. In a multi-stage job scheduling application,
    the individual tasks form the vertices of the graph and the sequencing of the
    tasks forms the edges. In a road traffic modeling system, the towns form the vertices
    of the graph and the roads connecting the towns form the edges.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多可以建模为图的用例结构。在社交网络应用中，用户之间的关系可以建模为图，其中用户形成图的顶点，用户之间的关系形成图的边。在多阶段作业调度应用中，单个任务形成图的顶点，任务的顺序形成图的边。在道路交通建模系统中，城镇形成图的顶点，连接城镇的道路形成图的边。
- en: The edges of a given graph have a very important property, namely *the direction
    of the connection*. In many use cases, the direction of the connection doesn't
    matter. The case of connectivity between cities by roads is one such example.
    But if the use case is to produce driving directions within a city, the connectivity
    between traffic junctions has a direction. Take any two traffic junctions and
    there will be road connectivity, but it is also possible that it is a one-way
    road. So it all depends on the direction the traffic is flowing. If the road is
    open to traffic from traffic junction J1 to J2 but closed from J2 to J1, then
    the graph of driving directions will have a connectivity from J1 to J2 and not
    from J2 to J1\. In such cases, the edge connecting J1 and J2 has a direction.
    If the road between J2 and J3 is open in both directions, then the edge connecting
    J2 and J3 has no direction. A graph in which all the edges have a direction is
    called a **directed graph**.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 给定图的边有一个非常重要的属性，即*连接的方向*。在许多用例中，连接的方向并不重要。例如，通过道路连接城市的情况。但如果用例是在城市内生成驾驶方向，则交通枢纽之间的连通性是有方向的。取任何两个交通枢纽，都存在道路连通性，但也可能是一条单行道。所以这完全取决于交通的流向。如果道路从交通枢纽J1到J2开放，但从J2到J1关闭，那么驾驶方向的图将从J1到J2有连通性，而不是从J2到J1。在这种情况下，连接J1和J2的边有方向。如果J2和J3之间的道路在两个方向上都开放，那么连接J2和J3的边没有方向。所有边都有方向的图称为**有向图**。
- en: Tip
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: When representing a graph pictorially, it is mandatory to give the direction
    on the edges of the directed graph. If it is not a directed graph, the edge can
    be represented without any direction at all or with direction to both sides. This
    is up to the individual's choice. *Figure 1* is not a directed graph, but is represented
    with directions to both the vertices that the edge is connecting.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当以图形方式表示图时，必须给出有向图边的方向。如果不是有向图，边可以没有任何方向地表示，或者可以表示为双向的。这取决于个人的选择。*图1* 不是一个有向图，但它表示了连接边的两个顶点的方向。
- en: In *Figure 2*, the relationship between two users in a social networking application
    use case is represented as a graph. Users form the vertices and the relationships
    between the users form the edges. User A follows User B. At the same time, User
    A is the son of User B. In this graph, there are two parallel edges sharing the
    same source and destination vertices. A graph containing parallel edges is called
    a multigraph. The graph shown in *Figure 2* is also a directed graph. This is
    a good example of a **directed multigraph**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图2*中，一个社交网络应用用例中两个用户之间的关系被表示为图。用户形成顶点，用户之间的关系形成边。用户A关注用户B。同时，用户A是用户B的儿子。在这个图中，存在两条具有相同源和目标顶点的并行边。包含并行边的图称为多重图。*图2*中显示的图也是一个有向图。这是一个**有向多重图**的好例子。
- en: '![Understanding graphs and their usage](img/image_08_002.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![理解图及其用法](img/image_08_002.jpg)'
- en: Figure 2
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图2
- en: In real-world use cases, the vertices and edges of a graph represent real-world
    entities. These entities have properties. For example, in the social connectivity
    graph of users from a social networking application, the users form the vertices
    and users have many properties such as name, e-mail, phone number, and so on.
    Similarly, the relationships between the users form the edges of the graph and
    the edges connecting user vertices can have properties such as relationship. Any
    graph processing application library should be flexible enough to attach any kind
    of property to the vertices and edges of a graph.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界的用例中，图的顶点和边代表现实世界的实体。这些实体具有属性。例如，在社交网络应用的用户社交连接图中，用户形成顶点，用户具有许多属性，如姓名、电子邮件、电话号码等。同样，用户之间的关系形成图的边，连接用户顶点的边可以具有如关系等属性。任何图处理应用程序库都应该足够灵活，能够将任何类型的属性附加到图的顶点和边上。
- en: The Spark GraphX library
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark GraphX库
- en: For graph processing, many libraries are available in the open source world.
    Giraph, Pregel, GraphLab, and Spark GraphX are some of them. Spark GraphX is one
    of the recent entrants into this space.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图处理，开源世界中有很多库可用。Giraph、Pregel、GraphLab和Spark GraphX都是其中的一些。Spark GraphX是最近进入这个领域的新成员。
- en: What is so special about Spark GraphX? Spark GraphX is a graph processing library
    built on top of the Spark data processing framework. Compared to the other graph
    processing libraries, Spark GraphX has a real advantage. It can make use of all
    the data processing capabilities of Spark. However, in reality, the performance
    of graph processing algorithms is not the only aspect that needs consideration.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX有什么特别之处？Spark GraphX是一个建立在Spark数据处理框架之上的图处理库。与其他图处理库相比，Spark GraphX具有真正的优势。它可以利用Spark的所有数据处理能力。然而，在现实中，图处理算法的性能并不是唯一需要考虑的方面。
- en: In many applications, the data that needs to be modeled as a graph does not
    exist in that form naturally. In many use cases, more than the graph processing,
    lots of processor time and other computing resources are expended to get the data
    in the right format so that the graph processing algorithms can be applied. This
    is the sweet spot where the combination of the Spark data processing framework
    and the Spark GraphX library deliver their value. The data processing jobs to
    make the data ready to be consumed by the Spark GraphX can be easily done using
    the plethora of tools available in the Spark toolkit. In summary, the Spark GraphX
    library, which is part of the Spark family, combines the power of the core data
    processing capabilities of Spark and a very easy-to-use graph processing library.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多应用中，需要将数据建模为图，但这些数据并不以这种形式自然存在。在许多用例中，除了图处理之外，还需要大量的处理器时间和其他计算资源来获取数据，以便应用图处理算法。这正是Spark数据处理框架和Spark
    GraphX库发挥其价值的地方。使用Spark工具包中可用的众多工具，可以轻松完成使数据准备好供Spark GraphX消费的数据处理作业。总之，作为Spark家族的一部分，Spark
    GraphX库结合了Spark的核心数据处理能力以及一个非常易于使用的图处理库。
- en: Revisit the bigger picture once again, as given in *Figure 3*, to set the context
    and see what is being discussed here before getting into the use cases. Unlike
    other chapters, in this chapter, the code samples will only be done in Scala because
    the Spark GraphX library only has a Scala API available at the moment.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 再次回顾一下*图3*所展示的更大图景，以设定上下文并了解在这里将要讨论的内容，然后再进入用例的使用。与其它章节不同，在本章中，代码示例将只使用Scala编写，因为Spark
    GraphX库目前只提供了Scala API。
- en: '![The Spark GraphX library](img/image_08_003.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![Spark GraphX库的Spark GraphX库](img/image_08_003.jpg)'
- en: Figure 3
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图3
- en: GraphX overview
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GraphX概述
- en: 'In any real-world use case, it is easy to understand the concept of a graph
    comprising vertices and edges. But when it comes to the implementation, this is
    not a data structure that is very well understood by even good designers and programmers.
    The reason is simple: unlike other ubiquitous data structures such as list, set,
    map, queue, and so on, graphs are not commonly used in most applications. Taking
    this into consideration, the concepts are introduced slowly and steadily, one
    step at a time, with simple and trivial examples, before taking up some real-world
    use cases.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何实际应用场景中，理解由顶点和边组成的图的概念是很容易的。但是，当涉及到实现时，即使对于优秀的设计师和程序员来说，这也不是一个非常理解的数据结构。原因是简单的：与其他普遍存在的数据结构，如列表、集合、映射、队列等不同，图在大多数应用中并不常用。考虑到这一点，概念是逐步、稳步地引入的，一次一步，通过简单且平凡的例子，然后再考虑一些实际应用场景。
- en: The most important aspect of the Spark GraphX library is a data type, Graph,
    which extends the Spark **resilient distributed dataset** (**RDD**) and introduces
    a new graph abstraction. The graph abstraction in Spark GraphX is a directed multigraph
    with properties attached to all the vertices and edges. The properties for each
    of these vertices and edges can be user defined types that are supported by the
    Scala type system. These types are parameterized in the Graph type. A given graph
    may be required to have different data types for vertices or edges. This is possible
    by using a type system related by an inheritance hierarchy. In addition to all
    these basic ground rules, the library includes a collection of graph builders
    and algorithms.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX库最重要的方面是一个数据类型，Graph，它扩展了Spark **弹性分布式数据集**（**RDD**）并引入了一种新的图抽象。Spark
    GraphX中的图抽象是一个带有所有顶点和边属性的定向多重图。这些顶点和边的属性可以是Scala类型系统支持的由用户定义的类型。这些类型在Graph类型中是参数化的。给定的图可能需要顶点或边有不同的数据类型。这可以通过使用一个与继承层次结构相关的类型系统来实现。除了所有这些基本规则之外，该库还包括一系列图构建器和算法。
- en: A vertex in a graph is identified by a unique 64-bit long identifier, `org.apache.spark.graphx.VertexId`.
    Instead of the VertexId type, a simple Scala type, Long, can also be used. In
    addition to that, vertices can take any type as a property. An edge in a graph
    should have a source vertex identifier, a destination vertex identifier, and any
    type as a property.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的一个顶点由一个唯一的64位长标识符识别，`org.apache.spark.graphx.VertexId`。除了VertexId类型，一个简单的Scala类型，Long，也可以使用。除此之外，顶点可以接受任何类型的属性。图中的一个边应该有一个源顶点标识符、一个目标顶点标识符以及任何类型的属性。
- en: '*Figure 4* shows a graph with a vertex property as a String type and an edge
    property as a String type. In addition to the properties, each vertex has a unique
    identifier and each edge has a source vertex number and destination vertex number.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4* 展示了一个顶点属性为String类型，边属性也为String类型的图。除了属性之外，每个顶点都有一个唯一的标识符，每个边都有一个源顶点编号和目标顶点编号。'
- en: '![GraphX overview](img/image_08_004.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![GraphX概述](img/image_08_004.jpg)'
- en: Figure 4
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图4
- en: When processing a graph, there are methods to get the vertices and edges. But
    these independent objects of a graph in isolation may not be sufficient while
    doing processing.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理图时，有方法可以获取顶点和边。但是，在独立处理时，这些图中的独立对象可能不足以进行处理。
- en: A vertex has its unique identifier and a property, as stated previously. An
    edge is uniquely identified by its source and destination vertices. To easily
    process each edge in graph processing applications, the triplet abstraction of
    the Spark GraphX library provides an easy way to access the properties of the
    source vertex, destination vertex, and the edge from a single object.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，一个顶点有一个唯一的标识符和属性。边通过其源顶点和目标顶点唯一标识。为了在图处理应用中轻松处理每个边，Spark GraphX库的三元组抽象提供了一种从单个对象访问源顶点、目标顶点和边属性的简单方法。
- en: 'The following Scala code snippet is used to create the graph shown in *Figure
    4* using the Spark GraphX library. After creating the graph, many methods are
    invoked on the graph that expose various properties of the graph. At the Scala
    REPL prompt, try the following statements:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的Scala代码片段用于使用Spark GraphX库创建*图4*所示的图。在创建图之后，可以在图上调用许多方法来暴露图的各个属性。在Scala REPL提示符下，尝试以下语句：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Readers will be familiar with Spark programming using RDDs. The preceding code
    snippet elucidated the process of constructing the vertices and edges of a graph
    using RDDs. RDDs can be constructed using data persisted in various data stores.
    In real-world use cases, most of the time the data will come from external sources,
    such as NoSQL data stores, and there are ways to construct RDDs using such data.
    Once the RDDs are constructed, graphs can be constructed using that.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 读者将熟悉使用RDD进行Spark编程。前面的代码片段解释了使用RDD构建图顶点和边的过程。可以使用存储在各种数据存储中的数据进行RDD的构建。在实际应用场景中，大多数情况下数据将来自外部来源，例如NoSQL数据存储，并且有方法可以使用此类数据构建RDD。一旦构建了RDD，就可以使用这些RDD构建图。
- en: 'The preceding code snippet also explained the various methods available with
    the graph to get all the required details of a given graph. The teaser use case
    covered here is a very small graph in terms of size. In real-world use cases,
    the number of vertices and edges of a graph can be in the millions. Since all
    these abstractions are implemented as RDDs, all the inherent goodness of immutability,
    partitioning, distribution, and parallel processing comes out of the box, hence
    making graph processing highly scalable. Finally, the following tables show how
    the vertices and edges are represented:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段还解释了图提供的各种方法来获取给定图的所需详细信息。这里涵盖的示例用例在规模上非常小。在实际应用场景中，图的顶点和边的数量可以达到数百万。由于所有这些抽象都作为RDD实现，因此所有固有的不可变性、分区、分布和并行处理的优势都自动获得，这使得图处理高度可扩展。最后，以下表格显示了顶点和边的表示方式：
- en: '**Vertex table**:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**顶点表**:'
- en: '| **VertexId** | **Vertex property** |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| **顶点ID** | **顶点属性** |'
- en: '| 1 | Thomas |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 1 | Thomas |'
- en: '| 2 | Krish |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Krish |'
- en: '| 3 | Mathew |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 3 | Mathew |'
- en: '**Edge table:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**边表**:'
- en: '| **Source VertexId** | **Destination VertexId** | **Edge property** |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| **源顶点ID** | **目标顶点ID** | **边属性** |'
- en: '| 1 | 2 | Follows |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | Follows |'
- en: '| 1 | 2 | Son |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | Son |'
- en: '| 2 | 3 | Follows |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3 | Follows |'
- en: '**Triplet table**:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**三元组表**:'
- en: '| **Source VertexId** | **Destination VertexId** | **Source vertex Property**
    | **Edge property** | **Destination vertex property** |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| **源顶点ID** | **目标顶点ID** | **源顶点属性** | **边属性** | **目标顶点属性** |'
- en: '| 1 | 2 | Thomas | Follows | Krish |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | Thomas | Follows | Krish |'
- en: '| 1 | 2 | Thomas | Son | Krish |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | Thomas | Son | Krish |'
- en: '| 2 | 3 | Krish | Follows | Mathew |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3 | Krish | Follows | Mathew |'
- en: Note
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It is important to note that these tables are only for explanation purposes.
    The real internal representation follows the rules and regulations of RDD representation.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这些表仅用于说明目的。实际的内部表示遵循RDD表示的规则和规定。
- en: If anything is represented as an RDD, it is bound to get partitioned and distributed.
    But if the partitioning and distribution are done freely, without any control
    for the graph, then it is going to be suboptimal when it comes to graph processing
    performance. Because of that, the creators of the Spark GraphX library have thought
    through this problem well in advance and implemented a graph partitioning strategy
    in order to have an optimized representation of the graph as RDDs.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任何内容表示为RDD，它必然会进行分区和分布。但是，如果分区和分布是自由进行的，没有任何对图的管控，那么在图处理性能方面将是不优的。正因为如此，Spark
    GraphX库的创建者提前深思熟虑了这个问题，并实现了一种图分区策略，以便以优化的形式将图表示为RDD。
- en: Graph partitioning
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图分区
- en: It is important to understand a little bit about how the graph RDDs are partitioned
    and distributed across various partitions. This will be useful for advanced optimizations
    that determine the partition and distribution of the various RDDs that are the
    constituent parts of a graph.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 理解图RDD如何在各个分区中进行分区和分布是很重要的。这将对确定构成图的各个RDD的分区和分布的高级优化很有用。
- en: In general, there are three RDDs for a given graph. Apart from the vertex RDD
    and the edge RDD, one more RDD is used internally, and that is the routing RDD.
    To have optimal performance, all the vertices needed to form a given edge are
    kept in the same partition where the edge is stored. If a given vertex is participating
    in multiple edges and these edges are located in different partitions, then this
    particular vertex can be stored in multiple partitions.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，对于给定的图有三个RDD。除了顶点RDD和边RDD之外，还有一个内部使用的RDD，即路由RDD。为了获得最佳性能，所有构成给定边的顶点都保留在存储边的同一个分区中。如果给定顶点参与多个边，而这些边位于不同的分区中，那么这个特定的顶点可以存储在多个分区中。
- en: To keep track of the partitions where a given vertex is stored redundantly,
    a routing RDD is also maintained, containing the vertex details and the partitions
    in which each vertex is available.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟踪给定顶点冗余存储的分区，还维护了一个路由 RDD，其中包含顶点详情以及每个顶点可用的分区。
- en: '*Figure 5* explains this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5* 解释了这一点：'
- en: '![Graph partitioning](img/image_08_005.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图分区](img/image_08_005.jpg)'
- en: Figure 5
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5
- en: In *Figure 5*, assume that the edges are partitioned into partitions 1 and 2\.
    Also assume that the vertices are partitioned into partitions 1 and 2.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 5* 中，假设边被分区到分区 1 和 2。同样假设顶点被分区到分区 1 和 2。
- en: In partition 1, all the vertices required for the edges are available locally.
    But in partition 2, only one vertex for the edge is available locally. So the
    missing vertex is also stored in partition 2 so that all the required vertices
    are available locally.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在分区 1 中，所有所需的顶点都可用于边的本地。但在分区 2 中，只有边的一个顶点可用于本地。因此，缺失的顶点也存储在分区 2 中，以便所有所需的顶点都可在本地获得。
- en: To keep track of the replications, the vertex routing RDD maintains the partition
    numbers where a given vertex is available. In *Figure 5*, in the vertex routing
    RDD, callout symbols are used to show the partitions in which these vertices are
    replicated. In this way, while processing the edges or triplets, all the information
    related to the constituent vertices is available locally and performance will
    be highly optimal. Since the RDDs are immutable, the problems associated with
    information getting changed are removed, even if they are stored in multiple partitions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟踪复制，顶点路由 RDD 维护了给定顶点可用的分区号。在 *图 5* 中，在顶点路由 RDD 中，使用标注符号来显示这些顶点复制的分区。这样，在处理边或三元组时，所有与构成顶点相关的信息都可在本地获得，性能将非常优化。由于
    RDD 是不可变的，因此即使它们存储在多个分区中，与信息更改相关的问题也被消除了。
- en: Graph processing
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图处理
- en: The constituent elements of a graph exposed to the users are the vertex RDD
    and the edge RDD. Just like any other data structure, a graph also undergoes lots
    of changes because of the change in the underlying data. To make the required
    graph operations to support various use cases, there are many algorithms available,
    using which the data hidden in the graph data structure can be processed to produce
    the desired business outcomes. Before getting into the algorithms to process a
    graph, it is good to understand some of the basics of graph processing using an
    air travel use case.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 用户暴露的图的构成元素是顶点 RDD 和边 RDD。就像任何其他数据结构一样，由于底层数据的改变，图也会经历许多变化。为了支持各种用例所需的图操作，有许多算法可用，使用这些算法可以处理图数据结构中的数据，以产生预期的业务结果。在深入了解处理图的算法之前，了解一些使用航空旅行用例的图处理基础知识是很好的。
- en: 'Assume that a person is trying to find a cheap return air ticket from Manchester
    to Bangalore. In the travel preferences, this person has mentioned that he/she
    doesn''t care about the number of stops but the price should be the lowest. Assume
    that the air ticket reservation system has picked up the same stops for both the
    onward and the return journey and produced the following routes or journey legs
    with the cheapest price:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一个人正在尝试从曼彻斯特到班加罗尔的便宜往返机票。在旅行偏好中，这个人提到他/她不关心停靠次数，但价格应该是最低的。假设机票预订系统为单程和返程旅程选择了相同的停靠点，并产生了以下路线或旅程段，以最低的价格：
- en: Manchester → London → Colombo → Bangalore
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Manchester → London → Colombo → Bangalore
- en: Bangalore → Colombo → London → Manchester
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Bangalore → Colombo → London → Manchester
- en: 'This route plan is a perfect example of a graph. If the onward journey is considered
    as one graph and the return journey is considered as another graph, the return
    journey graph can be produced by reversing the onward journey graph. At the Scala
    REPL prompt, try the following statements:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这条路线计划是图的完美例子。如果将单程旅程视为一个图，而返程旅程视为另一个图，则可以通过反转单程旅程图来生成返程旅程图。在 Scala REPL 提示符下，尝试以下语句：
- en: '[PRE1]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The source and destination of the onward journey legs are reversed in the return
    journey legs. When a graph is reversed, only the source and destination vertices
    of the edges are reversed and the identity of the vertices remains the same.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在返程旅程段中，单程旅程段的目的地和起点被反转。当一个图被反转时，只有边的源点和目标点被反转，顶点的身份保持不变。
- en: 'In other words, the vertex identifiers of each of the vertices remain the same.
    While processing a graph, it is important to know the names of the triplet attributes.
    They are useful for writing programs and processing the graph. As a continuation
    of the same Scala REPL session, try the following statements:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，每个顶点的顶点标识符保持不变。在处理图时，了解三元属性的名字很重要。它们对于编写程序和处理图非常有用。作为同一Scala REPL会话的延续，尝试以下语句：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following table gives the list of attributes of a triplet that can be used
    to process a graph and extract the required data from the graph. The preceding
    code snippet and the following table may be cross-verified to fully understand:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 下表列出了可以用来处理图并从图中提取所需数据的属性列表。前面的代码片段和下面的表格可以相互验证，以全面理解：
- en: '| **Triplet attribute** | **Description** |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| **三元属性** | **描述** |'
- en: '| `srcId` | Source vertex identifier |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| `srcId` | 源顶点标识符 |'
- en: '| `dstId` | Destination vertex identifier |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| `dstId` | 目标顶点标识符 |'
- en: '| `attr` | Edge property |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `attr` | 边属性 |'
- en: '| `srcAttr` | Source vertex property |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `srcAttr` | 源顶点属性 |'
- en: '| `dstAttr` | Destination vertex property |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| `dstAttr` | 目标顶点属性 |'
- en: In a graph, vertices are RDDs and edges are RDDs, and just by virtue of that,
    transformations are possible.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个图中，顶点是RDD，边也是RDD，正因为如此，才可能进行转换。
- en: 'Now, to demonstrate graph transformations, the same use case is used, with
    a slight twist. Assume that a travel agent is getting special discount prices
    from the airline companies for selected routes. The travel agent decides to keep
    the discount and offer the market price to his/her customers, and for this purpose
    he/she adds 10% to the price given by the airline company. This travel agent has
    noticed that the airport names are being displayed inconsistently and wanted to
    make sure that there is consistent representation when displayed throughout the
    website and decides to change all the stop names to upper case. As a continuation
    of the same Scala REPL session, try the following statements:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了演示图转换，使用相同的使用案例，但略有变化。假设一个旅行社从航空公司为选择的航线获得特殊的折扣价格。旅行社决定保留折扣并向客户提供市场价格，为此，他在航空公司给出的价格上增加了10%。这位旅行社注意到机场名称显示不一致，并确保在整个网站上显示时保持一致的表现，因此决定将所有停靠站名称更改为大写。作为同一Scala
    REPL会话的延续，尝试以下语句：
- en: '[PRE3]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In essence, these transformations are truly RDD transformations. If there is
    a conceptual understanding of how these different RDDs are cobbled together to
    form a graph, any programmer with RDD programming proficiency will be able to
    do graph processing very well. This is another testament to the power of the unified
    programming model of Spark.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，这些转换确实是RDD转换。如果对如何将这些不同的RDD组合在一起形成图有概念性的理解，那么任何具有RDD编程能力的程序员都能够很好地进行图处理。这是Spark统一编程模型强大功能的又一例证。
- en: The preceding use case did the map transformation on vertex and edge RDDs. Similarly,
    filter transformations are another useful type that is commonly used. Apart from
    these, all the transformations and actions can be used to process the vertex and
    edge RDDs.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的使用案例对顶点和边RDD进行了map转换。同样，filter转换也是另一种常用的有用类型。除了这些，所有转换和操作都可以用来处理顶点和边RDD。
- en: Graph structure processing
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图结构处理
- en: 'In the previous section, one type of graph processing is done by individually
    processing the required vertices or edges. One disadvantage of this approach is
    that the processing is going through three different stages, as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，一种图处理方式是通过单独处理所需的顶点或边来完成的。这种方法的缺点是处理过程需要经过三个不同的阶段，如下所示：
- en: Extract vertices or edges from the graph
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从图中提取顶点或边
- en: Process the vertices or edges
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理顶点或边
- en: Re-create a new graph with the processed vertices and edges
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新创建一个包含处理过的顶点和边的新图
- en: This is tedious and prone to user programming errors. To circumvent this problem,
    there are some structural operators available in the Spark GraphX library that
    let users process the graph as an individual unit that produces a new graph.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这很繁琐且容易导致用户编程错误。为了解决这个问题，Spark GraphX库中提供了一些结构化操作符，允许用户将图作为一个独立的单元进行处理，从而生成一个新的图。
- en: One important structural operation has already been discussed in the previous
    section, which is the reversal of a graph producing a new graph with all the directions
    of the edges reversed. Another frequently used structural operation is the extraction
    of a subgraph from a given graph. The resultant subgraph can be the entire parent
    graph itself or a subset of the parent graph, depending on the operation that
    is done on the parent graph.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个部分中已经讨论了一个重要的结构运算，即图的反转，它产生一个所有边方向都反转的新图。另一个常用的结构运算是从给定图中提取子图。结果子图可以是整个父图本身，也可以是父图的一个子集，具体取决于对父图进行的操作。
- en: 'When creating a graph from data from external sources, there is a possibility
    that the edges may have invalid vertices. This is very much a possibility if the
    vertices and the edges are created from the data coming from two different sources
    or different applications. With these vertices and edges, if a graph is created,
    some of the edges will have invalid vertices, and processing will result in unexpected
    outcomes. The following is a use case where some of the edges containing invalid
    vertices and pruning are done to get rid of that using a structural operator.
    At the Scala REPL prompt, try the following statements:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当从外部数据源创建图表时，可能会出现边具有无效顶点的情况。如果顶点和边是由来自两个不同来源或不同应用程序的数据创建的，这种情况尤为可能。使用这些顶点和边创建图表时，一些边将具有无效顶点，处理结果可能会出现意外。以下是一个用例，其中对包含无效顶点的边进行了剪枝操作，以使用结构运算符消除这些问题。在Scala
    REPL提示符下，尝试以下语句：
- en: '[PRE4]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In huge graphs, at times depending on the use case, there can be a whole lot
    of parallel edges. In some use cases, it is possible to combine the data of the
    parallel edges and maintain only one edge instead of maintaining lots of parallel
    edges. In the preceding use case, the final graph without any invalid edges, there
    are parallel edges, one with the property `Follows` and the other with `Son`,
    which have the same source and destination vertices.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型图中，有时根据用例，可能会有大量的并行边。在某些用例中，可以将并行边的数据进行合并，只维护一条边，而不是维护大量并行边。在前面的用例中，最终没有无效边的图，存在并行边，一个具有`Follows`属性，另一个具有`Son`属性，它们具有相同的源和目标顶点。
- en: 'It is fine to combine these parallel edges into one single edge with the property
    concatenated from the parallel edges, which will reduce the number of edges without
    losing information. This is accomplished by the groupEdges structural operation
    of the graph. As a continuation of the same Scala REPL session, try the following
    statements:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些并行边合并成一条具有从并行边拼接的属性的单一边是可以的，这将减少边的数量而不会丢失信息。这是通过图的groupEdges结构运算完成的。作为同一Scala
    REPL会话的延续，尝试以下语句：
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The preceding structural change in the graph reduced the number of edges by
    grouping the edges. When the edge property is numerical, and if it makes sense
    to consolidate by aggregating them, then also reduce the number of edges by removing
    the parallel edges, which can reduce the graph processing time considerably.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的前述结构变化通过分组边减少了边的数量。当边属性是数值型，并且通过聚合它们进行合并是有意义的，那么也可以通过移除并行边来减少边的数量，这可以显著减少图处理时间。
- en: Note
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: One important point to note in this code snippet is that the graph has been
    partitioned before the group-by operation on the edges.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码片段中需要注意的一个重要点是，在边上的group-by操作之前，图已经被分区。
- en: By default, the edges and the constituent vertices of a given graph need not
    be co-located in the same partition. For the group-by operation to work, all the
    parallel edges have to be located on the same partition. The CanonicalRandomVertexCut
    partition strategy makes sure that colocation happens for all the edges between
    two vertices, irrespective of direction.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，给定图的边和构成顶点不需要位于同一分区。为了使group-by操作生效，所有并行边都必须位于同一分区。CanonicalRandomVertexCut分区策略确保两个顶点之间的所有边都发生本地化，无论方向如何。
- en: There are some more structural operators available in the Spark GraphX library
    and a consultation of the Spark documentation will give a good insight into them.
    They can be used depending on the use case.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX库中还有一些其他结构运算符可用，查阅Spark文档将提供对这些运算符的深入了解。它们可以根据用例使用。
- en: Tennis tournament analysis
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网球锦标赛分析
- en: 'Since the basic graph processing fundamentals are in place, now it is time
    to take up a real-world use case that uses graphs. Here, a tennis tournament''s
    results are modeled using a graph. The Barclays ATP World Tour 2015 singles competition
    results are modeled using a graph. The vertices contain the player details and
    the edges contain the individual matches played. The edges are formed in such
    a way that the source vertex is the player who won the match and the destination
    vertex is the player who lost the match. The edge property contains the type of
    the match, the points the winner got in the match, and the head-to-head count
    of the players in the match. The points system used here is fictitious and is
    nothing but a weight earned by the winner in that particular match. The initial
    group matches carried the least weight, the semi-final matches carried more weight,
    and the final match carried the most weight. With this way of modeling the results,
    find out the following details by processing the graph:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于基本的图处理基础已经建立，现在是时候处理一个使用图的现实世界用例了。在这里，网球锦标赛的结果是通过图来建模的。2015年巴克莱斯ATP世界巡回赛单打比赛的结果是通过图来建模的。顶点包含球员详情，边包含个人比赛。边是以这样的方式形成的，即源顶点是赢得比赛的球员，目标顶点是输掉比赛的球员。边属性包含比赛类型、获胜者在比赛中获得的分数以及比赛中球员的头对头计数。这里使用的积分系统是虚构的，它只是获胜者在特定比赛中获得的一种权重。初始小组赛携带的权重最小，半决赛携带的权重更大，决赛携带的权重最大。通过这种方式建模结果，通过处理图来找出以下详细信息：
- en: List all the match details.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有比赛详情。
- en: List all the matches with player names, the match type, and the result.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有比赛，包括球员姓名、比赛类型和结果。
- en: List all the Group 1 winners with the points in the match.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有第一组获胜者及其比赛中的得分。
- en: List all the Group 2 winners with the points in the match.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有第二组获胜者及其比赛中的得分。
- en: List all the semi-final winners with the points in the match.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有半决赛获胜者及其比赛中的得分。
- en: List the final winner with the points in the match.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出比赛中的得分详情的最终获胜者。
- en: List the players with the total points they earned in the whole tournament.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出在整个锦标赛中赢得的总分的球员名单。
- en: List the winner of the match by finding the highest number of points scored
    by the player.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过找出球员在比赛中获得的最高得分来列出比赛的获胜者。
- en: In the group-based matches, because of the round robin scheme of draws, it is
    possible that the same players can meet more than once. Find if there are any
    such players who have played each other more than once in this tournament.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在基于小组的比赛，由于循环赛制的平局，相同的球员可能会相遇多次。找出在这个锦标赛中相互比赛超过一次的球员。
- en: List the players who have won at least one match.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出至少赢得一场比赛的球员名单。
- en: List the players who have lost at least one match.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出至少输掉一场比赛的球员名单。
- en: List the players who have won at least one match and lost at least one match.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出至少赢得一场比赛和至少输掉一场比赛的球员名单。
- en: List the players who have no wins at all.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出一场比赛都没有赢的球员名单。
- en: List the players who have no losses at all.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出一场比赛都没有输的球员名单。
- en: 'Those who are not familiar with the game of tennis have no need to worry because
    the rules of the games are not discussed here and are not required to understand
    this use case. For all practical purposes, it is to be taken only as a game played
    between two people, where one wins and the other loses. At the Scala REPL prompt,
    try the following statements:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不熟悉网球游戏的人来说，没有必要担心，因为这里没有讨论游戏规则，也不需要理解这个用例。从所有实际目的来看，它只被视为两个人之间进行的游戏，其中一人获胜，另一人失败。在Scala
    REPL提示符下，尝试以下语句：
- en: '[PRE6]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The graph containing the tennis tournament has been created, and from now on,
    all that is going to be done is the processing of this base graph and extracting
    information from it to fulfill the requirements of the use cases:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 网球锦标赛的图已经创建，从现在开始，将要进行的所有操作都是对这个基本图的加工以及从中提取信息以满足用例的要求：
- en: '[PRE7]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It is worth noticing here that the usage of triplets in graphs comes in handy
    for extracting all the required data elements of a given tennis match, including
    who was playing, who won, and the match type, from a single object. The following
    implementations of analysis use cases involve filtering the tennis match records
    of the tournament. Here, only simple filtering logic is used, but in real-world
    use cases, any complex logic can be implemented in functions, and that can be
    passed as arguments to the filter transformations:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，在图中使用三元组对于从单个对象中提取给定网球比赛的所需所有数据元素非常有用，包括谁在比赛、谁获胜以及比赛类型。以下分析用例的实现涉及筛选锦标赛的网球比赛记录。在这里，只使用了简单的过滤逻辑，但在现实世界的用例中，任何复杂的逻辑都可以在函数中实现，并且可以作为参数传递给过滤转换：
- en: '[PRE8]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following implementations of analysis use cases involve grouping by key
    and doing summary calculations. It is not limited to just finding the sum of the
    tennis match record points, as shown in the following use case implementations;
    rather, user-defined functions can be used to do the calculations as well:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下分析用例的实现涉及按键分组并进行汇总计算。它不仅限于找到网球比赛记录点的总和，如以下用例实现所示；相反，可以使用用户定义的函数来进行计算：
- en: '[PRE9]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following implementations of analysis use cases involve finding unique
    records from the query. The Spark distinct transformation does that:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下分析用例的实现涉及从查询中查找唯一记录。Spark的distinct转换可以做到这一点：
- en: '[PRE10]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In this use case, not much effort has been made to make the results pretty because
    they are reduced to simple RDD-based structures that can be manipulated however
    required using the RDD programming techniques that were already covered in the
    initial chapters of the book.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个用例中，并没有花费太多精力使结果看起来更美观，因为它们被简化为基于RDD的结构，可以使用书中最初章节中已经介绍过的RDD编程技术进行所需的操作。
- en: The highly succinct and uniform programming model of Spark, in conjunction with
    the Spark GraphX library, helps developers build real-world use cases with very
    few lines of code. This also demonstrates that once the right graph structure
    is built with the relevant data, with the supported graph operations, lots of
    truth that is hidden in the underlying data can be brought to light.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的高效和统一的编程模型，结合Spark GraphX库，帮助开发者用很少的代码构建现实世界的用例。这也证明了，一旦用相关数据构建了正确的图结构，并支持相应的图操作，就可以揭示隐藏在底层数据中的许多真相。
- en: Applying the PageRank algorithm
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用PageRank算法
- en: A research paper, titled *The Anatomy of a Large-Scale Hypertextual Web Search
    Engine,* by Sergey Brin and Lawrence Page, revolutionized web searching, and Google
    based its search engine on this concept of PageRank and came to dominate other
    web search engines.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇名为《大规模超文本搜索引擎的解剖学》的研究论文，由谢尔盖·布林和拉里·佩奇撰写，彻底改变了网络搜索，谷歌的搜索引擎就是基于这种PageRank概念而建立的，并最终主导了其他网络搜索引擎。
- en: When searching the web using Google, pages that are ranked highly by its algorithm
    are displayed. In the context of graphs, instead of web pages, if vertices are
    ranked based on the same algorithm, lots of new inferences can be made. From the
    outside, it may sound like this PageRank algorithm is useful only for web searches.
    But it has immense potential to be applied to many other areas.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用谷歌搜索网络时，其算法排名靠前的页面会被显示出来。在图论中，如果顶点根据相同的算法进行排名，而不是网页，就可以得出许多新的推论。从外部来看，这个PageRank算法可能听起来只对网络搜索有用。但它具有在许多其他领域应用的巨大潜力。
- en: In graph parlance, if there is an edge, E, connecting two vertices, from V1
    to V2, according to the PageRank algorithm, V2 is more important than V1\. In
    a huge graph of vertices and edges, it is possible to calculate the PageRank of
    each and every vertex.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在图论中，如果存在一个边E连接两个顶点，从V1到V2，根据PageRank算法，V2比V1更重要。在一个由顶点和边组成的大型图中，可以计算每个顶点的PageRank。
- en: The PageRank algorithm can be applied very well to the tennis tournament analysis
    use case covered in the preceding section. In the graph representation that is
    adopted here, each match is represented as an edge. The source vertex has the
    winner's details and the destination vertex has the loser's details. In the game
    of tennis, if this can be termed as some fictitious importance ranking, then in
    a given match the winner has higher importance ranking than the loser.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: PageRank算法可以很好地应用于前面章节中涵盖的网球锦标赛分析用例。在本节采用的图表示中，每场比赛由一条边表示。源顶点包含胜者的详细信息，目标顶点包含败者的详细信息。在网球比赛中，如果这可以称为某种虚构的重要性排名，那么在给定比赛中，胜者的重要性排名高于败者。
- en: 'If the graph in the previous use case is taken to demonstrate the PageRank
    algorithm, then that graph has to be reversed so that the winner of each match
    becomes the destination vertex of each and every edge. At the Scala REPL prompt,
    try the following statements:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将前一个用例中的图用来演示PageRank算法，那么该图必须反转，使得每场比赛的胜者成为每条边的目标顶点。在Scala REPL提示符下，尝试以下语句：
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If the preceding code is scrutinized carefully, it can be seen that the highest
    ranked players have won the highest number of matches.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仔细审查前面的代码，可以看出排名最高的玩家赢得了最多的比赛。
- en: Connected component algorithm
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连通分量算法
- en: In a graph, finding a subgraph consisting of connected vertices is a very common
    requirement with tremendous applications. In any graph, two vertices are that
    connected to each other by paths consisting of one or more edges, and are not
    connected to any other vertex in the same graph, are called a connected component.
    For example, in a graph, G, vertex V1 is connected to V2 by an edge and V2 is
    connected to V3 by another edge. In the same graph, G, vertex V4 is connected
    to V5 by another edge. In this case V1 and V3 are connected, V4 and V5 are connected
    and V1 and V5 are not connected. In graph G, there are two connected components.
    The Spark GraphX library has an implementation of the connected components algorithm.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个图中，找到由连通顶点组成的子图是一个非常常见的需求，具有巨大的应用。在任何图中，两个顶点通过由一个或多个边组成的路径相互连接，并且不与图中任何其他顶点连接，这些顶点被称为连通分量。例如，在一个图G中，顶点V1通过一条边与V2连接，V2通过另一条边与V3连接。在同一个图G中，顶点V4通过另一条边与V5连接。在这种情况下，V1和V3是连通的，V4和V5是连通的，而V1和V5是不连通的。在图G中，有两个连通分量。Spark
    GraphX库实现了连通分量算法。
- en: In a social networking application, if the connections between the users are
    modeled as a graph, finding whether a given user is connected to another user
    is achieved by checking whether there is a connected component with these two
    vertices. In computer games, maze traversing from point A to point B can be done
    using a connected components algorithm by modeling the maze junctions as vertices
    and the paths connecting the junctions as edges in a graph.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在社交网络应用程序中，如果将用户之间的连接建模为图，检查给定用户是否与另一个用户连接，可以通过检查是否存在包含这两个顶点的连通分量来实现。在计算机游戏中，从点A到点B的迷宫穿越可以通过将迷宫的交汇点建模为顶点，将连接交汇点的路径建模为图中的边来使用连通分量算法完成。
- en: 'In computer networks, checking whether packets can be sent from one IP address
    to another IP address is achieved by using a connected components algorithm. In
    logistics applications, such as a courier service, checking whether a packet can
    be sent from point A to point B is achieved by using a connected components algorithm.
    *Figure 6* shows a graph with three connected components:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机网络中，通过使用连通分量算法来检查是否可以从一个IP地址向另一个IP地址发送数据包。在物流应用中，例如快递服务，通过使用连通分量算法来检查是否可以从点A向点B发送数据包。*图6*显示了具有三个连通分量的图：
- en: '![Connected component algorithm](img/image_08_006.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![连通分量算法](img/image_08_006.jpg)'
- en: Figure 6
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图6
- en: '*Figure 6* is the pictorial representation of a graph. In it, there are three
    *clusters* of vertices connected by edges. In other words, there are three connected
    components in this graph.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6*是图的图形表示。在其中，有三个通过边连接的顶点*簇*。换句话说，在这个图中有三个连通分量。'
- en: 'The use case of users in a social networking application in which they follow
    each other is taken up here again for elucidation purposes. By extracting the
    connected components of the graph, it is possible to see whether any two users
    are connected or not. *Figure 7* shows the user graph:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这里再次以社交网络应用中用户相互关注的使用场景为例进行说明。通过提取图的连通分量，可以查看任何两个用户是否相连。*图 7* 展示了用户图：
- en: '![Connected component algorithm](img/image_08_007.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![连通分量算法](img/image_08_007.jpg)'
- en: Figure 7
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7
- en: 'In the graph depicted in *Figure 7*, it is clearly evident that there are two
    connected components. It is easy to say that Thomas and Mathew are connected and
    at the same time Thomas and Martin are not connected. If the connected component
    graph is extracted, it can be seen that Thomas and Martin will have the same connected
    component identifier, and at the same time, Thomas and Martin will have a different
    connected component identifiers. At the Scala REPL prompt, try the following statements:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 7* 所示的图中，很明显存在两个连通分量。可以说托马斯和马修是相连的，同时托马斯和马丁是不相连的。如果提取连通分量图，可以看到托马斯和马丁将具有相同的连通分量标识符，同时，托马斯和马丁将具有不同的连通分量标识符。在
    Scala REPL 提示符下，尝试以下语句：
- en: '[PRE12]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: There are some more graph processing algorithms available in the Spark GraphX
    library, and a detailed treatment of the complete set of algorithms deserves book
    on its own. The point here is that the Spark GraphX library provides very easy-to-use
    graph algorithms that fit very well into Spark's uniform programming model.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX 库中还有一些其他的图处理算法，对完整算法集的详细处理足以写成一本书。这里要说明的是，Spark GraphX 库提供了非常易于使用的图算法，这些算法非常适合
    Spark 的统一编程模型。
- en: Understanding GraphFrames
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 GraphFrames
- en: The Spark GraphX library is the graph processing library that has the least
    programming language support. Scala is the only programming language supported
    by the Spark GraphX library. GraphFrames is a new graph processing library available
    as an external Spark package developed by Databricks, University of California,
    Berkley, and Massachusetts Institute of Technology, built on top of Spark DataFrames.
    Since it is built on top of DataFrames, all the operations that can be done on
    DataFrames are potentially possible on GraphFrames, with support for programming
    languages such as Scala, Java, Python, and R with a uniform API. Since GraphFrames
    is built on top of DataFrames, the persistence of data, support for numerous data
    sources, and powerful graph queries in Spark SQL are additional benefits users
    get for free.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX 库是支持编程语言最少的图处理库。Scala 是 Spark GraphX 库唯一支持的编程语言。GraphFrames 是一个由
    Databricks、加州大学伯克利分校和麻省理工学院开发的新的图处理库，作为一个外部 Spark 包提供，它建立在 Spark DataFrames 之上。由于它是建立在
    DataFrames 之上的，因此 DataFrame 上可以进行的所有操作在 GraphFrames 上都有可能实现，并支持 Scala、Java、Python
    和 R 等编程语言，具有统一的 API。由于 GraphFrames 是建立在 DataFrames 之上的，因此数据的持久性、对众多数据源的支持以及 Spark
    SQL 中的强大图查询是用户免费获得的额外好处。
- en: Just like the Spark GraphX library, in GraphFrames the data is stored in vertices
    and edges. The vertices and edges use DataFrames as the data structure. The first
    use case covered in the beginning of this chapter is used again to elucidate GraphFrames-based
    graph processing.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 就像 Spark GraphX 库一样，在 GraphFrames 中，数据存储在顶点和边中。顶点和边使用 DataFrame 作为数据结构。本章开头讨论的第一个用例再次用于说明基于
    GraphFrames 的图处理。
- en: Note
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**CAUTION**: GraphFrames is an external Spark package. It has some incompatibility
    with Spark 2.0\. Because of that, the following code snippets will not work with
    Spark 2.0\. They work with Spark 1.6\. Refer to their website to check Spark 2.0
    support.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**：GraphFrames 是一个外部 Spark 包。它与 Spark 2.0 存在一些不兼容性。因此，以下代码片段在 Spark 2.0
    中将无法工作。它们在 Spark 1.6 中可以工作。请参考他们的网站以检查 Spark 2.0 的支持情况。'
- en: 'At the Scala REPL prompt of Spark 1.6, try the following statements. Since
    GraphFrames is an external Spark package, while bringing up the appropriate REPL,
    the library has to be imported and the following command is used in the terminal
    prompt to fire up the REPL and make sure that the library is loaded without any
    error messages:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Spark 1.6 的 Scala REPL 提示符下，尝试以下语句。由于 GraphFrames 是一个外部 Spark 包，在启动适当的 REPL
    时，必须导入库，并在终端提示符中使用以下命令来启动 REPL 并确保库加载时没有错误信息：
- en: '[PRE13]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: When creating DataFrames for the GraphFrame, the only thing to keep in mind
    is that there are some mandatory columns for the vertices and the edges. In the
    DataFrame for vertices, the id column is mandatory. In the DataFrame for edges,
    the src and dst columns are mandatory. Apart from that, any number of arbitrary
    columns can be stored with both the vertices and the edges of a GraphFrame. In
    the Spark GraphX library, the vertex identifier must be a long integer, but the
    GraphFrame doesn't have any such limitations and any type is supported as the
    vertex identifier. Readers should already be familiar with DataFrames; any operation
    that can be done on a DataFrame can be done on the vertices and edges of a GraphFrame.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建GraphFrame的DataFrame时，需要注意的唯一事项是，对于顶点和边有一些强制性的列。在顶点的DataFrame中，id列是强制性的。在边的DataFrame中，src和dst列是强制性的。除此之外，可以存储任意数量的任意列，与GraphFrame的顶点和边一起。在Spark
    GraphX库中，顶点标识符必须是长整数，但GraphFrame没有这样的限制，支持任何类型的顶点标识符。读者应该已经熟悉DataFrame；可以在GraphFrame的顶点和边上执行任何可以在DataFrame上执行的操作。
- en: Tip
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: All the graph processing algorithms supported by Spark GraphX are supported
    by GraphFrames as well.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX支持的 所有图处理算法，GraphFrames也支持。
- en: The Python version of GraphFrames has fewer features. Since Python is not a
    supported programming language for the Spark GraphX library, GraphFrame to GraphX
    and GraphX to GraphFrame conversions are not supported in Python. Since readers
    are familiar with the creation of DataFrames in Spark using Python, the Python
    example is omitted here. Moreover, there are some pending defects in the GraphFrames
    API for Python and not all the features demonstrated previously using Scala function
    properly in Python at the time of writing.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: GraphFrames的Python版本功能较少。由于Python不是Spark GraphX库的支持编程语言，因此Python中不支持GraphFrame到GraphX和GraphX到GraphFrame的转换。由于读者熟悉使用Python在Spark中创建DataFrame，因此这里省略了Python示例。此外，GraphFrames
    API的Python版本中还有一些悬而未决的缺陷，并且截至写作时，之前使用Scala函数演示的所有功能在Python中可能无法正常工作。
- en: Understanding GraphFrames queries
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解GraphFrames查询
- en: The Spark GraphX library is the RDD-based graph processing library, but GraphFrames
    is a Spark DataFrame-based graph processing library that is available as an external
    package. Spark GraphX supports many graph processing algorithms, but GraphFrames
    supports not only graph processing algorithms, but also graph queries. The major
    difference between graph processing algorithms and graph queries is that graph
    processing algorithms are used to process the data hidden in a graph data structure,
    while graph queries are used to search for patterns in the data hidden in a graph
    data structure. In GraphFrame parlance, graph queries are also known as motif
    finding. This has tremendous applications in genetics and other biological sciences
    that deal with sequence motifs.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX库是基于RDD的图处理库，但GraphFrames是一个基于Spark DataFrame的图处理库，它作为一个外部包提供。Spark
    GraphX支持许多图处理算法，但GraphFrames不仅支持图处理算法，还支持图查询。图处理算法和图查询之间的主要区别在于，图处理算法用于处理图数据结构中隐藏的数据，而图查询用于在图数据结构中隐藏的数据中搜索模式。在GraphFrame的术语中，图查询也被称为模式发现。这在处理序列模式的遗传学和其他生物科学领域有巨大的应用。
- en: From a use case perspective, take the use case of users following each other
    in a social media application. Users have relationships between them. In the previous
    sections, these relationships were modeled as graphs. In real-world use cases,
    such graphs can become really huge, and if there is a need to find users with
    relationships between them in both directions, it can be expressed as a pattern
    in graph query, and such relationships can be found using easy programmatic constructs.
    The following demonstration models the relationship between the users in a GraphFrame,
    and a pattern search is done using that.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 从用例的角度来看，以社交媒体应用中用户相互关注为例。用户之间存在关系。在前面的章节中，这些关系被建模为图。在现实世界的用例中，这样的图可以变得非常大，如果需要找到在两个方向上都有关系的用户，这可以表示为图查询中的模式，并且可以使用简单的程序结构找到这样的关系。以下演示在GraphFrame中建模用户之间的关系，并使用该模式进行搜索。
- en: 'At the Scala REPL prompt of Spark 1.6, try the following statements:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark 1.6的Scala REPL提示符下，尝试以下语句：
- en: '[PRE14]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note that the columns in the graph query result are formed with the elements
    given in the search pattern. There is no limit to the way the patterns can be
    formed.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，图查询结果中的列是由搜索模式中给出的元素组成的。模式的形成方式没有限制。
- en: Note
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note the data type of the graph query result. It is a DataFrame object. That
    brings a great flexibility in processing the query results using the familiar
    Spark SQL library.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 注意图查询结果的数据类型。它是一个DataFrame对象。这为使用熟悉的Spark SQL库处理查询结果带来了极大的灵活性。
- en: The biggest limitation of the Spark GraphX library is that its API is not currently
    supported with programming languages such as Python and R. Since GraphFrames is
    a DataFrame-based library, once it has matured, it will enable graph processing
    in all the programming languages supported by DataFrames. This Spark external
    package is definitely a potential candidate to be included as part of the Spark.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX库的最大局限性是其API目前不支持Python和R等编程语言。由于GraphFrames是一个基于DataFrame的库，一旦它成熟，它将使所有支持DataFrame的编程语言都能进行图处理。这个Spark外部包无疑是作为Spark一部分的潜在候选者。
- en: References
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'For more information please visit the following links:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如需更多信息，请访问以下链接：
- en: '[https://spark.apache.org/docs/1.5.2/graphx-programming-guide.html](https://spark.apache.org/docs/1.5.2/graphx-programming-guide.html)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/1.5.2/graphx-programming-guide.html](https://spark.apache.org/docs/1.5.2/graphx-programming-guide.html)'
- en: '[https://en.wikipedia.org/wiki/2015_ATP_World_Tour_Finals_%E2%80%93_Singles](https://en.wikipedia.org/wiki/2015_ATP_World_Tour_Finals_%E2%80%93_Singles)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://en.wikipedia.org/wiki/2015_ATP_World_Tour_Finals_%E2%80%93_Singles](https://en.wikipedia.org/wiki/2015_ATP_World_Tour_Finals_%E2%80%93_Singles)'
- en: '[http://www.protennislive.com/posting/2015/605/mds.pdf](http://www.protennislive.com/posting/2015/605/mds.pdf)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.protennislive.com/posting/2015/605/mds.pdf](http://www.protennislive.com/posting/2015/605/mds.pdf)'
- en: '[http://infolab.stanford.edu/~backrub/google.html](http://infolab.stanford.edu/~backrub/google.html)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://infolab.stanford.edu/~backrub/google.html](http://infolab.stanford.edu/~backrub/google.html)'
- en: '[http://graphframes.github.io/index.html](http://graphframes.github.io/index.html)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://graphframes.github.io/index.html](http://graphframes.github.io/index.html)'
- en: '[https://github.com/graphframes/graphframes](https://github.com/graphframes/graphframes)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/graphframes/graphframes](https://github.com/graphframes/graphframes)'
- en: '[https://spark-packages.org/package/graphframes/graphframes](https://spark-packages.org/package/graphframes/graphframes)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://spark-packages.org/package/graphframes/graphframes](https://spark-packages.org/package/graphframes/graphframes)'
- en: Summary
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: A Graph is a very useful data structure that has great application potential.
    Even though it is not very commonly used in most applications, there are some
    unique application use cases where using a Graph as a data structure is essential.
    A data structure is effectively used only when it is used in conjunction with
    well tested and highly optimized algorithms. Mathematicians and computer scientists
    have come up with many algorithms to process data that is part of a graph data
    structure. The Spark GraphX library has a large number of such algorithms implemented
    on top of the Spark core. This chapter provided a whirlwind tour of the Spark
    GraphX library and covered some of the basics through use cases at an introductory
    level.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图是一种非常有用的数据结构，具有巨大的应用潜力。尽管在大多数应用中并不常用，但有一些独特的应用场景，在这些场景中使用图作为数据结构是必不可少的。只有当数据结构与经过良好测试和高度优化的算法结合使用时，数据结构才能有效利用。数学家和计算机科学家已经提出了许多算法来处理图数据结构中的数据。Spark
    GraphX库在Spark核心之上实现了大量此类算法。本章简要介绍了Spark GraphX库，并通过入门级别的用例覆盖了一些基础知识。
- en: The DataFrame-based graph abstraction named GraphFrames, which comes in an external
    Spark package available separately from Spark, has tremendous potential in graph
    processing as well as graph queries. A brief introduction to this external Spark
    package has been provided in order to do graph queries to find patterns in graphs.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 名为GraphFrames的基于DataFrame的图抽象，它是一个外部Spark包，可以从Spark独立获取，在图处理和图查询方面具有巨大的潜力。为了进行图查询以找到图中的模式，已提供了对该外部Spark包的简要介绍。
- en: Any book teaching a new technology has to conclude with an application covering
    its salient features. Spark is no different. So far in this book, Spark as a next
    generation data processing platform has been covered. Now it is the time to tie
    up all the loose ends and build an end-to-end application. The next chapter is
    going to cover the design and development of a data processing application using
    Spark and the family of libraries built on top of it.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 任何一本教授新技术书籍都必须以一个涵盖其显著特性的应用来结尾。Spark也不例外。到目前为止，本书已经涵盖了Spark作为一个下一代数据处理平台的内容。现在，是时候将所有松散的环节串联起来，构建一个端到端的应用程序了。下一章将介绍使用Spark及其构建在其之上的库族来设计和开发数据处理应用程序。
